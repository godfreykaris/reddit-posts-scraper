[
{"Title": "Official Giveaway: June 2024 Seagate IronWolf Pro 16TB Hard Drive Giveaway", "Author": "u/Seagate_Surfer", "Content": "Hi \nr/DataHoarder\n crowd! We love your sub and would like to rev up another giveaway with the permission of the mod team.\n  \n\n    The prize is: one 16TB IronWolf Pro Hard Disk Drive\n  \n\n\nHow to enter:\n\n\n\n\nJust reply to this post once with a top-level comment response on the following topic:\n\n\n\n\nWhat kind of loyalty program matters to you for a company? Is drive capacity, price point, excellent customer service, etc. the highest priority for you? Please include the phrases RunWithIronWolf and Seagate in your comment.\n\n\n\n    Selection process/rules\n  \n\n    One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until June 27, 2024 at 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.\n  \n\n    Geographic restrictions:\n  \n\n    Our policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don’t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions (e.g. the obvious shipping restrictions to Russia and Belarus currently)\n  \n\n    US\n  \n\n    Canada (will require a basic skills-based question if winner is chosen by law)\n  \n\n    Brazil\n  \n\n    South America\n  \n\n    United Kingdom\n  \n\n    Germany\n  \n\n    France\n  \n\n    Iberia\n  \n\n    Australia\n  \n\n    New Zealand\n  \n\n    Korea\n  \n\n    India\n  \n\n    Malaysia\n  \n\n    Singapore\n  \n\n    China"},
{"Title": "Internet forums are disappearing because now it's all Reddit and Discord. And that's worrying.", "Author": "u/Run_the_Line", "Content": "No content"},
{"Title": "500,000 Books Have Been Deleted From The Internet Archive’s Lending Library", "Author": "u/Industrious_Badger", "Content": "No content"},
{"Title": "All of my data storage mediums, if you want I can update every Friday I get a new thing to put on the wall as a weekly thing", "Author": "u/LaundryMan2008", "Content": "No content"},
{"Title": "Largest SSD is 1,000 TB in 3.5\" size, why not bring 5.25\" mechanical drive?", "Author": "u/Warcraft_Fan", "Content": "The largest hard drive is 30TB but if they would use 5.25\" drive then it'd be possible to get some hundred TB in a standard 5.25\" half height (same as CD and DVD drive)\n  \n\n    Computer cases are still produced with 5.25\" support as some people still need optical drive or possibly tape drive. So what's keeping them from putting out massive 5.25\" hard drives?"},
{"Title": "Five Men Convicted of Operating Massive, Illegal Streaming Service That Allegedly Had More Content Than Netflix, Hulu, Vudu and Prime Video Combined", "Author": "u/falco_iii", "Content": "No content"},
{"Title": "Honey, I Shrunk My Server", "Author": "u/sylinen", "Content": "No content"},
{"Title": "Best option for a \"go bag\" external?", "Author": "u/Vietname", "Content": "I have a couple of small synology NAS's, each has a dedicated drive for regular backups, but i wanted to get a small external drive (ideally SSD) to put my really important data on for emergencies, e.g. the house is on fire and i can only grab a few things.\n  \n\n    What would you recommend?"},
{"Title": "Feasibility/Performance of Mini-PC NAS with external HDD/SSD enclosure?", "Author": "u/RXrenesis8", "Content": "Howdy \nr/DataHoarder\n!\n  \n\n    I am still a little baby hoarder with only about 15-20TB of data floating around my noisy 10 year old desktop-turned-HTPC. I was looking to expand to ~30TB (with room to grow of course) for a couple of initiatives and initially had been set on a rack and rackmount server or NAS chassis with a bunch of 3.5\" bays for price-efficient spinning drives.\n  \n\n    The cost though! Racks = $$$ Rackmount Chassis or pre-builts = $$$$!\n  \n\n    Every penny I would save in drive capacity I would pay back in getting a nice (home-office) rack and NAS.\n  \n\n    So I've come to you questioning a pivot point: What do you think about smaller solutions? Specifically I am thinking about a Mini-PC running nnRAID connected to a JBOD enclosure for disks or large/cheap SSDs.\n  \n\n    What's the performance difference between a setup like the above and a low-end rackmount setup (which is at the limit of what I could realistically afford)?\n  \n\n    Any pitfalls I should be aware of?\n  \n\n    Thanks in advance!"},
{"Title": "Looking for a recommendation for inexpensive 2TB SSD (SATA) with decent endurance", "Author": "u/gerdude1", "Content": "Hi,\n  \n\n    I have a few mini pc's (I have a decent size NAS as well) and would like to create CEPH storage, which requires three nodes on ProxMox. Hence I am looking for recommendations for a somehow inexpensive SSD's that have decent endurance (NVME is already used on all three Mini's, but they all have space for 2.5 SSD and a SATA port available). I am in the US and see price points of ~$120 for QLC and $150 for TLC. I have access to Microcenter, but there is very little available and newegg has all the usual suspects available (e.g. 970 Evo Plus).\n  \n\n    Would love to hear about some recommendations.\n  \n\n    Thanks in advance."},
{"Title": "I've got a decent sized physical media collection and unsure if it's worth saving lossless copies of it all", "Author": "u/TripleXero", "Content": "I've spent a stupid amount of time backing up all my DVDs and Blu-rays but I've already capped off an 11TB hard drive and split the extras between drives meant for other stuff and I'm still not done. I don't plan on getting rid of the original physical copies but it's much easier to access them digitally.\n  \n\n    I should also mention what I have backed up has been shrunk down already to decent looking MP4s to shove on iTunes for sleeker organization but I just don't know if it's worth keeping the original 1:1 files after. I shrunk the original files down once and realized after the fact that it wasn't in a flexible or presentable way for some so I'm hesitant to try again or wipe them completely after all the work. Is there maybe a good way to compress them? I've already went through and removed all non-English audio and subtitles"},
{"Title": "dm-vdo block-Level deduplication and compression merged into Linux 6.9", "Author": "u/LeichenExpress", "Content": "No content"},
{"Title": "VIA RAID disks question", "Author": "u/thenovum", "Content": "Hey. Is it possible to extract the data from via raid disk members without using a VIA RAID controler? Disks are from 2004."},
{"Title": "ServerPartDeals customer service", "Author": "u/demitrixrd", "Content": "I know many people on here already recommended SPD as a source for fair priced disks. I just wanted to add my $.02 after a recent experience with a failed drive I'd purchased a few months ago.\n  \n\n    A week ago I woke up to a TrueNas notification that a drive was faulted. I did some troubleshooting and wasn't able to recover any kind of connection to the drive. Plugging it in to a external adapter resulted in what sounded like a rock tumbler, so clearly it was beyond rescue. I started a RMA with SPD, and went back to work; expecting a few hours delay before hearing anything back. Later I realized I'd missed their almost immediate reply to the RMA request. I explained there was no way provide smart test results, and attached a video of my new rock tumbler. In short order the RMA# was provided. I shipped the faulted drive, and didn't think much of it. The drive was delivered yesterday and my replacement shipped this morning.\n  \n\n    Long story short, big kudos to ServerPartDeals for what is unprecedented customer service in the modern world; and to all the unsure shoppers, spend your money with SPD."},
{"Title": "Looking for help as a vlogging nomad. I film all content in 4k60p and visiting every country in the world. Guesstimating I'll need an additional ~24TB of storage for my remaining 100 countries. Budget: hopefully <$10k?", "Author": "u/immranderson", "Content": "Hey! I've been living exclusively out of my backpack + carryon luggage for the last decade and have been filming my travels as I go along. I've been traveling around the world and have amassed a large collection of 2/4TB Samsung T-Series SSDs which is beginning to bump up against the \nphysical carrying capacity\n in my bags.\n  \n\n    Lucky enough I've got a 128GB Pixel 1 that I use still to this day for daily remote storage + backup, so that has served me well.\n  \n\n    However, I also like to have local backups, and have been trying to shop around for SSDs. I'm trying to keep things as compact as possible, and I'm traveling so have avoided going the HDD route since my stuff can get pretty rough and tumbled quite often. I try not to edit directly off my external drives, and I've got an 8TB M-class macbook pro that I've been lugging around with me around the world.\n  \n\n    I'm trying to figure out how to handle my long term storage needs for the next few years of travel. On average, I'm capturing 100GB - 400GB per week of travel. I'm figuring I've got another 100 countries left to visit around the world, so 100 weeks * ~200GB per country maybe lands me in the ~20TB range of storage I'm anticipating I'll need for the remainder of my travels?\n  \n\n    Does anyone have any suggestions here? Could I get away with getting 2 x 16TB SSDs with external enclosures and that 32TB worth of capacity would generously cover my needs with wiggle room? If so, what SSD + enclosure combo would you recommend?"},
{"Title": "Only 12TB usable with 3x 4TB and 1x 8TB RAID5", "Author": "u/Sinnagangsta", "Content": "Hi all\n  \n\n    So I am setting up a RAID5 NAS and I have 3 4TB drives and 1 8TB drive. No hot spare drives. According to a RAID calculator, I will only have 12TB of usable storage, and it says 4TB is unused. This is consistent in the NAS panel, it is showing just under 12TB, why is this? Is that 8TB drive a waste, or am I missing something?\n  \nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-b851t2bway7d1.png\nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-p7soc3bway7d1.png\nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-44fhp3bway7d1.png"},
{"Title": "Migrate from Unraid to OMV, SnapRAID, mergerfs. How to keep hard links, that span between two drives?", "Author": "u/ChrisWreck", "Content": "I'm in the middle of migrating from Unraid to OpenMediaVault, where I'll be using Snapraid and mergerfs.\n  \n\n    I have 3 disks, one parity and two data drives. They're using XFS in Unraid. I want to use ext4 in OMV.\n  \n\n    I have formatted the parity drive to ext4, and planned to move data from disk 1 to the parity drive, then format disk 1 to ext4, and then move all data from disk 2 to disk 1 and make disk 2 the new parity drive for SnapRAID.\n  \n\n    However, I just realized I have hard links from the arr suite, spanning over both data disks ...\n  \n\n    How can I migrate and preserve the hard links? Preferably without having to move all data to one disk in Unraid before migrating.\n  \n\n    EDIT: For those of you wondering why I'm switching, I'm actually switching from Unraid to Proxmox, but I'll use OMV to handle my disks (combination of ZFS and ext4) and shares."},
{"Title": "Should I use cold cloud storage for small backup (4TB)?", "Author": "u/CreativeDog2024", "Content": "I know about the 3-2-1 rule, but I've not been implementing it. I'm a college student with 3 years and 4 TB worth of movies/TV shows that have taken DAYS to download at times.\n  \n\n    I have 2 local backups, one on a segate 5tb and the other on a WD 5tb.\n  \n\n    I don't want to lose these files, I've used a plex add on to export posters and a list of my media but if I were to ever try and get them back from scratch, it would take a long time and I'm not sure I'd ever dedicated that much time.\n  \n\n    I know about aws deep glacier as a last resort and it being pretty high cost to recover, but I don't really plan to ever recover unless I both of my local backups.\n  \n\n\n\n\n\n    What should I know about?\n  \n\n\n\n\n\n    What would you do?"},
{"Title": "Khan Academy Math Library downloading at once", "Author": "u/Aggressive_Green_764", "Content": "Hello guys i don't gonna have internet for a while and i thought about downloading the math library and  i don't wanna do it manually and i wanna do it just like it's on their website not the playlists on youtube\n  \n\n    Is there any way?"},
{"Title": "Get WD Purple for DIY NAS in Raid? Located in India", "Author": "u/The_Bipolar_Guy", "Content": "Building my first DIY NAS. Need 2+2 tb to start off with. Trying to be as cheap as possible. Will be storing all memories and irreplaceable things. Will get an external HDD for offsite backup. Also, I do not care about read write speeds. I just want my data to be safe and backed up at the end of the day for as cheap as possible, I will add new data maybe once a month if not even more rarely. I will be using my old motherboard (6 SATA ports) and processor. Will get a new 500 GB ssd for OS and new RAM.\n  \n\n    Now here is the dilemma. I am from India and WD Purples are selling for 5250 INR each, cheapest. Next up, WD Blue is also selling for 6000+ INR. I can technically afford (but want to avoid at all costs) to get a 10TB UltraStar or EXOS for 22000 INR but I need two physical drives at least and my total storage need for backup right now or even 3 years later will not exceed 4-5TB. so a 10TB HDD will be useless, not to mention spending 45K INR on drives only (which is VERY VERY EXPENSIVE FOR ME).\n  \n\n    I know WD Purple glosses over write errors and can be bad. Chucking is equally expensive, if not more. Should I just get 2x 2tb WD Purple for 10.5K INR and set up my backup server for now. Will add more HDDs later as needed (1-4 years later). Can I do anything to prevent the write errors?\n  \n\n    Also, if there is a cheaper way, especially in the long run, I would appreciate it. Currently I have ~2TB data which grows by like 200-400GB a year. I have thought of BluRay drives but I am unable to procure new BluRay drives cheap enough."},
{"Title": "Question in regard to mergerFS", "Author": "u/leviathan2701", "Content": "Hello,\n  \n\n    I just set up a NAS using Ubuntu 24 LTS, mergerFS & snapRAID. I am new to using Ubuntu, mergerFS & snapRAID but I did follow some guides via YouTube videos on setting them up. The drive pool has been created and snapRAID is working as expected however, I have what may be an easy question that I can't quite figure out.\n  \n\n    Following the guide, the mount point for mergerFS pool is at /mnt/storage which I have no issues accessing and adding/removing files via terminal using sudo or as root however, since the owner of the /mnt/storage location is root, my user account on the machine cannot write files to /mnt/storage and I cannot share it via samba. I know changing the overall permissions to 777 to allow it is risky and not worth it and I'm sure there is another way that I should be writing files to the location without logging in as root but again, I'm new with this and still learning. Any advice/help will be appreciated.\n  \n\n    mergerFS v2.33.5\n  \n\n    edit: was able to resolve the issue with all of your help. Thank you all very much!"},
{"Title": "Software for organizing manual backups over the last 10 years?", "Author": "u/PrivateAd990", "Content": "What software is available (paid or free) to help analyze my data on an external HD? it's only about a 1GB but 20+ backups (manually copied files over the years to this HD). MacOS or Linux. Wants:\n  \n\n\n\n\n\n    find data by extension (file type)\n  \n\n\n\n\n\n    find largest files\n  \n\n\n\n\n\n    identifying duplicates and handling it manually\n  \n\n\n\n\n\n    Accepting other tips of how to sift through data. I plan to organize all data to one folder rather than 20 backup folders."},
{"Title": "Seattle video store says it needs to raise $1.8M or face possible closure", "Author": "u/justreddit2024", "Content": "No content"},
{"Title": "Zip/ Compress Large Anime Collection", "Author": "u/Big-Durian-5011", "Content": "Hey guys, I have a collection of about 8 TB of anime on my OS od choice, Arch Linux, and was wondering if there was a way I could automatically (manually is fine too) compress all content in a singular folder and store the compresses/ zipper files in another folder.\n  \n\n    Edit: Just to be clear, the reason I want to zip/compress my anime is to back it up, not to download more anime. My plan is to:\n  \n\n\n\n\n\n    Make a copy of my folder of anime\n  \n\n\n\n\n\n    Zip/compress the copied folder\n  \n\n\n\n\n\n    Store the zipped/compressed folder on a seperate storage device (currently being stored in a 14TB hdd).\n  \n\n\n\n\n\n    If possible, set up an automatic process to continously do this process for any new anime I download."},
{"Title": "Question about Pixiv bulk downloading", "Author": "u/_izix", "Content": "Has anyone been blocked or banned from bulk downloading from pixiv?\n  \n\n    I've seen rumors that it may happen, but as far as I've been able to determine, there is no evidence of it actually happening. Is there maybe a hidden limit that's very high?\n  \n\n    I plan to download all images from users I follow with a script to update my archive with any new images every couple days. So far I have downloaded a few thousand images with no issues. Just figured I'd see if anyone has evidence of that happening before I continue.\n  \n\n    EDIT: I am using gallery-dl"},
{"Title": "Has SMR changed in the past few years?", "Author": "u/SirLouen", "Content": "I was reading this post commenting on the differences between SMR and CRM disks.\n  \n\n\nhttps://www.reddit.com/r/HomeServer/comments/hhfoqg/should_i_get_seagate_barracuda_or_seagate/\n\n\n\n\nhttps://www.youtube.com/watch?v=aztTf2gI55k\n\n\n\n    Basically, suggesting that SMR are seriously under classic CRM. But this happened to be like 4 years ago, so I wondered if Seagate has been able to figure out something to improve this for their disk, which is unlikely, but just wondering\n  \n\n    I saw today in my brick and mortar store, a Barracuda Compute 8 TB at $130 and a Barracuda Ironwolf at $190 w/ 8 TB also, so $60 difference for the same storage, not sure if its worth but feels that knowing all the issues attached with SMR (specially for a NAS where it's going to be used these disks), doesn't seem to be a good decision.\n  \n\n    So I wanted to know your opinion."},
{"Title": "Sony CCD TRV78E - how to digitize hi8 tapes?", "Author": "u/wtf94ftw", "Content": "Hey!\n  \n\n    So long story short my dad just retired and he wants to digitize his lifelong collection of hi8 tapes.\n  \n\n    I’ve read a lot of things last few days but I’m still not sure what would be the best option (budget friendly…) for the setup.\n  \n\n    Currently he’s been watching those tapes on TV with the sony CCD TRV78E camera, connected with both s-video and RCAs with an HDMI converter (\nhttps://amzn.eu/d/05vz9SBs\n) and everything’s working ok…\n  \n\n    I’m not great at these matters and I’m a bit lost tbh, but my initial idea was to plug the HDMI to a computer and record the screen as the movies are playing with a video capture sofware… which I now doubt to be an option because HDMI port on pcs don’t receive signal, is this right?\n  \n\n    Idk if the best option would be getting a camera that has the FireWire port and plays hi8 tapes or if it would be better to do this any other way, but I’ve read about those usb things not getting so much quality and I’m worried about it.\n  \n\n    Right now movies are playing in a 55” TV with good image quality and audio is perfectly synchronized, if this is relevant info in any way.\n  \n\n    He’s really motivated to do this by himself as he now have a lot of free time, but ofc this means that I’ll have to learn how to do it and teach him so he can continue by himself.\n  \n\n    Sorry, this was a long story after all, and sorry for some eventual english mistake as well!"},
{"Title": "Best free data integrity tools for validating.", "Author": "u/Captain_Starkiller", "Content": "Can anyone recommend some good tools for validating data integrity as a defense against bit rot?"},
{"Title": "Trying To Digitize Old Cassette Tapes", "Author": "u/boosterbear", "Content": "Hello all! I have been hunting for the right location to ask my many, many questions. This may not be technical enough for this subreddit, but it seemed like the right place to go.\n  \n\n    I'm a big fan of physical media, likely casual to most here but to my friends I am perceived as intensely pro-physical media. As such, whenever people have spare tapes, CDs, DVDs, etc etc, I'm the man they throw them at.\n  \n\n    Unfortunately, I am horribly unfamiliar with the digitization process for everything except for CDs and DVDs, and even then I occasionally have hiccups.\n  \n\n    Recently I purchased the \nJVC RC-EZ38S CD Portable System\n (link to user manual) from a flea market to play some of my tapes and CDs, and realized I had a few tapes I'm unable to find anywhere online. Usually I wouldn't worry about my tapes growing old from wear because I can download songs and save them that way, but these tapes (mostly Halloween tracks) were impossible for me to find elsewhere, so I've been trying to preserve them.\n  \n\n    The JVC product I purchased plays CDs, cassette tapes, and the radio. It has one single 3.5mm jack, a headphone output. I have done some googling, and found my best bet to save the audio is through a combination of cables and Audacity. Unfortunately, my computer only recognizes my aux cord as headphones, and I cannot treat my JVC product as a microphone when using Audacity. I have two cables - one aux with two 3.5mm ends, and one cable that has a male 3.5mm on one end and the other end has two male parts, white and yellow RCA jacks.\n  \n\n    How, if at all, can I use my JVC player to preserve the tapes I have? Is there a special cord combination I may be able to put together that won't put me out of house and home (I'm unemployed and in a somewhat difficult spot financially, even a $20 purchase has me aghast sometimes) or would I be better off looking for a different product to record my tapes? A friend of mine is currently looking to rehome an old car radio with cassette player - Do those typically have RCA plugs, and would that be a way to go about this?\n  \n\n    Anything helps, even just correcting my terms so I can communicate what I'm looking for a little better - I'm in a space where I truly don't know what it is that I don't know. I'd love to be a part of saving some lost media, even if it seems a little silly. People put work into those Halloween tapes, dammit!"},
{"Title": "What are the best options for adding disks to my setup?", "Author": "u/StarLordOfTheDance", "Content": "Is it possible to transition my setup from mergeFs+Snapraid to zfs without a lot of spare storage that I don't have?\n  \n\n    I currently have 2x4TB mergeFs setup, with a 4TB drive for Snapraid parity. (Total 8TB usable storage). - currently holding 7TB of data\n  \n\n    I have purchased 2x4TB more drives. And ideally want to end up in a situation where I have 16TB of usable storage, with 1 parity. (12TB usable would be acceptable but not ideal).\n  \n\n    The mergeFs harddrives are connected to a Ubuntu server. And I am moving the whole lot to a new server running proxmox (that has a Ubuntu server running in VM).\n  \n\n    can anyone help me figure out if it's possible to migrate this to a ZFS pool that will do what I want.\n  \n\n    I also have looked at unRAID because it supports adding disks, but that is its own hypervisor. So are there alternative ways of working that can work inside a proxmox VM?"},
{"Title": "I have question about ugreen enclosure", "Author": "u/Dismal_Award735", "Content": "No content"},
{"Title": "I need help identifying this hard drive, and where i can get the right cable.", "Author": "u/Chippomannen", "Content": "No content"},
{"Title": "Safest method to wipe out a drive without damaging it? I'm looking for paranoid-level shit.", "Author": "u/500xp1", "Content": "Looking for a method that makes it impossible to recover the wiped data."},
{"Title": "Backup software", "Author": "u/bhudzallmighty", "Content": "I currently have a dedicated optiplex running linux with nextcloud docker for my iphone data. I would like to expand this system to a DIY nas with a single 20tb hdd storage for backup . What is the best software to do so? I would like to be able to backup once a day. Can i back up the whole hdd? Or just folders? Thank you"},
{"Title": "500,000 CDs", "Author": "u/Sliced_Apples", "Content": "Hello, I am working for a startup in the sports industry and we have recently come into the possession of about five hundred thousand cds with 20 year old sports footage.\n  \n\n    We are trying to train an AI model off of them so as such, they need to be digitized.\n  \n\n    I know a little about burning cds but not much. As I have been made aware, this would be “ripping” and not burning.\n  \n\n    What would be the best way to go about doing this? What storage solution would be the best? Any advice is greatly appreciated. I’m happy to answer any questions as well."},
{"Title": "Best at-home manual photo scanner?", "Author": "u/Small_Vermicelli9655", "Content": "Looking to digitize a bunch of old family photos and was hoping for specific scanner suggestions. There’s lots of conflicting information online and I’m not very proficient in this area so was hoping for some insight lol.\n  \n\n    I’ve heard automatic scanners can mark grooves on the photos and would feel more comfortable with a manual one as time is not a priority. Hoping to stay around a $500 price range and resell after use.\n  \n\n    Thank you in advance!!"},
{"Title": "Today I learned something about shucking", "Author": "u/auridas330", "Content": "I bought two WD elements drives, both are same size, manufacture date, drive number, but one needed me to play with the 3.3v pin to show up.\n  \n\n    Never knew that WD plays Russian roulette with their drives lol"},
{"Title": "CD ripping compression", "Author": "u/nlj1978", "Content": "So going through my old CDs, some of them are previously burned CDs in MP3 format. I have been ripping discs in FLAC format.\n  \n\n    If the ripping software is starting with an MP3 file and ripping to FLAC is that problematic?\n  \n\n    Compressing a compressed file sounds like a bad idea"},
{"Title": "What is the best NVME SSD controller ?", "Author": "u/Yukinoooo", "Content": "I'm looking for an NVME SSD, 5 years warranty or more and a good controller but I don't know which NVME to choose because there are controllers : \"InnoGrit IG5236\", \"InnoGrit IG5666\", \"Phison E18\", \"Phison E26\" and \"SMI SM2264\""},
{"Title": "Synology DS923+, DS1821+ & DS223j all on sale right now at B&H", "Author": "u/iddrinktothat", "Content": "** The sale has ended. **\n  \n\n    Thought id let you guys know because i havent been seeing a lot of discounts on Synology."},
{"Title": "Longevity of Recordable CDs, DVDs and Blu-rays — Canadian Conservation Institute (CCI)", "Author": "u/didyousayboop", "Content": "Important information\n from the Canadian Conservation Institute, an agency of the federal government of Canada.\n  \nTable 2: the relative stability of optical disc formats\n\n\n\n\n\n\n\n            Optical disc formats\n          \n\n            Average longevity\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              CD-R (phthalocyanine dye, gold metal layer)\n            \n\n              >100 years\n            \n\n\n\n\n\n              CD-R (phthalocyanine dye, silver alloy metal layer)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              DVD-R (gold metal layer)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              CD (read-only, such as an audio CD)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              CD-RW (erasable CD)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              BD-RE (erasable Blu-ray)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              DVD+R (silver alloy metal layer)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              CD-R (cyanine or azo dye, silver alloy metal layer)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              DVD+RW (erasable DVD)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              BD-R (non-dye, gold metal layer)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              DVD-R (silver alloy metal layer)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              DVD and BD (read-only, such as a DVD or Blu-ray movie)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              BD-R (dye or non-dye, single layer or dual layer)\n            \n\n              5 to 10 years\n            \n\n\n\n\n\n              DVD-RW (erasable DVD)\n            \n\n              5 to 10 years\n            \n\n\n\n\n\n              DVD+R DL (dual layer)\n            \n\n              5 to 10 years"},
{"Title": "Looking for some specific storage design help", "Author": "u/Real_Bad_Horse", "Content": "Hey y'all, I don't know that this is the best place for my question, but I suspect that folks around here will either have advice or know where to point me if I'm better served asking this somewhere else.\n  \n\n    I built out my homelab to learn and get a job in IT. Mission success there. I've since gotten into all kinds of stuff and have a need to rework my storage, but I'm not sure how best to set things up.\n  \n\n    Here's what I'm looking to do:\n  \n\n    Complete separation of storage and compute Compute consists of a handful of VMs running on Proxmox, and critically, a Kubernetes cluster The cluster is currently running in VMs but I have plans to move just about everything into the cluster and move into SFF PCs This is partially why the complete separation is important, for flexibility and future migration\n  \n\n    Here's what I have currently for equipment:\n  \n\n    Brocade switch with 48x 1gbe and 8x10gig sfp 2x 12 bay 3.5\" servers, one with Proxmox, one with TrueNAS 1x 24 bay 2.5\" server Repurposed NetApp 24x 3.5\" chassis, modified to work as DAS 4x 16gb spinners, currently in raidz1 ~32 old 2, 3, and 4gb spinners\n  \n\n    I found that K8s cluster was very unstable with my first setup, which was an iscsi target on the TrueNAS server. The iSCSI share was mounted in Proxmox with LVM to create K8s VM OS and NFS storage for containers. This got much better when I moved to a local 3x SSD zpool on the Proxmox host. I understand that the latency with spinners and over the network was likely the cause, but this doesn't allow for the separation if like.\n  \n\n    Use here is all over - media server is the main thing currently, which for transcoding needs fast seq read/writes, K8s app dev for work, and all kinds of testing containers for work and home. I'd also like to put all VM storage remote as well to play around with some different compute setups. I'd really love to be able to fully wipe Proxmox and try out XCP-ng, or Azure HCI, stuff like that... It's a lab, after all.\n  \n\n    I'm competent enough to implement a solution, but I guess not enough experience yet to design. I'm not afraid of complex setup, but I do need redundancy, particularly if putting these small drives to use as I don't trust them - came for free with the NetApp shelf.\n  \n\n    So... Any suggestions on how to set this up for minimal latency and fast read/write? Ceph? Mirrored ZFS using all those small spinners? Dedicated ZFS pools for each K8s node? Caching layers? Not against additional equipment, within reason, if needed."},
{"Title": "Checking for Wiped SMART Data", "Author": "u/eakall", "Content": "So I recently got 35 2TB SSDs (mostly Samsung EVO 860/870) used and when checking the smart data for them I noticed very low power on hours.  The PoH (80-400hrs) is variable across the large set of drives and TBW is about 2-6TB for most of the drives. I was curious if there’s a way to check if the smart data has been reset?\n  \n\n    It seems a bit suspicious to me that these drives all are so low in PoH. Drives are also manufactured between 2020-2021 ish"},
{"Title": "Best option for transcoding?", "Author": "u/AbsolutelyNoClue22", "Content": "I want to use Plex to watch my movie library. I need transcoding to watch on the go, and on devices that need it. What is a good solution for this?\n  \n\n    I've thought about buying something like the TL-D800C, connect it to my laptop and run the Plex server from there. Is this a good idea? Is there a cheaper option?\n  \n\n    I'm new to all of this. I appreciate any help."},
{"Title": "No M2TS Files on Blu-ray?", "Author": "u/Carsonsgaming", "Content": "https://preview.redd.it/no-m2ts-files-on-blu-ray-v0-1i3wz54rsn7d1.png\n\n    As the title says. I'm not finding one anywhere. These are in a folder called AACS, then there's another folder with a bdmv file but that's it. I'm a complete noob to Blu-ray ripping so I'm hoping I'm just missing something. Only interested in ripping the audio."},
{"Title": "13.5 Volt", "Author": "u/Rayuzan_Mojavec", "Content": "I just got a 3.5 inch HDD. It needed 12 volts external power, but I only have 13.5 power adapter. Is it safe?"},
{"Title": "ST12000NTZ01 vs ST12000NTA01", "Author": "u/-Rhialto-", "Content": "The Z is sold by Amazon and the A by Best Buy, could it be just that? Same disk but different number depending on reseller?"},
{"Title": "Need to expand storage. Out of SATA but have PCI-E slot.", "Author": "u/DevanteWeary", "Content": "Hey guys. Using mITX motherboard and out of my four SATA ports, and need four more ports to connect four more drives.\n  \n\n    My PCIe slot is free and both m.2 slots are taken.\n  \n\n    What's the best way to get more free SATA ports?\nIt's for my low power streaming server/NAS that is running Unraid.\n  \n\n    Thank you for any advice!"},
{"Title": "Seeking Advice on Cost-Effective Backup Solutions for Multiple Hard Drives (beginner) - Thoughts on Bvckup 2?", "Author": "u/AlvTellez", "Content": "I have several larger hard drives:\n  \n\n\n\n\n\n    5TB portable drive connected to my HTPC for films and series via Plex\n  \n\n\n\n\n\n    Two unused 8TB drives\n  \n\n\n\n\n\n    4TB drive containing important media (that doesn't fit in my laptop and/or is more important)\n  \n\n\n\n\n\n    Initially, I considered getting a Synology NAS, but with less than 10TB of actual data, it seems like overkill, especially since I rarely access this data and usually keep the drives unplugged, except for the 5TB drive that's always connected to my HTPC (I also don't really need a NAS for my Plex needs, since I already have the HTPC as a server for that).\n  \n\n    After reading some posts, I thought about purchasing a license for Bvckup 2, which is more cost-effective and would allow me to use my other drives for backup.\n  \n\n    My plan is to transfer data from the 5TB drive to one of the 8TB drives and periodically back up the data to the other 8TB drive. If I run out of space, I could use the 4TB drive similarly and back up data to the other 5TB drive.\n  \n\n    While this might sound inefficient to experienced data hoarders, how bad/good is this idea? Are there any other software options that could simplify this process, compared to manually copying and pasting data between drives?"},
{"Title": "WD Red Plus 8TB vs WD Black 8TB vs IronWolf 8TB?", "Author": "u/GearFourth", "Content": "I ordered a WD Black 8TB, but now the Red Plus is on sale for $34 cheaper, do you guys believe the Black is worth $34 more?\n  \n\n    The biggest difference that I know of is Black has a longer warranty 5 vs 3. Are there any other differences? I would be using them for media storage."},
{"Title": "Will adding a new fan to a DAS result in the fan spinning at 100%?", "Author": "u/Apptryiguess", "Content": "I have a DAS and am pretty happy with the temps, but they could be slightly better since the DAS is in a closet and doesn't get that much airflow. My enterprise drives idle at 43-45 C which is ok, but could be a little better.\n  \n\n    So i thought about adding a new and better fan to the enclosure (Icy Box IB-3805-C31), but the fan never changes speeds, literally never. I don't let my drives spin down but if they were to, the fan does stop spinning after a while, afaik that's the only control the DAS has over the fan. So if i were to add a 2000rpm fan, would it instantly shoot up to that rpm and always spin that fast? Is there a way to control fan speed? I can't see the DAS's fan on any program controlling fan speed so that's something...\n  \n\n    Any idea on how it would behave? Any idea if there is a way to controll the fan speed? Thanks."},
{"Title": "chkbit: Check that your files were not corrupted", "Author": "u/laktakk", "Content": "No content"},
{"Title": "Software for splitting video files in bulk?", "Author": "u/Comfortable_Ad_6823", "Content": "I am currently ripping my SpongeBob DVDs. For anyone unaware, (almost) all SpongeBob episodes are split into A and B parts. For example, \"Pizza Delivery\" is only episode 5a, with \"Home Sweet Pineapple\" being episode 5b. Two \"segments\" make up one episode.\n  \n\n    Normally this isn't a problem, as each segment in the SpongeBob DVDs has its own .mkv file. That is, until season 9, where there are no .mkv files for individual segments, only the combined episode. This is rather annoying as I don't want to scrub to the half-way mark of the videos just to watch the episode I actually want to see. I've thought of splitting the files in half, but it would be a tedious process as seasons are quite long.\n  \n\n    Are there any programs or tools that would make this easier?"},
{"Title": "Official Giveaway: June 2024 Seagate IronWolf Pro 16TB Hard Drive Giveaway", "Author": "u/Seagate_Surfer", "Content": "Hi \nr/DataHoarder\n crowd! We love your sub and would like to rev up another giveaway with the permission of the mod team.\n  \n\n    The prize is: one 16TB IronWolf Pro Hard Disk Drive\n  \n\n\nHow to enter:\n\n\n\n\nJust reply to this post once with a top-level comment response on the following topic:\n\n\n\n\nWhat kind of loyalty program matters to you for a company? Is drive capacity, price point, excellent customer service, etc. the highest priority for you? Please include the phrases RunWithIronWolf and Seagate in your comment.\n\n\n\n    Selection process/rules\n  \n\n    One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until June 27, 2024 at 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.\n  \n\n    Geographic restrictions:\n  \n\n    Our policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don’t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions (e.g. the obvious shipping restrictions to Russia and Belarus currently)\n  \n\n    US\n  \n\n    Canada (will require a basic skills-based question if winner is chosen by law)\n  \n\n    Brazil\n  \n\n    South America\n  \n\n    United Kingdom\n  \n\n    Germany\n  \n\n    France\n  \n\n    Iberia\n  \n\n    Australia\n  \n\n    New Zealand\n  \n\n    Korea\n  \n\n    India\n  \n\n    Malaysia\n  \n\n    Singapore\n  \n\n    China"},
{"Title": "Internet forums are disappearing because now it's all Reddit and Discord. And that's worrying.", "Author": "u/Run_the_Line", "Content": "No content"},
{"Title": "500,000 Books Have Been Deleted From The Internet Archive’s Lending Library", "Author": "u/Industrious_Badger", "Content": "No content"},
{"Title": "All of my data storage mediums, if you want I can update every Friday I get a new thing to put on the wall as a weekly thing", "Author": "u/LaundryMan2008", "Content": "No content"},
{"Title": "Largest SSD is 1,000 TB in 3.5\" size, why not bring 5.25\" mechanical drive?", "Author": "u/Warcraft_Fan", "Content": "The largest hard drive is 30TB but if they would use 5.25\" drive then it'd be possible to get some hundred TB in a standard 5.25\" half height (same as CD and DVD drive)\n  \n\n    Computer cases are still produced with 5.25\" support as some people still need optical drive or possibly tape drive. So what's keeping them from putting out massive 5.25\" hard drives?"},
{"Title": "Five Men Convicted of Operating Massive, Illegal Streaming Service That Allegedly Had More Content Than Netflix, Hulu, Vudu and Prime Video Combined", "Author": "u/falco_iii", "Content": "No content"},
{"Title": "Honey, I Shrunk My Server", "Author": "u/sylinen", "Content": "No content"},
{"Title": "Best option for a \"go bag\" external?", "Author": "u/Vietname", "Content": "I have a couple of small synology NAS's, each has a dedicated drive for regular backups, but i wanted to get a small external drive (ideally SSD) to put my really important data on for emergencies, e.g. the house is on fire and i can only grab a few things.\n  \n\n    What would you recommend?"},
{"Title": "Feasibility/Performance of Mini-PC NAS with external HDD/SSD enclosure?", "Author": "u/RXrenesis8", "Content": "Howdy \nr/DataHoarder\n!\n  \n\n    I am still a little baby hoarder with only about 15-20TB of data floating around my noisy 10 year old desktop-turned-HTPC. I was looking to expand to ~30TB (with room to grow of course) for a couple of initiatives and initially had been set on a rack and rackmount server or NAS chassis with a bunch of 3.5\" bays for price-efficient spinning drives.\n  \n\n    The cost though! Racks = $$$ Rackmount Chassis or pre-builts = $$$$!\n  \n\n    Every penny I would save in drive capacity I would pay back in getting a nice (home-office) rack and NAS.\n  \n\n    So I've come to you questioning a pivot point: What do you think about smaller solutions? Specifically I am thinking about a Mini-PC running nnRAID connected to a JBOD enclosure for disks or large/cheap SSDs.\n  \n\n    What's the performance difference between a setup like the above and a low-end rackmount setup (which is at the limit of what I could realistically afford)?\n  \n\n    Any pitfalls I should be aware of?\n  \n\n    Thanks in advance!"},
{"Title": "Looking for a recommendation for inexpensive 2TB SSD (SATA) with decent endurance", "Author": "u/gerdude1", "Content": "Hi,\n  \n\n    I have a few mini pc's (I have a decent size NAS as well) and would like to create CEPH storage, which requires three nodes on ProxMox. Hence I am looking for recommendations for a somehow inexpensive SSD's that have decent endurance (NVME is already used on all three Mini's, but they all have space for 2.5 SSD and a SATA port available). I am in the US and see price points of ~$120 for QLC and $150 for TLC. I have access to Microcenter, but there is very little available and newegg has all the usual suspects available (e.g. 970 Evo Plus).\n  \n\n    Would love to hear about some recommendations.\n  \n\n    Thanks in advance."},
{"Title": "I've got a decent sized physical media collection and unsure if it's worth saving lossless copies of it all", "Author": "u/TripleXero", "Content": "I've spent a stupid amount of time backing up all my DVDs and Blu-rays but I've already capped off an 11TB hard drive and split the extras between drives meant for other stuff and I'm still not done. I don't plan on getting rid of the original physical copies but it's much easier to access them digitally.\n  \n\n    I should also mention what I have backed up has been shrunk down already to decent looking MP4s to shove on iTunes for sleeker organization but I just don't know if it's worth keeping the original 1:1 files after. I shrunk the original files down once and realized after the fact that it wasn't in a flexible or presentable way for some so I'm hesitant to try again or wipe them completely after all the work. Is there maybe a good way to compress them? I've already went through and removed all non-English audio and subtitles"},
{"Title": "dm-vdo block-Level deduplication and compression merged into Linux 6.9", "Author": "u/LeichenExpress", "Content": "No content"},
{"Title": "VIA RAID disks question", "Author": "u/thenovum", "Content": "Hey. Is it possible to extract the data from via raid disk members without using a VIA RAID controler? Disks are from 2004."},
{"Title": "ServerPartDeals customer service", "Author": "u/demitrixrd", "Content": "I know many people on here already recommended SPD as a source for fair priced disks. I just wanted to add my $.02 after a recent experience with a failed drive I'd purchased a few months ago.\n  \n\n    A week ago I woke up to a TrueNas notification that a drive was faulted. I did some troubleshooting and wasn't able to recover any kind of connection to the drive. Plugging it in to a external adapter resulted in what sounded like a rock tumbler, so clearly it was beyond rescue. I started a RMA with SPD, and went back to work; expecting a few hours delay before hearing anything back. Later I realized I'd missed their almost immediate reply to the RMA request. I explained there was no way provide smart test results, and attached a video of my new rock tumbler. In short order the RMA# was provided. I shipped the faulted drive, and didn't think much of it. The drive was delivered yesterday and my replacement shipped this morning.\n  \n\n    Long story short, big kudos to ServerPartDeals for what is unprecedented customer service in the modern world; and to all the unsure shoppers, spend your money with SPD."},
{"Title": "Looking for help as a vlogging nomad. I film all content in 4k60p and visiting every country in the world. Guesstimating I'll need an additional ~24TB of storage for my remaining 100 countries. Budget: hopefully <$10k?", "Author": "u/immranderson", "Content": "Hey! I've been living exclusively out of my backpack + carryon luggage for the last decade and have been filming my travels as I go along. I've been traveling around the world and have amassed a large collection of 2/4TB Samsung T-Series SSDs which is beginning to bump up against the \nphysical carrying capacity\n in my bags.\n  \n\n    Lucky enough I've got a 128GB Pixel 1 that I use still to this day for daily remote storage + backup, so that has served me well.\n  \n\n    However, I also like to have local backups, and have been trying to shop around for SSDs. I'm trying to keep things as compact as possible, and I'm traveling so have avoided going the HDD route since my stuff can get pretty rough and tumbled quite often. I try not to edit directly off my external drives, and I've got an 8TB M-class macbook pro that I've been lugging around with me around the world.\n  \n\n    I'm trying to figure out how to handle my long term storage needs for the next few years of travel. On average, I'm capturing 100GB - 400GB per week of travel. I'm figuring I've got another 100 countries left to visit around the world, so 100 weeks * ~200GB per country maybe lands me in the ~20TB range of storage I'm anticipating I'll need for the remainder of my travels?\n  \n\n    Does anyone have any suggestions here? Could I get away with getting 2 x 16TB SSDs with external enclosures and that 32TB worth of capacity would generously cover my needs with wiggle room? If so, what SSD + enclosure combo would you recommend?"},
{"Title": "Only 12TB usable with 3x 4TB and 1x 8TB RAID5", "Author": "u/Sinnagangsta", "Content": "Hi all\n  \n\n    So I am setting up a RAID5 NAS and I have 3 4TB drives and 1 8TB drive. No hot spare drives. According to a RAID calculator, I will only have 12TB of usable storage, and it says 4TB is unused. This is consistent in the NAS panel, it is showing just under 12TB, why is this? Is that 8TB drive a waste, or am I missing something?\n  \nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-b851t2bway7d1.png\nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-p7soc3bway7d1.png\nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-44fhp3bway7d1.png"},
{"Title": "Migrate from Unraid to OMV, SnapRAID, mergerfs. How to keep hard links, that span between two drives?", "Author": "u/ChrisWreck", "Content": "I'm in the middle of migrating from Unraid to OpenMediaVault, where I'll be using Snapraid and mergerfs.\n  \n\n    I have 3 disks, one parity and two data drives. They're using XFS in Unraid. I want to use ext4 in OMV.\n  \n\n    I have formatted the parity drive to ext4, and planned to move data from disk 1 to the parity drive, then format disk 1 to ext4, and then move all data from disk 2 to disk 1 and make disk 2 the new parity drive for SnapRAID.\n  \n\n    However, I just realized I have hard links from the arr suite, spanning over both data disks ...\n  \n\n    How can I migrate and preserve the hard links? Preferably without having to move all data to one disk in Unraid before migrating.\n  \n\n    EDIT: For those of you wondering why I'm switching, I'm actually switching from Unraid to Proxmox, but I'll use OMV to handle my disks (combination of ZFS and ext4) and shares."},
{"Title": "Should I use cold cloud storage for small backup (4TB)?", "Author": "u/CreativeDog2024", "Content": "I know about the 3-2-1 rule, but I've not been implementing it. I'm a college student with 3 years and 4 TB worth of movies/TV shows that have taken DAYS to download at times.\n  \n\n    I have 2 local backups, one on a segate 5tb and the other on a WD 5tb.\n  \n\n    I don't want to lose these files, I've used a plex add on to export posters and a list of my media but if I were to ever try and get them back from scratch, it would take a long time and I'm not sure I'd ever dedicated that much time.\n  \n\n    I know about aws deep glacier as a last resort and it being pretty high cost to recover, but I don't really plan to ever recover unless I both of my local backups.\n  \n\n\n\n\n\n    What should I know about?\n  \n\n\n\n\n\n    What would you do?"},
{"Title": "Khan Academy Math Library downloading at once", "Author": "u/Aggressive_Green_764", "Content": "Hello guys i don't gonna have internet for a while and i thought about downloading the math library and  i don't wanna do it manually and i wanna do it just like it's on their website not the playlists on youtube\n  \n\n    Is there any way?"},
{"Title": "Get WD Purple for DIY NAS in Raid? Located in India", "Author": "u/The_Bipolar_Guy", "Content": "Building my first DIY NAS. Need 2+2 tb to start off with. Trying to be as cheap as possible. Will be storing all memories and irreplaceable things. Will get an external HDD for offsite backup. Also, I do not care about read write speeds. I just want my data to be safe and backed up at the end of the day for as cheap as possible, I will add new data maybe once a month if not even more rarely. I will be using my old motherboard (6 SATA ports) and processor. Will get a new 500 GB ssd for OS and new RAM.\n  \n\n    Now here is the dilemma. I am from India and WD Purples are selling for 5250 INR each, cheapest. Next up, WD Blue is also selling for 6000+ INR. I can technically afford (but want to avoid at all costs) to get a 10TB UltraStar or EXOS for 22000 INR but I need two physical drives at least and my total storage need for backup right now or even 3 years later will not exceed 4-5TB. so a 10TB HDD will be useless, not to mention spending 45K INR on drives only (which is VERY VERY EXPENSIVE FOR ME).\n  \n\n    I know WD Purple glosses over write errors and can be bad. Chucking is equally expensive, if not more. Should I just get 2x 2tb WD Purple for 10.5K INR and set up my backup server for now. Will add more HDDs later as needed (1-4 years later). Can I do anything to prevent the write errors?\n  \n\n    Also, if there is a cheaper way, especially in the long run, I would appreciate it. Currently I have ~2TB data which grows by like 200-400GB a year. I have thought of BluRay drives but I am unable to procure new BluRay drives cheap enough."},
{"Title": "Question in regard to mergerFS", "Author": "u/leviathan2701", "Content": "Hello,\n  \n\n    I just set up a NAS using Ubuntu 24 LTS, mergerFS & snapRAID. I am new to using Ubuntu, mergerFS & snapRAID but I did follow some guides via YouTube videos on setting them up. The drive pool has been created and snapRAID is working as expected however, I have what may be an easy question that I can't quite figure out.\n  \n\n    Following the guide, the mount point for mergerFS pool is at /mnt/storage which I have no issues accessing and adding/removing files via terminal using sudo or as root however, since the owner of the /mnt/storage location is root, my user account on the machine cannot write files to /mnt/storage and I cannot share it via samba. I know changing the overall permissions to 777 to allow it is risky and not worth it and I'm sure there is another way that I should be writing files to the location without logging in as root but again, I'm new with this and still learning. Any advice/help will be appreciated.\n  \n\n    mergerFS v2.33.5\n  \n\n    edit: was able to resolve the issue with all of your help. Thank you all very much!"},
{"Title": "Software for organizing manual backups over the last 10 years?", "Author": "u/PrivateAd990", "Content": "What software is available (paid or free) to help analyze my data on an external HD? it's only about a 1GB but 20+ backups (manually copied files over the years to this HD). MacOS or Linux. Wants:\n  \n\n\n\n\n\n    find data by extension (file type)\n  \n\n\n\n\n\n    find largest files\n  \n\n\n\n\n\n    identifying duplicates and handling it manually\n  \n\n\n\n\n\n    Accepting other tips of how to sift through data. I plan to organize all data to one folder rather than 20 backup folders."},
{"Title": "Seattle video store says it needs to raise $1.8M or face possible closure", "Author": "u/justreddit2024", "Content": "No content"},
{"Title": "Zip/ Compress Large Anime Collection", "Author": "u/Big-Durian-5011", "Content": "Hey guys, I have a collection of about 8 TB of anime on my OS od choice, Arch Linux, and was wondering if there was a way I could automatically (manually is fine too) compress all content in a singular folder and store the compresses/ zipper files in another folder.\n  \n\n    Edit: Just to be clear, the reason I want to zip/compress my anime is to back it up, not to download more anime. My plan is to:\n  \n\n\n\n\n\n    Make a copy of my folder of anime\n  \n\n\n\n\n\n    Zip/compress the copied folder\n  \n\n\n\n\n\n    Store the zipped/compressed folder on a seperate storage device (currently being stored in a 14TB hdd).\n  \n\n\n\n\n\n    If possible, set up an automatic process to continously do this process for any new anime I download."},
{"Title": "Question about Pixiv bulk downloading", "Author": "u/_izix", "Content": "Has anyone been blocked or banned from bulk downloading from pixiv?\n  \n\n    I've seen rumors that it may happen, but as far as I've been able to determine, there is no evidence of it actually happening. Is there maybe a hidden limit that's very high?\n  \n\n    I plan to download all images from users I follow with a script to update my archive with any new images every couple days. So far I have downloaded a few thousand images with no issues. Just figured I'd see if anyone has evidence of that happening before I continue.\n  \n\n    EDIT: I am using gallery-dl"},
{"Title": "Has SMR changed in the past few years?", "Author": "u/SirLouen", "Content": "I was reading this post commenting on the differences between SMR and CRM disks.\n  \n\n\nhttps://www.reddit.com/r/HomeServer/comments/hhfoqg/should_i_get_seagate_barracuda_or_seagate/\n\n\n\n\nhttps://www.youtube.com/watch?v=aztTf2gI55k\n\n\n\n    Basically, suggesting that SMR are seriously under classic CRM. But this happened to be like 4 years ago, so I wondered if Seagate has been able to figure out something to improve this for their disk, which is unlikely, but just wondering\n  \n\n    I saw today in my brick and mortar store, a Barracuda Compute 8 TB at $130 and a Barracuda Ironwolf at $190 w/ 8 TB also, so $60 difference for the same storage, not sure if its worth but feels that knowing all the issues attached with SMR (specially for a NAS where it's going to be used these disks), doesn't seem to be a good decision.\n  \n\n    So I wanted to know your opinion."},
{"Title": "Sony CCD TRV78E - how to digitize hi8 tapes?", "Author": "u/wtf94ftw", "Content": "Hey!\n  \n\n    So long story short my dad just retired and he wants to digitize his lifelong collection of hi8 tapes.\n  \n\n    I’ve read a lot of things last few days but I’m still not sure what would be the best option (budget friendly…) for the setup.\n  \n\n    Currently he’s been watching those tapes on TV with the sony CCD TRV78E camera, connected with both s-video and RCAs with an HDMI converter (\nhttps://amzn.eu/d/05vz9SBs\n) and everything’s working ok…\n  \n\n    I’m not great at these matters and I’m a bit lost tbh, but my initial idea was to plug the HDMI to a computer and record the screen as the movies are playing with a video capture sofware… which I now doubt to be an option because HDMI port on pcs don’t receive signal, is this right?\n  \n\n    Idk if the best option would be getting a camera that has the FireWire port and plays hi8 tapes or if it would be better to do this any other way, but I’ve read about those usb things not getting so much quality and I’m worried about it.\n  \n\n    Right now movies are playing in a 55” TV with good image quality and audio is perfectly synchronized, if this is relevant info in any way.\n  \n\n    He’s really motivated to do this by himself as he now have a lot of free time, but ofc this means that I’ll have to learn how to do it and teach him so he can continue by himself.\n  \n\n    Sorry, this was a long story after all, and sorry for some eventual english mistake as well!"},
{"Title": "Best free data integrity tools for validating.", "Author": "u/Captain_Starkiller", "Content": "Can anyone recommend some good tools for validating data integrity as a defense against bit rot?"},
{"Title": "Trying To Digitize Old Cassette Tapes", "Author": "u/boosterbear", "Content": "Hello all! I have been hunting for the right location to ask my many, many questions. This may not be technical enough for this subreddit, but it seemed like the right place to go.\n  \n\n    I'm a big fan of physical media, likely casual to most here but to my friends I am perceived as intensely pro-physical media. As such, whenever people have spare tapes, CDs, DVDs, etc etc, I'm the man they throw them at.\n  \n\n    Unfortunately, I am horribly unfamiliar with the digitization process for everything except for CDs and DVDs, and even then I occasionally have hiccups.\n  \n\n    Recently I purchased the \nJVC RC-EZ38S CD Portable System\n (link to user manual) from a flea market to play some of my tapes and CDs, and realized I had a few tapes I'm unable to find anywhere online. Usually I wouldn't worry about my tapes growing old from wear because I can download songs and save them that way, but these tapes (mostly Halloween tracks) were impossible for me to find elsewhere, so I've been trying to preserve them.\n  \n\n    The JVC product I purchased plays CDs, cassette tapes, and the radio. It has one single 3.5mm jack, a headphone output. I have done some googling, and found my best bet to save the audio is through a combination of cables and Audacity. Unfortunately, my computer only recognizes my aux cord as headphones, and I cannot treat my JVC product as a microphone when using Audacity. I have two cables - one aux with two 3.5mm ends, and one cable that has a male 3.5mm on one end and the other end has two male parts, white and yellow RCA jacks.\n  \n\n    How, if at all, can I use my JVC player to preserve the tapes I have? Is there a special cord combination I may be able to put together that won't put me out of house and home (I'm unemployed and in a somewhat difficult spot financially, even a $20 purchase has me aghast sometimes) or would I be better off looking for a different product to record my tapes? A friend of mine is currently looking to rehome an old car radio with cassette player - Do those typically have RCA plugs, and would that be a way to go about this?\n  \n\n    Anything helps, even just correcting my terms so I can communicate what I'm looking for a little better - I'm in a space where I truly don't know what it is that I don't know. I'd love to be a part of saving some lost media, even if it seems a little silly. People put work into those Halloween tapes, dammit!"},
{"Title": "What are the best options for adding disks to my setup?", "Author": "u/StarLordOfTheDance", "Content": "Is it possible to transition my setup from mergeFs+Snapraid to zfs without a lot of spare storage that I don't have?\n  \n\n    I currently have 2x4TB mergeFs setup, with a 4TB drive for Snapraid parity. (Total 8TB usable storage). - currently holding 7TB of data\n  \n\n    I have purchased 2x4TB more drives. And ideally want to end up in a situation where I have 16TB of usable storage, with 1 parity. (12TB usable would be acceptable but not ideal).\n  \n\n    The mergeFs harddrives are connected to a Ubuntu server. And I am moving the whole lot to a new server running proxmox (that has a Ubuntu server running in VM).\n  \n\n    can anyone help me figure out if it's possible to migrate this to a ZFS pool that will do what I want.\n  \n\n    I also have looked at unRAID because it supports adding disks, but that is its own hypervisor. So are there alternative ways of working that can work inside a proxmox VM?"},
{"Title": "I have question about ugreen enclosure", "Author": "u/Dismal_Award735", "Content": "No content"},
{"Title": "I need help identifying this hard drive, and where i can get the right cable.", "Author": "u/Chippomannen", "Content": "No content"},
{"Title": "Safest method to wipe out a drive without damaging it? I'm looking for paranoid-level shit.", "Author": "u/500xp1", "Content": "Looking for a method that makes it impossible to recover the wiped data."},
{"Title": "Backup software", "Author": "u/bhudzallmighty", "Content": "I currently have a dedicated optiplex running linux with nextcloud docker for my iphone data. I would like to expand this system to a DIY nas with a single 20tb hdd storage for backup . What is the best software to do so? I would like to be able to backup once a day. Can i back up the whole hdd? Or just folders? Thank you"},
{"Title": "500,000 CDs", "Author": "u/Sliced_Apples", "Content": "Hello, I am working for a startup in the sports industry and we have recently come into the possession of about five hundred thousand cds with 20 year old sports footage.\n  \n\n    We are trying to train an AI model off of them so as such, they need to be digitized.\n  \n\n    I know a little about burning cds but not much. As I have been made aware, this would be “ripping” and not burning.\n  \n\n    What would be the best way to go about doing this? What storage solution would be the best? Any advice is greatly appreciated. I’m happy to answer any questions as well."},
{"Title": "Best at-home manual photo scanner?", "Author": "u/Small_Vermicelli9655", "Content": "Looking to digitize a bunch of old family photos and was hoping for specific scanner suggestions. There’s lots of conflicting information online and I’m not very proficient in this area so was hoping for some insight lol.\n  \n\n    I’ve heard automatic scanners can mark grooves on the photos and would feel more comfortable with a manual one as time is not a priority. Hoping to stay around a $500 price range and resell after use.\n  \n\n    Thank you in advance!!"},
{"Title": "Today I learned something about shucking", "Author": "u/auridas330", "Content": "I bought two WD elements drives, both are same size, manufacture date, drive number, but one needed me to play with the 3.3v pin to show up.\n  \n\n    Never knew that WD plays Russian roulette with their drives lol"},
{"Title": "CD ripping compression", "Author": "u/nlj1978", "Content": "So going through my old CDs, some of them are previously burned CDs in MP3 format. I have been ripping discs in FLAC format.\n  \n\n    If the ripping software is starting with an MP3 file and ripping to FLAC is that problematic?\n  \n\n    Compressing a compressed file sounds like a bad idea"},
{"Title": "What is the best NVME SSD controller ?", "Author": "u/Yukinoooo", "Content": "I'm looking for an NVME SSD, 5 years warranty or more and a good controller but I don't know which NVME to choose because there are controllers : \"InnoGrit IG5236\", \"InnoGrit IG5666\", \"Phison E18\", \"Phison E26\" and \"SMI SM2264\""},
{"Title": "Synology DS923+, DS1821+ & DS223j all on sale right now at B&H", "Author": "u/iddrinktothat", "Content": "** The sale has ended. **\n  \n\n    Thought id let you guys know because i havent been seeing a lot of discounts on Synology."},
{"Title": "Longevity of Recordable CDs, DVDs and Blu-rays — Canadian Conservation Institute (CCI)", "Author": "u/didyousayboop", "Content": "Important information\n from the Canadian Conservation Institute, an agency of the federal government of Canada.\n  \nTable 2: the relative stability of optical disc formats\n\n\n\n\n\n\n\n            Optical disc formats\n          \n\n            Average longevity\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              CD-R (phthalocyanine dye, gold metal layer)\n            \n\n              >100 years\n            \n\n\n\n\n\n              CD-R (phthalocyanine dye, silver alloy metal layer)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              DVD-R (gold metal layer)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              CD (read-only, such as an audio CD)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              CD-RW (erasable CD)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              BD-RE (erasable Blu-ray)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              DVD+R (silver alloy metal layer)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              CD-R (cyanine or azo dye, silver alloy metal layer)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              DVD+RW (erasable DVD)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              BD-R (non-dye, gold metal layer)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              DVD-R (silver alloy metal layer)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              DVD and BD (read-only, such as a DVD or Blu-ray movie)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              BD-R (dye or non-dye, single layer or dual layer)\n            \n\n              5 to 10 years\n            \n\n\n\n\n\n              DVD-RW (erasable DVD)\n            \n\n              5 to 10 years\n            \n\n\n\n\n\n              DVD+R DL (dual layer)\n            \n\n              5 to 10 years"},
{"Title": "Looking for some specific storage design help", "Author": "u/Real_Bad_Horse", "Content": "Hey y'all, I don't know that this is the best place for my question, but I suspect that folks around here will either have advice or know where to point me if I'm better served asking this somewhere else.\n  \n\n    I built out my homelab to learn and get a job in IT. Mission success there. I've since gotten into all kinds of stuff and have a need to rework my storage, but I'm not sure how best to set things up.\n  \n\n    Here's what I'm looking to do:\n  \n\n    Complete separation of storage and compute Compute consists of a handful of VMs running on Proxmox, and critically, a Kubernetes cluster The cluster is currently running in VMs but I have plans to move just about everything into the cluster and move into SFF PCs This is partially why the complete separation is important, for flexibility and future migration\n  \n\n    Here's what I have currently for equipment:\n  \n\n    Brocade switch with 48x 1gbe and 8x10gig sfp 2x 12 bay 3.5\" servers, one with Proxmox, one with TrueNAS 1x 24 bay 2.5\" server Repurposed NetApp 24x 3.5\" chassis, modified to work as DAS 4x 16gb spinners, currently in raidz1 ~32 old 2, 3, and 4gb spinners\n  \n\n    I found that K8s cluster was very unstable with my first setup, which was an iscsi target on the TrueNAS server. The iSCSI share was mounted in Proxmox with LVM to create K8s VM OS and NFS storage for containers. This got much better when I moved to a local 3x SSD zpool on the Proxmox host. I understand that the latency with spinners and over the network was likely the cause, but this doesn't allow for the separation if like.\n  \n\n    Use here is all over - media server is the main thing currently, which for transcoding needs fast seq read/writes, K8s app dev for work, and all kinds of testing containers for work and home. I'd also like to put all VM storage remote as well to play around with some different compute setups. I'd really love to be able to fully wipe Proxmox and try out XCP-ng, or Azure HCI, stuff like that... It's a lab, after all.\n  \n\n    I'm competent enough to implement a solution, but I guess not enough experience yet to design. I'm not afraid of complex setup, but I do need redundancy, particularly if putting these small drives to use as I don't trust them - came for free with the NetApp shelf.\n  \n\n    So... Any suggestions on how to set this up for minimal latency and fast read/write? Ceph? Mirrored ZFS using all those small spinners? Dedicated ZFS pools for each K8s node? Caching layers? Not against additional equipment, within reason, if needed."},
{"Title": "Checking for Wiped SMART Data", "Author": "u/eakall", "Content": "So I recently got 35 2TB SSDs (mostly Samsung EVO 860/870) used and when checking the smart data for them I noticed very low power on hours.  The PoH (80-400hrs) is variable across the large set of drives and TBW is about 2-6TB for most of the drives. I was curious if there’s a way to check if the smart data has been reset?\n  \n\n    It seems a bit suspicious to me that these drives all are so low in PoH. Drives are also manufactured between 2020-2021 ish"},
{"Title": "Best option for transcoding?", "Author": "u/AbsolutelyNoClue22", "Content": "I want to use Plex to watch my movie library. I need transcoding to watch on the go, and on devices that need it. What is a good solution for this?\n  \n\n    I've thought about buying something like the TL-D800C, connect it to my laptop and run the Plex server from there. Is this a good idea? Is there a cheaper option?\n  \n\n    I'm new to all of this. I appreciate any help."},
{"Title": "No M2TS Files on Blu-ray?", "Author": "u/Carsonsgaming", "Content": "https://preview.redd.it/no-m2ts-files-on-blu-ray-v0-1i3wz54rsn7d1.png\n\n    As the title says. I'm not finding one anywhere. These are in a folder called AACS, then there's another folder with a bdmv file but that's it. I'm a complete noob to Blu-ray ripping so I'm hoping I'm just missing something. Only interested in ripping the audio."},
{"Title": "13.5 Volt", "Author": "u/Rayuzan_Mojavec", "Content": "I just got a 3.5 inch HDD. It needed 12 volts external power, but I only have 13.5 power adapter. Is it safe?"},
{"Title": "ST12000NTZ01 vs ST12000NTA01", "Author": "u/-Rhialto-", "Content": "The Z is sold by Amazon and the A by Best Buy, could it be just that? Same disk but different number depending on reseller?"},
{"Title": "Need to expand storage. Out of SATA but have PCI-E slot.", "Author": "u/DevanteWeary", "Content": "Hey guys. Using mITX motherboard and out of my four SATA ports, and need four more ports to connect four more drives.\n  \n\n    My PCIe slot is free and both m.2 slots are taken.\n  \n\n    What's the best way to get more free SATA ports?\nIt's for my low power streaming server/NAS that is running Unraid.\n  \n\n    Thank you for any advice!"},
{"Title": "Seeking Advice on Cost-Effective Backup Solutions for Multiple Hard Drives (beginner) - Thoughts on Bvckup 2?", "Author": "u/AlvTellez", "Content": "I have several larger hard drives:\n  \n\n\n\n\n\n    5TB portable drive connected to my HTPC for films and series via Plex\n  \n\n\n\n\n\n    Two unused 8TB drives\n  \n\n\n\n\n\n    4TB drive containing important media (that doesn't fit in my laptop and/or is more important)\n  \n\n\n\n\n\n    Initially, I considered getting a Synology NAS, but with less than 10TB of actual data, it seems like overkill, especially since I rarely access this data and usually keep the drives unplugged, except for the 5TB drive that's always connected to my HTPC (I also don't really need a NAS for my Plex needs, since I already have the HTPC as a server for that).\n  \n\n    After reading some posts, I thought about purchasing a license for Bvckup 2, which is more cost-effective and would allow me to use my other drives for backup.\n  \n\n    My plan is to transfer data from the 5TB drive to one of the 8TB drives and periodically back up the data to the other 8TB drive. If I run out of space, I could use the 4TB drive similarly and back up data to the other 5TB drive.\n  \n\n    While this might sound inefficient to experienced data hoarders, how bad/good is this idea? Are there any other software options that could simplify this process, compared to manually copying and pasting data between drives?"},
{"Title": "WD Red Plus 8TB vs WD Black 8TB vs IronWolf 8TB?", "Author": "u/GearFourth", "Content": "I ordered a WD Black 8TB, but now the Red Plus is on sale for $34 cheaper, do you guys believe the Black is worth $34 more?\n  \n\n    The biggest difference that I know of is Black has a longer warranty 5 vs 3. Are there any other differences? I would be using them for media storage."},
{"Title": "Will adding a new fan to a DAS result in the fan spinning at 100%?", "Author": "u/Apptryiguess", "Content": "I have a DAS and am pretty happy with the temps, but they could be slightly better since the DAS is in a closet and doesn't get that much airflow. My enterprise drives idle at 43-45 C which is ok, but could be a little better.\n  \n\n    So i thought about adding a new and better fan to the enclosure (Icy Box IB-3805-C31), but the fan never changes speeds, literally never. I don't let my drives spin down but if they were to, the fan does stop spinning after a while, afaik that's the only control the DAS has over the fan. So if i were to add a 2000rpm fan, would it instantly shoot up to that rpm and always spin that fast? Is there a way to control fan speed? I can't see the DAS's fan on any program controlling fan speed so that's something...\n  \n\n    Any idea on how it would behave? Any idea if there is a way to controll the fan speed? Thanks."},
{"Title": "chkbit: Check that your files were not corrupted", "Author": "u/laktakk", "Content": "No content"},
{"Title": "Software for splitting video files in bulk?", "Author": "u/Comfortable_Ad_6823", "Content": "I am currently ripping my SpongeBob DVDs. For anyone unaware, (almost) all SpongeBob episodes are split into A and B parts. For example, \"Pizza Delivery\" is only episode 5a, with \"Home Sweet Pineapple\" being episode 5b. Two \"segments\" make up one episode.\n  \n\n    Normally this isn't a problem, as each segment in the SpongeBob DVDs has its own .mkv file. That is, until season 9, where there are no .mkv files for individual segments, only the combined episode. This is rather annoying as I don't want to scrub to the half-way mark of the videos just to watch the episode I actually want to see. I've thought of splitting the files in half, but it would be a tedious process as seasons are quite long.\n  \n\n    Are there any programs or tools that would make this easier?"},
{"Title": "Help downloading xvideo profiles/playlists", "Author": "u/Thehobbyist916", "Content": "YT-DLP is only able to download one link at a time\n  \n\n    Anyone have any suggestions or advice?\n  \n\n    Also, I’d like to be able to download YouTube RED content\n  \n\n    Thanks"},
{"Title": "Has anyone archived bash.org quotes?", "Author": "u/syswraith", "Content": "The website seems to be down for a while now. Also my password's *******. What's yours?"},
{"Title": "Organizing drives vs drive sizes vs raids/ZFS/stuff", "Author": "u/PuzzleHeadPistion", "Content": "Hey,\n  \n\n    I've got two NAS and a bunch of drives. One EXOS 16Tb, two Barracuda 8Tb, one IronWolf 6Tb, on WD \"white\" 6Tb and on WD Red 3Tb. My main NAS is a desktop with +6 slots, my second NAS is a 4 bay Asustor.\n  \n\n    Currently I don't use raid/parity of any kind... All drives are single volumes and it just sync's each drive from my main NAS to the second NAS, so I try to make the drive setup equal. However, the recent addition of the EXOS 16Tb kills that.\n  \n\n    Since my main NAS is changing to a FreeBSD/TrueNAS with a ZFS pool, what's the best setup?\n  \n\n    I was thinking maybe 8Tb+8Tb+6Tb+6Tb in the ZFS pool, then 16Tb+3Tb as single volumes on my second NAS. This way drives in the pool are as similar as possible in size and if parity wastes one drive, it will be about the same total capacity as the second NAS.\n  \n\n    Does this make sense?"},
{"Title": "Youtube server side add injection role out | Where is it already?", "Author": "u/Pommes254", "Content": "I am running ytdlp to archive a large amount of channels and i am kinda worried to contaminate my archive data with add injected versions.\nThe thing is so far i havent seen a single one with it in about 500 videos, i just finished downloading via proxies in germany, uk and japan (downloaded videos that are about 1-2 weeks old that i already have and compared length via script)\n  \n\n\nHow many users really get videos served with direct injected adds currently?\n\n\n\n\nAnd in what regions?\n\n\n\n    I hope a feature gets merged into ytdlp that checks video lengths and alerts if it detects more than +/- 1 sec compared to a known DB like sponsorblock."},
{"Title": "Why is it taking more than a day to transfer 1.6tb?", "Author": "u/RandonBrando", "Content": "I'm trying to transfer 1.6tb from a 2tb WD Easystore (5400rpm) to a 16tb ironwolf pro (7200rpm) with both drives connected through usb C. Both drives formatted in exFAT.\n  \n\n    I'm getting \nKB/s\n bytes/s - 18MB/s max.  \nNEW LOW SCORE\n\n\n\n    I need some help troubleshooting this because I'm not sure what else to check."},
{"Title": "How to Download a video from a private vimeo server?", "Author": "u/diradi", "Content": "I subscribed to an online course service, and the provider uploads the class recordings to the platform through a private Vimeo server. I can watch the classes, but it's practically impossible to download them using traditional methods. I was able to download some videos on the platform using IDM (Internet Download Manager), but lately, whenever I try to download a video, a message appears saying \"Unknown error, please try again.\"\n  \n\n    Can someone help me with a solution? Either a method to download private Vimeo videos or a way to fix the IDM error.\n  \n\n    Thank you."},
{"Title": "Looking for a software to recognize multiple TB of images", "Author": "u/EasyMoney322", "Content": "Hello, I'm looking for a self-hosted software (that also wouldn't upload photos anywhere) that could do image recognition on the fileshare with an acceptable success rate. I was able to find posts on this sub about nsfw bodyparts recognition, but its not what Im looking for.\n  \n\n    What level of recognition? It must be able to tell appart photos of mass events, people, pets, documents, roads, buildings etc. Having them organized by a location metadata, perhaps. Finding similar (almost duplicate, but with different hash) images.\n  \n\n    Would be great if I could select all the tagged images after, re-check them for false-positives, and delete.\n  \n\n    The fileshare is hosted on OpenSuse VM, but I also can deploy and mount it on any other OS on the same server. I have a lot of processing power, but I'd like to avoid training the AI by myself."},
{"Title": "Easier to get a NAS or just buy another desktop with lots of storage?", "Author": "u/El_Chupachichis", "Content": "I keep contemplating getting more storage, possibly a NAS.  But I'm not doing actual streaming, just collecting an ever larger amount of images, RAW and jpg (I'm an event photographer hobbyist).\n  \n\n    I would look at the NAS online and see perhaps a cheap 4 bay NAS, then look at the reviews and see a lot of complaints.  Seems like getting a reasonably reliable NAS would be more like getting a high end desktop.\n  \n\n    For those digital hoarders who don't have a lot of streamable data, do you prefer NAS or just a big desktop with a lot of drive slots, and maybe a software RAID?  I tend to be a cheapskate so historically it's always been \"buy another drive that's larger and copy stuff over\" but I really need to start thinking long term."},
{"Title": "alternative to Cathy or Virtual Volumes view that can do Boolean Search", "Author": "u/another_lease", "Content": "I need to do Boolean search on my unconnected disks.\n  \n\n    E.g., I need to search for files that contain the word \"confidence\" and \"interval\". If I enter `confidence interval` in the search bar,\n  \n\n\n\n\n\n    Cathy will only find files that contain the \nphrase\n \"confidence interval\" in their file name.\n  \n\n\n\n\n\n    Virtual Volumes View will find me files that contain both words anywhere in the file name, but it will also return files that contain \neither\n word in their filename.\n  \n\n\n\n\n\n    I know that Cathy and VVV have come up before on this subreddit. I was wondering if anyone's figured out some \nportable freeware\n that can do Boolean search.\n  \n\n    Thanks in advance."},
{"Title": "Will youtube ad Injections break music downloads?", "Author": "u/Nerds_r_us45", "Content": "I like downloading some channels in bulk and idk if this will break my ability to hoard music easily or not."},
{"Title": "Is it possible to save an online quiz  to offline and use it offline and recieve results?", "Author": "u/dokha", "Content": "It’s important to note thats the kind of assessment pages im talking about are the casual ones such as the fun ones you take on Buzzfeed and the ones you see on astrology sites..\n\n\n\n    I have no idea the correct tools involved and how to use them .. I did try browser addons such as Single File but the offline files never reach the results after taking the quiz.."},
{"Title": "Why isn't rsync checksum or the equivalent enough to verify your backups?", "Author": "u/Ninj_Pizz_ha", "Content": "I expect I'll get some flack from people super immersed into this subculture, but why do people still recommend opening up random files in the backup to make sure the backup actually worked? Why isn't rsync -c or the equivalent sufficient? Personally I only open my backups every once in blue moon. Maybe there's some edge case where rsync checksum itself is faulty or something I guess, but that's not on my list of likely concerns tbh."},
{"Title": "Photo scanning", "Author": "u/dashcash853", "Content": "Is the dpi a huge deal when it comes to this, I know some do 1200 dpi but a lot of the ones in my price range are 600 dpi."},
{"Title": "Best way to back up gallery and general data from phone?", "Author": "u/Topangers", "Content": "I have iCloud but sometimes popups that appear confuse me and it doesn't seem like the images are actually being backed up? I need to make space on my phone but I hoard the images and videos; same with the general data and applications on my device. Any advice would be greatly appreciated! :)"},
{"Title": "Newbie setup questions", "Author": "u/tranrep", "Content": "Hey all, trying to get myself situated and not the most tech-savvy person so apologies in advance if I'm missing the mark. For context, I'm mostly a hobbyist photographer that wants to just keep my data safe and I don't believe I'd have a need for most of what a NAS offers, so I'm looking into DAS/JBOD as a solution. I currently have around 6TB of photo/video I consider \"important\" enough to backup.\n  \n\n    My current setup is just a single 14 TB WD External HD which is not really being backed up anywhere so I'd like to improve my setup.\n  \n\n    At the core, I'm currently planning on doing the following:\n  \n\n\n\n\n\n    Buying a new 8TB HDD that I'll be \"working off of\", and moving all of my existing data into it\n  \n\n\n\n\n\n    Buying a 4 bay DAS, either using 2 drives for now for RAID1 or buying 4 for RAID4/5 (??) to periodically mirror data from the single 8TB drive onto.\n  \n\n\n\n\n\n    Using Backblaze to backup my PC + DAS.\n  \n\n\n\n\n\n    Does this setup make sense for my needs? If it does make sense, does anybody have any particular product recommendations for the DAS/JBOD and if there's any specific thing to look for in the type of drive(s) to purchase? Is this perhaps overkill for the use case? Please let me know if I'm not providing enough information, thanks."},
{"Title": "I'm using an SD card to USB cable to transfer some photos to my PC but there's only one file with no extension called \"USBC ¬÷\u001f\". Help!", "Author": "u/CorvusTheCryptid", "Content": "The issue is as I describe in the title. I've never had a problem like this before! There's a single file on the device when I plug it in, titled \"USBC ¬÷\u001f\", with no file extension. It's a huge file so I assume that fixing it will allow me access to my files, which have somehow merged into this singular, huge file. Please help, I can't afford to lose these pictures!"},
{"Title": "CD ripping", "Author": "u/nlj1978", "Content": "I have setup a Jellyfin server and have been successfully ripping CDs to flac using EAC.\n  \n\n    EAC does have one issue I haven't figured out. There doesn't seem to be a way to have the contents of one CD ripped into its own folder in the destination.\n  \n\n    Jellyfin's file structure wants each CD in its own folder.\n  \n\n    Is there a method to accomplish this I just haven't found yet?\n  \n\n    If not is there another ripping software that can do this?"},
{"Title": "Bulk image downloader that can download images linked from thumbnails", "Author": "u/xavierhollis", "Content": "Often I find myself checking out a gallery or a post on reddit that has multiple images. By clicking on the thumbnails I can open up larger versions of the same images. But if I want to save the images it gets tedious and time consuming having to go through them all one by one, opening up dozens of webpages or scrolling through each image to save them.\n  \n\n    Is there an app that will basically bulk download ALL the images from a gallery, not simply the thumbnails on that one page, but the higher res images the thumbnails link to?"},
{"Title": "Hydrus network server help?", "Author": "u/Head-Ordinary-4349", "Content": "Does anyone here have any experience translating your local \nHydrus network\n onto a publicly available server? I have made a local database of images which I would like to share and have editable by anyone publicly with a link, however I am very inexperienced in this sort of thing. The user resources describe a  hacky server component that can serve your database over https (as also mentioned \nhere\n), but honestly I have no idea where to even start. I'm wondering if anyone would be able to point me in the right direction or possibly even give me a bit of guidance on how I should proceed? Thanks!"},
{"Title": "Best non destructive way to scan books with illustrations and photographs?", "Author": "u/green__problem", "Content": "I have a flatbed scanner and a phone with a quality camera.\n  \n\n    For text-heavy books I use the CamScanner app, and then scan the cover using my flatbed. Non destructive, very effective. For magazines and newspapers, the flatbed is usually enough, as the lack of a solid spine makes scanning with minimal wear very easy.\n  \n\n    Now comes my problem: \nI have a lot of image-heavy books that I want to scan, but I have yet to find a good method to do so.\n\n\n\n    CamScanner is horrid at dealing with illustrations and photographs. The flatbed works \nalright\n, but not great. Because I avoid breaking the book's spine, there are always visible shadows and both text and images become a little blurry when they're close to the hinge.\n  \n\n\nI'm wondering if there's an app similar to CamScanner but more appropriate for photographs? Or a different method altogether.\n\n\n\n    I know some people melt the glue keeping the spine together, scan the pages individually, and then glue everything back on. This wouldn't work for all of the books in my collection- but I have considered trying it on a handful of them. I'm just a little scared of screwing the process up.\n  \n\n    Thanks in advance."},
{"Title": "Why is XFS not more popular? Are there are any concerns with XFS still?", "Author": "u/ECrispy", "Content": "This is for home desktop usage, not servers/data centers where XFS is far more common.\n  \n\n    performance - in every test I could find, XFS is near the top, beating btrfs/ext4. Its esp good for parallel workloads and almost everything on a modern desktop is like that. The only perf concern I read about is it used to have higher cpu usage for updating metadata but I believe thats been fixed and no longer relevant?\n  \n\n    (I think for most users, performance in benchmarks may not be noticeable and other features matter more, but its still an important consideration)\n  \n\n    SSD/OS installs - XFS is almost as fast as f2fs for these. I see no reason why anyone would use f2fs on anything other than a sd card or on any NAND device with wear leveling.\n  \n\n    CoW/snapshots - this is no doubt a very powerful feature of zfs/btrfs. But I see very little mention of reflinks/snapshots on XFS which can achieve a lot of this. They are not atomic but enough to satisfy a lot of use cases. I don't see support for this in the usual tools like snapper/timeshift either. XFS also has support for deduping. All of this comes without the usual cost of CoW\n  \n\n    other features - dynamic inodes (on ext4 an inode for every 16kb/256kb is wasteful, even if most people never notice it), automatic fsck, journalling (sure, copied from ext3, but thats not a bad thing)\n  \n\n    stability/reliability - I don't think there should be any doubt about this. Its a proven enterprise class fs with a hallowed pedigree and reputation, is now backed by RHEL and has probably seen more active development than most other file systems.\n  \n\n\n\n    The biggest factor seems to be that the default ext4 is good enough, and frankly most people will not care or know about, and should not care, about the underlying fs. There are also distros like Fedora/OpenSuse that used to use XFS as the default and have switched to btrfs. I don't know of anything that uses XFS as default except unRaid now - unRaid is used to manage TBs by home users and that probably says something.\n  \n\n\n\n    The only concerns I've found are -\n  \n\n    a) it doesn't support shrinking a volume. how common is this anyway? I've never seen any home user need to do this, 99% of the time you only need this when you are installing another OS on the same ssd/hdd and need to shrink your current /, which is an advanced use case.\n  \n\n    b)supposedly XFS doesn't handle hw failures. Even on this I found no consensus - some people say its risky and can corrupt with no recovery, others say even with a forced  shutdown its safe. I'm not sure if its any less robust than ext4/btrfs? Is this actually a concern these days?"},
{"Title": "Recertified EXOS X18 constantly reading?", "Author": "u/wiadrovit", "Content": "Hey there Guys,\n  \n\n    I've bought a recertified EXOS X18 12TB for my NAS. The drive isn't exactly loud and it performs as I would expect, but there's one thing that I can't walk past - it acts as if it was doing something, even when completely idle.\n  \n\n    The drive lives in my Sabrent DS-SC5B hdd enclosure which I've been using for over a year now and which I'm very satisfied with.\n  \n\n    Video: \nhttps://imgur.com/a/o39cfd8\n (it's the second one from the top - as you can see its LED is blinking in a regular manner).\n  \n\n    I've read that EXOS drives have their own APM feature which can be disabled using seachest tool. I've managed to successfully disable both EPC as well as the power balance feature, but that didn't change anything, the LED still blinks and I can hear a regular, gentle cracking sound as if something was read/written.\n  \n\n    The drive is mounted on my Debian installation and I've confirmed that no process is using it. What's weird is that activities stop as soon as I unmount the drive (and start again as soon as I mount it back).\n  \n\n    In fact, this is a second drive that does the same thing. I've returned previous one to the seller as I've felt something is not right with it. Both were manufactured (or rather reassembled?) back in March 2024.\n  \n\n    I should add that I have another EXOS drive (X16 16TB sitting in my backup device) and it doesn't act this way.\n  \n\n    Is it normal for these drives or do you think I should return this one as well and go for something else?\n  \n\n    It isn't that much annoying, I am just worried that if the head keeps flying all the time, the drive will wear sooner and might die prematurely.\n  \n\n    Thanks for any advice."},
{"Title": "Getting creative and hacky with SFF as NAS.", "Author": "u/kkgmgfn", "Content": "Trigger Warning : This post is for DataHoarders + SFF enthusiasts. So please don't come saying get a 2TB NVME, get a 2.5 SATA SSD and yap yap yap.. And I have other systems too. One EATX, One MFF, Two SFF and One HTPC. So I am not a new builder. Posting here since it will be more appropriate than posting in Homelab or DataHoarder sub.\n  \n\n    As we know it we have very limited SFF cases with HDD support. Manufacturers hardly make them anymore.\n  \n\n    Some options that we have today:\n  \n\n    Node 304: Outdated and front panel is very restrictive. 92mm fans in front are noisy as they are 3pin. In my country I can't find any 92mm fan.\n  \n\n    Jonsbo N series: Pat on the back for Jonsbo on launching several SFF NAS cases back to back. They feel like they have restrictive airflow. They aren't available in my country.\n  \n\n    SAMA IM 01 and its copies: Supports 4 - 5. A cheap knock of this is available. But is an option.\n  \n\n    So my question is have you guys though about squeezing extra HDDs in cases like Deepcool CH 160, Coolermaster NR200P etc. For example if I can use rear fan mount for 120 AIO intake then does 120 fan slot above have motherboard has hinges for 3. 5\"HDD? Does it have space to tuck one below a dual slot dual fan GPU. I know 1 3.5\" HDD can go on front panel when I use a SFX PSU. Similarly for NR200P. More suggestions are welcome. I'll use a Noctua L9i or 120 AIO as I have then lying around.\n  \n\n    I wish this post to be open for coming years so people can get ideas and inspiration from the comments."},
{"Title": "Feedback for backup plan", "Author": "u/DeadbeatSummer13", "Content": "My dataset is around 10-16tb. I plan on transferring my current externals to 1 big drive. I’m trying to decide if this working drive is going to be internal or external. Regardless, this will be backed up to a 2nd drive daily. Then, the 2nd drive will backup to backblaze daily. A private encryption key will be set on backblaze. Possibly down the road an off-site drive may be added to be backed up weekly and then disconnected and moved off-site.\n  \n\n    Feedback is greatly appreciated. What do you think?"},
{"Title": "Should I purchase a NAS for the data integrity features?", "Author": "u/SystemElegant2703", "Content": "Is it necessary to purchase a NAS if all I'm really interested in are the data integrity features (i.e automatic hash checking/recording, file self-healing, datascrubbing, etc.)? Currently I use MultiPar and backup my data to M-discs. However, I would like greater certainty that the hashes are accurate. For instance, I got a trojan recently and now I'm left questioning if the hundreds of files I've downloaded since my last backup have any data corruption, silent or otherwise. Since it's impossible to know without the features I listed previously, should I consider purchasing a NAS or is there a method I haven't thought of to ensure the same level of data integrity?"},
{"Title": "Help downloading xvideo profiles/playlists", "Author": "u/Thehobbyist916", "Content": "YT-DLP is only able to download one link at a time\n  \n\n    Anyone have any suggestions or advice?\n  \n\n    Also, I’d like to be able to download YouTube RED content\n  \n\n    Thanks"},
{"Title": "Has anyone archived bash.org quotes?", "Author": "u/syswraith", "Content": "The website seems to be down for a while now. Also my password's *******. What's yours?"},
{"Title": "Organizing drives vs drive sizes vs raids/ZFS/stuff", "Author": "u/PuzzleHeadPistion", "Content": "Hey,\n  \n\n    I've got two NAS and a bunch of drives. One EXOS 16Tb, two Barracuda 8Tb, one IronWolf 6Tb, on WD \"white\" 6Tb and on WD Red 3Tb. My main NAS is a desktop with +6 slots, my second NAS is a 4 bay Asustor.\n  \n\n    Currently I don't use raid/parity of any kind... All drives are single volumes and it just sync's each drive from my main NAS to the second NAS, so I try to make the drive setup equal. However, the recent addition of the EXOS 16Tb kills that.\n  \n\n    Since my main NAS is changing to a FreeBSD/TrueNAS with a ZFS pool, what's the best setup?\n  \n\n    I was thinking maybe 8Tb+8Tb+6Tb+6Tb in the ZFS pool, then 16Tb+3Tb as single volumes on my second NAS. This way drives in the pool are as similar as possible in size and if parity wastes one drive, it will be about the same total capacity as the second NAS.\n  \n\n    Does this make sense?"},
{"Title": "Youtube server side add injection role out | Where is it already?", "Author": "u/Pommes254", "Content": "I am running ytdlp to archive a large amount of channels and i am kinda worried to contaminate my archive data with add injected versions.\nThe thing is so far i havent seen a single one with it in about 500 videos, i just finished downloading via proxies in germany, uk and japan (downloaded videos that are about 1-2 weeks old that i already have and compared length via script)\n  \n\n\nHow many users really get videos served with direct injected adds currently?\n\n\n\n\nAnd in what regions?\n\n\n\n    I hope a feature gets merged into ytdlp that checks video lengths and alerts if it detects more than +/- 1 sec compared to a known DB like sponsorblock."},
{"Title": "Why is it taking more than a day to transfer 1.6tb?", "Author": "u/RandonBrando", "Content": "I'm trying to transfer 1.6tb from a 2tb WD Easystore (5400rpm) to a 16tb ironwolf pro (7200rpm) with both drives connected through usb C. Both drives formatted in exFAT.\n  \n\n    I'm getting \nKB/s\n bytes/s - 18MB/s max.  \nNEW LOW SCORE\n\n\n\n    I need some help troubleshooting this because I'm not sure what else to check."},
{"Title": "How to Download a video from a private vimeo server?", "Author": "u/diradi", "Content": "I subscribed to an online course service, and the provider uploads the class recordings to the platform through a private Vimeo server. I can watch the classes, but it's practically impossible to download them using traditional methods. I was able to download some videos on the platform using IDM (Internet Download Manager), but lately, whenever I try to download a video, a message appears saying \"Unknown error, please try again.\"\n  \n\n    Can someone help me with a solution? Either a method to download private Vimeo videos or a way to fix the IDM error.\n  \n\n    Thank you."},
{"Title": "Looking for a software to recognize multiple TB of images", "Author": "u/EasyMoney322", "Content": "Hello, I'm looking for a self-hosted software (that also wouldn't upload photos anywhere) that could do image recognition on the fileshare with an acceptable success rate. I was able to find posts on this sub about nsfw bodyparts recognition, but its not what Im looking for.\n  \n\n    What level of recognition? It must be able to tell appart photos of mass events, people, pets, documents, roads, buildings etc. Having them organized by a location metadata, perhaps. Finding similar (almost duplicate, but with different hash) images.\n  \n\n    Would be great if I could select all the tagged images after, re-check them for false-positives, and delete.\n  \n\n    The fileshare is hosted on OpenSuse VM, but I also can deploy and mount it on any other OS on the same server. I have a lot of processing power, but I'd like to avoid training the AI by myself."},
{"Title": "Easier to get a NAS or just buy another desktop with lots of storage?", "Author": "u/El_Chupachichis", "Content": "I keep contemplating getting more storage, possibly a NAS.  But I'm not doing actual streaming, just collecting an ever larger amount of images, RAW and jpg (I'm an event photographer hobbyist).\n  \n\n    I would look at the NAS online and see perhaps a cheap 4 bay NAS, then look at the reviews and see a lot of complaints.  Seems like getting a reasonably reliable NAS would be more like getting a high end desktop.\n  \n\n    For those digital hoarders who don't have a lot of streamable data, do you prefer NAS or just a big desktop with a lot of drive slots, and maybe a software RAID?  I tend to be a cheapskate so historically it's always been \"buy another drive that's larger and copy stuff over\" but I really need to start thinking long term."},
{"Title": "alternative to Cathy or Virtual Volumes view that can do Boolean Search", "Author": "u/another_lease", "Content": "I need to do Boolean search on my unconnected disks.\n  \n\n    E.g., I need to search for files that contain the word \"confidence\" and \"interval\". If I enter `confidence interval` in the search bar,\n  \n\n\n\n\n\n    Cathy will only find files that contain the \nphrase\n \"confidence interval\" in their file name.\n  \n\n\n\n\n\n    Virtual Volumes View will find me files that contain both words anywhere in the file name, but it will also return files that contain \neither\n word in their filename.\n  \n\n\n\n\n\n    I know that Cathy and VVV have come up before on this subreddit. I was wondering if anyone's figured out some \nportable freeware\n that can do Boolean search.\n  \n\n    Thanks in advance."},
{"Title": "Will youtube ad Injections break music downloads?", "Author": "u/Nerds_r_us45", "Content": "I like downloading some channels in bulk and idk if this will break my ability to hoard music easily or not."},
{"Title": "Is it possible to save an online quiz  to offline and use it offline and recieve results?", "Author": "u/dokha", "Content": "It’s important to note thats the kind of assessment pages im talking about are the casual ones such as the fun ones you take on Buzzfeed and the ones you see on astrology sites..\n\n\n\n    I have no idea the correct tools involved and how to use them .. I did try browser addons such as Single File but the offline files never reach the results after taking the quiz.."},
{"Title": "Why isn't rsync checksum or the equivalent enough to verify your backups?", "Author": "u/Ninj_Pizz_ha", "Content": "I expect I'll get some flack from people super immersed into this subculture, but why do people still recommend opening up random files in the backup to make sure the backup actually worked? Why isn't rsync -c or the equivalent sufficient? Personally I only open my backups every once in blue moon. Maybe there's some edge case where rsync checksum itself is faulty or something I guess, but that's not on my list of likely concerns tbh."},
{"Title": "Photo scanning", "Author": "u/dashcash853", "Content": "Is the dpi a huge deal when it comes to this, I know some do 1200 dpi but a lot of the ones in my price range are 600 dpi."},
{"Title": "Best way to back up gallery and general data from phone?", "Author": "u/Topangers", "Content": "I have iCloud but sometimes popups that appear confuse me and it doesn't seem like the images are actually being backed up? I need to make space on my phone but I hoard the images and videos; same with the general data and applications on my device. Any advice would be greatly appreciated! :)"},
{"Title": "Newbie setup questions", "Author": "u/tranrep", "Content": "Hey all, trying to get myself situated and not the most tech-savvy person so apologies in advance if I'm missing the mark. For context, I'm mostly a hobbyist photographer that wants to just keep my data safe and I don't believe I'd have a need for most of what a NAS offers, so I'm looking into DAS/JBOD as a solution. I currently have around 6TB of photo/video I consider \"important\" enough to backup.\n  \n\n    My current setup is just a single 14 TB WD External HD which is not really being backed up anywhere so I'd like to improve my setup.\n  \n\n    At the core, I'm currently planning on doing the following:\n  \n\n\n\n\n\n    Buying a new 8TB HDD that I'll be \"working off of\", and moving all of my existing data into it\n  \n\n\n\n\n\n    Buying a 4 bay DAS, either using 2 drives for now for RAID1 or buying 4 for RAID4/5 (??) to periodically mirror data from the single 8TB drive onto.\n  \n\n\n\n\n\n    Using Backblaze to backup my PC + DAS.\n  \n\n\n\n\n\n    Does this setup make sense for my needs? If it does make sense, does anybody have any particular product recommendations for the DAS/JBOD and if there's any specific thing to look for in the type of drive(s) to purchase? Is this perhaps overkill for the use case? Please let me know if I'm not providing enough information, thanks."},
{"Title": "I'm using an SD card to USB cable to transfer some photos to my PC but there's only one file with no extension called \"USBC ¬÷\u001f\". Help!", "Author": "u/CorvusTheCryptid", "Content": "The issue is as I describe in the title. I've never had a problem like this before! There's a single file on the device when I plug it in, titled \"USBC ¬÷\u001f\", with no file extension. It's a huge file so I assume that fixing it will allow me access to my files, which have somehow merged into this singular, huge file. Please help, I can't afford to lose these pictures!"},
{"Title": "CD ripping", "Author": "u/nlj1978", "Content": "I have setup a Jellyfin server and have been successfully ripping CDs to flac using EAC.\n  \n\n    EAC does have one issue I haven't figured out. There doesn't seem to be a way to have the contents of one CD ripped into its own folder in the destination.\n  \n\n    Jellyfin's file structure wants each CD in its own folder.\n  \n\n    Is there a method to accomplish this I just haven't found yet?\n  \n\n    If not is there another ripping software that can do this?"},
{"Title": "Bulk image downloader that can download images linked from thumbnails", "Author": "u/xavierhollis", "Content": "Often I find myself checking out a gallery or a post on reddit that has multiple images. By clicking on the thumbnails I can open up larger versions of the same images. But if I want to save the images it gets tedious and time consuming having to go through them all one by one, opening up dozens of webpages or scrolling through each image to save them.\n  \n\n    Is there an app that will basically bulk download ALL the images from a gallery, not simply the thumbnails on that one page, but the higher res images the thumbnails link to?"},
{"Title": "Hydrus network server help?", "Author": "u/Head-Ordinary-4349", "Content": "Does anyone here have any experience translating your local \nHydrus network\n onto a publicly available server? I have made a local database of images which I would like to share and have editable by anyone publicly with a link, however I am very inexperienced in this sort of thing. The user resources describe a  hacky server component that can serve your database over https (as also mentioned \nhere\n), but honestly I have no idea where to even start. I'm wondering if anyone would be able to point me in the right direction or possibly even give me a bit of guidance on how I should proceed? Thanks!"},
{"Title": "Best non destructive way to scan books with illustrations and photographs?", "Author": "u/green__problem", "Content": "I have a flatbed scanner and a phone with a quality camera.\n  \n\n    For text-heavy books I use the CamScanner app, and then scan the cover using my flatbed. Non destructive, very effective. For magazines and newspapers, the flatbed is usually enough, as the lack of a solid spine makes scanning with minimal wear very easy.\n  \n\n    Now comes my problem: \nI have a lot of image-heavy books that I want to scan, but I have yet to find a good method to do so.\n\n\n\n    CamScanner is horrid at dealing with illustrations and photographs. The flatbed works \nalright\n, but not great. Because I avoid breaking the book's spine, there are always visible shadows and both text and images become a little blurry when they're close to the hinge.\n  \n\n\nI'm wondering if there's an app similar to CamScanner but more appropriate for photographs? Or a different method altogether.\n\n\n\n    I know some people melt the glue keeping the spine together, scan the pages individually, and then glue everything back on. This wouldn't work for all of the books in my collection- but I have considered trying it on a handful of them. I'm just a little scared of screwing the process up.\n  \n\n    Thanks in advance."},
{"Title": "Why is XFS not more popular? Are there are any concerns with XFS still?", "Author": "u/ECrispy", "Content": "This is for home desktop usage, not servers/data centers where XFS is far more common.\n  \n\n    performance - in every test I could find, XFS is near the top, beating btrfs/ext4. Its esp good for parallel workloads and almost everything on a modern desktop is like that. The only perf concern I read about is it used to have higher cpu usage for updating metadata but I believe thats been fixed and no longer relevant?\n  \n\n    (I think for most users, performance in benchmarks may not be noticeable and other features matter more, but its still an important consideration)\n  \n\n    SSD/OS installs - XFS is almost as fast as f2fs for these. I see no reason why anyone would use f2fs on anything other than a sd card or on any NAND device with wear leveling.\n  \n\n    CoW/snapshots - this is no doubt a very powerful feature of zfs/btrfs. But I see very little mention of reflinks/snapshots on XFS which can achieve a lot of this. They are not atomic but enough to satisfy a lot of use cases. I don't see support for this in the usual tools like snapper/timeshift either. XFS also has support for deduping. All of this comes without the usual cost of CoW\n  \n\n    other features - dynamic inodes (on ext4 an inode for every 16kb/256kb is wasteful, even if most people never notice it), automatic fsck, journalling (sure, copied from ext3, but thats not a bad thing)\n  \n\n    stability/reliability - I don't think there should be any doubt about this. Its a proven enterprise class fs with a hallowed pedigree and reputation, is now backed by RHEL and has probably seen more active development than most other file systems.\n  \n\n\n\n    The biggest factor seems to be that the default ext4 is good enough, and frankly most people will not care or know about, and should not care, about the underlying fs. There are also distros like Fedora/OpenSuse that used to use XFS as the default and have switched to btrfs. I don't know of anything that uses XFS as default except unRaid now - unRaid is used to manage TBs by home users and that probably says something.\n  \n\n\n\n    The only concerns I've found are -\n  \n\n    a) it doesn't support shrinking a volume. how common is this anyway? I've never seen any home user need to do this, 99% of the time you only need this when you are installing another OS on the same ssd/hdd and need to shrink your current /, which is an advanced use case.\n  \n\n    b)supposedly XFS doesn't handle hw failures. Even on this I found no consensus - some people say its risky and can corrupt with no recovery, others say even with a forced  shutdown its safe. I'm not sure if its any less robust than ext4/btrfs? Is this actually a concern these days?"},
{"Title": "Recertified EXOS X18 constantly reading?", "Author": "u/wiadrovit", "Content": "Hey there Guys,\n  \n\n    I've bought a recertified EXOS X18 12TB for my NAS. The drive isn't exactly loud and it performs as I would expect, but there's one thing that I can't walk past - it acts as if it was doing something, even when completely idle.\n  \n\n    The drive lives in my Sabrent DS-SC5B hdd enclosure which I've been using for over a year now and which I'm very satisfied with.\n  \n\n    Video: \nhttps://imgur.com/a/o39cfd8\n (it's the second one from the top - as you can see its LED is blinking in a regular manner).\n  \n\n    I've read that EXOS drives have their own APM feature which can be disabled using seachest tool. I've managed to successfully disable both EPC as well as the power balance feature, but that didn't change anything, the LED still blinks and I can hear a regular, gentle cracking sound as if something was read/written.\n  \n\n    The drive is mounted on my Debian installation and I've confirmed that no process is using it. What's weird is that activities stop as soon as I unmount the drive (and start again as soon as I mount it back).\n  \n\n    In fact, this is a second drive that does the same thing. I've returned previous one to the seller as I've felt something is not right with it. Both were manufactured (or rather reassembled?) back in March 2024.\n  \n\n    I should add that I have another EXOS drive (X16 16TB sitting in my backup device) and it doesn't act this way.\n  \n\n    Is it normal for these drives or do you think I should return this one as well and go for something else?\n  \n\n    It isn't that much annoying, I am just worried that if the head keeps flying all the time, the drive will wear sooner and might die prematurely.\n  \n\n    Thanks for any advice."},
{"Title": "Getting creative and hacky with SFF as NAS.", "Author": "u/kkgmgfn", "Content": "Trigger Warning : This post is for DataHoarders + SFF enthusiasts. So please don't come saying get a 2TB NVME, get a 2.5 SATA SSD and yap yap yap.. And I have other systems too. One EATX, One MFF, Two SFF and One HTPC. So I am not a new builder. Posting here since it will be more appropriate than posting in Homelab or DataHoarder sub.\n  \n\n    As we know it we have very limited SFF cases with HDD support. Manufacturers hardly make them anymore.\n  \n\n    Some options that we have today:\n  \n\n    Node 304: Outdated and front panel is very restrictive. 92mm fans in front are noisy as they are 3pin. In my country I can't find any 92mm fan.\n  \n\n    Jonsbo N series: Pat on the back for Jonsbo on launching several SFF NAS cases back to back. They feel like they have restrictive airflow. They aren't available in my country.\n  \n\n    SAMA IM 01 and its copies: Supports 4 - 5. A cheap knock of this is available. But is an option.\n  \n\n    So my question is have you guys though about squeezing extra HDDs in cases like Deepcool CH 160, Coolermaster NR200P etc. For example if I can use rear fan mount for 120 AIO intake then does 120 fan slot above have motherboard has hinges for 3. 5\"HDD? Does it have space to tuck one below a dual slot dual fan GPU. I know 1 3.5\" HDD can go on front panel when I use a SFX PSU. Similarly for NR200P. More suggestions are welcome. I'll use a Noctua L9i or 120 AIO as I have then lying around.\n  \n\n    I wish this post to be open for coming years so people can get ideas and inspiration from the comments."},
{"Title": "Feedback for backup plan", "Author": "u/DeadbeatSummer13", "Content": "My dataset is around 10-16tb. I plan on transferring my current externals to 1 big drive. I’m trying to decide if this working drive is going to be internal or external. Regardless, this will be backed up to a 2nd drive daily. Then, the 2nd drive will backup to backblaze daily. A private encryption key will be set on backblaze. Possibly down the road an off-site drive may be added to be backed up weekly and then disconnected and moved off-site.\n  \n\n    Feedback is greatly appreciated. What do you think?"},
{"Title": "Should I purchase a NAS for the data integrity features?", "Author": "u/SystemElegant2703", "Content": "Is it necessary to purchase a NAS if all I'm really interested in are the data integrity features (i.e automatic hash checking/recording, file self-healing, datascrubbing, etc.)? Currently I use MultiPar and backup my data to M-discs. However, I would like greater certainty that the hashes are accurate. For instance, I got a trojan recently and now I'm left questioning if the hundreds of files I've downloaded since my last backup have any data corruption, silent or otherwise. Since it's impossible to know without the features I listed previously, should I consider purchasing a NAS or is there a method I haven't thought of to ensure the same level of data integrity?"},
{"Title": "ytarchive vs yt-dlp on video afterwards", "Author": "u/idle_cat", "Content": "On youtube, I archive livestreams of a channel. Is the live archive recording I get by using ytarchive a higher quality then the video I would get with yt-dlp that's processed afterwards? From my understanding the video goes through youtube's compression. Is the compression really strong in your opinion? I am wondering if it's worth getting the vod to save space.\n  \n\n    Side questions:\n  \n\n    Why do people put --format \"bv*+ba/b\" or something similar to get when yt-dlp already has it set to get the individual best audio and video as the default? \nhttps://github.com/yt-dlp/yt-dlp?tab=readme-ov-file#format-selection"},
{"Title": "Retire a drive after a single pending sector?", "Author": "u/Most_Mix_7505", "Content": "What would you all do?"},
{"Title": "Video and Audio URLs obtained from yt-dlp -g are downloading very slow. How to fix?", "Author": "u/CoolstarLikesHentai", "Content": "I am trying to get the original video file from a YouTube video by using the \nyt-dlp -g\n command (short for \nyt-dlp --get-url\n) to get the video URL and audio URL. I can successfully get both URLs, but when I download them it downloads very very slow (~150 kb/s). Is there any way I can speed up the download speed?"},
{"Title": "Backup my network pc's to my OMV Nas", "Author": "u/SbM_Yggdrassil", "Content": "Hi all, I'm at that part of my homelab journey where I've setup a bunch of fun stuff and now I'm starting to think about helpful stuff like backups.\n  \n\n    I have a raspberry pi 4 setup with open media vault and docker running various services. I would like to add one or more services (in containers if necessary) to accomplish the following:\n  \n\n\n\n\n\n    Make an image of bootdrives of my computers on a schedule\n  \n\n\n\n\n\n    save those images to the attached storage.\n  \n\n\n\n\n\n    reimaging solution for recovery\n  \n\n\n\n\n\n\n\n\n\n    Backup secondary, non-bootdrives of my computers (just copying is probably fine)\n  \n\n\n\n\n\n    I'm just wondering how to best add services and which would do it. If I should use syncthing/duplicati + something else or if there is one thing that can do it all. I'm not sure how incremental backups fit in here either but I'd like to implement that to reduce the burden of network traffic (in my home we have to use wi-fi a lot).\n  \n\n    For drive images I've used the free version of Macrium reflect before (and I've heard of acronis), but just on one of my windows pc's. I'd like to have something scheduled from the server side for centralised management.\n  \n\n    Does it make sense what I'm trying to achieve?"},
{"Title": "$5 worth the risk?", "Author": "u/Long_Instruction_391", "Content": "No content"},
{"Title": "Mini PC as NAS, good idea?", "Author": "u/smartyee", "Content": "No content"},
{"Title": "General Reminder Backups are Important", "Author": "u/TeamSylver", "Content": "Everyone here probably already knows that.\n  \n\n    I've just had all 3 drives in my desktop PC suddenly have problems.\n  \n\n    Thank god I can still read/write to the drives though. It's just god awful slow, especially during data transfers, where it will render the whole OS unusable until it's done.\n  \n\n    So that was a lot of pain and agony to temporarily move everything to the spare PC and laptops I have laying around (PC has 1tb, laptops have 1.5tb and 4.5tb).\n  \n\n    Means I now have no backups at all, since I still haven't finished setting up my work PC to be my off-site backup PC yet (it's basically manage/byo PC at my work BC it's such a small store).\n  \n\n    Annoying as well since that PC hosts my active directory and vaultwarden as well as the file server (thankfully I had a secondary active directory server set up, but no vaultwarden).\n  \n\n    Gotta love Crucial NVMes. All of them only 11 months old. Never again. 2 of 3 RMAs processed but I still gotta get data off of the third (OS drive) before I can post that.\n  \n\n    Edit: Forgot to mention they are Crucial P3 Plus 4TB NVMes"},
{"Title": "Dedup utility that FIRST finds duplicates by name/size/date, and THEN compares their content", "Author": "u/Msprg", "Content": "Hello,\n  \n\n    Let me preface with: I know there are a million posts about dedup tools already. Dedup by file content, checksum, attributes, similar photos, similar videos…\n  \n\n    Yet somehow, I failed to find any tools that would be able to first filter out the majority of files that differ in filename / date / size \nand\n \nthen\n on the results make sure that files are 100% surely duplicate by comparing their content.\n  \n\n    I've tried dupeguru, alldup, freefilesync, treesize, czkawka, I tried everything! (By voidtools that is).\n  \n\n    The point is that I'm either missing something, or that none of the tools offer the option I'm looking for.\n  \n\n    So here I am. Once again. Seeking answer to the eternal question: How do you deal with duplicates, fellow Data Hoarders?"},
{"Title": "What Non-NAS storage would you recommend?", "Author": "u/Bloodmoonwolf", "Content": "I currently have less than 800GB across 2 clouds and my laptop. I'm hitting my storage limit on Google and looking for a safe, local option. After losing everything on an old laptop that crashed, I started doing cloud storage, which is now becoming expensive.\n  \n\n    My current laptop is an old HP and I have yet to decide between a new Windows laptop or a Chromebook. I have a Plex library I would like to expand, even bought an external DVD reader to start the library. I don't necessarily need NAS. Plugging something into the TV or my laptop would be fine when I want to watch something on Plex (which isn't very often). The same goes for when I need to do a regular backup of files. I would prefer to buy something once instead of paying a monthly subscription and to not add another constant draw on our power supply.\n  \n\n    Most of the storage is for movies/shows, photos, and PDF scans of documents from when I went paperless. I would like to add music to this once I figure out a few things.\n  \n\n    What type/size/brand of local storage would you recommend for my situation?"},
{"Title": "Ripping dvd/blu-rays question for auto ripping? via bash script", "Author": "u/1michaelbrown", "Content": "I have setup a bash script to autorip so far it is working but with errors. So how would I fix the errors or do this a better way. Errors I am having\n  \nJun 17 20:24:15 markvm5 (udev-worker)[9984]: sr0: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:24:15 markvm5 (udev-worker)[9995]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:26:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] is taking longer than 56s to complete                                                      \nJun 17 20:26:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 is taking a long time                                                                                                     \nJun 17 20:28:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] timed out after 2min 56s, killing                                                          \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 killed                                                                                                                    \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] terminated by signal 9 (KILL).                                                                                                                   \nJun 17 20:41:49 markvm5 (udev-worker)[10159]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                   \nJun 17 20:52:38 markvm5 (udev-worker)[10201]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10205] is taking longer than 47s to complete                                                      \nJun 17 20:52:38 markvm5 systemd-udevd[467]: sr1: Worker [10201] processing SEQNUM=8077 is taking a long time Jun 17 20:24:15 markvm5 (udev-worker)[9984]: sr0: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:24:15 markvm5 (udev-worker)[9995]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:26:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] is taking longer than 56s to complete                                                      \nJun 17 20:26:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 is taking a long time                                                                                                     \nJun 17 20:28:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] timed out after 2min 56s, killing                                                          \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 killed                                                                                                                    \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] terminated by signal 9 (KILL).                                                                                                                   \nJun 17 20:41:49 markvm5 (udev-worker)[10159]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                   \nJun 17 20:52:38 markvm5 (udev-worker)[10201]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10205] is taking longer than 47s to complete                                                      \nJun 17 20:52:38 markvm5 systemd-udevd[467]: sr1: Worker [10201] processing SEQNUM=8077 is taking a long time \n\n    This is the process I used I setup a udev rule\n  \nSUBSYSTEM==\"block\", ENV{ID_CDROM}==\"1\", ACTION==\"change\", RUN+=\"/bin/systemctl start makemkv-rip.service\"SUBSYSTEM==\"block\", ENV{ID_CDROM}==\"1\", ACTION==\"change\", RUN+=\"/bin/systemctl start makemkv-rip.service\"\n\n    and the makemkv-rip.service at\n  \n/etc/systemd/system/makemkv-rip.service`/etc/systemd/system/makemkv-rip.service\n\n[Unit]                                                                                                                                                                                                           \nDescription=AutoRip CD on insertion                                                                                                                                                                              \n                                                                                                                                                                                                                 \n[Service]                                                                                                                                                                                                        \nType=oneshot                                                                                                                                                                                                     \nRemainAfterExit=no                                                                                                                                                                                               \nExecStart=/home/mike/autorip.sh                                                                                                                                                                                  \nExecStop=killall autorip.sh [Unit]                                                                                                                                                                                                           \nDescription=AutoRip CD on insertion                                                                                                                                                                              \n                                                                                                                                                                                                                 \n[Service]                                                                                                                                                                                                        \nType=oneshot                                                                                                                                                                                                     \nRemainAfterExit=no                                                                                                                                                                                               \nExecStart=/home/mike/autorip.sh                                                                                                                                                                                  \nExecStop=killall autorip.sh \n\n    It's weird because the script is working but still get these errors. Also need to figure out how to trigger encoding after rip. Also in my autorip script it is finding titles in ` TINFO` should it be finding them in CINFO."},
{"Title": "Extracting Subtitles from Patreon", "Author": "u/pinkwonderwall", "Content": "Is there a way to rip captions from Patreon videos? I'm talking about Patreon videos I already have access to through a paid subscription. I like to save a video's subtitles as a text file so I can ctrl+F search for a particular word and find the moment that topic is discussed. I've tried Chrome extensions, but none of them work with Patreon. I've also looked for other posts of people asking this question, and it seems like not many people are trying to do this lol. I searched Inspect and Page Source and didn't see any obvious solutions, but I'm inexperienced with that so I may be missing something."},
{"Title": "Exausted and burnt out due to caring for my data", "Author": "u/CreativeDog2024", "Content": "I have about 5TB of movies/tv shows/photos. I have 3 backups: one is my main frequently accessed HDD. Another is another HDD i keep in my drawer and the last is google drive.\n  \n\n    I'm not a programmer so idk how to verify whether there has been data loss but I make sure all the files on each are the same by using freefilesync (mac app). It takes so much time and I don't even know if the files are corrupted or not.\n  \n\n    Is there some cloud option that I can leave my data on and pay $10-15/month to forget about it, using it as a last resort if all my local backups are corrupted?\n  \n\n    I read quite a bit on this and people recommend backblaze (B2 I think, how do i even buy it?), AWS glacier and M-disks.\n  \n\n    I have no idea how to operate any of those because I don't code. I do use rclone for Gdrive though."},
{"Title": "Western Digital DC HC580 (CMR or SMR?) & DS923+", "Author": "u/sulicadiz", "Content": "I just bought a Western Digital DC HC580. I don't know an effective method to know if the drive is CMR or SMR. I have read here in the forum that I should buy a CMR hard drive to use with the NAS (I have a DS923+).\n  \n\n    Another question, before setting the NAS should I introduce all the drives I would be using?\nThe NAS have 4 slots, so I guess the first step would be to buy 4 hard drive then set up the unit. I suppose If I insert 2 drives then the other 2 I would lose data.\n  \n\n    Anyway, total noob here, please help"},
{"Title": "Are there some software that provides multiple download links using VPN at once?", "Author": "u/ElonTastical", "Content": "Let's say you wanna download multiple links from keep2share, but in that site it is limited by single download, you have to wait two hours before you can download another file. Is there a way to bypass this like the idea I mentioned in the title?"},
{"Title": "What's the most HDD failures you've seen in a 6 month period?", "Author": "u/the_Athereon", "Content": "Genuine question. How many of you have had a year as bad as mine so far?\n  \n\n    5 failures. 1 DOA\n  \n\n    Parity 1 and 2 went in January\n  \n\n    The first Replacement Drive was DOA\n  \n\n    Data Disks 5, 8 and 11 have since failed.\n  \n\n    I've been able to recover 90% of the data through the use of my backups and catching the problem in time. But seriously. 6 drives have died on me this year. And we're only half way through the year.\n  \n\n    They're dying so frequently that I can barely afford to replace them.\n  \n\n    Now. For the details.\n  \n\n    Parity Disk 2 had a physical fault of some kind. Reallocated sector counts when from 0 to 256 in one night.\n  \n\n    Parity 1 had a controller board failure (This will be a common cause. I've figured out the problem since this happened.)\n  \n\n    Data Disk 5 kicked the bucket spectacularly. The Seek Error Rate went from 85% accurate, which is the average in my server due to how many disks are in there. To 1% in the span of 3 days. Making it infuriatingly slow to get any data off the drive but still possible.\n  \n\n    Data 8 and 11 both experienced controller board failures. Strange drop outs in connection, hang ups, read and write error flags despite no data corruption either reading or writing. Obviously I couldn't trust those drives anymore.\n  \n\n    But this thing is, only 2 of these failures are genuine faults. The other 3 are my fault.\n  \n\n    The drives that had controller board failures, at least some of them, were due to how much pressure was being put on the sata connectors when I closed the side panel. Yes, I'm serious. In any other circumstance, the Define R6 would have ample room for sata power and data cables at the rear of the case. But when you have 11 drives and all their cables back there, the thickness of the noise dampening foam presses into those cables and puts dangerous amounts of pressure on the connectors.\n  \n\n    I proved this by running read checks on the \"failing drives\" with and without the side panel on. With it off, 1 drive had errors 100% of the time. With it on, all drives showed the same errors. Errors which disappeared when I removed the side panel... SMH.\n  \n\n    So now I need to replace yet more drives, the cables and the case.\n  \n\n    My server is a bottomless money pit. It has to be."},
{"Title": "New drives, questions about testing", "Author": "u/lilbud2000", "Content": "Yesterday I bought my first \"big\" refurb hard drives (2x12TB HGST drives, upgrade from a 2TB and 4TB drive).\n  \n\n    The current plan is to have one in my computer, and use the second as a backup with an external enclosure. Probably not the \"best\" way to do it, but it should suffice in the meantime.\n  \n\n    Currently waiting for them to ship and looking into the whole testing process in the meantime.\n  \n\n    I was wondering what would be the best way to test them, as I've read about a bunch of different ones (like smartctl, Badblocks, HD Sentinel, etc.) And it's making my head spin a bit.\n  \n\n    I guess my questions are as followed:\n  \n\n\n\n\n\n    What/how many tests need to be run on a refurb drive? I've seen some posts listing multiple long tests and others just saying a few SMART tests. Is there any general consensus?\n  \n\n\n\n\n\n    Badblocks is on Linux only, would that work on something like WSL? Or would I have to get a Linux machine/VM setup? I have a Pi 3 collecting dust, could that be used?\n  \n\n\n\n\n\n    How long would testing the drives take? I've seen that a full badblocks 4 pass run can take days or even a week of 24/7 running just for one drive. Does that sound right? I was thinking about using a secondary machine like my old Thinkpad if it was going to take a week. My desktop (where the drive will eventually end up) is in use daily, and I'd be a bit concerned about leaving it on but not killing the test accidentally.\n  \n\n\n\n\n\n    I'm a bit new to all this, only having a 2TB and 4TB drive for the past few years. Any help in making sense of all this would be appreciated."},
{"Title": "Ripping entire Russian Encyclopedia - viable?", "Author": "u/gulisav", "Content": "I'm not extremely tech savy, so I have some possibly silly questions.\n  \n\n    Two days ago it's been announced that Great Russian Encyclopedia has been given no funding this year at all and the encyclopedia will be discontinued. (The encyclopedia is a heir to the Great Soviet Encyclopedia, and is fairly decent as far as general encyclopedias go.) \nApparently\n Russia has bigger priorities than funding an encyclopedia... So, I think I might try my hand at saving the encyclopedia's online edition, before it 404s. Now, there are two domains, bigenc and old.bigenc (both .ru domains), and I'll focus on the latter. It seems fairly simple to rip, because each encyclopedic article has a corresponding PDF file, with the URLs only changing their final number (with 6 or 7 digits). I could produce a list of all the possible URLs in Excel. However, if I were to feed that list to a download manager, I'm wondering if that would cause any serious issues on the part of the server. There's probably close to a hundred thousand articles available on the site, and the downloader would also have to check possibly millions of URLs that contain no PDFs. Would this be like a sort of borderline DDOS attack? Could my requests be blocked?\n  \n\n    Furthermore, even if I rip all that stuff, it would result in thousands of files with nothing in particular to identify them, as the filenames are just numbers. Is there a way to derive the article titles from the text within the PDFs (which ofc include the title of the article) and rename the files accordingly?\n  \n\n    (The PDFs themselves are small in size, so I'm not worrying about space constraints.)"},
{"Title": "Safe to buy 3 yr old HDD?", "Author": "u/Shumhow", "Content": "Found a seller online selling a 1TB laptop HDD with casing for about 15 USD. Says everything is alright with the HDD, it is from Seagate and 3 years old. I have tried looking up at how old is too old for HDD but I understand there is no definite answer for the 'use'. But would it be advisable to 'buy' one which is 3 years old? I barely have any experience with this, so please do help me out! Thank you!"},
{"Title": "How many percent is recommended to free space on HDD with btrfs under GNU/Linux ?", "Author": "u/Yukinoooo", "Content": "I want my HDD to be efficient, good performance, fast, no error messages like impossible to read folders or read mode, bad sectors... If I want to use my HDD, it's for media files like photos, videos, music..."},
{"Title": "What is your preferred way to archive YouTube videos?", "Author": "u/EfficiencyFine3560", "Content": "Do you just run yt-dlp on a channel and put each channel in its own folder? Do you have a more elaborate directory strcuture? Do you use archive scripts to save stuff like comments and description? Please let me know your system!"},
{"Title": "Best way to catalogue music", "Author": "u/Foreign_Factor4011", "Content": "I know this might not be the right community to ask this question, so if the moderators need to delete this post, go ahead.\n  \n\n    I have a lot of music on my hard drive (we're talking 1000+ songs) and I'd like to organize everything into playlists.\n  \n\n    Each .mp3 file has metadata and I have software to organize playlists. I think I'll create the folder like this:\n  \n\n\nMusic/Genre/Artist/Album/.mp3 Files\n\n\n\n    Do you think there's a better way to organize it? I did some math and there would be at least 20% artists with maybe 1 music. There's another problem: some tracks aren't even part of an album. How can I improve this, if possible? Is there a better way to do it?"},
{"Title": "Dual NAS Media Backup + Plex (a bit lost)", "Author": "u/PuzzleHeadPistion", "Content": "Hi,\n  \n\n    I'm a bit lost on how to keep all my data safe.\n  \n\n    Currently I have an old desktop, i5-4690 + ASUS H97 Pro + 16Gb RAM, with 3Tb WD Red + 6Tb IronWolf + 8Tb Barracuda drives and 2.5GbE + 1GbE interfaces. This works as my Plex server and it's where I dump files from the desktop/laptop, it's running on Windows 10 for now, but about to switch to FreeBSD or TrueNAS (or Proxmox?) with ZFS pool.\nNow I've added an Asustor AS1102TL Drivestor 2 Lite (2 bays, 1GbE) which is probably being returned for an AS1104T Drivestor 4 (4 bays, 2,5GbE). It is supposed to be a remote NAS using Wireguard, that's why I didn't care for 1GbE, but the initial backup is taking a LONG time. The price difference is only 100€ for more bays and speed (useful for full copies and full restores if needed). Here there's a 6Tb WD \"white label\" and an 8Tb Barracuda as single volumes (JBOD looks risky and can't use RAID with different drives).\n  \n\n    Part of my issue is which file transfer protocol to use. NFS? My desktop and laptop are Windows, not sure NFS works properly. FTP? Or SMB? SMB is giving me speed issues, not going over 150MBps and for some reason when cloning the 6Tb IronWolf to the 6Tb WD \"white label\" the speed sinks to 10MBps. It's copying RAW photos and videos, like thousands of 50-100Mb files mostly.\n  \n\n    Having file access sorted, what's your recommendation for file transfer/backup? Asustor Backup Plan? Paragon Backup and Recovery? Macrium Reflect? Or, since I already own SyncBackPro, just use that? This question is related to both, from my computers to the main NAS and main NAS to the Asustor.\n  \n\n    A little guidance will be much appreciated, since I want to go through this once and \"forget\". My day job is IT PM so I know my way around a computer, but by far not an expert in this area. ty"},
{"Title": "What is the best way to go about cloning a 1 tb HDD with 48 bad sectors to an ssd?", "Author": "u/mudcakes2000", "Content": "I've installed aoemi backupper and ive seen there is an option to clone \"sector by sector\" however I have heard for large drives this can take hundred of hours. Will cloning the standard way work if I have some bad sectors? Or would this be detrimental? Im also not keen on doing it the sector by sector way as im worried my hard drive might fail during the long process. Does anyone have any experience with this ? Thanks"},
{"Title": "Has anyone tried a drive bigger than 16TB on an older Areca-RAID-card? (1260)", "Author": "u/flac_rules", "Content": "I have an older Areca Raid-card. The manual claims it supports very large drives with 48 bit LBA, but i also found a google cached search result from the areca site that claims the following:\n  \n\n    \"The maximum capacity of HDDs for Areca RAID controller's old version firmware supports up to 16TB capacity. From firmware version V156-20190124....\"\n  \n\n    The newest firmware for the card is older than v156, but i don't know if this quote is for a particular card or in general, I can't find a complete changelog in the site for the changelog of the card I have.\n  \n\n    So i know it is a bit of a long shot, but has anyone tried a larger than 16TB drive on a Areaca 1260-card or something of around that age? And did it work?"},
{"Title": "HBA or raid card?", "Author": "u/Deep-Egg-6167", "Content": "Hello,\n  \n\n    I'm about to build another system for my movie collection.  I currently have an adaptec 3514-16 with 16x12TB drives in RAID 5.    I'm debating about the size of the drives to get next but I'm guessing I'll get 16x16TB drives in a RAID 5.1 config but I'm not 100% sure   My collection hasn't grown that much in the last 4 years so 50TB will go a long way.\n  \n\n    I've read many debates saying just get an HBA card instead of a RAID card but I've never actually seen any performance (real world statistics) comparing the two.   I'm still open to considering either one but would appreciate anyone who can point me to some real statistics vs opinion or based on what they've heard.   Your opinion may be 100% correct but I'd love some posted benchmarks."},
{"Title": "ytarchive vs yt-dlp on video afterwards", "Author": "u/idle_cat", "Content": "On youtube, I archive livestreams of a channel. Is the live archive recording I get by using ytarchive a higher quality then the video I would get with yt-dlp that's processed afterwards? From my understanding the video goes through youtube's compression. Is the compression really strong in your opinion? I am wondering if it's worth getting the vod to save space.\n  \n\n    Side questions:\n  \n\n    Why do people put --format \"bv*+ba/b\" or something similar to get when yt-dlp already has it set to get the individual best audio and video as the default? \nhttps://github.com/yt-dlp/yt-dlp?tab=readme-ov-file#format-selection"},
{"Title": "Retire a drive after a single pending sector?", "Author": "u/Most_Mix_7505", "Content": "What would you all do?"},
{"Title": "Video and Audio URLs obtained from yt-dlp -g are downloading very slow. How to fix?", "Author": "u/CoolstarLikesHentai", "Content": "I am trying to get the original video file from a YouTube video by using the \nyt-dlp -g\n command (short for \nyt-dlp --get-url\n) to get the video URL and audio URL. I can successfully get both URLs, but when I download them it downloads very very slow (~150 kb/s). Is there any way I can speed up the download speed?"},
{"Title": "Backup my network pc's to my OMV Nas", "Author": "u/SbM_Yggdrassil", "Content": "Hi all, I'm at that part of my homelab journey where I've setup a bunch of fun stuff and now I'm starting to think about helpful stuff like backups.\n  \n\n    I have a raspberry pi 4 setup with open media vault and docker running various services. I would like to add one or more services (in containers if necessary) to accomplish the following:\n  \n\n\n\n\n\n    Make an image of bootdrives of my computers on a schedule\n  \n\n\n\n\n\n    save those images to the attached storage.\n  \n\n\n\n\n\n    reimaging solution for recovery\n  \n\n\n\n\n\n\n\n\n\n    Backup secondary, non-bootdrives of my computers (just copying is probably fine)\n  \n\n\n\n\n\n    I'm just wondering how to best add services and which would do it. If I should use syncthing/duplicati + something else or if there is one thing that can do it all. I'm not sure how incremental backups fit in here either but I'd like to implement that to reduce the burden of network traffic (in my home we have to use wi-fi a lot).\n  \n\n    For drive images I've used the free version of Macrium reflect before (and I've heard of acronis), but just on one of my windows pc's. I'd like to have something scheduled from the server side for centralised management.\n  \n\n    Does it make sense what I'm trying to achieve?"},
{"Title": "$5 worth the risk?", "Author": "u/Long_Instruction_391", "Content": "No content"},
{"Title": "Mini PC as NAS, good idea?", "Author": "u/smartyee", "Content": "No content"},
{"Title": "General Reminder Backups are Important", "Author": "u/TeamSylver", "Content": "Everyone here probably already knows that.\n  \n\n    I've just had all 3 drives in my desktop PC suddenly have problems.\n  \n\n    Thank god I can still read/write to the drives though. It's just god awful slow, especially during data transfers, where it will render the whole OS unusable until it's done.\n  \n\n    So that was a lot of pain and agony to temporarily move everything to the spare PC and laptops I have laying around (PC has 1tb, laptops have 1.5tb and 4.5tb).\n  \n\n    Means I now have no backups at all, since I still haven't finished setting up my work PC to be my off-site backup PC yet (it's basically manage/byo PC at my work BC it's such a small store).\n  \n\n    Annoying as well since that PC hosts my active directory and vaultwarden as well as the file server (thankfully I had a secondary active directory server set up, but no vaultwarden).\n  \n\n    Gotta love Crucial NVMes. All of them only 11 months old. Never again. 2 of 3 RMAs processed but I still gotta get data off of the third (OS drive) before I can post that.\n  \n\n    Edit: Forgot to mention they are Crucial P3 Plus 4TB NVMes"},
{"Title": "Dedup utility that FIRST finds duplicates by name/size/date, and THEN compares their content", "Author": "u/Msprg", "Content": "Hello,\n  \n\n    Let me preface with: I know there are a million posts about dedup tools already. Dedup by file content, checksum, attributes, similar photos, similar videos…\n  \n\n    Yet somehow, I failed to find any tools that would be able to first filter out the majority of files that differ in filename / date / size \nand\n \nthen\n on the results make sure that files are 100% surely duplicate by comparing their content.\n  \n\n    I've tried dupeguru, alldup, freefilesync, treesize, czkawka, I tried everything! (By voidtools that is).\n  \n\n    The point is that I'm either missing something, or that none of the tools offer the option I'm looking for.\n  \n\n    So here I am. Once again. Seeking answer to the eternal question: How do you deal with duplicates, fellow Data Hoarders?"},
{"Title": "What Non-NAS storage would you recommend?", "Author": "u/Bloodmoonwolf", "Content": "I currently have less than 800GB across 2 clouds and my laptop. I'm hitting my storage limit on Google and looking for a safe, local option. After losing everything on an old laptop that crashed, I started doing cloud storage, which is now becoming expensive.\n  \n\n    My current laptop is an old HP and I have yet to decide between a new Windows laptop or a Chromebook. I have a Plex library I would like to expand, even bought an external DVD reader to start the library. I don't necessarily need NAS. Plugging something into the TV or my laptop would be fine when I want to watch something on Plex (which isn't very often). The same goes for when I need to do a regular backup of files. I would prefer to buy something once instead of paying a monthly subscription and to not add another constant draw on our power supply.\n  \n\n    Most of the storage is for movies/shows, photos, and PDF scans of documents from when I went paperless. I would like to add music to this once I figure out a few things.\n  \n\n    What type/size/brand of local storage would you recommend for my situation?"},
{"Title": "Ripping dvd/blu-rays question for auto ripping? via bash script", "Author": "u/1michaelbrown", "Content": "I have setup a bash script to autorip so far it is working but with errors. So how would I fix the errors or do this a better way. Errors I am having\n  \nJun 17 20:24:15 markvm5 (udev-worker)[9984]: sr0: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:24:15 markvm5 (udev-worker)[9995]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:26:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] is taking longer than 56s to complete                                                      \nJun 17 20:26:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 is taking a long time                                                                                                     \nJun 17 20:28:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] timed out after 2min 56s, killing                                                          \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 killed                                                                                                                    \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] terminated by signal 9 (KILL).                                                                                                                   \nJun 17 20:41:49 markvm5 (udev-worker)[10159]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                   \nJun 17 20:52:38 markvm5 (udev-worker)[10201]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10205] is taking longer than 47s to complete                                                      \nJun 17 20:52:38 markvm5 systemd-udevd[467]: sr1: Worker [10201] processing SEQNUM=8077 is taking a long time Jun 17 20:24:15 markvm5 (udev-worker)[9984]: sr0: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:24:15 markvm5 (udev-worker)[9995]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:26:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] is taking longer than 56s to complete                                                      \nJun 17 20:26:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 is taking a long time                                                                                                     \nJun 17 20:28:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] timed out after 2min 56s, killing                                                          \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 killed                                                                                                                    \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] terminated by signal 9 (KILL).                                                                                                                   \nJun 17 20:41:49 markvm5 (udev-worker)[10159]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                   \nJun 17 20:52:38 markvm5 (udev-worker)[10201]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10205] is taking longer than 47s to complete                                                      \nJun 17 20:52:38 markvm5 systemd-udevd[467]: sr1: Worker [10201] processing SEQNUM=8077 is taking a long time \n\n    This is the process I used I setup a udev rule\n  \nSUBSYSTEM==\"block\", ENV{ID_CDROM}==\"1\", ACTION==\"change\", RUN+=\"/bin/systemctl start makemkv-rip.service\"SUBSYSTEM==\"block\", ENV{ID_CDROM}==\"1\", ACTION==\"change\", RUN+=\"/bin/systemctl start makemkv-rip.service\"\n\n    and the makemkv-rip.service at\n  \n/etc/systemd/system/makemkv-rip.service`/etc/systemd/system/makemkv-rip.service\n\n[Unit]                                                                                                                                                                                                           \nDescription=AutoRip CD on insertion                                                                                                                                                                              \n                                                                                                                                                                                                                 \n[Service]                                                                                                                                                                                                        \nType=oneshot                                                                                                                                                                                                     \nRemainAfterExit=no                                                                                                                                                                                               \nExecStart=/home/mike/autorip.sh                                                                                                                                                                                  \nExecStop=killall autorip.sh [Unit]                                                                                                                                                                                                           \nDescription=AutoRip CD on insertion                                                                                                                                                                              \n                                                                                                                                                                                                                 \n[Service]                                                                                                                                                                                                        \nType=oneshot                                                                                                                                                                                                     \nRemainAfterExit=no                                                                                                                                                                                               \nExecStart=/home/mike/autorip.sh                                                                                                                                                                                  \nExecStop=killall autorip.sh \n\n    It's weird because the script is working but still get these errors. Also need to figure out how to trigger encoding after rip. Also in my autorip script it is finding titles in ` TINFO` should it be finding them in CINFO."},
{"Title": "Extracting Subtitles from Patreon", "Author": "u/pinkwonderwall", "Content": "Is there a way to rip captions from Patreon videos? I'm talking about Patreon videos I already have access to through a paid subscription. I like to save a video's subtitles as a text file so I can ctrl+F search for a particular word and find the moment that topic is discussed. I've tried Chrome extensions, but none of them work with Patreon. I've also looked for other posts of people asking this question, and it seems like not many people are trying to do this lol. I searched Inspect and Page Source and didn't see any obvious solutions, but I'm inexperienced with that so I may be missing something."},
{"Title": "Exausted and burnt out due to caring for my data", "Author": "u/CreativeDog2024", "Content": "I have about 5TB of movies/tv shows/photos. I have 3 backups: one is my main frequently accessed HDD. Another is another HDD i keep in my drawer and the last is google drive.\n  \n\n    I'm not a programmer so idk how to verify whether there has been data loss but I make sure all the files on each are the same by using freefilesync (mac app). It takes so much time and I don't even know if the files are corrupted or not.\n  \n\n    Is there some cloud option that I can leave my data on and pay $10-15/month to forget about it, using it as a last resort if all my local backups are corrupted?\n  \n\n    I read quite a bit on this and people recommend backblaze (B2 I think, how do i even buy it?), AWS glacier and M-disks.\n  \n\n    I have no idea how to operate any of those because I don't code. I do use rclone for Gdrive though."},
{"Title": "Western Digital DC HC580 (CMR or SMR?) & DS923+", "Author": "u/sulicadiz", "Content": "I just bought a Western Digital DC HC580. I don't know an effective method to know if the drive is CMR or SMR. I have read here in the forum that I should buy a CMR hard drive to use with the NAS (I have a DS923+).\n  \n\n    Another question, before setting the NAS should I introduce all the drives I would be using?\nThe NAS have 4 slots, so I guess the first step would be to buy 4 hard drive then set up the unit. I suppose If I insert 2 drives then the other 2 I would lose data.\n  \n\n    Anyway, total noob here, please help"},
{"Title": "Are there some software that provides multiple download links using VPN at once?", "Author": "u/ElonTastical", "Content": "Let's say you wanna download multiple links from keep2share, but in that site it is limited by single download, you have to wait two hours before you can download another file. Is there a way to bypass this like the idea I mentioned in the title?"},
{"Title": "What's the most HDD failures you've seen in a 6 month period?", "Author": "u/the_Athereon", "Content": "Genuine question. How many of you have had a year as bad as mine so far?\n  \n\n    5 failures. 1 DOA\n  \n\n    Parity 1 and 2 went in January\n  \n\n    The first Replacement Drive was DOA\n  \n\n    Data Disks 5, 8 and 11 have since failed.\n  \n\n    I've been able to recover 90% of the data through the use of my backups and catching the problem in time. But seriously. 6 drives have died on me this year. And we're only half way through the year.\n  \n\n    They're dying so frequently that I can barely afford to replace them.\n  \n\n    Now. For the details.\n  \n\n    Parity Disk 2 had a physical fault of some kind. Reallocated sector counts when from 0 to 256 in one night.\n  \n\n    Parity 1 had a controller board failure (This will be a common cause. I've figured out the problem since this happened.)\n  \n\n    Data Disk 5 kicked the bucket spectacularly. The Seek Error Rate went from 85% accurate, which is the average in my server due to how many disks are in there. To 1% in the span of 3 days. Making it infuriatingly slow to get any data off the drive but still possible.\n  \n\n    Data 8 and 11 both experienced controller board failures. Strange drop outs in connection, hang ups, read and write error flags despite no data corruption either reading or writing. Obviously I couldn't trust those drives anymore.\n  \n\n    But this thing is, only 2 of these failures are genuine faults. The other 3 are my fault.\n  \n\n    The drives that had controller board failures, at least some of them, were due to how much pressure was being put on the sata connectors when I closed the side panel. Yes, I'm serious. In any other circumstance, the Define R6 would have ample room for sata power and data cables at the rear of the case. But when you have 11 drives and all their cables back there, the thickness of the noise dampening foam presses into those cables and puts dangerous amounts of pressure on the connectors.\n  \n\n    I proved this by running read checks on the \"failing drives\" with and without the side panel on. With it off, 1 drive had errors 100% of the time. With it on, all drives showed the same errors. Errors which disappeared when I removed the side panel... SMH.\n  \n\n    So now I need to replace yet more drives, the cables and the case.\n  \n\n    My server is a bottomless money pit. It has to be."},
{"Title": "New drives, questions about testing", "Author": "u/lilbud2000", "Content": "Yesterday I bought my first \"big\" refurb hard drives (2x12TB HGST drives, upgrade from a 2TB and 4TB drive).\n  \n\n    The current plan is to have one in my computer, and use the second as a backup with an external enclosure. Probably not the \"best\" way to do it, but it should suffice in the meantime.\n  \n\n    Currently waiting for them to ship and looking into the whole testing process in the meantime.\n  \n\n    I was wondering what would be the best way to test them, as I've read about a bunch of different ones (like smartctl, Badblocks, HD Sentinel, etc.) And it's making my head spin a bit.\n  \n\n    I guess my questions are as followed:\n  \n\n\n\n\n\n    What/how many tests need to be run on a refurb drive? I've seen some posts listing multiple long tests and others just saying a few SMART tests. Is there any general consensus?\n  \n\n\n\n\n\n    Badblocks is on Linux only, would that work on something like WSL? Or would I have to get a Linux machine/VM setup? I have a Pi 3 collecting dust, could that be used?\n  \n\n\n\n\n\n    How long would testing the drives take? I've seen that a full badblocks 4 pass run can take days or even a week of 24/7 running just for one drive. Does that sound right? I was thinking about using a secondary machine like my old Thinkpad if it was going to take a week. My desktop (where the drive will eventually end up) is in use daily, and I'd be a bit concerned about leaving it on but not killing the test accidentally.\n  \n\n\n\n\n\n    I'm a bit new to all this, only having a 2TB and 4TB drive for the past few years. Any help in making sense of all this would be appreciated."},
{"Title": "Ripping entire Russian Encyclopedia - viable?", "Author": "u/gulisav", "Content": "I'm not extremely tech savy, so I have some possibly silly questions.\n  \n\n    Two days ago it's been announced that Great Russian Encyclopedia has been given no funding this year at all and the encyclopedia will be discontinued. (The encyclopedia is a heir to the Great Soviet Encyclopedia, and is fairly decent as far as general encyclopedias go.) \nApparently\n Russia has bigger priorities than funding an encyclopedia... So, I think I might try my hand at saving the encyclopedia's online edition, before it 404s. Now, there are two domains, bigenc and old.bigenc (both .ru domains), and I'll focus on the latter. It seems fairly simple to rip, because each encyclopedic article has a corresponding PDF file, with the URLs only changing their final number (with 6 or 7 digits). I could produce a list of all the possible URLs in Excel. However, if I were to feed that list to a download manager, I'm wondering if that would cause any serious issues on the part of the server. There's probably close to a hundred thousand articles available on the site, and the downloader would also have to check possibly millions of URLs that contain no PDFs. Would this be like a sort of borderline DDOS attack? Could my requests be blocked?\n  \n\n    Furthermore, even if I rip all that stuff, it would result in thousands of files with nothing in particular to identify them, as the filenames are just numbers. Is there a way to derive the article titles from the text within the PDFs (which ofc include the title of the article) and rename the files accordingly?\n  \n\n    (The PDFs themselves are small in size, so I'm not worrying about space constraints.)"},
{"Title": "Safe to buy 3 yr old HDD?", "Author": "u/Shumhow", "Content": "Found a seller online selling a 1TB laptop HDD with casing for about 15 USD. Says everything is alright with the HDD, it is from Seagate and 3 years old. I have tried looking up at how old is too old for HDD but I understand there is no definite answer for the 'use'. But would it be advisable to 'buy' one which is 3 years old? I barely have any experience with this, so please do help me out! Thank you!"},
{"Title": "How many percent is recommended to free space on HDD with btrfs under GNU/Linux ?", "Author": "u/Yukinoooo", "Content": "I want my HDD to be efficient, good performance, fast, no error messages like impossible to read folders or read mode, bad sectors... If I want to use my HDD, it's for media files like photos, videos, music..."},
{"Title": "What is your preferred way to archive YouTube videos?", "Author": "u/EfficiencyFine3560", "Content": "Do you just run yt-dlp on a channel and put each channel in its own folder? Do you have a more elaborate directory strcuture? Do you use archive scripts to save stuff like comments and description? Please let me know your system!"},
{"Title": "Best way to catalogue music", "Author": "u/Foreign_Factor4011", "Content": "I know this might not be the right community to ask this question, so if the moderators need to delete this post, go ahead.\n  \n\n    I have a lot of music on my hard drive (we're talking 1000+ songs) and I'd like to organize everything into playlists.\n  \n\n    Each .mp3 file has metadata and I have software to organize playlists. I think I'll create the folder like this:\n  \n\n\nMusic/Genre/Artist/Album/.mp3 Files\n\n\n\n    Do you think there's a better way to organize it? I did some math and there would be at least 20% artists with maybe 1 music. There's another problem: some tracks aren't even part of an album. How can I improve this, if possible? Is there a better way to do it?"},
{"Title": "Dual NAS Media Backup + Plex (a bit lost)", "Author": "u/PuzzleHeadPistion", "Content": "Hi,\n  \n\n    I'm a bit lost on how to keep all my data safe.\n  \n\n    Currently I have an old desktop, i5-4690 + ASUS H97 Pro + 16Gb RAM, with 3Tb WD Red + 6Tb IronWolf + 8Tb Barracuda drives and 2.5GbE + 1GbE interfaces. This works as my Plex server and it's where I dump files from the desktop/laptop, it's running on Windows 10 for now, but about to switch to FreeBSD or TrueNAS (or Proxmox?) with ZFS pool.\nNow I've added an Asustor AS1102TL Drivestor 2 Lite (2 bays, 1GbE) which is probably being returned for an AS1104T Drivestor 4 (4 bays, 2,5GbE). It is supposed to be a remote NAS using Wireguard, that's why I didn't care for 1GbE, but the initial backup is taking a LONG time. The price difference is only 100€ for more bays and speed (useful for full copies and full restores if needed). Here there's a 6Tb WD \"white label\" and an 8Tb Barracuda as single volumes (JBOD looks risky and can't use RAID with different drives).\n  \n\n    Part of my issue is which file transfer protocol to use. NFS? My desktop and laptop are Windows, not sure NFS works properly. FTP? Or SMB? SMB is giving me speed issues, not going over 150MBps and for some reason when cloning the 6Tb IronWolf to the 6Tb WD \"white label\" the speed sinks to 10MBps. It's copying RAW photos and videos, like thousands of 50-100Mb files mostly.\n  \n\n    Having file access sorted, what's your recommendation for file transfer/backup? Asustor Backup Plan? Paragon Backup and Recovery? Macrium Reflect? Or, since I already own SyncBackPro, just use that? This question is related to both, from my computers to the main NAS and main NAS to the Asustor.\n  \n\n    A little guidance will be much appreciated, since I want to go through this once and \"forget\". My day job is IT PM so I know my way around a computer, but by far not an expert in this area. ty"},
{"Title": "What is the best way to go about cloning a 1 tb HDD with 48 bad sectors to an ssd?", "Author": "u/mudcakes2000", "Content": "I've installed aoemi backupper and ive seen there is an option to clone \"sector by sector\" however I have heard for large drives this can take hundred of hours. Will cloning the standard way work if I have some bad sectors? Or would this be detrimental? Im also not keen on doing it the sector by sector way as im worried my hard drive might fail during the long process. Does anyone have any experience with this ? Thanks"},
{"Title": "Has anyone tried a drive bigger than 16TB on an older Areca-RAID-card? (1260)", "Author": "u/flac_rules", "Content": "I have an older Areca Raid-card. The manual claims it supports very large drives with 48 bit LBA, but i also found a google cached search result from the areca site that claims the following:\n  \n\n    \"The maximum capacity of HDDs for Areca RAID controller's old version firmware supports up to 16TB capacity. From firmware version V156-20190124....\"\n  \n\n    The newest firmware for the card is older than v156, but i don't know if this quote is for a particular card or in general, I can't find a complete changelog in the site for the changelog of the card I have.\n  \n\n    So i know it is a bit of a long shot, but has anyone tried a larger than 16TB drive on a Areaca 1260-card or something of around that age? And did it work?"},
{"Title": "HBA or raid card?", "Author": "u/Deep-Egg-6167", "Content": "Hello,\n  \n\n    I'm about to build another system for my movie collection.  I currently have an adaptec 3514-16 with 16x12TB drives in RAID 5.    I'm debating about the size of the drives to get next but I'm guessing I'll get 16x16TB drives in a RAID 5.1 config but I'm not 100% sure   My collection hasn't grown that much in the last 4 years so 50TB will go a long way.\n  \n\n    I've read many debates saying just get an HBA card instead of a RAID card but I've never actually seen any performance (real world statistics) comparing the two.   I'm still open to considering either one but would appreciate anyone who can point me to some real statistics vs opinion or based on what they've heard.   Your opinion may be 100% correct but I'd love some posted benchmarks."},
{"Title": "When are 30TB Seagate drives expected to become broadly a available?", "Author": "u/coffeenerd_", "Content": "Knowing that they've completed pilot tests a long time ago, are being deployed commercially, and getting mass produced...\n  \n\n    Wondering when would these 30TB Seagate drives become broadly available for us folks?\n  \n\n    Any have any real information or seeing any listings across any retailers / wholesalers?"},
{"Title": "YouTube files changed", "Author": "u/clickyk2019", "Content": "I've redownloaded some videos from youtube with yt-dlp (same videos, same yt-dlp options) however when comparing (diff) the files downloaded 6 months ago with the current ones some, but not all, are different. In some cases the new size is almost half of the previous one.\n  \n\n    Does anyone knows if youtube re-encode or modify videos periodically?"},
{"Title": "Advice on a crazy idea", "Author": "u/Arcau1", "Content": "I have seen a little N100 board with a 4x NVME hat on ali express (also comes in a N305 version)\n  \n\n    I was wondering if it was possible to maybe use the nvme > 6 sata riser cards ive seen also.\n  \n\n    So turning this into a little 24 drive beast of a nas,\n  \n\n    So brain trust of the community i ask you:\n  \n\n    Is this even possible?\n  \n\n    Would it cripple the N100?\n  \n\n    Would the speeds on the disks be just stupid slow?\n  \n\n    Has anyone tried something like this already and have any words of wisdom?\n  \n\n    TIA"},
{"Title": "Have joined the club", "Author": "u/mdwkelly", "Content": "Good day all.\n  \n\n    Well I have joined the club and am now the proud owner of a Supermicro 45 Bay JBOD Expansion Server Shelf 847E16-RJBOD1 with ~30 drives and ~460TB. Currently have it hooked up via 2 SFF-8088 to SFF-8088 cables to a LSI 9201-16e 6Gbps 16-lane external SAS HBA installed in my \"server\".\n  \n\n    This is replacing my previous setup with the same \"server\", 2 x LSI 9201-16e 6Gbps 16-lane external SAS HBA cards with 8 x SFF-8088 to 4 SATA cables running to 8 x RSV-SATA-Cage-34 that are/were on a couple of shelves.\n  \n\n    Been up and running for about a week and thoughts so far are:\n  \n\n\n\n\n\n    It looks cool in the 4-post 42U rack\n  \n\n\n\n\n\n    It is loud! (I knew it was loud but that holy s#$% moment when you first power it up)\n  \n\n\n\n\n\n    snapraid backup/scrub is only happening at about 2/3 the speed of before (sort of knew this as well)\n  \n\n\n\n\n\n    that was a lot of screws to remove the drives from the RSV caddies and screw them into the JBOD caddies.\n  \n\n\n\n\n\n    It looks cool!\n  \n\n\n\n\n\n    As mentioned, I have it hooked up via 2 SFF-8088 to SFF-8088 cables, one for each backplane, and am wondering if I can hook up the other 2 SFF-8088 ports on the JBOD with two more cables to get some additional speed. I did read the manual it it discusses the other two ports are used for daisy-chaining but you never know.\n  \n\n    Not being one to let well enough alone, I am now on the journey to repackage my two \"servers\", one from above and the other used for acquiring linux ISO's, into a couple of 2U cases so I can get them nicely into the rack.\n  \n\n    For the latter, am thinking about a \nRackChoice MicroATX/Mini-ITX 2U Rackmount Server Chassis\n as I am running a mitx MB and a couple of 3.5 drives and a couple of SSD's with no add-on cards so should fit just nice.\n  \n\n    For the former, the \"server\" hooked to the JBOD, I am looking at this \nRackChoice 2U Rackmount Server Chassis\n as it allows full height cards to be used via PCI riser so I can keep using the HBA card I already have. The other option I am looking at is picking up a LSI SAS 9300-8e 12Gb/s SATA/SAS and a couple SFF-8644 to Mini SAS SFF-8088 cables and a 2nd \nRackChoice MicroATX/Mini-ITX 2U Rackmount Server Chassis\n but I am not sure if the SAS3 HBA is backwards compatible with SAS2 backplanes.\n  \n\n    Anyway, the adventure continues ....\n  \n\n    Thanks"},
{"Title": "Android RClone app mounts remote drives with random seek support", "Author": "u/fourDnet", "Content": "Found this nifty tool recently:\nRSAF - An Android Storage Access Framework document provider for rclone\n\n\n\n    Based on rclone 1.67 (latest version). First app that I've seen for android that supports mounting arbitrary remote drives (google drive, WebDAV, SFTP) and supports streaming.\n  \n\n\nHad to manually add it to the battery optimization exclusion list on a OnePlus device (like in 3 different places, for background running, Optimize Battery Use etc.), or it would lose connection.\n\n\n\n    But after adding it to the battery exclusion list, I could reach over 280 megabits/s streaming 4K HDR video from a local linux machine!\n  \n\n    Basically added a config for WebDAV (or SFTP), added an alias to go to the specific folder, and opened that folder within the app. Was able to stream using VLC 4K HDR with very rare stutters via the local wifi."},
{"Title": "How do you keep maxview storage manager open?", "Author": "u/Deep-Egg-6167", "Content": "Hello,\n  \n\n    I like to check when a raid is building (takes a couple of days) what percent it is at.  It logs out every 15 minutes or so - any guess how to leave it logged in?"},
{"Title": "Archiving Steam games that natively do not have DRM?", "Author": "u/Gwyn777", "Content": "Hello!\n  \n\n    I recently bought Cruelty Squad from steam. It is DRM free from the get go.\n  \n\n    What files do I need to save to archive the game?\n  \n\n    Something where I could theoretically uninstall steam, download it from my storage, then play without steam.\n  \n\n    Thank you for any help!"},
{"Title": "can anyone tell if this is molded or crimped molex to sata cable?", "Author": "u/KhanhEVB", "Content": "No content"},
{"Title": "Adobe Document Cloud help", "Author": "u/MatooMan", "Content": "Looking to download local copies to my PC from the following publications, anyone able to help me find an automated way to do this? An add on or program ideally.\n  \n\n    Thanks\n  \n\n\nhttps://archives.thepipingcentre.co.uk/publications"},
{"Title": "Compression", "Author": "u/Void-ux", "Content": "Hey, I store a relatively small amount of media (movies and tv), and some of it I likely won't watch for decades.\nMost of it is 1080p, and I keep my fav latest TV shows in 4k. Is there any way to losslessly compress this media? From what I've heard 1080p is best in h.264, which it is. The 4k stuff could be converted to h.265 10-bit, and I have done this with HandBrake, but I'm skeptical of how lossless it is since the file size reductions are ridiculous efficient."},
{"Title": "Would you return this dented 16TB hard drive?", "Author": "u/P10tr3kkk", "Content": "No content"},
{"Title": "Power Disable HDD in QNAP NAS", "Author": "u/CartoonistNo6669", "Content": "I've not gotten either yet, but I'm struggling to figure out of this is compatible.\n  \n\n    I'm planning on getting a TS-435XeU (\nhttps://www.qnap.com/en-us/product/ts-435xeu#\n)\n  \n\n    And filling it with 4x 10TB renewed Ultrastar He10 HDD (\nhttps://a.co/d/8EcBiGu\n) in RAID5.\n  \n\n    I see that these hard drives have Power Disable, and I can't find a concrete indication on QNAP's website if the NAS supports those.\n  \n\n    Any advice here?"},
{"Title": "Ripping dubs from dvd and adding to movies", "Author": "u/Wibble_Webble", "Content": "Hi, i want to start a project but i have no idea where to start. I have a barbie movie collection that has dubs in my native language. I found that someone has remastered these movies in HD and i have already downloaded them. The movies are however in English. I want to rip the audio track from the dvd's but just of the main movie and replace the original audio track from the remastered movies. I've already tried to rip the movie with handbreak but the mp4 file came out choppy in image and in audio. I also don't know how to replace the original audio track once i have successfully  ripped the audio from the dvd as well as sync it. I've read about using ffmpeg but i have no experience with it except for yt-dlp. If anyone can provide an incredibly dumbed down explanation, i would really appreciate it."},
{"Title": "VHS to HDMI upscaller", "Author": "u/Point-Frosty", "Content": "Hey yall! Looking for recommendations on a box that will convert composite coming from my vcr to hdmi. I would like to upscale to 1080.\n  \n\n    I am dealing with old vhs tapes that get snowy at times. I did purchase a Kanex Pro $80 unit and it does pretty good upscaling and interlacing. Unfortunately with my snowy tapes, the unit flashes a big source menu on the screen when snow happens.\n  \n\n    Does anyone know of a 1080 upscaller that won’t flash menu’s on the screen during my capture to OBS? Thanks so much for the advice!"},
{"Title": "VHS to DVD/Digital", "Author": "u/Djinnimania", "Content": "For context, I dropped the ball recently by forgetting both Mother’s Day and Father’s Day until the day of. They don’t seem upset, but I want to make it up to them by converting their wedding videos from VHS to either digital, DVD, or Blu-Ray. What would be the best way to do so?"},
{"Title": "External, internal hard drives", "Author": "u/WriteCodeBroh", "Content": "Let’s say a friend of mine was thinking about, hypothetically of course, buying a used workstation off of Facebook marketplace. And a lot of those modern used workstations don’t have a whole lot of space for hard drives.\n  \n\n    What if this friend drilled a hole in the side of the case, ran the required power and data cables (SATA probably) out to a custom built case with a backplane and a whole bunch of hard drives?\n  \n\n    I assume there are EMI and short related risks but frankly I’ve seen people run whole computers on open wooden racks with fans blowing on the components, function just fine for years, also don’t plan to touch/move things much and they’ll be off the floor and out of the way.\n  \n\n    So anyway, all that being said, how stupid of an idea is this?"},
{"Title": "files taking too much space in external hard drive?", "Author": "u/Tikas92", "Content": "Hello everyone. I have a question and I was wondering if anyone knows what's up with that. I recently transfered 3,53 TB worth of files from a 4TB Seagate to an 8TB Lacie but for some reason those files now take up 4,46 TB on the new drive. Why is that happening?"},
{"Title": "Getting a bit lost when it comes to good syncing/cloud storage options", "Author": "u/Creator13", "Content": "After using a laptop for the past six years and carrying it everywhere, I recently got a good desktop PC again. I've always played it super risky because all my data has never been properly backed up or duplicated. Now I want my files to be available between different (windows) computers. Ideally, every change would automatically get synced between both computers, through a cloud storage provider (that also stores the files for access from outside), as long as either computer is connected to the internet.\n  \n\n    Now, plenty of services offer this, in its most basic form. I get 1TB OneDrive though my parents' family plan and OneDrive is pretty nice. It integrates well enough into Windows. But there is one major limitation that makes it pretty much unsuitable for me: I don't want all my syncable data to be in one single folder. I want it spread out over different folders and even drives, because I run quite a few different drives with different purposes.\n  \n\n    Is there a service that basically offers a way to set custom endpoints for syncable folders? Say I have a cloud folder \n/Files\n, then I want a client that runs on any connected computer where I can set \n/Files\n to be synced to \nG:\\Files\n, or to \nC:\\Users\\some_user\\Documents\\CloudFiles\n on another computer?\n  \n\n    Ideally also affordable and reputable/secure of course, and for single individual users?"},
{"Title": "I have nearly 30 TB on external hard drives I want to find a permanent solution to keep my data as i continue increase the amount", "Author": "u/romic007", "Content": "Like the title states i have nearly 30 TB on several external hard drives. The files vary from (videos, fILms, series, pictures, music, documents, etc.) i looking for a permanent solution to keep my data as it continues to grow.\n  \n\n    I am not very tech savy at all\n  \n\n    I have seen things about nas, Synology stuff but im not too familiar with that stuff.\n  \n\n    I have heard good things about icloud but im i bit worried since my files were LEGALLY downloaded. Im worried that they could look at my stuff.\n  \n\n    I use my external hard drives daily and would like this permanent solution to be accessible whenever and wherever i am.\n  \n\n    I use my external hard drives on. My laptop via usb port and do not have a pc.\n  \n\n    I am leaning towards icloud or something equivalent to that since i wouldn't have to use external hard drives as much as i currently am now.\n  \n\n    Im planning on using this as my main backup system with external hard drives as secondary but like i said i use these hard drives daily would icloud be the best solution for my situation?"},
{"Title": "Data Compression", "Author": "u/elgato123", "Content": "Noticed that a drive was filling up, saw it was mostly log files...49Gb of log files. Broke out the ol' 7-zip and in ultra mode, it compressed it down to 1.8Gb. Wow\n  \n\n    I am wondering if there is any better compression or if this is about as good as it will get? Either way, I'm very impressed"},
{"Title": "New Build raid/filesystem recommendations", "Author": "u/NextRedditAccount0", "Content": "I have a new HL15 coming. I'm planning to use it for some docker for *arr, deluge, and as a NAS. I have a separate Plex server that will be accessing the files on the HL15. No plans of doing any VMs. I'm trying to figure out the best way to get good performance and some parity in case a drive fails. Yes I do have plenty of backups.\nMy current drives in my synology is 8x8TB, 1x 500GB SSD, 1x 1TB SSD in SHR2. I also have 3x 16TB drives coming.\n  \n\n    My original plan was to run unraid but I don't want to lose out on performance due to the 8x8TB are all 5400rpms.\nI'm open to running unraid or truenas or proxmox or etc. My end goal is to get as much speed as possible while being able to survive a drive failure. No future drive expansion is planned ATM but would be nice if the new solution could support it.\nAlso this will be on a 10gbps network.\n  \n\n    Thoughts?"},
{"Title": "Question re: drives in a RAID array I inherited from a relative", "Author": "u/RhetoricalAnswer-001", "Content": "Hope this is appropriate for the forum.\n  \n\n    I inherited a full height rackmount cabinet with 12 HDs. It looks like it belongs in a data center.\n  \n\n    I want to use the drives but my PC won't recognize them. Any tips on software that can \"see\" them, then wipe and reformat them?"},
{"Title": "Internet Archive Forced to Remove 500,000 books Due to Copyright Lawsuit", "Author": "u/Run_the_Line", "Content": "No content"},
{"Title": "How long for an SSD to do it's business after a long stint in cold storage?", "Author": "u/Captain_Starkiller", "Content": "I'm firing up a computer after it was offline for nearly two years. It's SSD is just a windows drive, the data storage drives are spinning rust. That said, I want to make sure the error protection has a chance to do its thing for the SSD, refill the charge traps so bit rot doesn't set in, ect. Does anyone have any idea how long I should let it run for, before turning it off again (for a month or two this time, not years) to make sure it does it's business?"},
{"Title": "Advice/Recommendation on a Personal Desktop Build with a focus on Data Storage that can also be used as a small homeserver for myself.", "Author": "u/curiousdoggo", "Content": "Goal:\n  \n\n    I know people typically separate their data storage/server/nas from their personal desktop so it can be left to do its designated tasks and so that it won't affect the performance of the desktop (if it has to serve a multitude of people or perform a lot of different tasks), but what if my server/nas needs are minimal and my primary focus is just a good personal desktop with a focus on datahoarding/data storage, some file sharing, running a few VMs, and possibly a few more server features? In this case, is it okay to just build a decently powerful modern personal desktop - killing 2 birds with 1 s tone, instead of building 2 computers, one for desktop (desperately need the upgrade now) and one specifically for a server/nas? Is this totally okay?\n  \n\n    I live by myself so aside from being a personal computer with data storage, it'll just be serving me alone at home. To be honest, at the moment, I pretty much just consume media on my desktop, so even nas/media server features like plex, jellyfins aren't even 100% necessary - though nice to have perhaps in the future.\n  \n\n\nSummary\n: Decently powerful personal desktop with a focus on datahoarding/data storage that can also perform some server side of things like running VMs, and other homelab things down the road.\n  \n\n\nOS\n: FreeBSD with ZFS + ECC Memory\n  \n\n\nCASE\n: thinking of a big case like Fractal Design Define 7 XL that is capable of holding 14-18 HDDs.\n  \n\n\nMOBO\n:\n  \n\n\nSSD\n: What's a good NVMe 2.0 ?(maybe 1TB)\n  \n\n\nCPU\n: amd or intel? what series/models would you guys recommend?\n  \n\n\nMEM\n: looking for ECC ram as the main focus will be data storage. but how much memory will I need for zfs (assuming I will fill up the whole case with 18 HDDs down the road)?\n  \n\n\nGPU\n: a gpu capable of driving maybe a LG DualUp 2560 x 2880 with a 34\" 1440p 3440×1440 ultrawide monitor. I will also be doing some photo editing with darktable, rawtherapee, etc. as well so a designated gpu that is good enough should be enough. (don't think there will be much gaming).\n  \n\n\nPSU\n: how big of a power supply? keep in mind the full capacity is 18 HDD, with dual monitor, etc.\n  \n\n\nCPU COOLER\n:\n  \n\n\nHDD\n: thinking of 18 or 20TB seagate exos (are they too loud to use in the bedroom in a personal desktop? should i go for ironwolf pro?)"},
{"Title": "When are 30TB Seagate drives expected to become broadly a available?", "Author": "u/coffeenerd_", "Content": "Knowing that they've completed pilot tests a long time ago, are being deployed commercially, and getting mass produced...\n  \n\n    Wondering when would these 30TB Seagate drives become broadly available for us folks?\n  \n\n    Any have any real information or seeing any listings across any retailers / wholesalers?"},
{"Title": "YouTube files changed", "Author": "u/clickyk2019", "Content": "I've redownloaded some videos from youtube with yt-dlp (same videos, same yt-dlp options) however when comparing (diff) the files downloaded 6 months ago with the current ones some, but not all, are different. In some cases the new size is almost half of the previous one.\n  \n\n    Does anyone knows if youtube re-encode or modify videos periodically?"},
{"Title": "Advice on a crazy idea", "Author": "u/Arcau1", "Content": "I have seen a little N100 board with a 4x NVME hat on ali express (also comes in a N305 version)\n  \n\n    I was wondering if it was possible to maybe use the nvme > 6 sata riser cards ive seen also.\n  \n\n    So turning this into a little 24 drive beast of a nas,\n  \n\n    So brain trust of the community i ask you:\n  \n\n    Is this even possible?\n  \n\n    Would it cripple the N100?\n  \n\n    Would the speeds on the disks be just stupid slow?\n  \n\n    Has anyone tried something like this already and have any words of wisdom?\n  \n\n    TIA"},
{"Title": "Have joined the club", "Author": "u/mdwkelly", "Content": "Good day all.\n  \n\n    Well I have joined the club and am now the proud owner of a Supermicro 45 Bay JBOD Expansion Server Shelf 847E16-RJBOD1 with ~30 drives and ~460TB. Currently have it hooked up via 2 SFF-8088 to SFF-8088 cables to a LSI 9201-16e 6Gbps 16-lane external SAS HBA installed in my \"server\".\n  \n\n    This is replacing my previous setup with the same \"server\", 2 x LSI 9201-16e 6Gbps 16-lane external SAS HBA cards with 8 x SFF-8088 to 4 SATA cables running to 8 x RSV-SATA-Cage-34 that are/were on a couple of shelves.\n  \n\n    Been up and running for about a week and thoughts so far are:\n  \n\n\n\n\n\n    It looks cool in the 4-post 42U rack\n  \n\n\n\n\n\n    It is loud! (I knew it was loud but that holy s#$% moment when you first power it up)\n  \n\n\n\n\n\n    snapraid backup/scrub is only happening at about 2/3 the speed of before (sort of knew this as well)\n  \n\n\n\n\n\n    that was a lot of screws to remove the drives from the RSV caddies and screw them into the JBOD caddies.\n  \n\n\n\n\n\n    It looks cool!\n  \n\n\n\n\n\n    As mentioned, I have it hooked up via 2 SFF-8088 to SFF-8088 cables, one for each backplane, and am wondering if I can hook up the other 2 SFF-8088 ports on the JBOD with two more cables to get some additional speed. I did read the manual it it discusses the other two ports are used for daisy-chaining but you never know.\n  \n\n    Not being one to let well enough alone, I am now on the journey to repackage my two \"servers\", one from above and the other used for acquiring linux ISO's, into a couple of 2U cases so I can get them nicely into the rack.\n  \n\n    For the latter, am thinking about a \nRackChoice MicroATX/Mini-ITX 2U Rackmount Server Chassis\n as I am running a mitx MB and a couple of 3.5 drives and a couple of SSD's with no add-on cards so should fit just nice.\n  \n\n    For the former, the \"server\" hooked to the JBOD, I am looking at this \nRackChoice 2U Rackmount Server Chassis\n as it allows full height cards to be used via PCI riser so I can keep using the HBA card I already have. The other option I am looking at is picking up a LSI SAS 9300-8e 12Gb/s SATA/SAS and a couple SFF-8644 to Mini SAS SFF-8088 cables and a 2nd \nRackChoice MicroATX/Mini-ITX 2U Rackmount Server Chassis\n but I am not sure if the SAS3 HBA is backwards compatible with SAS2 backplanes.\n  \n\n    Anyway, the adventure continues ....\n  \n\n    Thanks"},
{"Title": "Android RClone app mounts remote drives with random seek support", "Author": "u/fourDnet", "Content": "Found this nifty tool recently:\nRSAF - An Android Storage Access Framework document provider for rclone\n\n\n\n    Based on rclone 1.67 (latest version). First app that I've seen for android that supports mounting arbitrary remote drives (google drive, WebDAV, SFTP) and supports streaming.\n  \n\n\nHad to manually add it to the battery optimization exclusion list on a OnePlus device (like in 3 different places, for background running, Optimize Battery Use etc.), or it would lose connection.\n\n\n\n    But after adding it to the battery exclusion list, I could reach over 280 megabits/s streaming 4K HDR video from a local linux machine!\n  \n\n    Basically added a config for WebDAV (or SFTP), added an alias to go to the specific folder, and opened that folder within the app. Was able to stream using VLC 4K HDR with very rare stutters via the local wifi."},
{"Title": "How do you keep maxview storage manager open?", "Author": "u/Deep-Egg-6167", "Content": "Hello,\n  \n\n    I like to check when a raid is building (takes a couple of days) what percent it is at.  It logs out every 15 minutes or so - any guess how to leave it logged in?"},
{"Title": "Archiving Steam games that natively do not have DRM?", "Author": "u/Gwyn777", "Content": "Hello!\n  \n\n    I recently bought Cruelty Squad from steam. It is DRM free from the get go.\n  \n\n    What files do I need to save to archive the game?\n  \n\n    Something where I could theoretically uninstall steam, download it from my storage, then play without steam.\n  \n\n    Thank you for any help!"},
{"Title": "can anyone tell if this is molded or crimped molex to sata cable?", "Author": "u/KhanhEVB", "Content": "No content"},
{"Title": "Adobe Document Cloud help", "Author": "u/MatooMan", "Content": "Looking to download local copies to my PC from the following publications, anyone able to help me find an automated way to do this? An add on or program ideally.\n  \n\n    Thanks\n  \n\n\nhttps://archives.thepipingcentre.co.uk/publications"},
{"Title": "Compression", "Author": "u/Void-ux", "Content": "Hey, I store a relatively small amount of media (movies and tv), and some of it I likely won't watch for decades.\nMost of it is 1080p, and I keep my fav latest TV shows in 4k. Is there any way to losslessly compress this media? From what I've heard 1080p is best in h.264, which it is. The 4k stuff could be converted to h.265 10-bit, and I have done this with HandBrake, but I'm skeptical of how lossless it is since the file size reductions are ridiculous efficient."},
{"Title": "Would you return this dented 16TB hard drive?", "Author": "u/P10tr3kkk", "Content": "No content"},
{"Title": "Power Disable HDD in QNAP NAS", "Author": "u/CartoonistNo6669", "Content": "I've not gotten either yet, but I'm struggling to figure out of this is compatible.\n  \n\n    I'm planning on getting a TS-435XeU (\nhttps://www.qnap.com/en-us/product/ts-435xeu#\n)\n  \n\n    And filling it with 4x 10TB renewed Ultrastar He10 HDD (\nhttps://a.co/d/8EcBiGu\n) in RAID5.\n  \n\n    I see that these hard drives have Power Disable, and I can't find a concrete indication on QNAP's website if the NAS supports those.\n  \n\n    Any advice here?"},
{"Title": "Ripping dubs from dvd and adding to movies", "Author": "u/Wibble_Webble", "Content": "Hi, i want to start a project but i have no idea where to start. I have a barbie movie collection that has dubs in my native language. I found that someone has remastered these movies in HD and i have already downloaded them. The movies are however in English. I want to rip the audio track from the dvd's but just of the main movie and replace the original audio track from the remastered movies. I've already tried to rip the movie with handbreak but the mp4 file came out choppy in image and in audio. I also don't know how to replace the original audio track once i have successfully  ripped the audio from the dvd as well as sync it. I've read about using ffmpeg but i have no experience with it except for yt-dlp. If anyone can provide an incredibly dumbed down explanation, i would really appreciate it."},
{"Title": "VHS to HDMI upscaller", "Author": "u/Point-Frosty", "Content": "Hey yall! Looking for recommendations on a box that will convert composite coming from my vcr to hdmi. I would like to upscale to 1080.\n  \n\n    I am dealing with old vhs tapes that get snowy at times. I did purchase a Kanex Pro $80 unit and it does pretty good upscaling and interlacing. Unfortunately with my snowy tapes, the unit flashes a big source menu on the screen when snow happens.\n  \n\n    Does anyone know of a 1080 upscaller that won’t flash menu’s on the screen during my capture to OBS? Thanks so much for the advice!"},
{"Title": "VHS to DVD/Digital", "Author": "u/Djinnimania", "Content": "For context, I dropped the ball recently by forgetting both Mother’s Day and Father’s Day until the day of. They don’t seem upset, but I want to make it up to them by converting their wedding videos from VHS to either digital, DVD, or Blu-Ray. What would be the best way to do so?"},
{"Title": "External, internal hard drives", "Author": "u/WriteCodeBroh", "Content": "Let’s say a friend of mine was thinking about, hypothetically of course, buying a used workstation off of Facebook marketplace. And a lot of those modern used workstations don’t have a whole lot of space for hard drives.\n  \n\n    What if this friend drilled a hole in the side of the case, ran the required power and data cables (SATA probably) out to a custom built case with a backplane and a whole bunch of hard drives?\n  \n\n    I assume there are EMI and short related risks but frankly I’ve seen people run whole computers on open wooden racks with fans blowing on the components, function just fine for years, also don’t plan to touch/move things much and they’ll be off the floor and out of the way.\n  \n\n    So anyway, all that being said, how stupid of an idea is this?"},
{"Title": "files taking too much space in external hard drive?", "Author": "u/Tikas92", "Content": "Hello everyone. I have a question and I was wondering if anyone knows what's up with that. I recently transfered 3,53 TB worth of files from a 4TB Seagate to an 8TB Lacie but for some reason those files now take up 4,46 TB on the new drive. Why is that happening?"},
{"Title": "Getting a bit lost when it comes to good syncing/cloud storage options", "Author": "u/Creator13", "Content": "After using a laptop for the past six years and carrying it everywhere, I recently got a good desktop PC again. I've always played it super risky because all my data has never been properly backed up or duplicated. Now I want my files to be available between different (windows) computers. Ideally, every change would automatically get synced between both computers, through a cloud storage provider (that also stores the files for access from outside), as long as either computer is connected to the internet.\n  \n\n    Now, plenty of services offer this, in its most basic form. I get 1TB OneDrive though my parents' family plan and OneDrive is pretty nice. It integrates well enough into Windows. But there is one major limitation that makes it pretty much unsuitable for me: I don't want all my syncable data to be in one single folder. I want it spread out over different folders and even drives, because I run quite a few different drives with different purposes.\n  \n\n    Is there a service that basically offers a way to set custom endpoints for syncable folders? Say I have a cloud folder \n/Files\n, then I want a client that runs on any connected computer where I can set \n/Files\n to be synced to \nG:\\Files\n, or to \nC:\\Users\\some_user\\Documents\\CloudFiles\n on another computer?\n  \n\n    Ideally also affordable and reputable/secure of course, and for single individual users?"},
{"Title": "I have nearly 30 TB on external hard drives I want to find a permanent solution to keep my data as i continue increase the amount", "Author": "u/romic007", "Content": "Like the title states i have nearly 30 TB on several external hard drives. The files vary from (videos, fILms, series, pictures, music, documents, etc.) i looking for a permanent solution to keep my data as it continues to grow.\n  \n\n    I am not very tech savy at all\n  \n\n    I have seen things about nas, Synology stuff but im not too familiar with that stuff.\n  \n\n    I have heard good things about icloud but im i bit worried since my files were LEGALLY downloaded. Im worried that they could look at my stuff.\n  \n\n    I use my external hard drives daily and would like this permanent solution to be accessible whenever and wherever i am.\n  \n\n    I use my external hard drives on. My laptop via usb port and do not have a pc.\n  \n\n    I am leaning towards icloud or something equivalent to that since i wouldn't have to use external hard drives as much as i currently am now.\n  \n\n    Im planning on using this as my main backup system with external hard drives as secondary but like i said i use these hard drives daily would icloud be the best solution for my situation?"},
{"Title": "Data Compression", "Author": "u/elgato123", "Content": "Noticed that a drive was filling up, saw it was mostly log files...49Gb of log files. Broke out the ol' 7-zip and in ultra mode, it compressed it down to 1.8Gb. Wow\n  \n\n    I am wondering if there is any better compression or if this is about as good as it will get? Either way, I'm very impressed"},
{"Title": "New Build raid/filesystem recommendations", "Author": "u/NextRedditAccount0", "Content": "I have a new HL15 coming. I'm planning to use it for some docker for *arr, deluge, and as a NAS. I have a separate Plex server that will be accessing the files on the HL15. No plans of doing any VMs. I'm trying to figure out the best way to get good performance and some parity in case a drive fails. Yes I do have plenty of backups.\nMy current drives in my synology is 8x8TB, 1x 500GB SSD, 1x 1TB SSD in SHR2. I also have 3x 16TB drives coming.\n  \n\n    My original plan was to run unraid but I don't want to lose out on performance due to the 8x8TB are all 5400rpms.\nI'm open to running unraid or truenas or proxmox or etc. My end goal is to get as much speed as possible while being able to survive a drive failure. No future drive expansion is planned ATM but would be nice if the new solution could support it.\nAlso this will be on a 10gbps network.\n  \n\n    Thoughts?"},
{"Title": "Question re: drives in a RAID array I inherited from a relative", "Author": "u/RhetoricalAnswer-001", "Content": "Hope this is appropriate for the forum.\n  \n\n    I inherited a full height rackmount cabinet with 12 HDs. It looks like it belongs in a data center.\n  \n\n    I want to use the drives but my PC won't recognize them. Any tips on software that can \"see\" them, then wipe and reformat them?"},
{"Title": "Internet Archive Forced to Remove 500,000 books Due to Copyright Lawsuit", "Author": "u/Run_the_Line", "Content": "No content"},
{"Title": "How long for an SSD to do it's business after a long stint in cold storage?", "Author": "u/Captain_Starkiller", "Content": "I'm firing up a computer after it was offline for nearly two years. It's SSD is just a windows drive, the data storage drives are spinning rust. That said, I want to make sure the error protection has a chance to do its thing for the SSD, refill the charge traps so bit rot doesn't set in, ect. Does anyone have any idea how long I should let it run for, before turning it off again (for a month or two this time, not years) to make sure it does it's business?"},
{"Title": "Advice/Recommendation on a Personal Desktop Build with a focus on Data Storage that can also be used as a small homeserver for myself.", "Author": "u/curiousdoggo", "Content": "Goal:\n  \n\n    I know people typically separate their data storage/server/nas from their personal desktop so it can be left to do its designated tasks and so that it won't affect the performance of the desktop (if it has to serve a multitude of people or perform a lot of different tasks), but what if my server/nas needs are minimal and my primary focus is just a good personal desktop with a focus on datahoarding/data storage, some file sharing, running a few VMs, and possibly a few more server features? In this case, is it okay to just build a decently powerful modern personal desktop - killing 2 birds with 1 s tone, instead of building 2 computers, one for desktop (desperately need the upgrade now) and one specifically for a server/nas? Is this totally okay?\n  \n\n    I live by myself so aside from being a personal computer with data storage, it'll just be serving me alone at home. To be honest, at the moment, I pretty much just consume media on my desktop, so even nas/media server features like plex, jellyfins aren't even 100% necessary - though nice to have perhaps in the future.\n  \n\n\nSummary\n: Decently powerful personal desktop with a focus on datahoarding/data storage that can also perform some server side of things like running VMs, and other homelab things down the road.\n  \n\n\nOS\n: FreeBSD with ZFS + ECC Memory\n  \n\n\nCASE\n: thinking of a big case like Fractal Design Define 7 XL that is capable of holding 14-18 HDDs.\n  \n\n\nMOBO\n:\n  \n\n\nSSD\n: What's a good NVMe 2.0 ?(maybe 1TB)\n  \n\n\nCPU\n: amd or intel? what series/models would you guys recommend?\n  \n\n\nMEM\n: looking for ECC ram as the main focus will be data storage. but how much memory will I need for zfs (assuming I will fill up the whole case with 18 HDDs down the road)?\n  \n\n\nGPU\n: a gpu capable of driving maybe a LG DualUp 2560 x 2880 with a 34\" 1440p 3440×1440 ultrawide monitor. I will also be doing some photo editing with darktable, rawtherapee, etc. as well so a designated gpu that is good enough should be enough. (don't think there will be much gaming).\n  \n\n\nPSU\n: how big of a power supply? keep in mind the full capacity is 18 HDD, with dual monitor, etc.\n  \n\n\nCPU COOLER\n:\n  \n\n\nHDD\n: thinking of 18 or 20TB seagate exos (are they too loud to use in the bedroom in a personal desktop? should i go for ironwolf pro?)"},
{"Title": "5x3.5 tool-less drive bay prices", "Author": "u/Doodarazumas", "Content": "I'm putting together a nas and I saw several threads where people recommended these kind of 3x5.25 to 5x3.5 hard drive cages\n  \n\n\nhttps://www.amazon.com/dp/B00DWHLFMA/ref=cm_sw_r_cp_api_glt_fabc_ZJWWH4ZW3JXHXF89RMN3?_encoding=UTF8&th=1\n\n\n\n\nhttps://www.amazon.com/dp/B00DWHLFMA/ref=cm_sw_r_cp_api_glt_fabc_ZJWWH4ZW3JXHXF89RMN3?_encoding=UTF8&th=1\n\n\n\n    plus silverstone/rosewill/etc.\n  \n\n    Now most of these threads were from a few years back and since then the prices on all these things have tripled or quadrupled. Even no-name aliexpress ones I've found were about $150. Is there some secret method to finding or making something like that (5x 3.5 drives tool-less with a backplane in 3x5.25 bays) for a more reasonable $50-75 or am I just going to be a caveman with a screwdriver:\n  \n\n\nhttps://www.amazon.com/EMVANV-Stainless-5-25inch-Adapter-Bracket/dp/B0C1BQ36ML/ref=pd_ci_mcx_pspc_dp_d_2_i_1"},
{"Title": "Rackmount case recs with >12 bays", "Author": "u/jtscribe52", "Content": "I’ve currently maxed out my tower and have been trying to figure out a rack mount replacement that won’t break the bank. A lot of older recs point to SuperMicro cases, but those have really jumped in price the past few years. I’ve seen some other post recommending Sliger,  but I don’t see anything with more than 10 bays,  even in a 4U.\n  \n\n    Not opposed to something from AliExpress, but curious what everyone is using of late. Thanks in advance!"},
{"Title": "Any ideas for how to acquire BluRays of foreign versions of films? (Specifically, Russian Cars 2 and Planes, and Chinese Zootopia.)", "Author": "u/CtrlAltSysRq", "Content": "Up front: I don't mind paying for it. I'm not asking for help doing piracy 101 or anything.\n  \n\n    Hi fellow hoarders. I'm not sure if this is the right place to post this, but I figure this is a good place to ask fellow hoarders about what they hoard. Feel free to lmk if you think there's a better place to post this.\n  \n\n    I'm trying to archive the different versions of Disney movies that have regional differences. For example, I have the different versions of Inside Out where Riley hates either broccoli (US) or green bell peppers (Japan).\n  \n\n    Most movies only have a few variations, but Cars 2 and Planes each has about 7 variations each where the design of a car or a plane changes depending on the region. I've gotten nearly all of them, and almost all the variations of all the other movies, except for three:\n  \n\n\n\n\n\n    Chinese Zootopia (secondary newscaster is a panda)\n  \n\n\n\n\n\n    Russian Cars 2 (Car is styled as the Russian flag)\n  \n\n\n\n\n\n    Russian Planes (the \"sexy\" girl plane is styled after the Russian flag)\n  \n\n\n\n\n\n    You can probably see why I'm having trouble with these. Disney+ isn't offered in those countries for geopolitical reasons.\n  \n\n    I've scoured the internet that is available to me looking for ways to source these either physically or digitally, but even my non-public sources are not very interested in this kind of thing. So I'm reduced to looking for physical Blu-ray's of them and that is going about as well as you might expect.\n  \n\n    So I'm wondering if anyone has ideas of ways I might be able to swing this. Thanks in advance!"},
{"Title": "For photos and videos backup, is it better to use a cloud-based storage service or buy an SSD drive?", "Author": "u/jesuisapprenant", "Content": "I got a subscription for Dropbox at around $12 per month, and I was wondering if it is worth it to just buy a 2TB SSD drive since overall the cost is much cheaper (a nice SSD with 500mb r&w is about $119 so that's 10 months of storage cost for Dropbox, so I break even at 10 months.\n  \n\n    The pros of Dropbox is that I can access it anywhere, even on my phone, and I don't have to worry about data loss or drive failure or my disk getting stolen or lost. I also won't have to carry that disk around.\n  \n\n    The pros of an external drive is that it's much cheaper and it pays for itself in 10 months. I can also transfer data in and out much faster. I also don't need internet to access my files.\n  \n\n    Which solution is better for my use case? TIA"},
{"Title": "Question about using wget to download images from Newgrounds", "Author": "u/Glen_Garrett_Gayhart", "Content": "I've got a lot of urls like this: \nhttps://www.newgrounds.com/art/view/alvinhew/annika\n where one or more images are displayed.\n  \n\n    I want to use wget to get the images on these pages that have links like this: \nhttps://art.ngfiles.com/images/49000/49087_alvinhew_annika.jpg?f1254528733\n but I'm not sure how I should configure wget to go from the first sort of url to target the second sort.\n  \n\n    I could just open all of the \nwww.newgrounds\n urls and copy the art.ngfiles urls, but that would defeat the purpose of automating it. I want to download a lot of these, and I've got a batch file that will go through them all. How should I instruct wget to look at urls of the first \nwww.newgrounds\n sort, and then download everything from urls of the second art.ngfiles sort?\n  \n\n    I don't mind if I get some extra files, like thumbnails and things, but I don't want wget spidering all over the website and potentially downloading things from pages \nother\n than the art.ngfiles links.\n  \n\n    `\n  \n\n    Thanks in advance for any help!"},
{"Title": "GM service manual archiving", "Author": "u/Betelgeuse28", "Content": "Has anyone managed to download the newer service manuals from ACDelco TDS site? I bought a 3 day access pass to the site but I've had zero luck so far. Ive tried wget, Offline Explorer, HTTrack, and Webcopy. I'm not really trying to save an 18k page manual by rightclicking and save to pdf."},
{"Title": "Any thoughts on using something lie LBRY protocol for mass decentralised data hoarding?", "Author": "u/MasterDefibrillator", "Content": "Something like it, or the LBRY protocol itself."},
{"Title": "YouTube seems to be blocking accounts that are used with yt-dlp (by passing cookies)", "Author": "u/BowzasaurusRex", "Content": "No content"},
{"Title": "Looking for an external HDD to backup my NAS - what drives do you recommend?", "Author": "u/kavakravata", "Content": "Hey!\n  \n\n    I have a NAS with 16TB of active storage using RAID. As a newbie, I didn’t even think about the possibility of my NAS drives failing with time, especially after reading horror stories with seagate ironwolf drives which I’m currently using.\n  \n\n    I hate SaaS and cloud, and would much prefer a local backup to my Synology NAS. What drives do you recommend? Been looking at the WD My Book 16TB or Easystore 18TB from Amazon, but I’m unsure. I don’t care about house fires / theft, so ignore that risk of backup solutions.\n  \n\n    Taking all ideas! Thank you 🥰"},
{"Title": "LSI 9650se-16ml rebuild questiom", "Author": "u/SirMeili", "Content": "I know this is an old card. I've been using it since I bought it new in 2008. I'm prepping to do a migration to trunas and a set of larger drives and an also 9305 card but until I can get some new drives I'm limping along with this old card.\n  \n\n    I currently have a RAID6 array of 9 4tb WD red drives. One degraded and it's been trying to rebuild. I'm currently running windows server 2016 essentials. I think something is causing the is to bsod while rebuilding the array. So I went into the cards bios to rebuild there.\n  \n\n    Does anyone know if the card will rebuild while I'm in the bios screen of the card? I would rather leave it there and let it rebuild.\n  \n\n    It could also be the drive is hosed and I need to buy a new one. Not sure why the drive went degraded except that we had a storm the other night and my UPSs battery apparently failed (less than 6 months old) and the server hard shutdown. The drives were unlikely to be writing anything as I don't currently write to that array. It's purely read operations.\n  \n\n    Any help would be greatly appreciated.\n  \n\n    *Btw I have backed up data to external drives, but I would still rather not lose the data as I could mount the array and make copying to the new array in trunas faster."},
{"Title": "Cold storage backups", "Author": "u/Vatican87", "Content": "What's the best way to backup important media (Photos / Videos), are cold storage options the best way? As in do they degrade much at all if they're only spinning up every few months to backup files?"},
{"Title": "HD Tune Pro Question", "Author": "u/klaaaay", "Content": "Hello, I have installed the HD Tune Pro program to see how my disk was since in the Crystal Disk Info program it shows me 69% Good in green, the disk is approximately 2 and a half or 3 years old and I wanted to confirm the information, doing the Error Scan test I have noticed that there are rectangles that remain blank, should I be worried?\n  \nhttps://preview.redd.it/hd-tune-pro-question-v0-zycqm8oomt6d1.png"},
{"Title": "I upsized from a Fractal Design Node 804 into a Meshify 2 XL!", "Author": "u/shockguard", "Content": "No content"},
{"Title": "First machine at 15 YO", "Author": "u/modestt_rat", "Content": "No content"},
{"Title": "Backup Client From NAS", "Author": "u/FancyRectangle", "Content": "I've been using Arq 7 for quite some time at this point, and have had a Windows 2019 VM running exclusively to mount RO shares from my main NAS and backup to a couple endpoint.\n  \n\n    This has been on a physically separate box (security), but have been considering moving this VM to just be on the NAS itself and backing up from there.\n  \n\n    Does anyone else backup straight from NAS to a remote endpoint? I have a separate local NAS that pulls snapshots, but looking into some potential consolidation for a VM that needs to remain on consistently."},
{"Title": "Amazing piece of software: Podcast Bulk Downloader", "Author": "u/didyousayboop", "Content": "Podcast Bulk Downloader is a Windows program (written by \nu/cnovel\n) that allows you to batch download episodes of a podcast simply by copy/pasting in a link to the RSS feed.\n  \n\n    There is an option to automatically append the release dates of the episodes as a prefix to the file names.\n  \n\n    Download it on GitHub \nhere\n."},
{"Title": "Can you rename files based on metadata within the file?", "Author": "u/Elarionus", "Content": "I take photos with three different devices at work for different purposes, a Pixel, a Samsung, and an iPhone. They all name their files differently. This isn't an issue when they're all in Google Photos, but that's never their permanent home. They all add different pieces and parts to the file names. I know I could run them through a renamer to remove or add certain parts, but I was wondering if there's a software out there that lets me just dump thousands of photos into it and have it spit out filenames based on the metadata of when they were taken. YYYY-MM-DD_HH-MM-SS (Year, Month, Day, Hours, Minutes, Seconds).\n  \n\n    It would help us out a lot as we would be able to filter images in file explorer much more quickly."},
{"Title": "NEW to RAID and need help with a DIY 4 Bay", "Author": "u/FreasFrames", "Content": "I am new to the whole RAID landscape. I have been looking at the Thunderbay 4 to set up as a RAID 5 with 4x16TB HDD.\n  \n\n    the question I have is what is the most cost effective way of building one? or is it a smart idea to go with the OWC built 4x16TB so its just plug and play?\n  \n\n    Would like some help with what sites to source drives and enclosures from if OWC is not my end result\n  \n\n    Currently on a 2017 iMac Retina with 64MB DDR4 using a 3.4 GHz Quad-Core Intel i5. Running Ventura 13.6.6"},
{"Title": "Long term data storage options", "Author": "u/BroccoliSanchez", "Content": "I currently have a wd 14tb desktop harddrive for my digital backups of my home media. I know consumer drives have a decent shelf life but I was wondering if there is a particular brand or type of drive I should use to back up my main drive. I plan on keeping the backup drive in a fire and flood proof safe and only powering it up to do weekly updates of new files. External options are preferred for the simplicity"},
{"Title": "ZFS write errors on 7200 RPM drives, fine with badblocks", "Author": "u/rhnet", "Content": "I have been struggling adding 7200 RPM refurbished SATA drives (WUH721414AL) to my existing ZFS pool. The drives have no issues with badblocks, and I have tested them on another system as well.\n  \n\n    When I try to add them to an existing zfs mirror, I run into lots of WRITE/CKSUM errors, and they will eventually fault. Here's the output only 10% into a resilver.\n  \n    NAME                       STATE     READ WRITE CKSUM\n    tank                  DEGRADED     0     0     0\n      mirror-0                 DEGRADED     0     0     0\n        disk2_crypt            ONLINE       0     0     0\n        disk16_crypt           ONLINE       0     4    93  (resilvering)\n\n    And in dmesg I get stuff like:\n  \n[Sat Jun 15 12:39:59 2024] zio pool=tank vdev=/dev/mapper/disk16_crypt error=5 type=2 offset=7423255224320 size=12288 flags=1808aa\n[Sat Jun 15 12:39:59 2024] zio pool=tank vdev=/dev/mapper/disk16_crypt error=5 type=2 offset=7423255212032 size=12288 flags=1808aa\n\n    I have these attached to an HBA and SAS expander, but I've also tried with the SATA ports on the motherboard directly.\n  \n\n    Setup:\n  \n\n\n\n\n\n    LSI SAS9340-8i ServeRAID M1215 12Gbps SAS (from artofserver)\n  \n\n\n\n\n\n    Adaptec 2283400-R AEC-82885T LENOVO 36Port 12Gb/s SAS Expander Card 82885T US\n  \n\n\n\n\n\n    10Gtek# 12G Internal Mini SAS HD SFF-8643 to SFF-8643 Cable, with Sideband, 100-Ohm, 0.5-m(1.6ft), 2 Pack\n  \n\n\n\n\n\n    3x AdcAudx 2Pack SFF-8643 to SATA: 1M SFF-8643 Mini-SAS to SATA-Cable SFF8643 to SATA Mini SAS HD to SATA Forward Breakout (3.3FT)\n  \n\n\n\n\n\n    Lots of working fine 5200 RPM data drives: WD101EMAZ-11, WDC WD140EDFZ-11, WDC WD140EDGZ-11, WD80EMAZ-00W, ...\n  \n\n\n\n\n\n    Several 7200 RPM drives from Serverparts and goharddrive, all WUH721414AL.\n  \n\n    I run them with luks (cryptsetup luksFormat -c aes-xts-plain64 -s 512 -h sha256) and in zfs mirror."},
{"Title": "Something about sorting media that is really bugging me", "Author": "u/kyne_ahnung", "Content": "This is one of those questions where I don't know if I'm doing it wrong or so many other people are, but I can't work out why it's so hard to find a way to go through a big directory of videos or images in a gallery/viewer manually and easily say this one should go in folder A, that one in B, this one in D, that one in A; without having to - for each file - close the gallery (memorizing the filename), find it in the current directory among thousands of others, also find the destination and open that in another window, copy/move/drag the file to the destination.\n  \n\n    What I'm looking for:\n  \n\n\n\n\n\n    A video and image gallery\n  \n\n\n\n\n\n    Some kind of sidebar with shortcuts to favourited/saved paths\n  \n\n\n\n\n\n    The ability to easily move the image or video that I am currently viewing to one of these shortcuts either via drag or clicking move>move to>shortcut to folder A\n  \n\n\n\n\n\n    Am I crazy/stupid or is it unneccessarily hard to do this task in an ergonomic way? I have all my photos and videos sent and received on my phone over the years to sort through... deleting is no problem, finding duplicates is easy but how do people actually do the organizing? Any methods, software suggestions welcome.\n  \n\n     \n  \n\n    Edit: or another plausible method is being able to easily apply a tag to each file from the viewer, so you watch a video and can quickly click on or type a tag.."},
{"Title": "Download site with login?", "Author": "u/Cyan7988", "Content": "Hello, a website is about to shutdown and there are many links that are only accessible after logging in, when downloading website with httrack it only downloads the non logged in version of thr site which I can't see the download links, how to I make it download the logged in version of thr site? I have the password and username\n  \n\n    Using HTTRACK"},
{"Title": "A simple way to save a lot of data?", "Author": "u/Jatm4", "Content": "Hi there, I've been having a serious storage problem for a few weeks now. I used to store the media generated by my projects on individual external HDD, but this is no longer an option for me. I found a storage unit on Amazon (WD Elements 18TB) that was exactly what I needed. The problem? I bought it and it came DOA, and after seeing some comments about that device, it seems they are very unreliable, so it's no longer an option. Now I don't know how to solve my problem. I just want a drive to store my backups and where I can access them when needed, not something that needs to be constantly connected, some simple, a NAS seems a bit excessive and I wouldn't want to use a cloud. What solution do you recommend me? Did I just have bad luck with the WD Elements? I live outside the USA, so I would need something that can be purchased and shipped internationally"},
{"Title": "Can I put a 12-to-16 pin adapter inside a USB enclosure?", "Author": "u/biocoder86", "Content": "I have an old SSD drive I want to recover data from and maybe use as a portable drive going forward...\n  \n\n    Specifically I want to use this old 12 + 16 pin from an old MacBook Air (A1465), with a 12 + 16 to NVMe M key adapter.\n  \n\n\nhttps://amzn.eu/d/1gMJdGQ\n\n\n\n    Then I want to put those inside a NVMe M key to USB enclosure.\n  \n\n\nhttps://amzn.eu/d/9ifm71g\n\n\n\n    But the fourth image you scroll to of the adapter says that it cannot work in a USB enclosure, only plugged directly into the motherboard. Then in one of the user questions they seem to say the opposite with no explanation. That so long as it is 12 + 16 on one end and M key on the other it will work.\n  \n\n    So... will it work? If not, is this universally true or can I get a different adapter?"},
{"Title": "SATA vs SAS", "Author": "u/uberkalden2", "Content": "Genuinely confused here.  Are any of the enterprise drives SATA, or are they all SAS? They all say SATA in the description, but the details will typically also say SAS.  I was going to get a Sabrent external enclosure, but I don't think they work with SAS drives.\n  \n\n    Maybe my understanding of SATA is wrong?"},
{"Title": "5x3.5 tool-less drive bay prices", "Author": "u/Doodarazumas", "Content": "I'm putting together a nas and I saw several threads where people recommended these kind of 3x5.25 to 5x3.5 hard drive cages\n  \n\n\nhttps://www.amazon.com/dp/B00DWHLFMA/ref=cm_sw_r_cp_api_glt_fabc_ZJWWH4ZW3JXHXF89RMN3?_encoding=UTF8&th=1\n\n\n\n\nhttps://www.amazon.com/dp/B00DWHLFMA/ref=cm_sw_r_cp_api_glt_fabc_ZJWWH4ZW3JXHXF89RMN3?_encoding=UTF8&th=1\n\n\n\n    plus silverstone/rosewill/etc.\n  \n\n    Now most of these threads were from a few years back and since then the prices on all these things have tripled or quadrupled. Even no-name aliexpress ones I've found were about $150. Is there some secret method to finding or making something like that (5x 3.5 drives tool-less with a backplane in 3x5.25 bays) for a more reasonable $50-75 or am I just going to be a caveman with a screwdriver:\n  \n\n\nhttps://www.amazon.com/EMVANV-Stainless-5-25inch-Adapter-Bracket/dp/B0C1BQ36ML/ref=pd_ci_mcx_pspc_dp_d_2_i_1"},
{"Title": "Rackmount case recs with >12 bays", "Author": "u/jtscribe52", "Content": "I’ve currently maxed out my tower and have been trying to figure out a rack mount replacement that won’t break the bank. A lot of older recs point to SuperMicro cases, but those have really jumped in price the past few years. I’ve seen some other post recommending Sliger,  but I don’t see anything with more than 10 bays,  even in a 4U.\n  \n\n    Not opposed to something from AliExpress, but curious what everyone is using of late. Thanks in advance!"},
{"Title": "Any ideas for how to acquire BluRays of foreign versions of films? (Specifically, Russian Cars 2 and Planes, and Chinese Zootopia.)", "Author": "u/CtrlAltSysRq", "Content": "Up front: I don't mind paying for it. I'm not asking for help doing piracy 101 or anything.\n  \n\n    Hi fellow hoarders. I'm not sure if this is the right place to post this, but I figure this is a good place to ask fellow hoarders about what they hoard. Feel free to lmk if you think there's a better place to post this.\n  \n\n    I'm trying to archive the different versions of Disney movies that have regional differences. For example, I have the different versions of Inside Out where Riley hates either broccoli (US) or green bell peppers (Japan).\n  \n\n    Most movies only have a few variations, but Cars 2 and Planes each has about 7 variations each where the design of a car or a plane changes depending on the region. I've gotten nearly all of them, and almost all the variations of all the other movies, except for three:\n  \n\n\n\n\n\n    Chinese Zootopia (secondary newscaster is a panda)\n  \n\n\n\n\n\n    Russian Cars 2 (Car is styled as the Russian flag)\n  \n\n\n\n\n\n    Russian Planes (the \"sexy\" girl plane is styled after the Russian flag)\n  \n\n\n\n\n\n    You can probably see why I'm having trouble with these. Disney+ isn't offered in those countries for geopolitical reasons.\n  \n\n    I've scoured the internet that is available to me looking for ways to source these either physically or digitally, but even my non-public sources are not very interested in this kind of thing. So I'm reduced to looking for physical Blu-ray's of them and that is going about as well as you might expect.\n  \n\n    So I'm wondering if anyone has ideas of ways I might be able to swing this. Thanks in advance!"},
{"Title": "For photos and videos backup, is it better to use a cloud-based storage service or buy an SSD drive?", "Author": "u/jesuisapprenant", "Content": "I got a subscription for Dropbox at around $12 per month, and I was wondering if it is worth it to just buy a 2TB SSD drive since overall the cost is much cheaper (a nice SSD with 500mb r&w is about $119 so that's 10 months of storage cost for Dropbox, so I break even at 10 months.\n  \n\n    The pros of Dropbox is that I can access it anywhere, even on my phone, and I don't have to worry about data loss or drive failure or my disk getting stolen or lost. I also won't have to carry that disk around.\n  \n\n    The pros of an external drive is that it's much cheaper and it pays for itself in 10 months. I can also transfer data in and out much faster. I also don't need internet to access my files.\n  \n\n    Which solution is better for my use case? TIA"},
{"Title": "Question about using wget to download images from Newgrounds", "Author": "u/Glen_Garrett_Gayhart", "Content": "I've got a lot of urls like this: \nhttps://www.newgrounds.com/art/view/alvinhew/annika\n where one or more images are displayed.\n  \n\n    I want to use wget to get the images on these pages that have links like this: \nhttps://art.ngfiles.com/images/49000/49087_alvinhew_annika.jpg?f1254528733\n but I'm not sure how I should configure wget to go from the first sort of url to target the second sort.\n  \n\n    I could just open all of the \nwww.newgrounds\n urls and copy the art.ngfiles urls, but that would defeat the purpose of automating it. I want to download a lot of these, and I've got a batch file that will go through them all. How should I instruct wget to look at urls of the first \nwww.newgrounds\n sort, and then download everything from urls of the second art.ngfiles sort?\n  \n\n    I don't mind if I get some extra files, like thumbnails and things, but I don't want wget spidering all over the website and potentially downloading things from pages \nother\n than the art.ngfiles links.\n  \n\n    `\n  \n\n    Thanks in advance for any help!"},
{"Title": "GM service manual archiving", "Author": "u/Betelgeuse28", "Content": "Has anyone managed to download the newer service manuals from ACDelco TDS site? I bought a 3 day access pass to the site but I've had zero luck so far. Ive tried wget, Offline Explorer, HTTrack, and Webcopy. I'm not really trying to save an 18k page manual by rightclicking and save to pdf."},
{"Title": "Any thoughts on using something lie LBRY protocol for mass decentralised data hoarding?", "Author": "u/MasterDefibrillator", "Content": "Something like it, or the LBRY protocol itself."},
{"Title": "YouTube seems to be blocking accounts that are used with yt-dlp (by passing cookies)", "Author": "u/BowzasaurusRex", "Content": "No content"},
{"Title": "Looking for an external HDD to backup my NAS - what drives do you recommend?", "Author": "u/kavakravata", "Content": "Hey!\n  \n\n    I have a NAS with 16TB of active storage using RAID. As a newbie, I didn’t even think about the possibility of my NAS drives failing with time, especially after reading horror stories with seagate ironwolf drives which I’m currently using.\n  \n\n    I hate SaaS and cloud, and would much prefer a local backup to my Synology NAS. What drives do you recommend? Been looking at the WD My Book 16TB or Easystore 18TB from Amazon, but I’m unsure. I don’t care about house fires / theft, so ignore that risk of backup solutions.\n  \n\n    Taking all ideas! Thank you 🥰"},
{"Title": "LSI 9650se-16ml rebuild questiom", "Author": "u/SirMeili", "Content": "I know this is an old card. I've been using it since I bought it new in 2008. I'm prepping to do a migration to trunas and a set of larger drives and an also 9305 card but until I can get some new drives I'm limping along with this old card.\n  \n\n    I currently have a RAID6 array of 9 4tb WD red drives. One degraded and it's been trying to rebuild. I'm currently running windows server 2016 essentials. I think something is causing the is to bsod while rebuilding the array. So I went into the cards bios to rebuild there.\n  \n\n    Does anyone know if the card will rebuild while I'm in the bios screen of the card? I would rather leave it there and let it rebuild.\n  \n\n    It could also be the drive is hosed and I need to buy a new one. Not sure why the drive went degraded except that we had a storm the other night and my UPSs battery apparently failed (less than 6 months old) and the server hard shutdown. The drives were unlikely to be writing anything as I don't currently write to that array. It's purely read operations.\n  \n\n    Any help would be greatly appreciated.\n  \n\n    *Btw I have backed up data to external drives, but I would still rather not lose the data as I could mount the array and make copying to the new array in trunas faster."},
{"Title": "Cold storage backups", "Author": "u/Vatican87", "Content": "What's the best way to backup important media (Photos / Videos), are cold storage options the best way? As in do they degrade much at all if they're only spinning up every few months to backup files?"},
{"Title": "HD Tune Pro Question", "Author": "u/klaaaay", "Content": "Hello, I have installed the HD Tune Pro program to see how my disk was since in the Crystal Disk Info program it shows me 69% Good in green, the disk is approximately 2 and a half or 3 years old and I wanted to confirm the information, doing the Error Scan test I have noticed that there are rectangles that remain blank, should I be worried?\n  \nhttps://preview.redd.it/hd-tune-pro-question-v0-zycqm8oomt6d1.png"},
{"Title": "I upsized from a Fractal Design Node 804 into a Meshify 2 XL!", "Author": "u/shockguard", "Content": "No content"},
{"Title": "First machine at 15 YO", "Author": "u/modestt_rat", "Content": "No content"},
{"Title": "Backup Client From NAS", "Author": "u/FancyRectangle", "Content": "I've been using Arq 7 for quite some time at this point, and have had a Windows 2019 VM running exclusively to mount RO shares from my main NAS and backup to a couple endpoint.\n  \n\n    This has been on a physically separate box (security), but have been considering moving this VM to just be on the NAS itself and backing up from there.\n  \n\n    Does anyone else backup straight from NAS to a remote endpoint? I have a separate local NAS that pulls snapshots, but looking into some potential consolidation for a VM that needs to remain on consistently."},
{"Title": "Amazing piece of software: Podcast Bulk Downloader", "Author": "u/didyousayboop", "Content": "Podcast Bulk Downloader is a Windows program (written by \nu/cnovel\n) that allows you to batch download episodes of a podcast simply by copy/pasting in a link to the RSS feed.\n  \n\n    There is an option to automatically append the release dates of the episodes as a prefix to the file names.\n  \n\n    Download it on GitHub \nhere\n."},
{"Title": "Can you rename files based on metadata within the file?", "Author": "u/Elarionus", "Content": "I take photos with three different devices at work for different purposes, a Pixel, a Samsung, and an iPhone. They all name their files differently. This isn't an issue when they're all in Google Photos, but that's never their permanent home. They all add different pieces and parts to the file names. I know I could run them through a renamer to remove or add certain parts, but I was wondering if there's a software out there that lets me just dump thousands of photos into it and have it spit out filenames based on the metadata of when they were taken. YYYY-MM-DD_HH-MM-SS (Year, Month, Day, Hours, Minutes, Seconds).\n  \n\n    It would help us out a lot as we would be able to filter images in file explorer much more quickly."},
{"Title": "NEW to RAID and need help with a DIY 4 Bay", "Author": "u/FreasFrames", "Content": "I am new to the whole RAID landscape. I have been looking at the Thunderbay 4 to set up as a RAID 5 with 4x16TB HDD.\n  \n\n    the question I have is what is the most cost effective way of building one? or is it a smart idea to go with the OWC built 4x16TB so its just plug and play?\n  \n\n    Would like some help with what sites to source drives and enclosures from if OWC is not my end result\n  \n\n    Currently on a 2017 iMac Retina with 64MB DDR4 using a 3.4 GHz Quad-Core Intel i5. Running Ventura 13.6.6"},
{"Title": "Long term data storage options", "Author": "u/BroccoliSanchez", "Content": "I currently have a wd 14tb desktop harddrive for my digital backups of my home media. I know consumer drives have a decent shelf life but I was wondering if there is a particular brand or type of drive I should use to back up my main drive. I plan on keeping the backup drive in a fire and flood proof safe and only powering it up to do weekly updates of new files. External options are preferred for the simplicity"},
{"Title": "ZFS write errors on 7200 RPM drives, fine with badblocks", "Author": "u/rhnet", "Content": "I have been struggling adding 7200 RPM refurbished SATA drives (WUH721414AL) to my existing ZFS pool. The drives have no issues with badblocks, and I have tested them on another system as well.\n  \n\n    When I try to add them to an existing zfs mirror, I run into lots of WRITE/CKSUM errors, and they will eventually fault. Here's the output only 10% into a resilver.\n  \n    NAME                       STATE     READ WRITE CKSUM\n    tank                  DEGRADED     0     0     0\n      mirror-0                 DEGRADED     0     0     0\n        disk2_crypt            ONLINE       0     0     0\n        disk16_crypt           ONLINE       0     4    93  (resilvering)\n\n    And in dmesg I get stuff like:\n  \n[Sat Jun 15 12:39:59 2024] zio pool=tank vdev=/dev/mapper/disk16_crypt error=5 type=2 offset=7423255224320 size=12288 flags=1808aa\n[Sat Jun 15 12:39:59 2024] zio pool=tank vdev=/dev/mapper/disk16_crypt error=5 type=2 offset=7423255212032 size=12288 flags=1808aa\n\n    I have these attached to an HBA and SAS expander, but I've also tried with the SATA ports on the motherboard directly.\n  \n\n    Setup:\n  \n\n\n\n\n\n    LSI SAS9340-8i ServeRAID M1215 12Gbps SAS (from artofserver)\n  \n\n\n\n\n\n    Adaptec 2283400-R AEC-82885T LENOVO 36Port 12Gb/s SAS Expander Card 82885T US\n  \n\n\n\n\n\n    10Gtek# 12G Internal Mini SAS HD SFF-8643 to SFF-8643 Cable, with Sideband, 100-Ohm, 0.5-m(1.6ft), 2 Pack\n  \n\n\n\n\n\n    3x AdcAudx 2Pack SFF-8643 to SATA: 1M SFF-8643 Mini-SAS to SATA-Cable SFF8643 to SATA Mini SAS HD to SATA Forward Breakout (3.3FT)\n  \n\n\n\n\n\n    Lots of working fine 5200 RPM data drives: WD101EMAZ-11, WDC WD140EDFZ-11, WDC WD140EDGZ-11, WD80EMAZ-00W, ...\n  \n\n\n\n\n\n    Several 7200 RPM drives from Serverparts and goharddrive, all WUH721414AL.\n  \n\n    I run them with luks (cryptsetup luksFormat -c aes-xts-plain64 -s 512 -h sha256) and in zfs mirror."},
{"Title": "Something about sorting media that is really bugging me", "Author": "u/kyne_ahnung", "Content": "This is one of those questions where I don't know if I'm doing it wrong or so many other people are, but I can't work out why it's so hard to find a way to go through a big directory of videos or images in a gallery/viewer manually and easily say this one should go in folder A, that one in B, this one in D, that one in A; without having to - for each file - close the gallery (memorizing the filename), find it in the current directory among thousands of others, also find the destination and open that in another window, copy/move/drag the file to the destination.\n  \n\n    What I'm looking for:\n  \n\n\n\n\n\n    A video and image gallery\n  \n\n\n\n\n\n    Some kind of sidebar with shortcuts to favourited/saved paths\n  \n\n\n\n\n\n    The ability to easily move the image or video that I am currently viewing to one of these shortcuts either via drag or clicking move>move to>shortcut to folder A\n  \n\n\n\n\n\n    Am I crazy/stupid or is it unneccessarily hard to do this task in an ergonomic way? I have all my photos and videos sent and received on my phone over the years to sort through... deleting is no problem, finding duplicates is easy but how do people actually do the organizing? Any methods, software suggestions welcome.\n  \n\n     \n  \n\n    Edit: or another plausible method is being able to easily apply a tag to each file from the viewer, so you watch a video and can quickly click on or type a tag.."},
{"Title": "Download site with login?", "Author": "u/Cyan7988", "Content": "Hello, a website is about to shutdown and there are many links that are only accessible after logging in, when downloading website with httrack it only downloads the non logged in version of thr site which I can't see the download links, how to I make it download the logged in version of thr site? I have the password and username\n  \n\n    Using HTTRACK"},
{"Title": "A simple way to save a lot of data?", "Author": "u/Jatm4", "Content": "Hi there, I've been having a serious storage problem for a few weeks now. I used to store the media generated by my projects on individual external HDD, but this is no longer an option for me. I found a storage unit on Amazon (WD Elements 18TB) that was exactly what I needed. The problem? I bought it and it came DOA, and after seeing some comments about that device, it seems they are very unreliable, so it's no longer an option. Now I don't know how to solve my problem. I just want a drive to store my backups and where I can access them when needed, not something that needs to be constantly connected, some simple, a NAS seems a bit excessive and I wouldn't want to use a cloud. What solution do you recommend me? Did I just have bad luck with the WD Elements? I live outside the USA, so I would need something that can be purchased and shipped internationally"},
{"Title": "Can I put a 12-to-16 pin adapter inside a USB enclosure?", "Author": "u/biocoder86", "Content": "I have an old SSD drive I want to recover data from and maybe use as a portable drive going forward...\n  \n\n    Specifically I want to use this old 12 + 16 pin from an old MacBook Air (A1465), with a 12 + 16 to NVMe M key adapter.\n  \n\n\nhttps://amzn.eu/d/1gMJdGQ\n\n\n\n    Then I want to put those inside a NVMe M key to USB enclosure.\n  \n\n\nhttps://amzn.eu/d/9ifm71g\n\n\n\n    But the fourth image you scroll to of the adapter says that it cannot work in a USB enclosure, only plugged directly into the motherboard. Then in one of the user questions they seem to say the opposite with no explanation. That so long as it is 12 + 16 on one end and M key on the other it will work.\n  \n\n    So... will it work? If not, is this universally true or can I get a different adapter?"},
{"Title": "SATA vs SAS", "Author": "u/uberkalden2", "Content": "Genuinely confused here.  Are any of the enterprise drives SATA, or are they all SAS? They all say SATA in the description, but the details will typically also say SAS.  I was going to get a Sabrent external enclosure, but I don't think they work with SAS drives.\n  \n\n    Maybe my understanding of SATA is wrong?"},
{"Title": "Megaraid 9271-8i Dying - How do I replace it without data loss?", "Author": "u/Barja_Bardagi", "Content": "(Cross-posting a couple places to hopefully find help)  I've got a DIY NAS that I built a number of years ago based on a Megaraid 9271-8icc. There's 8x HDD RAID-50 array on it, and a 6x SSD RAID-6 array. Well, last Sunday, the card started dying. The machine's boot drives are NOT on the raid controller, and every few reboots, the card works for a while and then craps out. So, I bought a new (used) card from eBay.\n  \n\n    Now, storage is NOT my forte. I know enough to be dangerous to myself. How do I go about replacing the failing card without losing all my data? Will the new card see data on the drives and realize \"Oh, this is part of an array\"? Do I need to try to recover some settings from the old card? Could someone explain this to me like I'm an end user? :P"},
{"Title": "Instaloader hits login wall with VPN", "Author": "u/patagonianlamb", "Content": "A few weeks back, I managed to scrape a good amount of data from Instagram using a VPN and Instaloader without even logging in. It was great! But now, whenever I try to access Instagram through a VPN, it just takes me straight to the login page. Instaloader can't bypass the login wall either. Is this the end of accessing Instagram media without logging in via a VPN?"},
{"Title": "Refurbished NAS Hard Drives… Ye or Ne?", "Author": "u/maximumkush", "Content": "Starting my first NAS to fuel my addiction. I’m starting off with RAID 5 with 3 12tb hard drives. I found some decent priced refurbished ones. Asking the pros for their honest opinion"},
{"Title": "Would you not use a certified refurbished 20tb drive for parity?", "Author": "u/NotAnADC", "Content": "Asking specifically if I should only use a drive like that for expansion and not parity, cause maybe parity sees more action. Running in unraid. I know a lot of people like and trust serverpartdeals"},
{"Title": "How often should I update/refresh my cold storage?", "Author": "u/largePenisLover", "Content": "For cold/\"off-site\" storage of backups I use few HDD's. Backups go on them and then I store them nice and safe in a brick shed as an off-site kinda thing. They contain full backups. Disk is wiped and then a fresh backup goes on. I do this a few times a year. Not a real schedule to it.\n  \n\n    I fear bitrot.\nHow often should I refresh them to manage the chance of bitrot happening?\nWould it even help? I mean yes I wrote new data but the metal still aged."},
{"Title": "almost entirely geoblocked youtube videos?", "Author": "u/koalahugthekoala", "Content": "hi! so i have some important videos that are related to my special interest but have been geoblocked outside kosovo, somaliland, and northern cyprus. i know they still exist so what tool would i use to get them?\n  \n\n    i have no idea how github or anything works so that kinda rules out youtubedl unless someone did it for me. they are not on the wayback machine.\n  \n\n    here's the links if this helps you! \nhttps://youtube.com/watch?v=b7TYi0FwR1M\n \nhttps://youtube.com/watch?v=xmKYxwXox5g\n \nhttps://youtube.com/watch?v=AJr9VOCe1yY\n \nhttps://youtube.com/watch?v=FMLjygFXB7w\n \nhttps://youtube.com/watch?v=ZhLJyHxRuu8\n \nhttps://youtube.com/watch?v=mHU6dS07cZQ\n \nhttps://youtube.com/watch?v=Z6S5klRoI_c\n \nhttps://youtube.com/watch?v=AVeE9NMfAxE\n thank u for any help!"},
{"Title": "How do i rip a copy protected DVD?", "Author": "u/Icy-Composer9021", "Content": "I have some DVDs i wanna rip onto my computer and put on my ipod, specifically some simpsons and avp if it matters. Also region code is 2 or PAL on the simpsons."},
{"Title": "Personal NAS OS: Debian/Ubuntu vs TrueNAS or Rockstor", "Author": "u/PuzzleHeadPistion", "Content": "I have a personal NAS built on a i5-4690 with 16Gb RAM, which I use for archived work files (music, photos and videos), backups from my computers and as Plex Server. Services like ownCloud or something that would allow me to share files via url (like a personal WeTransfer) would be extremely useful. Maybe a system with ZFS would be good.\n  \n\n    I'm trying to decide whether to build from scratch on a full OS (Debian, Ubuntu or even Windows 2022?) vs something like TrueNAS or Rockstor. I haven't used Linux in almost 10y, but I used to use Arch.\n  \n\n    Not sure if it's relevant, but I also own an Asustor Drivestor 2 Lite and a ZenWifi XT9 router with a drive attached, use WireGuard VPN, etc."},
{"Title": "Samsung 8tb qvo ssd reliability", "Author": "u/ChillCaptain", "Content": "I bought the 8tb Samsung qvo ssd for a gaming/Roms drive.\n  \n\n    I know performance is meh and tbw is not great. But I don’t expect to write a lot to the drive. Copy my Roms and games once and switch out the games every so often.\n  \n\n    I’m mainly concerned with reliability. Id imagine it would be better than a spinning hard drive. Any opinions on reliability?"},
{"Title": "[HDD] 14TB Refreshed WD Ultrastar Hard Drive w/ 5 Year Warranty - $99.99 (NewEgg)", "Author": "u/Axodique", "Content": "No content"},
{"Title": "Quick question about IDM", "Author": "u/redskies1991", "Content": "Can i save my download location to an external drive (external ssd) ? Does it work.. coz i want to lessen the \"rebuilding\" time when i download large file sizes.."},
{"Title": "How to Download a Video off of Europeana?", "Author": "u/thxdley", "Content": "Sorry, i dunno if this belongs here but i dont know where else to put it. I'm pretty sure Europeana embeds the videos or something (i have no clue how any of it works) but when i try downloading the video it gives me a \"raw.html\"  which my computer wont download. Is it impossible to get my hands on this? I dont want to screen record it because of background noise/low quality/lag. Below is the link to the video im trying to download on Europeana.\n  \n\n\nhttps://www.europeana.eu/item/2051918/data_euscreenXL_EUS_0BCE32473CEBA87D2DB36A87B5511130"},
{"Title": "Does anyone know the IBM TS3500 Tape Library (IBM 3592 JC/JY)?", "Author": "u/_c0der", "Content": "Hi all,\n  \n\n    does anyone know the IBM TS3500 Tape Library with the corresponding IBM 3592 JC/JY type drives and tapes?\n  \n\n    I can have a full rack for free - where is the catch? Is it worth it?\n  \n\n    Power and space isn't an issue.\n  \n\n    Pictures: \nhttps://imgur.com/a/mjwmvI6"},
{"Title": "Is there info on failure rate of SSD vs spinning HD", "Author": "u/SlothChunks", "Content": "Hi everybody, I am trying to decide whether to buy a larger capacity drive to replace my two old Samsung SSDs that are 1TB and 500gb.\n  \n\n    When I looked at Amazon I saw that there are many options of new models if standard spinning drives for much less.\n  \n\n    As far as I know from reading over the years spinning drives are more likely to fail than the spinning disk drives.  But I haven’t ever actually seen the test data to see just how likely or unlikely they are to break compared to SSD.\n  \n\n    If this drive is going to be used only at home and not carried anywhere, does anyone have any idea just how much more likely it is to fail than an SSD?\n  \n\n    Bonus: question, are WesternDigital SSDs any better or worse than Samsung? Or are there any established brands are are absolutely better to avoid?"},
{"Title": "Equipment recommendations", "Author": "u/Broke_Bearded_Guy", "Content": "I was looking at buying a storage drawer preferably a 4U 60bay. I've seen some of the newer HGST units available but I've seen some posts about requiring proprietary drives I didn't know if anyone could make a recommendation my only real requirement is 120v compatible"},
{"Title": "just wondering if others with IDM also have this problem", "Author": "u/Street_Mine_1969", "Content": "for the last 3 days my IDM pop up download bar does not show on youtube and youtube only. other other video site is still okay and can download without problem. anyone else with IDM have this problem with youtube?"},
{"Title": "how do you batch select on czkawka?", "Author": "u/randomusername11222", "Content": "there is this select windows\n  \nhttps://preview.redd.it/how-do-you-batch-select-on-czkawka-v0-u0bmvpoaim6d1.png\n\n    But I cant like multiselect the files that I want manually?"},
{"Title": "Which SATA Ssd should I buy in 2024?", "Author": "u/eliosferre3", "Content": "Hi! I need it to be a sata ssd, I recently bought a Crucial MX500 which failed while I was installing Windows and wasn't able to detect again. Now I'm thinking on a 1TB Samsung 870 Evo, but reading some posts in this subreddit apparently it has a high failure rate as well? I thought Samsung would be reliable but I don't know what to expect or buy anymore."},
{"Title": "Recommended temporary external drives?", "Author": "u/DisasterSpinach", "Content": "I might not be asking in the right place because my goal isn't to set up something that is highly systematic or robust at this time.\n  \n\n    The place I'm renting has serious roof issues and a bunch of my stuff was water damaged. I'm trying to salvage what I can to some portable drives and get the most important belongings out as soon as I can.\n  \n\n    In the past I remember Easystores/WD Elements being popular here, but apparently they have different drives inside now or high failure rates or something?\n  \n\n    And then I was just going to go with whatever Costco carried, but at this time that's only the doomed Sandisk SSDs.\n  \n\n    Anyone have any recommendations? Doesn't have to be perfect, just reasonably priced.\n  \n\n    Just looking to buy two drives for about $300-500 total. I guess HDDs preferred if they are decently reliable and not SMR.\n  \n\n    EDIT: OK externals are all apparently crap? \nhttps://www.reddit.com/r/DataHoarder/comments/146hb9k/information_about_cmr_to_smr_manufacturer/\n\n\n\n    Maybe I'll just roll the dice on those Sandisk SSDs.."},
{"Title": "Has anyone else ever experienced this? 20TB Exos white label results in my ssd activity spiking to 100% and boot issues", "Author": "u/good4y0u", "Content": "I recently purchased a 20TB Exos white label drive from eBay, which was advertised as a Seagate refurbished drive. The serial numbers do trace back to Seagate, but I'm experiencing some unusual issues with it. Has anyone else encountered this?\n  \n\n    Here's what's happening when I test it with my Windows machine:\n  \n\n\n\n\n\n    With the machine powered off, I plug in the drive, but the machine doesn't boot.\n  \n\n\n\n\n\n    With the machine powered off, I boot to BIOS, and the disk is found. However, after rebooting, the machine doesn't boot.\n  \n\n\n\n\n\n    If I unplug the drive after step 2, the machine boots normally.\n  \n\n\n\n\n\n    If I plug the drive back in at the login screen, the machine freezes.\n  \n\n\n\n\n\n    If I log in first and then plug the drive in, I can see the task manager showing max activity on my main OS SSD before the machine freezes. Unplugging the drive at this point unfreezes the machine.\n  \n\n\n\n\n\n    I've bought a number of drives this way before and never had a serious issue. Any insights or suggestions would be greatly appreciated. In the meantime I am reaching out to the seller. The other drive I got seems to work fine."},
{"Title": "Modular NAS build", "Author": "u/Mother_Occasion_8076", "Content": "No content"},
{"Title": "I finally migrated off my old Drobo! What's the bottom line wit SoftRaid? Do I need to pay for the premium license?", "Author": "u/Splitsurround", "Content": "So against ALL odds I did get all my data safely off a dying Drobo, onto a High Point 4 bay enclosure with four 16Tb drives. I made it Raid 5 using Softeraid's trial, and so far, so good.\n  \n\n    I'm trying to wrap my head around paying for the SoftRaid premium or not: I've read all the FAQs and as far as I can tell, the only things I can't do without premium is create new raids and use their monitoring feature.\n  \n\n    I understand about the new volume thing but...if I \ndon't\n upgrade to premium, since I won't be able to use their monitoring, how will I know when a disk is dying or is dead?"},
{"Title": "Data management approach", "Author": "u/nlj1978", "Content": "Narrowing down my approach and looking for some additional guidance. Complete novice to home server operation.  After discussion in another thread, I've decided to not go with Windows OS on the server and instead run a Linux based OS so some sort.\n  \n\n    My hardware is a i5-9500 with 8gb or ram. In terms of storage I have a 256gb m2 NVME, 2x 10tb HDD and a 256g 2.5\" SSD if it is useful in some way. This leaves me with 2 sata3 ports(1 if I use the 2.5\" SSD) and 1 m2 slot available for further expansion of storage.\n  \n\n    Initial intended uses are to run JellyFin media server, Home Assistant and an image management app for pics, all local.\n  \n\n    I would like full redundancy via raid1, this is where I'm a bit uncertain on approach.\n  \n\n    I assume I'll run the OS and any apps on the NVME, not the HDD. Since i have the additional NVME slot available is there benefit to adding a second NVME drive for cache or even a mirror of the OS and apps?\n  \n\n    Should I be looking to manage my raid with an application of some sort or in the Debian OS itself?\n  \n\n    If the raid is setup in Debian, how does that affect future expansion? Do i have to add pairs of drives or could I for example just add a 18tb random drive?\n  \n\n    If for example a year from now I add 2 additional drives, at that time would there be a better solution than raid1?\n  \n\n    Thanks for your time."},
{"Title": "PlutoTV - Downloading episodes from live channel (ondemand not available)", "Author": "u/pstNN", "Content": "Hi all,\n  \n\n    I've been waiting for this show to be released online for ages and it just released this week, however, there doesn't seem to be any plans to make it on demand, which means I cant use StreamFab.\n  \n\n    Does anyone know of a way to download episodes without the ads/commercials from a live stream on PlutoTV france?\n  \n\n    This is the link. If there is a paid software for it, i have no problem buying it.\n  \n\n\nhttps://pluto.tv/fr/live-tv/662a622b5e2370000800f392\n\n\n\n    Thanks!"},
{"Title": "Donating space", "Author": "u/noideawhatimdoing444", "Content": "I'm not at the place where I can donate space on my server but eventually I will be. I'd like to give support to pages like Wikipedia or any other project I feel aligns with my values. Is that something thats even feasible?"},
{"Title": "Megaraid 9271-8i Dying - How do I replace it without data loss?", "Author": "u/Barja_Bardagi", "Content": "(Cross-posting a couple places to hopefully find help)  I've got a DIY NAS that I built a number of years ago based on a Megaraid 9271-8icc. There's 8x HDD RAID-50 array on it, and a 6x SSD RAID-6 array. Well, last Sunday, the card started dying. The machine's boot drives are NOT on the raid controller, and every few reboots, the card works for a while and then craps out. So, I bought a new (used) card from eBay.\n  \n\n    Now, storage is NOT my forte. I know enough to be dangerous to myself. How do I go about replacing the failing card without losing all my data? Will the new card see data on the drives and realize \"Oh, this is part of an array\"? Do I need to try to recover some settings from the old card? Could someone explain this to me like I'm an end user? :P"},
{"Title": "Instaloader hits login wall with VPN", "Author": "u/patagonianlamb", "Content": "A few weeks back, I managed to scrape a good amount of data from Instagram using a VPN and Instaloader without even logging in. It was great! But now, whenever I try to access Instagram through a VPN, it just takes me straight to the login page. Instaloader can't bypass the login wall either. Is this the end of accessing Instagram media without logging in via a VPN?"},
{"Title": "Refurbished NAS Hard Drives… Ye or Ne?", "Author": "u/maximumkush", "Content": "Starting my first NAS to fuel my addiction. I’m starting off with RAID 5 with 3 12tb hard drives. I found some decent priced refurbished ones. Asking the pros for their honest opinion"},
{"Title": "Would you not use a certified refurbished 20tb drive for parity?", "Author": "u/NotAnADC", "Content": "Asking specifically if I should only use a drive like that for expansion and not parity, cause maybe parity sees more action. Running in unraid. I know a lot of people like and trust serverpartdeals"},
{"Title": "How often should I update/refresh my cold storage?", "Author": "u/largePenisLover", "Content": "For cold/\"off-site\" storage of backups I use few HDD's. Backups go on them and then I store them nice and safe in a brick shed as an off-site kinda thing. They contain full backups. Disk is wiped and then a fresh backup goes on. I do this a few times a year. Not a real schedule to it.\n  \n\n    I fear bitrot.\nHow often should I refresh them to manage the chance of bitrot happening?\nWould it even help? I mean yes I wrote new data but the metal still aged."},
{"Title": "almost entirely geoblocked youtube videos?", "Author": "u/koalahugthekoala", "Content": "hi! so i have some important videos that are related to my special interest but have been geoblocked outside kosovo, somaliland, and northern cyprus. i know they still exist so what tool would i use to get them?\n  \n\n    i have no idea how github or anything works so that kinda rules out youtubedl unless someone did it for me. they are not on the wayback machine.\n  \n\n    here's the links if this helps you! \nhttps://youtube.com/watch?v=b7TYi0FwR1M\n \nhttps://youtube.com/watch?v=xmKYxwXox5g\n \nhttps://youtube.com/watch?v=AJr9VOCe1yY\n \nhttps://youtube.com/watch?v=FMLjygFXB7w\n \nhttps://youtube.com/watch?v=ZhLJyHxRuu8\n \nhttps://youtube.com/watch?v=mHU6dS07cZQ\n \nhttps://youtube.com/watch?v=Z6S5klRoI_c\n \nhttps://youtube.com/watch?v=AVeE9NMfAxE\n thank u for any help!"},
{"Title": "How do i rip a copy protected DVD?", "Author": "u/Icy-Composer9021", "Content": "I have some DVDs i wanna rip onto my computer and put on my ipod, specifically some simpsons and avp if it matters. Also region code is 2 or PAL on the simpsons."},
{"Title": "Personal NAS OS: Debian/Ubuntu vs TrueNAS or Rockstor", "Author": "u/PuzzleHeadPistion", "Content": "I have a personal NAS built on a i5-4690 with 16Gb RAM, which I use for archived work files (music, photos and videos), backups from my computers and as Plex Server. Services like ownCloud or something that would allow me to share files via url (like a personal WeTransfer) would be extremely useful. Maybe a system with ZFS would be good.\n  \n\n    I'm trying to decide whether to build from scratch on a full OS (Debian, Ubuntu or even Windows 2022?) vs something like TrueNAS or Rockstor. I haven't used Linux in almost 10y, but I used to use Arch.\n  \n\n    Not sure if it's relevant, but I also own an Asustor Drivestor 2 Lite and a ZenWifi XT9 router with a drive attached, use WireGuard VPN, etc."},
{"Title": "Samsung 8tb qvo ssd reliability", "Author": "u/ChillCaptain", "Content": "I bought the 8tb Samsung qvo ssd for a gaming/Roms drive.\n  \n\n    I know performance is meh and tbw is not great. But I don’t expect to write a lot to the drive. Copy my Roms and games once and switch out the games every so often.\n  \n\n    I’m mainly concerned with reliability. Id imagine it would be better than a spinning hard drive. Any opinions on reliability?"},
{"Title": "[HDD] 14TB Refreshed WD Ultrastar Hard Drive w/ 5 Year Warranty - $99.99 (NewEgg)", "Author": "u/Axodique", "Content": "No content"},
{"Title": "Quick question about IDM", "Author": "u/redskies1991", "Content": "Can i save my download location to an external drive (external ssd) ? Does it work.. coz i want to lessen the \"rebuilding\" time when i download large file sizes.."},
{"Title": "How to Download a Video off of Europeana?", "Author": "u/thxdley", "Content": "Sorry, i dunno if this belongs here but i dont know where else to put it. I'm pretty sure Europeana embeds the videos or something (i have no clue how any of it works) but when i try downloading the video it gives me a \"raw.html\"  which my computer wont download. Is it impossible to get my hands on this? I dont want to screen record it because of background noise/low quality/lag. Below is the link to the video im trying to download on Europeana.\n  \n\n\nhttps://www.europeana.eu/item/2051918/data_euscreenXL_EUS_0BCE32473CEBA87D2DB36A87B5511130"},
{"Title": "Does anyone know the IBM TS3500 Tape Library (IBM 3592 JC/JY)?", "Author": "u/_c0der", "Content": "Hi all,\n  \n\n    does anyone know the IBM TS3500 Tape Library with the corresponding IBM 3592 JC/JY type drives and tapes?\n  \n\n    I can have a full rack for free - where is the catch? Is it worth it?\n  \n\n    Power and space isn't an issue.\n  \n\n    Pictures: \nhttps://imgur.com/a/mjwmvI6"},
{"Title": "Is there info on failure rate of SSD vs spinning HD", "Author": "u/SlothChunks", "Content": "Hi everybody, I am trying to decide whether to buy a larger capacity drive to replace my two old Samsung SSDs that are 1TB and 500gb.\n  \n\n    When I looked at Amazon I saw that there are many options of new models if standard spinning drives for much less.\n  \n\n    As far as I know from reading over the years spinning drives are more likely to fail than the spinning disk drives.  But I haven’t ever actually seen the test data to see just how likely or unlikely they are to break compared to SSD.\n  \n\n    If this drive is going to be used only at home and not carried anywhere, does anyone have any idea just how much more likely it is to fail than an SSD?\n  \n\n    Bonus: question, are WesternDigital SSDs any better or worse than Samsung? Or are there any established brands are are absolutely better to avoid?"},
{"Title": "Equipment recommendations", "Author": "u/Broke_Bearded_Guy", "Content": "I was looking at buying a storage drawer preferably a 4U 60bay. I've seen some of the newer HGST units available but I've seen some posts about requiring proprietary drives I didn't know if anyone could make a recommendation my only real requirement is 120v compatible"},
{"Title": "just wondering if others with IDM also have this problem", "Author": "u/Street_Mine_1969", "Content": "for the last 3 days my IDM pop up download bar does not show on youtube and youtube only. other other video site is still okay and can download without problem. anyone else with IDM have this problem with youtube?"},
{"Title": "how do you batch select on czkawka?", "Author": "u/randomusername11222", "Content": "there is this select windows\n  \nhttps://preview.redd.it/how-do-you-batch-select-on-czkawka-v0-u0bmvpoaim6d1.png\n\n    But I cant like multiselect the files that I want manually?"},
{"Title": "Which SATA Ssd should I buy in 2024?", "Author": "u/eliosferre3", "Content": "Hi! I need it to be a sata ssd, I recently bought a Crucial MX500 which failed while I was installing Windows and wasn't able to detect again. Now I'm thinking on a 1TB Samsung 870 Evo, but reading some posts in this subreddit apparently it has a high failure rate as well? I thought Samsung would be reliable but I don't know what to expect or buy anymore."},
{"Title": "Recommended temporary external drives?", "Author": "u/DisasterSpinach", "Content": "I might not be asking in the right place because my goal isn't to set up something that is highly systematic or robust at this time.\n  \n\n    The place I'm renting has serious roof issues and a bunch of my stuff was water damaged. I'm trying to salvage what I can to some portable drives and get the most important belongings out as soon as I can.\n  \n\n    In the past I remember Easystores/WD Elements being popular here, but apparently they have different drives inside now or high failure rates or something?\n  \n\n    And then I was just going to go with whatever Costco carried, but at this time that's only the doomed Sandisk SSDs.\n  \n\n    Anyone have any recommendations? Doesn't have to be perfect, just reasonably priced.\n  \n\n    Just looking to buy two drives for about $300-500 total. I guess HDDs preferred if they are decently reliable and not SMR.\n  \n\n    EDIT: OK externals are all apparently crap? \nhttps://www.reddit.com/r/DataHoarder/comments/146hb9k/information_about_cmr_to_smr_manufacturer/\n\n\n\n    Maybe I'll just roll the dice on those Sandisk SSDs.."},
{"Title": "Has anyone else ever experienced this? 20TB Exos white label results in my ssd activity spiking to 100% and boot issues", "Author": "u/good4y0u", "Content": "I recently purchased a 20TB Exos white label drive from eBay, which was advertised as a Seagate refurbished drive. The serial numbers do trace back to Seagate, but I'm experiencing some unusual issues with it. Has anyone else encountered this?\n  \n\n    Here's what's happening when I test it with my Windows machine:\n  \n\n\n\n\n\n    With the machine powered off, I plug in the drive, but the machine doesn't boot.\n  \n\n\n\n\n\n    With the machine powered off, I boot to BIOS, and the disk is found. However, after rebooting, the machine doesn't boot.\n  \n\n\n\n\n\n    If I unplug the drive after step 2, the machine boots normally.\n  \n\n\n\n\n\n    If I plug the drive back in at the login screen, the machine freezes.\n  \n\n\n\n\n\n    If I log in first and then plug the drive in, I can see the task manager showing max activity on my main OS SSD before the machine freezes. Unplugging the drive at this point unfreezes the machine.\n  \n\n\n\n\n\n    I've bought a number of drives this way before and never had a serious issue. Any insights or suggestions would be greatly appreciated. In the meantime I am reaching out to the seller. The other drive I got seems to work fine."},
{"Title": "Modular NAS build", "Author": "u/Mother_Occasion_8076", "Content": "No content"},
{"Title": "I finally migrated off my old Drobo! What's the bottom line wit SoftRaid? Do I need to pay for the premium license?", "Author": "u/Splitsurround", "Content": "So against ALL odds I did get all my data safely off a dying Drobo, onto a High Point 4 bay enclosure with four 16Tb drives. I made it Raid 5 using Softeraid's trial, and so far, so good.\n  \n\n    I'm trying to wrap my head around paying for the SoftRaid premium or not: I've read all the FAQs and as far as I can tell, the only things I can't do without premium is create new raids and use their monitoring feature.\n  \n\n    I understand about the new volume thing but...if I \ndon't\n upgrade to premium, since I won't be able to use their monitoring, how will I know when a disk is dying or is dead?"},
{"Title": "Data management approach", "Author": "u/nlj1978", "Content": "Narrowing down my approach and looking for some additional guidance. Complete novice to home server operation.  After discussion in another thread, I've decided to not go with Windows OS on the server and instead run a Linux based OS so some sort.\n  \n\n    My hardware is a i5-9500 with 8gb or ram. In terms of storage I have a 256gb m2 NVME, 2x 10tb HDD and a 256g 2.5\" SSD if it is useful in some way. This leaves me with 2 sata3 ports(1 if I use the 2.5\" SSD) and 1 m2 slot available for further expansion of storage.\n  \n\n    Initial intended uses are to run JellyFin media server, Home Assistant and an image management app for pics, all local.\n  \n\n    I would like full redundancy via raid1, this is where I'm a bit uncertain on approach.\n  \n\n    I assume I'll run the OS and any apps on the NVME, not the HDD. Since i have the additional NVME slot available is there benefit to adding a second NVME drive for cache or even a mirror of the OS and apps?\n  \n\n    Should I be looking to manage my raid with an application of some sort or in the Debian OS itself?\n  \n\n    If the raid is setup in Debian, how does that affect future expansion? Do i have to add pairs of drives or could I for example just add a 18tb random drive?\n  \n\n    If for example a year from now I add 2 additional drives, at that time would there be a better solution than raid1?\n  \n\n    Thanks for your time."},
{"Title": "PlutoTV - Downloading episodes from live channel (ondemand not available)", "Author": "u/pstNN", "Content": "Hi all,\n  \n\n    I've been waiting for this show to be released online for ages and it just released this week, however, there doesn't seem to be any plans to make it on demand, which means I cant use StreamFab.\n  \n\n    Does anyone know of a way to download episodes without the ads/commercials from a live stream on PlutoTV france?\n  \n\n    This is the link. If there is a paid software for it, i have no problem buying it.\n  \n\n\nhttps://pluto.tv/fr/live-tv/662a622b5e2370000800f392\n\n\n\n    Thanks!"},
{"Title": "Donating space", "Author": "u/noideawhatimdoing444", "Content": "I'm not at the place where I can donate space on my server but eventually I will be. I'd like to give support to pages like Wikipedia or any other project I feel aligns with my values. Is that something thats even feasible?"},
{"Title": "Couple question to get started", "Author": "u/EvenRD", "Content": "Hello, i tried checking in the wiki or in FAQs but i couldn't find anything of use. I am considering starting hoarding files on physical drives since my online cloud is full and i don't want to pay a monthly fee. A couple questions:\n  \n\n\n\n\n\n    Should i? I need space to save personal files, photos and videos. Right now i think i could have all my storage done with 1TB, but for the sake of futereproofing and redundancy i think i should aim for 4TB. I still don't know if its convenient or should i just suck it up and pay online cloud services\n  \n\n\n\n\n\n    Do i need a NAS? I do all my work from my main computer so what i am basically thinking is just to add a RAID 5 HDD to my existing setup and call it a day, is there some reason i should NOT do?\n  \n\n\n\n\n\n    Since HDD tend to get noisy i'd like to shut them off when they are not needed, this way i can save energy as well"},
{"Title": "Twitter extension to download videos inside the page", "Author": "u/findthatgayporn", "Content": "Anyone knows a good one? I have two installed but have to open a new tab for each video I want to download; I need a extension to click and start downloading"},
{"Title": "Sending large files online solution?", "Author": "u/backflipbadboy", "Content": "I found the website \nhttps://tempfile.me\n who are claiming privacy + encryption when uploading large files online up to 10GB per file has anyone used such a service?"},
{"Title": "G-technology 6tb fair used price? Reliability for Family Backup?", "Author": "u/myfacenotmyaccount", "Content": "Some guy near me has a couple of these for $90 each, I was thinking to buy a couple to back up all my families data and pictures, wondering if it was a good idea?\n  \n\n\nhttps://www.amazon.com/G-Technology-Thunderbolt-High-Performance-Solution-0G04023/dp/B00QJJ5362?th=1"},
{"Title": "New HDD test sequence", "Author": "u/sobo5o", "Content": "Got another 5TB external Seagate Expansion HDD and want to optimize my routine. The drive is originally in exFAT with some warranty content on it. I have Windows 10, so not using badblocks, but have HD Sentinel. My order is this:\n  \n\n    Minimum:\n  \n\n\n\n\n\n\nShort\n Long self-test (which will do an initial READ)\n  \n\n\n\n\n\n    Surface WRITE+Read with default 0's\n  \n\n\n\n\n\n    Quick format (to NTFS for use)\n  \n\n\n\n\n\n    Extensive:\n  \n\n\n\n\n\n    Short self-test\n  \n\n\n\n\n\n    Quick format (to NTFS, solely for the next step)\n  \n\n\n\n\n\n    Filling disk with large files (\nusing TeraCopy verify+test\n using H2TestW)\n  \n\n\n\n\n\n    Surface READ test\n  \n\n\n\n\n\n    Surface WRITE+Read with default 0's\n  \n\n\n\n\n\n    Surface WRITE+Read with 1's (\n0xFF)\n\n\n\n\n\n\n\n    Surface WRITE+Read back with 0's\n  \n\n\n\n\n\n    Quick format (to NTFS)\n  \n\n\n\n\n\n    Alternatively, badblocks instead of steps 5-7, or full u/\nEchoGecko795\n routine below in the comments.\n  \n\n    Thanks to everyone, all questions answered!\n  \n\n    Some notes:\n  \n\n\n\n\n\n\nExtended self-test\n can be skipped, as it just \nshort self-test\n + \nREAD test\n sequence \nwithin\n the drive, just less informative than the \nSurface read test\n as doesn't consider connectivity performance\n  \n\n\n\n\n\n\nFull format\n in Windows isn't needed, as it's the same as \nSurface READ + WRITE\n (with 0's) tests, maybe more limited, and \nquick format\n is enough just to change the filesystem\n  \n\n\n\n\n\n    Different surface write+read patterns emulate the 4-pass badblocks test\n  \n\n\n\n\n\n    A few things I wanted to clarify:\n  \n\n\n\n\n\n    how redundant is filling the drive with files, considering further WRITE+Read surface test? Does it only serve as another WRITE pass, just with different data?\n  \n\n\n\n\n\n    do I really need the \nRead test\n before the \nWRITE+Read test\n, or is the latter enough? (i.e. can a READ \nbefore\n WRITE indicate something that a READ \nafter\n WRITE won't?). My idea was to see the initial READ after the drive is filled with files, then overwriting it with 0's and reading again\n  \n\n\n\n\n\n    how important is changing the pattern/flipping 0's to 1's?\n  \n\n\n\n\n\n    should I flip 1's to 0's back again? Can the 1's pattern remain, following a quick format prior to using the drive?\n  \n\n\n\n\n\n    And finally, is the more time-consuming 3-4 pass procedure really worth it, and not an overkill?"},
{"Title": "Regarding Uloz.to", "Author": "u/HakimOne", "Content": "Hi,\n  \n\n    Any thoughts on \nhttps://ulozto.net\n ? Their plans look too good to be true. 10 TB for 6 EURO, 50 TB for only 15 EURO. Rclone recently added \nUloz.to\n support."},
{"Title": "Shucking an old WD My Book?", "Author": "u/EdiblePwncakes", "Content": "I have this really old WD MyBook that I'm trying to backup the data off of. However the drive doesn't seem to spin at all even though the enclosure is powered on. It's a very old model, so much so that I can't quite find much info on it through a search online - its model is WD5000P302.\n  \n\n    I want to shuck it in hopes of preserving the data - however I've heard that these old WD MyBooks have some sort of drive encryption that might prevent this? Does anyone have any experience with this? The drive must be at least 10 years old if I were to guess.\n  \n\n    Or if the drive doesn't spin at all then might it be completely dead? Thanks for any advice.\n  \nhttps://preview.redd.it/shucking-an-old-wd-my-book-v0-hyto1szn9l6d1.jpg\nhttps://preview.redd.it/shucking-an-old-wd-my-book-v0-sr1olvho9l6d1.jpg"},
{"Title": "How do you go about pruning your hoard?", "Author": "u/Clive1792", "Content": "Personally I feel snowed under with what I've got. There's countless files on my PC scattered everywhere. Documents, pictures (probably in the 100,000s), audio files, video files. It's most certainly not organised at all, it's scattered all over the hard drives on this PC in various folders & folders of folders.\n  \n\n    But to make it better I had no real backup plan. I'd just drag & drop and then not really remember what I'd backed up and what I hadn't so then I'd buy a new hard drive & make another copy because the last drive was fairly full.\n  \n\n    I now have a number of drives that surely have many multiples of various single files.\n  \n\n    My end goal is I would like some organisation rather than random files & folders scattered here there & everywhere. I'd like to get rid of the multiple duplicate files & also delete files I no longer want/need.\n  \n\n    Have any of you attacked this kind of task? Any tips or do you really just do it file-by-file? Which to be honest with what I've got & the fact I only have limited time outside of work, this is going to take me many months if not 12months plus .... and that's if I get stuck in & stay focused doing it day in day out."},
{"Title": "Recommendations for changing my 40 drive setup", "Author": "u/Professional_Lychee9", "Content": "I currently have a 45bay supermicro SAS2 JBOD enclosure with 40x 16TB Exos X16 enterprise drives in it. I would like to upgrade to SAS3. I have 2 options:\n  \n\n\n\n\n\n    Keep all drives together and use a single server to connect to it\n  \n\n\n\n\n\n    Split the drives into 2-4 enclosures and connect them each to a server\n  \n\n\n\n\n\n    I have a kubernetes cluster with 3x R630s and 1x R730. and looking to use Rook/Ceph to surface these drives to Minio. IT is currently connected to the R730 via an LSI SAS3 16e card.\n  \n\n    what enclosures might you recommend? I was looking at the D60 but cant tell if it will take SATA drives. I also cant seem to find smaller enclosures (12-15 bays) that dont also need CPU/Mobo/RAM. just want a JBOD enclosure"},
{"Title": "how to download videos from just for fans?", "Author": "u/m300n", "Content": "hi, i was wondering if anyone here knows how to save videos from just for fans?"},
{"Title": "Moving large files online?", "Author": "u/ParticularTreacle446", "Content": "I need to send a large number of files over the internet without the need of buying hardware. i came accross this website has anyone used it? if so please share your thoughts. \ntempfile.me"},
{"Title": "I know iCloud is not considered a backup but..", "Author": "u/askinghawking", "Content": "I know iCloud is more considered as a sync service but do you think I can use it as a backup how I do it?\n  \n\n    I have a Mac that is only a backup tool. Means that I get all photos and documents to the Mac + iCloud there from my iphone - with a different iCloud account. So it couldn‘t happen that I delete a picture from my phone and is deleted everywhere.\n  \n\n    Would you consider it a cloud backup or would you use something else in addition? (Or course, it is also all backup up on a ssd to follow 3-2-1)"},
{"Title": "what are your predictions of IA lawsuit and is there any website archiving the archive?", "Author": "u/legz2006", "Content": "saw vid more muta(someordinarygames) about the lawsuit, something ive been keeping up with adn was wondering, will all that data just vanish?"},
{"Title": "Quiet HL15 Build help", "Author": "u/NextRedditAccount0", "Content": "I'm planning to pick up an HL15 to replace my Synology DS2415+.\nMy current DS2415+ is not the quietest thing in the world but the noise is manageable considering its a few feet away from my desk and bed. I'm also running 8x8TB shucked WD easystore drives in there.\n  \n\n    My plan is to pickup the HL15 and move all the drives over AND purchase some new larger drives since my pool is roughly 70% full and i'm planning to fill it up some more.\n  \n\n    Some questions.\nHow loud is the HL15? I'm planning on picking up the HL15 with the Noctua fans option.\nAny recommendations for quiet or quietish 12tb+ drives? I'm going to grab them from \nserverpartdeals.com\nI saw some videos with PWL drives and that thumping would drive me crazy. I hope the HL15 has some form of noise damping if PWL drives are my only option.\n  \n\n    Would love some feedback before I hit the buy button on this one."},
{"Title": "RAID 5 controller for Win 11 Workstation", "Author": "u/Heinrich_v_Schimmer", "Content": "As a photographer, I generate more than a TByte of data per month and therefore have a RAID 5 on my work system. The controller used for this RAID runs into problems with the energy saving modes of Windows; when the system wakes up from sleep mode, the drive is no longer visible in Explorer until a complete reboot.\n  \n\n    Does anyone know of a RAID 5 controller that can cope with the energy saving modes of Windows 11?\n  \n\n    PS: Software (OS) RAIDs are not an option."},
{"Title": "Using a homelab as a cache server for my cloud storage?", "Author": "u/sqenixs", "Content": "I'm looking to set up a homelab pc where it will have about 10TB of storage.  I also have a backblaze B2 bucket I will use for cloud storage.  I would like to use the homelab PC as a sort of cache drive where when I am at home I can use it, and when I am away I can connect to my backblaze b2 bucket directly from my laptop.  For example, I could open a word doc, make a few changes, and it would sync automatically to my cloud and NAS.  However the cloud would have more storage so I envision a scenario where my laptop would run out of space so I would keep some files \"cloud only\" and they would be on the NAS when at home or in the backblaze cloud when away.  However, some files I might want to only keep in the cloud and not on my laptop or NAS.  Is this possible?"},
{"Title": "looking for something similar to Qsync", "Author": "u/niloproject", "Content": "Hi everyone, I could use some help. I've put together a NAS for my business and I was wondering if there were any alternatives to Qnap Qsync that would work with Truenas. (I also asked this in the truenas server but figured it would hurt to ask here too). The functionality in specific that I'm looking for is the ability to create users that can then establish a two way sync with the server, but similar to with Qsync, there would ideally be a smart sync that would only download what users actually need locally and not anything that isn't necessary to their work so they're not having to deal with terabytes of storage being synced.  They could then work directly on the mounted drive from their machines and anything they create will be synced to everyone and they won't have to worry about manually downloading/duplicating files on the server.\n  \n\n    When building this I didn't realize how hard it would be to find a tool for this, and everything I've found just isn't very useful. Syncthing is not helpful, its not smart and would require everyone mirror 20tb of files (unless im misunderstanding what it does.) SMB sharing technically works but is too slow for people to work off of for our purposes as our files have huge datarates (multilayer EXR sequences, 1gb a frame kind of stuff).  I'm also experimenting with Google Workspace to see if that works any better for this but I'd figure I'd ask for help before I go down that road.\n  \n\n    If any of you have any experience with this or could maybe point me to a client-side software that can manage client side downloads from the server in a smart way like Qsync that would be amazing."},
{"Title": "Need recommendations for USB3 or eSata external drive to connect to router for FTP server.", "Author": "u/mufasis", "Content": "What’s going on data hoarders. I’m looking for a network drive I can connect to my router, USB3 or eSata. Will be used to store stuff on my home network as well as serve files by FTP, mostly music files and projects I need to share.\n  \n\n    Also what would be better USB3 or eSata?\n  \n\n    Looking for speed and reliability, thanks!"},
{"Title": "External Hard Drive for High Humidity Conditions", "Author": "u/BrEichen", "Content": "I'm gonna be living in a peat swamp forest in Borneo for a year and am looking to bring a hard drive to store movies, TV, and photos on as I will not have reliable internet access. Where I'll be the humidity is so high clothes and technology are stored in plastic bins w/ silica packets when not in use. I was wondering if anyone could recommend an external hard drive that could hold up to these conditions (if such a thing even exists). Sorry if this is a dumb or already answered question, pretty new to this stuff. Thanks!"},
{"Title": "YouTube is testing server-side ad injection into video streams (per SponsorBlock Twitter)", "Author": "u/ThePixelHunter", "Content": "No content"},
{"Title": "Is there a way to sync between devices using a usb cable?", "Author": "u/vrtqlwlpl", "Content": "Currently there is a programme called Syncthing which enables the wireless syncing of files between devices. It does not store data on the servers - rather, two devices have to be online at the same time for data to be synced. It's been a while so I don't remember the mechanisms through which it operates\n  \n\n    There are a couple of downsides. First being that wireless syncing is slow, second being that errors are more common with wireless syncing (from my experiences).\n  \n\n    Imagine a folder and imagine that every day I make a few changes to the files within it. I need the ability to sync all the changes within the folder for 2 devices. If I do not sync them, I would have to comb the entire folder for every change and apply them one by one OR delete the folder and paste the updated folder from my PC. It is around 50GB so it would take a while to paste\n  \n\n    I'd probably sync twice a week"},
{"Title": "Increasing the redundancy/error-correction of a partition?", "Author": "u/metal_wires", "Content": "I have a 2TB external HDD, and I have created a 256GB partition which is an encrypted VeraCrypt volume. I was thinking, that since I have more than 1.5TB space leftover, is it possible to use some of that remaining space to add parity data or error correction for this VeraCrypt partition, to protect against bit rot?\n  \n\n    I have tried searching all over the Internet for a tool that would let me create a \"error correction partition\" which stores ECC for the VeraCrypt partition, but I cannot find it. At most, I can find references to RAID 5, but I don't have multiple drives, just this one."},
{"Title": "I bought a sas controller LSI 9240-8i SAS SATA RAID Controller Card drives", "Author": "u/Unusual-Ingenuity831", "Content": "I need help installing it i bought this to use my sas hard drive but i have plugged it in and everything and it still wont work so i need help"},
{"Title": "How to download the video content from Microsoft Lean On-demand training?", "Author": "u/HardLearner01", "Content": "How to download the video content of this site?\n  \n\n\nDP-100 Design a machine learning solution (1 of 6) | Microsoft Learn"},
{"Title": "NVMe SSD based storage computer", "Author": "u/aes100", "Content": "If you were to build a storage computer based on NVMe SSDs, how would you do it? Nor datarate, nor storage space is priority. Just sheer number of NVMe SSDs... and you hate cables.\n  \n\n    Build#1: AMD Threadripper with PCIe to M.2 adapter cards. Because I think that is the only motherboard that has more than one or two PCIe slots. But Threadripper is overkill expensive for just storage and not worth it. I didn't do research on Intel side.\n  \n\n    Build#2: Get a server motherboard with lots of SATA ports and lots of SATA to M.2 adapters. Put the NVMe's in, and connect them to SATA ports. But you don't like cables.\n  \n\n    Build#3: Get a LattePanda Mu based on Intel N100 which they advertise a NAS carrier but I don't know if it exists yet or not. Or get a FriendlyELEC CM3588 based on Rockchip. You are free of cables, but are you gonna regret accessing the data on there because it is slow? Or is it actually fast enough to, I don't know, watch a video from it?\n  \n\n    What do you think about the above builds? What downs and ups do you think they have? How would you do it? Why?"},
{"Title": "Couple question to get started", "Author": "u/EvenRD", "Content": "Hello, i tried checking in the wiki or in FAQs but i couldn't find anything of use. I am considering starting hoarding files on physical drives since my online cloud is full and i don't want to pay a monthly fee. A couple questions:\n  \n\n\n\n\n\n    Should i? I need space to save personal files, photos and videos. Right now i think i could have all my storage done with 1TB, but for the sake of futereproofing and redundancy i think i should aim for 4TB. I still don't know if its convenient or should i just suck it up and pay online cloud services\n  \n\n\n\n\n\n    Do i need a NAS? I do all my work from my main computer so what i am basically thinking is just to add a RAID 5 HDD to my existing setup and call it a day, is there some reason i should NOT do?\n  \n\n\n\n\n\n    Since HDD tend to get noisy i'd like to shut them off when they are not needed, this way i can save energy as well"},
{"Title": "Twitter extension to download videos inside the page", "Author": "u/findthatgayporn", "Content": "Anyone knows a good one? I have two installed but have to open a new tab for each video I want to download; I need a extension to click and start downloading"},
{"Title": "Sending large files online solution?", "Author": "u/backflipbadboy", "Content": "I found the website \nhttps://tempfile.me\n who are claiming privacy + encryption when uploading large files online up to 10GB per file has anyone used such a service?"},
{"Title": "G-technology 6tb fair used price? Reliability for Family Backup?", "Author": "u/myfacenotmyaccount", "Content": "Some guy near me has a couple of these for $90 each, I was thinking to buy a couple to back up all my families data and pictures, wondering if it was a good idea?\n  \n\n\nhttps://www.amazon.com/G-Technology-Thunderbolt-High-Performance-Solution-0G04023/dp/B00QJJ5362?th=1"},
{"Title": "New HDD test sequence", "Author": "u/sobo5o", "Content": "Got another 5TB external Seagate Expansion HDD and want to optimize my routine. The drive is originally in exFAT with some warranty content on it. I have Windows 10, so not using badblocks, but have HD Sentinel. My order is this:\n  \n\n    Minimum:\n  \n\n\n\n\n\n\nShort\n Long self-test (which will do an initial READ)\n  \n\n\n\n\n\n    Surface WRITE+Read with default 0's\n  \n\n\n\n\n\n    Quick format (to NTFS for use)\n  \n\n\n\n\n\n    Extensive:\n  \n\n\n\n\n\n    Short self-test\n  \n\n\n\n\n\n    Quick format (to NTFS, solely for the next step)\n  \n\n\n\n\n\n    Filling disk with large files (\nusing TeraCopy verify+test\n using H2TestW)\n  \n\n\n\n\n\n    Surface READ test\n  \n\n\n\n\n\n    Surface WRITE+Read with default 0's\n  \n\n\n\n\n\n    Surface WRITE+Read with 1's (\n0xFF)\n\n\n\n\n\n\n\n    Surface WRITE+Read back with 0's\n  \n\n\n\n\n\n    Quick format (to NTFS)\n  \n\n\n\n\n\n    Alternatively, badblocks instead of steps 5-7, or full u/\nEchoGecko795\n routine below in the comments.\n  \n\n    Thanks to everyone, all questions answered!\n  \n\n    Some notes:\n  \n\n\n\n\n\n\nExtended self-test\n can be skipped, as it just \nshort self-test\n + \nREAD test\n sequence \nwithin\n the drive, just less informative than the \nSurface read test\n as doesn't consider connectivity performance\n  \n\n\n\n\n\n\nFull format\n in Windows isn't needed, as it's the same as \nSurface READ + WRITE\n (with 0's) tests, maybe more limited, and \nquick format\n is enough just to change the filesystem\n  \n\n\n\n\n\n    Different surface write+read patterns emulate the 4-pass badblocks test\n  \n\n\n\n\n\n    A few things I wanted to clarify:\n  \n\n\n\n\n\n    how redundant is filling the drive with files, considering further WRITE+Read surface test? Does it only serve as another WRITE pass, just with different data?\n  \n\n\n\n\n\n    do I really need the \nRead test\n before the \nWRITE+Read test\n, or is the latter enough? (i.e. can a READ \nbefore\n WRITE indicate something that a READ \nafter\n WRITE won't?). My idea was to see the initial READ after the drive is filled with files, then overwriting it with 0's and reading again\n  \n\n\n\n\n\n    how important is changing the pattern/flipping 0's to 1's?\n  \n\n\n\n\n\n    should I flip 1's to 0's back again? Can the 1's pattern remain, following a quick format prior to using the drive?\n  \n\n\n\n\n\n    And finally, is the more time-consuming 3-4 pass procedure really worth it, and not an overkill?"},
{"Title": "Regarding Uloz.to", "Author": "u/HakimOne", "Content": "Hi,\n  \n\n    Any thoughts on \nhttps://ulozto.net\n ? Their plans look too good to be true. 10 TB for 6 EURO, 50 TB for only 15 EURO. Rclone recently added \nUloz.to\n support."},
{"Title": "Shucking an old WD My Book?", "Author": "u/EdiblePwncakes", "Content": "I have this really old WD MyBook that I'm trying to backup the data off of. However the drive doesn't seem to spin at all even though the enclosure is powered on. It's a very old model, so much so that I can't quite find much info on it through a search online - its model is WD5000P302.\n  \n\n    I want to shuck it in hopes of preserving the data - however I've heard that these old WD MyBooks have some sort of drive encryption that might prevent this? Does anyone have any experience with this? The drive must be at least 10 years old if I were to guess.\n  \n\n    Or if the drive doesn't spin at all then might it be completely dead? Thanks for any advice.\n  \nhttps://preview.redd.it/shucking-an-old-wd-my-book-v0-hyto1szn9l6d1.jpg\nhttps://preview.redd.it/shucking-an-old-wd-my-book-v0-sr1olvho9l6d1.jpg"},
{"Title": "How do you go about pruning your hoard?", "Author": "u/Clive1792", "Content": "Personally I feel snowed under with what I've got. There's countless files on my PC scattered everywhere. Documents, pictures (probably in the 100,000s), audio files, video files. It's most certainly not organised at all, it's scattered all over the hard drives on this PC in various folders & folders of folders.\n  \n\n    But to make it better I had no real backup plan. I'd just drag & drop and then not really remember what I'd backed up and what I hadn't so then I'd buy a new hard drive & make another copy because the last drive was fairly full.\n  \n\n    I now have a number of drives that surely have many multiples of various single files.\n  \n\n    My end goal is I would like some organisation rather than random files & folders scattered here there & everywhere. I'd like to get rid of the multiple duplicate files & also delete files I no longer want/need.\n  \n\n    Have any of you attacked this kind of task? Any tips or do you really just do it file-by-file? Which to be honest with what I've got & the fact I only have limited time outside of work, this is going to take me many months if not 12months plus .... and that's if I get stuck in & stay focused doing it day in day out."},
{"Title": "Recommendations for changing my 40 drive setup", "Author": "u/Professional_Lychee9", "Content": "I currently have a 45bay supermicro SAS2 JBOD enclosure with 40x 16TB Exos X16 enterprise drives in it. I would like to upgrade to SAS3. I have 2 options:\n  \n\n\n\n\n\n    Keep all drives together and use a single server to connect to it\n  \n\n\n\n\n\n    Split the drives into 2-4 enclosures and connect them each to a server\n  \n\n\n\n\n\n    I have a kubernetes cluster with 3x R630s and 1x R730. and looking to use Rook/Ceph to surface these drives to Minio. IT is currently connected to the R730 via an LSI SAS3 16e card.\n  \n\n    what enclosures might you recommend? I was looking at the D60 but cant tell if it will take SATA drives. I also cant seem to find smaller enclosures (12-15 bays) that dont also need CPU/Mobo/RAM. just want a JBOD enclosure"},
{"Title": "how to download videos from just for fans?", "Author": "u/m300n", "Content": "hi, i was wondering if anyone here knows how to save videos from just for fans?"},
{"Title": "Moving large files online?", "Author": "u/ParticularTreacle446", "Content": "I need to send a large number of files over the internet without the need of buying hardware. i came accross this website has anyone used it? if so please share your thoughts. \ntempfile.me"},
{"Title": "I know iCloud is not considered a backup but..", "Author": "u/askinghawking", "Content": "I know iCloud is more considered as a sync service but do you think I can use it as a backup how I do it?\n  \n\n    I have a Mac that is only a backup tool. Means that I get all photos and documents to the Mac + iCloud there from my iphone - with a different iCloud account. So it couldn‘t happen that I delete a picture from my phone and is deleted everywhere.\n  \n\n    Would you consider it a cloud backup or would you use something else in addition? (Or course, it is also all backup up on a ssd to follow 3-2-1)"},
{"Title": "what are your predictions of IA lawsuit and is there any website archiving the archive?", "Author": "u/legz2006", "Content": "saw vid more muta(someordinarygames) about the lawsuit, something ive been keeping up with adn was wondering, will all that data just vanish?"},
{"Title": "Quiet HL15 Build help", "Author": "u/NextRedditAccount0", "Content": "I'm planning to pick up an HL15 to replace my Synology DS2415+.\nMy current DS2415+ is not the quietest thing in the world but the noise is manageable considering its a few feet away from my desk and bed. I'm also running 8x8TB shucked WD easystore drives in there.\n  \n\n    My plan is to pickup the HL15 and move all the drives over AND purchase some new larger drives since my pool is roughly 70% full and i'm planning to fill it up some more.\n  \n\n    Some questions.\nHow loud is the HL15? I'm planning on picking up the HL15 with the Noctua fans option.\nAny recommendations for quiet or quietish 12tb+ drives? I'm going to grab them from \nserverpartdeals.com\nI saw some videos with PWL drives and that thumping would drive me crazy. I hope the HL15 has some form of noise damping if PWL drives are my only option.\n  \n\n    Would love some feedback before I hit the buy button on this one."},
{"Title": "RAID 5 controller for Win 11 Workstation", "Author": "u/Heinrich_v_Schimmer", "Content": "As a photographer, I generate more than a TByte of data per month and therefore have a RAID 5 on my work system. The controller used for this RAID runs into problems with the energy saving modes of Windows; when the system wakes up from sleep mode, the drive is no longer visible in Explorer until a complete reboot.\n  \n\n    Does anyone know of a RAID 5 controller that can cope with the energy saving modes of Windows 11?\n  \n\n    PS: Software (OS) RAIDs are not an option."},
{"Title": "Using a homelab as a cache server for my cloud storage?", "Author": "u/sqenixs", "Content": "I'm looking to set up a homelab pc where it will have about 10TB of storage.  I also have a backblaze B2 bucket I will use for cloud storage.  I would like to use the homelab PC as a sort of cache drive where when I am at home I can use it, and when I am away I can connect to my backblaze b2 bucket directly from my laptop.  For example, I could open a word doc, make a few changes, and it would sync automatically to my cloud and NAS.  However the cloud would have more storage so I envision a scenario where my laptop would run out of space so I would keep some files \"cloud only\" and they would be on the NAS when at home or in the backblaze cloud when away.  However, some files I might want to only keep in the cloud and not on my laptop or NAS.  Is this possible?"},
{"Title": "looking for something similar to Qsync", "Author": "u/niloproject", "Content": "Hi everyone, I could use some help. I've put together a NAS for my business and I was wondering if there were any alternatives to Qnap Qsync that would work with Truenas. (I also asked this in the truenas server but figured it would hurt to ask here too). The functionality in specific that I'm looking for is the ability to create users that can then establish a two way sync with the server, but similar to with Qsync, there would ideally be a smart sync that would only download what users actually need locally and not anything that isn't necessary to their work so they're not having to deal with terabytes of storage being synced.  They could then work directly on the mounted drive from their machines and anything they create will be synced to everyone and they won't have to worry about manually downloading/duplicating files on the server.\n  \n\n    When building this I didn't realize how hard it would be to find a tool for this, and everything I've found just isn't very useful. Syncthing is not helpful, its not smart and would require everyone mirror 20tb of files (unless im misunderstanding what it does.) SMB sharing technically works but is too slow for people to work off of for our purposes as our files have huge datarates (multilayer EXR sequences, 1gb a frame kind of stuff).  I'm also experimenting with Google Workspace to see if that works any better for this but I'd figure I'd ask for help before I go down that road.\n  \n\n    If any of you have any experience with this or could maybe point me to a client-side software that can manage client side downloads from the server in a smart way like Qsync that would be amazing."},
{"Title": "Need recommendations for USB3 or eSata external drive to connect to router for FTP server.", "Author": "u/mufasis", "Content": "What’s going on data hoarders. I’m looking for a network drive I can connect to my router, USB3 or eSata. Will be used to store stuff on my home network as well as serve files by FTP, mostly music files and projects I need to share.\n  \n\n    Also what would be better USB3 or eSata?\n  \n\n    Looking for speed and reliability, thanks!"},
{"Title": "External Hard Drive for High Humidity Conditions", "Author": "u/BrEichen", "Content": "I'm gonna be living in a peat swamp forest in Borneo for a year and am looking to bring a hard drive to store movies, TV, and photos on as I will not have reliable internet access. Where I'll be the humidity is so high clothes and technology are stored in plastic bins w/ silica packets when not in use. I was wondering if anyone could recommend an external hard drive that could hold up to these conditions (if such a thing even exists). Sorry if this is a dumb or already answered question, pretty new to this stuff. Thanks!"},
{"Title": "YouTube is testing server-side ad injection into video streams (per SponsorBlock Twitter)", "Author": "u/ThePixelHunter", "Content": "No content"},
{"Title": "Is there a way to sync between devices using a usb cable?", "Author": "u/vrtqlwlpl", "Content": "Currently there is a programme called Syncthing which enables the wireless syncing of files between devices. It does not store data on the servers - rather, two devices have to be online at the same time for data to be synced. It's been a while so I don't remember the mechanisms through which it operates\n  \n\n    There are a couple of downsides. First being that wireless syncing is slow, second being that errors are more common with wireless syncing (from my experiences).\n  \n\n    Imagine a folder and imagine that every day I make a few changes to the files within it. I need the ability to sync all the changes within the folder for 2 devices. If I do not sync them, I would have to comb the entire folder for every change and apply them one by one OR delete the folder and paste the updated folder from my PC. It is around 50GB so it would take a while to paste\n  \n\n    I'd probably sync twice a week"},
{"Title": "Increasing the redundancy/error-correction of a partition?", "Author": "u/metal_wires", "Content": "I have a 2TB external HDD, and I have created a 256GB partition which is an encrypted VeraCrypt volume. I was thinking, that since I have more than 1.5TB space leftover, is it possible to use some of that remaining space to add parity data or error correction for this VeraCrypt partition, to protect against bit rot?\n  \n\n    I have tried searching all over the Internet for a tool that would let me create a \"error correction partition\" which stores ECC for the VeraCrypt partition, but I cannot find it. At most, I can find references to RAID 5, but I don't have multiple drives, just this one."},
{"Title": "I bought a sas controller LSI 9240-8i SAS SATA RAID Controller Card drives", "Author": "u/Unusual-Ingenuity831", "Content": "I need help installing it i bought this to use my sas hard drive but i have plugged it in and everything and it still wont work so i need help"},
{"Title": "How to download the video content from Microsoft Lean On-demand training?", "Author": "u/HardLearner01", "Content": "How to download the video content of this site?\n  \n\n\nDP-100 Design a machine learning solution (1 of 6) | Microsoft Learn"},
{"Title": "NVMe SSD based storage computer", "Author": "u/aes100", "Content": "If you were to build a storage computer based on NVMe SSDs, how would you do it? Nor datarate, nor storage space is priority. Just sheer number of NVMe SSDs... and you hate cables.\n  \n\n    Build#1: AMD Threadripper with PCIe to M.2 adapter cards. Because I think that is the only motherboard that has more than one or two PCIe slots. But Threadripper is overkill expensive for just storage and not worth it. I didn't do research on Intel side.\n  \n\n    Build#2: Get a server motherboard with lots of SATA ports and lots of SATA to M.2 adapters. Put the NVMe's in, and connect them to SATA ports. But you don't like cables.\n  \n\n    Build#3: Get a LattePanda Mu based on Intel N100 which they advertise a NAS carrier but I don't know if it exists yet or not. Or get a FriendlyELEC CM3588 based on Rockchip. You are free of cables, but are you gonna regret accessing the data on there because it is slow? Or is it actually fast enough to, I don't know, watch a video from it?\n  \n\n    What do you think about the above builds? What downs and ups do you think they have? How would you do it? Why?"},
{"Title": "Can storage have a maximum amount of storage space?", "Author": "u/Card_Boxy", "Content": "Sorry if this question was worded weirdly, but I am looking to buy a new hard drive for my pre-built Lenovo IdeaCentre Gaming 5 17IAB7. I noticed that, according to the specs on the Product Specifications Reference it could only fit 2 3.5\" HDDs with a maximum of 2 TB, and 1 M.2 SSD with a max of 1 TB.\n  \n\n    What would happen if I were to buy and install a HDD / SSD larger than the reported maximum on the specifications sheet?\n  \n\n    Here's the actual pages I was looking at.\n  \n\n\nhttps://psref.lenovo.com/Detail/IdeaCentre/IdeaCentre_Gaming_5_17IAB7?M=90T00003US\n\n\n\n\nhttps://psref.lenovo.com/Product/IdeaCentre/IdeaCentre_Gaming_5_17IAB7\n\n\n\n    Thanks in advance for your times."},
{"Title": "Need help figuring how do archive part of a soon-to-die site", "Author": "u/Mode7GFX", "Content": "I posted this on stack overflow and they called me stupid (I am) and locked the question when someone was in the middle of actually helping me so I'm asking here because it's probably a more welcoming community for this sort of thing.\n  \n\n\nhttps://prcm.jp/list/akb48%20%E3%83%97%E3%83%AA\n\n\n\n    So this (formerly) huge Japanese image sharing site is shutting down in 2 weeks and my sister's begging me to archive at least some of it. I was trying to find a python script to automate it, cuz it will take me forever going one by one on tens of thousands of images, but I can't seem to find one that can archive this sort of website. It only goes by pages of 9 and the thumbnail images are shrunk down a ton so you have to click on the image twice to open the full size. Luckily it seems like every thumbnail image shares a name with the source image, but with an added suffix of the preview size, so I imagine it would be possible to have the script delete the underscore and re-add the .jpeg extension. As for going through pages, I'm not so sure on, but if I can input a list of URLs and just batch copy the original URL adding every page number (I know how to do this without a script), I could just use that.\n  \n\n    I was only going to download AKB48 related images, because most of these images aren't available anywhere else online, and soon won't be anywhere period. They're all old and thus fairly small, so I'm not too worried about it taking a long time to download.\n  \n\n    If anyone can direct me to a script that can do this or has some other mass image downloading method you're aware of, please let me know. Thanks!"},
{"Title": "Any hardware Raid 4-bay enclosures out there that ARE \"power disable\" compatible?", "Author": "u/09Klr650", "Content": "Perhaps my search-fu is lacking but all the small 4-bay hardware raid enclosures I find specifically state they are not Power Disable compatible. Before I go the whole \"kapton tape in pin 3\" route is there a manufacturer/model out there that is capable? Without costing an arm, leg and earlobe preferably.  This will be my first such setup and I want to KISS for the moment. Figure that (4) 12TB Reman HGST would be a good start. At Raid 5 that's approx 36TB. Or approximately 4x all my current motley collection of externals combined. Thanks."},
{"Title": "Best way to transfer data from one external ssd to another external ssd?", "Author": "u/alucvrdofficial", "Content": "Not sure if this is the right subreddit to post in, but as the title states, I purchased another external ssd, and I want to upload all of the data on my current ssd to this new one. Does anybody have suggestions for how to go about this? Can I just plug em both in and drag the folders over?\n  \n\n    Also, if this isn't the right place to ask, does anyone have suggestions on where to look?"},
{"Title": "Extension cable to disable Power Disable Feature on HDD?", "Author": "u/feedmememes", "Content": "I just purchased this HDD of Amazon: \nhttps://www.amazon.com/gp/product/B08T3PBV57/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&th=1\n\n\n\n    However it did not come with the power extension cable mentioned in the product description. I have purchased this drive before and it would not work without that cable, so it is necessary for me to get one for the HDD to work. My question is what would I search for the get the correct part? Would any sata-to-sata power extension work or would it need to have some special spec? I've read a 4-pin Molex to SATA connector might be the solution, but I would like to confirm before purchasing because I am dumb!! Something like this for example:\nhttps://www.amazon.com/Cable-Matters-3-Pack-Molex-Power/dp/B00STNUB04/ref=sr_1_2?crid=B3ZGL1OM3IR1&dib=eyJ2IjoiMSJ9.f9jru-Gy4n_1s6sxvx6tecrDs0kKyQc_KXFNnctPSyGpgk3wiTyXQRVjv8latROCZFMth35JZj6AzNa09K_WespKmumHEQjA1Qn9tuzw8MBtUCX9qyoxPfAfS1R9c3JLDgIR1NHveuutkNGIKTrnouyP5DBd2e2yp3U9bkzTz5b_jPWn4NWf9pusLWEVS3OvqcRsb74HYfa7bE5vtR5EWmod_f3B-fJJnotQO7qTLbE.4mkQvoblx472TPQkw3pPm3UzP8ULyibyZTNH-zpyBg4&dib_tag=se&keywords=Sata-to-sata+power+adapter+cable&qid=1718302912&sprefix=sata-to-sata+power+adapter+cable+%2Caps%2C84&sr=8-2\n\n\n\n    Or if there are any other solutions that would be helpful too.\n  \n\n    Sorry for noob question and thank you in advanced for any help!"},
{"Title": "Need help with magazine scanning - resolution vs size", "Author": "u/MyBallsSmellFruity", "Content": "So I'm scanning magazines at 300 dpi.  Any less, and the images look kind of cruddy.  Of course, the image size is pretty large, so I'm having to batch convert them to manually make the image height 1200 (width is auto calculated).\n  \n\n    Is this pretty much the only way to get both decent quality and an acceptable image size?  The actual filesize difference in the PDFs is pretty noticeable - and significant when doing hundreds of magazines.\n  \n\n    Or is there an easier way that I just haven't stumbled across?"},
{"Title": "Attempting to digitize some Beta tapes, but getting this rainbow banding through the picture.", "Author": "u/hmhsbritannic12", "Content": "No content"},
{"Title": "I'm 98% of the way there — help me across the finish line! (Syncing help)", "Author": "u/740990929974739", "Content": "MY FRIENDS!\n\n\n\n    I'm finally doing it. Bought a 12 TB External HDD + Backblaze (Computer Backup, not B2) so I can back up my scattered external drives to the big HDD and have that backup automatically to Backblaze.\n  \n\n    That should allow me, I hope, to finally delete files from my computer's SSD as well as my 3 other external SSDs that are all clogged up with old photos and videos. (I'm a photographer + videographer + audio engineer so I produce a lot of files — I'm \nout\n of working space and it's ruining my life!)\n  \n\n    My issue:\n  \n\n    I backed up 2/3 external SSDs to the big HDD about a month ago, but since then, new files have been added. I want to add only the new files to the HDD, without having to re-copy the entire folder, since I suspect that would also mess with Backblaze's file detection.\n  \n\n\nI think this means I need a file syncing and/or deduplication program.\n\n\n\n    I've seen FreeFileSync as a recommended service. Is this what I need?\n  \n\n    Thanks so much for your help!"},
{"Title": "Upgrading and future-proofing my Plex Media server & library setup, looking for advice", "Author": "u/Reasonable_Jelly9435", "Content": "TL;DR - Nearing storage cap on my current external HDD. Want to upgrade storage and reasonably future-proof as best as possible. Considering changing my setup from PC (Plex Media Server) + external HDD (media storage), to a mini PC (Plex) + DAS. Could use advice.\n\n\n\n    Hi, I've done some research on upgrading my current Plex / general media storage setup and I've come up with a plan that looks something like the below. Please share any constructive criticisms, tips, things I might have overlooked, etc. I want to do this right the first time around.\n  \n\n    Use case: 1-2 simultaneous 1080p streams, most clients will be able to directly play my mostly HEVC (h.265) content without needing to transcode. Not all, though, so transcoding option is nice. I have Plex Pass so HW transcoding is also an option.\n  \n\n    My current setup:\n  \n\n\n\n\n\n    PC \n[Plex Media Server]\n\n\n\n\n\n\n\n    External Hard drive (12TB) [\n~10TB personal media\n]\n  \n\n\n\n\n\n\n\n\n\n    What I'm thinking of moving to:\n  \n\n\n\n\n\n    Mini PC (\nBeelink Mini S12\n) \n[Plex Media Server]\n\n\n\n\n\n\n\n    DAS (\n4-bay QNAP\n)\n  \n\n\n\n\n\n    3.5 12TB HDD (shuck my current drive) [\n~10TB personal media\n]\n  \n\n\n\n\n\n    3.5 12TB HDD (buy a new one) [\nRAID backup?\n]\n  \n\n\n\n\n\n    empty (add a 12TB in future for more storage?)\n  \n\n\n\n\n\n    empty (add a 12TB in future for more storage?)\n  \n\n\n\n\n\n\n\n\n\n    If this looks good, I have a bonus question: How do I safely move my content on my current 12TB external hard drive to the DAS? Is it as simple as shucking the drive and installing in the DAS? I've also read that setting up RAID will wipe the drives; will it be necessary to buy a third 12TB drive before moving my media?\n  \n\n    Thanks in advance!"},
{"Title": "First TrueNAS SCALE build - I'd like to begin doing weekly snapshots of Wikipedia. Any tips?", "Author": "u/saltyspicehead", "Content": "6 x 12TB Drives, Raidz2, NVMe L2ARC + SLOG etc etc etc roughly 45 TB to work with.\n  \n\n    I'd like to start by creating a weekly Wikipedia backup job to track change history. I'm familiar enough about storage tech to know that this should be possible without consuming a new ~120GB of storage every week, since only the delta will actually consume any disk space. However, I'm not familiar enough with non-enterprise solutions for this task. I see a few tools in the wiki but I'm not sure which one is best suited for this situation.\n  \n\n    Any solutions or guides you can recommend? I'd prefer not to enable dedup on my primary pool, but if that's the best option then I'll likely just create a secondary pool for this specific task."},
{"Title": "The Internet Archive solution and a creative way to compress large text files", "Author": "u/mazemadman12346", "Content": "As many of us are aware the internet archive is under legal flak for sharing books during covid to the dismay of book publishers\n  \n\n    This makes me wonder. What if they never actually shared any media or websites, and instead gave a series of links to \nlibraryofbabel.info\n (or similar website modified to generate random html code) which would conatain either the direct text or the source code of the designated media?\n  \n\n    By doing this they would be able to circumvent copyright laws as anything they share would be the product of randomly generated code and they would simply be telling you where to find it as opposed to sharing the image\n  \n\n    secondly, what if we made a website like this but for compression? Instead of needing 400mb of compressed files you could have a 2mb text file that links you to the necessary pages\n  \n\n    TLDR instead of compressing the entire bee movie script you would only need to compress a text folder containing 1-10 of \"\nhttps://libraryofbabel.info/bookmark.cgi?bee_movie_script_random\n)\" and write a program to decrypt them"},
{"Title": "Message Board Posts", "Author": "u/Expensive_Elk_3618", "Content": "I am trying to figure out how to download all of the message board posts in a certain category along with all of the responses.  I can get the first level done but not every level with responses.  I've tried HTTrack without success.  Years ago I used to do this sort of thing and it wasn't all that hard to figure out but I am older and everything is a little stricter. :-) So, I would need the easiest tool.  Thanks for any advice you can offer.   Here is one of the sites.  \nhttps://www.genealogy.com/forum/surnames/topics/reed/"},
{"Title": "Weird Method to Check Legitimacy of Drives", "Author": "u/miko-zee", "Content": "So I recommended a seller to my brother who is highly regarded as providing mostly legitimate drives. The problem is they seem to be of varying quality almost like shucking a drive. Sometimes they're totally new, sometimes unused old stock and sometimes manufacturer refurbished.\n  \n\n    My brother got a years old stock that had zero on power hours.\n  \n\n    However, a review of the seller suggested the following methodology. They were reviewing a 12TB Exos\n  \n\n    \"According to my tests, this drive is legit. I was able to:\n  \n\n\n\n\n\n    Verify the serial number at the Seagate website-  - - -    - Format the drive into 11 partitions.\n  \n\n\n\n\n\n    Put files into the first and last 2 partitions and was able to read back the files.\n  \n\n\n\n\n\n    Note that the drive has 11,175.98 GB of actual free space. The missing 825 GB may have been allocated to the file mapping table.\"\n  \n\n    Why do you need to partition it n-1 TB times then write data on the first and last partition? Is this even sound? I think they suggested it because it's quicker and more painless than stress testing the whole drive for a legitimacy test.\n  \n\n    EDIT. I want to clarify I know the scam of declaring high capacities using a smaller capacity medium. Also most of these drives usually have valid warranties just in a different region when checked via the their respective manufacturers website even the refurbished ones."},
{"Title": "Transport 3.5\" HDD with tray weekly in small casing - can't re-use packaging forever", "Author": "u/No-Balance-8038", "Content": "I want basically a similar small case that allows for a 3.5\" with tray which is 17cm long, but as small and portable! I will get a bigger antistatic bag still. The issue is that cardboard will wear down.\nI looked into Pelican cases and they are just too big to fit in my backpack!\n  \n\n    I already have 8 of \nhttps://www.amazon.de/gp/product/B01JOCHO80/\n but they do not have enough space for a 3.5\" with tray on ( ~ 170mm)\n  \n\n    Dimensions are:\n  \n\n\n\n\n\n    7cm height\n  \n\n\n\n\n\n    20cm length\n  \n\n\n\n\n\n    13cm width\n  \n\n\n\n\nhttps://preview.redd.it/transport-3-5-hdd-with-tray-weekly-in-small-casing-cant-re-v0-pfl9kd0ytc6d1.png\nhttps://preview.redd.it/transport-3-5-hdd-with-tray-weekly-in-small-casing-cant-re-v0-uifnnwg2uc6d1.png"},
{"Title": "Im looking for the best way to store my hentai collections preferbely cloud and external hard drive as backup. whats the best cloud service that can be used and external ssd. I want to start with 2TB for now as my collection is only 500gb and more to come in few days.", "Author": "u/RealComposer5655", "Content": "as title says"},
{"Title": "Macrium Reflect backup to NVMe drive in USB-C enclosure is very slow? Normal copying to same drive is fast...", "Author": "u/ozzuneoj", "Content": "Relevant Specs:\n  \n\n    Windows 10 22H2\n  \n\n    Ryzen 7 5800X3D\n  \n\n    Gigabyte X570 Aorus Elite\n  \n\n    64GB DDR4-3600\n  \n\n    Soldigm P44 Pro 2TB NVMe Gen4\n  \n\n    Macrium Reflect Free 8\n  \n\n    To keep things simple, I'm just going to focus on making a macrium image of my system partitions (C: and a couple without letters; about 100GB of data total) as a backup . I have been doing this for years but lately I've been trying to streamline and speed up the process.\n  \n\n    I have a SATA dock installed inside my system (straight SATA, no USB), and when I slot in my old 1TB Crucial MX500 drive, I can run the macrium backup in about 6 minutes.\n  \n\n    I have lots of spare NVMe drives, so I got one of these Orico 10Gbps USB 3.2 NVMe enclosures (\nhttps://www.amazon.com/ORICO-NVMe-Thunderbolt-Compatible-SSDs-PWM2-BK/dp/B0BJ23JTXX\n) several months ago and it has worked fine for transferring files. However, when I run the same macrium backup as before to this NVMe drive it seems to hang for a second, then shows an estimate of 6 minutes, then within a few seconds the transfer rate drops from 1+gbps to under 100mbps and the estimated time shoots up to 55 minutes.\n  \n\n    You would think that the symptoms point to a crappy USB enclosure or a problem with the drive... but when I copy the same image file directly from the SATA drive to the NVMe drive manually in Windows the transfer rate is pegged at over 550MB\\sec (megabytes) and it is done in just over a minute.\n  \n\n    Is there something I can adjust in Macrium or elsewhere that would fix this seeming incompatibility with this NVMe USB enclosure? I'd love to use it (to free up my old 1TB MX500) but having to wait nearly 10 times as long for backups is unacceptable.\n  \n\n    Thank you for any help you can offer."},
{"Title": "Samsung SSD cache sizes for 1TB", "Author": "u/madurbad", "Content": "Looking to buy a Samsung SSD. I only have the money for 1TB, but I'm not sure which model to get given the prices (I can only afford 1TB). Obviously I want performance to be the best, but that largely comes down to cache size between the Samsung T7, T7 shield, and T9. Unfortunately, I can't take advantage of USB 3.2x2.\n  \n\n    My question is: what are the cache sizes for each of these SSDs with their 1TB models (I heard cache sizes differ with storage capacity)?\n  \n\n    If theyre all the same, I'm looking to save money and just buy the T7.\n  \n\n    Thanks"},
{"Title": "How unlimited is Flickr Pro?", "Author": "u/jammsession", "Content": "A friend of mine is a photographer. He currently uses the good old \"put all photos onto one external HDD and labeling them\" method for storing his files.\n  \n\n    He now got to a point where he is scared of loosing data and asked about Flickr.\n  \n\n    So I was wondering if anyone else here has around 10TB of photos on Flickr Pro. Is it really unlimited? Price seems almost too good to be true."},
{"Title": "Help on selecting file system / software raid solution", "Author": "u/Altruistic-Coyote731", "Content": "Hi, I know this issue has been discussed to death but pleas bear with me!\n  \n\n    I am running a server for backups, metabase (BI Tool) and some other apps. I have 4 x 4 tb ssd drives. Right now I use Minio for data management as it was the easiest to setup but I have 2 issues with it:\n  \n\n\n\n\n\n    Memory usage: I have only 16gb available and Minio uses most of it during large syncs.\n  \n\n\n\n\n\n    For most of my use cases I need the fs directly eg. samba or nfs, databases, etc. You can mount  S3 buckets as drives but that just feels redundant.\n  \n\n\n\n\n\n    I researched the topic a bit and came up with 3 potential options described below that meet my requirements.\n  \n\n\nI would greatly appreciate feedback form the community on:\n\n\n\n\n\n\n\n    What is the memory usage like?\n  \n\n\n\n\n\n    Ease of setup?\n  \n\n\n\n\n\n    Ease of recovery in case of disk failure? (note that I have never had to deal with raid recovery before so total noob!)\n  \n\n\n\n\n\n    Anything i missed out from the pros/cons table below\n  \n\n\n\n\n\n\n\n\n\n\n\n            Options\n          \n\n            Option 1: mdadm RAID10 + xfs\n          \n\n\nOption 2: mdadm RAID10 + btrfs\n\n\n\n\nOptions 3: btrfs RAID10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n              Pros\n            \n\n              mdadm and xfs are stable solutions; good performance;\n            \n\n              snapshots\n            \n\n              snapshots; native RAID; healing;\n            \n\n\n\n\n\n              Cons\n            \n\n              missing features such as snapshots\n            \n\n              ???\n            \n\n              reliability of btrfs RAID\n            \n\n\n\n\n\n\n\n    I didn't include ZFS because, to my understanding, it's RAM intensive and has a seep learning curve.\n  \n\n    I am open to other solutions if they make more sense as well! :)"},
{"Title": "How to upgrade windows PC using with storage spaces, 6 hdds", "Author": "u/OC2k16", "Content": "Hello,\n  \n\n    I currently run a PC with win 10, older hardware. I have 6 3TB hdds, set up using storage spaces, two-way mirror, so 9TB total. They are all connected via sata.\n  \n\n    I want to upgrade to a different PC, and transfer the data to newer hard drives.\n  \n\n    Will it be as simple as: disconnecting some drives, connecting new ones, transfering the files to new hdds, and connecting new hdds to new PC? Or will windows get angry with that?\n  \n\n    I am going from win 10 to win 11 if that matters.\n  \n\n    Perhaps I should just transfer the files to the single drives, put those in the new PC, then add their backups and do the storage spaces then?\n  \n\n    Any advice would be appreciated!"},
{"Title": "Rsync Ran With Read Only Destination", "Author": "u/klnadler", "Content": "Hi all, I was transfering some data from my Unraid to an external drive mounted as an unassigned drive. I had to tweak the command a little to work with the permissions due to the drive being ExFat. After the transfer I realized the drive was set to read only through the Unassigned Disk settings, but the files transferred? How and why?\n  \n\n    Command used:\n  \nrsync -avPh --no-owner --no-group --no-perms"},
{"Title": "What my boss has collecting dust (brand new)", "Author": "u/ResponsibilityIll888", "Content": "No content"},
{"Title": "Anyone know of a device that can easily back-up data portably off a memory card onto an SSD?", "Author": "u/Ok-Cartographer1745", "Content": "I bought a Wolverine 80gb like 15 years ago. You plug in a memory card (not specifically Sony Memory Stick. I mean like Compact Flash, SD Card, and so on), press a button, and it copies your card to a folder on the hard drive.\n  \n\n    But that think is old and low capacity and I probably can't upgrade the hard drive due to the form factor and firmware likely only allowing 80gb drives.\n  \n\n    Anyway, anyone know of a similar device that is more modern?  I want it to:\n  \n\n\n\n\n\n    be portable and battery powered (nothing huge and nothing that needs to be plugged in to work)\n  \n\n\n\n\n\n    have a large SSD (500 GB or more)\n  \n\n\n\n\n\n    be self sustained (I don't want to have to plug it into a PC nor Bluetooth it to my phone)\n  \n\n\n\n\n\n    accept at least SD cards (more slots would be nice, but not necessary)\n  \n\n\n\n\n\n    I mainly want to do it to easily hoard pictures off my camera, especially if I need to quickly empty out my more expensive fast cards\n  \n\n    Also, a link to show what I already have. I'm not the one selling it and I don't recommend buying it because it's so outdated and slow (and the battery probably doesn't work considering how old it is).  So don't consider this advertising.\n  \n\n\nhttps://www.ebay.com/itm/125748798949?_trkparms=amclksrc%3DITM%26aid%3D1110006%26algo%3DHOMESPLICE.SIM%26ao%3D1%26asc%3D266917%2C266785%26meid%3D0caf8ebbb6584b81a8ed70c03fd786fd%26pid%3D101875%26rk%3D1%26rkt%3D5%26sd%3D285760155205%26itm%3D125748798949%26pmt%3D1%26noa%3D1%26pg%3D2332490%26algv%3DSimplAMLv11WebTrimmedV3MskuWithLambda85KnnRecallV1V2V4ItemNrtInQueryAndCassiniVisualRankerAndBertRecallWithVMEV3CPCAutoWithCassiniEmbRecall%26brand%3DWolverine&_trksid=p2332490.c101875.m1851"},
{"Title": "YouTube is A/B testing requiring login for video playback", "Author": "u/ThePixelHunter", "Content": "No content"},
{"Title": "Youtube channel downloader and sync for 1000s of videos?", "Author": "u/No_Doubt8973", "Content": "Hi first of all, I am on windows but I can install linux on a virtual machine.\n  \n\n    I have about 50 channels I am downloading videos from manually and it's so tiring I stopped for a year. I started again and found a lot of channels deleted videos or the channel is closed. And some of the channels have since uploaded thousands of videos.\n  \n\n    I used to manually go on youtube on my pc and grab the links but it stops loading after 1000 videos or it overloaded the chrome and crash. Would a channel downloader be able to download thousands of videos from one channel?\n  \n\n    How does the leading youtube downloaders know which videos were has been downloaded so that it doesn't download it again?\n  \n\n    Which program allows me to select preferred codec for a specific resolution?\n  \n\n    If it is possible I want to avoid av1 codec because my tablet can't play it unless it's 8k because youtube uses only av1 on 8k resolution, I would play it on my pc when I upgrade my video card black friday."},
{"Title": "Can storage have a maximum amount of storage space?", "Author": "u/Card_Boxy", "Content": "Sorry if this question was worded weirdly, but I am looking to buy a new hard drive for my pre-built Lenovo IdeaCentre Gaming 5 17IAB7. I noticed that, according to the specs on the Product Specifications Reference it could only fit 2 3.5\" HDDs with a maximum of 2 TB, and 1 M.2 SSD with a max of 1 TB.\n  \n\n    What would happen if I were to buy and install a HDD / SSD larger than the reported maximum on the specifications sheet?\n  \n\n    Here's the actual pages I was looking at.\n  \n\n\nhttps://psref.lenovo.com/Detail/IdeaCentre/IdeaCentre_Gaming_5_17IAB7?M=90T00003US\n\n\n\n\nhttps://psref.lenovo.com/Product/IdeaCentre/IdeaCentre_Gaming_5_17IAB7\n\n\n\n    Thanks in advance for your times."},
{"Title": "Need help figuring how do archive part of a soon-to-die site", "Author": "u/Mode7GFX", "Content": "I posted this on stack overflow and they called me stupid (I am) and locked the question when someone was in the middle of actually helping me so I'm asking here because it's probably a more welcoming community for this sort of thing.\n  \n\n\nhttps://prcm.jp/list/akb48%20%E3%83%97%E3%83%AA\n\n\n\n    So this (formerly) huge Japanese image sharing site is shutting down in 2 weeks and my sister's begging me to archive at least some of it. I was trying to find a python script to automate it, cuz it will take me forever going one by one on tens of thousands of images, but I can't seem to find one that can archive this sort of website. It only goes by pages of 9 and the thumbnail images are shrunk down a ton so you have to click on the image twice to open the full size. Luckily it seems like every thumbnail image shares a name with the source image, but with an added suffix of the preview size, so I imagine it would be possible to have the script delete the underscore and re-add the .jpeg extension. As for going through pages, I'm not so sure on, but if I can input a list of URLs and just batch copy the original URL adding every page number (I know how to do this without a script), I could just use that.\n  \n\n    I was only going to download AKB48 related images, because most of these images aren't available anywhere else online, and soon won't be anywhere period. They're all old and thus fairly small, so I'm not too worried about it taking a long time to download.\n  \n\n    If anyone can direct me to a script that can do this or has some other mass image downloading method you're aware of, please let me know. Thanks!"},
{"Title": "Any hardware Raid 4-bay enclosures out there that ARE \"power disable\" compatible?", "Author": "u/09Klr650", "Content": "Perhaps my search-fu is lacking but all the small 4-bay hardware raid enclosures I find specifically state they are not Power Disable compatible. Before I go the whole \"kapton tape in pin 3\" route is there a manufacturer/model out there that is capable? Without costing an arm, leg and earlobe preferably.  This will be my first such setup and I want to KISS for the moment. Figure that (4) 12TB Reman HGST would be a good start. At Raid 5 that's approx 36TB. Or approximately 4x all my current motley collection of externals combined. Thanks."},
{"Title": "Best way to transfer data from one external ssd to another external ssd?", "Author": "u/alucvrdofficial", "Content": "Not sure if this is the right subreddit to post in, but as the title states, I purchased another external ssd, and I want to upload all of the data on my current ssd to this new one. Does anybody have suggestions for how to go about this? Can I just plug em both in and drag the folders over?\n  \n\n    Also, if this isn't the right place to ask, does anyone have suggestions on where to look?"},
{"Title": "Extension cable to disable Power Disable Feature on HDD?", "Author": "u/feedmememes", "Content": "I just purchased this HDD of Amazon: \nhttps://www.amazon.com/gp/product/B08T3PBV57/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&th=1\n\n\n\n    However it did not come with the power extension cable mentioned in the product description. I have purchased this drive before and it would not work without that cable, so it is necessary for me to get one for the HDD to work. My question is what would I search for the get the correct part? Would any sata-to-sata power extension work or would it need to have some special spec? I've read a 4-pin Molex to SATA connector might be the solution, but I would like to confirm before purchasing because I am dumb!! Something like this for example:\nhttps://www.amazon.com/Cable-Matters-3-Pack-Molex-Power/dp/B00STNUB04/ref=sr_1_2?crid=B3ZGL1OM3IR1&dib=eyJ2IjoiMSJ9.f9jru-Gy4n_1s6sxvx6tecrDs0kKyQc_KXFNnctPSyGpgk3wiTyXQRVjv8latROCZFMth35JZj6AzNa09K_WespKmumHEQjA1Qn9tuzw8MBtUCX9qyoxPfAfS1R9c3JLDgIR1NHveuutkNGIKTrnouyP5DBd2e2yp3U9bkzTz5b_jPWn4NWf9pusLWEVS3OvqcRsb74HYfa7bE5vtR5EWmod_f3B-fJJnotQO7qTLbE.4mkQvoblx472TPQkw3pPm3UzP8ULyibyZTNH-zpyBg4&dib_tag=se&keywords=Sata-to-sata+power+adapter+cable&qid=1718302912&sprefix=sata-to-sata+power+adapter+cable+%2Caps%2C84&sr=8-2\n\n\n\n    Or if there are any other solutions that would be helpful too.\n  \n\n    Sorry for noob question and thank you in advanced for any help!"},
{"Title": "Need help with magazine scanning - resolution vs size", "Author": "u/MyBallsSmellFruity", "Content": "So I'm scanning magazines at 300 dpi.  Any less, and the images look kind of cruddy.  Of course, the image size is pretty large, so I'm having to batch convert them to manually make the image height 1200 (width is auto calculated).\n  \n\n    Is this pretty much the only way to get both decent quality and an acceptable image size?  The actual filesize difference in the PDFs is pretty noticeable - and significant when doing hundreds of magazines.\n  \n\n    Or is there an easier way that I just haven't stumbled across?"},
{"Title": "Attempting to digitize some Beta tapes, but getting this rainbow banding through the picture.", "Author": "u/hmhsbritannic12", "Content": "No content"},
{"Title": "I'm 98% of the way there — help me across the finish line! (Syncing help)", "Author": "u/740990929974739", "Content": "MY FRIENDS!\n\n\n\n    I'm finally doing it. Bought a 12 TB External HDD + Backblaze (Computer Backup, not B2) so I can back up my scattered external drives to the big HDD and have that backup automatically to Backblaze.\n  \n\n    That should allow me, I hope, to finally delete files from my computer's SSD as well as my 3 other external SSDs that are all clogged up with old photos and videos. (I'm a photographer + videographer + audio engineer so I produce a lot of files — I'm \nout\n of working space and it's ruining my life!)\n  \n\n    My issue:\n  \n\n    I backed up 2/3 external SSDs to the big HDD about a month ago, but since then, new files have been added. I want to add only the new files to the HDD, without having to re-copy the entire folder, since I suspect that would also mess with Backblaze's file detection.\n  \n\n\nI think this means I need a file syncing and/or deduplication program.\n\n\n\n    I've seen FreeFileSync as a recommended service. Is this what I need?\n  \n\n    Thanks so much for your help!"},
{"Title": "Upgrading and future-proofing my Plex Media server & library setup, looking for advice", "Author": "u/Reasonable_Jelly9435", "Content": "TL;DR - Nearing storage cap on my current external HDD. Want to upgrade storage and reasonably future-proof as best as possible. Considering changing my setup from PC (Plex Media Server) + external HDD (media storage), to a mini PC (Plex) + DAS. Could use advice.\n\n\n\n    Hi, I've done some research on upgrading my current Plex / general media storage setup and I've come up with a plan that looks something like the below. Please share any constructive criticisms, tips, things I might have overlooked, etc. I want to do this right the first time around.\n  \n\n    Use case: 1-2 simultaneous 1080p streams, most clients will be able to directly play my mostly HEVC (h.265) content without needing to transcode. Not all, though, so transcoding option is nice. I have Plex Pass so HW transcoding is also an option.\n  \n\n    My current setup:\n  \n\n\n\n\n\n    PC \n[Plex Media Server]\n\n\n\n\n\n\n\n    External Hard drive (12TB) [\n~10TB personal media\n]\n  \n\n\n\n\n\n\n\n\n\n    What I'm thinking of moving to:\n  \n\n\n\n\n\n    Mini PC (\nBeelink Mini S12\n) \n[Plex Media Server]\n\n\n\n\n\n\n\n    DAS (\n4-bay QNAP\n)\n  \n\n\n\n\n\n    3.5 12TB HDD (shuck my current drive) [\n~10TB personal media\n]\n  \n\n\n\n\n\n    3.5 12TB HDD (buy a new one) [\nRAID backup?\n]\n  \n\n\n\n\n\n    empty (add a 12TB in future for more storage?)\n  \n\n\n\n\n\n    empty (add a 12TB in future for more storage?)\n  \n\n\n\n\n\n\n\n\n\n    If this looks good, I have a bonus question: How do I safely move my content on my current 12TB external hard drive to the DAS? Is it as simple as shucking the drive and installing in the DAS? I've also read that setting up RAID will wipe the drives; will it be necessary to buy a third 12TB drive before moving my media?\n  \n\n    Thanks in advance!"},
{"Title": "First TrueNAS SCALE build - I'd like to begin doing weekly snapshots of Wikipedia. Any tips?", "Author": "u/saltyspicehead", "Content": "6 x 12TB Drives, Raidz2, NVMe L2ARC + SLOG etc etc etc roughly 45 TB to work with.\n  \n\n    I'd like to start by creating a weekly Wikipedia backup job to track change history. I'm familiar enough about storage tech to know that this should be possible without consuming a new ~120GB of storage every week, since only the delta will actually consume any disk space. However, I'm not familiar enough with non-enterprise solutions for this task. I see a few tools in the wiki but I'm not sure which one is best suited for this situation.\n  \n\n    Any solutions or guides you can recommend? I'd prefer not to enable dedup on my primary pool, but if that's the best option then I'll likely just create a secondary pool for this specific task."},
{"Title": "The Internet Archive solution and a creative way to compress large text files", "Author": "u/mazemadman12346", "Content": "As many of us are aware the internet archive is under legal flak for sharing books during covid to the dismay of book publishers\n  \n\n    This makes me wonder. What if they never actually shared any media or websites, and instead gave a series of links to \nlibraryofbabel.info\n (or similar website modified to generate random html code) which would conatain either the direct text or the source code of the designated media?\n  \n\n    By doing this they would be able to circumvent copyright laws as anything they share would be the product of randomly generated code and they would simply be telling you where to find it as opposed to sharing the image\n  \n\n    secondly, what if we made a website like this but for compression? Instead of needing 400mb of compressed files you could have a 2mb text file that links you to the necessary pages\n  \n\n    TLDR instead of compressing the entire bee movie script you would only need to compress a text folder containing 1-10 of \"\nhttps://libraryofbabel.info/bookmark.cgi?bee_movie_script_random\n)\" and write a program to decrypt them"},
{"Title": "Message Board Posts", "Author": "u/Expensive_Elk_3618", "Content": "I am trying to figure out how to download all of the message board posts in a certain category along with all of the responses.  I can get the first level done but not every level with responses.  I've tried HTTrack without success.  Years ago I used to do this sort of thing and it wasn't all that hard to figure out but I am older and everything is a little stricter. :-) So, I would need the easiest tool.  Thanks for any advice you can offer.   Here is one of the sites.  \nhttps://www.genealogy.com/forum/surnames/topics/reed/"},
{"Title": "Weird Method to Check Legitimacy of Drives", "Author": "u/miko-zee", "Content": "So I recommended a seller to my brother who is highly regarded as providing mostly legitimate drives. The problem is they seem to be of varying quality almost like shucking a drive. Sometimes they're totally new, sometimes unused old stock and sometimes manufacturer refurbished.\n  \n\n    My brother got a years old stock that had zero on power hours.\n  \n\n    However, a review of the seller suggested the following methodology. They were reviewing a 12TB Exos\n  \n\n    \"According to my tests, this drive is legit. I was able to:\n  \n\n\n\n\n\n    Verify the serial number at the Seagate website-  - - -    - Format the drive into 11 partitions.\n  \n\n\n\n\n\n    Put files into the first and last 2 partitions and was able to read back the files.\n  \n\n\n\n\n\n    Note that the drive has 11,175.98 GB of actual free space. The missing 825 GB may have been allocated to the file mapping table.\"\n  \n\n    Why do you need to partition it n-1 TB times then write data on the first and last partition? Is this even sound? I think they suggested it because it's quicker and more painless than stress testing the whole drive for a legitimacy test.\n  \n\n    EDIT. I want to clarify I know the scam of declaring high capacities using a smaller capacity medium. Also most of these drives usually have valid warranties just in a different region when checked via the their respective manufacturers website even the refurbished ones."},
{"Title": "Transport 3.5\" HDD with tray weekly in small casing - can't re-use packaging forever", "Author": "u/No-Balance-8038", "Content": "I want basically a similar small case that allows for a 3.5\" with tray which is 17cm long, but as small and portable! I will get a bigger antistatic bag still. The issue is that cardboard will wear down.\nI looked into Pelican cases and they are just too big to fit in my backpack!\n  \n\n    I already have 8 of \nhttps://www.amazon.de/gp/product/B01JOCHO80/\n but they do not have enough space for a 3.5\" with tray on ( ~ 170mm)\n  \n\n    Dimensions are:\n  \n\n\n\n\n\n    7cm height\n  \n\n\n\n\n\n    20cm length\n  \n\n\n\n\n\n    13cm width\n  \n\n\n\n\nhttps://preview.redd.it/transport-3-5-hdd-with-tray-weekly-in-small-casing-cant-re-v0-pfl9kd0ytc6d1.png\nhttps://preview.redd.it/transport-3-5-hdd-with-tray-weekly-in-small-casing-cant-re-v0-uifnnwg2uc6d1.png"},
{"Title": "Im looking for the best way to store my hentai collections preferbely cloud and external hard drive as backup. whats the best cloud service that can be used and external ssd. I want to start with 2TB for now as my collection is only 500gb and more to come in few days.", "Author": "u/RealComposer5655", "Content": "as title says"},
{"Title": "Macrium Reflect backup to NVMe drive in USB-C enclosure is very slow? Normal copying to same drive is fast...", "Author": "u/ozzuneoj", "Content": "Relevant Specs:\n  \n\n    Windows 10 22H2\n  \n\n    Ryzen 7 5800X3D\n  \n\n    Gigabyte X570 Aorus Elite\n  \n\n    64GB DDR4-3600\n  \n\n    Soldigm P44 Pro 2TB NVMe Gen4\n  \n\n    Macrium Reflect Free 8\n  \n\n    To keep things simple, I'm just going to focus on making a macrium image of my system partitions (C: and a couple without letters; about 100GB of data total) as a backup . I have been doing this for years but lately I've been trying to streamline and speed up the process.\n  \n\n    I have a SATA dock installed inside my system (straight SATA, no USB), and when I slot in my old 1TB Crucial MX500 drive, I can run the macrium backup in about 6 minutes.\n  \n\n    I have lots of spare NVMe drives, so I got one of these Orico 10Gbps USB 3.2 NVMe enclosures (\nhttps://www.amazon.com/ORICO-NVMe-Thunderbolt-Compatible-SSDs-PWM2-BK/dp/B0BJ23JTXX\n) several months ago and it has worked fine for transferring files. However, when I run the same macrium backup as before to this NVMe drive it seems to hang for a second, then shows an estimate of 6 minutes, then within a few seconds the transfer rate drops from 1+gbps to under 100mbps and the estimated time shoots up to 55 minutes.\n  \n\n    You would think that the symptoms point to a crappy USB enclosure or a problem with the drive... but when I copy the same image file directly from the SATA drive to the NVMe drive manually in Windows the transfer rate is pegged at over 550MB\\sec (megabytes) and it is done in just over a minute.\n  \n\n    Is there something I can adjust in Macrium or elsewhere that would fix this seeming incompatibility with this NVMe USB enclosure? I'd love to use it (to free up my old 1TB MX500) but having to wait nearly 10 times as long for backups is unacceptable.\n  \n\n    Thank you for any help you can offer."},
{"Title": "Samsung SSD cache sizes for 1TB", "Author": "u/madurbad", "Content": "Looking to buy a Samsung SSD. I only have the money for 1TB, but I'm not sure which model to get given the prices (I can only afford 1TB). Obviously I want performance to be the best, but that largely comes down to cache size between the Samsung T7, T7 shield, and T9. Unfortunately, I can't take advantage of USB 3.2x2.\n  \n\n    My question is: what are the cache sizes for each of these SSDs with their 1TB models (I heard cache sizes differ with storage capacity)?\n  \n\n    If theyre all the same, I'm looking to save money and just buy the T7.\n  \n\n    Thanks"},
{"Title": "How unlimited is Flickr Pro?", "Author": "u/jammsession", "Content": "A friend of mine is a photographer. He currently uses the good old \"put all photos onto one external HDD and labeling them\" method for storing his files.\n  \n\n    He now got to a point where he is scared of loosing data and asked about Flickr.\n  \n\n    So I was wondering if anyone else here has around 10TB of photos on Flickr Pro. Is it really unlimited? Price seems almost too good to be true."},
{"Title": "Help on selecting file system / software raid solution", "Author": "u/Altruistic-Coyote731", "Content": "Hi, I know this issue has been discussed to death but pleas bear with me!\n  \n\n    I am running a server for backups, metabase (BI Tool) and some other apps. I have 4 x 4 tb ssd drives. Right now I use Minio for data management as it was the easiest to setup but I have 2 issues with it:\n  \n\n\n\n\n\n    Memory usage: I have only 16gb available and Minio uses most of it during large syncs.\n  \n\n\n\n\n\n    For most of my use cases I need the fs directly eg. samba or nfs, databases, etc. You can mount  S3 buckets as drives but that just feels redundant.\n  \n\n\n\n\n\n    I researched the topic a bit and came up with 3 potential options described below that meet my requirements.\n  \n\n\nI would greatly appreciate feedback form the community on:\n\n\n\n\n\n\n\n    What is the memory usage like?\n  \n\n\n\n\n\n    Ease of setup?\n  \n\n\n\n\n\n    Ease of recovery in case of disk failure? (note that I have never had to deal with raid recovery before so total noob!)\n  \n\n\n\n\n\n    Anything i missed out from the pros/cons table below\n  \n\n\n\n\n\n\n\n\n\n\n\n            Options\n          \n\n            Option 1: mdadm RAID10 + xfs\n          \n\n\nOption 2: mdadm RAID10 + btrfs\n\n\n\n\nOptions 3: btrfs RAID10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n              Pros\n            \n\n              mdadm and xfs are stable solutions; good performance;\n            \n\n              snapshots\n            \n\n              snapshots; native RAID; healing;\n            \n\n\n\n\n\n              Cons\n            \n\n              missing features such as snapshots\n            \n\n              ???\n            \n\n              reliability of btrfs RAID\n            \n\n\n\n\n\n\n\n    I didn't include ZFS because, to my understanding, it's RAM intensive and has a seep learning curve.\n  \n\n    I am open to other solutions if they make more sense as well! :)"},
{"Title": "How to upgrade windows PC using with storage spaces, 6 hdds", "Author": "u/OC2k16", "Content": "Hello,\n  \n\n    I currently run a PC with win 10, older hardware. I have 6 3TB hdds, set up using storage spaces, two-way mirror, so 9TB total. They are all connected via sata.\n  \n\n    I want to upgrade to a different PC, and transfer the data to newer hard drives.\n  \n\n    Will it be as simple as: disconnecting some drives, connecting new ones, transfering the files to new hdds, and connecting new hdds to new PC? Or will windows get angry with that?\n  \n\n    I am going from win 10 to win 11 if that matters.\n  \n\n    Perhaps I should just transfer the files to the single drives, put those in the new PC, then add their backups and do the storage spaces then?\n  \n\n    Any advice would be appreciated!"},
{"Title": "Rsync Ran With Read Only Destination", "Author": "u/klnadler", "Content": "Hi all, I was transfering some data from my Unraid to an external drive mounted as an unassigned drive. I had to tweak the command a little to work with the permissions due to the drive being ExFat. After the transfer I realized the drive was set to read only through the Unassigned Disk settings, but the files transferred? How and why?\n  \n\n    Command used:\n  \nrsync -avPh --no-owner --no-group --no-perms"},
{"Title": "What my boss has collecting dust (brand new)", "Author": "u/ResponsibilityIll888", "Content": "No content"},
{"Title": "Anyone know of a device that can easily back-up data portably off a memory card onto an SSD?", "Author": "u/Ok-Cartographer1745", "Content": "I bought a Wolverine 80gb like 15 years ago. You plug in a memory card (not specifically Sony Memory Stick. I mean like Compact Flash, SD Card, and so on), press a button, and it copies your card to a folder on the hard drive.\n  \n\n    But that think is old and low capacity and I probably can't upgrade the hard drive due to the form factor and firmware likely only allowing 80gb drives.\n  \n\n    Anyway, anyone know of a similar device that is more modern?  I want it to:\n  \n\n\n\n\n\n    be portable and battery powered (nothing huge and nothing that needs to be plugged in to work)\n  \n\n\n\n\n\n    have a large SSD (500 GB or more)\n  \n\n\n\n\n\n    be self sustained (I don't want to have to plug it into a PC nor Bluetooth it to my phone)\n  \n\n\n\n\n\n    accept at least SD cards (more slots would be nice, but not necessary)\n  \n\n\n\n\n\n    I mainly want to do it to easily hoard pictures off my camera, especially if I need to quickly empty out my more expensive fast cards\n  \n\n    Also, a link to show what I already have. I'm not the one selling it and I don't recommend buying it because it's so outdated and slow (and the battery probably doesn't work considering how old it is).  So don't consider this advertising.\n  \n\n\nhttps://www.ebay.com/itm/125748798949?_trkparms=amclksrc%3DITM%26aid%3D1110006%26algo%3DHOMESPLICE.SIM%26ao%3D1%26asc%3D266917%2C266785%26meid%3D0caf8ebbb6584b81a8ed70c03fd786fd%26pid%3D101875%26rk%3D1%26rkt%3D5%26sd%3D285760155205%26itm%3D125748798949%26pmt%3D1%26noa%3D1%26pg%3D2332490%26algv%3DSimplAMLv11WebTrimmedV3MskuWithLambda85KnnRecallV1V2V4ItemNrtInQueryAndCassiniVisualRankerAndBertRecallWithVMEV3CPCAutoWithCassiniEmbRecall%26brand%3DWolverine&_trksid=p2332490.c101875.m1851"},
{"Title": "YouTube is A/B testing requiring login for video playback", "Author": "u/ThePixelHunter", "Content": "No content"},
{"Title": "Youtube channel downloader and sync for 1000s of videos?", "Author": "u/No_Doubt8973", "Content": "Hi first of all, I am on windows but I can install linux on a virtual machine.\n  \n\n    I have about 50 channels I am downloading videos from manually and it's so tiring I stopped for a year. I started again and found a lot of channels deleted videos or the channel is closed. And some of the channels have since uploaded thousands of videos.\n  \n\n    I used to manually go on youtube on my pc and grab the links but it stops loading after 1000 videos or it overloaded the chrome and crash. Would a channel downloader be able to download thousands of videos from one channel?\n  \n\n    How does the leading youtube downloaders know which videos were has been downloaded so that it doesn't download it again?\n  \n\n    Which program allows me to select preferred codec for a specific resolution?\n  \n\n    If it is possible I want to avoid av1 codec because my tablet can't play it unless it's 8k because youtube uses only av1 on 8k resolution, I would play it on my pc when I upgrade my video card black friday."},
{"Title": "Need help setting up pool", "Author": "u/Kriznick", "Content": "Hey, so new baby data hoarder here, built a pool using Windows Storage Spaces and 12hdds and 4ssds I had laying around. It's working fine so far, but I can't help but wondering if my performance and pool efficency is suffering.\n  \n\n    So I've got:\n  \n\n    1tb ssd x4\n  \n\n    4tb hdd x1 // 3tb hdd x2 // 1tb hdd x1 // .75tb hdd x4 // .64tb hdd x1 // .5tb hdd x3\n  \n\n    Totaling 4tb ssd and 16.4tb hdd. HOWEVER, I'm only getting 6tb of storage I THINK.\n  \n\n    I'm set to parity, which I thought was supposed to be more efficient for the storage, but it doesn't math out.... I've heard about this SHR-2 thing, but I have no idea about using NAS or whatever. Storage Spaces was nice because it was pretty push-pull click-click. Is there another simple setup program that's more efficient? I'm getting 1.7mb/s write speed, and thought it should have been faster since it's writing to multiple disk spaces simultaneously rather than just 1 drive...\n  \n\n    Am I just dumb and should just stick with what I have?\n  \n\n    I've tried researching it, but I can't make heads or tails of it.\n  \n\n    Thanks yall"},
{"Title": "Best cooled NVME enclosure", "Author": "u/JaL3J", "Content": "Suggestions for best cooled USB-C - NVME M.2 enclosure?\nLooking for:\n  \n\n\n\n\n\n\n\n\n\n\n\n    Single or dual NVME M.2 full length enclosure\n  \n\n\n\n\n\n\n\n\n\n    2. Cooling fan in housing and good heat transfer\n  \n\n\n\n\n\n    3. Low cost, 20-50usd, not 150+.\n  \n\n\n\n\n\n    4. USB-C 3.2 gen2 controller (10Gb/s or more).\n  \n\n\n\n\n\n    5. Preferrably a minimalistic design\n  \n\n\n\n\n\n    I've seen a couple of products on amazon etc., but usually too large and nothing with dual stick. Low profile housing is optimal.\n  \n\n    What would you suggest?"},
{"Title": "What drives do you recommend?", "Author": "u/Endeavour1988", "Content": "I currently have 3x 6TB Western Digital Golds for my media server.  2x Host content and one for spare (backups).\n  \n\n    * I do back up externally/offsite\n  \n\n    I've always had a bad history with Seagate but some of my external drives have been solid which are Seagate so I'm open minded.  Can anyone recommend from experience what brands to go for?  The Golds are 7 year old now so I would like to look at replacing 2x with 12TB and possibly the third with something larger like 16TB.  Which should hopefully see me through another 6 years."},
{"Title": "Are any HDD manufacturer RMAs not predatory?", "Author": "u/Vile-The-Terrible", "Content": "I bought a NAS less than two years ago from B&H that had Seagate Ironwolf Pro 16tbs in it. One of the drives started to fail so I began the RMA process with Seagate. They charged to have expedited delivery but it took them two weeks to process my order before shipping it. They then send me a nonfunctional drive. I now have to go through the process of RMAing the RMA drive, and the kicker? I have to pay the return shipping on the drive that failed and the broken drive they sent me.\n  \n\n    So as the title asks, are there any other companies I should be spending my dollars with going forward?\n  \n\n    Edit: In case it wasn’t clear. I understand that it is standard practice to pay for return shipping on the drive you’re using the warranty for. The problem is paying shipping again to return the faulty drive they sent me."},
{"Title": "Two 2TB external HDDs or one 4TB external HDD?", "Author": "u/Fonti_Sgasao", "Content": "Hey there, I need an external HDD just to store data, I would buy a 4TB HDD (probably Toshiba Canvio, never had a problem with it) but I heard that it's more likely to suffer data loss than a 2TB HDD, is it true?"},
{"Title": "The.tnk.loft Instagram profile is about to be deleted - best way to archive everything?", "Author": "u/studioviper", "Content": "As the title says, the fantastic and amazing the.tnk.loft Instagram account is about to be deleted. A lot of really great and inspiring content will be lost forever. Is there an easy way to back everything up? Thanks!"},
{"Title": "ATA security doesn't play well with WD USB-SATA bridge devices", "Author": "u/Visual-East8300", "Content": "A couple of years ago, I bricked a 10TB WD easystore by issuing \"hdparm --security-set-pass\" on the USB drive, un-bricked it by plugging the HDD to another USB adapter then \"hdparm --security-disable\". Today, I bricked a 4TB WD easystore (2.5 inch), out of luck this time because inside the enclosure it's an USB on-board WD Blue drive.\n  \n\n    Both are using ASMedia ASM1151W.\n  \n\n    Does anyone have ideas how to recover from this? Or it's not worth the time trying to fix?"},
{"Title": "Why is fluid RAID not more widely adopted by NAS makers?", "Author": "u/digitalanalog0524", "Content": "Synology and Terramaster both allow for fluid RAID setups (SHR and TRAID). I understand there is no black magic here and both are just using clever partitioning and a mix of RAID types. How come QNAP and Asustor do not offer these out of the box? I struggle to understand how Terramaster could out-innovate those two companies."},
{"Title": "Dreams and Aspirations", "Author": "u/thenazgul80", "Content": "Do I have this right? I want to build a nas to store my digital library and stream it to my and my family's devices. Currently relying on 5 external 2.5\" drives and windows media share. However I can't outright purchase something like a Synology nas due to cost. I have my old PC collecting dust. Amd fx 4100 Radeon 7700hd and 8 gb of ddr3 ram. Here is the plan. Undevolt the fx4100 to the lowest it can go. Diy mod my Asus Vento a8 PC case for cooling and dust prevention. Buy a 16-20 TB drive and start the nas. Once I can afford a second drive i plan on using them in raid 1. Once a 3rd drive is added I want to use them in raid 5. Over all I want to end up with 40-60tb of useable storage with some redundancy and keep the external 2.5\" drives for backups. From what I can gather, truenas won't let me just add drives later on down the line. Is unRAID my only option if I want to start with the bare minimum and expand later on as I can afford more drives?"},
{"Title": "Building up my personal media server, and I have additional questions about sourcing storage", "Author": "u/TheXypris", "Content": "So I asked \nr/Plex\n a few days ago and got some really great advice\n  \n\n    One of which was to send me here\n  \n\n    So along side what I was told there I had more questions\n  \n\n    How is shucking more affordable than just buying the regular drive? And how do I actually find those deals\n  \n\n    Are Seagate drives really that bad?\n  \n\n    What is the general consensus on buying drives second hand off eBay or through a liquidation auction? Bad idea or risky at best?\n  \n\n    I'm assuming Facebook marketplace/Craigslist should be avoided, but is there any merit in looking there? Like if I find a second hand external I could shuck?\n  \n\n    How important are RPMs sata type and all that other non capacity info? What's good and what's bad? Tradeoffs?\n  \n\n    How long will a healthy high capacity drive realistically last? People keep saying raid is mandatory and act like drives fail because you look at them funny. I can't afford a raid array right now and anything I'm putting on it would be easily required if time consuming.\n  \n\n    Are there price monitoring sites I can use to keep an eye out for deals or sales?\n  \n\n    And where is the best place to get sata and power cables for the drives?"},
{"Title": "Came across a Reddit Archive project (Pushshift alternative)", "Author": "u/marinluv", "Content": "Came across this \npost\n yesterday. That user and \nu/RaiderBDev\n are archiving Reddit data. The data is around 3-4Tb roughly from what I have seen.\n  \n\n    The GitHub Repo to archive and access the data: \nHere\n\n\n\n    To download and search Subreddit and user data manually: \nHere\n\n\n\n    Post on \nr/pushshift\n for the 2.5TB dump: \nHere"},
{"Title": "Need help with converting and compressing old VOB files", "Author": "u/martian_doggo", "Content": "So i have a bunch of old vob files, and i want to convert them to mkv or mp4 or something. I admit i don't have much experience in video manipulation but this is turning out to be exceptionally hard.\n  \n\n    I have around 5 movies which have 5 vob files each. The movies are around 4 hours long but around 12gb in size for barely 704x570p so i would love to concatinate and compress them.\n  \n\n    Now here's the problem, none of the video editor software is picking up the subtitles, not handbrake, not even ffmpeg but mpv somehow plays with the subtitles, though it takes mpv 10ish seconds to load the subtitles (weird ik).\n  \n\n    Now if i join 5 of the files to make 1 complete movie using ffmpeg, the subtitles stop loading.\n  \n\n    I have no idea what to do :(\n  \n\n    thanks"},
{"Title": "\"Vimm's Lair\" receives notice to remove tons of games.", "Author": "u/blackletum", "Content": "No content"},
{"Title": "10 year old Cold storage 4TB HGST drive 4 weak sectors 1200 bad sectors? User error ? Expert advice needed 🫠", "Author": "u/Positive_Minds", "Content": "This 4TB drive and also my 10 year old 2TB HGST drive. have popped up bad and weak sectors , they haven’t been switched on in 10 years ..\n  \n\n    So was this basically my fault for not powering them up every and using disk fresh etc or is it just a case of age related demagnetisation or mechanical failure ? I just don’t get as most of my 10 year old western digital drives or seagate have been fine when tested after 10 years\n  \n\n    I’m seriously thinking of doing yearly refreshes of my drives from now on .. My other question is can the weak sectors be reallocated or removed ?\n  \n\n    I read this on super user , is this true ?\n  \n\n    In order to keep the data signal from fading, you need to re-write the data. This is often known as “hard disk maintenance”, and should be done 3 or 4 times a year. While it does not prevent data from being corrupted or deleted, it can go a long way towards ensuring that the magnetic signal does not fade away completely. The way it works is to read every sector of the drive, and then re-write the data found there, provided the drive reported no errors. If this is done on a regular basis, the magnetic signal of every part of the drive will be refreshed long before the signal fades or becomes ambiguous. This technique also gives the drive controller the opportunity to decide whether to retire any sectors that are becoming too unreliable, before any important data is lost.\n  \n\n    Magnetic Field Breakdown\n  \n\n    Most sources state that permanent magnets lose their magnetic field strength at a rate of 1% per year. Assuming this is valid, after ~69 years, we can assume that half of the sectors in a hard drive would be corrupted (since they all lost half of their strength by this time). Obviously, this is quite a long time, but this risk is easily mitigated - simply re-write the data to the drive. How frequently you need to do this depends on the following two issues (I also go over this in my conclusion).\n  \n\n    To periodically refresh the data on the drive, simply transfer it to another location, and re-writing it back to the drive. That way, the magnetic domains in the physical disk surface will be renewed with their original strength (because you just re-wrote the files back to the disk). If you're concerned about filesystem corruption, you can also format the disk before transferring the data back.\n  \n\n    You can also help to avoid this issue by archiving your data with recovery data and error correction when you put the data onto the drive. Many archive formats support the inclusion of data recovery algorithms, so even if you have a few corrupted sectors, you can still re-build the lost data.\n  \n\n    Depending on the priority of the data you've stored, you may want to refresh the hard disk more often. If it is essential data, I would recommend no less then 2 years at maximum. If you can withstand some chance of minor data loss (e.g. a few corrupted sectors here and there), go with 5 years. It doesn't take long to copy the data off the drive, and copy it back.\n  \n\n    One thing not considered is the servo tracks and markings. These are written one time at the factory and never again (on modern disks). No amount of re-writes by the user or so-called low-level formatting freshens these. Once they fade, they fade!\n  \n\n    It's different with the first stepper motor disks of the 80's. They don't have servo tracks and a low-level format writes ALL of the bits - fresh."},
{"Title": "Backing up MacBook and multiple SSDs to single HDD", "Author": "u/cloudfortynine", "Content": "Hi everyone,\n  \n\n    I could use some guidance as I'm unsure what the simplest and low maintenance solution is for me. I'm looking to purchase an external HDD to backup the following:\n  \n\n\n\n\n\n    Macbook\n  \n\n\n\n\n\n    1TB SSD with my travel photos to be edited\n  \n\n\n\n\n\n    1TB SSD with my partners travel photos to be edited\n  \n\n\n\n\n\n    2TB SSD with music libraries for music production (Kontakt, Omnisphere etc)\n  \n\n\n\n\n\n    At first I was thinking of buying a 8TB external HDD and just backing everything up via Time Machine by having it all plugged in at once. However people online had also mentioned CCC and I'm unsure how that works? I was also hoping to back this all up to a portable HDD but it seems that 8TB HDDs can only be plugged in is that true? I'm not interested in NAS etc. as this is too complicated and expensive for me.\n  \n\n    As a sidetone I'm also planning on backing up to BackBlaze as well.\n  \n\n    Thanks in advance for any pointers!"},
{"Title": "Is a dual bay HDD docking station right for me?", "Author": "u/Vanillinn", "Content": "Hello! I only have my toe dipped in data hoarding but I've been meaning to buy the orico 6228US3 dual bay non cloning docking station.\n  \n\n    Here is my use case:\n  \n\n\n\n\n\n    Use my extra 3.5\" 500GB HDD for my modded wii u (to be formatted for the wii u) it will be where my games are installed while running the console\n  \n\n\n\n\n\n    back up photos, videos, school files, and game ROMs I have on future storage expansions (1-4TB at a time)\n  \n\n\n\n\n\n    have two drives connected to my pc at the same time\n  \n\n\n\n\n\n    on a very tight budget as a student\n  \n\n\n\n\n\n    In the future, I would like to build my own NAS if I get into bigger data hoarding and archiving. It's something I want to do but do not have the budget for right now. I have a lot of files currently but 1 or 2 more extra drives would be enough. If I could, I'd like to own two copies of my files.\n  \n\n    I have read some posts here on the subreddit raising issues on cooling, partitions, and corrupted drives. On cooling, would it still be an issue for a dual bay? I don't exactly understand the formatting problem of the partitions so I'd like to ask about that too. On corrupted drives, I'll always wait for the disk to stop spinning before ejection and also not move it as much as possible.\n  \n\n    Is a dual bay docking station a good low cost entry into data hoarding or is there an alternative more appropriate for my use case?"},
{"Title": "A New Idea for Data Storage: Combining Piezoelectric Materials and 3D NAND", "Author": "u/Mysterious_Crazy9606", "Content": "Hey everyone,\n  \n\n    I’ve been thinking about a new way to revolutionize data storage by combining piezoelectric materials with 3D NAND technology. Here’s the gist of my idea:\n  \n\n    The Concept\n  \n•\tHigh-Speed Piezoelectric Module: Use piezoelectric crystals that can oscillate at frequencies in the gigahertz range as an ultra-fast data buffer. This could potentially give us read and write speeds way beyond what we have with current tech.\n•\tMain 3D NAND Storage: Use 3D NAND for the main long-term storage. We all know it’s reliable and has a high capacity.\n\n    How It Would Work\n  \n1.\tWriting Data: Incoming data would first go to the piezoelectric module at super high speeds.\n2.\tTransferring Data: The data would then be transferred to the main 3D NAND storage for long-term keeping.\n3.\tReading Data: For reads, the system would first check the piezoelectric buffer for quick access. If the data isn’t there, it would pull from the 3D NAND storage.\n\n    Benefits\n  \n•\tSpeed: This setup could drastically reduce latency and boost read/write speeds.\n•\tEnergy Efficiency: Piezoelectric materials might be more energy-efficient for rapid operations.\n•\tNew Storage Architecture: Combining the speed of piezoelectrics with the capacity of 3D NAND could create a super-efficient storage solution.\n\n    Challenges\n  \n•\tTech Integration: Making sure the piezoelectric and 3D NAND components work seamlessly together.\n•\tCost: High-quality piezoelectric materials and the complexity of this setup might be pricey.\n•\tDurability and Reliability: The materials need to handle high-frequency oscillations over long periods without wearing out.\n\n    Potential Impact\n  \n\n    If we can make this work, it could be a game-changer for data centers, mobile devices, and industrial applications that need ultra-fast response times.\n  \n\n    What do you all think? Could this actually work?"},
{"Title": "help with a complicated wget string : how do -A and -R args stack, and is there any means of boolean filtering ?", "Author": "u/ImaginaryCheetah", "Content": "good afternoon,\n  \n\n    i'm not particularly familiar with \nwget\n so i'm asking the experts for assistance...\n  \n\n    my current string of \nwget -A \"*(USA)*zip\" -R -m -p -E -k -K -np -nd -w 2 https://target\n works fine to pull all files with \"(USA)\" included in the name, but i'd like to understand if i can get more complicated.\n  \n\n    does the \n-R\n arg work in conjunction with \n-A\n or would it override ?\n  \n\n    for example, \nwget -A \"*(USA)*zip\" -R \"*(Demo)*\" [etc]\n would this return all files with \"(USA)\" in the title unless it also had \"(Demo)\" in the file name ?\n  \n\n    is there any way of passing a boolean criteria through wget ? \"get files with (Europe) in the title if same file with (USA) in the title doesn't exist\" kind of thing ?\n  \n\n    i expect that might require grabbing a list of files with \nlftp\n and processing it instead of having \nwget\n do that kind of logic."},
{"Title": "Lsi hba 9207-8i", "Author": "u/Crystal_Jayhawk", "Content": "No content"},
{"Title": "Looking for an alternative to dban to wipe an old computer with SSD", "Author": "u/ilovecokeslurpees", "Content": "I have an old computer (turned it off 2.5 years ago but it was a mid-spec PC built in 2016 I bought second hand in 2017). I can barely boot it these days. I want to wipe the 1 TB SSD before throwing the whole PC into the trash or recycle or whatever. Most parts are unsalvageable. I used to use dban way back when but it appears to not have been updated in almost a decade. The PC is running Windows 10, but I would like a simple solution bootable from a USB to ensure complete data erasure. I tried ABAN but it couldn't detect anything. Any suggestions?"},
{"Title": "Historical data hoarders at the library of Alexandria lost untolds amount of work and knowledge after the library was burned. Sumerian texts survived 4000+ years due to being written on clay tablets. Is there any efforts to transcribe some of our knowledge into more permanent media?", "Author": "u/rrybwyb", "Content": "I mostly hoard books. Its amazing how many I can fit onto just a small 10 tb hard drive. But if that gets wet, dropped, or someone holds a magnet to it, I've lost millions of hours of research and knowledge from 10's of thousands of authors.\n  \n\n    Even looking at the history of the dead sea scrolls, Whatever idiots were in charge of transporting those did an awful job. They were taken from the dry desert to a place where they could get humid and rot.\n  \n\n    Are there any organizations out there that have transcribed some of our more important items into stone or clay? I've been looking more into Sumerian history and the reason we have many of these items still is because they were carved into clay - and clay can last a pretty long time.\n  \n\n    Its kind of short sighted of humans to think we're immune to a giant asteroid or nuclear winter. In that situation, What would humans 5,000 years in the future after a major catastrophe be able to look back on and decipher about the 2000s?\n  \n\n    Edit: also I can't believe I forgot about plastic. That supposedly forever product that never breaks down. Does anyone know if it is really as permanent as something like ceramic? I've seen it become quite brittle and disintegrate when left out in the sun for even 6-12 months"},
{"Title": "Issues with LSI 9300-16i wiping partition tables", "Author": "u/Electronic-Papaya", "Content": "I'm trying to free up some PCIe slots in my system so I'm switching from 2 x LSI 2008 to a single 16 port LSI 9300-16i.  I'm running Linux and using mdadm to run 3 arrays.\n  \n\n    Before I attached any of my drives with data and arrays configured, I installed the card with no drives attached and update the firmware to \n16.00.12.00\n, and made sure it was in IT mode.  As a test I then connected one of my arrays to the controller and booted the system.  After booting up, the drives were detected fine (4 x 2TB) but the array was gone.  It appears that the metadata was erased, mdadm didn't recognize any drive as being part of an array.\n  \n\n    I was able to recover the data and the array by following the steps here:  \nhttps://raid.wiki.kernel.org/index.php/Recovering_a_damaged_RAID\n\n\n\n    However, if I reboot again the same thing happens, the metadata is lost and mdadm does not recognize that the drives are part of an array.   I do not have this issue with the older LSI controllers.\n  \n\n    Any idea what's going on here?  When I created the array I used the entre drive, so I did not create a Linux RAID partition on each drive.  The array is configured using /dev/sda to /dev/sdd, and not /dev/sda1 to /dev/sdd1.  Not sure that has anything to do with it.\n  \n\n    Edit:  Seems to be an issue with the controller and GPT partition tables.  As a test, I created an array with a couple 120gb SSD's I had laying around.  I created the array with the whole drive, rebooted, and after a reboot the array was still present.  I realized my other drives are configured as GPT.  So I wiped the SSDs, switched them to GPT and again created the array.  This time after a reboot the array was gone, mdadm does not recognize the drives as being part of an array.  Not sure how to fix this."},
{"Title": "Buying drives from eBay?", "Author": "u/Seventeen-Oncelers", "Content": "I was considering buying a 10tb HDD on eBay and was wondering if this is considered a good place to buy? It's certified eBay refurbished, 30 day returns etc. Just curious on you guy's thoughts on buying hard drives on eBay."},
{"Title": "Cost Efficient Storage Revamp", "Author": "u/iLOLZU", "Content": "I'm want to get into archival with all the shenanigans with the Internet Archive and game preservation. I'm in need of a storage upgrade anyways. I have a Lian Li O11 with the 2x 3.5\" drive cage unpopulated and 2x 2.5\" HDDs (2.5TB total) installed, was thinking of getting a pair of 3.5\" HDDs & a pair of SATA SSDs. Considering 8TB Seagate Firecuda + 2TB Samsung 870s. I know higher capacity 3.5\" HDDs exist, but heard that buying a single high capacity drive is not worth while in terms of cost and data loss."},
{"Title": "Help needed with my western digital elements hdd", "Author": "u/Tiredcardinal", "Content": "I have a 4 year old WD elements 1.5tb hdd It was working completely fine until the starting of this year but all of a sudden it started giving buggy video outputs and I couldn't run games on it anymore So recently I decided to format it , only for it to be faulty a day later now I can copy any data to hdd normally but I cannot transfer anything for it Any suggestions or troubleshoots are welcome and appreciated"},
{"Title": "Need help setting up pool", "Author": "u/Kriznick", "Content": "Hey, so new baby data hoarder here, built a pool using Windows Storage Spaces and 12hdds and 4ssds I had laying around. It's working fine so far, but I can't help but wondering if my performance and pool efficency is suffering.\n  \n\n    So I've got:\n  \n\n    1tb ssd x4\n  \n\n    4tb hdd x1 // 3tb hdd x2 // 1tb hdd x1 // .75tb hdd x4 // .64tb hdd x1 // .5tb hdd x3\n  \n\n    Totaling 4tb ssd and 16.4tb hdd. HOWEVER, I'm only getting 6tb of storage I THINK.\n  \n\n    I'm set to parity, which I thought was supposed to be more efficient for the storage, but it doesn't math out.... I've heard about this SHR-2 thing, but I have no idea about using NAS or whatever. Storage Spaces was nice because it was pretty push-pull click-click. Is there another simple setup program that's more efficient? I'm getting 1.7mb/s write speed, and thought it should have been faster since it's writing to multiple disk spaces simultaneously rather than just 1 drive...\n  \n\n    Am I just dumb and should just stick with what I have?\n  \n\n    I've tried researching it, but I can't make heads or tails of it.\n  \n\n    Thanks yall"},
{"Title": "Best cooled NVME enclosure", "Author": "u/JaL3J", "Content": "Suggestions for best cooled USB-C - NVME M.2 enclosure?\nLooking for:\n  \n\n\n\n\n\n\n\n\n\n\n\n    Single or dual NVME M.2 full length enclosure\n  \n\n\n\n\n\n\n\n\n\n    2. Cooling fan in housing and good heat transfer\n  \n\n\n\n\n\n    3. Low cost, 20-50usd, not 150+.\n  \n\n\n\n\n\n    4. USB-C 3.2 gen2 controller (10Gb/s or more).\n  \n\n\n\n\n\n    5. Preferrably a minimalistic design\n  \n\n\n\n\n\n    I've seen a couple of products on amazon etc., but usually too large and nothing with dual stick. Low profile housing is optimal.\n  \n\n    What would you suggest?"},
{"Title": "What drives do you recommend?", "Author": "u/Endeavour1988", "Content": "I currently have 3x 6TB Western Digital Golds for my media server.  2x Host content and one for spare (backups).\n  \n\n    * I do back up externally/offsite\n  \n\n    I've always had a bad history with Seagate but some of my external drives have been solid which are Seagate so I'm open minded.  Can anyone recommend from experience what brands to go for?  The Golds are 7 year old now so I would like to look at replacing 2x with 12TB and possibly the third with something larger like 16TB.  Which should hopefully see me through another 6 years."},
{"Title": "Are any HDD manufacturer RMAs not predatory?", "Author": "u/Vile-The-Terrible", "Content": "I bought a NAS less than two years ago from B&H that had Seagate Ironwolf Pro 16tbs in it. One of the drives started to fail so I began the RMA process with Seagate. They charged to have expedited delivery but it took them two weeks to process my order before shipping it. They then send me a nonfunctional drive. I now have to go through the process of RMAing the RMA drive, and the kicker? I have to pay the return shipping on the drive that failed and the broken drive they sent me.\n  \n\n    So as the title asks, are there any other companies I should be spending my dollars with going forward?\n  \n\n    Edit: In case it wasn’t clear. I understand that it is standard practice to pay for return shipping on the drive you’re using the warranty for. The problem is paying shipping again to return the faulty drive they sent me."},
{"Title": "Two 2TB external HDDs or one 4TB external HDD?", "Author": "u/Fonti_Sgasao", "Content": "Hey there, I need an external HDD just to store data, I would buy a 4TB HDD (probably Toshiba Canvio, never had a problem with it) but I heard that it's more likely to suffer data loss than a 2TB HDD, is it true?"},
{"Title": "The.tnk.loft Instagram profile is about to be deleted - best way to archive everything?", "Author": "u/studioviper", "Content": "As the title says, the fantastic and amazing the.tnk.loft Instagram account is about to be deleted. A lot of really great and inspiring content will be lost forever. Is there an easy way to back everything up? Thanks!"},
{"Title": "ATA security doesn't play well with WD USB-SATA bridge devices", "Author": "u/Visual-East8300", "Content": "A couple of years ago, I bricked a 10TB WD easystore by issuing \"hdparm --security-set-pass\" on the USB drive, un-bricked it by plugging the HDD to another USB adapter then \"hdparm --security-disable\". Today, I bricked a 4TB WD easystore (2.5 inch), out of luck this time because inside the enclosure it's an USB on-board WD Blue drive.\n  \n\n    Both are using ASMedia ASM1151W.\n  \n\n    Does anyone have ideas how to recover from this? Or it's not worth the time trying to fix?"},
{"Title": "Why is fluid RAID not more widely adopted by NAS makers?", "Author": "u/digitalanalog0524", "Content": "Synology and Terramaster both allow for fluid RAID setups (SHR and TRAID). I understand there is no black magic here and both are just using clever partitioning and a mix of RAID types. How come QNAP and Asustor do not offer these out of the box? I struggle to understand how Terramaster could out-innovate those two companies."},
{"Title": "Dreams and Aspirations", "Author": "u/thenazgul80", "Content": "Do I have this right? I want to build a nas to store my digital library and stream it to my and my family's devices. Currently relying on 5 external 2.5\" drives and windows media share. However I can't outright purchase something like a Synology nas due to cost. I have my old PC collecting dust. Amd fx 4100 Radeon 7700hd and 8 gb of ddr3 ram. Here is the plan. Undevolt the fx4100 to the lowest it can go. Diy mod my Asus Vento a8 PC case for cooling and dust prevention. Buy a 16-20 TB drive and start the nas. Once I can afford a second drive i plan on using them in raid 1. Once a 3rd drive is added I want to use them in raid 5. Over all I want to end up with 40-60tb of useable storage with some redundancy and keep the external 2.5\" drives for backups. From what I can gather, truenas won't let me just add drives later on down the line. Is unRAID my only option if I want to start with the bare minimum and expand later on as I can afford more drives?"},
{"Title": "Building up my personal media server, and I have additional questions about sourcing storage", "Author": "u/TheXypris", "Content": "So I asked \nr/Plex\n a few days ago and got some really great advice\n  \n\n    One of which was to send me here\n  \n\n    So along side what I was told there I had more questions\n  \n\n    How is shucking more affordable than just buying the regular drive? And how do I actually find those deals\n  \n\n    Are Seagate drives really that bad?\n  \n\n    What is the general consensus on buying drives second hand off eBay or through a liquidation auction? Bad idea or risky at best?\n  \n\n    I'm assuming Facebook marketplace/Craigslist should be avoided, but is there any merit in looking there? Like if I find a second hand external I could shuck?\n  \n\n    How important are RPMs sata type and all that other non capacity info? What's good and what's bad? Tradeoffs?\n  \n\n    How long will a healthy high capacity drive realistically last? People keep saying raid is mandatory and act like drives fail because you look at them funny. I can't afford a raid array right now and anything I'm putting on it would be easily required if time consuming.\n  \n\n    Are there price monitoring sites I can use to keep an eye out for deals or sales?\n  \n\n    And where is the best place to get sata and power cables for the drives?"},
{"Title": "Came across a Reddit Archive project (Pushshift alternative)", "Author": "u/marinluv", "Content": "Came across this \npost\n yesterday. That user and \nu/RaiderBDev\n are archiving Reddit data. The data is around 3-4Tb roughly from what I have seen.\n  \n\n    The GitHub Repo to archive and access the data: \nHere\n\n\n\n    To download and search Subreddit and user data manually: \nHere\n\n\n\n    Post on \nr/pushshift\n for the 2.5TB dump: \nHere"},
{"Title": "Need help with converting and compressing old VOB files", "Author": "u/martian_doggo", "Content": "So i have a bunch of old vob files, and i want to convert them to mkv or mp4 or something. I admit i don't have much experience in video manipulation but this is turning out to be exceptionally hard.\n  \n\n    I have around 5 movies which have 5 vob files each. The movies are around 4 hours long but around 12gb in size for barely 704x570p so i would love to concatinate and compress them.\n  \n\n    Now here's the problem, none of the video editor software is picking up the subtitles, not handbrake, not even ffmpeg but mpv somehow plays with the subtitles, though it takes mpv 10ish seconds to load the subtitles (weird ik).\n  \n\n    Now if i join 5 of the files to make 1 complete movie using ffmpeg, the subtitles stop loading.\n  \n\n    I have no idea what to do :(\n  \n\n    thanks"},
{"Title": "\"Vimm's Lair\" receives notice to remove tons of games.", "Author": "u/blackletum", "Content": "No content"},
{"Title": "10 year old Cold storage 4TB HGST drive 4 weak sectors 1200 bad sectors? User error ? Expert advice needed 🫠", "Author": "u/Positive_Minds", "Content": "This 4TB drive and also my 10 year old 2TB HGST drive. have popped up bad and weak sectors , they haven’t been switched on in 10 years ..\n  \n\n    So was this basically my fault for not powering them up every and using disk fresh etc or is it just a case of age related demagnetisation or mechanical failure ? I just don’t get as most of my 10 year old western digital drives or seagate have been fine when tested after 10 years\n  \n\n    I’m seriously thinking of doing yearly refreshes of my drives from now on .. My other question is can the weak sectors be reallocated or removed ?\n  \n\n    I read this on super user , is this true ?\n  \n\n    In order to keep the data signal from fading, you need to re-write the data. This is often known as “hard disk maintenance”, and should be done 3 or 4 times a year. While it does not prevent data from being corrupted or deleted, it can go a long way towards ensuring that the magnetic signal does not fade away completely. The way it works is to read every sector of the drive, and then re-write the data found there, provided the drive reported no errors. If this is done on a regular basis, the magnetic signal of every part of the drive will be refreshed long before the signal fades or becomes ambiguous. This technique also gives the drive controller the opportunity to decide whether to retire any sectors that are becoming too unreliable, before any important data is lost.\n  \n\n    Magnetic Field Breakdown\n  \n\n    Most sources state that permanent magnets lose their magnetic field strength at a rate of 1% per year. Assuming this is valid, after ~69 years, we can assume that half of the sectors in a hard drive would be corrupted (since they all lost half of their strength by this time). Obviously, this is quite a long time, but this risk is easily mitigated - simply re-write the data to the drive. How frequently you need to do this depends on the following two issues (I also go over this in my conclusion).\n  \n\n    To periodically refresh the data on the drive, simply transfer it to another location, and re-writing it back to the drive. That way, the magnetic domains in the physical disk surface will be renewed with their original strength (because you just re-wrote the files back to the disk). If you're concerned about filesystem corruption, you can also format the disk before transferring the data back.\n  \n\n    You can also help to avoid this issue by archiving your data with recovery data and error correction when you put the data onto the drive. Many archive formats support the inclusion of data recovery algorithms, so even if you have a few corrupted sectors, you can still re-build the lost data.\n  \n\n    Depending on the priority of the data you've stored, you may want to refresh the hard disk more often. If it is essential data, I would recommend no less then 2 years at maximum. If you can withstand some chance of minor data loss (e.g. a few corrupted sectors here and there), go with 5 years. It doesn't take long to copy the data off the drive, and copy it back.\n  \n\n    One thing not considered is the servo tracks and markings. These are written one time at the factory and never again (on modern disks). No amount of re-writes by the user or so-called low-level formatting freshens these. Once they fade, they fade!\n  \n\n    It's different with the first stepper motor disks of the 80's. They don't have servo tracks and a low-level format writes ALL of the bits - fresh."},
{"Title": "Backing up MacBook and multiple SSDs to single HDD", "Author": "u/cloudfortynine", "Content": "Hi everyone,\n  \n\n    I could use some guidance as I'm unsure what the simplest and low maintenance solution is for me. I'm looking to purchase an external HDD to backup the following:\n  \n\n\n\n\n\n    Macbook\n  \n\n\n\n\n\n    1TB SSD with my travel photos to be edited\n  \n\n\n\n\n\n    1TB SSD with my partners travel photos to be edited\n  \n\n\n\n\n\n    2TB SSD with music libraries for music production (Kontakt, Omnisphere etc)\n  \n\n\n\n\n\n    At first I was thinking of buying a 8TB external HDD and just backing everything up via Time Machine by having it all plugged in at once. However people online had also mentioned CCC and I'm unsure how that works? I was also hoping to back this all up to a portable HDD but it seems that 8TB HDDs can only be plugged in is that true? I'm not interested in NAS etc. as this is too complicated and expensive for me.\n  \n\n    As a sidetone I'm also planning on backing up to BackBlaze as well.\n  \n\n    Thanks in advance for any pointers!"},
{"Title": "Is a dual bay HDD docking station right for me?", "Author": "u/Vanillinn", "Content": "Hello! I only have my toe dipped in data hoarding but I've been meaning to buy the orico 6228US3 dual bay non cloning docking station.\n  \n\n    Here is my use case:\n  \n\n\n\n\n\n    Use my extra 3.5\" 500GB HDD for my modded wii u (to be formatted for the wii u) it will be where my games are installed while running the console\n  \n\n\n\n\n\n    back up photos, videos, school files, and game ROMs I have on future storage expansions (1-4TB at a time)\n  \n\n\n\n\n\n    have two drives connected to my pc at the same time\n  \n\n\n\n\n\n    on a very tight budget as a student\n  \n\n\n\n\n\n    In the future, I would like to build my own NAS if I get into bigger data hoarding and archiving. It's something I want to do but do not have the budget for right now. I have a lot of files currently but 1 or 2 more extra drives would be enough. If I could, I'd like to own two copies of my files.\n  \n\n    I have read some posts here on the subreddit raising issues on cooling, partitions, and corrupted drives. On cooling, would it still be an issue for a dual bay? I don't exactly understand the formatting problem of the partitions so I'd like to ask about that too. On corrupted drives, I'll always wait for the disk to stop spinning before ejection and also not move it as much as possible.\n  \n\n    Is a dual bay docking station a good low cost entry into data hoarding or is there an alternative more appropriate for my use case?"},
{"Title": "A New Idea for Data Storage: Combining Piezoelectric Materials and 3D NAND", "Author": "u/Mysterious_Crazy9606", "Content": "Hey everyone,\n  \n\n    I’ve been thinking about a new way to revolutionize data storage by combining piezoelectric materials with 3D NAND technology. Here’s the gist of my idea:\n  \n\n    The Concept\n  \n•\tHigh-Speed Piezoelectric Module: Use piezoelectric crystals that can oscillate at frequencies in the gigahertz range as an ultra-fast data buffer. This could potentially give us read and write speeds way beyond what we have with current tech.\n•\tMain 3D NAND Storage: Use 3D NAND for the main long-term storage. We all know it’s reliable and has a high capacity.\n\n    How It Would Work\n  \n1.\tWriting Data: Incoming data would first go to the piezoelectric module at super high speeds.\n2.\tTransferring Data: The data would then be transferred to the main 3D NAND storage for long-term keeping.\n3.\tReading Data: For reads, the system would first check the piezoelectric buffer for quick access. If the data isn’t there, it would pull from the 3D NAND storage.\n\n    Benefits\n  \n•\tSpeed: This setup could drastically reduce latency and boost read/write speeds.\n•\tEnergy Efficiency: Piezoelectric materials might be more energy-efficient for rapid operations.\n•\tNew Storage Architecture: Combining the speed of piezoelectrics with the capacity of 3D NAND could create a super-efficient storage solution.\n\n    Challenges\n  \n•\tTech Integration: Making sure the piezoelectric and 3D NAND components work seamlessly together.\n•\tCost: High-quality piezoelectric materials and the complexity of this setup might be pricey.\n•\tDurability and Reliability: The materials need to handle high-frequency oscillations over long periods without wearing out.\n\n    Potential Impact\n  \n\n    If we can make this work, it could be a game-changer for data centers, mobile devices, and industrial applications that need ultra-fast response times.\n  \n\n    What do you all think? Could this actually work?"},
{"Title": "help with a complicated wget string : how do -A and -R args stack, and is there any means of boolean filtering ?", "Author": "u/ImaginaryCheetah", "Content": "good afternoon,\n  \n\n    i'm not particularly familiar with \nwget\n so i'm asking the experts for assistance...\n  \n\n    my current string of \nwget -A \"*(USA)*zip\" -R -m -p -E -k -K -np -nd -w 2 https://target\n works fine to pull all files with \"(USA)\" included in the name, but i'd like to understand if i can get more complicated.\n  \n\n    does the \n-R\n arg work in conjunction with \n-A\n or would it override ?\n  \n\n    for example, \nwget -A \"*(USA)*zip\" -R \"*(Demo)*\" [etc]\n would this return all files with \"(USA)\" in the title unless it also had \"(Demo)\" in the file name ?\n  \n\n    is there any way of passing a boolean criteria through wget ? \"get files with (Europe) in the title if same file with (USA) in the title doesn't exist\" kind of thing ?\n  \n\n    i expect that might require grabbing a list of files with \nlftp\n and processing it instead of having \nwget\n do that kind of logic."},
{"Title": "Lsi hba 9207-8i", "Author": "u/Crystal_Jayhawk", "Content": "No content"},
{"Title": "Looking for an alternative to dban to wipe an old computer with SSD", "Author": "u/ilovecokeslurpees", "Content": "I have an old computer (turned it off 2.5 years ago but it was a mid-spec PC built in 2016 I bought second hand in 2017). I can barely boot it these days. I want to wipe the 1 TB SSD before throwing the whole PC into the trash or recycle or whatever. Most parts are unsalvageable. I used to use dban way back when but it appears to not have been updated in almost a decade. The PC is running Windows 10, but I would like a simple solution bootable from a USB to ensure complete data erasure. I tried ABAN but it couldn't detect anything. Any suggestions?"},
{"Title": "Historical data hoarders at the library of Alexandria lost untolds amount of work and knowledge after the library was burned. Sumerian texts survived 4000+ years due to being written on clay tablets. Is there any efforts to transcribe some of our knowledge into more permanent media?", "Author": "u/rrybwyb", "Content": "I mostly hoard books. Its amazing how many I can fit onto just a small 10 tb hard drive. But if that gets wet, dropped, or someone holds a magnet to it, I've lost millions of hours of research and knowledge from 10's of thousands of authors.\n  \n\n    Even looking at the history of the dead sea scrolls, Whatever idiots were in charge of transporting those did an awful job. They were taken from the dry desert to a place where they could get humid and rot.\n  \n\n    Are there any organizations out there that have transcribed some of our more important items into stone or clay? I've been looking more into Sumerian history and the reason we have many of these items still is because they were carved into clay - and clay can last a pretty long time.\n  \n\n    Its kind of short sighted of humans to think we're immune to a giant asteroid or nuclear winter. In that situation, What would humans 5,000 years in the future after a major catastrophe be able to look back on and decipher about the 2000s?\n  \n\n    Edit: also I can't believe I forgot about plastic. That supposedly forever product that never breaks down. Does anyone know if it is really as permanent as something like ceramic? I've seen it become quite brittle and disintegrate when left out in the sun for even 6-12 months"},
{"Title": "Issues with LSI 9300-16i wiping partition tables", "Author": "u/Electronic-Papaya", "Content": "I'm trying to free up some PCIe slots in my system so I'm switching from 2 x LSI 2008 to a single 16 port LSI 9300-16i.  I'm running Linux and using mdadm to run 3 arrays.\n  \n\n    Before I attached any of my drives with data and arrays configured, I installed the card with no drives attached and update the firmware to \n16.00.12.00\n, and made sure it was in IT mode.  As a test I then connected one of my arrays to the controller and booted the system.  After booting up, the drives were detected fine (4 x 2TB) but the array was gone.  It appears that the metadata was erased, mdadm didn't recognize any drive as being part of an array.\n  \n\n    I was able to recover the data and the array by following the steps here:  \nhttps://raid.wiki.kernel.org/index.php/Recovering_a_damaged_RAID\n\n\n\n    However, if I reboot again the same thing happens, the metadata is lost and mdadm does not recognize that the drives are part of an array.   I do not have this issue with the older LSI controllers.\n  \n\n    Any idea what's going on here?  When I created the array I used the entre drive, so I did not create a Linux RAID partition on each drive.  The array is configured using /dev/sda to /dev/sdd, and not /dev/sda1 to /dev/sdd1.  Not sure that has anything to do with it.\n  \n\n    Edit:  Seems to be an issue with the controller and GPT partition tables.  As a test, I created an array with a couple 120gb SSD's I had laying around.  I created the array with the whole drive, rebooted, and after a reboot the array was still present.  I realized my other drives are configured as GPT.  So I wiped the SSDs, switched them to GPT and again created the array.  This time after a reboot the array was gone, mdadm does not recognize the drives as being part of an array.  Not sure how to fix this."},
{"Title": "Buying drives from eBay?", "Author": "u/Seventeen-Oncelers", "Content": "I was considering buying a 10tb HDD on eBay and was wondering if this is considered a good place to buy? It's certified eBay refurbished, 30 day returns etc. Just curious on you guy's thoughts on buying hard drives on eBay."},
{"Title": "Cost Efficient Storage Revamp", "Author": "u/iLOLZU", "Content": "I'm want to get into archival with all the shenanigans with the Internet Archive and game preservation. I'm in need of a storage upgrade anyways. I have a Lian Li O11 with the 2x 3.5\" drive cage unpopulated and 2x 2.5\" HDDs (2.5TB total) installed, was thinking of getting a pair of 3.5\" HDDs & a pair of SATA SSDs. Considering 8TB Seagate Firecuda + 2TB Samsung 870s. I know higher capacity 3.5\" HDDs exist, but heard that buying a single high capacity drive is not worth while in terms of cost and data loss."},
{"Title": "Help needed with my western digital elements hdd", "Author": "u/Tiredcardinal", "Content": "I have a 4 year old WD elements 1.5tb hdd It was working completely fine until the starting of this year but all of a sudden it started giving buggy video outputs and I couldn't run games on it anymore So recently I decided to format it , only for it to be faulty a day later now I can copy any data to hdd normally but I cannot transfer anything for it Any suggestions or troubleshoots are welcome and appreciated"},
{"Title": "Software to recover data from a formatted and written disk?", "Author": "u/lsgz3", "Content": "The disk has been formatted twice and written with New stuff. Is there any chance of recovering old files?"},
{"Title": "3D printed 8-Bay DAS with Supermicro backplane, trays, PSUs and external SAS-8088 connectors", "Author": "u/kschaffner", "Content": "https://imgur.com/a/YcbODga\n\n\n\n\nhttps://makerworld.com/en/models/491457\n\n\n\n    I've been working hard on this project for the past couple months in my spare time trying to make a product that I couldn't really find on the market. I had some extra PSUs and fans and supermicro trays so I figured why not design around that. I've probably put no less than 40+ hours into design, print, redesign, print, try fitment etc. Not the most experience with Fusion360 or CAD in general. The front LEDs do light up during activity :). I've been thinking of expanding this into a mATX or Mini-ITX supported case as well.\n  \n\n    I know this is also pretty much on the heals of shaztech_info but I think we have enough differences between us and I was kinda shocked to see someone else coming out with a similar idea around the same time lol. Let me know what you fellas and fellettes think!\n  \n\n    From Makerworld:\n  \n\n    I was unable to find a product that met my specifications of 8 hot-swap bays, a SAS backplane and external SAS connectors for easy connectivity, so I decided to design and build my own 8-bay Direct Attached Storage (DAS). This DAS features a Supermicro SAS833TQ backplane with Gen 5.5 hot-swap 3.5\" trays. It is powered by either a 200W PWS-203-1H (as-shown) or a 350W PWS-351-1H (or similar units of the same dimensions: PWS-351-1H 100 x 40 x 220mm, PWS-203-1H 76 x 40.3 x 192mm) power supply. Additionally, it includes an external SAS SFF-8088 to SFF-8087 adapter to cut down on internal wires.\n  \n\n    I printed this on my X1C and have realized that making it available for smaller print beds should also be done instead of 1 large single print.\n  \n\n    The body is 255 W x 190 H x 245mm D, it is printed as a single print, no supports needed. The body at 10% infill, 2 walls with gyroid infill .20mm layer height with a 0.4mm nozzle. This print requires NO supports to print. The print of the body will use approximately 984.5g of filament if no painting is done of the logo or numbers, and 982.6g if painted of a single color. This print took roughly 20 hours to print. I realize this might also be a turn off being a large print but I wasn't wanting to have to glue or screw it together if I could help it. If you are wanting this, let me know and I can work it into a new version. There are 2 version of the back plate for the different sizes of PSUs mentioned.\n  \n\n    Here is the list of parts used for this build:\n  \n\n\n\n\n\n\n\n            Part\n          \n\n            Price\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              Supermicro Gen 5.5 3.5\" trays (MCP-220-00075-0B) x8\n            \n\n              ~$50 for 8 on eBay\n            \n\n\n\n\n\n              Supermicro SAS833TQ 8-bay SAS backplane\n            \n\n              ~$35 on eBay\n            \n\n\n\n\n\n              SFF-8087 to SATA breakout cable x2\n            \n\n              ~$16\n            \n\n\n\n\n\n              SFF-8088 to SFF-8087 adapter\n            \n\n              ~$30\n            \n\n\n\n\n\n              Supermicro 1U PSU of dimensions 100 x 40 x 220mm or 76 x 40.3 x 192mm (As seen PWS-203-1H)\n            \n\n              ~32$ on eBay, also designed screw hole for PWS-351-1H ~$30 on eBay\n            \n\n\n\n\n\n              Molex Y-cable\n            \n\n              ~$6\n            \n\n\n\n\n\n              120mm of your choice x2 (Noctua NF-P12 shown)\n            \n\n              ~$16 ea.\n            \n\n\n\n\n\n              ATX power jumper cable w/ switch\n            \n\n              ~$11\n            \n\n\n\n\n\n              This required a tool to remove the pins from the connector to feed it through the hole\n            \n\n              ~$17, you don't have to get one like this, but I wanted the other pin extractors for future projects.)\n            \n\n\n\n\n\n\n\n    Grand Total of parts: $210, could save $32 with some random 120mm fans as long as they can pull through all the trays.\n  \n\n    For hardware needed:\n  \n\n\n\n\n\n\n\n            Part\n          \n\n            qty\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              M3x4x5 Heatset inserts\n            \n\n              7\n            \n\n\n\n\n\n              M4x6x6 Heatset inserts\n            \n\n              6\n            \n\n\n\n\n\n              M3x6 socket head screw\n            \n\n              3\n            \n\n\n\n\n\n              M3x12 socket head screw\n            \n\n              4\n            \n\n\n\n\n\n              M4x8 socket head screw\n            \n\n              6\n            \n\n\n\n\n\n\n\n    Some optional parts that might be desired:\n  \n\n    120mm wire fan grills ~$8\n  \n\n    Some rubber feet for the bottom"},
{"Title": "Can my old (possibly infected?) digital camera’s SD card and/or photos transfer a virus to my iPhone via an adapter?", "Author": "u/knOn0", "Content": "Hello! (I’ve asked this already but wanted to widen the net of insight before I proceed)\n  \n\n    I have an old digital camera from 2009-2011. I recently bought a new charger for it, turned it on, and it works perfectly! When I first turned it on, I was able to see tons of old pictures that I’d forgotten about; now, I can see my old photos but any new photo that I try to view has the “File Error” message. I did buy an SD card adapter to put my photos from the SD card to my iPhone, and now I’m seeing a “content unavailable: files could not be opened due to an unknown error.” (The iPhone is an 11, IOS 17).\n  \n\n    Does my SD card have a virus? Do the photos on them have a virus? Should I get a brand new adapter and SD card?\n  \n\n    TYIA"},
{"Title": "Which is more safe, a partitioned SSD (OS/Data) or two separate SSDs (one for OS, one for Data)", "Author": "u/cs_legend_93", "Content": "Hello all\n  \n\n    I'm trying to settle a debate with a other redditor.\n  \n\n    Assume both of these scenarios are basic setups without drive pools or raid.\n  \n\n    The redditor suggests and recommends that using a single SSD with a partition for the OS and Data drive is more safe than using dual drives.\n  \n\n    I believe using a partitioned SSD will both double your chances of drive failure due to writes and reads, and it will make it a pain in the ass to restore the backup.\n  \n\n    I suggested using two separate SSDs, and the redditor said that this indeed doubles the chances of drive failure due to two drives. I disagreed and said that it halves it due to the decreased reads and writes. I also suggested that dual drives will make it easier to restore a backup drive if one fails.\n  \n\n    Which scenario is better?\n  \n\n    In both scenerios there are backups, like a mirrored drive using Acronis disk imager or something like that. But it's still not a drive pool or RAID\n  \n\n    Here is the debate: \nhttps://www.reddit.com/r/buildapc/s/ArnZMYuQSD"},
{"Title": "Is there a software that batch reverse search images and download the best version of it?", "Author": "u/BulgyBoy123", "Content": "Hi guys,\nI'm looking for a software that is able to batch reverse search some images.\nI downloaded all of my pinterest boards, but some of the files are really tiny. I wouldn't mind being able to download bigger versions of said files without having to spend weeks doing that manually."},
{"Title": "Price Point", "Author": "u/Crafty_Future4829", "Content": "I apologize in advanced as I know there are a lot related posts to buying refurbished/used hard drives for non critical data.  On eBay,  it seems you can get 16tb exos drives for around 160.00 or 10 per tb.  They say refurbished with zero hours and the reseller (goharddrives) offers a 5 year warranty.\n  \n\n    Where do these hard drives from?  Do they really have zero hours as opposed to having smart data wiped?  Is this a good deal?\n  \n\n    I read another post being able to get used drives for around 5 dollars per tb.\n  \n\n    What is your sweet spot and reliable ebay sellers you would buy from?\n  \n\n    Thanks"},
{"Title": "Huge Collection", "Author": "u/CoreDreamStudiosLLC", "Content": "Good evening, hope all is well. I lost my dad on Saturday and was going through some things to get bills paid/cancelled, etc. He had over 430 media discs at his apartment which I've taken back to me.\n  \n\n    Most are DVD-R, about 20 are DVD, and the rest are DVD+RW and Divx.\n  \n\n    Is it worth ripping each one of the DVD-R's at minimum? Some are very rare and streaming sites probably won't even half this collection."},
{"Title": "is this samsung 512 gb micro sd fake?", "Author": "u/UlisesDeveloper", "Content": "No content"},
{"Title": "SATA only 50 to 500 mating cycles - what do you use for backup?", "Author": "u/No-Balance-8038", "Content": "I've got currently 5 backup 3.5\" HDD disks which are planned to be stored offsite. And backup is earliest weekly. But the real issue is that according to the SATA specification, after 50 times replugging the disk, both the Server slot for 3.5\" or the HDD itself can fail!\n  \n\n    What do I do? Put the disks in a USB enclosure and never remove it again?\nBut what about keeping the HDD running in proper temperature? My current usb cases do not have fans, and USB is not as reliable. I know turning off UASP helps for that, but I am still kind of disappointed that I am not meant to regularly take backups from SATA disks.\n  \n\n    I know theres also eSATA, but  I am not sure which combination of that would be reliable! I could basically instead have a PCIe eSATA card and eSATA cases.\nI even found two suitable cases \nhttps://www.turtlecase.eu/5-hdd/40-35-hard-drive-hdd-5-capacity-long-slots-waterproof-hd-5-turtle-case.html\n or \nhttps://www.feldherr.com/feldherr-esd-schaumstoff-set-euro-box-mit-16-faecher-fuer-3-5-zoll-festplatten/a-61567\n\n\n\n    What do you guys do recommend?"},
{"Title": "Internet Download Manager stopped detecting YouTube MKV format videos to download", "Author": "u/TheHighImperial", "Content": "Just today I discovered that it detects them if the video is embedded on a forum but not showing for the same video directly at YouTubes page. Ive updated the browser, IDM extension and even software. I also tried it on a different computer... same problem."},
{"Title": "Hulkshare Hacks?", "Author": "u/mamba_regime19", "Content": "Is there an easy way to download larger songs/mp3's from Hulkshare?\n\n\n\n    Found some old shows no longer available anywhere else that I wouldn't mind having but the files stop playing after like 10 mins so my downloaders stop as well.\n  \n\n    Is there anything like YoutubetoMp3 or SoundcloudtoMp3 that works?\n  \n\n    Saw some older posts from 11years ago....not sure if anybody has figured it out since then.\n  \n\n    Thanks!"},
{"Title": "Ways to summarize rsync logs? Too verbose so I never read them", "Author": "u/Ninj_Pizz_ha", "Content": "There's too much output from my rsync such that I end up not reading what was added/deleted. I think part of the issue is that \nit's logging stupid stuff like if a file timestamp got changed.\n\n\n\n    Really, I'd like a summary at the top that shows like \"x number of files from folder y were deleted/added.\" I'm using the \n-aih\n flags.\n  \n\n    Apologies for the somewhat vague question."},
{"Title": "NAS vs just in PC", "Author": "u/EnigmatheEgg", "Content": "Hi all!\n  \n\n    I have started to trust the internet less and less and have decided to save as much as I can in my own drives at home. I managed to find a Fractal design R5 with all drive sleds still there and thought it would make a great NAS Chassi. But now I'm wondering, do I need a NAS or can I just move my PC components there and just have a PC with 30+TB of space? All of the other people on the network don't have much data to store and would rather I help them anyway to save things. What other reasons would there be to have my data storage in a seperate chassi?"},
{"Title": "My home backup method is bad. I need help re-thinking it.", "Author": "u/Zach83", "Content": "I don't know a lot about networking, storage, and proper backing up. I'm a 3d artist and do some coding on the side so I don't get scared by technical manuals or learning new tech, but proper sys adminning is not my strength.\nI just did some reading on things like windows backup and mirroring and now I think I need to update/change/modernize how I backup my stuff.\nApparently the things I am relying on are NOT reliable at all.\nSo I dove in and now I can't see the forest for the trees anymore. I need help thinking this out.\n  \n\n\nMy current setup\nI have a work/gaming pc with 2 2TB drives and a synology 1 disk(2TB) NAS device.\nThe windows PC contains important data, the NAS serves media to a media pc(that needs no backing up) and some tablets\n  \n\n    To back these up I have a windows based \"NAS\" with 2 mirrored volumes, F and G. 2 4TB volumes (so 4 disks, 4TB each, 2 used for each mirorred volume)\nOn the Work PC there are three folders that I manually backup to G while working. Daily backups sort off.\nEvery week I run a Bat file with a few robocopy commands on the windows \"NAS\". The BAT maps the work PC's drives and the synology NAS drive and then does a copy with options like /mir and /purge. Essentially an incremental backup of the NAS and work PC drives to the windows \"NAS\".\n  \n\n    A few times a year a I run a second bat script. It copies everything to external devices that I store in my shed. Best offsite backup available to me.\n  \n\n\nmy questions\nHow to mirror?\nApparently windows mirrored volumes can not be relied on? I use it to protect against disk failure and apparently there are situations where the still working disk will NOT be read by another windows pc. Kinda defeats the point.\nI want such protection on the windows \"NAS\", an automatic and fast mirror copy.\nI want to be able to put any disk of the mirror pair in any other windows pc and have it appear like a normal disk, so it should be NTFS.\nWhat should I do? There are so many options and I have no idea what is reliable.\n  \n\n\nHow to backup without Robocopy (in a file system that windows can read like ntfs, and without puting files into a proprietary binary blob)?\nI'm told I shouldn't use Robocopy for incremental backups because it's too easy to fuck up, and should power cut out while copying I could be fucked.\nGoogling I went, searching for a way with the following requirements:\n  \n\n\n\n\n\n    I want to backup the synology nas and the 2 disks on the work pc weekly, to the windows \"NAS\".\n  \n\n\n\n\n\n    I only want to copy changed or new files and I want to remove files that no longer exist in the original source.\n  \n\n\n\n\n\n    The backup should not go into a binary blob, I want loose files.\n  \n\n\n\n\n\n    No need for file versions/history.\n  \n\n\n\n\n\n    Timestamps(date modifed/created) are important to me.\n  \n\n\n\n\n\n    And I found nothing. I probably don't even know the right terms to search for.\nHow should I do this backup?\n  \n\n    Ideally this should not involve signing up for a service or managed via a web interface hosted by some company. I want to keep everything in home and away from the internet.\nFree would be nice too."},
{"Title": "Any good suggestions for hardware to transfer analogue camcorder footage to a computer?", "Author": "u/Zazabar11", "Content": "My camcorder has av out and I have cables going from the camcorder to a framemister, which converts the signal to digital and uses an HDMI cable to transfer the signal to an elgato hd 60s, which ends with a USB C cable going to my computer for capture. It's a bit, but it has worked for older VHS tapes pretty well. I'm also using the basic capture software which comes with the elgato software.\n  \n\n    While trying to get footage from my camcorder, I noticed the audio and video footage stops getting captured on my PC when the tracking gets real messy, even if only for a couple seconds, and it ruins lots of the tape.\n  \n\n    Any suggestions for a capturing device which can handle any sort of tracking that may be required by the tapes?\n  \n\n    To note, I'm using a Sony CCD-TRV57, which uses VHS-C tapes (they're a compact form of regular VHS tapes)."},
{"Title": "winhttrack problem with cloning a single landing page. Any solutions?", "Author": "u/SolidShowerr", "Content": "I want to clone a landing page, I do everything right and download the files, but when I try to go to the index, it just opens the \"Loading screen\" from that page but not the page, it stays stuck on \"Loading\". Do you have a solution? Thank you\n  \nhttps://preview.redd.it/winhttrack-problem-with-cloning-a-single-landing-page-any-v0-9ywe6e7ja26d1.jpg"},
{"Title": "When to consider pre-emptive replacement of drives?", "Author": "u/MagicPracticalFlame", "Content": "I've got a small NAS with 4 x 6tb Drives in. The drives have just ticked over the 40,000 (grim dark) power-on time. Given that all the drives where purchased and installed at the same time, I'm worried about one crapping out and causing a domino effect when I get the replacement in to rebuild the array.\n  \n\n    The drives are Seagate ST6000VN0033 drives, health status shows as good on all counts. Just wondering when you guys start to consider replacement or migration to a new NAS (which is what I'd probably do)."},
{"Title": "Advice/guidance needed for a first time NAS builder", "Author": "u/de4thr4sher", "Content": "Hello everyone! I've been lurking around here for quite some time and all I'll say is that I've been inspired by your posts so much that I've decided to dive into the realm of building my first NAS and be a data hoarder myself. But I'll need your help with that as I've been very confused with a lot of things and obviously, I don't want to screw everything up.\n  \n\n    So, first things first. My intention with the setup is purely just hoarding data on a separate machine other than my main PC while i keep everything safe and secure as much as possible. I don't need it to be accessible from anywhere or anything like that, just locally from my main PC. Like an enormous external HDD to put it simply. I don't need crazy speeds either as I won't be using it for work or anything similar. It's main use will be storing and playing my audio/video files from there and ofc, store a lot of other files and having backups of my main system and other devices.\n  \n\n    I'll be starting with the hardware I already own and the ones I plan on buying (suggestions are welcome ofc)\n  \n\n    *Already owned hardware*\n  \n\n    Option 1 for mobo/CPU/RAM would be my old setup:\n  \n\n    A Z390-E paired with a 9700k (8C/8T) and 32GB (DDR4-3000) of RAM\n  \n\n    Option 2 would be a setup I got recently for free:\n  \n\n    An Asus ROG Maximus VII paired with a 4790k (4C/8T) and 16GB (DDR3-1600).\n  \n\n    A 700W Coolermaster PSU that I also got with the free setup, an old spare Kingston SSDNow V300 240GB and if I manage to finally build this NAS, I'll be getting rid of a 4TB WD drive and an 8TB Ironwolf drive.\n  \n\n    Will I have to use the 9700k setup in this case or even the 4790k will be enough?\n  \n\n    *Hardware I plan on buying*\n  \n\n    The goal for now is to get 4 drives so I can have 2 of them for redundancy and add another 4 next year and hopefully I won't have a storage issue for a long time.\n  \n\n    I've locked my eyes on Exos X16 14TB and on X18 16TB drives and a Define 7 XL R2 case for this whole setup as all these are in a fairly good price right now where I'm from. Seagate lists these drives as CMR so I guess shouldn't be concerned...? Later on I know I'll also have to get a Pci-e to 4x sata or something like that.\n  \n\n    That's about it as far as hardware goes. Let's dive into software now, shall we?\n  \n\n    The most confusing part for me and where I need your advice the most. What should I go for?\n  \n\n    I see a lot of people recommending unRAID for basic setups like this. I got very confused when I was trying to decide between that or TrueNAS and eventually I gave it up and decided to ask the experts here. What would you do? Is it worth spending extra for an unRAID licence?\n  \n\n    I know this post is stupid for 99.8% of you but it's obviously not my field of expertise and I'm trying to not spend anywhere else right now, except mainly for HDDs and a case.\n  \n\n    Suggestions AND roasts are welcome! :) Thanks in advance!"},
{"Title": "How much would it cost me to have and maintain a 1 TB database?", "Author": "u/AtwoodEnterprise", "Content": "I have an SEO SaaS and I store a lot of data for keywords and backlinks.\n  \n\n    My database is about 50gb and I’m currently paying about $80/mo for my webhosting VPS and up to 75gb of database storage.\n  \n\n    Currently, I use a lot of API’s to pull SEO data down because it’s such a hassle to store that much data, but over the next year I want to try and up my game a bit.\n  \n\n    So I’m gonna try and start off by increasing my keyword, and my backlink data to around 1 TB total if possible. The majority of the data is gonna be due to the backlink data of course.\n  \n\n    Would anyone have any estimates for how much something like this might cost? Or what factors I should consider/ask when obtaining pricing?"},
{"Title": "Simple web scraping Chrome extension side project", "Author": "u/Fair_Perspective_761", "Content": "I made a free Chrome extension that scrapes all plain text from the active webpage and download's it as a plain text .txt file. It works great on articles, blogs, online forums (Reddit), wiki's, and more. It has a filter option that filters out smaller text elements and keeps large elements.\n  \n\n    I made this extension as a tool to 'pre-process' large websites before analyzing them with ChatGPT. Cmd + A, Cmd + C, and Cmd + V wasn't cutting it for me, and ChatGPT 4o can process almost 100x more words when fed a plain text .txt file.\n  \n\n    Any feedback would be great. I don't track data and everything runs native in the users browser.\n  \n\n    My extension: \nWeb.txt"},
{"Title": "Where to find US Trademark Data", "Author": "u/Acrobatic_Stay_9221", "Content": "Hi, I'm looking for granular US trademark data that includes the name of the company that filed the trademark (I'm trying to view summary statistics on trademark filed by company in the US).\n  \n\n    I've tried: \nhttps://tmsearch.uspto.gov/search/search-resultsbut\n but can't find out how to get the aggregate data out of this.\n  \n\n    I've been told that this data should be publicly available, but am stumped on where to find it.\n  \n\n    Has anyone \"hoarded\" a data set that would have this data? Alternatively, does anyone know how to scrape data from this lookup above?"},
{"Title": "Is the video conversion offered by VIDBOX (was Honestech) a reliable product also, how would I go about digitizing old VHS/VCR videos?", "Author": "u/Duck_Dur", "Content": "Hello All,\n  \n\n    Is the video conservation service offered by VIDBOX (previously Honestech) a reliable product and how would you go about digitizing old VHS/VCR videos and if you were to recommend another brand, what would it be?\n  \n\n    EDIT: Fixed grammer"},
{"Title": "Any optical media ratings / testers out there checking media surfacing recently? Ridata Valor bd-r 10x brand?", "Author": "u/Gbxx69", "Content": "I lost track of the definitive site(s) for reviewing optical media or at least blu-ray discs / brands / sub brands.. can anyone send a link to who's doing the due diligence on media these days?\n  \n\n    I've seen Ridata Valor 10x bd-r discs which seem to be sold cheaper than PlexDisc or even the 6x RiData bd-r's... so what gives.. why is it somewhat cheaper?!? Were these sitting in a warehouse somewhere since before 2020 or something??!?\n  \n\n    I am looking to use the media as backup of videos, software and occasionally important data (of which I would make multiple backups over time)."},
{"Title": "Samsung 970 evo plus M2 ssd boot drive not recognizing any more. Now what?", "Author": "u/tobyisthecoolest", "Content": "I’ve been using this drive for about 1.5years and today got the boot drive not detected error. I opened bios, but the only shows up sometimes.\n  \n\n    I have a m2 to usb adapter, but the drive isn’t showing up on my other computers, so I can’t seem to copy the data off it easily.\n  \n\n    I’ve found posts with other ppl having problems with the EVO plus drives.\n  \n\n    What should I do now?\n  \n\n    If I buy a replacement boot drive how do I get windows onto it? My back ups aren’t perfect, so is there data recovery possible?\n  \n\n    Thanks"},
{"Title": "Chown Errors Running Rsnyc Going from Unraid to Unassigned Device", "Author": "u/klnadler", "Content": "Hi everyone, I'm syncing some files from my unraid to an external drive and I'm having issues with permissions, I did run newperms on the unraid side but I think this is a destination problem. The files seem to be transferring but not with the correct permissions\n  \nCommand: rsync -avPh\n05/2019-05-01/DSC00001(1)-2.ARW\n         32.77K   0%  248.06kB/s    0:01:40  rsync: [receiver] chown \"destination/2019/05/2019-05-01/.DSC00001(1)-1.ARW.sDzkxQ\" failed: Operation not permitted (1)\n         24.85M 100%   92.20MB/s    0:00:00 (xfr#2, ir-chk=1498/1516)\n05/2019-05-01/DSC00001(1)-positive-1.tif\n         32.77K   0%  118.96kB/s    0:07:37  rsync: [receiver] chown \"destination/05/2019-05-01/.DSC00001(1)-2.ARW.Q8mP3g\" failed: Operation not permitted (1)\n         54.49M 100%   99.36MB/s    0:00:00 (xfr#3, ir-chk=1497/1516)"},
{"Title": "Software to recover data from a formatted and written disk?", "Author": "u/lsgz3", "Content": "The disk has been formatted twice and written with New stuff. Is there any chance of recovering old files?"},
{"Title": "3D printed 8-Bay DAS with Supermicro backplane, trays, PSUs and external SAS-8088 connectors", "Author": "u/kschaffner", "Content": "https://imgur.com/a/YcbODga\n\n\n\n\nhttps://makerworld.com/en/models/491457\n\n\n\n    I've been working hard on this project for the past couple months in my spare time trying to make a product that I couldn't really find on the market. I had some extra PSUs and fans and supermicro trays so I figured why not design around that. I've probably put no less than 40+ hours into design, print, redesign, print, try fitment etc. Not the most experience with Fusion360 or CAD in general. The front LEDs do light up during activity :). I've been thinking of expanding this into a mATX or Mini-ITX supported case as well.\n  \n\n    I know this is also pretty much on the heals of shaztech_info but I think we have enough differences between us and I was kinda shocked to see someone else coming out with a similar idea around the same time lol. Let me know what you fellas and fellettes think!\n  \n\n    From Makerworld:\n  \n\n    I was unable to find a product that met my specifications of 8 hot-swap bays, a SAS backplane and external SAS connectors for easy connectivity, so I decided to design and build my own 8-bay Direct Attached Storage (DAS). This DAS features a Supermicro SAS833TQ backplane with Gen 5.5 hot-swap 3.5\" trays. It is powered by either a 200W PWS-203-1H (as-shown) or a 350W PWS-351-1H (or similar units of the same dimensions: PWS-351-1H 100 x 40 x 220mm, PWS-203-1H 76 x 40.3 x 192mm) power supply. Additionally, it includes an external SAS SFF-8088 to SFF-8087 adapter to cut down on internal wires.\n  \n\n    I printed this on my X1C and have realized that making it available for smaller print beds should also be done instead of 1 large single print.\n  \n\n    The body is 255 W x 190 H x 245mm D, it is printed as a single print, no supports needed. The body at 10% infill, 2 walls with gyroid infill .20mm layer height with a 0.4mm nozzle. This print requires NO supports to print. The print of the body will use approximately 984.5g of filament if no painting is done of the logo or numbers, and 982.6g if painted of a single color. This print took roughly 20 hours to print. I realize this might also be a turn off being a large print but I wasn't wanting to have to glue or screw it together if I could help it. If you are wanting this, let me know and I can work it into a new version. There are 2 version of the back plate for the different sizes of PSUs mentioned.\n  \n\n    Here is the list of parts used for this build:\n  \n\n\n\n\n\n\n\n            Part\n          \n\n            Price\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              Supermicro Gen 5.5 3.5\" trays (MCP-220-00075-0B) x8\n            \n\n              ~$50 for 8 on eBay\n            \n\n\n\n\n\n              Supermicro SAS833TQ 8-bay SAS backplane\n            \n\n              ~$35 on eBay\n            \n\n\n\n\n\n              SFF-8087 to SATA breakout cable x2\n            \n\n              ~$16\n            \n\n\n\n\n\n              SFF-8088 to SFF-8087 adapter\n            \n\n              ~$30\n            \n\n\n\n\n\n              Supermicro 1U PSU of dimensions 100 x 40 x 220mm or 76 x 40.3 x 192mm (As seen PWS-203-1H)\n            \n\n              ~32$ on eBay, also designed screw hole for PWS-351-1H ~$30 on eBay\n            \n\n\n\n\n\n              Molex Y-cable\n            \n\n              ~$6\n            \n\n\n\n\n\n              120mm of your choice x2 (Noctua NF-P12 shown)\n            \n\n              ~$16 ea.\n            \n\n\n\n\n\n              ATX power jumper cable w/ switch\n            \n\n              ~$11\n            \n\n\n\n\n\n              This required a tool to remove the pins from the connector to feed it through the hole\n            \n\n              ~$17, you don't have to get one like this, but I wanted the other pin extractors for future projects.)\n            \n\n\n\n\n\n\n\n    Grand Total of parts: $210, could save $32 with some random 120mm fans as long as they can pull through all the trays.\n  \n\n    For hardware needed:\n  \n\n\n\n\n\n\n\n            Part\n          \n\n            qty\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              M3x4x5 Heatset inserts\n            \n\n              7\n            \n\n\n\n\n\n              M4x6x6 Heatset inserts\n            \n\n              6\n            \n\n\n\n\n\n              M3x6 socket head screw\n            \n\n              3\n            \n\n\n\n\n\n              M3x12 socket head screw\n            \n\n              4\n            \n\n\n\n\n\n              M4x8 socket head screw\n            \n\n              6\n            \n\n\n\n\n\n\n\n    Some optional parts that might be desired:\n  \n\n    120mm wire fan grills ~$8\n  \n\n    Some rubber feet for the bottom"},
{"Title": "Can my old (possibly infected?) digital camera’s SD card and/or photos transfer a virus to my iPhone via an adapter?", "Author": "u/knOn0", "Content": "Hello! (I’ve asked this already but wanted to widen the net of insight before I proceed)\n  \n\n    I have an old digital camera from 2009-2011. I recently bought a new charger for it, turned it on, and it works perfectly! When I first turned it on, I was able to see tons of old pictures that I’d forgotten about; now, I can see my old photos but any new photo that I try to view has the “File Error” message. I did buy an SD card adapter to put my photos from the SD card to my iPhone, and now I’m seeing a “content unavailable: files could not be opened due to an unknown error.” (The iPhone is an 11, IOS 17).\n  \n\n    Does my SD card have a virus? Do the photos on them have a virus? Should I get a brand new adapter and SD card?\n  \n\n    TYIA"},
{"Title": "Which is more safe, a partitioned SSD (OS/Data) or two separate SSDs (one for OS, one for Data)", "Author": "u/cs_legend_93", "Content": "Hello all\n  \n\n    I'm trying to settle a debate with a other redditor.\n  \n\n    Assume both of these scenarios are basic setups without drive pools or raid.\n  \n\n    The redditor suggests and recommends that using a single SSD with a partition for the OS and Data drive is more safe than using dual drives.\n  \n\n    I believe using a partitioned SSD will both double your chances of drive failure due to writes and reads, and it will make it a pain in the ass to restore the backup.\n  \n\n    I suggested using two separate SSDs, and the redditor said that this indeed doubles the chances of drive failure due to two drives. I disagreed and said that it halves it due to the decreased reads and writes. I also suggested that dual drives will make it easier to restore a backup drive if one fails.\n  \n\n    Which scenario is better?\n  \n\n    In both scenerios there are backups, like a mirrored drive using Acronis disk imager or something like that. But it's still not a drive pool or RAID\n  \n\n    Here is the debate: \nhttps://www.reddit.com/r/buildapc/s/ArnZMYuQSD"},
{"Title": "Is there a software that batch reverse search images and download the best version of it?", "Author": "u/BulgyBoy123", "Content": "Hi guys,\nI'm looking for a software that is able to batch reverse search some images.\nI downloaded all of my pinterest boards, but some of the files are really tiny. I wouldn't mind being able to download bigger versions of said files without having to spend weeks doing that manually."},
{"Title": "Price Point", "Author": "u/Crafty_Future4829", "Content": "I apologize in advanced as I know there are a lot related posts to buying refurbished/used hard drives for non critical data.  On eBay,  it seems you can get 16tb exos drives for around 160.00 or 10 per tb.  They say refurbished with zero hours and the reseller (goharddrives) offers a 5 year warranty.\n  \n\n    Where do these hard drives from?  Do they really have zero hours as opposed to having smart data wiped?  Is this a good deal?\n  \n\n    I read another post being able to get used drives for around 5 dollars per tb.\n  \n\n    What is your sweet spot and reliable ebay sellers you would buy from?\n  \n\n    Thanks"},
{"Title": "Huge Collection", "Author": "u/CoreDreamStudiosLLC", "Content": "Good evening, hope all is well. I lost my dad on Saturday and was going through some things to get bills paid/cancelled, etc. He had over 430 media discs at his apartment which I've taken back to me.\n  \n\n    Most are DVD-R, about 20 are DVD, and the rest are DVD+RW and Divx.\n  \n\n    Is it worth ripping each one of the DVD-R's at minimum? Some are very rare and streaming sites probably won't even half this collection."},
{"Title": "is this samsung 512 gb micro sd fake?", "Author": "u/UlisesDeveloper", "Content": "No content"},
{"Title": "SATA only 50 to 500 mating cycles - what do you use for backup?", "Author": "u/No-Balance-8038", "Content": "I've got currently 5 backup 3.5\" HDD disks which are planned to be stored offsite. And backup is earliest weekly. But the real issue is that according to the SATA specification, after 50 times replugging the disk, both the Server slot for 3.5\" or the HDD itself can fail!\n  \n\n    What do I do? Put the disks in a USB enclosure and never remove it again?\nBut what about keeping the HDD running in proper temperature? My current usb cases do not have fans, and USB is not as reliable. I know turning off UASP helps for that, but I am still kind of disappointed that I am not meant to regularly take backups from SATA disks.\n  \n\n    I know theres also eSATA, but  I am not sure which combination of that would be reliable! I could basically instead have a PCIe eSATA card and eSATA cases.\nI even found two suitable cases \nhttps://www.turtlecase.eu/5-hdd/40-35-hard-drive-hdd-5-capacity-long-slots-waterproof-hd-5-turtle-case.html\n or \nhttps://www.feldherr.com/feldherr-esd-schaumstoff-set-euro-box-mit-16-faecher-fuer-3-5-zoll-festplatten/a-61567\n\n\n\n    What do you guys do recommend?"},
{"Title": "Internet Download Manager stopped detecting YouTube MKV format videos to download", "Author": "u/TheHighImperial", "Content": "Just today I discovered that it detects them if the video is embedded on a forum but not showing for the same video directly at YouTubes page. Ive updated the browser, IDM extension and even software. I also tried it on a different computer... same problem."},
{"Title": "Hulkshare Hacks?", "Author": "u/mamba_regime19", "Content": "Is there an easy way to download larger songs/mp3's from Hulkshare?\n\n\n\n    Found some old shows no longer available anywhere else that I wouldn't mind having but the files stop playing after like 10 mins so my downloaders stop as well.\n  \n\n    Is there anything like YoutubetoMp3 or SoundcloudtoMp3 that works?\n  \n\n    Saw some older posts from 11years ago....not sure if anybody has figured it out since then.\n  \n\n    Thanks!"},
{"Title": "Ways to summarize rsync logs? Too verbose so I never read them", "Author": "u/Ninj_Pizz_ha", "Content": "There's too much output from my rsync such that I end up not reading what was added/deleted. I think part of the issue is that \nit's logging stupid stuff like if a file timestamp got changed.\n\n\n\n    Really, I'd like a summary at the top that shows like \"x number of files from folder y were deleted/added.\" I'm using the \n-aih\n flags.\n  \n\n    Apologies for the somewhat vague question."},
{"Title": "NAS vs just in PC", "Author": "u/EnigmatheEgg", "Content": "Hi all!\n  \n\n    I have started to trust the internet less and less and have decided to save as much as I can in my own drives at home. I managed to find a Fractal design R5 with all drive sleds still there and thought it would make a great NAS Chassi. But now I'm wondering, do I need a NAS or can I just move my PC components there and just have a PC with 30+TB of space? All of the other people on the network don't have much data to store and would rather I help them anyway to save things. What other reasons would there be to have my data storage in a seperate chassi?"},
{"Title": "My home backup method is bad. I need help re-thinking it.", "Author": "u/Zach83", "Content": "I don't know a lot about networking, storage, and proper backing up. I'm a 3d artist and do some coding on the side so I don't get scared by technical manuals or learning new tech, but proper sys adminning is not my strength.\nI just did some reading on things like windows backup and mirroring and now I think I need to update/change/modernize how I backup my stuff.\nApparently the things I am relying on are NOT reliable at all.\nSo I dove in and now I can't see the forest for the trees anymore. I need help thinking this out.\n  \n\n\nMy current setup\nI have a work/gaming pc with 2 2TB drives and a synology 1 disk(2TB) NAS device.\nThe windows PC contains important data, the NAS serves media to a media pc(that needs no backing up) and some tablets\n  \n\n    To back these up I have a windows based \"NAS\" with 2 mirrored volumes, F and G. 2 4TB volumes (so 4 disks, 4TB each, 2 used for each mirorred volume)\nOn the Work PC there are three folders that I manually backup to G while working. Daily backups sort off.\nEvery week I run a Bat file with a few robocopy commands on the windows \"NAS\". The BAT maps the work PC's drives and the synology NAS drive and then does a copy with options like /mir and /purge. Essentially an incremental backup of the NAS and work PC drives to the windows \"NAS\".\n  \n\n    A few times a year a I run a second bat script. It copies everything to external devices that I store in my shed. Best offsite backup available to me.\n  \n\n\nmy questions\nHow to mirror?\nApparently windows mirrored volumes can not be relied on? I use it to protect against disk failure and apparently there are situations where the still working disk will NOT be read by another windows pc. Kinda defeats the point.\nI want such protection on the windows \"NAS\", an automatic and fast mirror copy.\nI want to be able to put any disk of the mirror pair in any other windows pc and have it appear like a normal disk, so it should be NTFS.\nWhat should I do? There are so many options and I have no idea what is reliable.\n  \n\n\nHow to backup without Robocopy (in a file system that windows can read like ntfs, and without puting files into a proprietary binary blob)?\nI'm told I shouldn't use Robocopy for incremental backups because it's too easy to fuck up, and should power cut out while copying I could be fucked.\nGoogling I went, searching for a way with the following requirements:\n  \n\n\n\n\n\n    I want to backup the synology nas and the 2 disks on the work pc weekly, to the windows \"NAS\".\n  \n\n\n\n\n\n    I only want to copy changed or new files and I want to remove files that no longer exist in the original source.\n  \n\n\n\n\n\n    The backup should not go into a binary blob, I want loose files.\n  \n\n\n\n\n\n    No need for file versions/history.\n  \n\n\n\n\n\n    Timestamps(date modifed/created) are important to me.\n  \n\n\n\n\n\n    And I found nothing. I probably don't even know the right terms to search for.\nHow should I do this backup?\n  \n\n    Ideally this should not involve signing up for a service or managed via a web interface hosted by some company. I want to keep everything in home and away from the internet.\nFree would be nice too."},
{"Title": "Any good suggestions for hardware to transfer analogue camcorder footage to a computer?", "Author": "u/Zazabar11", "Content": "My camcorder has av out and I have cables going from the camcorder to a framemister, which converts the signal to digital and uses an HDMI cable to transfer the signal to an elgato hd 60s, which ends with a USB C cable going to my computer for capture. It's a bit, but it has worked for older VHS tapes pretty well. I'm also using the basic capture software which comes with the elgato software.\n  \n\n    While trying to get footage from my camcorder, I noticed the audio and video footage stops getting captured on my PC when the tracking gets real messy, even if only for a couple seconds, and it ruins lots of the tape.\n  \n\n    Any suggestions for a capturing device which can handle any sort of tracking that may be required by the tapes?\n  \n\n    To note, I'm using a Sony CCD-TRV57, which uses VHS-C tapes (they're a compact form of regular VHS tapes)."},
{"Title": "winhttrack problem with cloning a single landing page. Any solutions?", "Author": "u/SolidShowerr", "Content": "I want to clone a landing page, I do everything right and download the files, but when I try to go to the index, it just opens the \"Loading screen\" from that page but not the page, it stays stuck on \"Loading\". Do you have a solution? Thank you\n  \nhttps://preview.redd.it/winhttrack-problem-with-cloning-a-single-landing-page-any-v0-9ywe6e7ja26d1.jpg"},
{"Title": "When to consider pre-emptive replacement of drives?", "Author": "u/MagicPracticalFlame", "Content": "I've got a small NAS with 4 x 6tb Drives in. The drives have just ticked over the 40,000 (grim dark) power-on time. Given that all the drives where purchased and installed at the same time, I'm worried about one crapping out and causing a domino effect when I get the replacement in to rebuild the array.\n  \n\n    The drives are Seagate ST6000VN0033 drives, health status shows as good on all counts. Just wondering when you guys start to consider replacement or migration to a new NAS (which is what I'd probably do)."},
{"Title": "Advice/guidance needed for a first time NAS builder", "Author": "u/de4thr4sher", "Content": "Hello everyone! I've been lurking around here for quite some time and all I'll say is that I've been inspired by your posts so much that I've decided to dive into the realm of building my first NAS and be a data hoarder myself. But I'll need your help with that as I've been very confused with a lot of things and obviously, I don't want to screw everything up.\n  \n\n    So, first things first. My intention with the setup is purely just hoarding data on a separate machine other than my main PC while i keep everything safe and secure as much as possible. I don't need it to be accessible from anywhere or anything like that, just locally from my main PC. Like an enormous external HDD to put it simply. I don't need crazy speeds either as I won't be using it for work or anything similar. It's main use will be storing and playing my audio/video files from there and ofc, store a lot of other files and having backups of my main system and other devices.\n  \n\n    I'll be starting with the hardware I already own and the ones I plan on buying (suggestions are welcome ofc)\n  \n\n    *Already owned hardware*\n  \n\n    Option 1 for mobo/CPU/RAM would be my old setup:\n  \n\n    A Z390-E paired with a 9700k (8C/8T) and 32GB (DDR4-3000) of RAM\n  \n\n    Option 2 would be a setup I got recently for free:\n  \n\n    An Asus ROG Maximus VII paired with a 4790k (4C/8T) and 16GB (DDR3-1600).\n  \n\n    A 700W Coolermaster PSU that I also got with the free setup, an old spare Kingston SSDNow V300 240GB and if I manage to finally build this NAS, I'll be getting rid of a 4TB WD drive and an 8TB Ironwolf drive.\n  \n\n    Will I have to use the 9700k setup in this case or even the 4790k will be enough?\n  \n\n    *Hardware I plan on buying*\n  \n\n    The goal for now is to get 4 drives so I can have 2 of them for redundancy and add another 4 next year and hopefully I won't have a storage issue for a long time.\n  \n\n    I've locked my eyes on Exos X16 14TB and on X18 16TB drives and a Define 7 XL R2 case for this whole setup as all these are in a fairly good price right now where I'm from. Seagate lists these drives as CMR so I guess shouldn't be concerned...? Later on I know I'll also have to get a Pci-e to 4x sata or something like that.\n  \n\n    That's about it as far as hardware goes. Let's dive into software now, shall we?\n  \n\n    The most confusing part for me and where I need your advice the most. What should I go for?\n  \n\n    I see a lot of people recommending unRAID for basic setups like this. I got very confused when I was trying to decide between that or TrueNAS and eventually I gave it up and decided to ask the experts here. What would you do? Is it worth spending extra for an unRAID licence?\n  \n\n    I know this post is stupid for 99.8% of you but it's obviously not my field of expertise and I'm trying to not spend anywhere else right now, except mainly for HDDs and a case.\n  \n\n    Suggestions AND roasts are welcome! :) Thanks in advance!"},
{"Title": "How much would it cost me to have and maintain a 1 TB database?", "Author": "u/AtwoodEnterprise", "Content": "I have an SEO SaaS and I store a lot of data for keywords and backlinks.\n  \n\n    My database is about 50gb and I’m currently paying about $80/mo for my webhosting VPS and up to 75gb of database storage.\n  \n\n    Currently, I use a lot of API’s to pull SEO data down because it’s such a hassle to store that much data, but over the next year I want to try and up my game a bit.\n  \n\n    So I’m gonna try and start off by increasing my keyword, and my backlink data to around 1 TB total if possible. The majority of the data is gonna be due to the backlink data of course.\n  \n\n    Would anyone have any estimates for how much something like this might cost? Or what factors I should consider/ask when obtaining pricing?"},
{"Title": "Simple web scraping Chrome extension side project", "Author": "u/Fair_Perspective_761", "Content": "I made a free Chrome extension that scrapes all plain text from the active webpage and download's it as a plain text .txt file. It works great on articles, blogs, online forums (Reddit), wiki's, and more. It has a filter option that filters out smaller text elements and keeps large elements.\n  \n\n    I made this extension as a tool to 'pre-process' large websites before analyzing them with ChatGPT. Cmd + A, Cmd + C, and Cmd + V wasn't cutting it for me, and ChatGPT 4o can process almost 100x more words when fed a plain text .txt file.\n  \n\n    Any feedback would be great. I don't track data and everything runs native in the users browser.\n  \n\n    My extension: \nWeb.txt"},
{"Title": "Where to find US Trademark Data", "Author": "u/Acrobatic_Stay_9221", "Content": "Hi, I'm looking for granular US trademark data that includes the name of the company that filed the trademark (I'm trying to view summary statistics on trademark filed by company in the US).\n  \n\n    I've tried: \nhttps://tmsearch.uspto.gov/search/search-resultsbut\n but can't find out how to get the aggregate data out of this.\n  \n\n    I've been told that this data should be publicly available, but am stumped on where to find it.\n  \n\n    Has anyone \"hoarded\" a data set that would have this data? Alternatively, does anyone know how to scrape data from this lookup above?"},
{"Title": "Is the video conversion offered by VIDBOX (was Honestech) a reliable product also, how would I go about digitizing old VHS/VCR videos?", "Author": "u/Duck_Dur", "Content": "Hello All,\n  \n\n    Is the video conservation service offered by VIDBOX (previously Honestech) a reliable product and how would you go about digitizing old VHS/VCR videos and if you were to recommend another brand, what would it be?\n  \n\n    EDIT: Fixed grammer"},
{"Title": "Any optical media ratings / testers out there checking media surfacing recently? Ridata Valor bd-r 10x brand?", "Author": "u/Gbxx69", "Content": "I lost track of the definitive site(s) for reviewing optical media or at least blu-ray discs / brands / sub brands.. can anyone send a link to who's doing the due diligence on media these days?\n  \n\n    I've seen Ridata Valor 10x bd-r discs which seem to be sold cheaper than PlexDisc or even the 6x RiData bd-r's... so what gives.. why is it somewhat cheaper?!? Were these sitting in a warehouse somewhere since before 2020 or something??!?\n  \n\n    I am looking to use the media as backup of videos, software and occasionally important data (of which I would make multiple backups over time)."},
{"Title": "Samsung 970 evo plus M2 ssd boot drive not recognizing any more. Now what?", "Author": "u/tobyisthecoolest", "Content": "I’ve been using this drive for about 1.5years and today got the boot drive not detected error. I opened bios, but the only shows up sometimes.\n  \n\n    I have a m2 to usb adapter, but the drive isn’t showing up on my other computers, so I can’t seem to copy the data off it easily.\n  \n\n    I’ve found posts with other ppl having problems with the EVO plus drives.\n  \n\n    What should I do now?\n  \n\n    If I buy a replacement boot drive how do I get windows onto it? My back ups aren’t perfect, so is there data recovery possible?\n  \n\n    Thanks"},
{"Title": "Chown Errors Running Rsnyc Going from Unraid to Unassigned Device", "Author": "u/klnadler", "Content": "Hi everyone, I'm syncing some files from my unraid to an external drive and I'm having issues with permissions, I did run newperms on the unraid side but I think this is a destination problem. The files seem to be transferring but not with the correct permissions\n  \nCommand: rsync -avPh\n05/2019-05-01/DSC00001(1)-2.ARW\n         32.77K   0%  248.06kB/s    0:01:40  rsync: [receiver] chown \"destination/2019/05/2019-05-01/.DSC00001(1)-1.ARW.sDzkxQ\" failed: Operation not permitted (1)\n         24.85M 100%   92.20MB/s    0:00:00 (xfr#2, ir-chk=1498/1516)\n05/2019-05-01/DSC00001(1)-positive-1.tif\n         32.77K   0%  118.96kB/s    0:07:37  rsync: [receiver] chown \"destination/05/2019-05-01/.DSC00001(1)-2.ARW.Q8mP3g\" failed: Operation not permitted (1)\n         54.49M 100%   99.36MB/s    0:00:00 (xfr#3, ir-chk=1497/1516)"},
{"Title": "Software to recover data from a formatted and written disk?", "Author": "u/lsgz3", "Content": "The disk has been formatted twice and written with New stuff. Is there any chance of recovering old files?"},
{"Title": "3D printed 8-Bay DAS with Supermicro backplane, trays, PSUs and external SAS-8088 connectors", "Author": "u/kschaffner", "Content": "https://imgur.com/a/YcbODga\n\n\n\n\nhttps://makerworld.com/en/models/491457\n\n\n\n    I've been working hard on this project for the past couple months in my spare time trying to make a product that I couldn't really find on the market. I had some extra PSUs and fans and supermicro trays so I figured why not design around that. I've probably put no less than 40+ hours into design, print, redesign, print, try fitment etc. Not the most experience with Fusion360 or CAD in general. The front LEDs do light up during activity :). I've been thinking of expanding this into a mATX or Mini-ITX supported case as well.\n  \n\n    I know this is also pretty much on the heals of shaztech_info but I think we have enough differences between us and I was kinda shocked to see someone else coming out with a similar idea around the same time lol. Let me know what you fellas and fellettes think!\n  \n\n    From Makerworld:\n  \n\n    I was unable to find a product that met my specifications of 8 hot-swap bays, a SAS backplane and external SAS connectors for easy connectivity, so I decided to design and build my own 8-bay Direct Attached Storage (DAS). This DAS features a Supermicro SAS833TQ backplane with Gen 5.5 hot-swap 3.5\" trays. It is powered by either a 200W PWS-203-1H (as-shown) or a 350W PWS-351-1H (or similar units of the same dimensions: PWS-351-1H 100 x 40 x 220mm, PWS-203-1H 76 x 40.3 x 192mm) power supply. Additionally, it includes an external SAS SFF-8088 to SFF-8087 adapter to cut down on internal wires.\n  \n\n    I printed this on my X1C and have realized that making it available for smaller print beds should also be done instead of 1 large single print.\n  \n\n    The body is 255 W x 190 H x 245mm D, it is printed as a single print, no supports needed. The body at 10% infill, 2 walls with gyroid infill .20mm layer height with a 0.4mm nozzle. This print requires NO supports to print. The print of the body will use approximately 984.5g of filament if no painting is done of the logo or numbers, and 982.6g if painted of a single color. This print took roughly 20 hours to print. I realize this might also be a turn off being a large print but I wasn't wanting to have to glue or screw it together if I could help it. If you are wanting this, let me know and I can work it into a new version. There are 2 version of the back plate for the different sizes of PSUs mentioned.\n  \n\n    Here is the list of parts used for this build:\n  \n\n\n\n\n\n\n\n            Part\n          \n\n            Price\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              Supermicro Gen 5.5 3.5\" trays (MCP-220-00075-0B) x8\n            \n\n              ~$50 for 8 on eBay\n            \n\n\n\n\n\n              Supermicro SAS833TQ 8-bay SAS backplane\n            \n\n              ~$35 on eBay\n            \n\n\n\n\n\n              SFF-8087 to SATA breakout cable x2\n            \n\n              ~$16\n            \n\n\n\n\n\n              SFF-8088 to SFF-8087 adapter\n            \n\n              ~$30\n            \n\n\n\n\n\n              Supermicro 1U PSU of dimensions 100 x 40 x 220mm or 76 x 40.3 x 192mm (As seen PWS-203-1H)\n            \n\n              ~32$ on eBay, also designed screw hole for PWS-351-1H ~$30 on eBay\n            \n\n\n\n\n\n              Molex Y-cable\n            \n\n              ~$6\n            \n\n\n\n\n\n              120mm of your choice x2 (Noctua NF-P12 shown)\n            \n\n              ~$16 ea.\n            \n\n\n\n\n\n              ATX power jumper cable w/ switch\n            \n\n              ~$11\n            \n\n\n\n\n\n              This required a tool to remove the pins from the connector to feed it through the hole\n            \n\n              ~$17, you don't have to get one like this, but I wanted the other pin extractors for future projects.)\n            \n\n\n\n\n\n\n\n    Grand Total of parts: $210, could save $32 with some random 120mm fans as long as they can pull through all the trays.\n  \n\n    For hardware needed:\n  \n\n\n\n\n\n\n\n            Part\n          \n\n            qty\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              M3x4x5 Heatset inserts\n            \n\n              7\n            \n\n\n\n\n\n              M4x6x6 Heatset inserts\n            \n\n              6\n            \n\n\n\n\n\n              M3x6 socket head screw\n            \n\n              3\n            \n\n\n\n\n\n              M3x12 socket head screw\n            \n\n              4\n            \n\n\n\n\n\n              M4x8 socket head screw\n            \n\n              6\n            \n\n\n\n\n\n\n\n    Some optional parts that might be desired:\n  \n\n    120mm wire fan grills ~$8\n  \n\n    Some rubber feet for the bottom"},
{"Title": "Can my old (possibly infected?) digital camera’s SD card and/or photos transfer a virus to my iPhone via an adapter?", "Author": "u/knOn0", "Content": "Hello! (I’ve asked this already but wanted to widen the net of insight before I proceed)\n  \n\n    I have an old digital camera from 2009-2011. I recently bought a new charger for it, turned it on, and it works perfectly! When I first turned it on, I was able to see tons of old pictures that I’d forgotten about; now, I can see my old photos but any new photo that I try to view has the “File Error” message. I did buy an SD card adapter to put my photos from the SD card to my iPhone, and now I’m seeing a “content unavailable: files could not be opened due to an unknown error.” (The iPhone is an 11, IOS 17).\n  \n\n    Does my SD card have a virus? Do the photos on them have a virus? Should I get a brand new adapter and SD card?\n  \n\n    TYIA"},
{"Title": "Which is more safe, a partitioned SSD (OS/Data) or two separate SSDs (one for OS, one for Data)", "Author": "u/cs_legend_93", "Content": "Hello all\n  \n\n    I'm trying to settle a debate with a other redditor.\n  \n\n    Assume both of these scenarios are basic setups without drive pools or raid.\n  \n\n    The redditor suggests and recommends that using a single SSD with a partition for the OS and Data drive is more safe than using dual drives.\n  \n\n    I believe using a partitioned SSD will both double your chances of drive failure due to writes and reads, and it will make it a pain in the ass to restore the backup.\n  \n\n    I suggested using two separate SSDs, and the redditor said that this indeed doubles the chances of drive failure due to two drives. I disagreed and said that it halves it due to the decreased reads and writes. I also suggested that dual drives will make it easier to restore a backup drive if one fails.\n  \n\n    Which scenario is better?\n  \n\n    In both scenerios there are backups, like a mirrored drive using Acronis disk imager or something like that. But it's still not a drive pool or RAID\n  \n\n    Here is the debate: \nhttps://www.reddit.com/r/buildapc/s/ArnZMYuQSD"},
{"Title": "Is there a software that batch reverse search images and download the best version of it?", "Author": "u/BulgyBoy123", "Content": "Hi guys,\nI'm looking for a software that is able to batch reverse search some images.\nI downloaded all of my pinterest boards, but some of the files are really tiny. I wouldn't mind being able to download bigger versions of said files without having to spend weeks doing that manually."},
{"Title": "Price Point", "Author": "u/Crafty_Future4829", "Content": "I apologize in advanced as I know there are a lot related posts to buying refurbished/used hard drives for non critical data.  On eBay,  it seems you can get 16tb exos drives for around 160.00 or 10 per tb.  They say refurbished with zero hours and the reseller (goharddrives) offers a 5 year warranty.\n  \n\n    Where do these hard drives from?  Do they really have zero hours as opposed to having smart data wiped?  Is this a good deal?\n  \n\n    I read another post being able to get used drives for around 5 dollars per tb.\n  \n\n    What is your sweet spot and reliable ebay sellers you would buy from?\n  \n\n    Thanks"},
{"Title": "Huge Collection", "Author": "u/CoreDreamStudiosLLC", "Content": "Good evening, hope all is well. I lost my dad on Saturday and was going through some things to get bills paid/cancelled, etc. He had over 430 media discs at his apartment which I've taken back to me.\n  \n\n    Most are DVD-R, about 20 are DVD, and the rest are DVD+RW and Divx.\n  \n\n    Is it worth ripping each one of the DVD-R's at minimum? Some are very rare and streaming sites probably won't even half this collection."},
{"Title": "is this samsung 512 gb micro sd fake?", "Author": "u/UlisesDeveloper", "Content": "No content"},
{"Title": "SATA only 50 to 500 mating cycles - what do you use for backup?", "Author": "u/No-Balance-8038", "Content": "I've got currently 5 backup 3.5\" HDD disks which are planned to be stored offsite. And backup is earliest weekly. But the real issue is that according to the SATA specification, after 50 times replugging the disk, both the Server slot for 3.5\" or the HDD itself can fail!\n  \n\n    What do I do? Put the disks in a USB enclosure and never remove it again?\nBut what about keeping the HDD running in proper temperature? My current usb cases do not have fans, and USB is not as reliable. I know turning off UASP helps for that, but I am still kind of disappointed that I am not meant to regularly take backups from SATA disks.\n  \n\n    I know theres also eSATA, but  I am not sure which combination of that would be reliable! I could basically instead have a PCIe eSATA card and eSATA cases.\nI even found two suitable cases \nhttps://www.turtlecase.eu/5-hdd/40-35-hard-drive-hdd-5-capacity-long-slots-waterproof-hd-5-turtle-case.html\n or \nhttps://www.feldherr.com/feldherr-esd-schaumstoff-set-euro-box-mit-16-faecher-fuer-3-5-zoll-festplatten/a-61567\n\n\n\n    What do you guys do recommend?"},
{"Title": "Internet Download Manager stopped detecting YouTube MKV format videos to download", "Author": "u/TheHighImperial", "Content": "Just today I discovered that it detects them if the video is embedded on a forum but not showing for the same video directly at YouTubes page. Ive updated the browser, IDM extension and even software. I also tried it on a different computer... same problem."},
{"Title": "Hulkshare Hacks?", "Author": "u/mamba_regime19", "Content": "Is there an easy way to download larger songs/mp3's from Hulkshare?\n\n\n\n    Found some old shows no longer available anywhere else that I wouldn't mind having but the files stop playing after like 10 mins so my downloaders stop as well.\n  \n\n    Is there anything like YoutubetoMp3 or SoundcloudtoMp3 that works?\n  \n\n    Saw some older posts from 11years ago....not sure if anybody has figured it out since then.\n  \n\n    Thanks!"},
{"Title": "Ways to summarize rsync logs? Too verbose so I never read them", "Author": "u/Ninj_Pizz_ha", "Content": "There's too much output from my rsync such that I end up not reading what was added/deleted. I think part of the issue is that \nit's logging stupid stuff like if a file timestamp got changed.\n\n\n\n    Really, I'd like a summary at the top that shows like \"x number of files from folder y were deleted/added.\" I'm using the \n-aih\n flags.\n  \n\n    Apologies for the somewhat vague question."},
{"Title": "NAS vs just in PC", "Author": "u/EnigmatheEgg", "Content": "Hi all!\n  \n\n    I have started to trust the internet less and less and have decided to save as much as I can in my own drives at home. I managed to find a Fractal design R5 with all drive sleds still there and thought it would make a great NAS Chassi. But now I'm wondering, do I need a NAS or can I just move my PC components there and just have a PC with 30+TB of space? All of the other people on the network don't have much data to store and would rather I help them anyway to save things. What other reasons would there be to have my data storage in a seperate chassi?"},
{"Title": "My home backup method is bad. I need help re-thinking it.", "Author": "u/Zach83", "Content": "I don't know a lot about networking, storage, and proper backing up. I'm a 3d artist and do some coding on the side so I don't get scared by technical manuals or learning new tech, but proper sys adminning is not my strength.\nI just did some reading on things like windows backup and mirroring and now I think I need to update/change/modernize how I backup my stuff.\nApparently the things I am relying on are NOT reliable at all.\nSo I dove in and now I can't see the forest for the trees anymore. I need help thinking this out.\n  \n\n\nMy current setup\nI have a work/gaming pc with 2 2TB drives and a synology 1 disk(2TB) NAS device.\nThe windows PC contains important data, the NAS serves media to a media pc(that needs no backing up) and some tablets\n  \n\n    To back these up I have a windows based \"NAS\" with 2 mirrored volumes, F and G. 2 4TB volumes (so 4 disks, 4TB each, 2 used for each mirorred volume)\nOn the Work PC there are three folders that I manually backup to G while working. Daily backups sort off.\nEvery week I run a Bat file with a few robocopy commands on the windows \"NAS\". The BAT maps the work PC's drives and the synology NAS drive and then does a copy with options like /mir and /purge. Essentially an incremental backup of the NAS and work PC drives to the windows \"NAS\".\n  \n\n    A few times a year a I run a second bat script. It copies everything to external devices that I store in my shed. Best offsite backup available to me.\n  \n\n\nmy questions\nHow to mirror?\nApparently windows mirrored volumes can not be relied on? I use it to protect against disk failure and apparently there are situations where the still working disk will NOT be read by another windows pc. Kinda defeats the point.\nI want such protection on the windows \"NAS\", an automatic and fast mirror copy.\nI want to be able to put any disk of the mirror pair in any other windows pc and have it appear like a normal disk, so it should be NTFS.\nWhat should I do? There are so many options and I have no idea what is reliable.\n  \n\n\nHow to backup without Robocopy (in a file system that windows can read like ntfs, and without puting files into a proprietary binary blob)?\nI'm told I shouldn't use Robocopy for incremental backups because it's too easy to fuck up, and should power cut out while copying I could be fucked.\nGoogling I went, searching for a way with the following requirements:\n  \n\n\n\n\n\n    I want to backup the synology nas and the 2 disks on the work pc weekly, to the windows \"NAS\".\n  \n\n\n\n\n\n    I only want to copy changed or new files and I want to remove files that no longer exist in the original source.\n  \n\n\n\n\n\n    The backup should not go into a binary blob, I want loose files.\n  \n\n\n\n\n\n    No need for file versions/history.\n  \n\n\n\n\n\n    Timestamps(date modifed/created) are important to me.\n  \n\n\n\n\n\n    And I found nothing. I probably don't even know the right terms to search for.\nHow should I do this backup?\n  \n\n    Ideally this should not involve signing up for a service or managed via a web interface hosted by some company. I want to keep everything in home and away from the internet.\nFree would be nice too."},
{"Title": "Any good suggestions for hardware to transfer analogue camcorder footage to a computer?", "Author": "u/Zazabar11", "Content": "My camcorder has av out and I have cables going from the camcorder to a framemister, which converts the signal to digital and uses an HDMI cable to transfer the signal to an elgato hd 60s, which ends with a USB C cable going to my computer for capture. It's a bit, but it has worked for older VHS tapes pretty well. I'm also using the basic capture software which comes with the elgato software.\n  \n\n    While trying to get footage from my camcorder, I noticed the audio and video footage stops getting captured on my PC when the tracking gets real messy, even if only for a couple seconds, and it ruins lots of the tape.\n  \n\n    Any suggestions for a capturing device which can handle any sort of tracking that may be required by the tapes?\n  \n\n    To note, I'm using a Sony CCD-TRV57, which uses VHS-C tapes (they're a compact form of regular VHS tapes)."},
{"Title": "winhttrack problem with cloning a single landing page. Any solutions?", "Author": "u/SolidShowerr", "Content": "I want to clone a landing page, I do everything right and download the files, but when I try to go to the index, it just opens the \"Loading screen\" from that page but not the page, it stays stuck on \"Loading\". Do you have a solution? Thank you\n  \nhttps://preview.redd.it/winhttrack-problem-with-cloning-a-single-landing-page-any-v0-9ywe6e7ja26d1.jpg"},
{"Title": "When to consider pre-emptive replacement of drives?", "Author": "u/MagicPracticalFlame", "Content": "I've got a small NAS with 4 x 6tb Drives in. The drives have just ticked over the 40,000 (grim dark) power-on time. Given that all the drives where purchased and installed at the same time, I'm worried about one crapping out and causing a domino effect when I get the replacement in to rebuild the array.\n  \n\n    The drives are Seagate ST6000VN0033 drives, health status shows as good on all counts. Just wondering when you guys start to consider replacement or migration to a new NAS (which is what I'd probably do)."},
{"Title": "Advice/guidance needed for a first time NAS builder", "Author": "u/de4thr4sher", "Content": "Hello everyone! I've been lurking around here for quite some time and all I'll say is that I've been inspired by your posts so much that I've decided to dive into the realm of building my first NAS and be a data hoarder myself. But I'll need your help with that as I've been very confused with a lot of things and obviously, I don't want to screw everything up.\n  \n\n    So, first things first. My intention with the setup is purely just hoarding data on a separate machine other than my main PC while i keep everything safe and secure as much as possible. I don't need it to be accessible from anywhere or anything like that, just locally from my main PC. Like an enormous external HDD to put it simply. I don't need crazy speeds either as I won't be using it for work or anything similar. It's main use will be storing and playing my audio/video files from there and ofc, store a lot of other files and having backups of my main system and other devices.\n  \n\n    I'll be starting with the hardware I already own and the ones I plan on buying (suggestions are welcome ofc)\n  \n\n    *Already owned hardware*\n  \n\n    Option 1 for mobo/CPU/RAM would be my old setup:\n  \n\n    A Z390-E paired with a 9700k (8C/8T) and 32GB (DDR4-3000) of RAM\n  \n\n    Option 2 would be a setup I got recently for free:\n  \n\n    An Asus ROG Maximus VII paired with a 4790k (4C/8T) and 16GB (DDR3-1600).\n  \n\n    A 700W Coolermaster PSU that I also got with the free setup, an old spare Kingston SSDNow V300 240GB and if I manage to finally build this NAS, I'll be getting rid of a 4TB WD drive and an 8TB Ironwolf drive.\n  \n\n    Will I have to use the 9700k setup in this case or even the 4790k will be enough?\n  \n\n    *Hardware I plan on buying*\n  \n\n    The goal for now is to get 4 drives so I can have 2 of them for redundancy and add another 4 next year and hopefully I won't have a storage issue for a long time.\n  \n\n    I've locked my eyes on Exos X16 14TB and on X18 16TB drives and a Define 7 XL R2 case for this whole setup as all these are in a fairly good price right now where I'm from. Seagate lists these drives as CMR so I guess shouldn't be concerned...? Later on I know I'll also have to get a Pci-e to 4x sata or something like that.\n  \n\n    That's about it as far as hardware goes. Let's dive into software now, shall we?\n  \n\n    The most confusing part for me and where I need your advice the most. What should I go for?\n  \n\n    I see a lot of people recommending unRAID for basic setups like this. I got very confused when I was trying to decide between that or TrueNAS and eventually I gave it up and decided to ask the experts here. What would you do? Is it worth spending extra for an unRAID licence?\n  \n\n    I know this post is stupid for 99.8% of you but it's obviously not my field of expertise and I'm trying to not spend anywhere else right now, except mainly for HDDs and a case.\n  \n\n    Suggestions AND roasts are welcome! :) Thanks in advance!"},
{"Title": "How much would it cost me to have and maintain a 1 TB database?", "Author": "u/AtwoodEnterprise", "Content": "I have an SEO SaaS and I store a lot of data for keywords and backlinks.\n  \n\n    My database is about 50gb and I’m currently paying about $80/mo for my webhosting VPS and up to 75gb of database storage.\n  \n\n    Currently, I use a lot of API’s to pull SEO data down because it’s such a hassle to store that much data, but over the next year I want to try and up my game a bit.\n  \n\n    So I’m gonna try and start off by increasing my keyword, and my backlink data to around 1 TB total if possible. The majority of the data is gonna be due to the backlink data of course.\n  \n\n    Would anyone have any estimates for how much something like this might cost? Or what factors I should consider/ask when obtaining pricing?"},
{"Title": "Simple web scraping Chrome extension side project", "Author": "u/Fair_Perspective_761", "Content": "I made a free Chrome extension that scrapes all plain text from the active webpage and download's it as a plain text .txt file. It works great on articles, blogs, online forums (Reddit), wiki's, and more. It has a filter option that filters out smaller text elements and keeps large elements.\n  \n\n    I made this extension as a tool to 'pre-process' large websites before analyzing them with ChatGPT. Cmd + A, Cmd + C, and Cmd + V wasn't cutting it for me, and ChatGPT 4o can process almost 100x more words when fed a plain text .txt file.\n  \n\n    Any feedback would be great. I don't track data and everything runs native in the users browser.\n  \n\n    My extension: \nWeb.txt"},
{"Title": "Where to find US Trademark Data", "Author": "u/Acrobatic_Stay_9221", "Content": "Hi, I'm looking for granular US trademark data that includes the name of the company that filed the trademark (I'm trying to view summary statistics on trademark filed by company in the US).\n  \n\n    I've tried: \nhttps://tmsearch.uspto.gov/search/search-resultsbut\n but can't find out how to get the aggregate data out of this.\n  \n\n    I've been told that this data should be publicly available, but am stumped on where to find it.\n  \n\n    Has anyone \"hoarded\" a data set that would have this data? Alternatively, does anyone know how to scrape data from this lookup above?"},
{"Title": "Is the video conversion offered by VIDBOX (was Honestech) a reliable product also, how would I go about digitizing old VHS/VCR videos?", "Author": "u/Duck_Dur", "Content": "Hello All,\n  \n\n    Is the video conservation service offered by VIDBOX (previously Honestech) a reliable product and how would you go about digitizing old VHS/VCR videos and if you were to recommend another brand, what would it be?\n  \n\n    EDIT: Fixed grammer"},
{"Title": "Any optical media ratings / testers out there checking media surfacing recently? Ridata Valor bd-r 10x brand?", "Author": "u/Gbxx69", "Content": "I lost track of the definitive site(s) for reviewing optical media or at least blu-ray discs / brands / sub brands.. can anyone send a link to who's doing the due diligence on media these days?\n  \n\n    I've seen Ridata Valor 10x bd-r discs which seem to be sold cheaper than PlexDisc or even the 6x RiData bd-r's... so what gives.. why is it somewhat cheaper?!? Were these sitting in a warehouse somewhere since before 2020 or something??!?\n  \n\n    I am looking to use the media as backup of videos, software and occasionally important data (of which I would make multiple backups over time)."},
{"Title": "Samsung 970 evo plus M2 ssd boot drive not recognizing any more. Now what?", "Author": "u/tobyisthecoolest", "Content": "I’ve been using this drive for about 1.5years and today got the boot drive not detected error. I opened bios, but the only shows up sometimes.\n  \n\n    I have a m2 to usb adapter, but the drive isn’t showing up on my other computers, so I can’t seem to copy the data off it easily.\n  \n\n    I’ve found posts with other ppl having problems with the EVO plus drives.\n  \n\n    What should I do now?\n  \n\n    If I buy a replacement boot drive how do I get windows onto it? My back ups aren’t perfect, so is there data recovery possible?\n  \n\n    Thanks"},
{"Title": "Chown Errors Running Rsnyc Going from Unraid to Unassigned Device", "Author": "u/klnadler", "Content": "Hi everyone, I'm syncing some files from my unraid to an external drive and I'm having issues with permissions, I did run newperms on the unraid side but I think this is a destination problem. The files seem to be transferring but not with the correct permissions\n  \nCommand: rsync -avPh\n05/2019-05-01/DSC00001(1)-2.ARW\n         32.77K   0%  248.06kB/s    0:01:40  rsync: [receiver] chown \"destination/2019/05/2019-05-01/.DSC00001(1)-1.ARW.sDzkxQ\" failed: Operation not permitted (1)\n         24.85M 100%   92.20MB/s    0:00:00 (xfr#2, ir-chk=1498/1516)\n05/2019-05-01/DSC00001(1)-positive-1.tif\n         32.77K   0%  118.96kB/s    0:07:37  rsync: [receiver] chown \"destination/05/2019-05-01/.DSC00001(1)-2.ARW.Q8mP3g\" failed: Operation not permitted (1)\n         54.49M 100%   99.36MB/s    0:00:00 (xfr#3, ir-chk=1497/1516)"},
{"Title": "M2 Pro/M3 Pro w/ 990 Pro NVMe + 40 Gb/s external", "Author": "u/Direct-Button1358", "Content": "Hi all,\n  \n\n    Systems: Mac Mini M2 Pro, MBP M3 Pro\n  \n\n    Thank you for your time. I am trying to put together an external drive using the Samsung 990 PRO NVMe with an external enclosure rated at 40 Gb/s like the ugreen or acasis.\n  \n\n    I do have a few questions:\n  \n\n\n\n\n\n    What external enclosure would work best for use with my M2 Pro and M3 Pro, I mostly do research and will be using it as an extended mobile storage solution .\n  \n\n\n\n\n\n    Is this overkill for my usage? Keep in mind, the difference in price between this SSD and others that write at half the speed is maybe $50 .  I am using my University start up funds for the purchase.\n  \n\n\n\n\n\n    Additionally: I am interested in eventually setting up NAS using this SSD paired with something like a Yottamaster enclosure.\n  \n\n    Thanks!"},
{"Title": "VirtualDub won't record audio from capture card but sound works fine outside of recording", "Author": "u/Throwaway173638o", "Content": "I'm trying to capture video and audio from my JVC HR-S7100U through a GV-USB2 capture card device.  I am using S-Video as source with composite as my audio sources.  I set the audio source to the device.\n  \n\n    When I try to capture video, the audio doesn't get recorded.  But when I'm not recording under Overview mode, the volume is playing fine.  Preview mode doesn't work for audio too.\n  \n\n    I also don't have any issues recording video and audio from OBS.  However I want to stick with Virtualdub for the best quality.\n  \n\n    I don't know what I can really do to fix this?"},
{"Title": "How to download Twitch vod?", "Author": "u/RainBowSwift71532", "Content": "I've been trying to download a twitch vod but have had no luck in doing so. If I want to download say a YouTube video. Search download YouTube video and a bunch of site pop up. Click on one copy and paste the YouTube link. Pick resolution and click download mad easy. But for some reason it's harder for a twitch vod. I have yet to find a site that will allow me to download a twitch vod. I'm trying to download a streamers recent twitch vod.\n  \n\n    I've tried a Twitch downloader for windows and it didn't work. It wouldn't download the video. So does anyone know a good site to download twitch vods? Please let me know!!"},
{"Title": "Do I need to reformat my drives?", "Author": "u/Sinnagangsta", "Content": "My Plex server storage is running off a WD MyCloud EX4. When I first started my server I only had 1 4TB drive, but I quickly outgrew that. The drive mode is set as JBOD “one drive”. I have another 4TB drive that I want to put in my NAS, but when I go in to change the RAID mode, I get warnings saying that all data will be lost. I know my only RAID options are 0 and 1. I believe I can also use JBOD as well with two drives? I’m not worried about redundancy as I can easily redownload content but would not like to have my drives erased just to add another drive. What would be the best way to move forward?"},
{"Title": "Download from Google Sites Embedded Image Pages", "Author": "u/kylemj89", "Content": "I am trying to download batch urls and renaming each image in sequence order.\n  \n\n    The images are saves with unique urls from google sites and fails to download after multiple saves using python BeautifulSoup and request\n  \n\n    Wget runs into the same\n  \n\n    HTTrack fails to download the webpages as dispayed (haven't yet got as far as renaming sequence\n  \n\n    Bulk Image downloader doesn't have the ability to rename or save in folders from \nhttps://tigerlovefish.com/\n\n\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/472-1st-january-14th-january-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/474-29th-january-11th-february-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1996/467-23rdoctober-5th-november-1996\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/478-26th-march-8th-april-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/480-23rd-april-6th-may-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/482-21st-may-3rd-june-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/484-18th-june-1st-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/486-17th-july-29th-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/490-10th-september-23rd-september-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/492-8th-october-21st-october-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/494-5th-november-18th-november-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/496-3rd-december-17th-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/tour-programme-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/477-12th-march-25th-march-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/479-9th-april-22nd-april-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/481-7th-may-20th-may-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/483-4th-june-17th-june-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/485-2nd-july-16th-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/487-30th-july-12th-august-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/489-27th-august-9th-september-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/491-24th-september-7th-october-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/493-22nd-october-4th-november-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/495-19th-november-2nd-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/497-17th-december-31st-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/498-1st-january-13th-january-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/500-28th-january-10th-february-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/502-25th-february-10th-march-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/504-25th-march-7th-april-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/506-22nd-april-5th-may-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/508-20th-may-2nd-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/510-17th-june-30th-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/512-15th-july-28th-july-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/514-12th-august-25th-august-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/516-9th-september-22nd-september-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/518-7th-october-20th-october-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/520-4th-november-17th-november-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/522-2nd-december-15th-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/524-30th-december-1998-12th-january-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/499-14th-january-27th-january-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/501-11th-february-24th-february-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/503-11th-march-24th-march-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/505-8th-april-21st-april-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/507-6th-may-19th-may-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/509-3rd-june-16th-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/511-1st-july-14th-july-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/513-29th-july-11th-august-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/515-26th-august-8th-september-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/517-23rd-september-6th-october-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/519-21st-october-3rd-november-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/521-18th-november-1st-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/523-16th-december-29th-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/tour-programme-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/525-13th-january-26th-january-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/527-10th-february-23rd-february-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/529-10th-march-23rd-march-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/531-7th-april-20th-april-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/533-5th-may-18th-may-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/535-2nd-june-15th-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/537-30th-june-13th-july-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/539-28th-july-10th-august-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/541-25th-august-7th-september-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/543-22nd-september-5th-october-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/545-20th-october-2nd-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/547-17th-november-30th-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/549-15th-december-28th-december-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/poll-winners-party-and-tour-programme-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/526-27th-january-9th-february-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/528-24th-february-9th-march-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/530-24th-march-6th-april-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/532-21st-april-4th-may-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/534-19th-may-1st-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/536-16th-june-29th-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/538-14th-july-27th-july-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/540-11th-august-24th-august-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/542-8th-september-21st-september-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/544-6th-october-19th-october-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/546-3rd-november-16th-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/548-1st-december-14th-december-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/550-29thdecember-1989-11th-january-2000\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/poll-winners-party-and-tour-programme-1999\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/551-12thjanuary-25thjanuary-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/553-9th-february-22nd-february-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/555-8th-march-21st-march-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/557-5th-april-18th-april-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/559-3rd-may-16th-may-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/561-31stmay-13thjune-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/563-28thjune-11thjuly-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/565-26th-july-8th-august-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/567-23rd-august-5th-september-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/569-20th-september-3rd-october-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/571-18thoctober-31stoctober2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/573-15thnovember-28thnovember-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/575-13thdecember-9th-january-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/tour-programme-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/552-26th-january-8th-february-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/554-23rd-february-8th-march-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/556-22nd-march-4th-april-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/558-19th-april-2nd-may-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/560-17thmay-30thmay2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/562-14thjune-27thjune-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/564-12thjuly-25thjuly-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/566-9th-august-22nd-august-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/568-6th-september-19th-september-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/570-4th-october-17thoctober-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/572-1st-november-14th-november-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/574-29th-november-12th-december-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/576-free-with-issue-575\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/577-10thjanuary-23rdjanuary-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/579-7th-february-20th-february-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/581-7th-march-20th-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/583-4th-april-17th-april-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/585-2nd-may-15th-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/587-30th-may-12th-june-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/589-27thjune-10thjuly-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/591-25th-july-7th-august-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/593-22nd-august-4th-september-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/595-19th-september-2nd-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/597-17th-october-30th-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/599-14th-november-27th-november-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/601-19th-december-2001-8th-january-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/smash-hits-brits-special-1st-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/578-24thjanuary-6thfebruary-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/580-21st-february-6th-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/582-21st-march-3rd-april-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/584-18th-april-1st-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/586-16th-may-29th-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/588-13thjune-26thjune-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/590-11thjuly-24thjuly-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/592-8th-august-21st-august-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/594-5th-september-18th-september-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/596-3rd-october-16th-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/598-31st-october-13th-november-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/600-28th-november-18th-december-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/602-19th-december-2001-8th-january-2002-free-with-issue-601\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/603-9th-january-22nd-january-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/605-6th-february-19th-february-2002\nhttps://sites.google.com/view/smash-hits-remembered-01/home/2002/607-6th-march-19th-march-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/609-3rd-april-16th-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/611-1st-may-14th-may-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/613-29th-may-11th-june-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/615-26th-june-9th-july-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/617-24th-july-6th-august-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/619-23rd-august-3rd-september-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/621-18th-september-1st-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/623-16th-october-29th-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/625-13th-november-26th-november-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/627-18th-december-2002-7th-january-2003\nhttps://sites.google.com/view/smash-hits-remembered-01/home/2002/604-23rd-january-5th-february-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/606-20th-february-5th-march-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/608-20th-march-2nd-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/610-17th-april-30th-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/612-15th-may-28th-may-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/614-12th-june-25th-june-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/616-10th-july-23rd-july-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/618-7th-august-20th-august-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/620-4th-september-17th-september-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/622-2nd-october-15th-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/624-30th-october-12th-november-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/626-27th-november-17th-december-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/sneak-preview-magazine\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/636-30th-april-13th-may-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/638-28th-may-10th-june-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/642-23rd-july-5th-august-2003\nhttps://sites.google.com/view/smashhitsremembered01/home/2003/summer-quiz-book\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/635-16th-april-29th-april-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2004/659-5th-march-18th-march-2004\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2004/659-5th-march-18th-march-2004"},
{"Title": "Media storage guide for a highschooler", "Author": "u/MintedMince", "Content": "Hi! So I am a highschooler from a third world country and recently I have been struggling to keep all of my data intact. I have been juggling around 1 or 2 spare hard-drives and google accounts to somehow store family photos and other important media with as many backups as I can make. The thing is, I can't really afford a lot to invest into some more high-end, and I really do not want to loose my (had a few close calls, though my backups saved me). So any advice on improving the situation or do most people hang around doing the same thing? Would love to hear from yall :)"},
{"Title": "Best way to contact Seagate for warranty?", "Author": "u/green314159", "Content": "*** Update - I got in contact with Seagate and they wanted me to send them the drive and pay for the shipping costs when sending it in to them. They will cover the shipping costs for the return trip. Does this seem like standard procedure? It's my first time needing to RMA during the warranty period. I live in the USA.\n  \n\n    Original post: A Seagate Barracuda 8TB drive with warranty expiration date sometime in 2025 has failed the other day. What is the best way to get in contact with technical support and get the warranty and replacement going? Sorry if this is the wrong place on Reddit to ask"},
{"Title": "Rosewill hot swap bay source/alternative?", "Author": "u/thecaramelbandit", "Content": "I've got a rosewill 4U case with one of their 4x3.5 hot swap enclosures. I want to add a second but they seem to be out of stock everywhere.\n  \n\n    Anyone have a source for one, or know of an alternative that will also fit?"},
{"Title": "Raid controller advices", "Author": "u/Surax98", "Content": "Hello guys, I am looking for a raid controller to be used over USB 3.2 10Gbps (I know, it's far from being advisable but that's the only thing I can do right now, since my server is a laptop) and I have to choose between the following:\n  \n\n\n\n\n\n    IBM M5015 (PCIe 2.0 x8, SAS 6Gbps, 512MB cache DDR2 800MHz) for 20€ and located in my city\n  \n\n\n\n\n\n    LSI 9271 (PCIe 3.0 x8, SAS 6Gbps, 1GB cache DDR3 idk-how-many MHz) for 33€ shipped from China.\n  \n\n\n\n\n\n    Now, since I am over USB 10Gbps, I am limited in both scenarios, but I'd like to know if that faster and more cache of the 9271 will actually make a difference for a domestic usage. To help you better understand my use cases, I will list them:\n  \n\n\n\n\n\n    Plex and Jellyfin media server\n  \n\n\n\n\n\n    IMMICH for photo synching\n  \n\n\n\n\n\n    Nextcloud for everything else\n  \n\n\n\n\n\n    These are the main I/O bound containers I am running on my server. What do you think? Any other suggestions for a raid controller, instead (which costs less than 40€)?"},
{"Title": "How much damage have I caused from leaving a HDD in the sun?", "Author": "u/JerichoBlows", "Content": "I ordered a refurbished 12TB Seagate Enterprise HDD and it was delivered today while I wasn't home. It was over +100°F (+38°C) degrees today and the sun was beaming directly on the mailbox for 4 hours before I got to it. I suspected the box could have easily been 130°F (55°C) or possibly much hotter having been in the direct sunlight for so long. I immediately put the entire box in the refrigerator. After about 5 minutes in the fridge, I decided to measure the temp using a digital BBQ thermometer. It measured at 104°F (40°C) but this was likely not accurate because I was using a thermometer that is meant to be shoved inside of meat and the box had already been in the fridge for 5 mins.\n  \n\n    How much damage could have been caused from it sitting in the direct +100°F (+38°C) degree sunlight for just over 4 hours? Thanks!"},
{"Title": "How to organize 10+ years of computer and phone backups? ~3TB", "Author": "u/PrivateAd990", "Content": "I'm looking for strategies, tools / software and tips to make my long journey of organizing these backups easier. Main questions at the bottom for a TLDR.\n  \n\n    About the content:\n  \n\n\n\n\n\n    ~3tb total, 15 laptop backups, 12 phone backups\n  \n\n\n\n\n\n    there will be overlap / duplicates in content between backups\n  \n\n\n\n\n\n    backups contain folders I manually dragged onto the portable drive. I never plan to do a full restore of a backup.\n  \n\n\n\n\n\n    backups may contain photos, videos, downloads, photo editing files, code and projects I wrote, a lot of junk I'd like to scrap\n  \n\n\n\n\n\n    Hardware:\n  \n\n\n\n\n\n    A recent MacBook Pro\n  \n\n\n\n\n\n    empty Samsung T9 4TB SSD, ~2000MB/s\n  \n\n\n\n\n\n    WD 2.5\" passport HDD 5TB, ~110MB/s\n  \n\n\n\n\n\n    A second HDD with a copy of the above for redundancy\n  \n\n\n\n\n\n    Plan:\n  \n\n\n\n\n\n    first bring everything on the HDD to the SSD since the SSD is way faster\n  \n\n\n\n\n\n    sort through everything. I need help with this part\n  \n\n\n\n\n\n    move the organized backup back to the HDD since SSD's aren't suitable for cold storage\n  \n\n\n\n\n\n    implement a plan for the 3 2 1 backup method\n  \n\n\n\n\n\n    Questions:\n  \n\n\n\n\n\n    software or tools to sort, organize, de-dupe, delete through everything on the drive. Free or paid\n  \n\n\n\n\n\n    tips for how to search through everything instead of going folder by folder? I'm guessing software can help here.\n  \n\n\n\n\n\n    output folder structure suggestions? Should I just flatten all backups to one? Let's say, all photos I took with my phone from all the backups to one folder? Or is that a bad idea"},
{"Title": "Live sync of data drive over the internet or simple backup. Lsyncd, DRDB or Kopia backup", "Author": "u/1000Zebras", "Content": "Hi, \n  \n\n    I'm curious what you guys would implement in this situation in order to, above all, simply maintain at the very least one solid, off-site backup of all of my data files and also, in the event of something happening to my main data drive on-site, reduce downtime as much as possible. \n  \n\n    Here is my current setup as is relevant to the question at hand: \n  \n\n\n\n\n\n    OrangePi 5 Plus running dietpi (so pretty much just debian) as my main server on-site\n  \n\n\n\n\n\n    One eMMC boot drive on the OrangePi containing the OS and all of my docker-compose files, as well as the OS itself\n  \n\n\n\n\n\n    Recently acquired 14TB external USB drive that houses purely my data for all of my docker containers (and then some outside of those, as well, but not much)\n  \n\n\n\n\n\n    OrangePi is running Tailscale\n  \n\n\n\n\n\n    A second RPi that lives at my brother's house also running Tailscale (so any connection between the two will more than likely be running over the interwebs, but through Tailscale) and with a second 14tb drive identical to the other connected to it, ready for data storage \n  \n\n\n\n\n\n    What I'm wondering is what may be the best strategy for maintaining a backup of the main data drive on the secondary drive, ideally in a mirrored fashion such that were the main drive to fail, I'd simply be able to plug in the secondary drive to the OrangePi, mount it at the same mountpoint as primary would have been, and I'd be back up and running nearly immediately (once the drive was physically moved between locations, of course). \n  \n\n    It's worth noting that, at present, I am dealing with nearly 4.5TB of data on main data drive (also currently backed up to the cloud via Kopia and iDrive E2)\n  \n\n    I've been considering: \n  \n\n\n\n\n\n    Trying out lsyncd or DRDB in order to literally have the drives mirror each other in as near realtime as the connection will allow. I have not used either of these tools yet, however, so I'm not familiar with exactly how they work behind the scene. And also, I realize that it is a lot of data to keep in sync over an internet connection, especially at file or block-level granularity as I believe those tools are designed for. In \"normal\" usage, I am not necessarily adding or changing all that much data on a day to day basis, but were I to make any major shifts in organization, or simply to add a lot more data into the mix suddenly, I'm wondering if the tools would be able to keep up\n  \n\n\n\n\n\n    Running an rsync job over ssh at a specified interval (say, maybe, a couple of times a day) in order to keep the two up date. I would of course again run into the same problem that would arise with the first option were I to make any drastic changes, but theoretically I'd eventually always have a 1 to 1 sync/backup between the two drives\n  \n\n\n\n\n\n    Simply running some sort of backup program from the main Orangepi data drive to the RPi's data drive, again at whatever specified interval (say, maybe, daily). I'd probably have to run some sort of webDAV server on the secondary RPi in order to facilitate backups between the two were I to use Kopia. Or, I suppose I could even run the data drive on RPi on a minio instance and have Kopia backup via the S3 protocol, but this seems perhaps like a little bit of overkill, and it wouldn't necessarily be the sort of 1 to 1 sync I'm shooting for as Kopia would organize the backup data in a fashion that it understands. This would be acceptable, though, as again at the end of the day the most important thing is to have all of the data itself stored safely in both locations, one way or another. \n  \n\n\n\n\n\n    How would you guys go about keeping things in sync between the two data drives? Or, should I just eschew that idea given the limitations of the bandwidth/connection between the two and go for straight backups using Kopia, or some othe rbackup system? \n  \n\n    Please, if you have any thoughts on how you'd architect this scenario, I'd very much appreciate any and perspectives/insights. \n  \n\n    Hopefully that all makes sense. If you need anything clarified, by all means speak up and I'll do my best to address. \n  \n\n    Thank you so very much for your time, expertise, and patience with my rambling question. I look forward to hearing how people weigh in. \n  \n\n    Kind Regards,\n  \n\n    LS"},
{"Title": "Python script to help identify hot swapped drives", "Author": "u/radialmonster", "Content": "No content"},
{"Title": "Question related to the voiceover feature (headphone symbol) in internet archive", "Author": "u/69PepperoniPickles69", "Content": "Do you know if there's a way to upload my own files so that listen to them instead of reading? Or does it have to include actually uploading books and them getting approved, scripted and so on? And if so do you guys know any alternative website where we can upload large texts for listening with decent quality?"},
{"Title": "How best to migrate to new hardware?", "Author": "u/SlayterDevAgain", "Content": "I'm about to build a new NAS. With my current NAS I just kind of threw drives at it as I aquired them (2x 2TB in RAID 1, a 4TB and a 6TB drive in pools by themselves, and 5 6TB drives in an external enclosure in RAID 5).\n  \n\n    In the new build I have 3 10TB drives I'll be adding. I don't necessarily need to keep all the drives from the old build (I at least want the 5x 6TB drives but not externally) but what would be the best way to migrate the data to the new build? Any advice is appreciated.\n  \n\n    Further info: Current build is FreeNAS and I'll probably keep with that or TrueNAS."},
{"Title": "4x5.25\" to 7x3.5\" adapter?", "Author": "u/Adam1394", "Content": "Hello, I look for aforementioned adapter for my Define XL R2 case."},
{"Title": "Backing up Google calendar", "Author": "u/c05d", "Content": "Hi,\n  \n\n    I’ve been using Google calendar for close to 20 years now. It’s started to bother me that my entire life is in Google’s hands and Id like to back this up & transfer to another service like Outlook\n  \n\n    what’s the best way to do this? I want everything including tasks etc to transfer\n  \n\n    thanks"},
{"Title": "What is the best free(non trial) software for converting a dvd to mp4 (ideally with subtitles)?", "Author": "u/Immediate-Risk-7569", "Content": "Every software I found is a trial with either a time limit or an ugly watermark."},
{"Title": "\"Best\" 3.5\" 8Tb HDD Brand?", "Author": "u/Large_Medium_8984", "Content": "This question pops up all the time on here but I only see specific use cases when others ask and nothing really close to what my situation is. I'm looking to bring together all of mine and my families ancient Hard drives, laptop backups, flash drives, externals, family photo scans and videos all onto a few backup HDDs. Just over a Million files @ under 6TB that I'd like to put into an 8Tb HDD (or 2). Photos, Videos, Text Docs, and whatever else might be in there. These drives will not be used for gaming at all, so no need to worry about being rough on the drive with pulling all the time, as I see a lot of people looking for gaming AND storage when asking this. Just something to have peace of mind that nothing could go wrong in a reasonable amount of time with them. I've read good and bad things about both Seagate Barracuda and Western Digital Blue. Are there other 3.5\"s I should also look in to? I'm not expecting these drives to live dormant 5-10 years, but it would be nice. I'd like to read any and all personal experiences users have had over the years."},
{"Title": "What Podcasts to Hoard?", "Author": "u/4bstractals", "Content": "So, I just discovered \nPodcastBulkDownloader\n thanks to a recent \nthread\n, and it's got we wondering...\n  \n\n    If I am going to start assembling a podcast hoard, what are the criteria that I might use to decide what gets included? Obviously, podcasts I \nlike\n would be the primary metric -- but I can download all of those in a couple of hours, and I have a \nlot\n more space.\n  \n\n    So... what about podcasts at risk of going behind a paywall? Podcasts of significant cultural importance? How does one best serve as a casual archivist for such a massive amount of data?"},
{"Title": "[YoYotta] How can I change destination folder in LTO Tape", "Author": "u/ddd102", "Content": "https://preview.redd.it/yoyotta-how-can-i-change-destination-folder-in-lto-tape-v0-6t4uhiti1w5d1.png\n\n    Hi, there.\n  \n\n    I'm very newbie on YoYotta.\nToday, I do my first copy job. 3.5 inch HDD to LTO 8 Tape by YoYotta.\nBut, I wonder how can I change destination folder trees. This software create just same folder trees from the source folders. I don't want that way. I want to create different folder trees on LTO Tapes which I'll do back up my data.\n  \n\n    Anyone knows how can do that?\nAnd is there any LTO or YoYotta user community? even though subreddit.\nI need more information. Official website of YoYotta, already I checked, but I need to story from real users.\n  \n\n    Thanks!"},
{"Title": "Vimms Lair, the largest collections of ROMs, is being taken down.", "Author": "u/snowysysadmin59", "Content": "Corporate greed at it again. Anyone got a backup? 🥺"},
{"Title": "Best Way To Dump/Mirror 16'000 mp3 (Podcast) Files?", "Author": "u/Redditarianist", "Content": "As the title states. I'm looking to upload around 16 thousand podcasted files to the Internet Archive & am looking for the best way.\n  \n\n    Is there an RSS ingest system at all?"},
{"Title": "Any good Kemono/coomer bulk downloaders?", "Author": "u/TravDeMan", "Content": "I've been looking for a while and im struggling to find any"},
{"Title": "Would it be possible to recover previously-deleted photos from a 1998 digital camera?", "Author": "u/Throwaway173638o", "Content": "I was curious in recovering any previously-deleted and current photos off a vintage camera.  The catch is that it doesn't have an SD card and that taking any additional photos after its filled starts to delete them.\n  \n\n    It does use a 3.5 mm cord with some kind of port for vintage computers. I have no problem getting a 3.5 mm to USB cord.\n  \n\n    Is there a similar process with data recovery for SD cards and hard drives that I can do with recovering data from the camera?  Would I also need some drivers for this camera to detect too?\n  \n\n    For context, the digital camera is a Mattel Barbie Digital Camera from 1998."},
{"Title": "M2 Pro/M3 Pro w/ 990 Pro NVMe + 40 Gb/s external", "Author": "u/Direct-Button1358", "Content": "Hi all,\n  \n\n    Systems: Mac Mini M2 Pro, MBP M3 Pro\n  \n\n    Thank you for your time. I am trying to put together an external drive using the Samsung 990 PRO NVMe with an external enclosure rated at 40 Gb/s like the ugreen or acasis.\n  \n\n    I do have a few questions:\n  \n\n\n\n\n\n    What external enclosure would work best for use with my M2 Pro and M3 Pro, I mostly do research and will be using it as an extended mobile storage solution .\n  \n\n\n\n\n\n    Is this overkill for my usage? Keep in mind, the difference in price between this SSD and others that write at half the speed is maybe $50 .  I am using my University start up funds for the purchase.\n  \n\n\n\n\n\n    Additionally: I am interested in eventually setting up NAS using this SSD paired with something like a Yottamaster enclosure.\n  \n\n    Thanks!"},
{"Title": "VirtualDub won't record audio from capture card but sound works fine outside of recording", "Author": "u/Throwaway173638o", "Content": "I'm trying to capture video and audio from my JVC HR-S7100U through a GV-USB2 capture card device.  I am using S-Video as source with composite as my audio sources.  I set the audio source to the device.\n  \n\n    When I try to capture video, the audio doesn't get recorded.  But when I'm not recording under Overview mode, the volume is playing fine.  Preview mode doesn't work for audio too.\n  \n\n    I also don't have any issues recording video and audio from OBS.  However I want to stick with Virtualdub for the best quality.\n  \n\n    I don't know what I can really do to fix this?"},
{"Title": "How to download Twitch vod?", "Author": "u/RainBowSwift71532", "Content": "I've been trying to download a twitch vod but have had no luck in doing so. If I want to download say a YouTube video. Search download YouTube video and a bunch of site pop up. Click on one copy and paste the YouTube link. Pick resolution and click download mad easy. But for some reason it's harder for a twitch vod. I have yet to find a site that will allow me to download a twitch vod. I'm trying to download a streamers recent twitch vod.\n  \n\n    I've tried a Twitch downloader for windows and it didn't work. It wouldn't download the video. So does anyone know a good site to download twitch vods? Please let me know!!"},
{"Title": "Do I need to reformat my drives?", "Author": "u/Sinnagangsta", "Content": "My Plex server storage is running off a WD MyCloud EX4. When I first started my server I only had 1 4TB drive, but I quickly outgrew that. The drive mode is set as JBOD “one drive”. I have another 4TB drive that I want to put in my NAS, but when I go in to change the RAID mode, I get warnings saying that all data will be lost. I know my only RAID options are 0 and 1. I believe I can also use JBOD as well with two drives? I’m not worried about redundancy as I can easily redownload content but would not like to have my drives erased just to add another drive. What would be the best way to move forward?"},
{"Title": "Download from Google Sites Embedded Image Pages", "Author": "u/kylemj89", "Content": "I am trying to download batch urls and renaming each image in sequence order.\n  \n\n    The images are saves with unique urls from google sites and fails to download after multiple saves using python BeautifulSoup and request\n  \n\n    Wget runs into the same\n  \n\n    HTTrack fails to download the webpages as dispayed (haven't yet got as far as renaming sequence\n  \n\n    Bulk Image downloader doesn't have the ability to rename or save in folders from \nhttps://tigerlovefish.com/\n\n\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/472-1st-january-14th-january-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/474-29th-january-11th-february-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1996/467-23rdoctober-5th-november-1996\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/478-26th-march-8th-april-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/480-23rd-april-6th-may-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/482-21st-may-3rd-june-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/484-18th-june-1st-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/486-17th-july-29th-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/490-10th-september-23rd-september-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/492-8th-october-21st-october-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/494-5th-november-18th-november-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/496-3rd-december-17th-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/tour-programme-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/477-12th-march-25th-march-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/479-9th-april-22nd-april-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/481-7th-may-20th-may-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/483-4th-june-17th-june-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/485-2nd-july-16th-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/487-30th-july-12th-august-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/489-27th-august-9th-september-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/491-24th-september-7th-october-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/493-22nd-october-4th-november-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/495-19th-november-2nd-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/497-17th-december-31st-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/498-1st-january-13th-january-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/500-28th-january-10th-february-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/502-25th-february-10th-march-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/504-25th-march-7th-april-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/506-22nd-april-5th-may-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/508-20th-may-2nd-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/510-17th-june-30th-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/512-15th-july-28th-july-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/514-12th-august-25th-august-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/516-9th-september-22nd-september-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/518-7th-october-20th-october-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/520-4th-november-17th-november-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/522-2nd-december-15th-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/524-30th-december-1998-12th-january-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/499-14th-january-27th-january-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/501-11th-february-24th-february-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/503-11th-march-24th-march-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/505-8th-april-21st-april-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/507-6th-may-19th-may-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/509-3rd-june-16th-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/511-1st-july-14th-july-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/513-29th-july-11th-august-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/515-26th-august-8th-september-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/517-23rd-september-6th-october-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/519-21st-october-3rd-november-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/521-18th-november-1st-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/523-16th-december-29th-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/tour-programme-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/525-13th-january-26th-january-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/527-10th-february-23rd-february-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/529-10th-march-23rd-march-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/531-7th-april-20th-april-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/533-5th-may-18th-may-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/535-2nd-june-15th-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/537-30th-june-13th-july-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/539-28th-july-10th-august-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/541-25th-august-7th-september-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/543-22nd-september-5th-october-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/545-20th-october-2nd-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/547-17th-november-30th-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/549-15th-december-28th-december-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/poll-winners-party-and-tour-programme-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/526-27th-january-9th-february-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/528-24th-february-9th-march-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/530-24th-march-6th-april-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/532-21st-april-4th-may-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/534-19th-may-1st-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/536-16th-june-29th-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/538-14th-july-27th-july-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/540-11th-august-24th-august-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/542-8th-september-21st-september-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/544-6th-october-19th-october-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/546-3rd-november-16th-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/548-1st-december-14th-december-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/550-29thdecember-1989-11th-january-2000\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/poll-winners-party-and-tour-programme-1999\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/551-12thjanuary-25thjanuary-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/553-9th-february-22nd-february-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/555-8th-march-21st-march-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/557-5th-april-18th-april-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/559-3rd-may-16th-may-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/561-31stmay-13thjune-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/563-28thjune-11thjuly-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/565-26th-july-8th-august-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/567-23rd-august-5th-september-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/569-20th-september-3rd-october-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/571-18thoctober-31stoctober2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/573-15thnovember-28thnovember-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/575-13thdecember-9th-january-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/tour-programme-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/552-26th-january-8th-february-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/554-23rd-february-8th-march-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/556-22nd-march-4th-april-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/558-19th-april-2nd-may-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/560-17thmay-30thmay2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/562-14thjune-27thjune-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/564-12thjuly-25thjuly-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/566-9th-august-22nd-august-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/568-6th-september-19th-september-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/570-4th-october-17thoctober-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/572-1st-november-14th-november-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/574-29th-november-12th-december-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/576-free-with-issue-575\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/577-10thjanuary-23rdjanuary-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/579-7th-february-20th-february-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/581-7th-march-20th-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/583-4th-april-17th-april-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/585-2nd-may-15th-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/587-30th-may-12th-june-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/589-27thjune-10thjuly-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/591-25th-july-7th-august-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/593-22nd-august-4th-september-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/595-19th-september-2nd-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/597-17th-october-30th-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/599-14th-november-27th-november-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/601-19th-december-2001-8th-january-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/smash-hits-brits-special-1st-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/578-24thjanuary-6thfebruary-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/580-21st-february-6th-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/582-21st-march-3rd-april-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/584-18th-april-1st-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/586-16th-may-29th-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/588-13thjune-26thjune-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/590-11thjuly-24thjuly-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/592-8th-august-21st-august-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/594-5th-september-18th-september-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/596-3rd-october-16th-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/598-31st-october-13th-november-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/600-28th-november-18th-december-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/602-19th-december-2001-8th-january-2002-free-with-issue-601\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/603-9th-january-22nd-january-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/605-6th-february-19th-february-2002\nhttps://sites.google.com/view/smash-hits-remembered-01/home/2002/607-6th-march-19th-march-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/609-3rd-april-16th-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/611-1st-may-14th-may-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/613-29th-may-11th-june-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/615-26th-june-9th-july-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/617-24th-july-6th-august-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/619-23rd-august-3rd-september-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/621-18th-september-1st-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/623-16th-october-29th-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/625-13th-november-26th-november-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/627-18th-december-2002-7th-january-2003\nhttps://sites.google.com/view/smash-hits-remembered-01/home/2002/604-23rd-january-5th-february-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/606-20th-february-5th-march-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/608-20th-march-2nd-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/610-17th-april-30th-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/612-15th-may-28th-may-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/614-12th-june-25th-june-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/616-10th-july-23rd-july-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/618-7th-august-20th-august-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/620-4th-september-17th-september-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/622-2nd-october-15th-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/624-30th-october-12th-november-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/626-27th-november-17th-december-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/sneak-preview-magazine\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/636-30th-april-13th-may-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/638-28th-may-10th-june-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/642-23rd-july-5th-august-2003\nhttps://sites.google.com/view/smashhitsremembered01/home/2003/summer-quiz-book\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/635-16th-april-29th-april-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2004/659-5th-march-18th-march-2004\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2004/659-5th-march-18th-march-2004"},
{"Title": "Media storage guide for a highschooler", "Author": "u/MintedMince", "Content": "Hi! So I am a highschooler from a third world country and recently I have been struggling to keep all of my data intact. I have been juggling around 1 or 2 spare hard-drives and google accounts to somehow store family photos and other important media with as many backups as I can make. The thing is, I can't really afford a lot to invest into some more high-end, and I really do not want to loose my (had a few close calls, though my backups saved me). So any advice on improving the situation or do most people hang around doing the same thing? Would love to hear from yall :)"},
{"Title": "Best way to contact Seagate for warranty?", "Author": "u/green314159", "Content": "*** Update - I got in contact with Seagate and they wanted me to send them the drive and pay for the shipping costs when sending it in to them. They will cover the shipping costs for the return trip. Does this seem like standard procedure? It's my first time needing to RMA during the warranty period. I live in the USA.\n  \n\n    Original post: A Seagate Barracuda 8TB drive with warranty expiration date sometime in 2025 has failed the other day. What is the best way to get in contact with technical support and get the warranty and replacement going? Sorry if this is the wrong place on Reddit to ask"},
{"Title": "Rosewill hot swap bay source/alternative?", "Author": "u/thecaramelbandit", "Content": "I've got a rosewill 4U case with one of their 4x3.5 hot swap enclosures. I want to add a second but they seem to be out of stock everywhere.\n  \n\n    Anyone have a source for one, or know of an alternative that will also fit?"},
{"Title": "Raid controller advices", "Author": "u/Surax98", "Content": "Hello guys, I am looking for a raid controller to be used over USB 3.2 10Gbps (I know, it's far from being advisable but that's the only thing I can do right now, since my server is a laptop) and I have to choose between the following:\n  \n\n\n\n\n\n    IBM M5015 (PCIe 2.0 x8, SAS 6Gbps, 512MB cache DDR2 800MHz) for 20€ and located in my city\n  \n\n\n\n\n\n    LSI 9271 (PCIe 3.0 x8, SAS 6Gbps, 1GB cache DDR3 idk-how-many MHz) for 33€ shipped from China.\n  \n\n\n\n\n\n    Now, since I am over USB 10Gbps, I am limited in both scenarios, but I'd like to know if that faster and more cache of the 9271 will actually make a difference for a domestic usage. To help you better understand my use cases, I will list them:\n  \n\n\n\n\n\n    Plex and Jellyfin media server\n  \n\n\n\n\n\n    IMMICH for photo synching\n  \n\n\n\n\n\n    Nextcloud for everything else\n  \n\n\n\n\n\n    These are the main I/O bound containers I am running on my server. What do you think? Any other suggestions for a raid controller, instead (which costs less than 40€)?"},
{"Title": "How much damage have I caused from leaving a HDD in the sun?", "Author": "u/JerichoBlows", "Content": "I ordered a refurbished 12TB Seagate Enterprise HDD and it was delivered today while I wasn't home. It was over +100°F (+38°C) degrees today and the sun was beaming directly on the mailbox for 4 hours before I got to it. I suspected the box could have easily been 130°F (55°C) or possibly much hotter having been in the direct sunlight for so long. I immediately put the entire box in the refrigerator. After about 5 minutes in the fridge, I decided to measure the temp using a digital BBQ thermometer. It measured at 104°F (40°C) but this was likely not accurate because I was using a thermometer that is meant to be shoved inside of meat and the box had already been in the fridge for 5 mins.\n  \n\n    How much damage could have been caused from it sitting in the direct +100°F (+38°C) degree sunlight for just over 4 hours? Thanks!"},
{"Title": "How to organize 10+ years of computer and phone backups? ~3TB", "Author": "u/PrivateAd990", "Content": "I'm looking for strategies, tools / software and tips to make my long journey of organizing these backups easier. Main questions at the bottom for a TLDR.\n  \n\n    About the content:\n  \n\n\n\n\n\n    ~3tb total, 15 laptop backups, 12 phone backups\n  \n\n\n\n\n\n    there will be overlap / duplicates in content between backups\n  \n\n\n\n\n\n    backups contain folders I manually dragged onto the portable drive. I never plan to do a full restore of a backup.\n  \n\n\n\n\n\n    backups may contain photos, videos, downloads, photo editing files, code and projects I wrote, a lot of junk I'd like to scrap\n  \n\n\n\n\n\n    Hardware:\n  \n\n\n\n\n\n    A recent MacBook Pro\n  \n\n\n\n\n\n    empty Samsung T9 4TB SSD, ~2000MB/s\n  \n\n\n\n\n\n    WD 2.5\" passport HDD 5TB, ~110MB/s\n  \n\n\n\n\n\n    A second HDD with a copy of the above for redundancy\n  \n\n\n\n\n\n    Plan:\n  \n\n\n\n\n\n    first bring everything on the HDD to the SSD since the SSD is way faster\n  \n\n\n\n\n\n    sort through everything. I need help with this part\n  \n\n\n\n\n\n    move the organized backup back to the HDD since SSD's aren't suitable for cold storage\n  \n\n\n\n\n\n    implement a plan for the 3 2 1 backup method\n  \n\n\n\n\n\n    Questions:\n  \n\n\n\n\n\n    software or tools to sort, organize, de-dupe, delete through everything on the drive. Free or paid\n  \n\n\n\n\n\n    tips for how to search through everything instead of going folder by folder? I'm guessing software can help here.\n  \n\n\n\n\n\n    output folder structure suggestions? Should I just flatten all backups to one? Let's say, all photos I took with my phone from all the backups to one folder? Or is that a bad idea"},
{"Title": "Live sync of data drive over the internet or simple backup. Lsyncd, DRDB or Kopia backup", "Author": "u/1000Zebras", "Content": "Hi, \n  \n\n    I'm curious what you guys would implement in this situation in order to, above all, simply maintain at the very least one solid, off-site backup of all of my data files and also, in the event of something happening to my main data drive on-site, reduce downtime as much as possible. \n  \n\n    Here is my current setup as is relevant to the question at hand: \n  \n\n\n\n\n\n    OrangePi 5 Plus running dietpi (so pretty much just debian) as my main server on-site\n  \n\n\n\n\n\n    One eMMC boot drive on the OrangePi containing the OS and all of my docker-compose files, as well as the OS itself\n  \n\n\n\n\n\n    Recently acquired 14TB external USB drive that houses purely my data for all of my docker containers (and then some outside of those, as well, but not much)\n  \n\n\n\n\n\n    OrangePi is running Tailscale\n  \n\n\n\n\n\n    A second RPi that lives at my brother's house also running Tailscale (so any connection between the two will more than likely be running over the interwebs, but through Tailscale) and with a second 14tb drive identical to the other connected to it, ready for data storage \n  \n\n\n\n\n\n    What I'm wondering is what may be the best strategy for maintaining a backup of the main data drive on the secondary drive, ideally in a mirrored fashion such that were the main drive to fail, I'd simply be able to plug in the secondary drive to the OrangePi, mount it at the same mountpoint as primary would have been, and I'd be back up and running nearly immediately (once the drive was physically moved between locations, of course). \n  \n\n    It's worth noting that, at present, I am dealing with nearly 4.5TB of data on main data drive (also currently backed up to the cloud via Kopia and iDrive E2)\n  \n\n    I've been considering: \n  \n\n\n\n\n\n    Trying out lsyncd or DRDB in order to literally have the drives mirror each other in as near realtime as the connection will allow. I have not used either of these tools yet, however, so I'm not familiar with exactly how they work behind the scene. And also, I realize that it is a lot of data to keep in sync over an internet connection, especially at file or block-level granularity as I believe those tools are designed for. In \"normal\" usage, I am not necessarily adding or changing all that much data on a day to day basis, but were I to make any major shifts in organization, or simply to add a lot more data into the mix suddenly, I'm wondering if the tools would be able to keep up\n  \n\n\n\n\n\n    Running an rsync job over ssh at a specified interval (say, maybe, a couple of times a day) in order to keep the two up date. I would of course again run into the same problem that would arise with the first option were I to make any drastic changes, but theoretically I'd eventually always have a 1 to 1 sync/backup between the two drives\n  \n\n\n\n\n\n    Simply running some sort of backup program from the main Orangepi data drive to the RPi's data drive, again at whatever specified interval (say, maybe, daily). I'd probably have to run some sort of webDAV server on the secondary RPi in order to facilitate backups between the two were I to use Kopia. Or, I suppose I could even run the data drive on RPi on a minio instance and have Kopia backup via the S3 protocol, but this seems perhaps like a little bit of overkill, and it wouldn't necessarily be the sort of 1 to 1 sync I'm shooting for as Kopia would organize the backup data in a fashion that it understands. This would be acceptable, though, as again at the end of the day the most important thing is to have all of the data itself stored safely in both locations, one way or another. \n  \n\n\n\n\n\n    How would you guys go about keeping things in sync between the two data drives? Or, should I just eschew that idea given the limitations of the bandwidth/connection between the two and go for straight backups using Kopia, or some othe rbackup system? \n  \n\n    Please, if you have any thoughts on how you'd architect this scenario, I'd very much appreciate any and perspectives/insights. \n  \n\n    Hopefully that all makes sense. If you need anything clarified, by all means speak up and I'll do my best to address. \n  \n\n    Thank you so very much for your time, expertise, and patience with my rambling question. I look forward to hearing how people weigh in. \n  \n\n    Kind Regards,\n  \n\n    LS"},
{"Title": "Python script to help identify hot swapped drives", "Author": "u/radialmonster", "Content": "No content"},
{"Title": "Question related to the voiceover feature (headphone symbol) in internet archive", "Author": "u/69PepperoniPickles69", "Content": "Do you know if there's a way to upload my own files so that listen to them instead of reading? Or does it have to include actually uploading books and them getting approved, scripted and so on? And if so do you guys know any alternative website where we can upload large texts for listening with decent quality?"},
{"Title": "How best to migrate to new hardware?", "Author": "u/SlayterDevAgain", "Content": "I'm about to build a new NAS. With my current NAS I just kind of threw drives at it as I aquired them (2x 2TB in RAID 1, a 4TB and a 6TB drive in pools by themselves, and 5 6TB drives in an external enclosure in RAID 5).\n  \n\n    In the new build I have 3 10TB drives I'll be adding. I don't necessarily need to keep all the drives from the old build (I at least want the 5x 6TB drives but not externally) but what would be the best way to migrate the data to the new build? Any advice is appreciated.\n  \n\n    Further info: Current build is FreeNAS and I'll probably keep with that or TrueNAS."},
{"Title": "4x5.25\" to 7x3.5\" adapter?", "Author": "u/Adam1394", "Content": "Hello, I look for aforementioned adapter for my Define XL R2 case."},
{"Title": "Backing up Google calendar", "Author": "u/c05d", "Content": "Hi,\n  \n\n    I’ve been using Google calendar for close to 20 years now. It’s started to bother me that my entire life is in Google’s hands and Id like to back this up & transfer to another service like Outlook\n  \n\n    what’s the best way to do this? I want everything including tasks etc to transfer\n  \n\n    thanks"},
{"Title": "What is the best free(non trial) software for converting a dvd to mp4 (ideally with subtitles)?", "Author": "u/Immediate-Risk-7569", "Content": "Every software I found is a trial with either a time limit or an ugly watermark."},
{"Title": "\"Best\" 3.5\" 8Tb HDD Brand?", "Author": "u/Large_Medium_8984", "Content": "This question pops up all the time on here but I only see specific use cases when others ask and nothing really close to what my situation is. I'm looking to bring together all of mine and my families ancient Hard drives, laptop backups, flash drives, externals, family photo scans and videos all onto a few backup HDDs. Just over a Million files @ under 6TB that I'd like to put into an 8Tb HDD (or 2). Photos, Videos, Text Docs, and whatever else might be in there. These drives will not be used for gaming at all, so no need to worry about being rough on the drive with pulling all the time, as I see a lot of people looking for gaming AND storage when asking this. Just something to have peace of mind that nothing could go wrong in a reasonable amount of time with them. I've read good and bad things about both Seagate Barracuda and Western Digital Blue. Are there other 3.5\"s I should also look in to? I'm not expecting these drives to live dormant 5-10 years, but it would be nice. I'd like to read any and all personal experiences users have had over the years."},
{"Title": "What Podcasts to Hoard?", "Author": "u/4bstractals", "Content": "So, I just discovered \nPodcastBulkDownloader\n thanks to a recent \nthread\n, and it's got we wondering...\n  \n\n    If I am going to start assembling a podcast hoard, what are the criteria that I might use to decide what gets included? Obviously, podcasts I \nlike\n would be the primary metric -- but I can download all of those in a couple of hours, and I have a \nlot\n more space.\n  \n\n    So... what about podcasts at risk of going behind a paywall? Podcasts of significant cultural importance? How does one best serve as a casual archivist for such a massive amount of data?"},
{"Title": "[YoYotta] How can I change destination folder in LTO Tape", "Author": "u/ddd102", "Content": "https://preview.redd.it/yoyotta-how-can-i-change-destination-folder-in-lto-tape-v0-6t4uhiti1w5d1.png\n\n    Hi, there.\n  \n\n    I'm very newbie on YoYotta.\nToday, I do my first copy job. 3.5 inch HDD to LTO 8 Tape by YoYotta.\nBut, I wonder how can I change destination folder trees. This software create just same folder trees from the source folders. I don't want that way. I want to create different folder trees on LTO Tapes which I'll do back up my data.\n  \n\n    Anyone knows how can do that?\nAnd is there any LTO or YoYotta user community? even though subreddit.\nI need more information. Official website of YoYotta, already I checked, but I need to story from real users.\n  \n\n    Thanks!"},
{"Title": "Vimms Lair, the largest collections of ROMs, is being taken down.", "Author": "u/snowysysadmin59", "Content": "Corporate greed at it again. Anyone got a backup? 🥺"},
{"Title": "Best Way To Dump/Mirror 16'000 mp3 (Podcast) Files?", "Author": "u/Redditarianist", "Content": "As the title states. I'm looking to upload around 16 thousand podcasted files to the Internet Archive & am looking for the best way.\n  \n\n    Is there an RSS ingest system at all?"},
{"Title": "Any good Kemono/coomer bulk downloaders?", "Author": "u/TravDeMan", "Content": "I've been looking for a while and im struggling to find any"},
{"Title": "Would it be possible to recover previously-deleted photos from a 1998 digital camera?", "Author": "u/Throwaway173638o", "Content": "I was curious in recovering any previously-deleted and current photos off a vintage camera.  The catch is that it doesn't have an SD card and that taking any additional photos after its filled starts to delete them.\n  \n\n    It does use a 3.5 mm cord with some kind of port for vintage computers. I have no problem getting a 3.5 mm to USB cord.\n  \n\n    Is there a similar process with data recovery for SD cards and hard drives that I can do with recovering data from the camera?  Would I also need some drivers for this camera to detect too?\n  \n\n    For context, the digital camera is a Mattel Barbie Digital Camera from 1998."},
{"Title": "WD MyPassport Ultra vs WD Black [6TB]", "Author": "u/Previous_Day4842", "Content": "Is one of these drives better than the other? It seems on here some people mention the WD black being total rubish. I really like these drives for the aesthetic, but have never owned one. I have owned the MyPassport models for years and years and have never had an issue. Are they equal and i'm safe to get the WD Black for aesthetics? Or would it be wiser to get the MyPassport Ultra, with the metal build and USB-C Connection?\n  \n\n    I would be using this drive for time machine backups. Aesthetics are rather important to me, so it is a bummer that the MyPassport ultra does not come in black."},
{"Title": "How much free space should I leave on my 1TB HDD with a btrfs file system ?", "Author": "u/Yukinoooo", "Content": "Is it dangerous to leave 80GB on my 1TB HDD (only files without OS) ? I'm using GNU/Linux + KDE"},
{"Title": "Starting my self owned drive journey", "Author": "u/tessereis", "Content": "I'm moving from various cloud drives to local backups. I really would like some suggestion from this sub.\n  \n\n    I've 2 backups.\n  \n\n\n\n\n\n    SSD 1TB - formatted to exFat. I've heard bad things about this fs but I really need this drive to be cross compatible and plug and play. This seemed to be the only sane choice.\n  \n\n\n\n\n\n    HDD 2TB - formatted to ext4/zfs. Haven't decided on this yet, will probably go with zfs because it auto recovers and doesn't need to run something like fsck. Increased size for versioning.\n  \n\n\n\n\n\n    I'm planning to keep my SSD portable (on a trip etc) and whenever I'm at home, connect it to a system (rasp pi or a regular PC) with photoprism or librephotos installed. HDD is going to be the cold storage.\n  \n\n    I tried to follow the 3-2-1 rule but can't afford to get another drive just yet. Although, I'm thinking to get S3 Glacier for that offsite storage."},
{"Title": "SFTP/FTP/Local File Move", "Author": "u/Dking2204", "Content": "Coming from MacOS using Transit to Windows, I would like to move a large number of personal files from the Mac drives to the new Windows machine. What software is recommended? I keep seeing that Filezilla needs to be more secure, and I'm unsure about others. I appreciate any help you can provide."},
{"Title": "Offline served and auto-updating Wikipedia instance", "Author": "u/BarthoAz", "Content": "Hello!\n  \n\n    I was wondering if there was some tool out there that could:\n  \n\n\n\n\n\n    download the entire Wikipedia database (w/ images and in maybe 2~3 languages)\n  \n\n\n\n\n\n    keep it synced/updated\n  \n\n\n\n\n\n    being able to serve it statically through a self-hosted website\n  \n\n\n\n\n\n    bonus: keeping all of the data in files easily readable by humans, even without any tool\n  \n\n\n\n\n\n    Quite a wishlist, but I want to know if something like this (or similar) already exists before trying to do it myself!"},
{"Title": "NOAA Coast Survey is shutting down the Raster Navigational Chart Tile Service (RNC) and other related services", "Author": "u/TheHornedGod", "Content": "I stumbled across this while doing some research and noticed there are no threads here about it. I'm late to the party on this but I thought if there are some people already on the case then maybe users from this subreddit might be interested in finding them to help with backups and hosting.\n  \n\n    The NOAA is shutting down some of their online and printed services and they are removing that data from their websites. This project actually began in 2021 and is set to be completed in 2025.\n  \n\n\nSo what is the RNC?\n\n\n\n\n\n    NOAA's RNC Tile Service (WMTS)\n  \n\n\n\n\n\n    The NOAA RNC Tile Service provides standardized nautical chart tilesets for the public, eliminating the need for application developers to regularly undergo the cumbersome process of transforming NOAA BSB files into tilesets. It provides geo-referenced charts compatible with the Web Map Tile Specifications (WMTS) and Tile Map Service Specification (TMS). All tilesets are published on a weekly basis.\n  \n\n\n\n    Original website (already deleted?): \nhttps://tileservice.charts.noaa.gov\n\n\n\n    Their annoucement:\n  \n\n\n\n    NOAA will shut down its Raster Navigational Chart (RNC) Tile Service and the online RNC Viewer on October 1, 2021. The NOAA Seamless Raster Navigational Chart Services will be shut down on January 1, 2022. This is part of a larger NOAA program to end production and maintenance of all NOAA traditional paper and raster nautical charts that was announced in the Federal Register in November 2019.\n  \n\n\n\n\n\n    Cancellation of traditional NOAA paper nautical charts and associated raster nautical chart products, such as BookletCharts™ and Raster Navigational Charts (RNC) will occur over the next four years and be completed by January 2025. More information about this overarching program to “sunset” traditional  nautical chart products is available on the “\nFarewell to Traditional Nautical Charts\n” web page.\n  \n\n\n\n    -- \nsource\n\n\n\n\nWhy help with this project?\n\n\n\n    The abandoned nautical tilesets and paper charts have been replaced with GIS offerings for modern equipment, however these older documents were a failsafe for smaller vessels and operations. They may not have the technical know how to backup and retrieve this data otherwise."},
{"Title": "Photo deduplication on Mac", "Author": "u/ChumboChili", "Content": "Hello all -\n  \n\n    I have a significant volume of photo dupes to work through, but I am a bit particular as to how I want to proceed through them, and so I wanted to ask about those with experience with deduplication apps.\n  \n\n    I want to create a master set of photos, organized by year and device.  Accordingly, in a serial fashion, I want to use a folder as a reference source, compare its contents to a second folder, and in the second folder I would like to be able to:\n  \n\n    --easily see the non-duplicate photos;\n  \n\n    --also be able to see the duplicate photos, and delete them.\n  \n\n    I would also like to be able to identify and delete duplicates WITHIN a folder and its subfolders, although I understand that functionality is pretty standard.\n  \n\n    One final question, is whether this can also be performed for video files.\n  \n\n    Any recommendations to achieve this workflow would be most appreciated.  Thanks all."},
{"Title": "How do you archive emails?", "Author": "u/Commercial_Union_296", "Content": "How were you able to save your emails from many years back?"},
{"Title": "For Those That Archive YouTube Videos From Your Favorite Channels, Do You Archive Your Videos in the Highest Possible Quality or Do You Limit The Quality of Your Downloads to Save Storage Space?", "Author": "u/Ripcitytoker", "Content": "I personally always save videos in the highest quality possible, regardless of how much storage it takes u. Does anyone else do this or do you download videos in lower quality (like 1080p instead of 4k) in order to use up less storage space?"},
{"Title": "Good Databasing software for digital media (movies in particular)?", "Author": "u/sbourwest", "Content": "My Dad has a pretty extensive collection of movies (close to 6,000), and his only real method for cataloguing is a private streaming platform (Emby), but he's interested in creating a database for all of his content, but doesn't want to have to populate the whole thing himself, he'd rather be able to just type in the media and have it pull from online databases like IMDB or the like.\n  \n\n    He would prefer PC software, no mobile apps or online-only (have to register an account) platforms, browser-based is fine though.\n  \n\n    I've tried doing a bit of looking myself but most personal film cataloguing software is focused on physical media (DVDs, Blu-Rays, etc.) and not a digital collection."},
{"Title": "Best software to automatically catalog / search your data", "Author": "u/ripperdoc", "Content": "New to this subreddit. For long believed in manual cataloguing but I’m starting to feel I don’t have time for that. What’s the go to software for automatically cataloguing data, from documents to websites to media?"},
{"Title": "Uploading files to a shared folder consumes my storage space?", "Author": "u/IseeYouLater", "Content": "Hello,\n  \n\n    as mentioned in the headline I am slightly confused.\n  \n\n    A friend shared a google drive folder with me to upload our vacation pics - I created a Subfolder in his shared folder and now when I upload my pics to the subfolder that I created, the files count against my storage limit. Which is bad cuz I am already very close to max.\n  \n\n    Is this intended? Everywhere on the net it says subfolders should count against the parent folder's storage limit.\n  \n\n    What am I missing here?"},
{"Title": "How often does the pCloud discount $890 10TB lifetime come around? I need to move my GSuite data soon to a new place.", "Author": "u/n4n4n4n4n", "Content": "(I will be using cryptomator to mask the data)"},
{"Title": "Multipath aggregation aware file copy software?", "Author": "u/pally_nid", "Content": "I barely know how to ask this question...\n  \n\n    Would anyone know of a file copying software that can handle a source/destination like a NAS with multiple 1gb network interfaces.\nMaybe its best if I describe the effect I am looking for.\n  \n\n    Start a copy job, reach the avg-peak of 100MB/s and then the software becomes aware of this and then continues to enumerate folders as subtasks and starts these folders on the other IP addresses available from the NAS.\n  \n\n    So, if the NAS had 2 gb/s NICs, both would be saturated at 100MB/s, rather than only one granting higher thorough-put.\n  \n\n    Thank you for reading."},
{"Title": "FLAC Server + Player that handles Ratings well, last played?", "Author": "u/th_teacher", "Content": "I believe nothing works well with \"standard\" tags, only stored in the database?\n  \n\n    I do not need multi-user handling.\n  \n\n    But I do want to be able to periodically export from the database and store the ratings in the FLAC tags for playlist creation\n  \n\n    hoping other servers/players will at least use them read-only\n  \n\n    Last played would be nice too, is played - count a thing?"},
{"Title": "How to backup an entire website from a few days ago?", "Author": "u/TheGoodSir1", "Content": "Since vimm.net got in trouble with Nintendo I can't get new games for my GBC (I have a flash cart) and I was wondering if it would be possible to back up the entirety of vimm.net to archive.org   or a personal file/files, I know you can save individual webpages but since in some sections of the website there is near 20,000 pages, it would take forever. Are there any ways too?"},
{"Title": "using gallery-dl for downloading sub. only content in deviantart", "Author": "u/South-Order2046", "Content": "I want to download a gallery of a creator that I have been subscribed to. I first tried download them with using \"WFDownloaderApp\" but it only downloaded the public images and gave me an error while trying to download the private images (subscribers only). Then, I tried my chances with gallery-dl. First, I had tried without adding any .conf file, but it gave me \"API responded with 429 Too Many Requests.\" error.  It doesn't work with any amounts of delay. Next, I added the .conf file, put my own client_id and client_secret values into that file. But it still give me the same error. How can I solve this problem? Thank you all for your answers."},
{"Title": "Does anyone know how to look into .rpk files? (Related to EA games)", "Author": "u/EUOS_the_cat", "Content": "Let me know if this isn't the right sub for this, and if it isn't, point me in the right direction please.\n  \n\n    I'm on a mission to extract models from old Littlest Pet Shop games (PC, Wii), and unfortunately they were made by EA. Me and another person have looked into it, and the models are stored in the .big format. These have ways to be opened, however they lead to the .rpk files that have no information that either of us could find on how to get into. The only info about them I see is that they're used as skins for RadLight, which obviously isn't what these files are.\n  \n\n    If anyone knows a way to get into these files, I'd be very thankful."},
{"Title": "CGSociety - Site Rip", "Author": "u/valdearg", "Content": "Completely forgot about this from \nhttps://old.reddit.com/r/DataHoarder/comments/18tlukv/cgsociety_is_closing_up_soon_decades_of_valuable/\n\n\n\n\nhttps://archive.org/details/cgsocietyarchive\n\n\n\n    It's about 300GB+\n  \n\n    Images has JSON files with their metadata alongside it.\n  \n\n    Torrent needs to be regenerated I think, not sure if there's a way to do that."},
{"Title": "How far does your email archive go back to?", "Author": "u/Commercial_Union_296", "Content": "My sent email archive goes back to 2013."},
{"Title": "Sorting tens of thousands of recovered video files by presence of audio?", "Author": "u/CyberpunkLover", "Content": "I've been collecting music video clips for about 15 years now, and collected something like 85k clips.\nI've been putting everything on hard drives, then after filling them up, moving everything to larger drive.\nThe last drive I've used was some Western Digital Blue 8TB drive, and last week it filled up, so I purchased a new 20TB drive and was about to copy everything into it, but before I could do that, the WD drive failed.\n  \n\n    I've used few file restoration programs, and managed to salvage about 80% of everything that was on the drive, but the problem is, like 70% of what I've restored is either corrupted, or doesn't have audio. And all the files were put into ~75 different folders, with around 900 or so files each.\nI'd like to sort out the files with audio and without, in order to save the good ones and get rid of the bad ones.\nAll files were renamed to random letters and numbers by recovery software, so the corrupted and muted files are basically completely useless to me, since I can't even use the file names to find out what files those are.\n  \n\n    All the files are either .mp4, .mkv, .avi, .mov or .wmv.\n  \n\n    Sorting through tens of thousands of files would take me months, and I just don't have the time or patience to do that. I've had the idea of importing files into video editing soft like Premiere and look at the generated waveform to find out good files,  but there's quite a lot of files with codecs unsupported by Premiere, like VP09 and such, so vast majority of files, even with audio present show up as flat lines on Premiere waveform, thus this method is completely useless to me. Like, importing a folder of restored files only generates maybe 20-30 waveforms, the rest are flat lines, and so manual sorting is still required.\n  \n\n    Anyone know of any software that can scan thousands of files and either mark or separate them by presence of audio, or have some other solution?"},
{"Title": "Hard Drive Formatting from Windows to Mac  Catch-22 Situation", "Author": "u/djensenteeken", "Content": "Hey everyone, so i have a situation i need help with.\n  \n\n    I recently switched over from my HP Omen laptop to a new MacBook Pro. Not knowing about the data formatting situation, I backed up all my data from my old laptop onto my Seagate Expansion Portable Drive 2TB. When using my MacBook, I noticed I couldn't upload files to this harddrive because the file formatting was different.\n  \n\n    I found on the internet that to switch the external harddrive from NTFS to APFS I can use Disk Utility to reformat the device. For this to happen however i have to backup the files that I have on my external harddrive, because to reformat it the harddrive has to be erased.\n  \n\n    The thing is, if i back-up the files to my old HP Omen, I can't reupload the files back to my external hard drive because it has been reformatted to APFS, and the files are NTFS. I also can't back-up the files to my new MacBook, because the size of my files is way to big for the internal storage of my Macbook!\n  \n\n    Is the only option for this really just to buy another external harddrive coded to APFS, or keep my files on my hard drive on my old dusty laptop that barely functions? This feels like a catch-22 situation to me.\n  \n\n    Sorry if this question has a) been answered already or b) is not relevant to this subreddit. Any help is appreciated!"},
{"Title": "NAS nvme build options", "Author": "u/AHappyGaijin", "Content": "Hello, i am currently building my first NAS using a Topton N100 board.\n  \n\n    Im currently deciding on which nvme to use as a system drive - currently leaning for a WD Blue SN580 2Tb. My question is if one should get 2 of the same drive to mirror the operating System?\n  \n\n    Using 2 nvme drives would limit the pcie expansion possibility of the board because the second nvme slot shares lanes with the nvme slot. Though currently i have no plans to use a pcie expansion card."},
{"Title": "NVMe SSD enclosure vs Portable external SSD?", "Author": "u/ProFalseIdol", "Content": "I am looking for at least 1TB to store videos and pictures. Travel a lot, so it has to be as convenient and compact as a Flash thumb drive. I saw plenty of recommendations of using NVMe + enclosure for portable consumer storage.\n  \n\n    Then I saw the SSK Portable options (while looking for their enclosure).. Also the Crucial X6..\n  \n\n\nhttps://www.amazon.com/SSK-Portable-External-MacBook-Laptops/dp/B0CL94LX9W?ref_=ast_sto_dp&th=1\n\n\n\n\nWhat are the pros and cons?\n For 87 USD, you have a ready to use USB C or A portable solution. Got a new laptop with USB 4 and USB-C 3.2 Gen 2 ports (I assume I can get that sweet 2000 MB/s read/write)..\n  \n\n    Versus an M.2 NVMe + enclosure that I probably will never upgrade and will be permanently external as if I bought a Thumb drive..\n  \n\n    TIA!"},
{"Title": "Is it worth archiving random pages aimlessly?", "Author": "u/peliciego", "Content": "Hi folks. I wonder if it is worth using the \"wayback machine\" and \"archive.ph\" addons for archiving random websites when you are navigating across the internet.\n  \n\n    Sometimes I focus on old websites (*index.html or other dork commands). Other times, it is local news in my surroundings. And from time to time, websites in minority languages. I don't save locally in large quantities. Do you think this strategy is worth it?\n  \n\n    Sometimes it is like planting a forest. You may never see the results in 100 years."},
{"Title": "Looking for a cloud backup service", "Author": "u/aradbe", "Content": "Hey all,\n  \n\n    so pretty simple, im looking for a cloud service where can i backup some of my important files so ill have them in case i lose them.\n  \n\n    i dont know much about this kinda stuff amd im looking for something simple and reliable, i was interested to see if thers a service where i can start off with purchasing a sub for a set amount of storage and if i want more later i can add a few dollars and expand the storage. like maybe start out with 100gb and expand it to 200gb if i need it later.\n  \n\n    If there nothing like then i would just like a recommendation for a good reliable backup service that will do the job.\n  \n\n    Thanks for any replies !"},
{"Title": "What's your guys system for archiving entire youtube channels look like?", "Author": "u/glowcialist", "Content": "I tried TubeArchivist, and it worked great for maybe 500 vids, but now seems to be completely blocked, I'm assuming that any script utilizing yt-dlp would face similar issues?\n  \n\n    4k tube seemed to work alright for individual playlists at first, but now seems to be consistently throttled to like 50 kb/s.\n  \n\n    Any ideas?\n  \n\n    Edit: Please forgive the missing apostrophe in the title. I won't do it again."},
{"Title": "How do I download a certain video from the wayback machine?", "Author": "u/wiicrafttech", "Content": "This is the link I'm using\n  \n\n\nhttps://web.archive.org/web/20230520032047/https://www.youtube.com/watch?v=Oy2c6Mt9KwY#"},
{"Title": "Looking for some critiquing of my plan.", "Author": "u/OnenonlyAl", "Content": "Thanks for taking the time to read and comment. I'm looking to backup a zpool of media. I had tried to setup a truenas for the data but I didn't love the UI and I have what I need on Ubuntu with docker. My plan is to destroy a zpool of the truenas made of 4x10tb raidz1 and move that pool into the primary server (add a pcie with more sata ports) then use zpool attach to mirror my current 4x8tb raidz1 (mnt) to the newly recreated zpool of the 4x10tb from the old truenas server (named mntbackup). So zpool attach mnt to mntbackup. Sounds like this automatically starts mirroring.\n  \n\n    I know this isn't ideal without being an off-site backup but I'm not the most literate at actually managing this and want something easy. Would I be able to just plug in backup, then unplug the backup pool and cold storage? I don't need perfect redundancy. Would I be able to plug the mntbackup raidz1 back in sometime in the future and the missing new data automatically sync or would I need scripts of rysnc or zfs send receive to add new data?\n  \n\n    Thanks for any insight and help!"},
{"Title": "Suitcase for 3.5\" disks with screwed on HotSwap", "Author": "u/No-Balance-8038", "Content": "Need a way to protect my backup disks that are meant to be stored offsite.\nI already got cases, but they are too small to account for a 3.5\" HDD plus the mount for SilverStone Technology RM43-320-RS.\n  \n\n    What would you guys recommend? I live in Germany. From Amazon would be cool.\nI already have 3.5\" Protection cases but they are not long enough!\nThe HDDs are 17cm long with it."},
{"Title": "Software for finding all files with identical names on a drive", "Author": "u/MisterPenishead", "Content": "I have a hard drive with thousands of files spread across different folders and some of the files have the same name in spite of them having different content. Is there a software I can use to find all files with identical names so that I can rename them?"},
{"Title": "AWS deep freeze pricing", "Author": "u/KingRollos", "Content": "I'm thinking of moving most of my backup to Amazon's deep freeze service. I'm sure it's made complicated deliberately.\n  \n\n    I'm thinking of adding it in bits. Will this cost me more? Do I need to gather it all together and then transfer in 1 go?"},
{"Title": "Im looking to transfer highest quality from Hi-Fi camera for 8mm Tapes.  Which is better: Mini-USB or FireWire?", "Author": "u/Throwaway173638o", "Content": "I have a Sony Hi-Fi camera for 8mm videos that has a FireWire, Mini USB, A/V, and S-video ports.  I want to get the highest quality as possible.  I narrowed down to FireWire or Mini USB transfer for better quality. Which of the two is better overall or are they the same?\n  \n\n    Edit: For context, the camera is a Sony DCR-TRV730 and the tapes are Sony Hi8 MP 8mm Video Cassette.  Cassette also lists it as Digital8 with \"60\" while the Hi8 is listed as \"120\""},
{"Title": "Sort backup raid 1", "Author": "u/sweetestpeach94", "Content": "Hi, I hope I can get some help. I have a Lacie 2big thunderbolt 2 set as Raid 1. I’ve just completed the backup of almost 6TB of data (mainly pics), however half of it are just the mirror copies. Now I would move the original half on another disk, the problem is that the backup isn’t like sort out in different folders, it’s just every file and its copy back to back in sequence all together (file A, file A-2 , file B, file B-2, file C, file C - 2 etc.). So here is my question, how I select just one half of the files to move it in the new disk without their duplicate?"},
{"Title": "Alternatives to Epson V600", "Author": "u/ass-master-blaster", "Content": "The V600 is discontinued in my country (past prices are around $650) and the V850 is too expensive ($1600). Are there any alternatives around the same price and quality for a newer model scanner? I've looked at the FastFoto and don't like the quality of the photos and am happy to spend the time with a flatbed scanner."},
{"Title": "Ibms first commercially available 5mb ramac's disk storage 1956", "Author": "u/noideawhatimdoing444", "Content": "No content"},
{"Title": "are SSK USB flash drives safe?", "Author": "u/retrorays", "Content": "I read how USB drives can run malware to act as a USB keyboard and then compromise your system. I see the SSK drives are from China. Do we know if they are safe?"},
{"Title": "Need some help sanity checking my UnRAID 'Reamalgamation' project, specifically Disk Shelves", "Author": "u/AshleyUncia", "Content": "So here's the situation; I currently live with my spouse in a one bedroom apartment built in 1922.  For this reason there are some real issues with the loads on the electrical circuits between my network storage, gaming PC, HTPCs and so on.  Plus just 'physical space' and noise limitations.\n  \n\n    As such, when my 16 drive UnRAID server ran out of drive slots, the only solution was to build a second server which is in the Livingroom, in a 4U Rosewill case, sitting discretely in an Ikea Lack table with caster wheels.  The main server has a Ryzen 9 3950X and does all the dockers and stuff.  The secondary server has an Intel E5 2697v2 and sits there eating electricity for the sake of letting me run 12 more drives.\n  \n\n    But we're moving!  Three floors!  Gonna run ethernet in all the walls.  There will be a finished basement area for 'the gaming goodness' and I can finally set up network and storage in a real rack, on the unfinished side of the basement, with it's own 15amp circuit and where no one will care how much noise anything in there makes.  That means I an get disk shelf and make all of this way less stupid!\n  \n\n    The main plan is to retire the server inside the 4U rack case, then transplant the main tower server into that 4U rack case and expand it's drive capacity with a disk shelf.  So here's where I have questions:\n  \n\n    Firstly, things like the NetApp DS4246 and related seem to be what I'm looking at.  All my drives are SATA, to these disk shelves support SATA out of the box, is additional hardware required for SATA drives, or do I need to look for something alternate/specific?\n  \n\n    Secondly, these shelves offer up to four PSUs for redundancy, but how many are needed at minimum assuming 'up time' is not a major concern?  Also what kind of power consumption should I see beyond the drives it's powering?  I should def see an advantage over a whole 11 year old Xeon running, right?\n  \n\n    Thirdly, for the 'host server' to access this kind of disk shelf, I should only require something like an LSI 9201-16E and a quartet of 8088 to SFF-8088 cables, right?  From there on, the host device should just have an LSI controller which see's up to 24 drives on it, and it's all happy and 'just works'?"},
{"Title": "Any Software Recommendations for Folder Sync that Works on Top of Existing OS?", "Author": "u/avattz", "Content": "I almost had a data loss scare yesterday with a Windows machine, luckily I managed to restore it, but this has lead to figuring out a file sync system for my machines in case one has an issue with the boot drive or hardware failure. I currently have a small RAID 1 file server running Samba and while I manually copy files from my computers to this server, I wanted to see if there was software that could automated this.\n  \n\n    The goal is for this software to automatically copy a new completed file placed in the documents folder to a  network drive that is available on the same computer. Literally \"copy this file over there when it exists\". I looked into FreeFileSync and Syncthing but these appear to sync directly to a server instead to a local folder.\n  \n\n    One additional thing I an looking for is two-way syncing. This way, I can make a \"universal\" document folders where all my computers will have the same content, and update them if they are missing anything. This could count as additional backup since I would have the same files over many computers.\n  \n\n    Does anyone have recommendations for a software solution?\n  \n\n    Preferably:\n  \n\n\n\n\n\n    Open source\n  \n\n\n\n\n\n    \"Live\" syncing (runs when new or changed file detected instead of scheduled syncing)\n  \n\n\n\n\n\n    Flexible / Plenty of Options / Configurable\n  \n\n\n\n\n\n    Uses native Windows file commands\n  \n\n\n\n\n\n    Doesn't hurt, but works on Linux (I have \"better\" options for my Linux machines though)\n  \n\n\n\n\n\n    I appreciate any recommendations!\n  \n\n    Edit: I remember SyncToy which would be perfect, if anyone knows of an open source version of SyncToy, then that would be what I am looking for!"},
{"Title": "Video upscaling 480p to 1080 ffmpeg", "Author": "u/1michaelbrown", "Content": "The title pretty much explains what I’m asking. I want to know if it’s worth it since most dvds only provide 480p. Would it be worth it upscaling it to 1080p. With FFmpeg.\n  \n\n    I plan on buying 100” screen and projector. If that matters\n  \n\n    What I am using to encode with. I can use either.\n  \n\n    Mac mini M1 Or Dell power edge r620 with Debian vm With two cpus with a total of 40 cores.\n  \n\n    I plan on using FFmpeg via command line. (Some inside thoughts I want to make a script that will kind of automate this process. Checking if upscaling is needed or not)\n  \n\n    I am new here I hope this post is the right place."},
{"Title": "UPS APC BX1200MI-MS a good choice with no fans?", "Author": "u/maguillo", "Content": "Hello , I am about to buy the APC BX1200MI-MS with 1200VA and 650W (for the price) to back my nas , but the thing is it does not have fans to cool the device like other models , so I dont know if is or not necessary as I dont want the place smell burnt plastic , or how it disipates the heat? Thanks\n  \nhttps://preview.redd.it/ups-apc-bx1200mi-ms-a-good-choice-with-no-fans-v0-xbq80a528l5d1.png\nhttps://preview.redd.it/ups-apc-bx1200mi-ms-a-good-choice-with-no-fans-v0-s5alvwq38l5d1.png"},
{"Title": "Which type of external backup drives/systems should I get and use?", "Author": "u/BrinkleyPT", "Content": "Hi.\n  \n\n    I'm building a new PC with 1TB SSD nVME.\n  \n\n    What should I get for backup that's reliable?\n  \n\n    And if I get something how often should I replace the drive to ensure I don't lose data?\n  \n\n    Still trying to figure out what's the best method of image and file backup and what to buy and use, but also replace and when to replace it in order to avoid losing data.\n  \n\n    Thanks 👍"},
{"Title": "Is it good practice to leave free space on Optical Disks?", "Author": "u/finbarrgalloway", "Content": "I know for hard disk storage they often tell you to leave 1/3 to 1/4 free to not stress the drive, but does this hold true for a DVD? Or can I fill them up to my hearts content?"},
{"Title": "Does tubeup delete video file after upload?", "Author": "u/elgato123", "Content": "Once tubeup downloads a youtube video and uploads it to \narchive.org\n, does it then delete the file locally? I can see a hard drive getting full fast if not."},
{"Title": "Future Data Hoarder!", "Author": "u/allweretakenornot", "Content": "Hello! I long time lurker finally looking to break into data hoarding. My mom is looking to back up around a terabyte of photos and I was considering getting her a storage bay likely in RAID 1 to protect her data. Is there any recommended system? I was looking on Amazon and saw this 5 bay orico enclosure. Are these systems good? Should I try and find a cloud solution for her?\n  \n\n    PS: I read the rules and saw that they recommended tech support. If this post is not in the nature of the subreddit please let me know! Happy hoarding!"},
{"Title": "Does anyone use serverpartdeal drives as their main drives in a nas?", "Author": "u/DGU_kibb", "Content": "I'm planning my next NAS. Definitely going for an array of larger capacity drives. I bought new drives for my last build, but im going to have to buy several 12tb drives for my next one.\n  \n\n    I know if you have backups then it doesn't really matter (and I do have backups) but I'm curious, i know serverpartdeals is reputable around here, but are people using these in their main nas? Or are you using them purely as backups/cold storage or for unimportant data at the most?"},
{"Title": "Questions about File Integrity when and after transferring files", "Author": "u/gpspam", "Content": "Hello everyone, I'm a bit new to true data hoarding and I had made what is probably considered rookie mistakes.\n  \n\n    Some backstory: I had an unfortunate ssd failure which cost me about $1000 to recover the files. After some research I've decided to set up a NAS w/ RAID1 (and other back up methods). Now I have some questions to help me transition/transfer/migration from my old external hdd setup to my NAS solution.\n  \n\n    My first question mainly revolves around keeping file integrity when transferring files. What programs are best at doing this? I've done some research and I've currently chosen TeraCopy. It looks pretty good; other posts have suggested stuff like Robocopy but I couldn't find/get it to work (maybe it's command line stuff that, though I admittedly didn't look too hard since I don't trust inbuilt windows stuff that much). How good is TeraCopy and its file integrity verification?\n  \n\n    My second question is about checking files for corruption, mainly videos. This one is a bit of a shot in the dark, a hail mary hope of mine that I can fix this headache inducing rookie mistake of mine. Long story short, I had to reinitialize my NAS due to changing its setup. When doing this, I copied data I had on the NAS to a ext HDD (no verification done, I now know it was a stupid rookie mistake) totaling approx 3.5 TB of data, mainly video files (probably around 1k hours). Now I found at least 1 of them has a bit of corruption, where about 20 seconds got messed up. Is there a way or program that can find these kind of problems with files? I'm guessing probably not, but if there are potential solutions I'd love to find them. Otherwise, I guess those errors/problems will just exist and years later I'll find out and lament that if I knew years ago I could have replaced those files but not when I do.\n  \n\n    Thanks for your help and I'll reply if I have any follow up questions."},
{"Title": "Planning on storing txt, xlsx, and MKV files. It seems like Flash-Drives/Micro SD's aren't reliable, what is a good alternative?", "Author": "u/Sasutaschi", "Content": "So far I've mostly stored Data on the aforementioned methods, but browsing this Sub, it seems like a SSD + Enclosure would be the best way to go.\n  \n\n    This Enclosure was recommended.\n  \n\n\nhttps://www.amazon.com/ineo-Aluminum-External-Enclosure-C2594-NVME/dp/B07MZQF1H6\n\n\n\n    For a SSD, I was thinking about the Samsung EVO 980.\n  \n\n    Are there better alternatives?\n  \n\n    Finally, would it be possible to watch MKV files, if plugged into a TV/PS4 from the enclosure? Will there be a delay?\n  \n\n    Thx. for the advice and have a nice day."},
{"Title": "SAS Expander with SATA power?", "Author": "u/emanknugsaeman", "Content": ""},
{"Title": "Question about Macrium's compression", "Author": "u/Revolutionary_Cod672", "Content": "Hi all,\n  \n\n    I've got a 12TB home server and I'm trying to use Macrium Reflect to run backups. In an effort to cut costs, I'm trying to backup onto smaller external HDs. I've got one media library that's about 6TB that I'm trying to put onto a drive that's got an actual capacity of 4.5TB, I'm trying to rely on compression to make that work.\n  \n\n    The issue is that I've tried with both medium and high compression but the backup always fails due to insufficient space. Does the compression happen after the backup takes place? Or am I doing something wrong?\n  \n\n    Wasn't sure if I needed to have 6TB of space available initially, then it does some compression afterwards.\n  \n\n    Thanks in advance."},
{"Title": "Looking for a cloud backup service", "Author": "u/aradbe", "Content": "Hey all,\n  \n\n    so pretty simple, im looking for a cloud service where can i backup some of my important files so ill have them in case i lose them.\n  \n\n    i dont know much about this kinda stuff amd im looking for something simple and reliable, i was interested to see if thers a service where i can start off with purchasing a sub for a set amount of storage and if i want more later i can add a few dollars and expand the storage. like maybe start out with 100gb and expand it to 200gb if i need it later.\n  \n\n    If there nothing like then i would just like a recommendation for a good reliable backup service that will do the job.\n  \n\n    Thanks for any replies !"},
{"Title": "What's your guys system for archiving entire youtube channels look like?", "Author": "u/glowcialist", "Content": "I tried TubeArchivist, and it worked great for maybe 500 vids, but now seems to be completely blocked, I'm assuming that any script utilizing yt-dlp would face similar issues?\n  \n\n    4k tube seemed to work alright for individual playlists at first, but now seems to be consistently throttled to like 50 kb/s.\n  \n\n    Any ideas?\n  \n\n    Edit: Please forgive the missing apostrophe in the title. I won't do it again."},
{"Title": "How do I download a certain video from the wayback machine?", "Author": "u/wiicrafttech", "Content": "This is the link I'm using\n  \n\n\nhttps://web.archive.org/web/20230520032047/https://www.youtube.com/watch?v=Oy2c6Mt9KwY#"},
{"Title": "Looking for some critiquing of my plan.", "Author": "u/OnenonlyAl", "Content": "Thanks for taking the time to read and comment. I'm looking to backup a zpool of media. I had tried to setup a truenas for the data but I didn't love the UI and I have what I need on Ubuntu with docker. My plan is to destroy a zpool of the truenas made of 4x10tb raidz1 and move that pool into the primary server (add a pcie with more sata ports) then use zpool attach to mirror my current 4x8tb raidz1 (mnt) to the newly recreated zpool of the 4x10tb from the old truenas server (named mntbackup). So zpool attach mnt to mntbackup. Sounds like this automatically starts mirroring.\n  \n\n    I know this isn't ideal without being an off-site backup but I'm not the most literate at actually managing this and want something easy. Would I be able to just plug in backup, then unplug the backup pool and cold storage? I don't need perfect redundancy. Would I be able to plug the mntbackup raidz1 back in sometime in the future and the missing new data automatically sync or would I need scripts of rysnc or zfs send receive to add new data?\n  \n\n    Thanks for any insight and help!"},
{"Title": "Suitcase for 3.5\" disks with screwed on HotSwap", "Author": "u/No-Balance-8038", "Content": "Need a way to protect my backup disks that are meant to be stored offsite.\nI already got cases, but they are too small to account for a 3.5\" HDD plus the mount for SilverStone Technology RM43-320-RS.\n  \n\n    What would you guys recommend? I live in Germany. From Amazon would be cool.\nI already have 3.5\" Protection cases but they are not long enough!\nThe HDDs are 17cm long with it."},
{"Title": "Software for finding all files with identical names on a drive", "Author": "u/MisterPenishead", "Content": "I have a hard drive with thousands of files spread across different folders and some of the files have the same name in spite of them having different content. Is there a software I can use to find all files with identical names so that I can rename them?"},
{"Title": "AWS deep freeze pricing", "Author": "u/KingRollos", "Content": "I'm thinking of moving most of my backup to Amazon's deep freeze service. I'm sure it's made complicated deliberately.\n  \n\n    I'm thinking of adding it in bits. Will this cost me more? Do I need to gather it all together and then transfer in 1 go?"},
{"Title": "Im looking to transfer highest quality from Hi-Fi camera for 8mm Tapes.  Which is better: Mini-USB or FireWire?", "Author": "u/Throwaway173638o", "Content": "I have a Sony Hi-Fi camera for 8mm videos that has a FireWire, Mini USB, A/V, and S-video ports.  I want to get the highest quality as possible.  I narrowed down to FireWire or Mini USB transfer for better quality. Which of the two is better overall or are they the same?\n  \n\n    Edit: For context, the camera is a Sony DCR-TRV730 and the tapes are Sony Hi8 MP 8mm Video Cassette.  Cassette also lists it as Digital8 with \"60\" while the Hi8 is listed as \"120\""},
{"Title": "Sort backup raid 1", "Author": "u/sweetestpeach94", "Content": "Hi, I hope I can get some help. I have a Lacie 2big thunderbolt 2 set as Raid 1. I’ve just completed the backup of almost 6TB of data (mainly pics), however half of it are just the mirror copies. Now I would move the original half on another disk, the problem is that the backup isn’t like sort out in different folders, it’s just every file and its copy back to back in sequence all together (file A, file A-2 , file B, file B-2, file C, file C - 2 etc.). So here is my question, how I select just one half of the files to move it in the new disk without their duplicate?"},
{"Title": "Alternatives to Epson V600", "Author": "u/ass-master-blaster", "Content": "The V600 is discontinued in my country (past prices are around $650) and the V850 is too expensive ($1600). Are there any alternatives around the same price and quality for a newer model scanner? I've looked at the FastFoto and don't like the quality of the photos and am happy to spend the time with a flatbed scanner."},
{"Title": "Ibms first commercially available 5mb ramac's disk storage 1956", "Author": "u/noideawhatimdoing444", "Content": "No content"},
{"Title": "are SSK USB flash drives safe?", "Author": "u/retrorays", "Content": "I read how USB drives can run malware to act as a USB keyboard and then compromise your system. I see the SSK drives are from China. Do we know if they are safe?"},
{"Title": "Need some help sanity checking my UnRAID 'Reamalgamation' project, specifically Disk Shelves", "Author": "u/AshleyUncia", "Content": "So here's the situation; I currently live with my spouse in a one bedroom apartment built in 1922.  For this reason there are some real issues with the loads on the electrical circuits between my network storage, gaming PC, HTPCs and so on.  Plus just 'physical space' and noise limitations.\n  \n\n    As such, when my 16 drive UnRAID server ran out of drive slots, the only solution was to build a second server which is in the Livingroom, in a 4U Rosewill case, sitting discretely in an Ikea Lack table with caster wheels.  The main server has a Ryzen 9 3950X and does all the dockers and stuff.  The secondary server has an Intel E5 2697v2 and sits there eating electricity for the sake of letting me run 12 more drives.\n  \n\n    But we're moving!  Three floors!  Gonna run ethernet in all the walls.  There will be a finished basement area for 'the gaming goodness' and I can finally set up network and storage in a real rack, on the unfinished side of the basement, with it's own 15amp circuit and where no one will care how much noise anything in there makes.  That means I an get disk shelf and make all of this way less stupid!\n  \n\n    The main plan is to retire the server inside the 4U rack case, then transplant the main tower server into that 4U rack case and expand it's drive capacity with a disk shelf.  So here's where I have questions:\n  \n\n    Firstly, things like the NetApp DS4246 and related seem to be what I'm looking at.  All my drives are SATA, to these disk shelves support SATA out of the box, is additional hardware required for SATA drives, or do I need to look for something alternate/specific?\n  \n\n    Secondly, these shelves offer up to four PSUs for redundancy, but how many are needed at minimum assuming 'up time' is not a major concern?  Also what kind of power consumption should I see beyond the drives it's powering?  I should def see an advantage over a whole 11 year old Xeon running, right?\n  \n\n    Thirdly, for the 'host server' to access this kind of disk shelf, I should only require something like an LSI 9201-16E and a quartet of 8088 to SFF-8088 cables, right?  From there on, the host device should just have an LSI controller which see's up to 24 drives on it, and it's all happy and 'just works'?"},
{"Title": "Any Software Recommendations for Folder Sync that Works on Top of Existing OS?", "Author": "u/avattz", "Content": "I almost had a data loss scare yesterday with a Windows machine, luckily I managed to restore it, but this has lead to figuring out a file sync system for my machines in case one has an issue with the boot drive or hardware failure. I currently have a small RAID 1 file server running Samba and while I manually copy files from my computers to this server, I wanted to see if there was software that could automated this.\n  \n\n    The goal is for this software to automatically copy a new completed file placed in the documents folder to a  network drive that is available on the same computer. Literally \"copy this file over there when it exists\". I looked into FreeFileSync and Syncthing but these appear to sync directly to a server instead to a local folder.\n  \n\n    One additional thing I an looking for is two-way syncing. This way, I can make a \"universal\" document folders where all my computers will have the same content, and update them if they are missing anything. This could count as additional backup since I would have the same files over many computers.\n  \n\n    Does anyone have recommendations for a software solution?\n  \n\n    Preferably:\n  \n\n\n\n\n\n    Open source\n  \n\n\n\n\n\n    \"Live\" syncing (runs when new or changed file detected instead of scheduled syncing)\n  \n\n\n\n\n\n    Flexible / Plenty of Options / Configurable\n  \n\n\n\n\n\n    Uses native Windows file commands\n  \n\n\n\n\n\n    Doesn't hurt, but works on Linux (I have \"better\" options for my Linux machines though)\n  \n\n\n\n\n\n    I appreciate any recommendations!\n  \n\n    Edit: I remember SyncToy which would be perfect, if anyone knows of an open source version of SyncToy, then that would be what I am looking for!"},
{"Title": "Video upscaling 480p to 1080 ffmpeg", "Author": "u/1michaelbrown", "Content": "The title pretty much explains what I’m asking. I want to know if it’s worth it since most dvds only provide 480p. Would it be worth it upscaling it to 1080p. With FFmpeg.\n  \n\n    I plan on buying 100” screen and projector. If that matters\n  \n\n    What I am using to encode with. I can use either.\n  \n\n    Mac mini M1 Or Dell power edge r620 with Debian vm With two cpus with a total of 40 cores.\n  \n\n    I plan on using FFmpeg via command line. (Some inside thoughts I want to make a script that will kind of automate this process. Checking if upscaling is needed or not)\n  \n\n    I am new here I hope this post is the right place."},
{"Title": "UPS APC BX1200MI-MS a good choice with no fans?", "Author": "u/maguillo", "Content": "Hello , I am about to buy the APC BX1200MI-MS with 1200VA and 650W (for the price) to back my nas , but the thing is it does not have fans to cool the device like other models , so I dont know if is or not necessary as I dont want the place smell burnt plastic , or how it disipates the heat? Thanks\n  \nhttps://preview.redd.it/ups-apc-bx1200mi-ms-a-good-choice-with-no-fans-v0-xbq80a528l5d1.png\nhttps://preview.redd.it/ups-apc-bx1200mi-ms-a-good-choice-with-no-fans-v0-s5alvwq38l5d1.png"},
{"Title": "Which type of external backup drives/systems should I get and use?", "Author": "u/BrinkleyPT", "Content": "Hi.\n  \n\n    I'm building a new PC with 1TB SSD nVME.\n  \n\n    What should I get for backup that's reliable?\n  \n\n    And if I get something how often should I replace the drive to ensure I don't lose data?\n  \n\n    Still trying to figure out what's the best method of image and file backup and what to buy and use, but also replace and when to replace it in order to avoid losing data.\n  \n\n    Thanks 👍"},
{"Title": "Is it good practice to leave free space on Optical Disks?", "Author": "u/finbarrgalloway", "Content": "I know for hard disk storage they often tell you to leave 1/3 to 1/4 free to not stress the drive, but does this hold true for a DVD? Or can I fill them up to my hearts content?"},
{"Title": "Does tubeup delete video file after upload?", "Author": "u/elgato123", "Content": "Once tubeup downloads a youtube video and uploads it to \narchive.org\n, does it then delete the file locally? I can see a hard drive getting full fast if not."},
{"Title": "Future Data Hoarder!", "Author": "u/allweretakenornot", "Content": "Hello! I long time lurker finally looking to break into data hoarding. My mom is looking to back up around a terabyte of photos and I was considering getting her a storage bay likely in RAID 1 to protect her data. Is there any recommended system? I was looking on Amazon and saw this 5 bay orico enclosure. Are these systems good? Should I try and find a cloud solution for her?\n  \n\n    PS: I read the rules and saw that they recommended tech support. If this post is not in the nature of the subreddit please let me know! Happy hoarding!"},
{"Title": "Does anyone use serverpartdeal drives as their main drives in a nas?", "Author": "u/DGU_kibb", "Content": "I'm planning my next NAS. Definitely going for an array of larger capacity drives. I bought new drives for my last build, but im going to have to buy several 12tb drives for my next one.\n  \n\n    I know if you have backups then it doesn't really matter (and I do have backups) but I'm curious, i know serverpartdeals is reputable around here, but are people using these in their main nas? Or are you using them purely as backups/cold storage or for unimportant data at the most?"},
{"Title": "Questions about File Integrity when and after transferring files", "Author": "u/gpspam", "Content": "Hello everyone, I'm a bit new to true data hoarding and I had made what is probably considered rookie mistakes.\n  \n\n    Some backstory: I had an unfortunate ssd failure which cost me about $1000 to recover the files. After some research I've decided to set up a NAS w/ RAID1 (and other back up methods). Now I have some questions to help me transition/transfer/migration from my old external hdd setup to my NAS solution.\n  \n\n    My first question mainly revolves around keeping file integrity when transferring files. What programs are best at doing this? I've done some research and I've currently chosen TeraCopy. It looks pretty good; other posts have suggested stuff like Robocopy but I couldn't find/get it to work (maybe it's command line stuff that, though I admittedly didn't look too hard since I don't trust inbuilt windows stuff that much). How good is TeraCopy and its file integrity verification?\n  \n\n    My second question is about checking files for corruption, mainly videos. This one is a bit of a shot in the dark, a hail mary hope of mine that I can fix this headache inducing rookie mistake of mine. Long story short, I had to reinitialize my NAS due to changing its setup. When doing this, I copied data I had on the NAS to a ext HDD (no verification done, I now know it was a stupid rookie mistake) totaling approx 3.5 TB of data, mainly video files (probably around 1k hours). Now I found at least 1 of them has a bit of corruption, where about 20 seconds got messed up. Is there a way or program that can find these kind of problems with files? I'm guessing probably not, but if there are potential solutions I'd love to find them. Otherwise, I guess those errors/problems will just exist and years later I'll find out and lament that if I knew years ago I could have replaced those files but not when I do.\n  \n\n    Thanks for your help and I'll reply if I have any follow up questions."},
{"Title": "Planning on storing txt, xlsx, and MKV files. It seems like Flash-Drives/Micro SD's aren't reliable, what is a good alternative?", "Author": "u/Sasutaschi", "Content": "So far I've mostly stored Data on the aforementioned methods, but browsing this Sub, it seems like a SSD + Enclosure would be the best way to go.\n  \n\n    This Enclosure was recommended.\n  \n\n\nhttps://www.amazon.com/ineo-Aluminum-External-Enclosure-C2594-NVME/dp/B07MZQF1H6\n\n\n\n    For a SSD, I was thinking about the Samsung EVO 980.\n  \n\n    Are there better alternatives?\n  \n\n    Finally, would it be possible to watch MKV files, if plugged into a TV/PS4 from the enclosure? Will there be a delay?\n  \n\n    Thx. for the advice and have a nice day."},
{"Title": "SAS Expander with SATA power?", "Author": "u/emanknugsaeman", "Content": ""},
{"Title": "Question about Macrium's compression", "Author": "u/Revolutionary_Cod672", "Content": "Hi all,\n  \n\n    I've got a 12TB home server and I'm trying to use Macrium Reflect to run backups. In an effort to cut costs, I'm trying to backup onto smaller external HDs. I've got one media library that's about 6TB that I'm trying to put onto a drive that's got an actual capacity of 4.5TB, I'm trying to rely on compression to make that work.\n  \n\n    The issue is that I've tried with both medium and high compression but the backup always fails due to insufficient space. Does the compression happen after the backup takes place? Or am I doing something wrong?\n  \n\n    Wasn't sure if I needed to have 6TB of space available initially, then it does some compression afterwards.\n  \n\n    Thanks in advance."},
{"Title": "Is this a good deal listed in my local facebook marketplace “Dell poweredge r710 md1220 READ”", "Author": "u/makzero", "Content": "No content"},
{"Title": "Transcode Settings and Workflows for Archiving Video Game Clips", "Author": "u/HalluxTheGreat", "Content": "Looking for advice on how to compress some of the gameplay videos I make in some video games. I typically record in 3440 x 1440 30fps with a bitrate of 10000-15000 kbps. And at the end of the day or week I use handbrake to cut the size to about half. A lot of my clips arent for posting to streams but to just compare my early gameplay with myself later on to see how I changed with 0 hours in a game vs 100 or even 1000, or to just capture the moment when playing with friends.\n  \n\n    Does anyone have any workflows in capturing their own gameplay and storing it? Naming schemes, settings, scripts, etc...\n  \n\n    I've been looking at alternatives such as Shutter encoder as well."},
{"Title": "Need to rename thousands of files that were named with a bad template", "Author": "u/NighthawkE3", "Content": "Okay this is a potentially weird one, I’ll do my best\n  \n\n    Very quick summery: I have about 5000 files that must be renamed from:\n  \n\n\n\n    To Simply\n  \n\n\n\n    I have about 5000 of these incorrectly named files, and they can't be used in the current format. I have both Windows and Linux operating systems at my disposal, any help would be massively appreciated"},
{"Title": "Silverstone shows off CS383 at Computex", "Author": "u/Odrel", "Content": "GamersNexus is looking at the Silverstone CS383\n at Computex. The video is super quick but some highlights include:\n  \n\n\n\n\n\n    Up to 12x3,5\" drives\n  \n\n\n\n\n\n    Option to add a second power supply by removing a HDD cage (-4 HDDs)\n  \n\n\n\n\n\n    5,25\" bay at the top\n  \n\n\n\n\n\n    Support for large motherboards and GPUs\n  \n\n\n\n\n\n    Targeting $400 in Q3"},
{"Title": "TrackTalk.net, one of the biggest athletics forums of its time, on the verge of shutting down - Looking for a way to back it up.", "Author": "u/xd-Drewski13", "Content": "I'm somewhat of a fan of track and field fan and this was one of my favorite sites to go on back in the day. It seems that the owner is unsure if he can keep it up and is running out of time/energy to maintain it. I was wondering if there would be a simple way to back it up.\n  \n\n    It contains thousands of threads about information that would mostly be lost to time if it were to disappear.\n  \n\n    I have a fairly large server for movies and shows but don't have to experience scraping and hoarding data like this. Any ideas? I know this site is a certain type of forum template, but I don't know which one it is or the best way to go about this."},
{"Title": "Recovering webms and other video file formats (using R-Linux, or a recommended alternative)", "Author": "u/burning_torch", "Content": "I formatted a drive full of videos by accident on my Ubuntu 22.04 computer. Stupid me. It was a full format, not a quick format, but I stopped it only a second or two after it had started. I ran testdisk to check the damages and try to recover the files; it didn't really work all too well. I tried to run photorec, but the software is unusable - my input was randomized and would constantly change if it even accepted input at all; this wasn't a mapping issue, as the right arrow key would act as arrow up, enter, arrow down, or any other random input at any given time. Either way, I eventually found and ran R-Studio's R-Linux, which seemed to work fine, if a little unintuitive. I ran the software and seemingly recovered a lot of files; among others, I recovered a lot of mp4 files. This was expected, as the drive was filled almost exclusively with videos. However, R-Linux does not have built in capabilities to recover webms or other video file formats like qt, and I know there were a great deal of those files on the drive. Does anyone know of any good ways to recover those files as well?\n  \n\n    I know R-Linux has the ability to add custom file types by building an xml file for that type. I wouldn't know where to begin on getting the information for such a file, but does anyone have one that would work for the not included video file types (webm, qt, etc.)? Or does anyone know of a software that has the ability to recover those files?"},
{"Title": "How does position affect hdd life span?", "Author": "u/d3crypti0n", "Content": "Hello everybody,\n  \n\n    I found a cheap server chassis for my rack I wanted to buy but the thing that bothers me is the positing of the drives, they are mounted vertically.\n  \n\n    This brings me to my question - does the position affect the hdd lifespan? Do drives that stand life longer / shorter then the ones who are mounted horizontally due to gravity (because of the rotating platters) ?\nIf yes, how big of difference does it make?"},
{"Title": "when your hdd order is delayed for the 3rd time you really learn what files are important to you", "Author": "u/d1ckpunch68", "Content": "No content"},
{"Title": "Decades since I was a teenager but sometimes 'You just don't understand me, Dad!' still applies.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "My favorite hard drive tracker + when will 30+ TB drives hit retail?", "Author": "u/chuckremes", "Content": "I will share some information and then ask a question too.\n  \n\n    I like this site for tracking hard drive prices. Last September I bought a bunch of 16 TB drives for $10.6 per terabyte and then I saw the price go as low as $9.40. For the 16+ TB sizes it's now been hovering at around $14/TB for months. Very concerning.\n  \n\n\nhttps://diskprices.com/?locale=us&condition=new&disk_types=external_hdd,internal_hdd,external_ssd,internal_ssd\n\n\n\n    So when can we expect to see those 30+ TB drives hit retail? The older articles I read all indicated 2024Q1 but we're about to exit 2024Q2 and I still haven't seen any. What's the latest buzz?"},
{"Title": "40Gb/s fiber in Finland is o so tempting for Torrents and Usenet...", "Author": "u/Rugta", "Content": "No content"},
{"Title": "Anyway to grab the name of a mega folder in the terminal? Megatools doesnt preserve the folder name", "Author": "u/NotAnADC", "Content": "Thank you for any help! Been trying to download mega files but hate that I can't save the folder names"},
{"Title": "Does anyone have a used harddrive to give for free?", "Author": "u/Alexander_Alexis", "Content": "Hello, i need to put emergently  my phone photos to my pc but my pc is full(200gb ssd) And i dont have moneys or a place near to buy a hard drive, does anyone have a very used hard drive? i need one only for the photos so not running games or big stuff like that"},
{"Title": "Starting data hording journey", "Author": "u/nlj1978", "Content": "After the help I got here on ripping my cd collection I'm jumping in the deep end. I'm putting together a media server. Have a HP z1 G5 tower workstation with i5-9500 on the way but still have decisions to make in terms of hardware and software.\n  \n\n    I'm finding mixed data on ECC ram support. Apparently the motherboards come in a couple variations. Once I confirm I believe I believe ECC is a better choice for this application. Still need to verify but I believe the board supports either 64 or 128gig.  That said how much ram should I use?\n  \n\n    Mobo has 2 m2 slots and 4 sata ports. Computer comes with a 256g nvme. I've read a little about using m2 Intel Optane drives for improved server performance. Anyone have any experience or input on this?\n  \n\n    Drives I'm still pondering.\n  \n\n    On the software side I am leaning towards TrueNas and  Jellyfin. Both seem relatively user friendly to someone with limited server knowledge. Thoughts?"},
{"Title": "I just need a a quiet always on network disk without all the usual NAS apps/features.", "Author": "u/largePenisLover", "Content": "The only thing missing from my setup is a simple NAS like 4tb volume that I can split into two partitions or shares, running on a very quiet always on device.\nI've been looking at NAS solutions for this but these do wayyyy to much feature wise and often have a weird walled gardenish approaches to things.\nLike this device that looks perfect, synology BeeDrive, apparently needs to be controlled VIA a synology run web service and has undeletable folders related to photo and video apps. Less idiot proof devices don't have this nonsense but are weird about backing them up.\nIt all feels very bloatwary to a home-NAS newbie\n  \n\n    I JUST need a dumb networked file box WITHOUT all the apps and features QNAP and Synolgoy bring to the table.\nI need it to be JUST a network share that I can access from any device on my home network using the file browsers on those devices.\nNo video managers, DSM's, BSM's, photo managers, or any of the usual stuff. Just files, in a file browser, that I can doubleclick to open.\nJut a dumb, \nquiet\n, reliable, file box.\n  \n\n    I want to be able to backup this dumb file box by mapping it to a drive letter on the backup pc and then run my backup script.\nNo bullshit with installing third party synology/qnap/whatever software, I just want to integrate it in my existing backup solutions and ignore what vendors want me to do.\n  \n\n    Does anyone know if such a dumb file box is available as an off the shelf product?"},
{"Title": "DAS Box - Can it be restarted remotely after a blackout?", "Author": "u/jfromeo", "Content": "I am in the search of a USB-C DAS to upgrade my 3,5\" HDD hoarding, as I do not have the space to accommodate a rack solution at the moment.\n  \n\n    I have found the MB-X10U31 from Fantec, which ticks all the features (10 bays, hot-swap, USB-C, etc). Quite similiar to the Mediasonic, IcyBox and Sabrent ones.\n  \n\n\nhttps://fantecshop.de/p/fantec-mb-x10u31\n\n\nhttps://preview.redd.it/das-box-can-it-be-restarted-remotely-after-a-blackout-v0-npzcdqysbb5d1.jpg\n\n    But I have one feature I depend on, and I cannot deduce how it will behave, and the brand has not answered me either.\n  \n\n    I need to find out \nif the box can somehow be restarted remotely after a blackout\n, as I live 1.000km away from the server and there is no one to operate it. I have an UPS which can hold around 15 minutes, but sometimes the blackout are longer and I have a routine via NUT to power off all the devices if power is not restored within that period of time. I can WoL the main machine, but I do not know how could I power up the DAS box.\n  \n\n    Thanks in advance."},
{"Title": "Merging folders and files", "Author": "u/cl326", "Content": "I have a Windows 11 system with many folders, sub-folders, and files. I want to keep only one copy of each file based on its MD5 hash, including its filename and extension. In the end I want just one folder with all the unique files. Is there any easy way to do this? If not a specific app, I'm willing to write an app or script in Python, Ruby, or PowerShell. Any thoughts or suggestions?"},
{"Title": "WD Ultrastar DC SN655 7.68 Tb for 196€ (211$) at a French retailer", "Author": "u/Nayko93", "Content": "I just found this deal, a 7.68TB NAS SSD for 196€, that's 0.02 cents per GB !I was thinking it could interest a few people here\n  \n\n\nhttps://fr.shopping.rakuten.com/offer/buy/11626286226/disque-dur-interne-7-68to-wd-ultrastar-dc-sn655-2-5-u-3-pcie-4-0-nvme-wus5ea176esp7e3.html\n\n\n\n    I'm not even sure it's real but it look like it, seller have a good reputation and the website is legitMaybe it's a price error, I don't know, but I've seen other posts talking about huge deal on those SSD so it seem this kind of deal is not impossible\n  \n\n    I tried to place a order to see if they ship outside of France and unfortunately they don't, so you either need to be in France, or use a friend or package forwarding service\n  \n\n    I'm almost tempted to buy 2 myself, since I'm looking to make my first home NASThat's a lot of money but for this much storage it would be dumb to pass it... but I know nothing of those SSD or NAS SSD in general, They need a PCI adapter to plug on a normal MB and I think I've read somewhere they heat up a lot ?I would be more comfortable dealing with normal sata or m.2 SSD... but such a deal.. I'm really tempted\n  \n\n\n\n    Update : It was legit, the seller confirmed my order and the price\n  \n\n    Unfortunately I had to cancel my order, because I can't find any U.3 pci card that can hold more than 1 SSD, and I need 3 off them, but I don't have 3 PCI left in my NAS"},
{"Title": "WD MyCloud Home once again screws me over", "Author": "u/techek", "Content": "My MyCloud Home has been updated to version 4.23.0 from December 4th 2023. I now know not become all excited and such, because almost every update since my purchase, has introduced one or more downgrades. Why remains unanswered.\n  \n\n    This time is no exception although the information about version 4.23.0 starts of with \"We constantly evaluate the customer experience ... wish to improve ... bring new and exciting features\" and so on.\n  \n\n    In reality it's a load of b......t, because this time they remove support for backing up videos and photos from Facebook. Previous update removed feature for editing photos in the app, before that remote backup with ElephantDrive disappeared, less connectivity and so on.\n  \n\n    The list of downgrades is impressive! And I feel used. Thanks for nothing, Western Digital!\n  \n\n    I cannot recommend their products for anyone anymore - those days are definitely over now."},
{"Title": "irc.hackint.org", "Author": "u/GuillermoBotonio", "Content": "Anyone know why I would suddenly not be able to access irc.hackint.org? I was able to go on there for about 3 days then its not loading. The guy I talked to from the page says the server is loading for him. I can get on Hackint.org ok but not the IRC."},
{"Title": "Are there any risks of using a USB Switch with a power supply on my PC and my DAS ?", "Author": "u/Yukinoooo", "Content": "My goal is to use my DAS on my PC and my media player (like a kind of Nvidia Shield, not Android or IOS, just the KODI interface under GNU/Linux) safely. I'm wondering if it's a good idea to use the two ports (PC and my media player) of a usb switch + a power supply and one port for my DAS ? If not, which solution should I use ?"},
{"Title": "RAID card no longer working, gives firmware error on POST", "Author": "u/Cyber_Akuma", "Content": "I have a LSI 9260-8i, this was actually reflashed from the original IRM ServeRAID M5014 it arrived as. It has since also been upgraded to the latest firmware from LSI/Broadcom, which is 12.15.0-0239 (also the card at boot identifies as BIOS version \"3.30.02.2 (Build June 17, 2014)\"). I am just simply using it in my Windows 10 system, not as part of a server or NAS.\n  \n\n    This card had been disconnected from my system for about 6-12 months, as well as it's drives, I recently reconnected everything in a new system. I have four HDDs in a RAID5, but had recently acquired the license key to enable RAID6 and had installed a 5th HDD in preparation for that. I had a few errors at first, but many things in the system were at first giving me errors so I didn't think much of it as I had performed several upgrades and changes at once.\n  \n\n    I eventually got everything booting properly and then opened up the RAID Windows management software (Version 17.05.02.01 at the time) and it seemed to be going ok. It was performing a Patrol Read on all of my drives and was recharging the battery (Though it claimed the battery was bad, but it was new, so I figured it needed to do a recharge cycle and re-learn to see it as good again). It said the Patrol Read was only going to take 10 minutes but I knew it was going to take hours. Halfway in, at about the 3-4 hour mark, the software completely stopped responding. I restarted it, and now the card was showing that absolutely nothing was installed to it.\n  \n\n    I performed a reboot and now I kept getting an error message during the card's initialization during post:\n  \n\n\n\n    LSI MegaRAID SAS-MFI BIOS Version 3.30.02.2 (Build June 17, 2014) Copyright(c) 2014 LSI Corporation Host Adapter Bus 5 Dev 0:\n  \n\n\n\n\n\n    F/W is in Fault State MFI Register State 0xF0010002\n  \n\n\n\n\n\n    Adapter at Baseport is not responding\n  \n\n\n\n\n\n    No MegaRAID Adapter Installed\n  \n\n\n\n    The card then could be seen as installed, but the drives were not showing up, and the management software could not even tell a card was installed anymore. I tried updating to the latest management software (17.05.06.00) in case it might at least see there is a card installed, with that being it's own can of worms of expecting me to manually install OpenJDK and set the environment paths myself, it also just gets stuck loading the application.\n  \n\n    I tried MegaCLI, StorCLI, and MegaSCU (I admit I am not too familiar with managing this card through a CLI) but -v and -AdpAllInfo -aALL but they all returned nothing. I tried disconnecting the drives in case one had somehow become so fault during storage that it was crashing it, and no difference. I tried the only other PCI socket in my motherboard and it would not even boot then, guess that socket isn't even working with everything else installed in my system.\n  \n\n    I have no idea what to do now. The card refuses to work, claiming it's suffering some kind of firmware fault on POST, none of the software seems to even detect the presence of the card at all despite it physically showing up in Device Manager (although with an \"An I/O adapter hardware error has occurred.\" error) and HWiNFO, and I am not aware of any way I can attempt a force-reflash of the firmware in case it's a software issue (although I somehow doubt it) or of what else to try.\n  \n\n    And yes, I have a backup of my data."},
{"Title": "IT BEGINS!", "Author": "u/pele4096", "Content": "No content"},
{"Title": "Just started VHS digitizing. Any tips for cable management?", "Author": "u/Applewoood", "Content": "No content"},
{"Title": "Jonsbo announces the N5 case", "Author": "u/Ben4425", "Content": "Nascompares just posted a description of the new \nJonsbo N5 case\n. It's a \nbeast\n with space for up to \n12\n 3.5\" drives and motherboard support for mITX, mATX, ATX, and E-ATX all with full-height PCIe cards."},
{"Title": "Is this a good deal listed in my local facebook marketplace “Dell poweredge r710 md1220 READ”", "Author": "u/makzero", "Content": "No content"},
{"Title": "Transcode Settings and Workflows for Archiving Video Game Clips", "Author": "u/HalluxTheGreat", "Content": "Looking for advice on how to compress some of the gameplay videos I make in some video games. I typically record in 3440 x 1440 30fps with a bitrate of 10000-15000 kbps. And at the end of the day or week I use handbrake to cut the size to about half. A lot of my clips arent for posting to streams but to just compare my early gameplay with myself later on to see how I changed with 0 hours in a game vs 100 or even 1000, or to just capture the moment when playing with friends.\n  \n\n    Does anyone have any workflows in capturing their own gameplay and storing it? Naming schemes, settings, scripts, etc...\n  \n\n    I've been looking at alternatives such as Shutter encoder as well."},
{"Title": "Need to rename thousands of files that were named with a bad template", "Author": "u/NighthawkE3", "Content": "Okay this is a potentially weird one, I’ll do my best\n  \n\n    Very quick summery: I have about 5000 files that must be renamed from:\n  \n\n\n\n    To Simply\n  \n\n\n\n    I have about 5000 of these incorrectly named files, and they can't be used in the current format. I have both Windows and Linux operating systems at my disposal, any help would be massively appreciated"},
{"Title": "Silverstone shows off CS383 at Computex", "Author": "u/Odrel", "Content": "GamersNexus is looking at the Silverstone CS383\n at Computex. The video is super quick but some highlights include:\n  \n\n\n\n\n\n    Up to 12x3,5\" drives\n  \n\n\n\n\n\n    Option to add a second power supply by removing a HDD cage (-4 HDDs)\n  \n\n\n\n\n\n    5,25\" bay at the top\n  \n\n\n\n\n\n    Support for large motherboards and GPUs\n  \n\n\n\n\n\n    Targeting $400 in Q3"},
{"Title": "TrackTalk.net, one of the biggest athletics forums of its time, on the verge of shutting down - Looking for a way to back it up.", "Author": "u/xd-Drewski13", "Content": "I'm somewhat of a fan of track and field fan and this was one of my favorite sites to go on back in the day. It seems that the owner is unsure if he can keep it up and is running out of time/energy to maintain it. I was wondering if there would be a simple way to back it up.\n  \n\n    It contains thousands of threads about information that would mostly be lost to time if it were to disappear.\n  \n\n    I have a fairly large server for movies and shows but don't have to experience scraping and hoarding data like this. Any ideas? I know this site is a certain type of forum template, but I don't know which one it is or the best way to go about this."},
{"Title": "Recovering webms and other video file formats (using R-Linux, or a recommended alternative)", "Author": "u/burning_torch", "Content": "I formatted a drive full of videos by accident on my Ubuntu 22.04 computer. Stupid me. It was a full format, not a quick format, but I stopped it only a second or two after it had started. I ran testdisk to check the damages and try to recover the files; it didn't really work all too well. I tried to run photorec, but the software is unusable - my input was randomized and would constantly change if it even accepted input at all; this wasn't a mapping issue, as the right arrow key would act as arrow up, enter, arrow down, or any other random input at any given time. Either way, I eventually found and ran R-Studio's R-Linux, which seemed to work fine, if a little unintuitive. I ran the software and seemingly recovered a lot of files; among others, I recovered a lot of mp4 files. This was expected, as the drive was filled almost exclusively with videos. However, R-Linux does not have built in capabilities to recover webms or other video file formats like qt, and I know there were a great deal of those files on the drive. Does anyone know of any good ways to recover those files as well?\n  \n\n    I know R-Linux has the ability to add custom file types by building an xml file for that type. I wouldn't know where to begin on getting the information for such a file, but does anyone have one that would work for the not included video file types (webm, qt, etc.)? Or does anyone know of a software that has the ability to recover those files?"},
{"Title": "How does position affect hdd life span?", "Author": "u/d3crypti0n", "Content": "Hello everybody,\n  \n\n    I found a cheap server chassis for my rack I wanted to buy but the thing that bothers me is the positing of the drives, they are mounted vertically.\n  \n\n    This brings me to my question - does the position affect the hdd lifespan? Do drives that stand life longer / shorter then the ones who are mounted horizontally due to gravity (because of the rotating platters) ?\nIf yes, how big of difference does it make?"},
{"Title": "when your hdd order is delayed for the 3rd time you really learn what files are important to you", "Author": "u/d1ckpunch68", "Content": "No content"},
{"Title": "Decades since I was a teenager but sometimes 'You just don't understand me, Dad!' still applies.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "My favorite hard drive tracker + when will 30+ TB drives hit retail?", "Author": "u/chuckremes", "Content": "I will share some information and then ask a question too.\n  \n\n    I like this site for tracking hard drive prices. Last September I bought a bunch of 16 TB drives for $10.6 per terabyte and then I saw the price go as low as $9.40. For the 16+ TB sizes it's now been hovering at around $14/TB for months. Very concerning.\n  \n\n\nhttps://diskprices.com/?locale=us&condition=new&disk_types=external_hdd,internal_hdd,external_ssd,internal_ssd\n\n\n\n    So when can we expect to see those 30+ TB drives hit retail? The older articles I read all indicated 2024Q1 but we're about to exit 2024Q2 and I still haven't seen any. What's the latest buzz?"},
{"Title": "40Gb/s fiber in Finland is o so tempting for Torrents and Usenet...", "Author": "u/Rugta", "Content": "No content"},
{"Title": "Anyway to grab the name of a mega folder in the terminal? Megatools doesnt preserve the folder name", "Author": "u/NotAnADC", "Content": "Thank you for any help! Been trying to download mega files but hate that I can't save the folder names"},
{"Title": "Does anyone have a used harddrive to give for free?", "Author": "u/Alexander_Alexis", "Content": "Hello, i need to put emergently  my phone photos to my pc but my pc is full(200gb ssd) And i dont have moneys or a place near to buy a hard drive, does anyone have a very used hard drive? i need one only for the photos so not running games or big stuff like that"},
{"Title": "Starting data hording journey", "Author": "u/nlj1978", "Content": "After the help I got here on ripping my cd collection I'm jumping in the deep end. I'm putting together a media server. Have a HP z1 G5 tower workstation with i5-9500 on the way but still have decisions to make in terms of hardware and software.\n  \n\n    I'm finding mixed data on ECC ram support. Apparently the motherboards come in a couple variations. Once I confirm I believe I believe ECC is a better choice for this application. Still need to verify but I believe the board supports either 64 or 128gig.  That said how much ram should I use?\n  \n\n    Mobo has 2 m2 slots and 4 sata ports. Computer comes with a 256g nvme. I've read a little about using m2 Intel Optane drives for improved server performance. Anyone have any experience or input on this?\n  \n\n    Drives I'm still pondering.\n  \n\n    On the software side I am leaning towards TrueNas and  Jellyfin. Both seem relatively user friendly to someone with limited server knowledge. Thoughts?"},
{"Title": "I just need a a quiet always on network disk without all the usual NAS apps/features.", "Author": "u/largePenisLover", "Content": "The only thing missing from my setup is a simple NAS like 4tb volume that I can split into two partitions or shares, running on a very quiet always on device.\nI've been looking at NAS solutions for this but these do wayyyy to much feature wise and often have a weird walled gardenish approaches to things.\nLike this device that looks perfect, synology BeeDrive, apparently needs to be controlled VIA a synology run web service and has undeletable folders related to photo and video apps. Less idiot proof devices don't have this nonsense but are weird about backing them up.\nIt all feels very bloatwary to a home-NAS newbie\n  \n\n    I JUST need a dumb networked file box WITHOUT all the apps and features QNAP and Synolgoy bring to the table.\nI need it to be JUST a network share that I can access from any device on my home network using the file browsers on those devices.\nNo video managers, DSM's, BSM's, photo managers, or any of the usual stuff. Just files, in a file browser, that I can doubleclick to open.\nJut a dumb, \nquiet\n, reliable, file box.\n  \n\n    I want to be able to backup this dumb file box by mapping it to a drive letter on the backup pc and then run my backup script.\nNo bullshit with installing third party synology/qnap/whatever software, I just want to integrate it in my existing backup solutions and ignore what vendors want me to do.\n  \n\n    Does anyone know if such a dumb file box is available as an off the shelf product?"},
{"Title": "DAS Box - Can it be restarted remotely after a blackout?", "Author": "u/jfromeo", "Content": "I am in the search of a USB-C DAS to upgrade my 3,5\" HDD hoarding, as I do not have the space to accommodate a rack solution at the moment.\n  \n\n    I have found the MB-X10U31 from Fantec, which ticks all the features (10 bays, hot-swap, USB-C, etc). Quite similiar to the Mediasonic, IcyBox and Sabrent ones.\n  \n\n\nhttps://fantecshop.de/p/fantec-mb-x10u31\n\n\nhttps://preview.redd.it/das-box-can-it-be-restarted-remotely-after-a-blackout-v0-npzcdqysbb5d1.jpg\n\n    But I have one feature I depend on, and I cannot deduce how it will behave, and the brand has not answered me either.\n  \n\n    I need to find out \nif the box can somehow be restarted remotely after a blackout\n, as I live 1.000km away from the server and there is no one to operate it. I have an UPS which can hold around 15 minutes, but sometimes the blackout are longer and I have a routine via NUT to power off all the devices if power is not restored within that period of time. I can WoL the main machine, but I do not know how could I power up the DAS box.\n  \n\n    Thanks in advance."},
{"Title": "Merging folders and files", "Author": "u/cl326", "Content": "I have a Windows 11 system with many folders, sub-folders, and files. I want to keep only one copy of each file based on its MD5 hash, including its filename and extension. In the end I want just one folder with all the unique files. Is there any easy way to do this? If not a specific app, I'm willing to write an app or script in Python, Ruby, or PowerShell. Any thoughts or suggestions?"},
{"Title": "WD Ultrastar DC SN655 7.68 Tb for 196€ (211$) at a French retailer", "Author": "u/Nayko93", "Content": "I just found this deal, a 7.68TB NAS SSD for 196€, that's 0.02 cents per GB !I was thinking it could interest a few people here\n  \n\n\nhttps://fr.shopping.rakuten.com/offer/buy/11626286226/disque-dur-interne-7-68to-wd-ultrastar-dc-sn655-2-5-u-3-pcie-4-0-nvme-wus5ea176esp7e3.html\n\n\n\n    I'm not even sure it's real but it look like it, seller have a good reputation and the website is legitMaybe it's a price error, I don't know, but I've seen other posts talking about huge deal on those SSD so it seem this kind of deal is not impossible\n  \n\n    I tried to place a order to see if they ship outside of France and unfortunately they don't, so you either need to be in France, or use a friend or package forwarding service\n  \n\n    I'm almost tempted to buy 2 myself, since I'm looking to make my first home NASThat's a lot of money but for this much storage it would be dumb to pass it... but I know nothing of those SSD or NAS SSD in general, They need a PCI adapter to plug on a normal MB and I think I've read somewhere they heat up a lot ?I would be more comfortable dealing with normal sata or m.2 SSD... but such a deal.. I'm really tempted\n  \n\n\n\n    Update : It was legit, the seller confirmed my order and the price\n  \n\n    Unfortunately I had to cancel my order, because I can't find any U.3 pci card that can hold more than 1 SSD, and I need 3 off them, but I don't have 3 PCI left in my NAS"},
{"Title": "WD MyCloud Home once again screws me over", "Author": "u/techek", "Content": "My MyCloud Home has been updated to version 4.23.0 from December 4th 2023. I now know not become all excited and such, because almost every update since my purchase, has introduced one or more downgrades. Why remains unanswered.\n  \n\n    This time is no exception although the information about version 4.23.0 starts of with \"We constantly evaluate the customer experience ... wish to improve ... bring new and exciting features\" and so on.\n  \n\n    In reality it's a load of b......t, because this time they remove support for backing up videos and photos from Facebook. Previous update removed feature for editing photos in the app, before that remote backup with ElephantDrive disappeared, less connectivity and so on.\n  \n\n    The list of downgrades is impressive! And I feel used. Thanks for nothing, Western Digital!\n  \n\n    I cannot recommend their products for anyone anymore - those days are definitely over now."},
{"Title": "irc.hackint.org", "Author": "u/GuillermoBotonio", "Content": "Anyone know why I would suddenly not be able to access irc.hackint.org? I was able to go on there for about 3 days then its not loading. The guy I talked to from the page says the server is loading for him. I can get on Hackint.org ok but not the IRC."},
{"Title": "Are there any risks of using a USB Switch with a power supply on my PC and my DAS ?", "Author": "u/Yukinoooo", "Content": "My goal is to use my DAS on my PC and my media player (like a kind of Nvidia Shield, not Android or IOS, just the KODI interface under GNU/Linux) safely. I'm wondering if it's a good idea to use the two ports (PC and my media player) of a usb switch + a power supply and one port for my DAS ? If not, which solution should I use ?"},
{"Title": "RAID card no longer working, gives firmware error on POST", "Author": "u/Cyber_Akuma", "Content": "I have a LSI 9260-8i, this was actually reflashed from the original IRM ServeRAID M5014 it arrived as. It has since also been upgraded to the latest firmware from LSI/Broadcom, which is 12.15.0-0239 (also the card at boot identifies as BIOS version \"3.30.02.2 (Build June 17, 2014)\"). I am just simply using it in my Windows 10 system, not as part of a server or NAS.\n  \n\n    This card had been disconnected from my system for about 6-12 months, as well as it's drives, I recently reconnected everything in a new system. I have four HDDs in a RAID5, but had recently acquired the license key to enable RAID6 and had installed a 5th HDD in preparation for that. I had a few errors at first, but many things in the system were at first giving me errors so I didn't think much of it as I had performed several upgrades and changes at once.\n  \n\n    I eventually got everything booting properly and then opened up the RAID Windows management software (Version 17.05.02.01 at the time) and it seemed to be going ok. It was performing a Patrol Read on all of my drives and was recharging the battery (Though it claimed the battery was bad, but it was new, so I figured it needed to do a recharge cycle and re-learn to see it as good again). It said the Patrol Read was only going to take 10 minutes but I knew it was going to take hours. Halfway in, at about the 3-4 hour mark, the software completely stopped responding. I restarted it, and now the card was showing that absolutely nothing was installed to it.\n  \n\n    I performed a reboot and now I kept getting an error message during the card's initialization during post:\n  \n\n\n\n    LSI MegaRAID SAS-MFI BIOS Version 3.30.02.2 (Build June 17, 2014) Copyright(c) 2014 LSI Corporation Host Adapter Bus 5 Dev 0:\n  \n\n\n\n\n\n    F/W is in Fault State MFI Register State 0xF0010002\n  \n\n\n\n\n\n    Adapter at Baseport is not responding\n  \n\n\n\n\n\n    No MegaRAID Adapter Installed\n  \n\n\n\n    The card then could be seen as installed, but the drives were not showing up, and the management software could not even tell a card was installed anymore. I tried updating to the latest management software (17.05.06.00) in case it might at least see there is a card installed, with that being it's own can of worms of expecting me to manually install OpenJDK and set the environment paths myself, it also just gets stuck loading the application.\n  \n\n    I tried MegaCLI, StorCLI, and MegaSCU (I admit I am not too familiar with managing this card through a CLI) but -v and -AdpAllInfo -aALL but they all returned nothing. I tried disconnecting the drives in case one had somehow become so fault during storage that it was crashing it, and no difference. I tried the only other PCI socket in my motherboard and it would not even boot then, guess that socket isn't even working with everything else installed in my system.\n  \n\n    I have no idea what to do now. The card refuses to work, claiming it's suffering some kind of firmware fault on POST, none of the software seems to even detect the presence of the card at all despite it physically showing up in Device Manager (although with an \"An I/O adapter hardware error has occurred.\" error) and HWiNFO, and I am not aware of any way I can attempt a force-reflash of the firmware in case it's a software issue (although I somehow doubt it) or of what else to try.\n  \n\n    And yes, I have a backup of my data."},
{"Title": "IT BEGINS!", "Author": "u/pele4096", "Content": "No content"},
{"Title": "Just started VHS digitizing. Any tips for cable management?", "Author": "u/Applewoood", "Content": "No content"},
{"Title": "Jonsbo announces the N5 case", "Author": "u/Ben4425", "Content": "Nascompares just posted a description of the new \nJonsbo N5 case\n. It's a \nbeast\n with space for up to \n12\n 3.5\" drives and motherboard support for mITX, mATX, ATX, and E-ATX all with full-height PCIe cards."},
{"Title": "Newbie needing help", "Author": "u/Lochness_al", "Content": "I have 5 portable SSD and HDD plugged into my computer making my desk a mess I was wonding what would be a good external bay and HDD to buy. I want to run it with some kind of redundancy  (raid 1 most likely) It has my audio books, photos, and movies on it that I access through jelly fin I have thought about a nas before but I'm not that good with computers and just run jelly fin off my main PC."},
{"Title": "Need Help Setting Up Android and iPhone Backup Over WiFi to Windows PC", "Author": "u/BrokenScorp", "Content": "Hey everyone,\n  \n\n    I’m looking for some advice on setting up a reliable photo backup solution for my Android and iPhone over WiFi to my Windows PC. Currently, I’m using Resilio Sync, but it doesn’t seem to work well with iOS.\n  \n\n    Does anyone have any recommendations for tools or software that can handle this more effectively? Ideally, I’d like something that can manage both platforms seamlessly and ensure my data is safely backed up to my PC.\n  \n\n    Thanks in advance for your suggestions!"},
{"Title": "Teracopy Cut/Paste", "Author": "u/rickydumpling", "Content": "Does anyone know how Teracopy handles cutting and pasting? I interrupted it while moving multiple folders with verify enabled and I can’t find one of the original folders. Just wondering if this means that Teracopy finished pasting, verified, then deleted the original folder or something else."},
{"Title": "Powered down some HSGT workhorses today for not quite the last time - SMART stats are insane.", "Author": "u/platformterrestial", "Content": "We powered down an old storage server today and I took a few drives home partially to re-use and partially to check the SMART data.\n  \n\n    94568 power on hours, 23 spin ups. Still cranking away happily.\n  \nhttps://preview.redd.it/powered-down-some-hsgt-workhorses-today-for-not-quite-the-v0-8hl946jqa85d1.png"},
{"Title": "Portable (no-install) backup software for Windows?", "Author": "u/nefarious_bumpps", "Content": "I'm looking for a portable backup utility for Windows 10/11 desktops/laptops that can run from a USB drive without installation and perform disk image and full volume/partition backups and restores quickly to a USB external hdd/ssd.\n  \n\n    Free or reasonably-priced (under $150) commercial license.\n  \n\n    Any suggestions?"},
{"Title": "External Hard Drives", "Author": "u/Cravendale3", "Content": "Can someone explain why curry’s sells a 1tb external hard drive for £143 and then some random online shop sells 128tb for £130? How can there but such a tb difference but price is practically the same, I’m having such a difficult time trying to pick the right drive because there’s so much variety in price and tb storage, all I want is around 2tbs for a decent price, confused 🤔"},
{"Title": "Is there any news about Redfox AnyDVD being taken down?", "Author": "u/brandonyoung", "Content": "I use AnyDVD  as an easy way to make backup iso images of my DVDs and blurays.  I just noticed their forums now come up with an error page, and their main website  domain name no longer resolves to a site. \nhttp://www.redfox.bz/\n\n\n\n    Has their been any news of them going out of business or being taken down?  I tried Google search, but I haven't found anything.\n  \n\n    As an alternative, I can use makemkv to copy the folders, or just the video files. but it isn't the same.   I find backing up to iso image files easier for me to manage and organize my backups.  I tried using imgburn to copy the files to  an iso.  But VLC wouldn't play it.  Maybe I messed up somewhere in the settings  when creating the iso image from the backed up files?"},
{"Title": "Online NAS custom builders?", "Author": "u/Creepy_Finish1497", "Content": "Are there any online retailers that build NAS' for consumers?"},
{"Title": "Still not over the fact after close to 20 years Apple/iTunes/Apple TV lowers their movie trailer encode rate not just for new encodes/trailers but all prexisting encodes/trailers too", "Author": "u/ekos_640", "Content": "You can still download trailers from Apple though it's just a step or two more now - but they went from 9mbps on their movie trailer encodes since 2005-2006 until about 2022 when they redid everything on their backend and killed the old iTunes movie trailers site and moved it to Apple TV down to 6mbps\n  \n\n    Guess they wanted to start saving on storage/bandwith costs over the cost of the old files\n  \n\n    This wasn't just for new trailers from then on, but all preexisting trailers too :(\n  \n\n    Already have some 'older' movies I added to Plex I could have grabbed better trailers for then but didn't know I wanted the movies yet or changed my mind since I initially saw them :(\n  \n\n    We used to live in an age of opulence :("},
{"Title": "Need Honest Advice", "Author": "u/Substantial-Big8229", "Content": "For context, I left my gaming PC in a storage unit in a desert environment for nearly 2-3 years without ventilation, I'm concerned about potential data corruption or loss, especially regarding the SSD.\n  \n\n    I haven't powered it on, cleaned it, or updated its firmware during this time. What are the realistic chances of data corruption or loss, and how feasible is data recovery at this stage?\n  \n\n    (NOTE: Its consumer grade TLC SSD if that makes a difference.)"},
{"Title": "11 years ago I built a computer", "Author": "u/BinaryPatrickDev", "Content": "No content"},
{"Title": "Jumper pins on exos x18 14tb", "Author": "u/ctles", "Content": "Figured i might try here in that probably lots of people would have the 14tb exos here:\nWhat's the 4 jumper pins next to the SATA data for, see image below. I've looked through the main document i could find and asked a rep in seagate chat but he could only provide me what jumper pins may be for and his doc said the drive didn't have any jumper pins. But clearly they're there:\n  \n\n\nhttps://www.kitguru.net/wp-content/uploads/2018/11/Seagate-Exos-X14-14TB-Hard-Drive-Review-on-KitGuru-SATA-Connectors.png"},
{"Title": "Big off-line database for recipes?", "Author": "u/CamT86", "Content": "I'm about to start compiling some recipes for offline use(ideally in a way that'll be easy to view on a tablet, either in its memory or from a home server) and i was wondering if maybe there was already something similar thats already been set up, that i could work from rather than start from scratch. I dont really have any bright ideas on how to do this.\n  \n\n    In 2 weeks i'll need to go to a remote cabin with really poor internet connection(old style satellite shared between 8 households, thats barely better than 56k... not the elon musk new stuff) and cook for a few families that are also staying out there for summer. I'm sure this time I could literally just bring a cookbook and maybe a few printouts for what i need, but id like to set something up for future use as well.\nThey already have a small server set up with i think Kodi or plex that gets dragged back to civilization every few months for updates, so i figure i could just add whatever database file/system to that, to also be accessible to the person doing the cooking."},
{"Title": "Easy store external hard drive not mounting", "Author": "u/JessSerrano", "Content": "Hello! I have an Apple MacBook and I have the 2TB EasyStore external hard drive.\n  \n\n    I plug it in and sometimes it mounts, sometimes it doesn’t. I have another external hard drive (Seagate) that mounts with no issues. I changed cords too and my EasyStore isn’t mounting. Sometimes it does, though, which is odd. The light always turns on when I plug the cord into my Mac. Any suggestions on how to fix this? Thank you!"},
{"Title": "No media on window help.", "Author": "u/MisakaMisakaS100", "Content": "No content"},
{"Title": "Fast write speed small capacity USB Flash Drive", "Author": "u/Eidbanger", "Content": "Searching for a small capacity (due to expecting lower price) flash drive which has fast write speeds. I found a \n$32 Kingston DataTraveler Max 256 GB\n with up to 900 MB/s write but curious to hear if there's anything from 500 MB/s write for cheaper (~$10-20)?\nI'll be using this for creating bootable ISO images."},
{"Title": "Twitter is silently deleting some suspended accounts which has not been logged in for some time.", "Author": "u/cyberanakinvader", "Content": "I think I've made a disturbing discovery regarding Twitter where they have silently deleted some suspended accounts which has not been logged in for some time, including some of mine.\n  \n\n    Has anyone else encountered this issue recently?"},
{"Title": "Lib-gen question", "Author": "u/Hungry-Sentence-6722", "Content": "I’ve seen the direct download page for lib-gen sci-mag articles. I would like to understand how to convert all those files to the correct file name and extension. Libgen desktop is having issues with sourcing from mirrors.  I also don’t see the point in one by one files.. any advice? The metadata must be in the sql file but many pdf’s are just a few pages of a large book, I want to merge them all automatically."},
{"Title": "I don't trust raid 5", "Author": "u/obalobadik", "Content": "I have a 4-bay Asustor nas and 4x3TB HDD's. As for now I do not require more than 3TB raw storage and run the nas in raid 1 with only two drives.\n  \n\n    When I eventually want to increase my storage, I am sceptical to convert my volume to raid 5. Seeing the struggles involved with recovering data from an raid 5 array, I can't trust it as an option. I am more comfortable running two 2x3TB raid 1 array, since then I know that the data is formatted such that I can fetch it without rebuilding.  Even asustor themselves does not have a method of recovering the data from an raid 5 array. I have been using snapraid before, and that is has been feeling more safe, as  when a drive has failed, only the data on that drive has potentially been lost.\n  \n\n    Am I paranoid and recovering from raid 5 data loss not that troublesome? can you recover data from a single drive that is from a raid 5 array?"},
{"Title": "I'm running low on space in my custom built tower, what internal HDD's would you recommend?", "Author": "u/AVoraciousLatias", "Content": "Hi there, I have a 1 tb HDD and a 1 tb SDD. I'm looking to upgrade my HDD so I can store more games and programs on it, I'm looking for possibly a 4 tb or bigger so I won't have to worry about it any time soon. Do you have any suggestions for reliable HDDs that will last for a while? I'm looking for an internal that can be hooked up to the motherboard."},
{"Title": "Building a DIY JBOD", "Author": "u/OverlyBurntToast", "Content": "I have a bunch of old hard drives, and was wondering the best approach to putting them in some sort of DIY enclosure.\nMy first thought was to just buy a bunch of the super cheap SATA to USB converters and plug that into a USB hub (speed is a low priority), but that wont be able to power the 3.5 inch drives I have.\nI was wondering if I could power the hard drives using a spare PC PSU I have, and then connect the hard drives via some sort of SATA DATA to USB or something.\nDoes anyone have any ideas or hints, I would appreciate it greatly, as I am not too experienced in this field."},
{"Title": "Mid tower case vs 4U chassis for DIY NAS?", "Author": "u/Neurrone", "Content": "Hi,\n  \n\n    I'm currently looking to upgrade from an O11 air mini that only holds 4 drives because I realized it would be nice to have more drive slots and inadequate airflow causing some drives to run hot (ambient 28 C, idle 45, 51 under load). I made the mistake of choosing a case that only has as many drives that I had, so wanted to do it right this time. Use case is TrueNas with some apps, running on Ryzen 5700G to optimize for idle power consumption.\n  \n\n    I don't yet have a rack, but will be getting one when I move. Hence, I shortlisted some 4U rackmounts to place vertically first on a shelf:\n  \n\n\n\n\n\n\nLogic case sc-4316\n: US$350, 16 drives\n  \n\n\n\n\n\n\nSliger CX4712 \n: US$399, 12 drives. I'm leaning towards this\n  \n\n\n\n\n\n    These 4u cases aren't available for me locally - so estimated shipping to get either of those is an extra US$200, though I'm trying to find out if I can reduce that somehow.\n  \n\n    On the other hand,, a tower like the Fractal Meshify 2 (US$150) is much cheaper, and available to me locally, so I don't have to pay much for shipping. I could get 3 of these with the money needed to get the 4U.\n  \n\n    In this situation, are there enough advantages of those 4U cases to justify the extra expense? If I get a rack, I think I could place the Meshify 2 on its side on a shelf so that it only takes 6U.\n  \n\n    I'm new to rackmounted chassis, so these are the pros and cons I'm weighing, let me know if I missed anything.\n  \n\n    Pros:\n  \n\n\n\n\n\n    Support for redundant PSUs, hot swappable fans and drives for less uptime in case of a failure\n  \n\n\n\n\n\n    Support for larger motherboards: I currently have an ATX, not sure how useful support for larger form factors would be if I upgrade to lower end server boards\n  \n\n\n\n\n\n    Designed for rack mounting, smaller footprint\n  \n\n\n\n\n\n    Cons:\n  \n\n\n\n\n\n    Expensive\n  \n\n\n\n\n\n    Requires fan swaps for silence\n  \n\n\n\n\n\n    Higher drive temperatures? I assume drive temps would be worse compared to e.g, the meshify\n  \n\n\n\n\n\n    Won't fit my 160 mm cooler\n  \n\n\n\n\n\n    Thanks for reading!"},
{"Title": "My new Factory Recertified 22TB Seagate hard drives", "Author": "u/dropswisdom", "Content": "Sorry, had to re-post due to my previous post lacking in details.\n  \n\n    So here: got the drives here: \nhttps://www.ebay.com.sg/itm/204806952151\n\n\n\n    It was slightly cheaper when I got it. But it's one of the cheapest options you can find anywhere even now. The next step is 24TB drives which are not sold factory recertified as of yet, so they would cost.. about 50% more than this. I was concerned that some of the disks will arrive damaged, but as you can see it comes very well packaged, and they all passed testing. I put them into a Xpenology home made NAS. which is basically a itx motherboard inside a NAS case (jonsbo N1). It works like a charm. with one disk redundancy, I got about 80TB of fast storage.\n  \n\n    They cleared the hours on it when they recertified, but not the rest I think. But all the disks passed testing and are not making any suspicious noises or giving any issues.\n  \nhttps://preview.redd.it/my-new-factory-recertified-22tb-seagate-hard-drives-v0-j8twcye0lx4d1.jpg\nSeagate 22TB Sata Hard Drives"},
{"Title": "Do you trust your backup enough to not use parity?", "Author": "u/19wolf", "Content": "If downtime isn't an issue, is there a reason to \"waste\"  space if you have a valid 3-2-1 backup? I'm using unraid so if a drive dies it's not like I need to restore my whole pool. How does everyone else feel about this?"},
{"Title": "Best Way to Convert Podcasts on Spotify?", "Author": "u/ShyGuyGaming76", "Content": "I listen to a lot of audio dramas, and with about two exceptions (The Magnus Archives and Kakos Industries) most of them are \nonly\n on Spotify, so I'm not really able to archive them conveniently. What I'm doing right now is just screen recording them and converting it to an audio file. However, this is \nungodly\n slow.\n  \n\n    Any better ways?"},
{"Title": "Newbie needing help", "Author": "u/Lochness_al", "Content": "I have 5 portable SSD and HDD plugged into my computer making my desk a mess I was wonding what would be a good external bay and HDD to buy. I want to run it with some kind of redundancy  (raid 1 most likely) It has my audio books, photos, and movies on it that I access through jelly fin I have thought about a nas before but I'm not that good with computers and just run jelly fin off my main PC."},
{"Title": "Need Help Setting Up Android and iPhone Backup Over WiFi to Windows PC", "Author": "u/BrokenScorp", "Content": "Hey everyone,\n  \n\n    I’m looking for some advice on setting up a reliable photo backup solution for my Android and iPhone over WiFi to my Windows PC. Currently, I’m using Resilio Sync, but it doesn’t seem to work well with iOS.\n  \n\n    Does anyone have any recommendations for tools or software that can handle this more effectively? Ideally, I’d like something that can manage both platforms seamlessly and ensure my data is safely backed up to my PC.\n  \n\n    Thanks in advance for your suggestions!"},
{"Title": "Teracopy Cut/Paste", "Author": "u/rickydumpling", "Content": "Does anyone know how Teracopy handles cutting and pasting? I interrupted it while moving multiple folders with verify enabled and I can’t find one of the original folders. Just wondering if this means that Teracopy finished pasting, verified, then deleted the original folder or something else."},
{"Title": "Powered down some HSGT workhorses today for not quite the last time - SMART stats are insane.", "Author": "u/platformterrestial", "Content": "We powered down an old storage server today and I took a few drives home partially to re-use and partially to check the SMART data.\n  \n\n    94568 power on hours, 23 spin ups. Still cranking away happily.\n  \nhttps://preview.redd.it/powered-down-some-hsgt-workhorses-today-for-not-quite-the-v0-8hl946jqa85d1.png"},
{"Title": "Portable (no-install) backup software for Windows?", "Author": "u/nefarious_bumpps", "Content": "I'm looking for a portable backup utility for Windows 10/11 desktops/laptops that can run from a USB drive without installation and perform disk image and full volume/partition backups and restores quickly to a USB external hdd/ssd.\n  \n\n    Free or reasonably-priced (under $150) commercial license.\n  \n\n    Any suggestions?"},
{"Title": "External Hard Drives", "Author": "u/Cravendale3", "Content": "Can someone explain why curry’s sells a 1tb external hard drive for £143 and then some random online shop sells 128tb for £130? How can there but such a tb difference but price is practically the same, I’m having such a difficult time trying to pick the right drive because there’s so much variety in price and tb storage, all I want is around 2tbs for a decent price, confused 🤔"},
{"Title": "Is there any news about Redfox AnyDVD being taken down?", "Author": "u/brandonyoung", "Content": "I use AnyDVD  as an easy way to make backup iso images of my DVDs and blurays.  I just noticed their forums now come up with an error page, and their main website  domain name no longer resolves to a site. \nhttp://www.redfox.bz/\n\n\n\n    Has their been any news of them going out of business or being taken down?  I tried Google search, but I haven't found anything.\n  \n\n    As an alternative, I can use makemkv to copy the folders, or just the video files. but it isn't the same.   I find backing up to iso image files easier for me to manage and organize my backups.  I tried using imgburn to copy the files to  an iso.  But VLC wouldn't play it.  Maybe I messed up somewhere in the settings  when creating the iso image from the backed up files?"},
{"Title": "Online NAS custom builders?", "Author": "u/Creepy_Finish1497", "Content": "Are there any online retailers that build NAS' for consumers?"},
{"Title": "Still not over the fact after close to 20 years Apple/iTunes/Apple TV lowers their movie trailer encode rate not just for new encodes/trailers but all prexisting encodes/trailers too", "Author": "u/ekos_640", "Content": "You can still download trailers from Apple though it's just a step or two more now - but they went from 9mbps on their movie trailer encodes since 2005-2006 until about 2022 when they redid everything on their backend and killed the old iTunes movie trailers site and moved it to Apple TV down to 6mbps\n  \n\n    Guess they wanted to start saving on storage/bandwith costs over the cost of the old files\n  \n\n    This wasn't just for new trailers from then on, but all preexisting trailers too :(\n  \n\n    Already have some 'older' movies I added to Plex I could have grabbed better trailers for then but didn't know I wanted the movies yet or changed my mind since I initially saw them :(\n  \n\n    We used to live in an age of opulence :("},
{"Title": "Need Honest Advice", "Author": "u/Substantial-Big8229", "Content": "For context, I left my gaming PC in a storage unit in a desert environment for nearly 2-3 years without ventilation, I'm concerned about potential data corruption or loss, especially regarding the SSD.\n  \n\n    I haven't powered it on, cleaned it, or updated its firmware during this time. What are the realistic chances of data corruption or loss, and how feasible is data recovery at this stage?\n  \n\n    (NOTE: Its consumer grade TLC SSD if that makes a difference.)"},
{"Title": "11 years ago I built a computer", "Author": "u/BinaryPatrickDev", "Content": "No content"},
{"Title": "Jumper pins on exos x18 14tb", "Author": "u/ctles", "Content": "Figured i might try here in that probably lots of people would have the 14tb exos here:\nWhat's the 4 jumper pins next to the SATA data for, see image below. I've looked through the main document i could find and asked a rep in seagate chat but he could only provide me what jumper pins may be for and his doc said the drive didn't have any jumper pins. But clearly they're there:\n  \n\n\nhttps://www.kitguru.net/wp-content/uploads/2018/11/Seagate-Exos-X14-14TB-Hard-Drive-Review-on-KitGuru-SATA-Connectors.png"},
{"Title": "Big off-line database for recipes?", "Author": "u/CamT86", "Content": "I'm about to start compiling some recipes for offline use(ideally in a way that'll be easy to view on a tablet, either in its memory or from a home server) and i was wondering if maybe there was already something similar thats already been set up, that i could work from rather than start from scratch. I dont really have any bright ideas on how to do this.\n  \n\n    In 2 weeks i'll need to go to a remote cabin with really poor internet connection(old style satellite shared between 8 households, thats barely better than 56k... not the elon musk new stuff) and cook for a few families that are also staying out there for summer. I'm sure this time I could literally just bring a cookbook and maybe a few printouts for what i need, but id like to set something up for future use as well.\nThey already have a small server set up with i think Kodi or plex that gets dragged back to civilization every few months for updates, so i figure i could just add whatever database file/system to that, to also be accessible to the person doing the cooking."},
{"Title": "Easy store external hard drive not mounting", "Author": "u/JessSerrano", "Content": "Hello! I have an Apple MacBook and I have the 2TB EasyStore external hard drive.\n  \n\n    I plug it in and sometimes it mounts, sometimes it doesn’t. I have another external hard drive (Seagate) that mounts with no issues. I changed cords too and my EasyStore isn’t mounting. Sometimes it does, though, which is odd. The light always turns on when I plug the cord into my Mac. Any suggestions on how to fix this? Thank you!"},
{"Title": "No media on window help.", "Author": "u/MisakaMisakaS100", "Content": "No content"},
{"Title": "Fast write speed small capacity USB Flash Drive", "Author": "u/Eidbanger", "Content": "Searching for a small capacity (due to expecting lower price) flash drive which has fast write speeds. I found a \n$32 Kingston DataTraveler Max 256 GB\n with up to 900 MB/s write but curious to hear if there's anything from 500 MB/s write for cheaper (~$10-20)?\nI'll be using this for creating bootable ISO images."},
{"Title": "Twitter is silently deleting some suspended accounts which has not been logged in for some time.", "Author": "u/cyberanakinvader", "Content": "I think I've made a disturbing discovery regarding Twitter where they have silently deleted some suspended accounts which has not been logged in for some time, including some of mine.\n  \n\n    Has anyone else encountered this issue recently?"},
{"Title": "Lib-gen question", "Author": "u/Hungry-Sentence-6722", "Content": "I’ve seen the direct download page for lib-gen sci-mag articles. I would like to understand how to convert all those files to the correct file name and extension. Libgen desktop is having issues with sourcing from mirrors.  I also don’t see the point in one by one files.. any advice? The metadata must be in the sql file but many pdf’s are just a few pages of a large book, I want to merge them all automatically."},
{"Title": "I don't trust raid 5", "Author": "u/obalobadik", "Content": "I have a 4-bay Asustor nas and 4x3TB HDD's. As for now I do not require more than 3TB raw storage and run the nas in raid 1 with only two drives.\n  \n\n    When I eventually want to increase my storage, I am sceptical to convert my volume to raid 5. Seeing the struggles involved with recovering data from an raid 5 array, I can't trust it as an option. I am more comfortable running two 2x3TB raid 1 array, since then I know that the data is formatted such that I can fetch it without rebuilding.  Even asustor themselves does not have a method of recovering the data from an raid 5 array. I have been using snapraid before, and that is has been feeling more safe, as  when a drive has failed, only the data on that drive has potentially been lost.\n  \n\n    Am I paranoid and recovering from raid 5 data loss not that troublesome? can you recover data from a single drive that is from a raid 5 array?"},
{"Title": "I'm running low on space in my custom built tower, what internal HDD's would you recommend?", "Author": "u/AVoraciousLatias", "Content": "Hi there, I have a 1 tb HDD and a 1 tb SDD. I'm looking to upgrade my HDD so I can store more games and programs on it, I'm looking for possibly a 4 tb or bigger so I won't have to worry about it any time soon. Do you have any suggestions for reliable HDDs that will last for a while? I'm looking for an internal that can be hooked up to the motherboard."},
{"Title": "Building a DIY JBOD", "Author": "u/OverlyBurntToast", "Content": "I have a bunch of old hard drives, and was wondering the best approach to putting them in some sort of DIY enclosure.\nMy first thought was to just buy a bunch of the super cheap SATA to USB converters and plug that into a USB hub (speed is a low priority), but that wont be able to power the 3.5 inch drives I have.\nI was wondering if I could power the hard drives using a spare PC PSU I have, and then connect the hard drives via some sort of SATA DATA to USB or something.\nDoes anyone have any ideas or hints, I would appreciate it greatly, as I am not too experienced in this field."},
{"Title": "Mid tower case vs 4U chassis for DIY NAS?", "Author": "u/Neurrone", "Content": "Hi,\n  \n\n    I'm currently looking to upgrade from an O11 air mini that only holds 4 drives because I realized it would be nice to have more drive slots and inadequate airflow causing some drives to run hot (ambient 28 C, idle 45, 51 under load). I made the mistake of choosing a case that only has as many drives that I had, so wanted to do it right this time. Use case is TrueNas with some apps, running on Ryzen 5700G to optimize for idle power consumption.\n  \n\n    I don't yet have a rack, but will be getting one when I move. Hence, I shortlisted some 4U rackmounts to place vertically first on a shelf:\n  \n\n\n\n\n\n\nLogic case sc-4316\n: US$350, 16 drives\n  \n\n\n\n\n\n\nSliger CX4712 \n: US$399, 12 drives. I'm leaning towards this\n  \n\n\n\n\n\n    These 4u cases aren't available for me locally - so estimated shipping to get either of those is an extra US$200, though I'm trying to find out if I can reduce that somehow.\n  \n\n    On the other hand,, a tower like the Fractal Meshify 2 (US$150) is much cheaper, and available to me locally, so I don't have to pay much for shipping. I could get 3 of these with the money needed to get the 4U.\n  \n\n    In this situation, are there enough advantages of those 4U cases to justify the extra expense? If I get a rack, I think I could place the Meshify 2 on its side on a shelf so that it only takes 6U.\n  \n\n    I'm new to rackmounted chassis, so these are the pros and cons I'm weighing, let me know if I missed anything.\n  \n\n    Pros:\n  \n\n\n\n\n\n    Support for redundant PSUs, hot swappable fans and drives for less uptime in case of a failure\n  \n\n\n\n\n\n    Support for larger motherboards: I currently have an ATX, not sure how useful support for larger form factors would be if I upgrade to lower end server boards\n  \n\n\n\n\n\n    Designed for rack mounting, smaller footprint\n  \n\n\n\n\n\n    Cons:\n  \n\n\n\n\n\n    Expensive\n  \n\n\n\n\n\n    Requires fan swaps for silence\n  \n\n\n\n\n\n    Higher drive temperatures? I assume drive temps would be worse compared to e.g, the meshify\n  \n\n\n\n\n\n    Won't fit my 160 mm cooler\n  \n\n\n\n\n\n    Thanks for reading!"},
{"Title": "My new Factory Recertified 22TB Seagate hard drives", "Author": "u/dropswisdom", "Content": "Sorry, had to re-post due to my previous post lacking in details.\n  \n\n    So here: got the drives here: \nhttps://www.ebay.com.sg/itm/204806952151\n\n\n\n    It was slightly cheaper when I got it. But it's one of the cheapest options you can find anywhere even now. The next step is 24TB drives which are not sold factory recertified as of yet, so they would cost.. about 50% more than this. I was concerned that some of the disks will arrive damaged, but as you can see it comes very well packaged, and they all passed testing. I put them into a Xpenology home made NAS. which is basically a itx motherboard inside a NAS case (jonsbo N1). It works like a charm. with one disk redundancy, I got about 80TB of fast storage.\n  \n\n    They cleared the hours on it when they recertified, but not the rest I think. But all the disks passed testing and are not making any suspicious noises or giving any issues.\n  \nhttps://preview.redd.it/my-new-factory-recertified-22tb-seagate-hard-drives-v0-j8twcye0lx4d1.jpg\nSeagate 22TB Sata Hard Drives"},
{"Title": "Do you trust your backup enough to not use parity?", "Author": "u/19wolf", "Content": "If downtime isn't an issue, is there a reason to \"waste\"  space if you have a valid 3-2-1 backup? I'm using unraid so if a drive dies it's not like I need to restore my whole pool. How does everyone else feel about this?"},
{"Title": "Best Way to Convert Podcasts on Spotify?", "Author": "u/ShyGuyGaming76", "Content": "I listen to a lot of audio dramas, and with about two exceptions (The Magnus Archives and Kakos Industries) most of them are \nonly\n on Spotify, so I'm not really able to archive them conveniently. What I'm doing right now is just screen recording them and converting it to an audio file. However, this is \nungodly\n slow.\n  \n\n    Any better ways?"},
{"Title": "Newbie needing help", "Author": "u/Lochness_al", "Content": "I have 5 portable SSD and HDD plugged into my computer making my desk a mess I was wonding what would be a good external bay and HDD to buy. I want to run it with some kind of redundancy  (raid 1 most likely) It has my audio books, photos, and movies on it that I access through jelly fin I have thought about a nas before but I'm not that good with computers and just run jelly fin off my main PC."},
{"Title": "Need Help Setting Up Android and iPhone Backup Over WiFi to Windows PC", "Author": "u/BrokenScorp", "Content": "Hey everyone,\n  \n\n    I’m looking for some advice on setting up a reliable photo backup solution for my Android and iPhone over WiFi to my Windows PC. Currently, I’m using Resilio Sync, but it doesn’t seem to work well with iOS.\n  \n\n    Does anyone have any recommendations for tools or software that can handle this more effectively? Ideally, I’d like something that can manage both platforms seamlessly and ensure my data is safely backed up to my PC.\n  \n\n    Thanks in advance for your suggestions!"},
{"Title": "Teracopy Cut/Paste", "Author": "u/rickydumpling", "Content": "Does anyone know how Teracopy handles cutting and pasting? I interrupted it while moving multiple folders with verify enabled and I can’t find one of the original folders. Just wondering if this means that Teracopy finished pasting, verified, then deleted the original folder or something else."},
{"Title": "Powered down some HSGT workhorses today for not quite the last time - SMART stats are insane.", "Author": "u/platformterrestial", "Content": "We powered down an old storage server today and I took a few drives home partially to re-use and partially to check the SMART data.\n  \n\n    94568 power on hours, 23 spin ups. Still cranking away happily.\n  \nhttps://preview.redd.it/powered-down-some-hsgt-workhorses-today-for-not-quite-the-v0-8hl946jqa85d1.png"},
{"Title": "Portable (no-install) backup software for Windows?", "Author": "u/nefarious_bumpps", "Content": "I'm looking for a portable backup utility for Windows 10/11 desktops/laptops that can run from a USB drive without installation and perform disk image and full volume/partition backups and restores quickly to a USB external hdd/ssd.\n  \n\n    Free or reasonably-priced (under $150) commercial license.\n  \n\n    Any suggestions?"},
{"Title": "External Hard Drives", "Author": "u/Cravendale3", "Content": "Can someone explain why curry’s sells a 1tb external hard drive for £143 and then some random online shop sells 128tb for £130? How can there but such a tb difference but price is practically the same, I’m having such a difficult time trying to pick the right drive because there’s so much variety in price and tb storage, all I want is around 2tbs for a decent price, confused 🤔"},
{"Title": "Is there any news about Redfox AnyDVD being taken down?", "Author": "u/brandonyoung", "Content": "I use AnyDVD  as an easy way to make backup iso images of my DVDs and blurays.  I just noticed their forums now come up with an error page, and their main website  domain name no longer resolves to a site. \nhttp://www.redfox.bz/\n\n\n\n    Has their been any news of them going out of business or being taken down?  I tried Google search, but I haven't found anything.\n  \n\n    As an alternative, I can use makemkv to copy the folders, or just the video files. but it isn't the same.   I find backing up to iso image files easier for me to manage and organize my backups.  I tried using imgburn to copy the files to  an iso.  But VLC wouldn't play it.  Maybe I messed up somewhere in the settings  when creating the iso image from the backed up files?"},
{"Title": "Online NAS custom builders?", "Author": "u/Creepy_Finish1497", "Content": "Are there any online retailers that build NAS' for consumers?"},
{"Title": "Still not over the fact after close to 20 years Apple/iTunes/Apple TV lowers their movie trailer encode rate not just for new encodes/trailers but all prexisting encodes/trailers too", "Author": "u/ekos_640", "Content": "You can still download trailers from Apple though it's just a step or two more now - but they went from 9mbps on their movie trailer encodes since 2005-2006 until about 2022 when they redid everything on their backend and killed the old iTunes movie trailers site and moved it to Apple TV down to 6mbps\n  \n\n    Guess they wanted to start saving on storage/bandwith costs over the cost of the old files\n  \n\n    This wasn't just for new trailers from then on, but all preexisting trailers too :(\n  \n\n    Already have some 'older' movies I added to Plex I could have grabbed better trailers for then but didn't know I wanted the movies yet or changed my mind since I initially saw them :(\n  \n\n    We used to live in an age of opulence :("},
{"Title": "Need Honest Advice", "Author": "u/Substantial-Big8229", "Content": "For context, I left my gaming PC in a storage unit in a desert environment for nearly 2-3 years without ventilation, I'm concerned about potential data corruption or loss, especially regarding the SSD.\n  \n\n    I haven't powered it on, cleaned it, or updated its firmware during this time. What are the realistic chances of data corruption or loss, and how feasible is data recovery at this stage?\n  \n\n    (NOTE: Its consumer grade TLC SSD if that makes a difference.)"},
{"Title": "11 years ago I built a computer", "Author": "u/BinaryPatrickDev", "Content": "No content"},
{"Title": "Jumper pins on exos x18 14tb", "Author": "u/ctles", "Content": "Figured i might try here in that probably lots of people would have the 14tb exos here:\nWhat's the 4 jumper pins next to the SATA data for, see image below. I've looked through the main document i could find and asked a rep in seagate chat but he could only provide me what jumper pins may be for and his doc said the drive didn't have any jumper pins. But clearly they're there:\n  \n\n\nhttps://www.kitguru.net/wp-content/uploads/2018/11/Seagate-Exos-X14-14TB-Hard-Drive-Review-on-KitGuru-SATA-Connectors.png"},
{"Title": "Big off-line database for recipes?", "Author": "u/CamT86", "Content": "I'm about to start compiling some recipes for offline use(ideally in a way that'll be easy to view on a tablet, either in its memory or from a home server) and i was wondering if maybe there was already something similar thats already been set up, that i could work from rather than start from scratch. I dont really have any bright ideas on how to do this.\n  \n\n    In 2 weeks i'll need to go to a remote cabin with really poor internet connection(old style satellite shared between 8 households, thats barely better than 56k... not the elon musk new stuff) and cook for a few families that are also staying out there for summer. I'm sure this time I could literally just bring a cookbook and maybe a few printouts for what i need, but id like to set something up for future use as well.\nThey already have a small server set up with i think Kodi or plex that gets dragged back to civilization every few months for updates, so i figure i could just add whatever database file/system to that, to also be accessible to the person doing the cooking."},
{"Title": "Easy store external hard drive not mounting", "Author": "u/JessSerrano", "Content": "Hello! I have an Apple MacBook and I have the 2TB EasyStore external hard drive.\n  \n\n    I plug it in and sometimes it mounts, sometimes it doesn’t. I have another external hard drive (Seagate) that mounts with no issues. I changed cords too and my EasyStore isn’t mounting. Sometimes it does, though, which is odd. The light always turns on when I plug the cord into my Mac. Any suggestions on how to fix this? Thank you!"},
{"Title": "No media on window help.", "Author": "u/MisakaMisakaS100", "Content": "No content"},
{"Title": "Fast write speed small capacity USB Flash Drive", "Author": "u/Eidbanger", "Content": "Searching for a small capacity (due to expecting lower price) flash drive which has fast write speeds. I found a \n$32 Kingston DataTraveler Max 256 GB\n with up to 900 MB/s write but curious to hear if there's anything from 500 MB/s write for cheaper (~$10-20)?\nI'll be using this for creating bootable ISO images."},
{"Title": "Twitter is silently deleting some suspended accounts which has not been logged in for some time.", "Author": "u/cyberanakinvader", "Content": "I think I've made a disturbing discovery regarding Twitter where they have silently deleted some suspended accounts which has not been logged in for some time, including some of mine.\n  \n\n    Has anyone else encountered this issue recently?"},
{"Title": "Lib-gen question", "Author": "u/Hungry-Sentence-6722", "Content": "I’ve seen the direct download page for lib-gen sci-mag articles. I would like to understand how to convert all those files to the correct file name and extension. Libgen desktop is having issues with sourcing from mirrors.  I also don’t see the point in one by one files.. any advice? The metadata must be in the sql file but many pdf’s are just a few pages of a large book, I want to merge them all automatically."},
{"Title": "I don't trust raid 5", "Author": "u/obalobadik", "Content": "I have a 4-bay Asustor nas and 4x3TB HDD's. As for now I do not require more than 3TB raw storage and run the nas in raid 1 with only two drives.\n  \n\n    When I eventually want to increase my storage, I am sceptical to convert my volume to raid 5. Seeing the struggles involved with recovering data from an raid 5 array, I can't trust it as an option. I am more comfortable running two 2x3TB raid 1 array, since then I know that the data is formatted such that I can fetch it without rebuilding.  Even asustor themselves does not have a method of recovering the data from an raid 5 array. I have been using snapraid before, and that is has been feeling more safe, as  when a drive has failed, only the data on that drive has potentially been lost.\n  \n\n    Am I paranoid and recovering from raid 5 data loss not that troublesome? can you recover data from a single drive that is from a raid 5 array?"},
{"Title": "I'm running low on space in my custom built tower, what internal HDD's would you recommend?", "Author": "u/AVoraciousLatias", "Content": "Hi there, I have a 1 tb HDD and a 1 tb SDD. I'm looking to upgrade my HDD so I can store more games and programs on it, I'm looking for possibly a 4 tb or bigger so I won't have to worry about it any time soon. Do you have any suggestions for reliable HDDs that will last for a while? I'm looking for an internal that can be hooked up to the motherboard."},
{"Title": "Building a DIY JBOD", "Author": "u/OverlyBurntToast", "Content": "I have a bunch of old hard drives, and was wondering the best approach to putting them in some sort of DIY enclosure.\nMy first thought was to just buy a bunch of the super cheap SATA to USB converters and plug that into a USB hub (speed is a low priority), but that wont be able to power the 3.5 inch drives I have.\nI was wondering if I could power the hard drives using a spare PC PSU I have, and then connect the hard drives via some sort of SATA DATA to USB or something.\nDoes anyone have any ideas or hints, I would appreciate it greatly, as I am not too experienced in this field."},
{"Title": "Mid tower case vs 4U chassis for DIY NAS?", "Author": "u/Neurrone", "Content": "Hi,\n  \n\n    I'm currently looking to upgrade from an O11 air mini that only holds 4 drives because I realized it would be nice to have more drive slots and inadequate airflow causing some drives to run hot (ambient 28 C, idle 45, 51 under load). I made the mistake of choosing a case that only has as many drives that I had, so wanted to do it right this time. Use case is TrueNas with some apps, running on Ryzen 5700G to optimize for idle power consumption.\n  \n\n    I don't yet have a rack, but will be getting one when I move. Hence, I shortlisted some 4U rackmounts to place vertically first on a shelf:\n  \n\n\n\n\n\n\nLogic case sc-4316\n: US$350, 16 drives\n  \n\n\n\n\n\n\nSliger CX4712 \n: US$399, 12 drives. I'm leaning towards this\n  \n\n\n\n\n\n    These 4u cases aren't available for me locally - so estimated shipping to get either of those is an extra US$200, though I'm trying to find out if I can reduce that somehow.\n  \n\n    On the other hand,, a tower like the Fractal Meshify 2 (US$150) is much cheaper, and available to me locally, so I don't have to pay much for shipping. I could get 3 of these with the money needed to get the 4U.\n  \n\n    In this situation, are there enough advantages of those 4U cases to justify the extra expense? If I get a rack, I think I could place the Meshify 2 on its side on a shelf so that it only takes 6U.\n  \n\n    I'm new to rackmounted chassis, so these are the pros and cons I'm weighing, let me know if I missed anything.\n  \n\n    Pros:\n  \n\n\n\n\n\n    Support for redundant PSUs, hot swappable fans and drives for less uptime in case of a failure\n  \n\n\n\n\n\n    Support for larger motherboards: I currently have an ATX, not sure how useful support for larger form factors would be if I upgrade to lower end server boards\n  \n\n\n\n\n\n    Designed for rack mounting, smaller footprint\n  \n\n\n\n\n\n    Cons:\n  \n\n\n\n\n\n    Expensive\n  \n\n\n\n\n\n    Requires fan swaps for silence\n  \n\n\n\n\n\n    Higher drive temperatures? I assume drive temps would be worse compared to e.g, the meshify\n  \n\n\n\n\n\n    Won't fit my 160 mm cooler\n  \n\n\n\n\n\n    Thanks for reading!"},
{"Title": "My new Factory Recertified 22TB Seagate hard drives", "Author": "u/dropswisdom", "Content": "Sorry, had to re-post due to my previous post lacking in details.\n  \n\n    So here: got the drives here: \nhttps://www.ebay.com.sg/itm/204806952151\n\n\n\n    It was slightly cheaper when I got it. But it's one of the cheapest options you can find anywhere even now. The next step is 24TB drives which are not sold factory recertified as of yet, so they would cost.. about 50% more than this. I was concerned that some of the disks will arrive damaged, but as you can see it comes very well packaged, and they all passed testing. I put them into a Xpenology home made NAS. which is basically a itx motherboard inside a NAS case (jonsbo N1). It works like a charm. with one disk redundancy, I got about 80TB of fast storage.\n  \n\n    They cleared the hours on it when they recertified, but not the rest I think. But all the disks passed testing and are not making any suspicious noises or giving any issues.\n  \nhttps://preview.redd.it/my-new-factory-recertified-22tb-seagate-hard-drives-v0-j8twcye0lx4d1.jpg\nSeagate 22TB Sata Hard Drives"},
{"Title": "Do you trust your backup enough to not use parity?", "Author": "u/19wolf", "Content": "If downtime isn't an issue, is there a reason to \"waste\"  space if you have a valid 3-2-1 backup? I'm using unraid so if a drive dies it's not like I need to restore my whole pool. How does everyone else feel about this?"},
{"Title": "Best Way to Convert Podcasts on Spotify?", "Author": "u/ShyGuyGaming76", "Content": "I listen to a lot of audio dramas, and with about two exceptions (The Magnus Archives and Kakos Industries) most of them are \nonly\n on Spotify, so I'm not really able to archive them conveniently. What I'm doing right now is just screen recording them and converting it to an audio file. However, this is \nungodly\n slow.\n  \n\n    Any better ways?"},
{"Title": "Still trying to get the hand of Virtual Dub for transcribing my tapes", "Author": "u/KWalthersArt", "Content": "I am posting this so I can get answers while I sleep, I hope I'm not breaking any rules about redundent or stupid questions.\n  \n\n    So the problems I have are.\n  \n\n    Langrith compression seems to follow a high instance of dropped frames\n  \n\n    if I record to long audio and video goes out of sync.\n  \n\n    I don't know how to import my files into davinci for recompression in better lossless codec.\n  \n\n    I don't know how to install a better codec in VDub\n  \n\n    Some tapes have a whine sound on them.\n  \n\n    Set up.\n  \n\n    Gaming PC Intel Core i7\n  \n\n    Diamond VC500 usb card in a high level USB slot.\n  \n\n    Internal Hard drive then to external.\n  \n\n    Zenith XBR716 DVD-R VCR for play back.\n  \n\n    Most tapes are at SLP speed, I was a stupid teenager."},
{"Title": "Repairing drives…", "Author": "u/TwoRight9509", "Content": "A decade ago you’d send a broken drive to a place in California to get a repair / copy.\n  \n\n    How do we handle that now? Is there a best company to sent to?"},
{"Title": "Retrieving Photos From iPhoto Library In Time Machine Backup", "Author": "u/Akura_Awesome", "Content": "I have about a decade’s worth of Time Machine back ups across a dozen external drives, all with disparate photo libraries on them.\n  \n\n    Is there any sure fire way to pull these libraries out with metadata to throw on my NAS?\n  \n\n    I’ve tried to pull them in before but I get notifications about version and key mismatches, not to mention they can be a pain to locate.\n  \n\n    Any ideas are appreciated!"},
{"Title": "Help! I erased one of four RAID volumes set up with Disk Utilities", "Author": "u/peterinjapan", "Content": "Hi, I'm having an issue with a RAID with a volume I accidentally erased. My Yottamaster RAID started becoming unstable and was beeping all the time, so after giving up on it, I bought a Logitech enclosure and put the drives in, creating a RAID 5 volume with SoftRaid 8.\n  \n\n    After I got everything set up, of my disks disappeared from the new RAID, and as I was verifying the other three, another one gave me issues. So I decided to format the \"new\" disks and try again. I seem to have had one of the volumes in my old (backup) RAID selected, and erased it.\n  \n\n    The backup RAID was, I think, set up as two striped RAID volumes, which were then striped together to create a raid of that. This might not be the best way to do a RAID, but there was no option other than striped or mirrored disks, and at the time SoftRaid was not working with Apple Silicon at all.\n  \n\n    I have bought a large external disk to serve as a working disk to hopefully save my data. Can anyone suggest what will happen when I use the Restore option in Disk Utilities? If I can save the files and hopefully the folder structure, that will be good.  If there are any other tools besides Disk Utility I should be exploring, please let me know.\n  \n\n    Sending the disks to a data service isn't an option as I'm in rural Japan."},
{"Title": "Saw this and thought it belonged here.", "Author": "u/Mist17", "Content": "No content"},
{"Title": "Document Scanning Services", "Author": "u/JL4575", "Content": "I’m looking to scan a small collection of magazines, more than I want to manage manually. Each is stapled through the middle, not bound, and I would really like to not destroy the collection in getting them scanned. Can anyone recommend mail order services they’ve used?"},
{"Title": "G-RAID - Use built in HW RAID, Disk Utility RAID or something else?", "Author": "u/SuperChooch", "Content": "I have an older G-RAID device that is not supported by WD, attached to a Mac mini.    It is currently running G-RAID's hardware RAID at RAID 0 and I want to redeploy it for another purpose and make it RAID 1.  It is not mission critical and I'll be backing it up to another local location and to the cloud so if it craps out, it won't be the end of the world.  Should I continue to use G-RAID's RAID, should I use the Mac's Disk Utility RAID assistant or should I use something else?"},
{"Title": "2 part question.", "Author": "u/GrayManTech", "Content": "Hi.\n  \n\n    I have a bunch of DVDs that I want to convert to mp4 or whatever. I know I need a DVD player of some sort and software. I've seen here there are a couple of dvd players that don't need to be modified to use for this, but the posts I found were pretty old, have the available drives changed and if so which ones work out of the box?\n  \n\n    2nd part, storage. Is it possible to setup a Nas or something to use wifi so everyone in my house can access it? My router has a USB port but from what I understand it's disabled by xfinity. Basically I'm looking for something that can hold both 2.5 and 3.5 hdd since I already have both."},
{"Title": "CD ripping for dummies", "Author": "u/nlj1978", "Content": "While spring cleaning I stumbled across a long forgotten CD collection. Rummaging through it nostalgia is kicking hard. So of course I'm going to have to rip it all so I can enjoy.\n  \n\n    Have ~200 CDs I've located to rip.  Also have a previous stash of ripped CDs on one of my home computers\n  \n\n    Googling a bit I'm reading about FLAC files being best to get the best rip and gather the music information. Exact Audio Copy along with a few others get mentioned alot for ripping.\n  \n\n    What's the most user friendly and effective ripping software for someone new to this? Doesn't have to be freeware, will pay for solid software.\n  \n\n    Is the FLAC file format relatively usable? For example I have a networked Onkyo receiver, would it be able to play those files from the network?"},
{"Title": "Which would be better for a small NAS, using a RPi 4?", "Author": "u/NaAlSiO6", "Content": "I'm currently looking at two external HDD/SSD enclosures and can't decide which one to go with.\n  \n\n\n\n\n\n    The \nADSA-ST SUPERSPEED USB DUAL HDD DOCK\n\n\n\n\n\n\n\n    The \nAsus TUF Gaming A1\n\n\n\n\n\n\n\n    The first one supports two SSDs/HDDs, but it's somewhat difficult to find reasonable priced (when compared to a same capacity M.2 drive) 2.5 inch SATA SSDs. Still, it's not impossible and it could give me a lot more room to expand in the future. However, I also wonder about the performance of the drives, as there will be no cooling\n  \n\n    The second one however only supports one NVME SSD. Which couples with the USB 3.2 Gen 2X1 interface would give me better speed and thermals, due to the metal construction."},
{"Title": "[Noob] Using LTO5 for archival purposes, tips?", "Author": "u/mactep66", "Content": "I just got myself a FC LTO5 drive along with a few tapes (haven't arrived yet) for the purposes of archiving old data and freeing up my HDDs.\n  \n\n    What im looking for is a tool/tools that will keep a (hopefully) searchable index of all the files on all my tapes on my main SSD, one that would allow me to add/remove files from a tape at will and one for archiving large amounts of data as reliably and fast as possible.\n  \n\n    Ive head of Uranium backup, Veeam CE and my 5 should also be compatible with LTFS, but i haven't heard the best things about it, how good is it?"},
{"Title": "Needing Help Managing Duplicates", "Author": "u/klnadler", "Content": "Hi everyone, I'm on a long journey consolidating years of external drives to an Unraid server. I've been having a hard time managing duplicates, I am using Czkawka which is great at finding the duplicates but I'm having trouble with selecting the correct file to remove. I'll provide a screenshot of an example, after searching for duplicates I chose to select the newer file to delete and most of the files with -1 in the name are the newer file and it's from using exiftool to pool the files together. In the screenshot the one selected isn't the newer file according to any of the tags.\n  \n\n\nPhoto\n\n\n\n    Another issue I'm having is finding thumbnails that were accidentally sorted into the folders along the way. Some of the thumbnails are of the whole image and others are of faces from iPhotos face detection feature. Any guidance is appreciated TIA!"},
{"Title": "How hard is it to switch between RAID configurations?", "Author": "u/Austinitered", "Content": "I have a CM3588 Nas with 4 x 4TB M.2 SSDs I'm trying to setup and I'm stuck between the RAID configurations. It sounds like RAID-5 isn't the best since they SSDs are over 3TB; haven't fully confirmed this, just something I've read (LTT used it on this setup though). RAID-Z sounds like the best option so far, but only allows for 1 drive failure and I don't really see me utilizing >8TB anytime in the near future. Because of this, I'm wondering if I should start with RAID-10, and adjust/recreate the configuration to RAID-6 and then/or RAID-Z later on?\n  \n\n    Just started looking into RAID configurations, so this is all new to me. I'm guessing the biggest hurdle is migrating the data to temporary disks if I need to switch to a different configuration?\n  \n\n    Edit: Using Open Media Vault"},
{"Title": "Software recommendations for monitoring disk speeds (including NAS drives) in a nice graph format", "Author": "u/ThatGuyFilms", "Content": "I have a homelab setup that I do heaps of data transfers on, as I work in the video space a bunch of media coming in off external hard drives, NAS drives, an Unraid server and LTO tape.\n  \n\n    I'm after a software (ideally that works on both mac and windows) that can give me realtime data into transfers speeds from attached drives, to LTO tape and bandwidth across the machines and switch.\n  \n\n    I currently use the iStat menus (\nhttps://bjango.com/mac/istatmenus/\n) which I love, however you can only view it in a small popup window and can't see combined usage (i.e. network traffic as well as drive speeds) so would love an all in one solution if one exists, that displays in a nice graph format that shows the speeds of everything. Any recommendations?"},
{"Title": "How to download video from mediasite.com", "Author": "u/pavoganso", "Content": "Hi,\n  \n\n    I can't figure out how to download video. It doesn't seem to have a m3u8 stream."},
{"Title": "LTO5 tape drive with usbc thunderbolt", "Author": "u/mc_louis", "Content": "Hi everyone. I'm in the middle of some home renovation, and I decided that I want to reduce the space occupied by my all my stuff.\n  \n\n    At the moment I have a whole tower pc with windows 11 that I use just to run my external sas hp lto5 drive, through \nTHIS\n an lsi9211, which is a pcie 2.0 x8 lanes, everything working perfectly fine.\n  \n\n    I would like to remove the tower pc, if only I can connect the tape drive to a generic usb to use it with just the laptop when I need. I found few adapters like \nthis\n and I pulled the trigger. But it's not working, as I understand because my hba card is a x8 lanes, but all this adapters looks like they're just x4 lanes. I tried just covering the contacts on the card that correspond to the 5,6,7,8 lanes, as seen somewhere, but it's not working.\n  \n\n    Does anybody ever worked something like this out? For what I understand, there are not pcie x8 adapters that are affordable... are there any hba card that are x4 lanes? I found something on ebay, like \nthis\n, somewhere in the description says x8, but pictures and specifics says x4. Would this card work with my drive or am I missing something else?\n  \n\n    Damn it would be a game changer for me a usbc tape drive..."},
{"Title": "Should I buy a 1TB external SSD, or a Blu-ray burner + a 50-pack BD-R spindle + 50 jewel cases?", "Author": "u/TheresThisOtherThing", "Content": "Hello, I am new here and to data hoarding in general, so please give me the for-dummies version.\n  \n\n    I need to back up some data, a little less than 1TB. I have a couple copies in the cloud with different providers, and I'd like to make a physical copy that I can put in a box and store at a relative's house. I don't expect to update or modify this copy at all, ever, just copy the files in it to my laptop if the copies in the cloud \nand\n my laptop somehow all fail at the same time.\n  \n\n    I've been poking around on Amazon and it looks like at time of writing, a 1 TB external SSD or a combination of a Blu-ray burner, a 50-pack of BD-Rs, and 50 jewel cases, will each cost around $80. Which option is better for my case, and could you point me to better options? I'm on a budget, so maybe keep it below $100 if possible. Thanks!"},
{"Title": "Using an external drive to store photos question.", "Author": "u/shdujssnensisishs", "Content": "https://support.apple.com/guide/iphone/import-and-export-photos-and-videos-iph480caa1f3/ios\n\n\n\n    The link above is to apple’s website that shows u how to move photos to an external device. More specifically the “Export photos and videos to an external storage device” section.\n  \n\n    If I choose to do this, will my iPhone move the photos or just copy the photos and videos over and leave the originals on my phone?\n  \n\n    How would restoring the photos work? If I import it back, would the dates and location and everything still be there? Has anyone done this and can I get insight on this? Thank you!"},
{"Title": "any way to download entire galleries of art like gallery-dl?", "Author": "u/dietgilroy", "Content": "i tried using that but it didn't work at all, so i might use wfdownloader for that. i am considering trying to archive art from deviantart."},
{"Title": "The infuriating things about communicating the importance of data hoarding to the average internet user", "Author": "u/volthunter", "Content": "This is inspired by a conversation I've had which often feels cyclical about how we are losing access to most of the data on the internet, Yuzu the switch emulator was taken down and with it many clones and spin off's, Vimm's lair has had it's Nintendo roms forcefully removed, internet archive is being sued and getting cease and desists, some from Nintendo some from other companies, we've lost a multitude of pirate websites as of late, but people think piracy \" cant be defeated\".\n  \n\n    My point being that in the past 2 years more damage has been done to the current scene of the internet and preservation than all the years prior, it's not just about piracy or emulation, it's more than that, google search was a vital core of the internet and it's been ripped out.\n  \n\n    It's like the adage that there is a man in Czechoslovakia maintaining a piece of software that is crucial to the internet's existence and multiple times that has proven to be true, and now google has fallen and the internet is worse for it.\n  \n\n    A big loss that most people don't know if is that visa through their various connections to right wing christian organisations was actively campaigned by mormon extremists to revoke funding from most of the main xxx websites such as pornhub and xhamster, this seems funny, but an incredible amount of material was lost and i don't think it wise to dismiss something like this as just some minor occurrence.\n  \n\n    This may have been one of the largest data losses ever, the loss of amateur content on pornhub represented billions of hours of video that is lost to time, and PornHub conclusively proved that it was a sham case set up by a mormon church that aims to ban all adult material and even then, they were forced to shut down a retaliatory case and to shut down the amateur section of the site because of pressure from visa.\n  \n\n    The government itself has made material that many corporations would prefer you don't have access to such as fixing old factory equipment and booklets on home electric repair, with the american governments currently starting the fight to launch right to repair, you must realise that the companies would prefer if you did not have that right or information, ifixit and it's guides would be eliminated.\n  \n\n    Even the people testing products, tech channels like linus and level 1 techs would all be eliminated in time, too much finds itself at odds with these companies and you think it's hypothetical but if you upload a video tearing down an iphone and repairing it, apple may take it down, they are known to do it, same for john deer tractor hacks and lg washing machine repair videos, this is a fight, and we are losing.\n  \n\n    Anyways, i just see things getting worse and frankly it seems like we aren't bouncing back how the internet seems to think we are, the torrent scenes are no where near as alive as they used to be, even with private trackers, the scene is a shadow of what it once was, and i only see it getting worse, so hoard, data hoard it all."},
{"Title": "Upgrading from a USB JBOD", "Author": "u/doubledundercoder", "Content": "Hey all. I’ve got a usb 3.1 jbod attached to a decent laptop with 16gb of ram with a roughly 16tb zfs RAID. Works fine most of the time. I get 100mb/s reads if only one process is accessing the volume. If more than one process try’s it just tanks.\n  \n\n    Upgrading to a SAS enclosure or just getting a desktop case where I plug in the drives directly to the sata controller, what kind of performance increase can I expect for multiple processes on the volume? Am I dreaming thinking it will make a huge difference? It’s mostly for hosting Plex. Anyone gone from this setup to a direct attached on zfs?\n  \n\n    4 7.2k sata drives"},
{"Title": "Best way to transcode entire library of videos on Google Drive preferably though Google cloud", "Author": "u/cewong2", "Content": "I’ve been searing around for a day and a half trying to find a way to transcode lots of videos I have stored in my Google drive. I haven’t been able to find anyone ever having a solution (lots of what I’ve found isn’t gets downloaded and reuploaded after transcoding). Hopefully this is posted in the right place otherwise please suggest a subReddit for me to post to.\n  \n\n    Lots of my videos are in x264 format and I want to transcode them into x265 as I read there’s possibly a saving of at least 20-30% but it’s nearly 60-70TB which would take probably a long time compared just using Google’s free cloud trial. Can anyone recommend me a guide or tool that I can use to get this done?"},
{"Title": "NVME Speeds:  PCIe x1 , and USB3.0", "Author": "u/Anarcho_Christian", "Content": "I've got an extra Kingston NVME Drive lying around, and a lot of extra usb 3.0 ports.\n  \n\n    Would the speeds be comparable on a USB 3.0 drive vs a PCIe x1? Not \"theoretical\" speeds mind you, but like, practical speeds?"},
{"Title": "Macrium Reflect vs Arq Backup", "Author": "u/Gazumbo", "Content": "I've been using Arq for a few years. No majors issues, although I haven't had to test a full restore. I've been tempted to switch to Macrium as I already have a disk image using Macrium and switching would then mean I'm only using one piece of software instead of two.\n  \n\n    But, with regards to file and folder backup, what would I miss by switching to Macrium? I'm a home user and not knowledgeable on the more technical side of backup software. I believe Arq does a full backup and incremental from then on. I know Macrium has this option also.\n  \n\n    My main need is software that will never delete a file from a backup, no matter if I delete the source file or move it. Retaining a few versions. Bonus would be the ability to mirror this backup to the cloud in some form.\n  \n\n    Currently, I have local backup to an external drive using Arq, and cloud backup to backblaze using their personal computer license. So it's two different pieces of software but that's not a problem."},
{"Title": "Power Outage Froze my TrueNAS OS. How to Monitor Offsite TrueNAS Replication?", "Author": "u/Luz3r", "Content": "Hey everyone,\n  \n\n    I recently had a power outage at my backup location, and it seems to have messed with my TrueNAS box. It got stuck in a weird state, but thankfully a reboot fixed it. The problem is, I don't check my offsite server that often since it's a secondary location. This time, I only found out because I got an alert about my ZFS replication failing.\n  \n\n\nMy question is:\n How can I best check if my replication is actually working properly?\n  \n\n    I was thinking about setting up Uptime Kuma to monitor the offsite TrueNAS web interface. While this wouldn't necessarily tell me if replication is failing, it might catch issues like SSH being unresponsive. Ideally, I'd like to get Telegram alerts for any problems.\n  \n\n\nAnyone have any suggestions for a better or cool way to monitor my TrueNAS replication health?"},
{"Title": "Still trying to get the hand of Virtual Dub for transcribing my tapes", "Author": "u/KWalthersArt", "Content": "I am posting this so I can get answers while I sleep, I hope I'm not breaking any rules about redundent or stupid questions.\n  \n\n    So the problems I have are.\n  \n\n    Langrith compression seems to follow a high instance of dropped frames\n  \n\n    if I record to long audio and video goes out of sync.\n  \n\n    I don't know how to import my files into davinci for recompression in better lossless codec.\n  \n\n    I don't know how to install a better codec in VDub\n  \n\n    Some tapes have a whine sound on them.\n  \n\n    Set up.\n  \n\n    Gaming PC Intel Core i7\n  \n\n    Diamond VC500 usb card in a high level USB slot.\n  \n\n    Internal Hard drive then to external.\n  \n\n    Zenith XBR716 DVD-R VCR for play back.\n  \n\n    Most tapes are at SLP speed, I was a stupid teenager."},
{"Title": "Repairing drives…", "Author": "u/TwoRight9509", "Content": "A decade ago you’d send a broken drive to a place in California to get a repair / copy.\n  \n\n    How do we handle that now? Is there a best company to sent to?"},
{"Title": "Retrieving Photos From iPhoto Library In Time Machine Backup", "Author": "u/Akura_Awesome", "Content": "I have about a decade’s worth of Time Machine back ups across a dozen external drives, all with disparate photo libraries on them.\n  \n\n    Is there any sure fire way to pull these libraries out with metadata to throw on my NAS?\n  \n\n    I’ve tried to pull them in before but I get notifications about version and key mismatches, not to mention they can be a pain to locate.\n  \n\n    Any ideas are appreciated!"},
{"Title": "Help! I erased one of four RAID volumes set up with Disk Utilities", "Author": "u/peterinjapan", "Content": "Hi, I'm having an issue with a RAID with a volume I accidentally erased. My Yottamaster RAID started becoming unstable and was beeping all the time, so after giving up on it, I bought a Logitech enclosure and put the drives in, creating a RAID 5 volume with SoftRaid 8.\n  \n\n    After I got everything set up, of my disks disappeared from the new RAID, and as I was verifying the other three, another one gave me issues. So I decided to format the \"new\" disks and try again. I seem to have had one of the volumes in my old (backup) RAID selected, and erased it.\n  \n\n    The backup RAID was, I think, set up as two striped RAID volumes, which were then striped together to create a raid of that. This might not be the best way to do a RAID, but there was no option other than striped or mirrored disks, and at the time SoftRaid was not working with Apple Silicon at all.\n  \n\n    I have bought a large external disk to serve as a working disk to hopefully save my data. Can anyone suggest what will happen when I use the Restore option in Disk Utilities? If I can save the files and hopefully the folder structure, that will be good.  If there are any other tools besides Disk Utility I should be exploring, please let me know.\n  \n\n    Sending the disks to a data service isn't an option as I'm in rural Japan."},
{"Title": "Saw this and thought it belonged here.", "Author": "u/Mist17", "Content": "No content"},
{"Title": "Document Scanning Services", "Author": "u/JL4575", "Content": "I’m looking to scan a small collection of magazines, more than I want to manage manually. Each is stapled through the middle, not bound, and I would really like to not destroy the collection in getting them scanned. Can anyone recommend mail order services they’ve used?"},
{"Title": "G-RAID - Use built in HW RAID, Disk Utility RAID or something else?", "Author": "u/SuperChooch", "Content": "I have an older G-RAID device that is not supported by WD, attached to a Mac mini.    It is currently running G-RAID's hardware RAID at RAID 0 and I want to redeploy it for another purpose and make it RAID 1.  It is not mission critical and I'll be backing it up to another local location and to the cloud so if it craps out, it won't be the end of the world.  Should I continue to use G-RAID's RAID, should I use the Mac's Disk Utility RAID assistant or should I use something else?"},
{"Title": "2 part question.", "Author": "u/GrayManTech", "Content": "Hi.\n  \n\n    I have a bunch of DVDs that I want to convert to mp4 or whatever. I know I need a DVD player of some sort and software. I've seen here there are a couple of dvd players that don't need to be modified to use for this, but the posts I found were pretty old, have the available drives changed and if so which ones work out of the box?\n  \n\n    2nd part, storage. Is it possible to setup a Nas or something to use wifi so everyone in my house can access it? My router has a USB port but from what I understand it's disabled by xfinity. Basically I'm looking for something that can hold both 2.5 and 3.5 hdd since I already have both."},
{"Title": "CD ripping for dummies", "Author": "u/nlj1978", "Content": "While spring cleaning I stumbled across a long forgotten CD collection. Rummaging through it nostalgia is kicking hard. So of course I'm going to have to rip it all so I can enjoy.\n  \n\n    Have ~200 CDs I've located to rip.  Also have a previous stash of ripped CDs on one of my home computers\n  \n\n    Googling a bit I'm reading about FLAC files being best to get the best rip and gather the music information. Exact Audio Copy along with a few others get mentioned alot for ripping.\n  \n\n    What's the most user friendly and effective ripping software for someone new to this? Doesn't have to be freeware, will pay for solid software.\n  \n\n    Is the FLAC file format relatively usable? For example I have a networked Onkyo receiver, would it be able to play those files from the network?"},
{"Title": "Which would be better for a small NAS, using a RPi 4?", "Author": "u/NaAlSiO6", "Content": "I'm currently looking at two external HDD/SSD enclosures and can't decide which one to go with.\n  \n\n\n\n\n\n    The \nADSA-ST SUPERSPEED USB DUAL HDD DOCK\n\n\n\n\n\n\n\n    The \nAsus TUF Gaming A1\n\n\n\n\n\n\n\n    The first one supports two SSDs/HDDs, but it's somewhat difficult to find reasonable priced (when compared to a same capacity M.2 drive) 2.5 inch SATA SSDs. Still, it's not impossible and it could give me a lot more room to expand in the future. However, I also wonder about the performance of the drives, as there will be no cooling\n  \n\n    The second one however only supports one NVME SSD. Which couples with the USB 3.2 Gen 2X1 interface would give me better speed and thermals, due to the metal construction."},
{"Title": "[Noob] Using LTO5 for archival purposes, tips?", "Author": "u/mactep66", "Content": "I just got myself a FC LTO5 drive along with a few tapes (haven't arrived yet) for the purposes of archiving old data and freeing up my HDDs.\n  \n\n    What im looking for is a tool/tools that will keep a (hopefully) searchable index of all the files on all my tapes on my main SSD, one that would allow me to add/remove files from a tape at will and one for archiving large amounts of data as reliably and fast as possible.\n  \n\n    Ive head of Uranium backup, Veeam CE and my 5 should also be compatible with LTFS, but i haven't heard the best things about it, how good is it?"},
{"Title": "Needing Help Managing Duplicates", "Author": "u/klnadler", "Content": "Hi everyone, I'm on a long journey consolidating years of external drives to an Unraid server. I've been having a hard time managing duplicates, I am using Czkawka which is great at finding the duplicates but I'm having trouble with selecting the correct file to remove. I'll provide a screenshot of an example, after searching for duplicates I chose to select the newer file to delete and most of the files with -1 in the name are the newer file and it's from using exiftool to pool the files together. In the screenshot the one selected isn't the newer file according to any of the tags.\n  \n\n\nPhoto\n\n\n\n    Another issue I'm having is finding thumbnails that were accidentally sorted into the folders along the way. Some of the thumbnails are of the whole image and others are of faces from iPhotos face detection feature. Any guidance is appreciated TIA!"},
{"Title": "How hard is it to switch between RAID configurations?", "Author": "u/Austinitered", "Content": "I have a CM3588 Nas with 4 x 4TB M.2 SSDs I'm trying to setup and I'm stuck between the RAID configurations. It sounds like RAID-5 isn't the best since they SSDs are over 3TB; haven't fully confirmed this, just something I've read (LTT used it on this setup though). RAID-Z sounds like the best option so far, but only allows for 1 drive failure and I don't really see me utilizing >8TB anytime in the near future. Because of this, I'm wondering if I should start with RAID-10, and adjust/recreate the configuration to RAID-6 and then/or RAID-Z later on?\n  \n\n    Just started looking into RAID configurations, so this is all new to me. I'm guessing the biggest hurdle is migrating the data to temporary disks if I need to switch to a different configuration?\n  \n\n    Edit: Using Open Media Vault"},
{"Title": "Software recommendations for monitoring disk speeds (including NAS drives) in a nice graph format", "Author": "u/ThatGuyFilms", "Content": "I have a homelab setup that I do heaps of data transfers on, as I work in the video space a bunch of media coming in off external hard drives, NAS drives, an Unraid server and LTO tape.\n  \n\n    I'm after a software (ideally that works on both mac and windows) that can give me realtime data into transfers speeds from attached drives, to LTO tape and bandwidth across the machines and switch.\n  \n\n    I currently use the iStat menus (\nhttps://bjango.com/mac/istatmenus/\n) which I love, however you can only view it in a small popup window and can't see combined usage (i.e. network traffic as well as drive speeds) so would love an all in one solution if one exists, that displays in a nice graph format that shows the speeds of everything. Any recommendations?"},
{"Title": "How to download video from mediasite.com", "Author": "u/pavoganso", "Content": "Hi,\n  \n\n    I can't figure out how to download video. It doesn't seem to have a m3u8 stream."},
{"Title": "LTO5 tape drive with usbc thunderbolt", "Author": "u/mc_louis", "Content": "Hi everyone. I'm in the middle of some home renovation, and I decided that I want to reduce the space occupied by my all my stuff.\n  \n\n    At the moment I have a whole tower pc with windows 11 that I use just to run my external sas hp lto5 drive, through \nTHIS\n an lsi9211, which is a pcie 2.0 x8 lanes, everything working perfectly fine.\n  \n\n    I would like to remove the tower pc, if only I can connect the tape drive to a generic usb to use it with just the laptop when I need. I found few adapters like \nthis\n and I pulled the trigger. But it's not working, as I understand because my hba card is a x8 lanes, but all this adapters looks like they're just x4 lanes. I tried just covering the contacts on the card that correspond to the 5,6,7,8 lanes, as seen somewhere, but it's not working.\n  \n\n    Does anybody ever worked something like this out? For what I understand, there are not pcie x8 adapters that are affordable... are there any hba card that are x4 lanes? I found something on ebay, like \nthis\n, somewhere in the description says x8, but pictures and specifics says x4. Would this card work with my drive or am I missing something else?\n  \n\n    Damn it would be a game changer for me a usbc tape drive..."},
{"Title": "Should I buy a 1TB external SSD, or a Blu-ray burner + a 50-pack BD-R spindle + 50 jewel cases?", "Author": "u/TheresThisOtherThing", "Content": "Hello, I am new here and to data hoarding in general, so please give me the for-dummies version.\n  \n\n    I need to back up some data, a little less than 1TB. I have a couple copies in the cloud with different providers, and I'd like to make a physical copy that I can put in a box and store at a relative's house. I don't expect to update or modify this copy at all, ever, just copy the files in it to my laptop if the copies in the cloud \nand\n my laptop somehow all fail at the same time.\n  \n\n    I've been poking around on Amazon and it looks like at time of writing, a 1 TB external SSD or a combination of a Blu-ray burner, a 50-pack of BD-Rs, and 50 jewel cases, will each cost around $80. Which option is better for my case, and could you point me to better options? I'm on a budget, so maybe keep it below $100 if possible. Thanks!"},
{"Title": "Using an external drive to store photos question.", "Author": "u/shdujssnensisishs", "Content": "https://support.apple.com/guide/iphone/import-and-export-photos-and-videos-iph480caa1f3/ios\n\n\n\n    The link above is to apple’s website that shows u how to move photos to an external device. More specifically the “Export photos and videos to an external storage device” section.\n  \n\n    If I choose to do this, will my iPhone move the photos or just copy the photos and videos over and leave the originals on my phone?\n  \n\n    How would restoring the photos work? If I import it back, would the dates and location and everything still be there? Has anyone done this and can I get insight on this? Thank you!"},
{"Title": "any way to download entire galleries of art like gallery-dl?", "Author": "u/dietgilroy", "Content": "i tried using that but it didn't work at all, so i might use wfdownloader for that. i am considering trying to archive art from deviantart."},
{"Title": "The infuriating things about communicating the importance of data hoarding to the average internet user", "Author": "u/volthunter", "Content": "This is inspired by a conversation I've had which often feels cyclical about how we are losing access to most of the data on the internet, Yuzu the switch emulator was taken down and with it many clones and spin off's, Vimm's lair has had it's Nintendo roms forcefully removed, internet archive is being sued and getting cease and desists, some from Nintendo some from other companies, we've lost a multitude of pirate websites as of late, but people think piracy \" cant be defeated\".\n  \n\n    My point being that in the past 2 years more damage has been done to the current scene of the internet and preservation than all the years prior, it's not just about piracy or emulation, it's more than that, google search was a vital core of the internet and it's been ripped out.\n  \n\n    It's like the adage that there is a man in Czechoslovakia maintaining a piece of software that is crucial to the internet's existence and multiple times that has proven to be true, and now google has fallen and the internet is worse for it.\n  \n\n    A big loss that most people don't know if is that visa through their various connections to right wing christian organisations was actively campaigned by mormon extremists to revoke funding from most of the main xxx websites such as pornhub and xhamster, this seems funny, but an incredible amount of material was lost and i don't think it wise to dismiss something like this as just some minor occurrence.\n  \n\n    This may have been one of the largest data losses ever, the loss of amateur content on pornhub represented billions of hours of video that is lost to time, and PornHub conclusively proved that it was a sham case set up by a mormon church that aims to ban all adult material and even then, they were forced to shut down a retaliatory case and to shut down the amateur section of the site because of pressure from visa.\n  \n\n    The government itself has made material that many corporations would prefer you don't have access to such as fixing old factory equipment and booklets on home electric repair, with the american governments currently starting the fight to launch right to repair, you must realise that the companies would prefer if you did not have that right or information, ifixit and it's guides would be eliminated.\n  \n\n    Even the people testing products, tech channels like linus and level 1 techs would all be eliminated in time, too much finds itself at odds with these companies and you think it's hypothetical but if you upload a video tearing down an iphone and repairing it, apple may take it down, they are known to do it, same for john deer tractor hacks and lg washing machine repair videos, this is a fight, and we are losing.\n  \n\n    Anyways, i just see things getting worse and frankly it seems like we aren't bouncing back how the internet seems to think we are, the torrent scenes are no where near as alive as they used to be, even with private trackers, the scene is a shadow of what it once was, and i only see it getting worse, so hoard, data hoard it all."},
{"Title": "Upgrading from a USB JBOD", "Author": "u/doubledundercoder", "Content": "Hey all. I’ve got a usb 3.1 jbod attached to a decent laptop with 16gb of ram with a roughly 16tb zfs RAID. Works fine most of the time. I get 100mb/s reads if only one process is accessing the volume. If more than one process try’s it just tanks.\n  \n\n    Upgrading to a SAS enclosure or just getting a desktop case where I plug in the drives directly to the sata controller, what kind of performance increase can I expect for multiple processes on the volume? Am I dreaming thinking it will make a huge difference? It’s mostly for hosting Plex. Anyone gone from this setup to a direct attached on zfs?\n  \n\n    4 7.2k sata drives"},
{"Title": "Best way to transcode entire library of videos on Google Drive preferably though Google cloud", "Author": "u/cewong2", "Content": "I’ve been searing around for a day and a half trying to find a way to transcode lots of videos I have stored in my Google drive. I haven’t been able to find anyone ever having a solution (lots of what I’ve found isn’t gets downloaded and reuploaded after transcoding). Hopefully this is posted in the right place otherwise please suggest a subReddit for me to post to.\n  \n\n    Lots of my videos are in x264 format and I want to transcode them into x265 as I read there’s possibly a saving of at least 20-30% but it’s nearly 60-70TB which would take probably a long time compared just using Google’s free cloud trial. Can anyone recommend me a guide or tool that I can use to get this done?"},
{"Title": "NVME Speeds:  PCIe x1 , and USB3.0", "Author": "u/Anarcho_Christian", "Content": "I've got an extra Kingston NVME Drive lying around, and a lot of extra usb 3.0 ports.\n  \n\n    Would the speeds be comparable on a USB 3.0 drive vs a PCIe x1? Not \"theoretical\" speeds mind you, but like, practical speeds?"},
{"Title": "Macrium Reflect vs Arq Backup", "Author": "u/Gazumbo", "Content": "I've been using Arq for a few years. No majors issues, although I haven't had to test a full restore. I've been tempted to switch to Macrium as I already have a disk image using Macrium and switching would then mean I'm only using one piece of software instead of two.\n  \n\n    But, with regards to file and folder backup, what would I miss by switching to Macrium? I'm a home user and not knowledgeable on the more technical side of backup software. I believe Arq does a full backup and incremental from then on. I know Macrium has this option also.\n  \n\n    My main need is software that will never delete a file from a backup, no matter if I delete the source file or move it. Retaining a few versions. Bonus would be the ability to mirror this backup to the cloud in some form.\n  \n\n    Currently, I have local backup to an external drive using Arq, and cloud backup to backblaze using their personal computer license. So it's two different pieces of software but that's not a problem."},
{"Title": "Power Outage Froze my TrueNAS OS. How to Monitor Offsite TrueNAS Replication?", "Author": "u/Luz3r", "Content": "Hey everyone,\n  \n\n    I recently had a power outage at my backup location, and it seems to have messed with my TrueNAS box. It got stuck in a weird state, but thankfully a reboot fixed it. The problem is, I don't check my offsite server that often since it's a secondary location. This time, I only found out because I got an alert about my ZFS replication failing.\n  \n\n\nMy question is:\n How can I best check if my replication is actually working properly?\n  \n\n    I was thinking about setting up Uptime Kuma to monitor the offsite TrueNAS web interface. While this wouldn't necessarily tell me if replication is failing, it might catch issues like SSH being unresponsive. Ideally, I'd like to get Telegram alerts for any problems.\n  \n\n\nAnyone have any suggestions for a better or cool way to monitor my TrueNAS replication health?"},
{"Title": "Still trying to get the hand of Virtual Dub for transcribing my tapes", "Author": "u/KWalthersArt", "Content": "I am posting this so I can get answers while I sleep, I hope I'm not breaking any rules about redundent or stupid questions.\n  \n\n    So the problems I have are.\n  \n\n    Langrith compression seems to follow a high instance of dropped frames\n  \n\n    if I record to long audio and video goes out of sync.\n  \n\n    I don't know how to import my files into davinci for recompression in better lossless codec.\n  \n\n    I don't know how to install a better codec in VDub\n  \n\n    Some tapes have a whine sound on them.\n  \n\n    Set up.\n  \n\n    Gaming PC Intel Core i7\n  \n\n    Diamond VC500 usb card in a high level USB slot.\n  \n\n    Internal Hard drive then to external.\n  \n\n    Zenith XBR716 DVD-R VCR for play back.\n  \n\n    Most tapes are at SLP speed, I was a stupid teenager."},
{"Title": "Repairing drives…", "Author": "u/TwoRight9509", "Content": "A decade ago you’d send a broken drive to a place in California to get a repair / copy.\n  \n\n    How do we handle that now? Is there a best company to sent to?"},
{"Title": "Retrieving Photos From iPhoto Library In Time Machine Backup", "Author": "u/Akura_Awesome", "Content": "I have about a decade’s worth of Time Machine back ups across a dozen external drives, all with disparate photo libraries on them.\n  \n\n    Is there any sure fire way to pull these libraries out with metadata to throw on my NAS?\n  \n\n    I’ve tried to pull them in before but I get notifications about version and key mismatches, not to mention they can be a pain to locate.\n  \n\n    Any ideas are appreciated!"},
{"Title": "Help! I erased one of four RAID volumes set up with Disk Utilities", "Author": "u/peterinjapan", "Content": "Hi, I'm having an issue with a RAID with a volume I accidentally erased. My Yottamaster RAID started becoming unstable and was beeping all the time, so after giving up on it, I bought a Logitech enclosure and put the drives in, creating a RAID 5 volume with SoftRaid 8.\n  \n\n    After I got everything set up, of my disks disappeared from the new RAID, and as I was verifying the other three, another one gave me issues. So I decided to format the \"new\" disks and try again. I seem to have had one of the volumes in my old (backup) RAID selected, and erased it.\n  \n\n    The backup RAID was, I think, set up as two striped RAID volumes, which were then striped together to create a raid of that. This might not be the best way to do a RAID, but there was no option other than striped or mirrored disks, and at the time SoftRaid was not working with Apple Silicon at all.\n  \n\n    I have bought a large external disk to serve as a working disk to hopefully save my data. Can anyone suggest what will happen when I use the Restore option in Disk Utilities? If I can save the files and hopefully the folder structure, that will be good.  If there are any other tools besides Disk Utility I should be exploring, please let me know.\n  \n\n    Sending the disks to a data service isn't an option as I'm in rural Japan."},
{"Title": "Saw this and thought it belonged here.", "Author": "u/Mist17", "Content": "No content"},
{"Title": "Document Scanning Services", "Author": "u/JL4575", "Content": "I’m looking to scan a small collection of magazines, more than I want to manage manually. Each is stapled through the middle, not bound, and I would really like to not destroy the collection in getting them scanned. Can anyone recommend mail order services they’ve used?"},
{"Title": "G-RAID - Use built in HW RAID, Disk Utility RAID or something else?", "Author": "u/SuperChooch", "Content": "I have an older G-RAID device that is not supported by WD, attached to a Mac mini.    It is currently running G-RAID's hardware RAID at RAID 0 and I want to redeploy it for another purpose and make it RAID 1.  It is not mission critical and I'll be backing it up to another local location and to the cloud so if it craps out, it won't be the end of the world.  Should I continue to use G-RAID's RAID, should I use the Mac's Disk Utility RAID assistant or should I use something else?"},
{"Title": "2 part question.", "Author": "u/GrayManTech", "Content": "Hi.\n  \n\n    I have a bunch of DVDs that I want to convert to mp4 or whatever. I know I need a DVD player of some sort and software. I've seen here there are a couple of dvd players that don't need to be modified to use for this, but the posts I found were pretty old, have the available drives changed and if so which ones work out of the box?\n  \n\n    2nd part, storage. Is it possible to setup a Nas or something to use wifi so everyone in my house can access it? My router has a USB port but from what I understand it's disabled by xfinity. Basically I'm looking for something that can hold both 2.5 and 3.5 hdd since I already have both."},
{"Title": "CD ripping for dummies", "Author": "u/nlj1978", "Content": "While spring cleaning I stumbled across a long forgotten CD collection. Rummaging through it nostalgia is kicking hard. So of course I'm going to have to rip it all so I can enjoy.\n  \n\n    Have ~200 CDs I've located to rip.  Also have a previous stash of ripped CDs on one of my home computers\n  \n\n    Googling a bit I'm reading about FLAC files being best to get the best rip and gather the music information. Exact Audio Copy along with a few others get mentioned alot for ripping.\n  \n\n    What's the most user friendly and effective ripping software for someone new to this? Doesn't have to be freeware, will pay for solid software.\n  \n\n    Is the FLAC file format relatively usable? For example I have a networked Onkyo receiver, would it be able to play those files from the network?"},
{"Title": "Which would be better for a small NAS, using a RPi 4?", "Author": "u/NaAlSiO6", "Content": "I'm currently looking at two external HDD/SSD enclosures and can't decide which one to go with.\n  \n\n\n\n\n\n    The \nADSA-ST SUPERSPEED USB DUAL HDD DOCK\n\n\n\n\n\n\n\n    The \nAsus TUF Gaming A1\n\n\n\n\n\n\n\n    The first one supports two SSDs/HDDs, but it's somewhat difficult to find reasonable priced (when compared to a same capacity M.2 drive) 2.5 inch SATA SSDs. Still, it's not impossible and it could give me a lot more room to expand in the future. However, I also wonder about the performance of the drives, as there will be no cooling\n  \n\n    The second one however only supports one NVME SSD. Which couples with the USB 3.2 Gen 2X1 interface would give me better speed and thermals, due to the metal construction."},
{"Title": "[Noob] Using LTO5 for archival purposes, tips?", "Author": "u/mactep66", "Content": "I just got myself a FC LTO5 drive along with a few tapes (haven't arrived yet) for the purposes of archiving old data and freeing up my HDDs.\n  \n\n    What im looking for is a tool/tools that will keep a (hopefully) searchable index of all the files on all my tapes on my main SSD, one that would allow me to add/remove files from a tape at will and one for archiving large amounts of data as reliably and fast as possible.\n  \n\n    Ive head of Uranium backup, Veeam CE and my 5 should also be compatible with LTFS, but i haven't heard the best things about it, how good is it?"},
{"Title": "Needing Help Managing Duplicates", "Author": "u/klnadler", "Content": "Hi everyone, I'm on a long journey consolidating years of external drives to an Unraid server. I've been having a hard time managing duplicates, I am using Czkawka which is great at finding the duplicates but I'm having trouble with selecting the correct file to remove. I'll provide a screenshot of an example, after searching for duplicates I chose to select the newer file to delete and most of the files with -1 in the name are the newer file and it's from using exiftool to pool the files together. In the screenshot the one selected isn't the newer file according to any of the tags.\n  \n\n\nPhoto\n\n\n\n    Another issue I'm having is finding thumbnails that were accidentally sorted into the folders along the way. Some of the thumbnails are of the whole image and others are of faces from iPhotos face detection feature. Any guidance is appreciated TIA!"},
{"Title": "How hard is it to switch between RAID configurations?", "Author": "u/Austinitered", "Content": "I have a CM3588 Nas with 4 x 4TB M.2 SSDs I'm trying to setup and I'm stuck between the RAID configurations. It sounds like RAID-5 isn't the best since they SSDs are over 3TB; haven't fully confirmed this, just something I've read (LTT used it on this setup though). RAID-Z sounds like the best option so far, but only allows for 1 drive failure and I don't really see me utilizing >8TB anytime in the near future. Because of this, I'm wondering if I should start with RAID-10, and adjust/recreate the configuration to RAID-6 and then/or RAID-Z later on?\n  \n\n    Just started looking into RAID configurations, so this is all new to me. I'm guessing the biggest hurdle is migrating the data to temporary disks if I need to switch to a different configuration?\n  \n\n    Edit: Using Open Media Vault"},
{"Title": "Software recommendations for monitoring disk speeds (including NAS drives) in a nice graph format", "Author": "u/ThatGuyFilms", "Content": "I have a homelab setup that I do heaps of data transfers on, as I work in the video space a bunch of media coming in off external hard drives, NAS drives, an Unraid server and LTO tape.\n  \n\n    I'm after a software (ideally that works on both mac and windows) that can give me realtime data into transfers speeds from attached drives, to LTO tape and bandwidth across the machines and switch.\n  \n\n    I currently use the iStat menus (\nhttps://bjango.com/mac/istatmenus/\n) which I love, however you can only view it in a small popup window and can't see combined usage (i.e. network traffic as well as drive speeds) so would love an all in one solution if one exists, that displays in a nice graph format that shows the speeds of everything. Any recommendations?"},
{"Title": "How to download video from mediasite.com", "Author": "u/pavoganso", "Content": "Hi,\n  \n\n    I can't figure out how to download video. It doesn't seem to have a m3u8 stream."},
{"Title": "LTO5 tape drive with usbc thunderbolt", "Author": "u/mc_louis", "Content": "Hi everyone. I'm in the middle of some home renovation, and I decided that I want to reduce the space occupied by my all my stuff.\n  \n\n    At the moment I have a whole tower pc with windows 11 that I use just to run my external sas hp lto5 drive, through \nTHIS\n an lsi9211, which is a pcie 2.0 x8 lanes, everything working perfectly fine.\n  \n\n    I would like to remove the tower pc, if only I can connect the tape drive to a generic usb to use it with just the laptop when I need. I found few adapters like \nthis\n and I pulled the trigger. But it's not working, as I understand because my hba card is a x8 lanes, but all this adapters looks like they're just x4 lanes. I tried just covering the contacts on the card that correspond to the 5,6,7,8 lanes, as seen somewhere, but it's not working.\n  \n\n    Does anybody ever worked something like this out? For what I understand, there are not pcie x8 adapters that are affordable... are there any hba card that are x4 lanes? I found something on ebay, like \nthis\n, somewhere in the description says x8, but pictures and specifics says x4. Would this card work with my drive or am I missing something else?\n  \n\n    Damn it would be a game changer for me a usbc tape drive..."},
{"Title": "Should I buy a 1TB external SSD, or a Blu-ray burner + a 50-pack BD-R spindle + 50 jewel cases?", "Author": "u/TheresThisOtherThing", "Content": "Hello, I am new here and to data hoarding in general, so please give me the for-dummies version.\n  \n\n    I need to back up some data, a little less than 1TB. I have a couple copies in the cloud with different providers, and I'd like to make a physical copy that I can put in a box and store at a relative's house. I don't expect to update or modify this copy at all, ever, just copy the files in it to my laptop if the copies in the cloud \nand\n my laptop somehow all fail at the same time.\n  \n\n    I've been poking around on Amazon and it looks like at time of writing, a 1 TB external SSD or a combination of a Blu-ray burner, a 50-pack of BD-Rs, and 50 jewel cases, will each cost around $80. Which option is better for my case, and could you point me to better options? I'm on a budget, so maybe keep it below $100 if possible. Thanks!"},
{"Title": "Using an external drive to store photos question.", "Author": "u/shdujssnensisishs", "Content": "https://support.apple.com/guide/iphone/import-and-export-photos-and-videos-iph480caa1f3/ios\n\n\n\n    The link above is to apple’s website that shows u how to move photos to an external device. More specifically the “Export photos and videos to an external storage device” section.\n  \n\n    If I choose to do this, will my iPhone move the photos or just copy the photos and videos over and leave the originals on my phone?\n  \n\n    How would restoring the photos work? If I import it back, would the dates and location and everything still be there? Has anyone done this and can I get insight on this? Thank you!"},
{"Title": "any way to download entire galleries of art like gallery-dl?", "Author": "u/dietgilroy", "Content": "i tried using that but it didn't work at all, so i might use wfdownloader for that. i am considering trying to archive art from deviantart."},
{"Title": "The infuriating things about communicating the importance of data hoarding to the average internet user", "Author": "u/volthunter", "Content": "This is inspired by a conversation I've had which often feels cyclical about how we are losing access to most of the data on the internet, Yuzu the switch emulator was taken down and with it many clones and spin off's, Vimm's lair has had it's Nintendo roms forcefully removed, internet archive is being sued and getting cease and desists, some from Nintendo some from other companies, we've lost a multitude of pirate websites as of late, but people think piracy \" cant be defeated\".\n  \n\n    My point being that in the past 2 years more damage has been done to the current scene of the internet and preservation than all the years prior, it's not just about piracy or emulation, it's more than that, google search was a vital core of the internet and it's been ripped out.\n  \n\n    It's like the adage that there is a man in Czechoslovakia maintaining a piece of software that is crucial to the internet's existence and multiple times that has proven to be true, and now google has fallen and the internet is worse for it.\n  \n\n    A big loss that most people don't know if is that visa through their various connections to right wing christian organisations was actively campaigned by mormon extremists to revoke funding from most of the main xxx websites such as pornhub and xhamster, this seems funny, but an incredible amount of material was lost and i don't think it wise to dismiss something like this as just some minor occurrence.\n  \n\n    This may have been one of the largest data losses ever, the loss of amateur content on pornhub represented billions of hours of video that is lost to time, and PornHub conclusively proved that it was a sham case set up by a mormon church that aims to ban all adult material and even then, they were forced to shut down a retaliatory case and to shut down the amateur section of the site because of pressure from visa.\n  \n\n    The government itself has made material that many corporations would prefer you don't have access to such as fixing old factory equipment and booklets on home electric repair, with the american governments currently starting the fight to launch right to repair, you must realise that the companies would prefer if you did not have that right or information, ifixit and it's guides would be eliminated.\n  \n\n    Even the people testing products, tech channels like linus and level 1 techs would all be eliminated in time, too much finds itself at odds with these companies and you think it's hypothetical but if you upload a video tearing down an iphone and repairing it, apple may take it down, they are known to do it, same for john deer tractor hacks and lg washing machine repair videos, this is a fight, and we are losing.\n  \n\n    Anyways, i just see things getting worse and frankly it seems like we aren't bouncing back how the internet seems to think we are, the torrent scenes are no where near as alive as they used to be, even with private trackers, the scene is a shadow of what it once was, and i only see it getting worse, so hoard, data hoard it all."},
{"Title": "Upgrading from a USB JBOD", "Author": "u/doubledundercoder", "Content": "Hey all. I’ve got a usb 3.1 jbod attached to a decent laptop with 16gb of ram with a roughly 16tb zfs RAID. Works fine most of the time. I get 100mb/s reads if only one process is accessing the volume. If more than one process try’s it just tanks.\n  \n\n    Upgrading to a SAS enclosure or just getting a desktop case where I plug in the drives directly to the sata controller, what kind of performance increase can I expect for multiple processes on the volume? Am I dreaming thinking it will make a huge difference? It’s mostly for hosting Plex. Anyone gone from this setup to a direct attached on zfs?\n  \n\n    4 7.2k sata drives"},
{"Title": "Best way to transcode entire library of videos on Google Drive preferably though Google cloud", "Author": "u/cewong2", "Content": "I’ve been searing around for a day and a half trying to find a way to transcode lots of videos I have stored in my Google drive. I haven’t been able to find anyone ever having a solution (lots of what I’ve found isn’t gets downloaded and reuploaded after transcoding). Hopefully this is posted in the right place otherwise please suggest a subReddit for me to post to.\n  \n\n    Lots of my videos are in x264 format and I want to transcode them into x265 as I read there’s possibly a saving of at least 20-30% but it’s nearly 60-70TB which would take probably a long time compared just using Google’s free cloud trial. Can anyone recommend me a guide or tool that I can use to get this done?"},
{"Title": "NVME Speeds:  PCIe x1 , and USB3.0", "Author": "u/Anarcho_Christian", "Content": "I've got an extra Kingston NVME Drive lying around, and a lot of extra usb 3.0 ports.\n  \n\n    Would the speeds be comparable on a USB 3.0 drive vs a PCIe x1? Not \"theoretical\" speeds mind you, but like, practical speeds?"},
{"Title": "Macrium Reflect vs Arq Backup", "Author": "u/Gazumbo", "Content": "I've been using Arq for a few years. No majors issues, although I haven't had to test a full restore. I've been tempted to switch to Macrium as I already have a disk image using Macrium and switching would then mean I'm only using one piece of software instead of two.\n  \n\n    But, with regards to file and folder backup, what would I miss by switching to Macrium? I'm a home user and not knowledgeable on the more technical side of backup software. I believe Arq does a full backup and incremental from then on. I know Macrium has this option also.\n  \n\n    My main need is software that will never delete a file from a backup, no matter if I delete the source file or move it. Retaining a few versions. Bonus would be the ability to mirror this backup to the cloud in some form.\n  \n\n    Currently, I have local backup to an external drive using Arq, and cloud backup to backblaze using their personal computer license. So it's two different pieces of software but that's not a problem."},
{"Title": "Power Outage Froze my TrueNAS OS. How to Monitor Offsite TrueNAS Replication?", "Author": "u/Luz3r", "Content": "Hey everyone,\n  \n\n    I recently had a power outage at my backup location, and it seems to have messed with my TrueNAS box. It got stuck in a weird state, but thankfully a reboot fixed it. The problem is, I don't check my offsite server that often since it's a secondary location. This time, I only found out because I got an alert about my ZFS replication failing.\n  \n\n\nMy question is:\n How can I best check if my replication is actually working properly?\n  \n\n    I was thinking about setting up Uptime Kuma to monitor the offsite TrueNAS web interface. While this wouldn't necessarily tell me if replication is failing, it might catch issues like SSH being unresponsive. Ideally, I'd like to get Telegram alerts for any problems.\n  \n\n\nAnyone have any suggestions for a better or cool way to monitor my TrueNAS replication health?"},
{"Title": "Can 3.5” external enclosure setup drive", "Author": "u/ChillCaptain", "Content": "https://www.amazon.com/SSK-External-Docking-Enclosure-Supports/dp/B08P1539VD/ref=asc_df_B08P1539VD/?hvadid=693495256271&hvpos=&hvnetw=g&hvrand=2570617204095985210&hvpone=&hvptwo=&hvqmt=&hvdev=m&hvdvcmdl=&hvlocint=&hvlocphy=9057119&hvtargid=pla-1626594922711&psc=1&mcid=086ce8faf4d5351490f73a899c982a27&gad_source=1\n\n\n\n    I’m looking to get this enclosure to help with backups.\n  \n\n    Can I insert a brand new drive and set up the drive in windows? Usually this is done in disk management where you select gpt vs mbr and select the drive letter. After setting it up can I take the drive and insert it internally through sata and use the drive?\n  \n\n    I’m wondering if the usb connection limits this?"},
{"Title": "MixesDB - A Site Archiving Mixes And Live Shows Is Shutting Down At The End Of The Month. Data Hoarders, How Can We Fully Archive The Site?", "Author": "u/FinleyGomez", "Content": "No content"},
{"Title": "What is the best way to back-up 1 PB?", "Author": "u/Early-Mechanic6508", "Content": "My job has about 900 TB worth of storage.\n  \n\n    I'm looking for a cloud-based backup.\n  \n\n    Google Drive seems to have increments of 5 TB. Should I just get 200 users on drive?\n  \n\n    Since Dropbox unlimited is dead, that does not seem to be an option.\n  \n\n    Does anyone know a cheaper way? Does anyone have any suggestions?"},
{"Title": "DAS with 2x Raid1 for working and backup storage - Could use some guidance", "Author": "u/Final_Wedding_5634", "Content": "Hobbyist Photographer and videographer looking for DAS to expand my 2019 Macbook Pro's working space and archival backup space.\nCost is certainly a consideration.\n  \n\n    I have two needs:\n  \n\n\n\n\n\n    Backups - I presently have 2 x 3TB 5.4k rpm HDDs for storage in a desktop nearby. This PC needs to be replaced as its old and dying slowly. The HDDs work great - used for cold storage. the PC is off most of the time.\n  \n\n\n\n\n\n    More working space. Presently, I just keep my MBP clear of working document - i only load one project at a time and work off the internal 500GB SSD. This works but is getting tedious. I typically edit in either iMovie or Davinci Resolve (depending on project needs) and would like to move this to a larger DAS.\n  \n\n\n\n\n\n    I'm thinking I'd like\n  \n\n\n\n\n\n    1 DAS with 4 bays. But from who? OWC? MediaSonic?\n  \n\n\n\n\n\n    Configure the two HDDs into a single Raid 1 for local backups with redundancy. I'll copy files to cold storage as needed. This data is backed up to an external drive in a fire-safe and critical docs are backedup to the cloud as well.\n  \n\n\n\n\n\n    Configure two SSDs into a single Raid 1 for faster working space redundancy. I'll use these as working space for editing two or three streams of 1080.60 video. Once projects are finished, the final result and maybe the raw footage is saved to the HDDs for archival.\n  \n\n\n\n\n\n    Questions:\n  \n\n\n\n\n\n    General thoughts for this approach? I'm sure i'm not the only one doing this but I couldn't find anything. Maybe I should just go RAID 10 or 5 or something :(\n  \n\n\n\n\n\n    Is there a specific bus type to handle 2x 1 Raid? How do i know if a DAS can handle this 2x Raid 1 configuration? is any JBOD good enough? Suggestions for affordable DAS?\n  \n\n\n\n\n\n    Raid controllers? Do i use Disk Utility or the DAS's softwareraid? Who's got the best notification of a failed drive?\n  \n\n\n\n\n\n    Speed - ideally i'd like NVMe as it's fast and future proof (i.e. I'll eventually get into 4k filming, maybe). Are there boxes that have NVMe and HDD? I couldn't find any. Would SSDs suffice (the 2.5\" variety such as evos).\n  \n\n\n\n\n\n    edited for clarity"},
{"Title": "Is this Rot?", "Author": "u/MDCasino21", "Content": "No content"},
{"Title": "Synology vs Ebay PC", "Author": "u/Suspicious_Dig_5684", "Content": "So I have a server; what I am looking for is something to put 2 18tb drives in and be a dedicated photo backup for both IPhone and Android. Would love a way to pull the pictures from ICloud and get them local as well. The wife has more pictures in the cloud then she has space on the phone and I don't have a easy way to pull those down.\n  \n\n    Is the ds223 worth it? Are there better options. Biggest concern is a simple way to backup the iPhone that doesn't require user input.\n  \n\n    We tired nextcloud works great on android but with iphone I have to constantly remind her to open the app before it would backup anything.\n  \n\n    Thanks for any help."},
{"Title": "Any DataHoarders from 3rd world countries?", "Author": "u/kkgmgfn", "Content": "How do you backup TBs of data to cloud considering that we dont have unlimited home plans even on shelling money?\n  \n\n    I am from Bangalore,India I have multiple TBs to upload, thats collected over 15yrs. Later in incremental backup is fine but initial is hard."},
{"Title": "PSA: Blocking the blank PSU slots on NetApp disk shelves is non-optional, i.e. don't screw up like I did!", "Author": "u/xxpor", "Content": "My DS4246 came from ebay with the standard 2 PSU/2 Blank slot setup. I have the left side of the shelf totally full, and the right side partially full, but mostly empty. The drives on the right side were sitting around 45c, but the drives on the left side hit 67c (!!!!). I thought the drive sensors might be lying, since they were so high. I took a closer look at the empty slots and realized that the airflow that the PSUs were moving were likely coming mostly from the back of the unit since that's a path of less resistance than flowing over the drives themselves.\n  \n\n    I printed 2 of these guys: \nhttps://www.thingiverse.com/thing:6514452\n. I stuck them in the slots, and within 10 seconds the fans spun way up and started moving serious air. Now the drives are all around 35-42c, totally normal!\n  \n\n    So if you have a NetApp disk shelf, check your drive temps and make sure you block every open port. There's also an STL available to blank off IOM slots if you need it under the netapp category. Of course, they're available to buy as well."},
{"Title": "Currently have a desktop PC with a 1-bay NAS hosting my video and audio.  If I get this 12u rack with UPS and power strip with 2 vented racks, 1 to sit my PC on, other for my modem and wifi.  My next purchase will be a rackmount Synology 4-bay nas.  is this the way to go for me?", "Author": "u/Kevalemig", "Content": "No content"},
{"Title": "How can I add subtitles to my okru videos?", "Author": "u/irinaz165", "Content": "Hi! I've been trying to upload some videos to okru, I have the .srt files for the subtitles but I can't find the option to add them to my videos.\n  \n\n    I know it's possible to do it because I've seen videos with the option of turning the subtitles on and even with several languages to choose from.\n  \n\n    Thanks in advance!"},
{"Title": "What NAS Software and Mobile Apps work well for cleaning up a mess of photos and files", "Author": "u/SP4CEBAR-YT", "Content": "I have many storage devices with photos, documents, and backups of other storage devices, so there are a lot of duplicate files and photos. To fix this, I probably need a NAS with a good mobile app that can:\n  \n\n\n\n\n\n    find duplicate files and photos\n  \n\n\n\n\n\n    delete local photos after transferring them to the NAS\n  \n\n\n\n\n\n    handle errors during Photo transfers  (and avoid partial transfers that can't be resumed)\n  \n\n\n\n\n\n    optionally find if a photo is a photograph or a screenshot based on its metadata\n  \n\n\n\n\n\n    What NAS Manufacturers do you recommend based on their mobile apps and NAS software?"},
{"Title": "Storage solutions for photographers (and beyond).", "Author": "u/Uhuhgurl", "Content": "Hello all, I’m seeking advice from the experts here on finding the right storage solution for my wife and I. \n  \n\n    To give you some background, my wife is a professional photographer primarily working in digital. For many years, she has been using an external drive for her work. I, on the other hand, shoot film but recently started digitizing my photos.\n  \n\n    We had a Synology SD215 for a few years, which met many of our needs but was ultimately too slow for my wife's requirements. Additionally, we didn't fully utilize its capabilities. Now though, we believe integrating a NAS back into our workflow is exactly what we’re looking for.\n  \n\n    Some requirements:\n  \n\n\n\n\n\n    A storage solution that allows multiple users to interact with it simultaneously.\n  \n\n\n\n\n\n    Large storage capacity with fast read and write speeds.\n  \n\n\n\n\n\n    RAID capability for data loss protection.\n  \n\n\n\n\n\n    Versatility for various uses, including working storage, archival storage for digital assets (primarily images), potential Plex use, and security camera support.\n  \n\n\n\n\n\n    A \"set it and forget it\" solution that won't require frequent upgrades or replacements.\n  \n\n\n\n\n\n    Until this morning I was considering the OWC Jupiter Mini but I have some concerns about its network requirements (though I’m not opposed to upgrading our network if necessary). I’ve also considered a DIY approach but would prefer a solution with customer support in case we encounter any issues.\n  \n\n    Any recommendations you have would be greatly appreciated. Thank you!"},
{"Title": "Indexing of images with text recognition?", "Author": "u/asheritess", "Content": "TLDR: Is there any program that will analyze my images for text and attach what it finds to its metadata or create an external index, such that I can search by text in finder/file explorer?\n  \n\n    I'm currently using Apple's Photos to store nearly all my photos, in conjunction with periodically exporting my images from iCloud to hard drives.\n  \n\n    I have a good degree of organization of my exported files, able to export them with dates attached. This is useful for finding photos from trips I know the dates of or walking down memory lane. I also backed up the actual Photo Libraries that the app loads back when they were manageable sizes that could be stored on my computer.\n  \n\n    When I did work for distance learning, downloaded images, etc, the amount of images I generated skyrocketed. Since then iCloud's image recognition and character recognition abilities have become exceptional in my opinion, even processing frames of videos. However, this is not available on the desktop app.\n  \n\n    My efficiency has increased, as on my phone I can search my indexed library going back years by date, location, subject, and text. As of late I have been delighted to see that I can also search by text for images in folders on my Mac. I want to reap these benefits on an external storage drive.\n  \n\n    I've seen multiple image library applications with OCR capabilities. I understand that they are not able to handle such a large volume of images. I do like the convenience of scrolling through a library and am interested in hearing suggestions for these, although I have done some research myself. An issue that it poses is (in my experience) libraries doubling the amount of space my images take up by making their own copies for the library, and if I attempted to put all my photos into libraries that would take up so much space.\n  \n\n    I wonder if an idea I have has been executed by anyone other than Apple: is there any program that will alter the metadata, or create an index independent of a library app, such that I could search by text within Finder(/file explorer)? I want to use this feature on my backup drives and have all my images processed like what my laptop is currently doing locally. Or alternatively, is there a way to use Apple's feature on an external drive?"},
{"Title": "Searching for a decent 5+ bay JBOD with UASP", "Author": "u/ShapeShifter499", "Content": "Is there a decent 5 or more bay JBOD enclosure that supports UASP? My primary use is with a Linux machine via usb 3.0.\n  \n\n    I tried a terramaster D5-300C but I'm getting a load of I/O errors that seem related to UASP capping out. I may return it unless there's a software fix.\n  \n\n    Should I just resort to not having UASP on JBOD?"},
{"Title": "QNAP DAS for Plex server", "Author": "u/mxz117", "Content": "I'm looking at needing a storage upgrade for my plex server and a DAS seems to be the best option.\n  \n\n    It's already running on a champ of a little mini pc, already have an external SSD but I need more storage.\n  \n\n    I've found the QNAP TR-004 which looks like it would work well for me I've just got some questions about it. That I can't really seem to find answers about.\n  \n\n    Do I HAVE to use server drives? They seem to be way more expensive, logically thinking the drives would only need to be active when somebody is watching something, which isn't constantly as there's only about 3 users.\n  \n\n    Do I have to fill all 4 slots? Or could I fill 2, then add another 2 in the future when needed. (And do they all have to be the same drive/capacity/speed)\n  \n\n    And how would this go for future proofing vs a NAS? Would it be viable to just buy another of these DAS's to add more storage and plug into the computer or would a more expensive NAS be a better option?"},
{"Title": "Can you download long videos from VK.com", "Author": "u/raisedbyowls", "Content": "I know it’s an account only thing, but it’s easy to reg and there’s so much stuff, but I discovered that nothing can help me to get the video lasting over an hour. It’s a legal video, just in case."},
{"Title": "Any way to do an automatic \"on-demand\" setup involving an SSD and an HDD, where the SSD has only my recent active files, and everything else gets offloaded to the HDD until I try to access it again?", "Author": "u/OliveBranchMLP", "Content": "Howdy, I'm a film editor looking for an \"active\" solution to my problem.\n  \n\n    I have tried Googling this with terms like \"cold storage\" and \"file retrieval\" but those are giving me results that aren't applicable to my use-case scenario. I'm sure this setup exists, I just have no idea what it's called or what words to search for it.\n  \nMy current setup:\n\n    I have two drives:\n  \n\n\n\n\n\n    an \"active\" 2TB NVMe SSD, where I put all the stuff I'm actively working on\n  \n\n\n\n\n\n    an \"offline\" 24TB SATA HDD, where I put all the stuff I'm not actively working on\n  \n\n\n\n\n\n    The folder structure is identical between the drives, but to optimize space, no actual data is duplicated between them.\n  \n\n    (Yes, I have both drives backed up to a third drive.)\n  \nThe problem:\n\n    It's getting cumbersome having to manually move files to and from these drives as I need them, especially while preserving the file structure. I always have to dig into every folder to move the individual files because I don't need EVERYTHING in that folder. And it's hard to keep them in sync or avoid file conflicts because every syncing program I've found tries to sync EVERYTHING.\n  \nWhat I want:\n\n    Is there a way to automate this process, so that I only ever look at my SSD, but my SSD shows me everything that's on the HDD too as if they're one drive, and when I open a file on the SSD, it transfers it over from my HDD?\n  \n\n    Any help would be appreciated!"},
{"Title": "Using Photorec to scrape an old HDD", "Author": "u/Vast-Avocado-6321", "Content": "Hey all, I'm using \"Photorec\" that's included in \"TestDisk\" (i.e. free software that searches for deleted photos on storage mediums) to scrape some drives for .jpgs that used to be in an old PC of mine. Here's my conundrum:\n  \n\n    I initially scraped this drive for all .jpg files and it pulled about 11,000 files (this was a year ago). I'm now running the same program again, and searching for .jpg and it's only pulling about 3,000 files. I initially thought that maybe the data search was interrupted so I ran it again, and it pulled about the same amount. What's going on here? Is this software just not as robust as I thought? Should I try a paid software? Did the jpgs disappear from the sectors during the initial scrape and now, even though the drive has not been in use? Thanks."},
{"Title": "Good used document scanner", "Author": "u/OkBackground5843", "Content": "I'm shopping around on eBay for a document scanner. I'm hoping to get something good for under $150 which is why I'm shopping used. I see quite a few Canon DR-M160's within my price range. It seems like this is/was a fairly high end scanner, will it hold up well for home use?"},
{"Title": "How would you manage data storage on a pre-failing drive? Ensuring integrity is a risky context", "Author": "u/I-need-a-proper-nick", "Content": "Hi all,\n  \n\n    While the usual practice is to trash (pre-)failing \nexternal USB-powered\n drives, I tend to like to keep them as additional backup storage (like a 3rd copy) and some served me surprisingly well over the years.\n  \n\n\n\n\n\n    First, I simply copied the data in there and leave it be.\n  \n\n\n\n\n\n    Then I wondered how to make the thing more robust and I used checksums over the whole content which were periodically ran in order to ensure integrity\n  \n\n\n\n\n\n    Now, I'd like to know if you had other suggestions on how to store data in risky situations such as failing or pre-failing drives? Ideally, I'd like to be able to have a way to check integrity or maybe have self-healing ability (I looked into Multipar PAR2 but there're too many files to do so) inside the drive itself\n  \n\n\n\n\n\n    Thank you for your inputs."},
{"Title": "JMCD 12S4 12-bay case with backplane", "Author": "u/pavoganso", "Content": "This looks like a Jonsbo-killer with a decent amount of drive bays. Looks like my dream case based on the form factor.\n  \nhttps://preview.redd.it/jmcd-12s4-12-bay-case-with-backplane-v0-948ajvjeek4d1.jpg\nhttps://preview.redd.it/jmcd-12s4-12-bay-case-with-backplane-v0-2kf5zl9gek4d1.jpg\nhttps://preview.redd.it/jmcd-12s4-12-bay-case-with-backplane-v0-6e3kutphek4d1.jpg\n\n    Any thoughts or anyone tried it yet?"},
{"Title": "My ideal setup (theoretical)", "Author": "u/Balnian", "Content": "Hi fellow Homelaber!\nRecently I had to part way with my modest homelab setup (2x R710) because I'm moving to Japan (I don't think I need to explain why R710 and Japan don't work together).\n  \n\n    I've been looking for a replacement setup (mostly a NAS) that would sip power and leaning toward a one box solution to save on CPU power overhead.\n  \n\n    Some of the requirements I've come up with:\n  \n\n\n\n\n\n    Must have a NAS Component for backups/storage\n  \n\n\n\n\n\n    Must have enough compute power for simple services (Jellyfin, VPN, Hass)\n  \n\n\n\n\n\n    Should be able to do some basic transcoding (Jellyfin) preferably AV1\n  \n\n\n\n\n\n    Nice to have would be a NPU for basic AI task (Frigate/Hass)\n  \n\n\n\n\n\n    Inspired by the Asustor Flashstor (\n gen 1\n & \ngen 2\n), Minisforum MS-01 and some perusing of the intel spec sheets I found this \"gem\": \nIntel Core Ultra 5 125H\n.\n  \n\n    What's interesting with this processor are the 28 PCIe lanes which would theoretically allow for 12 M.2 SSD with   2 PCIe lanes each and still have 4 PCIe lanes free (can add NIC or other). It also has hardware support for AV1 transcoding and an NPU. Finally, since it's a 5 series processor it should have plenty of power for my needs.\n  \nSystem configuration\n\n    The configuration I came up with is interesting because it has 4 drives with a higher throughput (Gen5 x2) if we use SSDs like the \nSamsung 990 EVO\n which support PCIe® 4.0 x4 or 5.0 x2 interface.\n  \n\n    N.B.: An alternative config. would be a 6 drives config with all drives connected to a x4 interface\n  \n\n    Finally, this is just a theoretical configuration, a bunch of stuff could go wrong like improper support for the PCIe bifurcation for the x1 interface of the CPU. But I'm also bullish on this and would love to see an equivalent spec'd CPU from the newly announced Lunar Lake architecture generation (better energy efficiency, more powerful CPU, GPU and NPU with better power management) .\n  \n\n\nSome discussion points for the community:\n\n\n\n    What are your thoughts?\n  \n\n    What would you change to better fit your needs?\n  \n\n    Any improvement suggestions?\n  \n\n    Which manufacturer would you like to see try to bring this to market?\n  \n\n    What would you run on such a device?"},
{"Title": "My oldest Mp3s turn 25 this year!", "Author": "u/Over_Contact_5032", "Content": "No content"},
{"Title": "NVME SSD Enclosures/Docks Recommendations?", "Author": "u/Jasonwj322a", "Content": "Desperately need new enclosures as my current sabrent ones keeps disconnecting randomly. I've tried new cables so I don't believe that is the issue. Maybe the connector is worn?\n  \n\n    Either way, I checked out many options, but am having a hard time deciding since the well reviewed ones can cost upwards of $150. Sabrent offers a no frills enclosure for $30, but they also have a docking station which supports 2 SSD for $120. The latter also has a fan, which is neat since I have to point a cooling fan on my current ones. Though I am aware that it will be another point of failure.\n  \n\n    Curious what you guys are using? I know ZikeDrive and Orico are also well reviewed as well."},
{"Title": "Microfiche without equipment, or Microfiche alternatives?", "Author": "u/busybeeworking", "Content": "I want to archive a large number of documents, but don't want to do it on something that requires equipment that is expensive or could break.\n  \n\n    I heard using a flashlight and magnifying glass would be possible but annoying. I also heard using photographic slides but I only saw information for that for images, not written documents. Thoughts?\n  \n\n    Edit: I'm going to buy the archived material, the thing us I need a way to view it without equipment"},
{"Title": "Can 3.5” external enclosure setup drive", "Author": "u/ChillCaptain", "Content": "https://www.amazon.com/SSK-External-Docking-Enclosure-Supports/dp/B08P1539VD/ref=asc_df_B08P1539VD/?hvadid=693495256271&hvpos=&hvnetw=g&hvrand=2570617204095985210&hvpone=&hvptwo=&hvqmt=&hvdev=m&hvdvcmdl=&hvlocint=&hvlocphy=9057119&hvtargid=pla-1626594922711&psc=1&mcid=086ce8faf4d5351490f73a899c982a27&gad_source=1\n\n\n\n    I’m looking to get this enclosure to help with backups.\n  \n\n    Can I insert a brand new drive and set up the drive in windows? Usually this is done in disk management where you select gpt vs mbr and select the drive letter. After setting it up can I take the drive and insert it internally through sata and use the drive?\n  \n\n    I’m wondering if the usb connection limits this?"},
{"Title": "MixesDB - A Site Archiving Mixes And Live Shows Is Shutting Down At The End Of The Month. Data Hoarders, How Can We Fully Archive The Site?", "Author": "u/FinleyGomez", "Content": "No content"},
{"Title": "What is the best way to back-up 1 PB?", "Author": "u/Early-Mechanic6508", "Content": "My job has about 900 TB worth of storage.\n  \n\n    I'm looking for a cloud-based backup.\n  \n\n    Google Drive seems to have increments of 5 TB. Should I just get 200 users on drive?\n  \n\n    Since Dropbox unlimited is dead, that does not seem to be an option.\n  \n\n    Does anyone know a cheaper way? Does anyone have any suggestions?"},
{"Title": "DAS with 2x Raid1 for working and backup storage - Could use some guidance", "Author": "u/Final_Wedding_5634", "Content": "Hobbyist Photographer and videographer looking for DAS to expand my 2019 Macbook Pro's working space and archival backup space.\nCost is certainly a consideration.\n  \n\n    I have two needs:\n  \n\n\n\n\n\n    Backups - I presently have 2 x 3TB 5.4k rpm HDDs for storage in a desktop nearby. This PC needs to be replaced as its old and dying slowly. The HDDs work great - used for cold storage. the PC is off most of the time.\n  \n\n\n\n\n\n    More working space. Presently, I just keep my MBP clear of working document - i only load one project at a time and work off the internal 500GB SSD. This works but is getting tedious. I typically edit in either iMovie or Davinci Resolve (depending on project needs) and would like to move this to a larger DAS.\n  \n\n\n\n\n\n    I'm thinking I'd like\n  \n\n\n\n\n\n    1 DAS with 4 bays. But from who? OWC? MediaSonic?\n  \n\n\n\n\n\n    Configure the two HDDs into a single Raid 1 for local backups with redundancy. I'll copy files to cold storage as needed. This data is backed up to an external drive in a fire-safe and critical docs are backedup to the cloud as well.\n  \n\n\n\n\n\n    Configure two SSDs into a single Raid 1 for faster working space redundancy. I'll use these as working space for editing two or three streams of 1080.60 video. Once projects are finished, the final result and maybe the raw footage is saved to the HDDs for archival.\n  \n\n\n\n\n\n    Questions:\n  \n\n\n\n\n\n    General thoughts for this approach? I'm sure i'm not the only one doing this but I couldn't find anything. Maybe I should just go RAID 10 or 5 or something :(\n  \n\n\n\n\n\n    Is there a specific bus type to handle 2x 1 Raid? How do i know if a DAS can handle this 2x Raid 1 configuration? is any JBOD good enough? Suggestions for affordable DAS?\n  \n\n\n\n\n\n    Raid controllers? Do i use Disk Utility or the DAS's softwareraid? Who's got the best notification of a failed drive?\n  \n\n\n\n\n\n    Speed - ideally i'd like NVMe as it's fast and future proof (i.e. I'll eventually get into 4k filming, maybe). Are there boxes that have NVMe and HDD? I couldn't find any. Would SSDs suffice (the 2.5\" variety such as evos).\n  \n\n\n\n\n\n    edited for clarity"},
{"Title": "Is this Rot?", "Author": "u/MDCasino21", "Content": "No content"},
{"Title": "Synology vs Ebay PC", "Author": "u/Suspicious_Dig_5684", "Content": "So I have a server; what I am looking for is something to put 2 18tb drives in and be a dedicated photo backup for both IPhone and Android. Would love a way to pull the pictures from ICloud and get them local as well. The wife has more pictures in the cloud then she has space on the phone and I don't have a easy way to pull those down.\n  \n\n    Is the ds223 worth it? Are there better options. Biggest concern is a simple way to backup the iPhone that doesn't require user input.\n  \n\n    We tired nextcloud works great on android but with iphone I have to constantly remind her to open the app before it would backup anything.\n  \n\n    Thanks for any help."},
{"Title": "Any DataHoarders from 3rd world countries?", "Author": "u/kkgmgfn", "Content": "How do you backup TBs of data to cloud considering that we dont have unlimited home plans even on shelling money?\n  \n\n    I am from Bangalore,India I have multiple TBs to upload, thats collected over 15yrs. Later in incremental backup is fine but initial is hard."},
{"Title": "PSA: Blocking the blank PSU slots on NetApp disk shelves is non-optional, i.e. don't screw up like I did!", "Author": "u/xxpor", "Content": "My DS4246 came from ebay with the standard 2 PSU/2 Blank slot setup. I have the left side of the shelf totally full, and the right side partially full, but mostly empty. The drives on the right side were sitting around 45c, but the drives on the left side hit 67c (!!!!). I thought the drive sensors might be lying, since they were so high. I took a closer look at the empty slots and realized that the airflow that the PSUs were moving were likely coming mostly from the back of the unit since that's a path of less resistance than flowing over the drives themselves.\n  \n\n    I printed 2 of these guys: \nhttps://www.thingiverse.com/thing:6514452\n. I stuck them in the slots, and within 10 seconds the fans spun way up and started moving serious air. Now the drives are all around 35-42c, totally normal!\n  \n\n    So if you have a NetApp disk shelf, check your drive temps and make sure you block every open port. There's also an STL available to blank off IOM slots if you need it under the netapp category. Of course, they're available to buy as well."},
{"Title": "Currently have a desktop PC with a 1-bay NAS hosting my video and audio.  If I get this 12u rack with UPS and power strip with 2 vented racks, 1 to sit my PC on, other for my modem and wifi.  My next purchase will be a rackmount Synology 4-bay nas.  is this the way to go for me?", "Author": "u/Kevalemig", "Content": "No content"},
{"Title": "How can I add subtitles to my okru videos?", "Author": "u/irinaz165", "Content": "Hi! I've been trying to upload some videos to okru, I have the .srt files for the subtitles but I can't find the option to add them to my videos.\n  \n\n    I know it's possible to do it because I've seen videos with the option of turning the subtitles on and even with several languages to choose from.\n  \n\n    Thanks in advance!"},
{"Title": "What NAS Software and Mobile Apps work well for cleaning up a mess of photos and files", "Author": "u/SP4CEBAR-YT", "Content": "I have many storage devices with photos, documents, and backups of other storage devices, so there are a lot of duplicate files and photos. To fix this, I probably need a NAS with a good mobile app that can:\n  \n\n\n\n\n\n    find duplicate files and photos\n  \n\n\n\n\n\n    delete local photos after transferring them to the NAS\n  \n\n\n\n\n\n    handle errors during Photo transfers  (and avoid partial transfers that can't be resumed)\n  \n\n\n\n\n\n    optionally find if a photo is a photograph or a screenshot based on its metadata\n  \n\n\n\n\n\n    What NAS Manufacturers do you recommend based on their mobile apps and NAS software?"},
{"Title": "Storage solutions for photographers (and beyond).", "Author": "u/Uhuhgurl", "Content": "Hello all, I’m seeking advice from the experts here on finding the right storage solution for my wife and I. \n  \n\n    To give you some background, my wife is a professional photographer primarily working in digital. For many years, she has been using an external drive for her work. I, on the other hand, shoot film but recently started digitizing my photos.\n  \n\n    We had a Synology SD215 for a few years, which met many of our needs but was ultimately too slow for my wife's requirements. Additionally, we didn't fully utilize its capabilities. Now though, we believe integrating a NAS back into our workflow is exactly what we’re looking for.\n  \n\n    Some requirements:\n  \n\n\n\n\n\n    A storage solution that allows multiple users to interact with it simultaneously.\n  \n\n\n\n\n\n    Large storage capacity with fast read and write speeds.\n  \n\n\n\n\n\n    RAID capability for data loss protection.\n  \n\n\n\n\n\n    Versatility for various uses, including working storage, archival storage for digital assets (primarily images), potential Plex use, and security camera support.\n  \n\n\n\n\n\n    A \"set it and forget it\" solution that won't require frequent upgrades or replacements.\n  \n\n\n\n\n\n    Until this morning I was considering the OWC Jupiter Mini but I have some concerns about its network requirements (though I’m not opposed to upgrading our network if necessary). I’ve also considered a DIY approach but would prefer a solution with customer support in case we encounter any issues.\n  \n\n    Any recommendations you have would be greatly appreciated. Thank you!"},
{"Title": "Indexing of images with text recognition?", "Author": "u/asheritess", "Content": "TLDR: Is there any program that will analyze my images for text and attach what it finds to its metadata or create an external index, such that I can search by text in finder/file explorer?\n  \n\n    I'm currently using Apple's Photos to store nearly all my photos, in conjunction with periodically exporting my images from iCloud to hard drives.\n  \n\n    I have a good degree of organization of my exported files, able to export them with dates attached. This is useful for finding photos from trips I know the dates of or walking down memory lane. I also backed up the actual Photo Libraries that the app loads back when they were manageable sizes that could be stored on my computer.\n  \n\n    When I did work for distance learning, downloaded images, etc, the amount of images I generated skyrocketed. Since then iCloud's image recognition and character recognition abilities have become exceptional in my opinion, even processing frames of videos. However, this is not available on the desktop app.\n  \n\n    My efficiency has increased, as on my phone I can search my indexed library going back years by date, location, subject, and text. As of late I have been delighted to see that I can also search by text for images in folders on my Mac. I want to reap these benefits on an external storage drive.\n  \n\n    I've seen multiple image library applications with OCR capabilities. I understand that they are not able to handle such a large volume of images. I do like the convenience of scrolling through a library and am interested in hearing suggestions for these, although I have done some research myself. An issue that it poses is (in my experience) libraries doubling the amount of space my images take up by making their own copies for the library, and if I attempted to put all my photos into libraries that would take up so much space.\n  \n\n    I wonder if an idea I have has been executed by anyone other than Apple: is there any program that will alter the metadata, or create an index independent of a library app, such that I could search by text within Finder(/file explorer)? I want to use this feature on my backup drives and have all my images processed like what my laptop is currently doing locally. Or alternatively, is there a way to use Apple's feature on an external drive?"},
{"Title": "Searching for a decent 5+ bay JBOD with UASP", "Author": "u/ShapeShifter499", "Content": "Is there a decent 5 or more bay JBOD enclosure that supports UASP? My primary use is with a Linux machine via usb 3.0.\n  \n\n    I tried a terramaster D5-300C but I'm getting a load of I/O errors that seem related to UASP capping out. I may return it unless there's a software fix.\n  \n\n    Should I just resort to not having UASP on JBOD?"},
{"Title": "QNAP DAS for Plex server", "Author": "u/mxz117", "Content": "I'm looking at needing a storage upgrade for my plex server and a DAS seems to be the best option.\n  \n\n    It's already running on a champ of a little mini pc, already have an external SSD but I need more storage.\n  \n\n    I've found the QNAP TR-004 which looks like it would work well for me I've just got some questions about it. That I can't really seem to find answers about.\n  \n\n    Do I HAVE to use server drives? They seem to be way more expensive, logically thinking the drives would only need to be active when somebody is watching something, which isn't constantly as there's only about 3 users.\n  \n\n    Do I have to fill all 4 slots? Or could I fill 2, then add another 2 in the future when needed. (And do they all have to be the same drive/capacity/speed)\n  \n\n    And how would this go for future proofing vs a NAS? Would it be viable to just buy another of these DAS's to add more storage and plug into the computer or would a more expensive NAS be a better option?"},
{"Title": "Can you download long videos from VK.com", "Author": "u/raisedbyowls", "Content": "I know it’s an account only thing, but it’s easy to reg and there’s so much stuff, but I discovered that nothing can help me to get the video lasting over an hour. It’s a legal video, just in case."},
{"Title": "Any way to do an automatic \"on-demand\" setup involving an SSD and an HDD, where the SSD has only my recent active files, and everything else gets offloaded to the HDD until I try to access it again?", "Author": "u/OliveBranchMLP", "Content": "Howdy, I'm a film editor looking for an \"active\" solution to my problem.\n  \n\n    I have tried Googling this with terms like \"cold storage\" and \"file retrieval\" but those are giving me results that aren't applicable to my use-case scenario. I'm sure this setup exists, I just have no idea what it's called or what words to search for it.\n  \nMy current setup:\n\n    I have two drives:\n  \n\n\n\n\n\n    an \"active\" 2TB NVMe SSD, where I put all the stuff I'm actively working on\n  \n\n\n\n\n\n    an \"offline\" 24TB SATA HDD, where I put all the stuff I'm not actively working on\n  \n\n\n\n\n\n    The folder structure is identical between the drives, but to optimize space, no actual data is duplicated between them.\n  \n\n    (Yes, I have both drives backed up to a third drive.)\n  \nThe problem:\n\n    It's getting cumbersome having to manually move files to and from these drives as I need them, especially while preserving the file structure. I always have to dig into every folder to move the individual files because I don't need EVERYTHING in that folder. And it's hard to keep them in sync or avoid file conflicts because every syncing program I've found tries to sync EVERYTHING.\n  \nWhat I want:\n\n    Is there a way to automate this process, so that I only ever look at my SSD, but my SSD shows me everything that's on the HDD too as if they're one drive, and when I open a file on the SSD, it transfers it over from my HDD?\n  \n\n    Any help would be appreciated!"},
{"Title": "Using Photorec to scrape an old HDD", "Author": "u/Vast-Avocado-6321", "Content": "Hey all, I'm using \"Photorec\" that's included in \"TestDisk\" (i.e. free software that searches for deleted photos on storage mediums) to scrape some drives for .jpgs that used to be in an old PC of mine. Here's my conundrum:\n  \n\n    I initially scraped this drive for all .jpg files and it pulled about 11,000 files (this was a year ago). I'm now running the same program again, and searching for .jpg and it's only pulling about 3,000 files. I initially thought that maybe the data search was interrupted so I ran it again, and it pulled about the same amount. What's going on here? Is this software just not as robust as I thought? Should I try a paid software? Did the jpgs disappear from the sectors during the initial scrape and now, even though the drive has not been in use? Thanks."},
{"Title": "Good used document scanner", "Author": "u/OkBackground5843", "Content": "I'm shopping around on eBay for a document scanner. I'm hoping to get something good for under $150 which is why I'm shopping used. I see quite a few Canon DR-M160's within my price range. It seems like this is/was a fairly high end scanner, will it hold up well for home use?"},
{"Title": "How would you manage data storage on a pre-failing drive? Ensuring integrity is a risky context", "Author": "u/I-need-a-proper-nick", "Content": "Hi all,\n  \n\n    While the usual practice is to trash (pre-)failing \nexternal USB-powered\n drives, I tend to like to keep them as additional backup storage (like a 3rd copy) and some served me surprisingly well over the years.\n  \n\n\n\n\n\n    First, I simply copied the data in there and leave it be.\n  \n\n\n\n\n\n    Then I wondered how to make the thing more robust and I used checksums over the whole content which were periodically ran in order to ensure integrity\n  \n\n\n\n\n\n    Now, I'd like to know if you had other suggestions on how to store data in risky situations such as failing or pre-failing drives? Ideally, I'd like to be able to have a way to check integrity or maybe have self-healing ability (I looked into Multipar PAR2 but there're too many files to do so) inside the drive itself\n  \n\n\n\n\n\n    Thank you for your inputs."},
{"Title": "JMCD 12S4 12-bay case with backplane", "Author": "u/pavoganso", "Content": "This looks like a Jonsbo-killer with a decent amount of drive bays. Looks like my dream case based on the form factor.\n  \nhttps://preview.redd.it/jmcd-12s4-12-bay-case-with-backplane-v0-948ajvjeek4d1.jpg\nhttps://preview.redd.it/jmcd-12s4-12-bay-case-with-backplane-v0-2kf5zl9gek4d1.jpg\nhttps://preview.redd.it/jmcd-12s4-12-bay-case-with-backplane-v0-6e3kutphek4d1.jpg\n\n    Any thoughts or anyone tried it yet?"},
{"Title": "My ideal setup (theoretical)", "Author": "u/Balnian", "Content": "Hi fellow Homelaber!\nRecently I had to part way with my modest homelab setup (2x R710) because I'm moving to Japan (I don't think I need to explain why R710 and Japan don't work together).\n  \n\n    I've been looking for a replacement setup (mostly a NAS) that would sip power and leaning toward a one box solution to save on CPU power overhead.\n  \n\n    Some of the requirements I've come up with:\n  \n\n\n\n\n\n    Must have a NAS Component for backups/storage\n  \n\n\n\n\n\n    Must have enough compute power for simple services (Jellyfin, VPN, Hass)\n  \n\n\n\n\n\n    Should be able to do some basic transcoding (Jellyfin) preferably AV1\n  \n\n\n\n\n\n    Nice to have would be a NPU for basic AI task (Frigate/Hass)\n  \n\n\n\n\n\n    Inspired by the Asustor Flashstor (\n gen 1\n & \ngen 2\n), Minisforum MS-01 and some perusing of the intel spec sheets I found this \"gem\": \nIntel Core Ultra 5 125H\n.\n  \n\n    What's interesting with this processor are the 28 PCIe lanes which would theoretically allow for 12 M.2 SSD with   2 PCIe lanes each and still have 4 PCIe lanes free (can add NIC or other). It also has hardware support for AV1 transcoding and an NPU. Finally, since it's a 5 series processor it should have plenty of power for my needs.\n  \nSystem configuration\n\n    The configuration I came up with is interesting because it has 4 drives with a higher throughput (Gen5 x2) if we use SSDs like the \nSamsung 990 EVO\n which support PCIe® 4.0 x4 or 5.0 x2 interface.\n  \n\n    N.B.: An alternative config. would be a 6 drives config with all drives connected to a x4 interface\n  \n\n    Finally, this is just a theoretical configuration, a bunch of stuff could go wrong like improper support for the PCIe bifurcation for the x1 interface of the CPU. But I'm also bullish on this and would love to see an equivalent spec'd CPU from the newly announced Lunar Lake architecture generation (better energy efficiency, more powerful CPU, GPU and NPU with better power management) .\n  \n\n\nSome discussion points for the community:\n\n\n\n    What are your thoughts?\n  \n\n    What would you change to better fit your needs?\n  \n\n    Any improvement suggestions?\n  \n\n    Which manufacturer would you like to see try to bring this to market?\n  \n\n    What would you run on such a device?"},
{"Title": "My oldest Mp3s turn 25 this year!", "Author": "u/Over_Contact_5032", "Content": "No content"},
{"Title": "NVME SSD Enclosures/Docks Recommendations?", "Author": "u/Jasonwj322a", "Content": "Desperately need new enclosures as my current sabrent ones keeps disconnecting randomly. I've tried new cables so I don't believe that is the issue. Maybe the connector is worn?\n  \n\n    Either way, I checked out many options, but am having a hard time deciding since the well reviewed ones can cost upwards of $150. Sabrent offers a no frills enclosure for $30, but they also have a docking station which supports 2 SSD for $120. The latter also has a fan, which is neat since I have to point a cooling fan on my current ones. Though I am aware that it will be another point of failure.\n  \n\n    Curious what you guys are using? I know ZikeDrive and Orico are also well reviewed as well."},
{"Title": "Microfiche without equipment, or Microfiche alternatives?", "Author": "u/busybeeworking", "Content": "I want to archive a large number of documents, but don't want to do it on something that requires equipment that is expensive or could break.\n  \n\n    I heard using a flashlight and magnifying glass would be possible but annoying. I also heard using photographic slides but I only saw information for that for images, not written documents. Thoughts?\n  \n\n    Edit: I'm going to buy the archived material, the thing us I need a way to view it without equipment"},
{"Title": "80TB across 6 drives (with backup)", "Author": "u/19wolf", "Content": "I'm migrating my giant 8-bay CS381 into a 6-bay Ugreen, mostly for physical size reduction (and partly because the 8-bay model was $300 more expensive for some reason?). I bought two of them so I'll have an active+backup and I'm trying to decide how to set everything up.\n  \n\n\n\n\n\n    I absolutely do not want to use UGreen's OS. Right now I'm using UnRAID, but previously used Debian/MergerFS. I'm thinking maybe I'll try out TrueNAS? Or else stick with Unraid.\n  \n\n\n\n\n\n    I have 4x16tb drives (plus some 12/14tb), and am torn between buying 8 more to fill out the 6x2=12 bays, or going all in and getting 12x20tb drives.\n  \n\n\n\n\n\n    I'm not sure how I want to lay everything out. Currently I'm using 68 of 80TB, and I think it grows slowly enough to still last me a bit. I'll have the backup system and don't really mind downtime so I'm wondering if RAIDz/1 parity is enough for my purposes? Or does it really make the difference to do RAIDz2 with 20tb drives? Or maybe I should just skip RAID/parity altogether?\n  \n\n\n\n\n\n    What would you do?"},
{"Title": "Good NAS for video storage in 2024?", "Author": "u/DieserCoookie", "Content": "So atm im using a external harddrive connected to my Fritz!Router but im starting to run out of space on that one so i was wondering if maybe it's time to invest into a NAS and some huge harddrives.\n  \n\n    I stream the videos over network if that is a point to consider.\n  \n\n    So any suggestions?"},
{"Title": "Best small long-term storage medium", "Author": "u/ondsinet", "Content": "Hello. This might be a bit of an uncommon use case, so i haven't been able to find much info on the internet. I'd like to make a backup copy of my (videogame) cd collection to a more modern form factor (my computer doesn't have a cd reader). Instead of one big hard disk, I would like to dedicate an individual \"device\" to each game/game series, so storage space of around 1GB to 100GB, possibly in an easily stackble form factor. I know that CDs are perfect for this, i know i should just get an usb cd reader (i will), that's what all the search results said. I was wondering if there is any other medium that's suitable for this. USB sticks and SD cards fit every need, except they apparently won't keep data reliably when unpowered for years.\n  \n\n    Sorry if this is a stupid question, or this isn't the right place, but i haven't had to deal with a similar issue before ( i just copy all my other stuff to normal hard drives, but i wanted to keep the collection feel for these games), so feel free to kick me towards the right direction if I'm missing something obvious."},
{"Title": "Anyone using VueScan with a Fujitsu ADF scanner?", "Author": "u/Primary_Season7533", "Content": "I got a Fujitsu fi-7160 to digitize my family's photos. Had really high hopes for this scanner since Fujitsu seems very reliable and it has CCD sensors. I've been very disappointed with the image quality from their own software, Paperstream Capture, so I turned to VueScan.\n  \n\n    However, there seem to be something that's fundamentally wrong with this software or the combination of the software and scanner. I get really unpredictable results, cropping some photos but not others, settings not updating when I press the buttons – then updating next time I scan, duplex only works sometimes (not set to skip blank pages)... the list of bugs goes on.\n  \n\n    Yes, I wrote to Ed Hamrick who asked me for a bug report. Did my best to write one but never heard back. Saw an April update (VueScan 9.8.32) was supposed to address Fujitsu scanner issues but seems to only be worse for me compared to earlier.\n  \n\n    Have tried NAPS2 and it seems to work super well so hardware should be fine.\n  \n\n    Anyone who got Fujitsu ADF-scanners to work with VueScan?"},
{"Title": "Is ext4/XFS really better than ZFS/BTRFS for reliability?", "Author": "u/No-Balance-8038", "Content": "I have had a btrfs raid1c3 out of 3x20TB disks myself. It was really unhelpful when I used AOSP (via USB) as it didnt tell me why it did make it read only... not using AOSP would have helped\nRecently I switched over to a real server, with a HBA and immediate connection.\n  \n\n    Then I googled, and the following points were made:\n  \n\n    btrfs: Super bad because silently is overfilled and getting NOENT - all disk used, but regular rebalance is completely not recommended to avoid this issue altogether. Apparently misrepresents actual disk space.\nZFS: Super bad because will never be in Linux tree, and is hard to maintain, apparently \"just hype\"\nhttps://www.reddit.com/r/zfs/comments/sfo1tq/linus_tech_tips_fails_at_using_zfs_properly_loses/\n\n\n\n\nhttps://storytime.ivysaur.me/posts/why-not-zfs/\n\n\n\n\nhttps://github.com/openzfs/zfs/labels/Type%3A%20Defect\n\n\n\n    And then we had that corruption bug in ZFS. Backups are most important!\nBut then people in ZFS IRC tell me to instead use multiple different filesystems and just hope to have one that doesnt break, and to start with ext4, cause its the easiest to repair...\n[...]\n  \n\n    So in the end I read, use ext4 or XFS on a single disk but have 2 offline backups offsite.\n  \n\n    Whats your verdict? My server is as follows:\n  \n\n    64GB registered ECC RAM (single bit correction)\nIntel i3-9100\n10x20TB HDD installed - 10 slots empty\n2x2TB SSD\nSuperMicro X11SCL-F Motherboard\n  \n\n    My Data is unique in the sense of that I put lots of time in it, and that I would not want to re-do all that stuff at any given point."},
{"Title": "WD passport transfer speed accurate?", "Author": "u/bananamuffinsareyum", "Content": "Hi, I’m transferring files from a Samsung T7 ssd to my WD passport HDD through davinci resolve clone tool. 1 TB of 6k Blackmagic video footage.\n  \n\n    It’s taking about 10-12 hours estimated. Is this normal? I feel like my Lacie did transfers faster back when I used it. Wondering if anyone else has been in same situation."},
{"Title": "Anyone have a clean workflow for automating youtube channels to emby?", "Author": "u/theresmorethan42", "Content": "There are bits and kinda jumbled together things all over the place, bur does anyone know of a tool that just does the thing? ie. I feed it a list of channels/playlists and it dumps the right metadata/.nfo to feed emby properly?"},
{"Title": "Can I Use a Surveillance HDD as a nas hdd?", "Author": "u/osrott", "Content": "Hey, I'm looking for a new nas hdds for my  ds215+. Can I safely use a Surveillance HDD?"},
{"Title": "Is DiskGenius a good tool to check refurbished HDDs?", "Author": "u/Ok_Fish285", "Content": "No content"},
{"Title": "MEGA sending data while downloading", "Author": "u/CorgiFun1874", "Content": "Hi everyone !\n  \n\n    I'm making a local backup of files I store on MEGA servers, using their MEGAsync software. But turns out after downloading 7 GB of data, it uploaded 350 MB, and it keeps growing.\n  \n\n    I couldn't find any information about it. What does MEGA send when downloading ? Signatures and tracking files are no way that heavy !"},
{"Title": "I *feel* like I've been adding less and less to my server as the 'old media I want to collect runs out, and it becomes only a trickle of new media', but my spreadsheet tells me that it's all in my head...", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Questions on magnetic tape for storage (Now that prices have changed, apparently)", "Author": "u/Alemismun", "Content": "Yesterday I saw some article about how magnetic tape was much cheaper per TB than hard disks (and you could drop them like SSDs, which is always nice), and this has made me consider if I should perhaps switch...\n  \n\n    But its really hard to get any reliable info on the matter, which is why Im making this post.\n  \n\n\n\n\n\n    Is magnetic tape actually cheaper? Some older reddit posts say that this is not the case (and indeed, the latest LTO tape is much more expensive per TB than a hard drive), but at the same time, random websites on the internet seem to pitch some wild prices, \nsuch as this one\n (or the same one from \nanother site\n) (or the same one \nfrom amazon\n, wait wtf why are all the cheap ones the same model), which comes at about 6 bucks per terabyte of data. This is way better than even a used hard drive.\n  \n\n\n\n\n\n    Are there any hidden costs or technical issues that one could expect? Or does it just behave like a hard drive but with much lower speeds? Do they wear out or are they expected to last more than hard drives? Is there any issue with buying used?\n  \n\n\n\n\n\n    Is it even possible to encrypt this data (in particular with Veracrypt)? This is kind of a dealbreaker for me otherwise, as I greatly value data security.\n  \n\n\n\n\n\n    I generally store lots of random data across many folders, in the form of a digital library. Generally books/films by category. Plus random family pictures and work documents here and there.\nSpeed is not much of a concern, nor is having the storage cold. My hard drives usually take all night to sync, then they stay disconnected until needed again."},
{"Title": "Are there any legit m-disks currently for sale?", "Author": "u/Gwyn777", "Content": "Of course I see the ones on amazon, but they look sketchy. After hearing of disks being labeled as m-disc but not truly them, I am skeptical."},
{"Title": "S3 Glacier Deep Archive VS Backblaze B2", "Author": "u/Ryhaph99", "Content": "I chose B2 because, although I might be able to save some money with glacier deep archive, AWS pricing is so confusing that I feel like I'm gonna fuck it up and owe them a ton of money. B2 was much easier to understand and say let's go.\n  \n\n    Is AWS intentionally making it confusing or is that just how they are able to make it cheap in specific use cases? Am I just dense? B2 has been great so far but ultimately I'd rather be paying $0.6/TB/month than $6/TB/month for my offsite backups.\n  \n\n    I'm also considering the \"at a friend's house\" solution. Maybe there are even co-lo facilities for this kinda thing that could be competitive in my area. I'm more curious about cloud solutions than guerilla solutions though, so please let me know if you have any insight.\n  \n\n    TL;DR: most cost effective cloud solution for data hoarding is desired, do you have it?"},
{"Title": "Scanning trifolded statements", "Author": "u/briko3", "Content": "I have many sets of client statements that run about 20 pages front and back and were trifolded into an envelope. I have an Epson 410 scanner and no matter how much I try to flatten these statements, it can never reliably feed one page at a time. It always ends up clumping several together throughout the scan, which has been frustrating.\n  \n\n    So my question is, does anyone know of a scanner that does well in these kinds of circumstances? Thanks"},
{"Title": "Soundcloud Database", "Author": "u/yonah_xy", "Content": "hello, new here.\n  \n\n    I’m a HUGE fan of this soundcloud artist 9TAILS. I’m looking into archiving him just in case and i’m aiming at OG files, so the wavs. I was hoping someome here could help me out or someone who has access to it. It’s a lot but i’m just a fan!"},
{"Title": "Recommended fans for Norco 4220 (4U, 20 HDD bays) case? (re: 80mm fans)", "Author": "u/sofakng", "Content": "I've been using a Norco 4220 case for quite a while but I think it's time to replace the fans.\n  \n\n    Behind the 20-bay HDDs are 4x \nDelta AFB0812H\n fans.  They are loud, which is fine for now but it would be nice to get something quieter if I need to move the server.\n  \n\n    There are also two empty rear fans (80mm) that I would like to populate.\n  \n\n    I was thinking about buying 4x \nArtic P8 Max\n (HDD bays) and 2x \nArtic P8 PWM\n (rear case).  Would this be a good choice or does anybody have any other recommendations?"},
{"Title": "M3 Pro Mac External SSD pauses/freezes", "Author": "u/mishrah10", "Content": "I recently purchased an internal ssd and combined it with an enclosure to make it external ssd. Now on my personal M3 Pro Macbook the ssd just pauses, the light blinks on enclosure but no read or write. On BlackMagic the speed comes as 0. But after couple of minutes it starts writing at full speed. So basically it is 0 then 950 MBPS then again 0. Mostly its 0. But on my office Intel Mac it is constantly 950MBPS I don’t know what settings to change. Note the ssd is formatted to AFPS. Thanks\n  \n\n    Upvote1Downvote0comments0 awardsShare"},
{"Title": "Building a fileserver", "Author": "u/MrMaxxExcaliber", "Content": "I just bought a Poweredge T320 and plan to add 6 disks for data storage (photos) probably in RAID5. Specs: Dell PowerEdge T320 Xeon E5-1410 2.80GHz 16GB RAM Tower Server No HDD My thought was to use two x 3Tb disks for the OS, in RAID1. The server (allegedly) has the RAID controller included.. Is this doable? Can I have two separate RAID filesystems?"},
{"Title": "Stop LSI sleeping Win11", "Author": "u/cowrevengeJP", "Content": "Is there a way to stop the LSI card from sleeping with the rest of the OS? I don't want the drives to keep spinning, but the PC crashes after sleeping. Doesn't happen if I use the onboard raid instead only, as it just waits a few seconds to spin up again.\n  \n\n    I have 8 drives, so I can't use board only.\n  \n\n    The card is a Dell/HP LSI I bought on Mercari and flashed to unlock RAID."},
{"Title": "backup formats to increasing recovery chances from hardware corruption?", "Author": "u/IcyCheetah3568", "Content": "What type of password protected file/folder backup format, or method, is good to increase recovery chances (not breaking the whole backup) from hardware corruption or from file transfer corruption (from one storage to another or copying/moving backups within an OS). I understand that the condition of the hardware is very important but I want to see what we can do on software level to at least have some better chances at recovery when something happens.\n  \n\n    Using RAR archives with recovery records? Does compression settings matter? Store, Fastest, Best, etc.\n  \n\n    Whole disk encryption on the backup drive? (Or a partition to also have easy access to other files)\n  \n\n    Is there any reason to use a backup program for this purpose? They also put all files into one single file, with or without compression, is it any different than a rar/7zip/zip file? Maybe something about processing metadata and chances of recovery?"},
{"Title": "New HDDs running +8° acceptable?", "Author": "u/BigFatRusski", "Content": "So I swapped my 2 bay synology drives from WD red to WD101EDBZ, an upgrade of 2tb on raid1. My WD red was running at cool 37°, new drive is at 45°. This is the newer model EDBZ, and not helium filled. Also, my nas warned me that this model drive is not on compatibility list… message received and ignored. I’ve had very good experience with Red drives, is +8° still considered reliable long run? I usually swap drives every 2-3 years.\n  \n\n    Edit: second EDBZ drive with same firmware is running at 41°🤷‍♂️"},
{"Title": "Toshiba PC P300 usage failure", "Author": "u/Ghosteen_18", "Content": "No content"},
{"Title": "Checksum verification - Blake2B / 3 or SHA512?", "Author": "u/manzurfahim", "Content": "Hello everyone,\n  \n\n    Hope you are well.\n  \n\n    I am thinking of doing a checksum verification between the source files and the files on backup drives.  Quickhash seems like a nice little utility to do that. It has multiple algorithms: MD5, SHA-1, SHA-3, SHA256, SHA512, xxHash64, Blake2B, Blake3 and CRC32.\n  \n\n    Did a little googling and it seems like SHA512 and Blake2B / 3 are the best ones, but I'm only going to choose one and wondering if you use any of them or checksum and which should I use. I could use some advise.\n  \n\n    Many thanks in advance.\n  \nhttps://preview.redd.it/checksum-verification-blake2b-3-or-sha512-v0-495hfvgnj34d1.jpg"},
{"Title": "Most efficient way of converting terabytes of h.264 to h.265?", "Author": "u/X2ytUniverse", "Content": "Over the last few years I've done quite a bit of wedding photography and videography, and have quite a lot of footage. As a rule of thumb, I keep footage for 5 years, in case people need some additonal stuff, photos or videos later (happened only like 3 times ever, but still).\nFor quite some time i've been using OM-D E-M5 Mark III, which as far as I know can only record with h.264. (at least thats what we've always recorded in), and only switched to h.265/hevc camera quite recently. Problem is, I've got terabytes of old h.264 files left over, and space is becoming an issue., there's only so many drives I can store safely and/or connect to computer.\nWhat I'd like is to convert h.264 files to h.265, which would save me terabytes of space, but all the solutions I've found by researching so far include very small amount of files being converted, and even then it takes quite some time.\nWhat I've got is ~3520 video files in h.264, around 9 terabytes total space.\nWhat would be the best way to convert all of that into h.265?"},
{"Title": "Next Step from WD Black 4TB?", "Author": "u/Hawthm_the_Coward", "Content": "Hello! I've been using a home setup with a 1 TB SSD and an older model WD Black 4 TB HDD for some time now. It's done a good job, but lately, I've been annoyed with the HDD's capabilities... It's fairly noisy despite being in a quieting enclosure, and the 4 TB capacity is pretty close to being filled up.\n  \n\n    So, here are some considerations I have.\n  \n\n\n\n\n\n    The replacement absolutely must be 7200 RPM, and a similar performance. Applications regularly load from this drive so a 5400 RPM drive is not an option. No matter what, this has to hold true.\n  \n\n\n\n\n\n    A quieter drive without losing capacity would be very nice. I'd be alright swapping for something like a 4 TB Blue if it was comparable.\n  \n\n\n\n\n\n    Alternatively, a size upgrade would also be great. I've heard the Exos X18 16 TB is good and also pretty fast. How much worse would the noise be compared to the Black?\n  \n\n\n\n\n\n    If possible, a slight upgrade to both would be wonderful. Would an HGST He8 6TB be quieter, too?\n  \n\n\n\n\n\n    Just trying to weigh my options, and any and all insights would be much appreciated!"},
{"Title": "Mirroring and also Frequency of Cold Storage Backups", "Author": "u/ngs428", "Content": "In my current situation I have about 4.5TB of media I am backing up on my home PC.  The contents of the existing media changes daily as I add, change and delete content.\n  \n\n    I have been doing a cold storage backup, but that only seems to happen every 3 months or so at best.  Over those 3 months there was a lot of time spent on revising the original media, I would hate to lose that.\n  \n\n    I understand that Mirroring is not considered a true backup, but it certainly is a backup in the case of a drive failure, which is what I am most concerned about.\n  \n\n    Thoughts or comments on mirroring and frequency of cold storage backups?  I feel like employing both is a good strategy."},
{"Title": "Archiving Jobs on a Mac. Any alternatives to Retrospect?", "Author": "u/blunderbot", "Content": "Just wondering if there's another way to archive my largish projects on a Mac. I'm about to upgrade the computer that handles this work (probably to a Mac Mini M2) so now is a good time to weigh my options.\n  \n\n    Jobs range from 5-20TB, each job is in its own folder that is then archived to a collective Media Set. At the moment, the archives are kept on hard drives that I keep offline.\n  \n\n    The best feature for me is that I can search the Media Set for the offline files I want to restore and easily grab just those files. I need to do this for less than 5% of my jobs so it's great when it works, but not worth spending $ on solutions with ongoing costs.\n  \n\n    But retrospect occasionally needs to rebuild the catalog which significantly slows down the process. I also have a mild concern that the archive format is not plainly readable."},
{"Title": "RAID 0 on 980 NVME 4x4 Drive?", "Author": "u/Administrative-Air73", "Content": "Simple problem - I got a 2TB SAMSUNG 980 PRO Gen 4 NVME SDD for my C-Drive filled with programs and Unreal Environments that I need to expand. My options are to buy a 4TB Drive for $320 or buy another 2TB for $169; considering my bank is already breaking along side my PC I was considering using RAID 0 as a solution, temporarily backing my OS to another drive in the meantime. Is this practical?"},
{"Title": "Issues Finding Duplicates with Czkawka on Unraid", "Author": "u/klnadler", "Content": "I’m in the process of cleaning up my massive photo library and have been using exiftool to sort everything. I have a small folder of photos that a lot are found within a much larger folder of photos I’m trying to delete out. I used Czkawka to find the duplicates by having both folders as a source and it found a lot of the matches but it’s still missing many and none of the other options (different hashes, file size, name) don’t produce the correct results. Any help on what to do?"},
{"Title": "any way to fix my HDD?", "Author": "u/greetings__mortal", "Content": "I have this old Toshiba 1TB hdd that I had salvaged from a laptop a few years back. It travels with me a lot and I often share it with others, which means it has been through quite some unintentional abuse. But recently it stated acting up. it would keep freezing on windows. I managed to recover the important data using Linux where it froze once in a while but worked significantly better and after the recovery i formatted the HDD in hopes of fixing it. But It was of no use since now it just freezes after a few seconds of me trying to transfer a large file to it. I ran HDDscan and it is filled with bad blocks. Is there any way to fix it? or is it dead?"},
{"Title": "How do i get back files i changed it a folder because they had the same name?", "Author": "u/NokiaTheReuploader", "Content": "i needed to send something some archives to my friend and when i downloaded more of them i forgot to change the old files name and when i clicked ''change it the folder'' the old files dissapeared, how can i retrieve them?"},
{"Title": "What DIY DAS Case", "Author": "u/BurgerQuester", "Content": "I’m looking to build a DAS to add storage to my unraid server.\n  \n\n    I’ve got an optiplex 5050 as the ‘server’ for now with an m2 drive, and 2 sata connection ports.\n  \n\n    The plan is to get a pcie expansion card to add more sata ports to the optiplex and add drives as and when I need them.\n  \n\n    What case would you use for this?\n  \n\n    Or is my idea a bad one?"},
{"Title": "H.264 vs MPEG2", "Author": "u/mro2352", "Content": "I have seen that my Plex server has been transcoding my mkv files which have mpeg2 encoding to h.264. What are the pros and cons of h.264 over mpeg2? I want to preserve the subtitles as a general rule and want to keep my collection in a single data format."},
{"Title": "Does 9400-16i HBA require PCIe 3.1?", "Author": "u/sofakng", "Content": "I'm looking to upgrade my possibly defective 9211-8i (x2) to a 9400-16i but the 9400-16i lists PCIe 3.1.\n  \n\n    My motherboard is a SuperMicro X9DR3-F which only supports PCIe 3.0.\n  \n\n    Will this be compatible?  For some reason the 9305-16i cards are more expensive (but they only require PCIe 3.0) ..."},
{"Title": "Best way to grab FB videos in highest quality in June 2024?", "Author": "u/rubbishfairy", "Content": "Hey guys I know there is a lot of info about this out there already but it seems to go out of date quickly and a lot of it just seems to be wrong. So I'm hoping there's some proper experts in this sub.\n  \n\n    Firstly I know there are various browser plugins. I got one called \"video download helper\" especially for the task but it just doesn't work with FB. I'm also a fan of Jdownloader but again that doesn't work with FB.\n  \n\n    Secondly I know you can switch \"www\" for \"mbasic\" and find the actual URLs of videos. You can then download them but ONLY it seems in the lowest possible quality. I suspect the URL just needs to be changed slightly to give me the high quality but I don't know how.\n  \n\n    What do you guys suggest?"},
{"Title": "\"Autocare Depot\"?", "Author": "u/joetaxpayer", "Content": "I've remarked that drives seem to have crept back up in price. The Toshiba Enterprise 16TB I bought for $220 2 years ago is far higher today.\n  \n\n    I just got a camel alert for this drive at $250, which is far better than the $290 I've seen. But. the vendor is \"Autocare Depot\". I look them up and it says \"Autocaredepot, a subsidiary of e-commerce giant \nNewegg.com\n, is a fast growing online retailer.\"\n  \n\n    Looking for feedback on this company before i make the purchase. Newegg, but they seem to have an odd mix of stuff. Not sure what i'm dealing with here."},
{"Title": "Internet Archive", "Author": "u/Specialist-Pause9394", "Content": "There needs to be a indexed search engine at the Internet Archive. It's time consuming to put in the URLs of a webpage. I wish there was a way for the Internet Archive to search every webpage in the archives and indexed it like Google does for the live web."},
{"Title": "Do I need to worry about the data safety?", "Author": "u/johnqhu", "Content": "Hi Guys,\n  \n\n    A newbie question here.\n  \n\n    I have a 1618+ with raid6 array and 6 disks. One of them was broken today. In fact it's quite weird. The broken one is less than 1 month old. It's a WD red pro 18TB. I bought it from Amazon. Amazon agreed to send me a brand new replacement. But I need to return the broken one.\n  \n\n    So my question is: do I need to worry about the data safety? I know raid6 can only tolerate 2 disks failure. But some software claim be able to recover some information when even 3 disk failed. So I just wondering whether anyone can get some useful data from just 1 disk? Whether is it 0 risk or still some risk to send a disk of raid6 to others without erasing data? On my side, I cannot erase it because it even cannot be found when i put it into my PC.\n  \n\n    Regards,"},
{"Title": "Downloading Instagram Likes?", "Author": "u/Monitichello", "Content": "Anyone know how I can download my likes from instagram? Looking to store full videos and images rather than just links to posts."},
{"Title": "My ears are bleeding", "Author": "u/ElonTastical", "Content": "No content"},
{"Title": "Incremental M-DISK backups and drive choice", "Author": "u/ReactCereals", "Content": "Hello, so I have decided to revise my current backup strategy and opt for using off site M-DISK backups.\n  \n\n    However, there are still two things I can't figure out (or find recent opinions about at least).\n  \n\n    My first issue is choosing an internal burner to buy. Currently I only have an array of old DVD drives to batch rip old DVDs and no experience regarding bluray/M-DISK. I feel like I can only find product recommendations that are quite a few years old and it feels like one year people tend to recommend pioneer over everything else and another year its only LG and the year after pioneer again and so on...\n  \n\n    On top I can't figure out what to even watch out for. For example the currently available Pioneer drives BDR-S12XLT, BDR-213EBK, BDR-S13EBK, etc. all offer the same compatibility, same write speeds, same read speeds, and according as to how I read their product page the exact same features. Is there even something in a technical data sheet I can use to judge whether one drive might be more reliable for my use case than the other? What drives do you use/recommend in 2024 and why?\n  \n\n    My base line requirement is just burning M-DISKs (single/dual layer) and occasionally ripping a Blu-ray. Linux support would be highly appreciated but I can fall back to a windows system I have to keep running for other legacy scanning software anyways.\n  \n\n    For backing up old collections of media which won't change I guess how to do it is pretty straight forward. However, I'd also like to backup folders that like to change and grow like my document folders. These changing folders by far do not even come close to fill up the capacity of any M-DISK as of now. So I'd like to regularly keep burning info about recent changes/new files only on the same disk to not waste e.g. a 25 GB disk every time I backup a 3 GB folder. I originally intended to write a few small scripts that would keep track of changes/new files since last backup and manage versioning for writing/restoring those. However, I feel like reinventing the wheel here but can't really find the software I am looking for. Any simple and open source software recommendations there?\n  \n\n    Thanks for your input!"},
{"Title": "Linus Media Group is working on digitizing the Reboot master tapes; they already have the DCR-300/DCR-500 VTR machines to play them back, but they need documentation and/or experts to sort out hardware issues", "Author": "u/Alt230s", "Content": "No content"},
{"Title": "12 years worth of posts getting deleted...", "Author": "u/moonronic", "Content": "Hi there, I am not massively tech literate nor sure of where to go or who to ask about this, but I have this website I've been using for 12 years called Quotev, recently, they took out the social feed where you could see other people's posts, now it's hard to find your friends on there and such from years passed. It says they are deleting all messages on July 1st, and I was hoping if anybody knows an easy method to archive all my posts on the website? the activity page is the main part i'd want to save; it's \nhttps://www.quotev.com/(username)/activity"},
{"Title": "VHSC To digital backup", "Author": "u/EngineeringGlum5318", "Content": "Hello everyone, as my title suggests I have a bunch of old VHS compact that I’m looking to digitize.\n  \n\n    Just trying to figure out how to best go about digitizing with the right equipment for decent quality.\n  \n\n    Any suggestions / help is welcome!"},
{"Title": "Syncing To Sd Cards using FreeFileSync", "Author": "u/MachineThatGoesP1ng", "Content": "I'm assuming some of you guys use Freefilesync and i was wondering if anyone can help me with syncing files on automation to a specific Sd card. The problem I'm having is that when i put in the Sd card as the destination folder FFS only recognizes the D: drive and doesn't consider the Sd unique, so if i put in a different Sd card it still tried to sync into that drive. Im sure the Sd has a unique ID somewhere, is there a way for FFS to recognize and use that as a destination and how do i obtain the unique ID?"},
{"Title": "Data Strategy Review: Is my approach good?", "Author": "u/Distinct-Yoghurt5665", "Content": "I really hope it's ok to ask this. From the rules and the wiki it does seem ok, but I'm new to this sub.\n  \n\n\n\n    So currently I have two external SSDs for my home server. I'm using SSD_A to save all my stuff to it and SSD_B as a backup.\n  \n\n\n\n    Now in the near future my SSD_A will be full. So I want to do the following: I want to buy a very large HDD use that as a backup and then use the two SSDs as my standard mounts for the home server to save stuff to.\n  \n\n\n\n\nIdeas\n\n\n\n\n\n\n\n    I could use \nmergerfs\n to combine both external SSDs to one mount point. I need to to this for some of my applications.\n  \n\n\n\n\n\n    I could then use \nrsync\n to create my backups from the SSD-mergerfs-mount to the HDD.\n  \n\n\n\n\n\n    Hopefully there is an \nrsync flag to indicate that I do not want to sync already existing data\n again (even if it changed). This ensures that broken files will not overwrite healthy files on the HDD. Yes, I know that this means that changes to files won't be backed up but this is ok for my use case.\n  \n\n\n\n\n\n    I could use \next4\n for all drives, cause there is no reason not to and I do not know anything else.\n  \n\n\n\n\n\n\n\n    What do the experts think? Does that sound like a good approach? Could anything go wrong? I do not care about write speed to the SSDs they are fast enough I do not need striping. I also do not care if some data gets lost between the back up cycles so I do not need RAID.\n  \n\n    Is mergerfs the best there is and is it easy to set up?\n  \n\n    Should I use anything else then ext4? ext4 has always been my go to and I do not really see anything wrong with it. File hashes seem to be unnecessary cause I can just not overwrite existing files, that seems to do the trick for my use case.\n  \n\n\n\n    Very much appreciate any feedback on my plan."},
{"Title": "Thoughts on digitizing strangers’ home videos?", "Author": "u/RelaxRelapse", "Content": "I often buy used VHS-C and Video8 tapes from Japan, both because they tend to be cheap and also because often times people in Japan used it to make personal copies of TV shows using those formats. Plus it’s cheaper than shipping full sized VHS tapes.\n  \n\n    Unsurprisingly I’ll find home videos in the lots I buy. A part of me feels obligated to make digital copies since they’re someone’s memories, and also a time capsule of that period of time. Another part of me feels I shouldn’t because they are someone’s personal recording that I assume they had no plans to show outside of their homes. And then again, what do I even do with the digital copies if I do make them besides hoard them? I legally couldn’t share them most likely. I wouldn’t mind digitizing a copy and sending it to the original owner, but since it’s just a random lot online from a resale shop, there’s nothing really to go off of.\n  \n\n    I’ve found NSFW content as well, but the choice with that stuff is obvious and I just erase them. The normal, everyday stuff though I’m unsure about. I think I just want to get a second opinion before I proceed."},
{"Title": "Do you guys think there's interest in things like this being scanned and preserved? 70s Pamphlets (gardening, cooking, random health stuff like self breast exams and mongolism)", "Author": "u/Quirky_Ad_69", "Content": "No content"},
{"Title": "Is anyone happy with iDrive?", "Author": "u/Jack15911", "Content": "This is an honest question because most people who are happy with their service don't write about it.\n  \n\n    I currently use external drives to swap between the home safe and the safety deposit box, but want to add  personal backup data into the cloud so I can cut down on external backup drives (individual drives, not NAS).\n  \n\n    Most reviews on the web rank iDrive pretty highly, while mostly I see unhappiness on Reddit. Does iDrive work mostly or does it not?"},
{"Title": "Next Step from WD Black 4TB?", "Author": "u/Hawthm_the_Coward", "Content": "Hello! I've been using a home setup with a 1 TB SSD and an older model WD Black 4 TB HDD for some time now. It's done a good job, but lately, I've been annoyed with the HDD's capabilities... It's fairly noisy despite being in a quieting enclosure, and the 4 TB capacity is pretty close to being filled up.\n  \n\n    So, here are some considerations I have.\n  \n\n\n\n\n\n    The replacement absolutely must be 7200 RPM, and a similar performance. Applications regularly load from this drive so a 5400 RPM drive is not an option. No matter what, this has to hold true.\n  \n\n\n\n\n\n    A quieter drive without losing capacity would be very nice. I'd be alright swapping for something like a 4 TB Blue if it was comparable.\n  \n\n\n\n\n\n    Alternatively, a size upgrade would also be great. I've heard the Exos X18 16 TB is good and also pretty fast. How much worse would the noise be compared to the Black?\n  \n\n\n\n\n\n    If possible, a slight upgrade to both would be wonderful. Would an HGST He8 6TB be quieter, too?\n  \n\n\n\n\n\n    Just trying to weigh my options, and any and all insights would be much appreciated!"},
{"Title": "Mirroring and also Frequency of Cold Storage Backups", "Author": "u/ngs428", "Content": "In my current situation I have about 4.5TB of media I am backing up on my home PC.  The contents of the existing media changes daily as I add, change and delete content.\n  \n\n    I have been doing a cold storage backup, but that only seems to happen every 3 months or so at best.  Over those 3 months there was a lot of time spent on revising the original media, I would hate to lose that.\n  \n\n    I understand that Mirroring is not considered a true backup, but it certainly is a backup in the case of a drive failure, which is what I am most concerned about.\n  \n\n    Thoughts or comments on mirroring and frequency of cold storage backups?  I feel like employing both is a good strategy."},
{"Title": "Archiving Jobs on a Mac. Any alternatives to Retrospect?", "Author": "u/blunderbot", "Content": "Just wondering if there's another way to archive my largish projects on a Mac. I'm about to upgrade the computer that handles this work (probably to a Mac Mini M2) so now is a good time to weigh my options.\n  \n\n    Jobs range from 5-20TB, each job is in its own folder that is then archived to a collective Media Set. At the moment, the archives are kept on hard drives that I keep offline.\n  \n\n    The best feature for me is that I can search the Media Set for the offline files I want to restore and easily grab just those files. I need to do this for less than 5% of my jobs so it's great when it works, but not worth spending $ on solutions with ongoing costs.\n  \n\n    But retrospect occasionally needs to rebuild the catalog which significantly slows down the process. I also have a mild concern that the archive format is not plainly readable."},
{"Title": "RAID 0 on 980 NVME 4x4 Drive?", "Author": "u/Administrative-Air73", "Content": "Simple problem - I got a 2TB SAMSUNG 980 PRO Gen 4 NVME SDD for my C-Drive filled with programs and Unreal Environments that I need to expand. My options are to buy a 4TB Drive for $320 or buy another 2TB for $169; considering my bank is already breaking along side my PC I was considering using RAID 0 as a solution, temporarily backing my OS to another drive in the meantime. Is this practical?"},
{"Title": "Issues Finding Duplicates with Czkawka on Unraid", "Author": "u/klnadler", "Content": "I’m in the process of cleaning up my massive photo library and have been using exiftool to sort everything. I have a small folder of photos that a lot are found within a much larger folder of photos I’m trying to delete out. I used Czkawka to find the duplicates by having both folders as a source and it found a lot of the matches but it’s still missing many and none of the other options (different hashes, file size, name) don’t produce the correct results. Any help on what to do?"},
{"Title": "any way to fix my HDD?", "Author": "u/greetings__mortal", "Content": "I have this old Toshiba 1TB hdd that I had salvaged from a laptop a few years back. It travels with me a lot and I often share it with others, which means it has been through quite some unintentional abuse. But recently it stated acting up. it would keep freezing on windows. I managed to recover the important data using Linux where it froze once in a while but worked significantly better and after the recovery i formatted the HDD in hopes of fixing it. But It was of no use since now it just freezes after a few seconds of me trying to transfer a large file to it. I ran HDDscan and it is filled with bad blocks. Is there any way to fix it? or is it dead?"},
{"Title": "How do i get back files i changed it a folder because they had the same name?", "Author": "u/NokiaTheReuploader", "Content": "i needed to send something some archives to my friend and when i downloaded more of them i forgot to change the old files name and when i clicked ''change it the folder'' the old files dissapeared, how can i retrieve them?"},
{"Title": "What DIY DAS Case", "Author": "u/BurgerQuester", "Content": "I’m looking to build a DAS to add storage to my unraid server.\n  \n\n    I’ve got an optiplex 5050 as the ‘server’ for now with an m2 drive, and 2 sata connection ports.\n  \n\n    The plan is to get a pcie expansion card to add more sata ports to the optiplex and add drives as and when I need them.\n  \n\n    What case would you use for this?\n  \n\n    Or is my idea a bad one?"},
{"Title": "H.264 vs MPEG2", "Author": "u/mro2352", "Content": "I have seen that my Plex server has been transcoding my mkv files which have mpeg2 encoding to h.264. What are the pros and cons of h.264 over mpeg2? I want to preserve the subtitles as a general rule and want to keep my collection in a single data format."},
{"Title": "Does 9400-16i HBA require PCIe 3.1?", "Author": "u/sofakng", "Content": "I'm looking to upgrade my possibly defective 9211-8i (x2) to a 9400-16i but the 9400-16i lists PCIe 3.1.\n  \n\n    My motherboard is a SuperMicro X9DR3-F which only supports PCIe 3.0.\n  \n\n    Will this be compatible?  For some reason the 9305-16i cards are more expensive (but they only require PCIe 3.0) ..."},
{"Title": "Best way to grab FB videos in highest quality in June 2024?", "Author": "u/rubbishfairy", "Content": "Hey guys I know there is a lot of info about this out there already but it seems to go out of date quickly and a lot of it just seems to be wrong. So I'm hoping there's some proper experts in this sub.\n  \n\n    Firstly I know there are various browser plugins. I got one called \"video download helper\" especially for the task but it just doesn't work with FB. I'm also a fan of Jdownloader but again that doesn't work with FB.\n  \n\n    Secondly I know you can switch \"www\" for \"mbasic\" and find the actual URLs of videos. You can then download them but ONLY it seems in the lowest possible quality. I suspect the URL just needs to be changed slightly to give me the high quality but I don't know how.\n  \n\n    What do you guys suggest?"},
{"Title": "\"Autocare Depot\"?", "Author": "u/joetaxpayer", "Content": "I've remarked that drives seem to have crept back up in price. The Toshiba Enterprise 16TB I bought for $220 2 years ago is far higher today.\n  \n\n    I just got a camel alert for this drive at $250, which is far better than the $290 I've seen. But. the vendor is \"Autocare Depot\". I look them up and it says \"Autocaredepot, a subsidiary of e-commerce giant \nNewegg.com\n, is a fast growing online retailer.\"\n  \n\n    Looking for feedback on this company before i make the purchase. Newegg, but they seem to have an odd mix of stuff. Not sure what i'm dealing with here."},
{"Title": "Internet Archive", "Author": "u/Specialist-Pause9394", "Content": "There needs to be a indexed search engine at the Internet Archive. It's time consuming to put in the URLs of a webpage. I wish there was a way for the Internet Archive to search every webpage in the archives and indexed it like Google does for the live web."},
{"Title": "Do I need to worry about the data safety?", "Author": "u/johnqhu", "Content": "Hi Guys,\n  \n\n    A newbie question here.\n  \n\n    I have a 1618+ with raid6 array and 6 disks. One of them was broken today. In fact it's quite weird. The broken one is less than 1 month old. It's a WD red pro 18TB. I bought it from Amazon. Amazon agreed to send me a brand new replacement. But I need to return the broken one.\n  \n\n    So my question is: do I need to worry about the data safety? I know raid6 can only tolerate 2 disks failure. But some software claim be able to recover some information when even 3 disk failed. So I just wondering whether anyone can get some useful data from just 1 disk? Whether is it 0 risk or still some risk to send a disk of raid6 to others without erasing data? On my side, I cannot erase it because it even cannot be found when i put it into my PC.\n  \n\n    Regards,"},
{"Title": "Downloading Instagram Likes?", "Author": "u/Monitichello", "Content": "Anyone know how I can download my likes from instagram? Looking to store full videos and images rather than just links to posts."},
{"Title": "My ears are bleeding", "Author": "u/ElonTastical", "Content": "No content"},
{"Title": "Incremental M-DISK backups and drive choice", "Author": "u/ReactCereals", "Content": "Hello, so I have decided to revise my current backup strategy and opt for using off site M-DISK backups.\n  \n\n    However, there are still two things I can't figure out (or find recent opinions about at least).\n  \n\n    My first issue is choosing an internal burner to buy. Currently I only have an array of old DVD drives to batch rip old DVDs and no experience regarding bluray/M-DISK. I feel like I can only find product recommendations that are quite a few years old and it feels like one year people tend to recommend pioneer over everything else and another year its only LG and the year after pioneer again and so on...\n  \n\n    On top I can't figure out what to even watch out for. For example the currently available Pioneer drives BDR-S12XLT, BDR-213EBK, BDR-S13EBK, etc. all offer the same compatibility, same write speeds, same read speeds, and according as to how I read their product page the exact same features. Is there even something in a technical data sheet I can use to judge whether one drive might be more reliable for my use case than the other? What drives do you use/recommend in 2024 and why?\n  \n\n    My base line requirement is just burning M-DISKs (single/dual layer) and occasionally ripping a Blu-ray. Linux support would be highly appreciated but I can fall back to a windows system I have to keep running for other legacy scanning software anyways.\n  \n\n    For backing up old collections of media which won't change I guess how to do it is pretty straight forward. However, I'd also like to backup folders that like to change and grow like my document folders. These changing folders by far do not even come close to fill up the capacity of any M-DISK as of now. So I'd like to regularly keep burning info about recent changes/new files only on the same disk to not waste e.g. a 25 GB disk every time I backup a 3 GB folder. I originally intended to write a few small scripts that would keep track of changes/new files since last backup and manage versioning for writing/restoring those. However, I feel like reinventing the wheel here but can't really find the software I am looking for. Any simple and open source software recommendations there?\n  \n\n    Thanks for your input!"},
{"Title": "Linus Media Group is working on digitizing the Reboot master tapes; they already have the DCR-300/DCR-500 VTR machines to play them back, but they need documentation and/or experts to sort out hardware issues", "Author": "u/Alt230s", "Content": "No content"},
{"Title": "12 years worth of posts getting deleted...", "Author": "u/moonronic", "Content": "Hi there, I am not massively tech literate nor sure of where to go or who to ask about this, but I have this website I've been using for 12 years called Quotev, recently, they took out the social feed where you could see other people's posts, now it's hard to find your friends on there and such from years passed. It says they are deleting all messages on July 1st, and I was hoping if anybody knows an easy method to archive all my posts on the website? the activity page is the main part i'd want to save; it's \nhttps://www.quotev.com/(username)/activity"},
{"Title": "VHSC To digital backup", "Author": "u/EngineeringGlum5318", "Content": "Hello everyone, as my title suggests I have a bunch of old VHS compact that I’m looking to digitize.\n  \n\n    Just trying to figure out how to best go about digitizing with the right equipment for decent quality.\n  \n\n    Any suggestions / help is welcome!"},
{"Title": "Syncing To Sd Cards using FreeFileSync", "Author": "u/MachineThatGoesP1ng", "Content": "I'm assuming some of you guys use Freefilesync and i was wondering if anyone can help me with syncing files on automation to a specific Sd card. The problem I'm having is that when i put in the Sd card as the destination folder FFS only recognizes the D: drive and doesn't consider the Sd unique, so if i put in a different Sd card it still tried to sync into that drive. Im sure the Sd has a unique ID somewhere, is there a way for FFS to recognize and use that as a destination and how do i obtain the unique ID?"},
{"Title": "Data Strategy Review: Is my approach good?", "Author": "u/Distinct-Yoghurt5665", "Content": "I really hope it's ok to ask this. From the rules and the wiki it does seem ok, but I'm new to this sub.\n  \n\n\n\n    So currently I have two external SSDs for my home server. I'm using SSD_A to save all my stuff to it and SSD_B as a backup.\n  \n\n\n\n    Now in the near future my SSD_A will be full. So I want to do the following: I want to buy a very large HDD use that as a backup and then use the two SSDs as my standard mounts for the home server to save stuff to.\n  \n\n\n\n\nIdeas\n\n\n\n\n\n\n\n    I could use \nmergerfs\n to combine both external SSDs to one mount point. I need to to this for some of my applications.\n  \n\n\n\n\n\n    I could then use \nrsync\n to create my backups from the SSD-mergerfs-mount to the HDD.\n  \n\n\n\n\n\n    Hopefully there is an \nrsync flag to indicate that I do not want to sync already existing data\n again (even if it changed). This ensures that broken files will not overwrite healthy files on the HDD. Yes, I know that this means that changes to files won't be backed up but this is ok for my use case.\n  \n\n\n\n\n\n    I could use \next4\n for all drives, cause there is no reason not to and I do not know anything else.\n  \n\n\n\n\n\n\n\n    What do the experts think? Does that sound like a good approach? Could anything go wrong? I do not care about write speed to the SSDs they are fast enough I do not need striping. I also do not care if some data gets lost between the back up cycles so I do not need RAID.\n  \n\n    Is mergerfs the best there is and is it easy to set up?\n  \n\n    Should I use anything else then ext4? ext4 has always been my go to and I do not really see anything wrong with it. File hashes seem to be unnecessary cause I can just not overwrite existing files, that seems to do the trick for my use case.\n  \n\n\n\n    Very much appreciate any feedback on my plan."},
{"Title": "Thoughts on digitizing strangers’ home videos?", "Author": "u/RelaxRelapse", "Content": "I often buy used VHS-C and Video8 tapes from Japan, both because they tend to be cheap and also because often times people in Japan used it to make personal copies of TV shows using those formats. Plus it’s cheaper than shipping full sized VHS tapes.\n  \n\n    Unsurprisingly I’ll find home videos in the lots I buy. A part of me feels obligated to make digital copies since they’re someone’s memories, and also a time capsule of that period of time. Another part of me feels I shouldn’t because they are someone’s personal recording that I assume they had no plans to show outside of their homes. And then again, what do I even do with the digital copies if I do make them besides hoard them? I legally couldn’t share them most likely. I wouldn’t mind digitizing a copy and sending it to the original owner, but since it’s just a random lot online from a resale shop, there’s nothing really to go off of.\n  \n\n    I’ve found NSFW content as well, but the choice with that stuff is obvious and I just erase them. The normal, everyday stuff though I’m unsure about. I think I just want to get a second opinion before I proceed."},
{"Title": "Do you guys think there's interest in things like this being scanned and preserved? 70s Pamphlets (gardening, cooking, random health stuff like self breast exams and mongolism)", "Author": "u/Quirky_Ad_69", "Content": "No content"},
{"Title": "Is anyone happy with iDrive?", "Author": "u/Jack15911", "Content": "This is an honest question because most people who are happy with their service don't write about it.\n  \n\n    I currently use external drives to swap between the home safe and the safety deposit box, but want to add  personal backup data into the cloud so I can cut down on external backup drives (individual drives, not NAS).\n  \n\n    Most reviews on the web rank iDrive pretty highly, while mostly I see unhappiness on Reddit. Does iDrive work mostly or does it not?"},
{"Title": "Best deal on 20tb or 22tb drives from serverpartdeals?", "Author": "u/thegameksk", "Content": "Looking to upgrade my NAS storage. They will he used mainly for Plex, transmission, calibre and comics reading. Also how do I tell when serverpartdeals has a sale? Is it advertised somewhere?"},
{"Title": "Is SyncBack 11 Free the best free option for my situation?", "Author": "u/ngs428", "Content": "I have a W11 desktop PC with about 3TB of data consisting of family videos and pictures.  I currently have it on an 8TB internal HDD and once every 3 months do a copy to my external HDD and delete the old backup.\n  \n\n    Moving forward I am looking to have the external HDD connected to the PC 24/7 and monitor for changes in the source folders on the internal HDD and mirror those changes to the external HDD.  So if I delete something on the internal, it deletes from the external.  Add to the internal, it adds to the external.\n  \n\n    After some research of looks like SyncBack 11 will do this and is free.  I see Veeam mentioned quite a bit.  What is the best option out there for free or low cost?\n  \n\n    Edit: I see freefilesync may be an option. \nhttps://freefilesync.org/download.php\n\n\n\n    Thank you!"},
{"Title": "A data hoarding tool I really like for moving files around, backups, copying, etc", "Author": "u/LuckyRide", "Content": "As always, I don't work for them, but I really like the product.\n  \n\n    \"Synchronize Files and Folders\" => \nhttps://freefilesync.org\n\n\n\n    It's really just a copy program - pretty typical and standard. Except it does SUCH a good job.\n  \n\n    You can set up sessions that copies when you run them - so update, mirror, things like that, to arbitrarily complex sets of disks and files. I use it extensively for backups to always know my files are backed up. It needs to be kicked off manually, but it just works so well and I like monitoring the steps.\n  \n\n    Most especially, I move files around between diff folders (think picture sorting, etc) and it will figure that out and \"move\" the files versus \"always re-copy\". So it really speeds everything up.\n  \n\n    So really what I use it for is \"make sure every file is backed up properly\" - and it does it really well - it \"never gives up until success\" no matter what happens. You can just re-run and make sure it's \"all up to date\".\n  \n\n    It supports Windows, Mac, and I think linux - so same on all platforms. It's donation-ware - and I think there is some more features if you donate - but I don't remember since I donated since the very beginning.\n  \n\n    No other tool really does it as well - no Windows copy or anything like that gives me any confidence like this does."},
{"Title": "WD Passport Ultra on Mac: HFS+ vs NTFS with WD Driver", "Author": "u/DatasTemporalLobe", "Content": "Trying to get a WD Passport Ultra to work on a Mac in order to back up an iPhone.  I see the Western Digital app has an option to download a driver (Paragon) for NTFS.\n  \n\n    Is it better to download the driver and use NTFS or reformat to HFS+? I like that I'd be able to use the hard drive on a pc if I go with NTFS with the Paragon driver but am I losing any functionality on the Mac?"},
{"Title": "Most efficient method of syncing a primary drive to a back-up drive (MacOS)", "Author": "u/pipmike", "Content": "I could use advise on which syncing software to use for a Mac and two external hard drives.\n  \n\n    Scenario:\n  \n\n\n\n\n\n    I have one external hard drive as my primary \"hoard\" drive to which I actively add large files (1+ GB), move files to different folders, change file tags, etc.\n  \n\n\n\n\n\n    I have a second external hard drive that I use as my first-level disaster recovery in case my primary drive fails. The second drive is currently one-way synced to the primary hard drive using a rysnc script i wrote.\n  \n\n\n\n\n\n    I don't need to store changes or previous file versions. Just want to mirror one drive to another.\n  \n\n\n\n\n\n    While rsync gets the job done, it doesn't handle the above efficiently because any changes are seen as new files, which means it's constantly writing/re-writing large files to the secondary hard drive.\n  \n\n\n\n\n\n    If I change the name of a directory including 100+ GB of files, rather than just similarly rename the directory of the secondary hard drive, rsync will delete all of the files, create a new directory, and re-sync all of those files.\n  \n\n\n\n\n\n    If I rename a file, rysnc will delete the file and then rewrite it.\n  \n\n\n\n\n\n    If I add a MacOS file tag to the file, rysnc will delete the file and then rewrite it.\n  \n\n\n\n\n\n    Thus, if I make any directory changes or tags, rsync can take hours (even days) to re-sync. I can imagine that's not healthy on either drive.\n  \n\n    It would be great if MacOS had a native function that said \"if I do anything to Drive A, do the same thing to Drive B\", but I haven't found it if it exists. Thus, I'm looking at other options (Chronosync, Carbon Copy Cloner, etc.) that might be a better solution for my use case.\n  \n\n    Open for all suggestions or feedback."},
{"Title": "How to avoid wasting time encrypting twice? Need to encrypt eHDD and want to encrypt cloud storage. Can I encrypt in place?", "Author": "u/Snowblind45", "Content": "Hello, I’ve new this this stuff. I’m trying to improve my data hoarding habits.\n  \n\n    Currently I have 2 external HDD identical to each other (5 TB filled). I plan on also storing a copy on Blackblaze Cloud storage. I’ve heard that rclone can encrypt the files as it uploads them to the cloud, amazing! But what about encrypting the drive itself? Do I spend time using rclone to encrypt and upload, then encrypt the drive using maybe veracrypt? Is it possible to encrypt first using veracrypt then simply rclone upload those contents to the cloud?\n  \n\n    I’m feeling a bit confused about veracrypt since a tutorial makes it seem like I need to have free space to allocate a virtual partition to encrypt but I don’t have the extra space…is there a way to encrypt in place?"},
{"Title": "Diff Checker - to check whether backup folder contents match source folder?", "Author": "u/redexposure", "Content": "I'm wondering if anyone can recommend a type of \"Diff Checker\", for files and folders, to see whether backup drive/folder contents match the source folder (and highlight files which haven't been duplicated)?\n  \n\n    Essentially, the inverse of a Duplicate Finder.\n  \n\n    Does anyone know of any tools like this?"},
{"Title": "How to connect an LTO tape drive to a Synology NAS (DS1621+)", "Author": "u/CyclicRedundancyMach", "Content": "All,\n  \n\n    I am looking to cold-store about 25tb of video along with the normal user data.  We are full-time RVrs and the continuous movement increases the risk of a full crash, risking all of my data.  My wife would be less than pleased.  In an attempt for a happy marriage, I wanted to purchase a tape drive for simple cold backups.  I would do a full backup followed by an incremental every month or so, rotating them.  I'd also do a full data backup and mail the tape(s) to a friend for safe keeping.\n  \n\n    I am just not sure how to connect an LTO.  Suggestions?\n  \n\n\n\n\n\n    The NAS has USB, gigabit RJ45s (CAT6), and a USB, a PCIE expansion slot.\n  \n\n\n\n\n\n    All of the drives seem to have SAS connections.\n  \n\n\n\n\n\n    I honestly thought that this would be 15 minute no-brainer.   would have thought that this illustrious group of data-centric technocrats would have 15 fully documented methods.  Instead, there is nothing at all.\n  \n\n    I would appreciate your advice."},
{"Title": "RE: Tools for Bit-for-Bit / 1:1 Optical Media Preservation", "Author": "u/Archivist_Goals", "Content": "I wanted to create a separate post that further elaborates on what was mentioned in \nthis post's comments\n from others. And, I will tag the original post's author \nu/KeptinGL6\n:\n  \n\n    Just to clarify for everyone, MPF is the overall GUI.\n  \n\n    There are 3 main utilities from different people that are used in the Media Preservation Frontend program:\n  \n\n\n\n\n\n    Redumper\n  \n\n\n\n\n\n    AARU\n  \n\n\n\n\n\n    Disc Image Creator (DIC)\n  \n\n\n\n\n\n\nDIC is actively being phased out. Redumper is pretty much the gold standard right now. AARU is also very well developed. DIC's original developer sort-of abandoned it and it's regarded as a legacy dumper utility and will be phased out at some point.\n\n\n\n    Edit: Some clarification. The original developer behind DIC didn't abandon it. Redumper is being chosen over DIC where applicable and/or possible.\n  \n\n    These programs' inception originate to the \nRedump.org\n, Video Game Preservation Collective, Gaming Alexandria and Hit Save! organizations and communities where, through Discord, a ton of collaboration has taken hold for proactive media preservation, the world over. It's a very sizable, but niche community of dedicated people very much akin to the VHS Decode and Domesday Laser Disc duplicator projects.\n  \n\n    Links\nhttps://www.preservegames.org/\nhttps://www.gamingalexandria.com/wp/\nhttps://hitsave.org/\n\n\n\n    Discords\nhttps://discord.com/invite/AHTfxQV\nhttps://discord.com/invite/dQhd6d7\nhttps://discord.com/invite/TCKT6uA\n\n\n\n    The Video Game History Foundation is also an invaluable resource\nhttps://gamehistory.org/\n\n\n\n    These utilities are not solely aimed at preserving video/PC games. They can be used to preserve all forms of media. EAC, Exact Audio Copy, is a bit dated because it can not grab, for example, compact disc subcode\nhttps://en.wikipedia.org/wiki/Compact_Disc_subcode\n\n\n\n    Redumper can be found here:\nhttps://github.com/superg/redumper\nBOS (Binary Object Scanner) is an integral part of MPF for detection of copy protection mechanisms and can be found here: \nhttps://github.com/SabreTools/BinaryObjectScanner\n\n\n\n    While EAC is a decent utility, it lacks the ability to grab all possible information written to a an optical disc. Redumper/AARU have the ability to grab even more."},
{"Title": "LSi 9300 able to connect 7x HDDs and 1x SDD?", "Author": "u/fenderbender8", "Content": "I am new to the diy NAS scene, and have decided on creating a N100 mini PC NAS as it meets my needs for low power consumption and enough performance for my use case. However, seeing as the mini PC I have only has 1 NVMe slot, I was wondering if it would be fine to hook up 1x Sata SSD over the LSI card to act as the boot drive and 7x HDDs in Raid for storage? Would this work?"},
{"Title": "Downloading from Shootproof.com", "Author": "u/Bringback-T_D", "Content": "A \nshootproof.com\n gallery was sent out to attendees of an event I just went to... However, I can't figure out how to download everything... It's all watermarked, so I wouldn't consider it 'stealing' (I also plan to purchase some of the pictures), but I just want to have a good-enough archive, before it's taken down....\n  \n\n    I attempted to use \nhttps://github.com/ShootProof/shootproof-cli\n, however it's broken and out-of-date. What other tools/commands should I try out?"},
{"Title": "Canopus ADVC-55?", "Author": "u/LandRoverMedic", "Content": "Hi all, trying to build a setup for transfer of home movies etc, anyone having luck with ADVC-55’s? I see a few on ebay at a decent price. I hope to run with FireWire card and win11, not set on capture program yet. Was going to run with an old SHARP VC-684 although doesn’t have s-video so may look for another.\n  \n\n    Appreciate any help. 👍🏻"},
{"Title": "External HDD Reader", "Author": "u/alex_5506", "Content": "Hi there- I have an older laptop with a broken monitor so I can’t just boot it up (also can’t locate cords so I can’t use an external monitor). Is there any kind of external hdd reader that will work without another laptop/desktop? These days I’m strictly iPhone/ipad and don’t own a windows based machine. Any suggestions for easily accessing my old laptop hdd would be greatly appreciated."},
{"Title": "2 issues while digitizing VHS tapes", "Author": "u/desperado491", "Content": "My setup is:\n  \n\n    Playing VHS tapes on a Sony VHS/DVD combo with component jacks running into a Sony DCR-TRV 340 Camcorder and then via firewire into my Windows 7, capturing into WinDV.\n  \n\n    The biggest issue I've noticed is dropped frames- 33 frames dropped over the course of a 2 hour tape, another tape dropped 14 frames. This causes it to go out of sync. Is this the result of my computer? The tapes? I'm not sure how these dropped frames can be avoided and any help would be greatly appreciated.\n  \n\n    Another issue are these moving lines going up and down the screen. I've attached a video below that shows it. Adjusting the tracking doesn't seem to solve the issue. I first saw this issue in OBS but it's still happening in WinDV. Can anyone help identify these lines so I know what's causing them?\n  \n\n    Thanks so much!!\n  \n\n\nhttps://youtu.be/xtHPgzeOorc"},
{"Title": "Personal Backups: what are the recommendations?", "Author": "u/ligerzeronz", "Content": "So currently, I have 4 portable hard drives which i am not using. These have family photos/videos/documents.\n  \n\n    I am wanting to use these drives in the next 2 months but has to be completely empty.\n  \n\n    I am also now at a phase where i need stuff backed up just in case (3TB on one NAS, same data as above)\n  \n\n    I am not worried about it being cold storage as I have now uploaded these to Youtube and Google Photos. What would you guys recommend? A few I've heard is Backblaze and crashplan but i am completely new in this realm"},
{"Title": "Which file system(s) should I choose?", "Author": "u/jyssys", "Content": "Context: I'm going to run Linux file server VMs on VmWare ESXi. Each server will have two virtual disks connected: one for live data, and one for backup (on separate physical hard drives). The plan is to use Rsnapshot to backup the live data onto the backup data disk.\n  \n\n    In the past, I've had troubles where files has somehow gotten corrupted, and then the backup of the working files has rolled out of scope in the backup scheme, losing me those files. I'm told that there are file systems that can help me avoid that sort of thing. But which one? For the backups, I'm thinking simply ext4 since it's just rock solid. But for the live data, something like btrfs or zfs sounds good, but I cannot make my mind up about which one, or even if either is what I want. Ideally, I could run some tool once in a while, and if the tool spots corruption, I could just restore the file from backup. Which is best for this out of btrfs or zfs? Or is there a better option?"},
{"Title": "I Resurrected Subscene from the Subscene_V2 dump", "Author": "u/UltraNigatelo1911", "Content": "https://resubscene.vercel.app/\n\n    A subtitles database website using all the data that was dumped before subscene closure (Only extracted Arabic & English subtitle)\n  \nwebsite screenshot\n\n    The dump was massive with over 2 million extracted subtitle files (deduped & counting only english & arabic)\n  \n\n    With over 75 GB of extracted files\n  \nand 1.2 GB of just the metadata\n\n    The whole goal of this project was to provide a website to access this vast amount of subtitles accumulated over the years of subscene operation\n  \n\n    and also an opportunity to improve the horrible user experience the website suffered from, and the slow and inaccurate search, inability to download individual \n.srt; .ass;\n files directly.\n  \n\n    I plan on adding the missing languages and open sourcing the whole project alongside the processed data\n  \nHuge thanks to the Subscene dump:\nSubscene.com full Dump : r/DataHoarder (reddit.com)"},
{"Title": "Backup a GitHub repository's Wiki and Discussions", "Author": "u/pea_gravel", "Content": "There's this old GitHub repository that I'd like to have its Wiki and Discussions backed up. Do you guys know if it's possible to have a copy of it in markdown or any other format?\n  \n\n    Thanks"},
{"Title": "Need advice for creating a data hoarding setup - pretty lost", "Author": "u/CommercialDue1397", "Content": "Hi,\n  \n\n    I have a budget of around $5,000 CAD and would like to try to back up my data as well as I can. I would like to have 2 backups, 1 onsite 1 offsite.\n  \n\n    I have around 35 TB of data that I need to back up, and another 32 TB that I'd like to dedicate to new data.\n  \n\n    I'm looking into making a NAS build with RAID1 and creating the same build twice (once offsite, once where I live) but I really don't think that's cost-effective. In terms of drives - eyeing WD Red at the moment.\n  \n\n    I'm pretty sure this is a bad idea. I just don't know what would be considered a good idea. I don't know much about this sort of stuff and I'm tired of having 20 hard drives that could fail at any time. I've been lucky that my drives haven't failed in 10 years+ (besides one) but I don't want to take that risk anymore.\n  \n\n    Budget could increase theoreticaly to $8,000 CAD if needed but I'm trying to stay under $5,000 as much as I can.\n  \n\n    Please help suggest any solutions that I should look into. I don't have a good local network where I live right now, but I am going to move soon and will be able to get 10gbit inside the new place + 1gbit symmetrical offsite.\n  \n\n    Thank you!"},
{"Title": "How to recover old and faulty HDD?", "Author": "u/LauraAmerica", "Content": "I recently went back to my parents' (overseas) and found my backup (\nWD 3TB My Book\n). I got all hyped, it enclosures the treasures from my golden years. Sadly, it doesn't seem to work properly anymore —even when it was stored in a dry fresh dark place (for over a decade).\n  \n\n    When I plugged it in the computer it was able to read it without issue. Knowing the fragility of the situation, I started to copy the whole drive instead of browsing it. After 10% or so it stopped working. I re-plugged it in a different port and retried with similar results (with a progress equally low). After that it became hard to read it so I stopped —I didn't want to damage it by forcing a huge transfer in an unstable condition.\n  \n\n    My current plan is to try to access it from some Linux distro and, if I can read it, copy by folders (everything is organized in main categories).\n  \n\n    I don't think my old friend has much time left for trial and errors, so I'd like to check with you. I'm sure you'll have better ideas than my current barbaric plan.\n  \n\n    Thank you, this is important for me, and I highly appreciate and advise."},
{"Title": "Mobile game Rips?", "Author": "u/Wise_Leather_9159", "Content": "Okay I've been banging my head on every wall and surface of the Internet trying to solve a problem, I want to extract some 3D models from a mobile game so I can do some renders with em in SFM but everything I've tried just seems to come up empty or just simply not work. Does anyone have any advice, how to's etc etc???"},
{"Title": "I bought one of those fake flash drives accidently... Now half my videos are unplayable, is there any way to recover them or are they gone forever? Thanks.", "Author": "u/Valuable-Chance5370", "Content": "No content"},
{"Title": "BetaBagels: A briefing with the MTA Open Data Team https://us02web.zoom.us/meeting/register/tZEscuihpjwvGdT4RvNn7xPQbc0KsnpLHCGT#/registration", "Author": "u/Gabba_Rama", "Content": "Taking place online, may be of interest. \nhttps://us02web.zoom.us/meeting/register/tZEscuihpjwvGdT4RvNn7xPQbc0KsnpLHCGT#/registration"},
{"Title": "What do you do with your old hdd that are “still good”?", "Author": "u/Strange_Advisor_", "Content": "So as things grow I find myself replacing disks with bigger ones, replacing enclosures with Nas and das and now im at the point of what do I do with the obsolete stuff ? I have about 6 x 2 TB hdd and 1 x 3 TB hdd and one old ProBox that I am retiring with my upgrade ... do I just leave them on a shelf? Do I yeet them? There is nothing really important on them, just movies and tv shows, but it seems like a waste to toss them and seems like a waste to keep them. Thus i have no idea what do so ... so what does everyone else do? Thanks fam !"},
{"Title": "Efficient way to bulk download from Live Music Archive?", "Author": "u/jplank1983", "Content": "I'm interested in downloading all shows from a particular musician from the Live Music Archive on archive.org in FLAC format. Is there an efficient way to do this? The way I've been doing this so far is to navigate to each show's page and download the flac files manually. But, this is tedious as there are many, many shows. I'm wondering if there's some tool that would allow me to do the same thing more easily. I am on a Windows 11 machine, in case that's relevant."},
{"Title": "Best deal on 20tb or 22tb drives from serverpartdeals?", "Author": "u/thegameksk", "Content": "Looking to upgrade my NAS storage. They will he used mainly for Plex, transmission, calibre and comics reading. Also how do I tell when serverpartdeals has a sale? Is it advertised somewhere?"},
{"Title": "Is SyncBack 11 Free the best free option for my situation?", "Author": "u/ngs428", "Content": "I have a W11 desktop PC with about 3TB of data consisting of family videos and pictures.  I currently have it on an 8TB internal HDD and once every 3 months do a copy to my external HDD and delete the old backup.\n  \n\n    Moving forward I am looking to have the external HDD connected to the PC 24/7 and monitor for changes in the source folders on the internal HDD and mirror those changes to the external HDD.  So if I delete something on the internal, it deletes from the external.  Add to the internal, it adds to the external.\n  \n\n    After some research of looks like SyncBack 11 will do this and is free.  I see Veeam mentioned quite a bit.  What is the best option out there for free or low cost?\n  \n\n    Edit: I see freefilesync may be an option. \nhttps://freefilesync.org/download.php\n\n\n\n    Thank you!"},
{"Title": "A data hoarding tool I really like for moving files around, backups, copying, etc", "Author": "u/LuckyRide", "Content": "As always, I don't work for them, but I really like the product.\n  \n\n    \"Synchronize Files and Folders\" => \nhttps://freefilesync.org\n\n\n\n    It's really just a copy program - pretty typical and standard. Except it does SUCH a good job.\n  \n\n    You can set up sessions that copies when you run them - so update, mirror, things like that, to arbitrarily complex sets of disks and files. I use it extensively for backups to always know my files are backed up. It needs to be kicked off manually, but it just works so well and I like monitoring the steps.\n  \n\n    Most especially, I move files around between diff folders (think picture sorting, etc) and it will figure that out and \"move\" the files versus \"always re-copy\". So it really speeds everything up.\n  \n\n    So really what I use it for is \"make sure every file is backed up properly\" - and it does it really well - it \"never gives up until success\" no matter what happens. You can just re-run and make sure it's \"all up to date\".\n  \n\n    It supports Windows, Mac, and I think linux - so same on all platforms. It's donation-ware - and I think there is some more features if you donate - but I don't remember since I donated since the very beginning.\n  \n\n    No other tool really does it as well - no Windows copy or anything like that gives me any confidence like this does."},
{"Title": "WD Passport Ultra on Mac: HFS+ vs NTFS with WD Driver", "Author": "u/DatasTemporalLobe", "Content": "Trying to get a WD Passport Ultra to work on a Mac in order to back up an iPhone.  I see the Western Digital app has an option to download a driver (Paragon) for NTFS.\n  \n\n    Is it better to download the driver and use NTFS or reformat to HFS+? I like that I'd be able to use the hard drive on a pc if I go with NTFS with the Paragon driver but am I losing any functionality on the Mac?"},
{"Title": "Most efficient method of syncing a primary drive to a back-up drive (MacOS)", "Author": "u/pipmike", "Content": "I could use advise on which syncing software to use for a Mac and two external hard drives.\n  \n\n    Scenario:\n  \n\n\n\n\n\n    I have one external hard drive as my primary \"hoard\" drive to which I actively add large files (1+ GB), move files to different folders, change file tags, etc.\n  \n\n\n\n\n\n    I have a second external hard drive that I use as my first-level disaster recovery in case my primary drive fails. The second drive is currently one-way synced to the primary hard drive using a rysnc script i wrote.\n  \n\n\n\n\n\n    I don't need to store changes or previous file versions. Just want to mirror one drive to another.\n  \n\n\n\n\n\n    While rsync gets the job done, it doesn't handle the above efficiently because any changes are seen as new files, which means it's constantly writing/re-writing large files to the secondary hard drive.\n  \n\n\n\n\n\n    If I change the name of a directory including 100+ GB of files, rather than just similarly rename the directory of the secondary hard drive, rsync will delete all of the files, create a new directory, and re-sync all of those files.\n  \n\n\n\n\n\n    If I rename a file, rysnc will delete the file and then rewrite it.\n  \n\n\n\n\n\n    If I add a MacOS file tag to the file, rysnc will delete the file and then rewrite it.\n  \n\n\n\n\n\n    Thus, if I make any directory changes or tags, rsync can take hours (even days) to re-sync. I can imagine that's not healthy on either drive.\n  \n\n    It would be great if MacOS had a native function that said \"if I do anything to Drive A, do the same thing to Drive B\", but I haven't found it if it exists. Thus, I'm looking at other options (Chronosync, Carbon Copy Cloner, etc.) that might be a better solution for my use case.\n  \n\n    Open for all suggestions or feedback."},
{"Title": "How to avoid wasting time encrypting twice? Need to encrypt eHDD and want to encrypt cloud storage. Can I encrypt in place?", "Author": "u/Snowblind45", "Content": "Hello, I’ve new this this stuff. I’m trying to improve my data hoarding habits.\n  \n\n    Currently I have 2 external HDD identical to each other (5 TB filled). I plan on also storing a copy on Blackblaze Cloud storage. I’ve heard that rclone can encrypt the files as it uploads them to the cloud, amazing! But what about encrypting the drive itself? Do I spend time using rclone to encrypt and upload, then encrypt the drive using maybe veracrypt? Is it possible to encrypt first using veracrypt then simply rclone upload those contents to the cloud?\n  \n\n    I’m feeling a bit confused about veracrypt since a tutorial makes it seem like I need to have free space to allocate a virtual partition to encrypt but I don’t have the extra space…is there a way to encrypt in place?"},
{"Title": "Diff Checker - to check whether backup folder contents match source folder?", "Author": "u/redexposure", "Content": "I'm wondering if anyone can recommend a type of \"Diff Checker\", for files and folders, to see whether backup drive/folder contents match the source folder (and highlight files which haven't been duplicated)?\n  \n\n    Essentially, the inverse of a Duplicate Finder.\n  \n\n    Does anyone know of any tools like this?"},
{"Title": "How to connect an LTO tape drive to a Synology NAS (DS1621+)", "Author": "u/CyclicRedundancyMach", "Content": "All,\n  \n\n    I am looking to cold-store about 25tb of video along with the normal user data.  We are full-time RVrs and the continuous movement increases the risk of a full crash, risking all of my data.  My wife would be less than pleased.  In an attempt for a happy marriage, I wanted to purchase a tape drive for simple cold backups.  I would do a full backup followed by an incremental every month or so, rotating them.  I'd also do a full data backup and mail the tape(s) to a friend for safe keeping.\n  \n\n    I am just not sure how to connect an LTO.  Suggestions?\n  \n\n\n\n\n\n    The NAS has USB, gigabit RJ45s (CAT6), and a USB, a PCIE expansion slot.\n  \n\n\n\n\n\n    All of the drives seem to have SAS connections.\n  \n\n\n\n\n\n    I honestly thought that this would be 15 minute no-brainer.   would have thought that this illustrious group of data-centric technocrats would have 15 fully documented methods.  Instead, there is nothing at all.\n  \n\n    I would appreciate your advice."},
{"Title": "RE: Tools for Bit-for-Bit / 1:1 Optical Media Preservation", "Author": "u/Archivist_Goals", "Content": "I wanted to create a separate post that further elaborates on what was mentioned in \nthis post's comments\n from others. And, I will tag the original post's author \nu/KeptinGL6\n:\n  \n\n    Just to clarify for everyone, MPF is the overall GUI.\n  \n\n    There are 3 main utilities from different people that are used in the Media Preservation Frontend program:\n  \n\n\n\n\n\n    Redumper\n  \n\n\n\n\n\n    AARU\n  \n\n\n\n\n\n    Disc Image Creator (DIC)\n  \n\n\n\n\n\n\nDIC is actively being phased out. Redumper is pretty much the gold standard right now. AARU is also very well developed. DIC's original developer sort-of abandoned it and it's regarded as a legacy dumper utility and will be phased out at some point.\n\n\n\n    Edit: Some clarification. The original developer behind DIC didn't abandon it. Redumper is being chosen over DIC where applicable and/or possible.\n  \n\n    These programs' inception originate to the \nRedump.org\n, Video Game Preservation Collective, Gaming Alexandria and Hit Save! organizations and communities where, through Discord, a ton of collaboration has taken hold for proactive media preservation, the world over. It's a very sizable, but niche community of dedicated people very much akin to the VHS Decode and Domesday Laser Disc duplicator projects.\n  \n\n    Links\nhttps://www.preservegames.org/\nhttps://www.gamingalexandria.com/wp/\nhttps://hitsave.org/\n\n\n\n    Discords\nhttps://discord.com/invite/AHTfxQV\nhttps://discord.com/invite/dQhd6d7\nhttps://discord.com/invite/TCKT6uA\n\n\n\n    The Video Game History Foundation is also an invaluable resource\nhttps://gamehistory.org/\n\n\n\n    These utilities are not solely aimed at preserving video/PC games. They can be used to preserve all forms of media. EAC, Exact Audio Copy, is a bit dated because it can not grab, for example, compact disc subcode\nhttps://en.wikipedia.org/wiki/Compact_Disc_subcode\n\n\n\n    Redumper can be found here:\nhttps://github.com/superg/redumper\nBOS (Binary Object Scanner) is an integral part of MPF for detection of copy protection mechanisms and can be found here: \nhttps://github.com/SabreTools/BinaryObjectScanner\n\n\n\n    While EAC is a decent utility, it lacks the ability to grab all possible information written to a an optical disc. Redumper/AARU have the ability to grab even more."},
{"Title": "LSi 9300 able to connect 7x HDDs and 1x SDD?", "Author": "u/fenderbender8", "Content": "I am new to the diy NAS scene, and have decided on creating a N100 mini PC NAS as it meets my needs for low power consumption and enough performance for my use case. However, seeing as the mini PC I have only has 1 NVMe slot, I was wondering if it would be fine to hook up 1x Sata SSD over the LSI card to act as the boot drive and 7x HDDs in Raid for storage? Would this work?"},
{"Title": "Downloading from Shootproof.com", "Author": "u/Bringback-T_D", "Content": "A \nshootproof.com\n gallery was sent out to attendees of an event I just went to... However, I can't figure out how to download everything... It's all watermarked, so I wouldn't consider it 'stealing' (I also plan to purchase some of the pictures), but I just want to have a good-enough archive, before it's taken down....\n  \n\n    I attempted to use \nhttps://github.com/ShootProof/shootproof-cli\n, however it's broken and out-of-date. What other tools/commands should I try out?"},
{"Title": "Canopus ADVC-55?", "Author": "u/LandRoverMedic", "Content": "Hi all, trying to build a setup for transfer of home movies etc, anyone having luck with ADVC-55’s? I see a few on ebay at a decent price. I hope to run with FireWire card and win11, not set on capture program yet. Was going to run with an old SHARP VC-684 although doesn’t have s-video so may look for another.\n  \n\n    Appreciate any help. 👍🏻"},
{"Title": "External HDD Reader", "Author": "u/alex_5506", "Content": "Hi there- I have an older laptop with a broken monitor so I can’t just boot it up (also can’t locate cords so I can’t use an external monitor). Is there any kind of external hdd reader that will work without another laptop/desktop? These days I’m strictly iPhone/ipad and don’t own a windows based machine. Any suggestions for easily accessing my old laptop hdd would be greatly appreciated."},
{"Title": "2 issues while digitizing VHS tapes", "Author": "u/desperado491", "Content": "My setup is:\n  \n\n    Playing VHS tapes on a Sony VHS/DVD combo with component jacks running into a Sony DCR-TRV 340 Camcorder and then via firewire into my Windows 7, capturing into WinDV.\n  \n\n    The biggest issue I've noticed is dropped frames- 33 frames dropped over the course of a 2 hour tape, another tape dropped 14 frames. This causes it to go out of sync. Is this the result of my computer? The tapes? I'm not sure how these dropped frames can be avoided and any help would be greatly appreciated.\n  \n\n    Another issue are these moving lines going up and down the screen. I've attached a video below that shows it. Adjusting the tracking doesn't seem to solve the issue. I first saw this issue in OBS but it's still happening in WinDV. Can anyone help identify these lines so I know what's causing them?\n  \n\n    Thanks so much!!\n  \n\n\nhttps://youtu.be/xtHPgzeOorc"},
{"Title": "Personal Backups: what are the recommendations?", "Author": "u/ligerzeronz", "Content": "So currently, I have 4 portable hard drives which i am not using. These have family photos/videos/documents.\n  \n\n    I am wanting to use these drives in the next 2 months but has to be completely empty.\n  \n\n    I am also now at a phase where i need stuff backed up just in case (3TB on one NAS, same data as above)\n  \n\n    I am not worried about it being cold storage as I have now uploaded these to Youtube and Google Photos. What would you guys recommend? A few I've heard is Backblaze and crashplan but i am completely new in this realm"},
{"Title": "Which file system(s) should I choose?", "Author": "u/jyssys", "Content": "Context: I'm going to run Linux file server VMs on VmWare ESXi. Each server will have two virtual disks connected: one for live data, and one for backup (on separate physical hard drives). The plan is to use Rsnapshot to backup the live data onto the backup data disk.\n  \n\n    In the past, I've had troubles where files has somehow gotten corrupted, and then the backup of the working files has rolled out of scope in the backup scheme, losing me those files. I'm told that there are file systems that can help me avoid that sort of thing. But which one? For the backups, I'm thinking simply ext4 since it's just rock solid. But for the live data, something like btrfs or zfs sounds good, but I cannot make my mind up about which one, or even if either is what I want. Ideally, I could run some tool once in a while, and if the tool spots corruption, I could just restore the file from backup. Which is best for this out of btrfs or zfs? Or is there a better option?"},
{"Title": "I Resurrected Subscene from the Subscene_V2 dump", "Author": "u/UltraNigatelo1911", "Content": "https://resubscene.vercel.app/\n\n    A subtitles database website using all the data that was dumped before subscene closure (Only extracted Arabic & English subtitle)\n  \nwebsite screenshot\n\n    The dump was massive with over 2 million extracted subtitle files (deduped & counting only english & arabic)\n  \n\n    With over 75 GB of extracted files\n  \nand 1.2 GB of just the metadata\n\n    The whole goal of this project was to provide a website to access this vast amount of subtitles accumulated over the years of subscene operation\n  \n\n    and also an opportunity to improve the horrible user experience the website suffered from, and the slow and inaccurate search, inability to download individual \n.srt; .ass;\n files directly.\n  \n\n    I plan on adding the missing languages and open sourcing the whole project alongside the processed data\n  \nHuge thanks to the Subscene dump:\nSubscene.com full Dump : r/DataHoarder (reddit.com)"},
{"Title": "Backup a GitHub repository's Wiki and Discussions", "Author": "u/pea_gravel", "Content": "There's this old GitHub repository that I'd like to have its Wiki and Discussions backed up. Do you guys know if it's possible to have a copy of it in markdown or any other format?\n  \n\n    Thanks"},
{"Title": "Need advice for creating a data hoarding setup - pretty lost", "Author": "u/CommercialDue1397", "Content": "Hi,\n  \n\n    I have a budget of around $5,000 CAD and would like to try to back up my data as well as I can. I would like to have 2 backups, 1 onsite 1 offsite.\n  \n\n    I have around 35 TB of data that I need to back up, and another 32 TB that I'd like to dedicate to new data.\n  \n\n    I'm looking into making a NAS build with RAID1 and creating the same build twice (once offsite, once where I live) but I really don't think that's cost-effective. In terms of drives - eyeing WD Red at the moment.\n  \n\n    I'm pretty sure this is a bad idea. I just don't know what would be considered a good idea. I don't know much about this sort of stuff and I'm tired of having 20 hard drives that could fail at any time. I've been lucky that my drives haven't failed in 10 years+ (besides one) but I don't want to take that risk anymore.\n  \n\n    Budget could increase theoreticaly to $8,000 CAD if needed but I'm trying to stay under $5,000 as much as I can.\n  \n\n    Please help suggest any solutions that I should look into. I don't have a good local network where I live right now, but I am going to move soon and will be able to get 10gbit inside the new place + 1gbit symmetrical offsite.\n  \n\n    Thank you!"},
{"Title": "How to recover old and faulty HDD?", "Author": "u/LauraAmerica", "Content": "I recently went back to my parents' (overseas) and found my backup (\nWD 3TB My Book\n). I got all hyped, it enclosures the treasures from my golden years. Sadly, it doesn't seem to work properly anymore —even when it was stored in a dry fresh dark place (for over a decade).\n  \n\n    When I plugged it in the computer it was able to read it without issue. Knowing the fragility of the situation, I started to copy the whole drive instead of browsing it. After 10% or so it stopped working. I re-plugged it in a different port and retried with similar results (with a progress equally low). After that it became hard to read it so I stopped —I didn't want to damage it by forcing a huge transfer in an unstable condition.\n  \n\n    My current plan is to try to access it from some Linux distro and, if I can read it, copy by folders (everything is organized in main categories).\n  \n\n    I don't think my old friend has much time left for trial and errors, so I'd like to check with you. I'm sure you'll have better ideas than my current barbaric plan.\n  \n\n    Thank you, this is important for me, and I highly appreciate and advise."},
{"Title": "Mobile game Rips?", "Author": "u/Wise_Leather_9159", "Content": "Okay I've been banging my head on every wall and surface of the Internet trying to solve a problem, I want to extract some 3D models from a mobile game so I can do some renders with em in SFM but everything I've tried just seems to come up empty or just simply not work. Does anyone have any advice, how to's etc etc???"},
{"Title": "I bought one of those fake flash drives accidently... Now half my videos are unplayable, is there any way to recover them or are they gone forever? Thanks.", "Author": "u/Valuable-Chance5370", "Content": "No content"},
{"Title": "BetaBagels: A briefing with the MTA Open Data Team https://us02web.zoom.us/meeting/register/tZEscuihpjwvGdT4RvNn7xPQbc0KsnpLHCGT#/registration", "Author": "u/Gabba_Rama", "Content": "Taking place online, may be of interest. \nhttps://us02web.zoom.us/meeting/register/tZEscuihpjwvGdT4RvNn7xPQbc0KsnpLHCGT#/registration"},
{"Title": "What do you do with your old hdd that are “still good”?", "Author": "u/Strange_Advisor_", "Content": "So as things grow I find myself replacing disks with bigger ones, replacing enclosures with Nas and das and now im at the point of what do I do with the obsolete stuff ? I have about 6 x 2 TB hdd and 1 x 3 TB hdd and one old ProBox that I am retiring with my upgrade ... do I just leave them on a shelf? Do I yeet them? There is nothing really important on them, just movies and tv shows, but it seems like a waste to toss them and seems like a waste to keep them. Thus i have no idea what do so ... so what does everyone else do? Thanks fam !"},
{"Title": "Efficient way to bulk download from Live Music Archive?", "Author": "u/jplank1983", "Content": "I'm interested in downloading all shows from a particular musician from the Live Music Archive on archive.org in FLAC format. Is there an efficient way to do this? The way I've been doing this so far is to navigate to each show's page and download the flac files manually. But, this is tedious as there are many, many shows. I'm wondering if there's some tool that would allow me to do the same thing more easily. I am on a Windows 11 machine, in case that's relevant."},
{"Title": "How to archive mixed data types? Structured + unstructured...", "Author": "u/rnourse", "Content": "Looking for some ideas from the hive mind here. The department I support is retiring a number of applications and wants to archive the data for regulatory and compliance reasons. But these apps are a mixture of structured and unstructured data and since at least one of them is a SaaS app we wont have the ability to simply leave the old system running in RO mode. I'm trying to develop a shortlist of commercial products that can handle both the db tables+schemas along with pdf files, emails and documents in a single tool, ideally via a single pane of glass.\n  \n\n    Has anyone here had a similar challenge and if so, what types of tools did you consider?  Cloud as a target is fine."},
{"Title": "Better option for in site backup ?", "Author": "u/Ihavefinancialissues", "Content": "Storage option for on-site backup ? This is part of a backup plan with off site and cloud backup."},
{"Title": "Internal power error with new HDD", "Author": "Unknown author", "Content": "Currently running into an issue with adding another drive to my hoard. Any time I connect a new drive I get a BSOD Internal power error. I remove the new HDD and the error goes away. I have tried other driver other power connectors but nothing beside removing the newly connected HDD fixes it.\n  \n\n    Currently running:\n  \n\n    Os: Windows Server 2022 Standard v 21H2\nHDD count 10\nSSd count 2\n  \n\n    PSU 850watt\n  \n\n    Any idea what I am doing wrong ?"},
{"Title": "Segate exos", "Author": "u/sezayesh", "Content": "Hello guys. Noob here.\n  \n\n    I just bought a seagate exos 10TB and i think i made a mistake. I read someone saying about iron wolf drives that you should reduce start/stop events on these drives because they are build for 24/7 operation. Does it mean they are not suitable for pc use?(Since you keep turning them on and off) And is it the same with exos dar drives?\n  \n\n    Thank you"},
{"Title": "Long Lasting External Hard Drive Recommendations?", "Author": "u/Ispeakforthelorax", "Content": "Just discovered this sub, and wanted recommendations on external hard drives that will last!\n  \n\n    For a bit of background, my laptop is currently filled with all my stuff (personal documents, stuff from my undergrad, photos, videos, phone back ups, etc.). I currently just have a back up on a WD 1 TB HDD (I know I'm a bad boy for not following the 3-2-1 method, but I am trying to now!). I've been using this HDD for the past 8 years (and it saved my ass when my laptop died on me twice), and I am recently starting to hear sounds from it when it's running and it got me worried to find a replacement.\n  \n\n    All my data is ~250 GB, and I am looking for recommendations on what are some good external hard drives I can use! Although I am considering online cloud services, but I'm not sure if I want to pay a yearly subscription which has roughly the same annual cost similar to an external hard drive. I would prefer to pay for 2 hard drives and have it last for couple of years instead, rinse and repeat.\n  \n\n    I am looking to buy 2 hard drives, but am having a hard time decide which ones. I don't care about transfer speeds, and am looking for 500GB to 1 TB memory. The thing I care most about is that it lasts. I know there isn't any guarantee a that a external drive will last and could die any moment, but I would prefer it to last at least 5 years (hopefully 10 years) before I find a replacement. I generally do a back up 3-4 times a year, and let it collect dust on my shelf for the rest of the year.\n  \n\n    I was thinking of buying a HDD since I thought those last longer than SSDs, but apparently a bunch of websites on Google is telling me otherwise? That today's SSDs now last as long as HDDs or longer? Has SSDs surpassed HDDs in the past decade?\n  \n\n    Right now, I got my eyes on:\n  \n\n    Samsung T7 1 TB Portable SSD\n  \n\n    LaCie Rugged Mini 1 TB (SSD)\n  \n\n    Seagate STHN1000400 1TB Backup Plus Slim Portable Drive\n  \n\n    WD - Easystore 1TB External USB 3.0 Portable Drive\n  \n\n\n\n    I'm thinking I may do 1 HDD and 1 SSD cause why not lmao. I would be open to any suggestions on how to go about this!\n  \n\n    I would love to hear your thoughts and recommendations from your personal experiences!"},
{"Title": "I am a non-techy person. Is there an easy way to calculate the size of a website?", "Author": "u/ColdDijon", "Content": "I am non-techy and I would like to download all the images from a specific website for personal archiving.\n  \n\n    Is there a way I could know exactly just how much storage/size a website has before I download the whole website/images, and is there a way to just download the images, and have them downloaded automatically categorized like it does on the site? The site is a photo gallery.\n  \n\n    Thanks to whoever can help!"},
{"Title": "File Integrity checking for offline storage - RapidCRC still sufficient?", "Author": "u/Individual-Many-5784", "Content": "Just started properly getting into the rabbit hole that is datahoarding; for the past couple years I have only been storing my relevant files on external storage devices and using RapidCRC to generate CRC32 hashes for the files within each directory (such that I can pick up on any file corruption issues during quarterly checks of my data). While I have since decided to build myself a proper NAS to serve as my primary storage (with external storage and a cloud service serving as the backups), a couple questions still remain in regards to my current practices with external storage:\n  \n\n    To my understanding, there are far better hashing algorithms than CRC32 but would they provide any tangible benefits over CRC32 solely from a data corruption perspective (e.g. a lower chance of hash remaining the same in the event of corruption, even if unlikely to begin with)?\n  \n\n    (I'm probably overthinking this one, but) does it matter if I have one checksum file per directory (that contains all the file hashes in said directory) as opposed to an individual file per item?\n  \n\n    Lastly, would there be a more efficient method of checking the directories (opening checksum files to verify file integrity) than doing so manually? I don't have much practical knowledge with running scripts and the like, but am willing to learn if necessary.\n  \n\n    Thanks for reading and appreciate the help! :)"},
{"Title": "Curate your dataset before the internet gets spammed by ai generated content.", "Author": "u/YouWide5985", "Content": "I've spent the past few weeks doing this, and only now do I realize that I have the data hoarding disease."},
{"Title": "Growing my RAID1 with larger disks or creating a new RAID1 and copying?", "Author": "u/bloepz", "Content": "I currently have 2*3TB in RAID1 (HDD) and have two new disks (6TB HDD) which I want to use instead.\n  \n\n    It is encrypted and looks like this:\n  \n\n    /dev/sd(d,e)1 (partitions) -> /dev/md1 (raid1) -> /dev/mapper/raid1 (crypt) -> /files/raid1 (ext4)\n  \n\n    Is it better/faster to:\n  \n\n\n\n\n\n    Create a new RAID1 on the two 6TB, encrypt it, create filesystem and copy the data from the old RAID1 to this new RAID1\n  \n\n\n\n\n\n    or\n  \n\n\n\n\n\n    Add disks to the existing RAID1, grow it and resize the crypt and fs like this:\n  \n\n\n\n\n\n\nmdadm /dev/md1 --add /dev/sdf1 /dev/sdh1 --replace /dev/sdd1 /dev/sde1 --with /dev/sdf1 /dev/sdh1\n\n\n\n\nmdadm /dev/md1 --remove /dev/sdd1 /dev/sde1\n\n\n\n\ncryptsetup --resize /dev/mapper/raid1\n\n\n\n\nresize2fs /dev/mapper/raid1\n\n\n\n    Availability is not an issue - it can be offline for the whole time. I'm assuming growing the existing would take more time but that's purely a guess. And does one of those models do more wear on the new disks?"},
{"Title": "Organizing Photos & Videos + Deleting Duplicates", "Author": "u/Misclickable", "Content": "Hi. I would like to organize my backup of pictures and videos of my iPhone. I've been importing the pictures and videos on my iPhones to my PC for the last decade. Sometimes the import function didn't work as expected and I had to import everything all over again. Long story short, I now have 3 folders:\n  \n\n    Folder 1: Old pictures that are in DICM folders. It branches out quite a bit and their names are IMG_0001.\nFolder 2: A folder with pictures and videos split into two folders.\nFolder 3: Main folder that I want everything to be in. Most of it is right, but I'm sure it is missing the older pictures and videos in Folder 1.\n  \n\n    What I'm looking for:\n  \n\n\n\n\n\n    I want the pictures and videos to be chronologically placed so I can go through them without interruption.\n  \n\n\n\n\n\n    Preferably a program that would look at the 3 folders and create a new folder with all the files organized like 2024-05-28_IMG_0001.\n  \n\n\n\n\n\n    Remove duplicates so they don't occupy space unnecessarily. It could check if the file was created at the same time, instead of comparing the files one by one.\n  \n\n\n\n\n\n    What I've done so far:\n  \n\n\n\n\n\n    Tried using AntiDupl.NET but it would take too long to sort them one by one.\n  \n\n\n\n\n\n    Tried using dupeGuru but I can't verify the files actually being duplicates.\n  \n\n\n\n\n\n    A slight problem could be that some images are in .HEIC and some videos are in .HEVC format. I don't mind them being in that format as I use ImageGlass to view the pictures and VLC to view the videos.\n  \n\n    Extra: I'd appreciate if anybody have a good method of backing up their pictures and videos on their iPhone."},
{"Title": "6 bay USB Raid enclosure", "Author": "u/boglim_destroyer", "Content": "I just set up my DS224+ with mirrored 16tb drives and am currently backing up to a 5tb external, as my data can fit on that currently. However this will not always be the case and I am planning for when that time comes.\n  \n\n    I have 6 x 4tb drives that are not in use and I would like to find a USB RAID enclosure for these that I can run RAID 5 with a hot spare or RAID 6. Does anyone have any recommendations on an enclosure?"},
{"Title": "Prefer To Use Drives As Drives, Not Combined Storage (Noob Question)", "Author": "u/shadowoflight", "Content": "Hello,\n  \n\n    Totally new to NAS.\n  \n\n    I typically just add drives to my desktop, so in that sense I'm already super used to treating each drive individually.\n  \n\n    Been considering an NAS because sometimes the random drive spin-up causing the whole system to slow down or pause. Can be annoying, esp when gaming, that's why I'm considering shifting all my data storage off-pc.\n  \n\n    I thought it was just a matter of getting a NAS and plugging the drives in, but it seems like in a NAS, it is considered a single storage drive regardless of the number of drives it has?\n  \n\n    I'm assuming you can split up the storage, but that's still not using the drives individually yes?\n  \n\n    Or is there a way/setting you can set so that you don't have to use any kind of RAID and just have the system treat each drive as, well, a drive?"},
{"Title": "Is there an easyish app to auto-save and organize images and videos that meet a certain criteria?", "Author": "u/drupadoo", "Content": "Like everytime I watch a youtube video, just download it and back it up. Same with every reddit image I look at. Etc."},
{"Title": "Program to View/Change in Mass Encoding Types of Text (.lrc) files", "Author": "u/ngs428", "Content": "I have about 13,000 text (song lyric .lrc) files saved music file folders.  The are several hundred folders in this structure.\n  \n\n    I am looking for a program that can scan the folder and give me a view of the encoding types on each of the .lrc files.  Some are saved as UTF-8-BOM and I need to remove the BOM, saving them as UTF-8 only.\n  \n\n    Something like the document list in Notepad++ but having an “encoding” column.\n  \n\n    Or maybe there is a better way to accomplish what I am trying to do?  Any help would be appreciated!  Thanks!\n  \n\n    Edit: I just found EncodingChecker at:\nhttps://github.com/amrali-eg/EncodingChecker\n This is what I am looking for.  I will leave the post up for anyone with the same question in the future."},
{"Title": "Can a Focus Enhancement FS-H200 digitize DV tapes?", "Author": "u/AriFeblowitzVFX", "Content": "I just bought one of these things on Ebay assuming that if it hooks up to your camera via firewire and records direct from camera to flash card, that it could handle recording tapes to a flash card right?\n  \n\n    Well, the manual only talks about recording with the camera and has nothing about playblack/digitizing,. why would it not have that feature?\n  \n\n    Does anyone know if there's a way to use these to digitize?"},
{"Title": "back up a larger drive into a smaller drive using compression", "Author": "u/8yp00o19pB14Ic", "Content": "atm i have a sff hp thin client running linux, set up as a samba file server. got all my data on a 1 tb toshiba usb hdd. about 700 gb of photos and documents, music and movies....\n  \n\n    i bought a 2 tb  seagate usb hdd for a great price this week because i want to back up the data on the toshiba hdd, i dont trust all my data being on a single drive jic it fails.....\n  \n\n    my plan was to copy all the data from the toshiba to the seagate, set up the seagate as the new file server drive, and then i was going to set up the file server to do a weekly incremental backup on the toshiba drive. basically set the file server to back up the seagate drive to the toshiba drive weekly...\n  \n\n    i have done backups before, backing up my laptop's 256 gb ssd to the toshiba drive, no issues there.\n  \n\n    part of me wonders if its possible to compress down a backup of a drive and fit it into a smaller drive, say theoretically i had 1.2 tb worth on the seagate drive and compress it and store the backup on the 1 tb toshiba drive.\n  \n\n    if i could back up a larger drive into a smaller drive using compression, id be able to take advantage of that 2 tb instead of the opposite way around, where i only have 1 tb to play with and im backing up to a 2 tb drive.\n  \n\n    what am i missing, is this possible to do?"},
{"Title": "Archive down", "Author": "u/Legendary_Player", "Content": "Updates:\nhttps://x.com/internetarchive/status/1794793738482659453\n [May 26th, 6:12 pm UTC]\n  \n\n\nhttps://x.com/internetarchive/status/1795117949499445554\n (DDOS Attack) [May 27th, 3:40 pm UTC]\n  \n\n\nhttps://x.com/internetarchive/status/1795140710624039286\n (Up again, then down, then Up again) [May 27th, 5:11 pm UTC]\n  \n\n    It's up ⬆️ for now 🥳 [from around May 27th, 7:29 pm UTC]\n  \n\n\nhttps://x.com/internetarchive/status/1795451463465845141\n (Another New DDOS Attack) [May 28th, 1:46 pm UTC]\n  \n\n    \"We are continuing to experience service disruptions due to a recurrence of a ddos attack. We’ll post updates in this thread.\"\n  \n\n\nhttps://x.com/internetarchive/status/1795536130160390567\n (Another Update) [May 28, 7:22 pm UTC]\n  \n\n\nhttps://x.com/internetarchive/status/1795559880423534731\n (Another Update) [May 28, 8:56 pm UTC]\n  \n\n    Some attacks are occurring today 😟 [June 5, 3:30 pm UTC]"},
{"Title": "Dvd drive", "Author": "u/mro2352", "Content": "I’m wondering when firmware from dvd drives didn’t have a flash chip but actual rom."},
{"Title": "Linux Executables to Shrink your Video Horde?", "Author": "Unknown author", "Content": "I was looking for any kind of script or docker image that can help. My horde has gotten very bloated again. I have tried Fileflows(Docker image is broke on version 24.05+ for me), Tdarr just doesn't provide enough customization, and I don't feel like learning how to code my own plugin, & Handbrake docker doesn't have permissions to launch NGIX for me.\n  \n\n    I was thinking of a script with \nfind\n, a txt file for processed files, \nffmpeg\n, and \nwatch\n.  Because I would like to do everything in AV1 and I have  an A380 available in my server for transcodes. As any one done a script like this or know of one? I can reinvent the wheel but I would prefer to have a starting point. Thanks"},
{"Title": "Anyone in Minnesota repair Digibeta decks?", "Author": "u/AriFeblowitzVFX", "Content": "Here are the 3 problem machines:  \n  \n\n\n\n\n\n    VTR NTSC - Thomson TTV 3450 N\n  \n\n\n\n\n\n    Sony DVW-A510\n  \n\n\n\n\n\n    Betamax EDV-7000\n  \n\n\n\n\n\n    TTV 3450- \n  \n\n    Error code 009, eject button doesn’t work, no video signal output, not even for menu or time codes\n  \n\n    DVW-A510- everything works except for the Channel condition doesn’t light up and the video signal from the tapes are blank gray with no audio, but the menu, time code, and color bars all output and the tape plays/rewinds/ejects fine.  \n  \n\n    EDV-7000-\n  \n\n    This one a tape got stuck and none of the tape buttons like play or eject are working\n  \n\n    I only need one of the digibeta decks repaired and I should be good, but it would be good to at least get the tape out of the Betamax deck as well.\n  \n\n    Anyone know of anyone in Minnesota who fixes these things?  As you could guess I’ve been having bad luck trying to get a working digibeta deck on EBay haha."},
{"Title": "How do you error correct between multiple backup copies?", "Author": "u/Auralisme", "Content": "Let’s say you have 1TB worth of files that you don’t need to access frequently (twice a year.) You have 3 different 1TB hard drives available so you make 3 copies of the files.\n  \n\n    Scenario 1: Some sections on one of the drives are no longer correct.\n  \n\n    Scenario 2: Some sections on two of the drives are no longer correct, but they don’t overlap.\n  \n\n    What should you do in each of these scenarios?\n  \n\n    In my mind a raid 4 would makes sense for this application but I’ve read that using raid for long term backup strategies is not a good idea, so I’m trying to figure out how to make this work with 3 separate identical copies.\n  \n\n    My guess would be to simply overwrite the data on the damaged copy with one of the correct ones in scenario 1, but is there a good way to recover from scenario 2? What preparations do I need to do beforehand to ensure scenario 2 is recoverable? Is there any software I can use for such situations?\n  \n\n    Thank you for taking the time to answer this."},
{"Title": "GHTorrent used to be largest github archive. It was stopped updating couple of years ago and now whole site is down. Any alternatives?", "Author": "u/real_life_ironman", "Content": "As title, \nghtorrent.org\n is not working anymore. Someone hacked/bought the domain. And mongo files from \nhttp://ghtorrent-downloads.ewi.tudelft.nl/\n are not accessible anymore.\n  \n\n    I just ordered ~100TB of harddrives and wanted to start a project. Any alternatives to access this so I can store it?"},
{"Title": "automatically move/sort music artists into folders", "Author": "u/vanderzee", "Content": "im not so tech savy, i tried finding a solution but it only got me more confused\n  \n\n    i would like to move all my music artist folers into genre folders\n  \n\n\n\n    is there some whay to do this with software assistance?\n  \n\n\n\n\n\n    thanks!"},
{"Title": "How do I store NVME drives while it’s not in use?", "Author": "u/Teeeeze", "Content": "I have a few nvme drives that are not currently used lying around in my house. But I think there’s a certain way to store and preserve it but not sure.\n  \n\n    I searched on the internet and YouTube but no clue."},
{"Title": "Looking for a scanner that can handle a 40-year collection of documents according to my needs.", "Author": "u/SergeantYoshi", "Content": "Hello dear community,\n  \n\n    I have spent the last few weeks extensively researching scanners and now I have my second one here. I first had a ScanSnap ix1600 and now I have the Epson ES-580W. Both are great scanners, although I like the ES-580W a bit better because it has a web interface. But now I have reached the point where I don't want to bring every existing scanner into my house just to see if it has the functions I want, simply because the internet doesn't provide enough information. Therefore, I am reaching out to you for help.\n  \n\n    I need a scanner that allows me to create a large number of different profiles, in which I can then scan to a network folder. The reason is that my family and I have a wide variety of different documents that all need to be scanned directly into the corresponding folders (around 60+ profiles/shortcuts). The ScanSnap only has a handful of profiles and even though the Epson has 300 contacts, I can ultimately only create 48 presets. And I would like to be able to customize the file prefixes for each profile.\n  \n\n    I am hoping the community can help me find a suitable scanner. It should have what the previous two had, but additionally, it is important to me that it:\n  \n\n\n\n\n\n    Has a web server where I can make my settings (create profiles, etc.)\n  \n\n\n\n\n\n    Has a lot of Network Folder Shortcuts. Or alot of Shortcuts in General.\n  \n\n\n\n\n\n    Can scan receipts well\n  \n\n\n\n\n\n    Can handle no less than 30 pages\n  \n\n\n\n\n\n    The Epson was pleasantly quiet, so it would be great if it wasn't too loud (not a main criterion)\n  \n\n\n\n\n\n    The cheaper, the better, but given the price range I am currently considering, I expect to find something around €800 or less with the desired features.\n  \n\n    I look forward to your responses and hope that people can help me out."},
{"Title": "How to archive mixed data types? Structured + unstructured...", "Author": "u/rnourse", "Content": "Looking for some ideas from the hive mind here. The department I support is retiring a number of applications and wants to archive the data for regulatory and compliance reasons. But these apps are a mixture of structured and unstructured data and since at least one of them is a SaaS app we wont have the ability to simply leave the old system running in RO mode. I'm trying to develop a shortlist of commercial products that can handle both the db tables+schemas along with pdf files, emails and documents in a single tool, ideally via a single pane of glass.\n  \n\n    Has anyone here had a similar challenge and if so, what types of tools did you consider?  Cloud as a target is fine."},
{"Title": "Better option for in site backup ?", "Author": "u/Ihavefinancialissues", "Content": "Storage option for on-site backup ? This is part of a backup plan with off site and cloud backup."},
{"Title": "Internal power error with new HDD", "Author": "Unknown author", "Content": "Currently running into an issue with adding another drive to my hoard. Any time I connect a new drive I get a BSOD Internal power error. I remove the new HDD and the error goes away. I have tried other driver other power connectors but nothing beside removing the newly connected HDD fixes it.\n  \n\n    Currently running:\n  \n\n    Os: Windows Server 2022 Standard v 21H2\nHDD count 10\nSSd count 2\n  \n\n    PSU 850watt\n  \n\n    Any idea what I am doing wrong ?"},
{"Title": "Segate exos", "Author": "u/sezayesh", "Content": "Hello guys. Noob here.\n  \n\n    I just bought a seagate exos 10TB and i think i made a mistake. I read someone saying about iron wolf drives that you should reduce start/stop events on these drives because they are build for 24/7 operation. Does it mean they are not suitable for pc use?(Since you keep turning them on and off) And is it the same with exos dar drives?\n  \n\n    Thank you"},
{"Title": "Long Lasting External Hard Drive Recommendations?", "Author": "u/Ispeakforthelorax", "Content": "Just discovered this sub, and wanted recommendations on external hard drives that will last!\n  \n\n    For a bit of background, my laptop is currently filled with all my stuff (personal documents, stuff from my undergrad, photos, videos, phone back ups, etc.). I currently just have a back up on a WD 1 TB HDD (I know I'm a bad boy for not following the 3-2-1 method, but I am trying to now!). I've been using this HDD for the past 8 years (and it saved my ass when my laptop died on me twice), and I am recently starting to hear sounds from it when it's running and it got me worried to find a replacement.\n  \n\n    All my data is ~250 GB, and I am looking for recommendations on what are some good external hard drives I can use! Although I am considering online cloud services, but I'm not sure if I want to pay a yearly subscription which has roughly the same annual cost similar to an external hard drive. I would prefer to pay for 2 hard drives and have it last for couple of years instead, rinse and repeat.\n  \n\n    I am looking to buy 2 hard drives, but am having a hard time decide which ones. I don't care about transfer speeds, and am looking for 500GB to 1 TB memory. The thing I care most about is that it lasts. I know there isn't any guarantee a that a external drive will last and could die any moment, but I would prefer it to last at least 5 years (hopefully 10 years) before I find a replacement. I generally do a back up 3-4 times a year, and let it collect dust on my shelf for the rest of the year.\n  \n\n    I was thinking of buying a HDD since I thought those last longer than SSDs, but apparently a bunch of websites on Google is telling me otherwise? That today's SSDs now last as long as HDDs or longer? Has SSDs surpassed HDDs in the past decade?\n  \n\n    Right now, I got my eyes on:\n  \n\n    Samsung T7 1 TB Portable SSD\n  \n\n    LaCie Rugged Mini 1 TB (SSD)\n  \n\n    Seagate STHN1000400 1TB Backup Plus Slim Portable Drive\n  \n\n    WD - Easystore 1TB External USB 3.0 Portable Drive\n  \n\n\n\n    I'm thinking I may do 1 HDD and 1 SSD cause why not lmao. I would be open to any suggestions on how to go about this!\n  \n\n    I would love to hear your thoughts and recommendations from your personal experiences!"},
{"Title": "I am a non-techy person. Is there an easy way to calculate the size of a website?", "Author": "u/ColdDijon", "Content": "I am non-techy and I would like to download all the images from a specific website for personal archiving.\n  \n\n    Is there a way I could know exactly just how much storage/size a website has before I download the whole website/images, and is there a way to just download the images, and have them downloaded automatically categorized like it does on the site? The site is a photo gallery.\n  \n\n    Thanks to whoever can help!"},
{"Title": "File Integrity checking for offline storage - RapidCRC still sufficient?", "Author": "u/Individual-Many-5784", "Content": "Just started properly getting into the rabbit hole that is datahoarding; for the past couple years I have only been storing my relevant files on external storage devices and using RapidCRC to generate CRC32 hashes for the files within each directory (such that I can pick up on any file corruption issues during quarterly checks of my data). While I have since decided to build myself a proper NAS to serve as my primary storage (with external storage and a cloud service serving as the backups), a couple questions still remain in regards to my current practices with external storage:\n  \n\n    To my understanding, there are far better hashing algorithms than CRC32 but would they provide any tangible benefits over CRC32 solely from a data corruption perspective (e.g. a lower chance of hash remaining the same in the event of corruption, even if unlikely to begin with)?\n  \n\n    (I'm probably overthinking this one, but) does it matter if I have one checksum file per directory (that contains all the file hashes in said directory) as opposed to an individual file per item?\n  \n\n    Lastly, would there be a more efficient method of checking the directories (opening checksum files to verify file integrity) than doing so manually? I don't have much practical knowledge with running scripts and the like, but am willing to learn if necessary.\n  \n\n    Thanks for reading and appreciate the help! :)"},
{"Title": "Curate your dataset before the internet gets spammed by ai generated content.", "Author": "u/YouWide5985", "Content": "I've spent the past few weeks doing this, and only now do I realize that I have the data hoarding disease."},
{"Title": "Growing my RAID1 with larger disks or creating a new RAID1 and copying?", "Author": "u/bloepz", "Content": "I currently have 2*3TB in RAID1 (HDD) and have two new disks (6TB HDD) which I want to use instead.\n  \n\n    It is encrypted and looks like this:\n  \n\n    /dev/sd(d,e)1 (partitions) -> /dev/md1 (raid1) -> /dev/mapper/raid1 (crypt) -> /files/raid1 (ext4)\n  \n\n    Is it better/faster to:\n  \n\n\n\n\n\n    Create a new RAID1 on the two 6TB, encrypt it, create filesystem and copy the data from the old RAID1 to this new RAID1\n  \n\n\n\n\n\n    or\n  \n\n\n\n\n\n    Add disks to the existing RAID1, grow it and resize the crypt and fs like this:\n  \n\n\n\n\n\n\nmdadm /dev/md1 --add /dev/sdf1 /dev/sdh1 --replace /dev/sdd1 /dev/sde1 --with /dev/sdf1 /dev/sdh1\n\n\n\n\nmdadm /dev/md1 --remove /dev/sdd1 /dev/sde1\n\n\n\n\ncryptsetup --resize /dev/mapper/raid1\n\n\n\n\nresize2fs /dev/mapper/raid1\n\n\n\n    Availability is not an issue - it can be offline for the whole time. I'm assuming growing the existing would take more time but that's purely a guess. And does one of those models do more wear on the new disks?"},
{"Title": "Organizing Photos & Videos + Deleting Duplicates", "Author": "u/Misclickable", "Content": "Hi. I would like to organize my backup of pictures and videos of my iPhone. I've been importing the pictures and videos on my iPhones to my PC for the last decade. Sometimes the import function didn't work as expected and I had to import everything all over again. Long story short, I now have 3 folders:\n  \n\n    Folder 1: Old pictures that are in DICM folders. It branches out quite a bit and their names are IMG_0001.\nFolder 2: A folder with pictures and videos split into two folders.\nFolder 3: Main folder that I want everything to be in. Most of it is right, but I'm sure it is missing the older pictures and videos in Folder 1.\n  \n\n    What I'm looking for:\n  \n\n\n\n\n\n    I want the pictures and videos to be chronologically placed so I can go through them without interruption.\n  \n\n\n\n\n\n    Preferably a program that would look at the 3 folders and create a new folder with all the files organized like 2024-05-28_IMG_0001.\n  \n\n\n\n\n\n    Remove duplicates so they don't occupy space unnecessarily. It could check if the file was created at the same time, instead of comparing the files one by one.\n  \n\n\n\n\n\n    What I've done so far:\n  \n\n\n\n\n\n    Tried using AntiDupl.NET but it would take too long to sort them one by one.\n  \n\n\n\n\n\n    Tried using dupeGuru but I can't verify the files actually being duplicates.\n  \n\n\n\n\n\n    A slight problem could be that some images are in .HEIC and some videos are in .HEVC format. I don't mind them being in that format as I use ImageGlass to view the pictures and VLC to view the videos.\n  \n\n    Extra: I'd appreciate if anybody have a good method of backing up their pictures and videos on their iPhone."},
{"Title": "6 bay USB Raid enclosure", "Author": "u/boglim_destroyer", "Content": "I just set up my DS224+ with mirrored 16tb drives and am currently backing up to a 5tb external, as my data can fit on that currently. However this will not always be the case and I am planning for when that time comes.\n  \n\n    I have 6 x 4tb drives that are not in use and I would like to find a USB RAID enclosure for these that I can run RAID 5 with a hot spare or RAID 6. Does anyone have any recommendations on an enclosure?"},
{"Title": "Prefer To Use Drives As Drives, Not Combined Storage (Noob Question)", "Author": "u/shadowoflight", "Content": "Hello,\n  \n\n    Totally new to NAS.\n  \n\n    I typically just add drives to my desktop, so in that sense I'm already super used to treating each drive individually.\n  \n\n    Been considering an NAS because sometimes the random drive spin-up causing the whole system to slow down or pause. Can be annoying, esp when gaming, that's why I'm considering shifting all my data storage off-pc.\n  \n\n    I thought it was just a matter of getting a NAS and plugging the drives in, but it seems like in a NAS, it is considered a single storage drive regardless of the number of drives it has?\n  \n\n    I'm assuming you can split up the storage, but that's still not using the drives individually yes?\n  \n\n    Or is there a way/setting you can set so that you don't have to use any kind of RAID and just have the system treat each drive as, well, a drive?"},
{"Title": "Is there an easyish app to auto-save and organize images and videos that meet a certain criteria?", "Author": "u/drupadoo", "Content": "Like everytime I watch a youtube video, just download it and back it up. Same with every reddit image I look at. Etc."},
{"Title": "Program to View/Change in Mass Encoding Types of Text (.lrc) files", "Author": "u/ngs428", "Content": "I have about 13,000 text (song lyric .lrc) files saved music file folders.  The are several hundred folders in this structure.\n  \n\n    I am looking for a program that can scan the folder and give me a view of the encoding types on each of the .lrc files.  Some are saved as UTF-8-BOM and I need to remove the BOM, saving them as UTF-8 only.\n  \n\n    Something like the document list in Notepad++ but having an “encoding” column.\n  \n\n    Or maybe there is a better way to accomplish what I am trying to do?  Any help would be appreciated!  Thanks!\n  \n\n    Edit: I just found EncodingChecker at:\nhttps://github.com/amrali-eg/EncodingChecker\n This is what I am looking for.  I will leave the post up for anyone with the same question in the future."},
{"Title": "Can a Focus Enhancement FS-H200 digitize DV tapes?", "Author": "u/AriFeblowitzVFX", "Content": "I just bought one of these things on Ebay assuming that if it hooks up to your camera via firewire and records direct from camera to flash card, that it could handle recording tapes to a flash card right?\n  \n\n    Well, the manual only talks about recording with the camera and has nothing about playblack/digitizing,. why would it not have that feature?\n  \n\n    Does anyone know if there's a way to use these to digitize?"},
{"Title": "back up a larger drive into a smaller drive using compression", "Author": "u/8yp00o19pB14Ic", "Content": "atm i have a sff hp thin client running linux, set up as a samba file server. got all my data on a 1 tb toshiba usb hdd. about 700 gb of photos and documents, music and movies....\n  \n\n    i bought a 2 tb  seagate usb hdd for a great price this week because i want to back up the data on the toshiba hdd, i dont trust all my data being on a single drive jic it fails.....\n  \n\n    my plan was to copy all the data from the toshiba to the seagate, set up the seagate as the new file server drive, and then i was going to set up the file server to do a weekly incremental backup on the toshiba drive. basically set the file server to back up the seagate drive to the toshiba drive weekly...\n  \n\n    i have done backups before, backing up my laptop's 256 gb ssd to the toshiba drive, no issues there.\n  \n\n    part of me wonders if its possible to compress down a backup of a drive and fit it into a smaller drive, say theoretically i had 1.2 tb worth on the seagate drive and compress it and store the backup on the 1 tb toshiba drive.\n  \n\n    if i could back up a larger drive into a smaller drive using compression, id be able to take advantage of that 2 tb instead of the opposite way around, where i only have 1 tb to play with and im backing up to a 2 tb drive.\n  \n\n    what am i missing, is this possible to do?"},
{"Title": "Archive down", "Author": "u/Legendary_Player", "Content": "Updates:\nhttps://x.com/internetarchive/status/1794793738482659453\n [May 26th, 6:12 pm UTC]\n  \n\n\nhttps://x.com/internetarchive/status/1795117949499445554\n (DDOS Attack) [May 27th, 3:40 pm UTC]\n  \n\n\nhttps://x.com/internetarchive/status/1795140710624039286\n (Up again, then down, then Up again) [May 27th, 5:11 pm UTC]\n  \n\n    It's up ⬆️ for now 🥳 [from around May 27th, 7:29 pm UTC]\n  \n\n\nhttps://x.com/internetarchive/status/1795451463465845141\n (Another New DDOS Attack) [May 28th, 1:46 pm UTC]\n  \n\n    \"We are continuing to experience service disruptions due to a recurrence of a ddos attack. We’ll post updates in this thread.\"\n  \n\n\nhttps://x.com/internetarchive/status/1795536130160390567\n (Another Update) [May 28, 7:22 pm UTC]\n  \n\n\nhttps://x.com/internetarchive/status/1795559880423534731\n (Another Update) [May 28, 8:56 pm UTC]\n  \n\n    Some attacks are occurring today 😟 [June 5, 3:30 pm UTC]"},
{"Title": "Dvd drive", "Author": "u/mro2352", "Content": "I’m wondering when firmware from dvd drives didn’t have a flash chip but actual rom."},
{"Title": "Linux Executables to Shrink your Video Horde?", "Author": "Unknown author", "Content": "I was looking for any kind of script or docker image that can help. My horde has gotten very bloated again. I have tried Fileflows(Docker image is broke on version 24.05+ for me), Tdarr just doesn't provide enough customization, and I don't feel like learning how to code my own plugin, & Handbrake docker doesn't have permissions to launch NGIX for me.\n  \n\n    I was thinking of a script with \nfind\n, a txt file for processed files, \nffmpeg\n, and \nwatch\n.  Because I would like to do everything in AV1 and I have  an A380 available in my server for transcodes. As any one done a script like this or know of one? I can reinvent the wheel but I would prefer to have a starting point. Thanks"},
{"Title": "Anyone in Minnesota repair Digibeta decks?", "Author": "u/AriFeblowitzVFX", "Content": "Here are the 3 problem machines:  \n  \n\n\n\n\n\n    VTR NTSC - Thomson TTV 3450 N\n  \n\n\n\n\n\n    Sony DVW-A510\n  \n\n\n\n\n\n    Betamax EDV-7000\n  \n\n\n\n\n\n    TTV 3450- \n  \n\n    Error code 009, eject button doesn’t work, no video signal output, not even for menu or time codes\n  \n\n    DVW-A510- everything works except for the Channel condition doesn’t light up and the video signal from the tapes are blank gray with no audio, but the menu, time code, and color bars all output and the tape plays/rewinds/ejects fine.  \n  \n\n    EDV-7000-\n  \n\n    This one a tape got stuck and none of the tape buttons like play or eject are working\n  \n\n    I only need one of the digibeta decks repaired and I should be good, but it would be good to at least get the tape out of the Betamax deck as well.\n  \n\n    Anyone know of anyone in Minnesota who fixes these things?  As you could guess I’ve been having bad luck trying to get a working digibeta deck on EBay haha."},
{"Title": "How do you error correct between multiple backup copies?", "Author": "u/Auralisme", "Content": "Let’s say you have 1TB worth of files that you don’t need to access frequently (twice a year.) You have 3 different 1TB hard drives available so you make 3 copies of the files.\n  \n\n    Scenario 1: Some sections on one of the drives are no longer correct.\n  \n\n    Scenario 2: Some sections on two of the drives are no longer correct, but they don’t overlap.\n  \n\n    What should you do in each of these scenarios?\n  \n\n    In my mind a raid 4 would makes sense for this application but I’ve read that using raid for long term backup strategies is not a good idea, so I’m trying to figure out how to make this work with 3 separate identical copies.\n  \n\n    My guess would be to simply overwrite the data on the damaged copy with one of the correct ones in scenario 1, but is there a good way to recover from scenario 2? What preparations do I need to do beforehand to ensure scenario 2 is recoverable? Is there any software I can use for such situations?\n  \n\n    Thank you for taking the time to answer this."},
{"Title": "GHTorrent used to be largest github archive. It was stopped updating couple of years ago and now whole site is down. Any alternatives?", "Author": "u/real_life_ironman", "Content": "As title, \nghtorrent.org\n is not working anymore. Someone hacked/bought the domain. And mongo files from \nhttp://ghtorrent-downloads.ewi.tudelft.nl/\n are not accessible anymore.\n  \n\n    I just ordered ~100TB of harddrives and wanted to start a project. Any alternatives to access this so I can store it?"},
{"Title": "automatically move/sort music artists into folders", "Author": "u/vanderzee", "Content": "im not so tech savy, i tried finding a solution but it only got me more confused\n  \n\n    i would like to move all my music artist folers into genre folders\n  \n\n\n\n    is there some whay to do this with software assistance?\n  \n\n\n\n\n\n    thanks!"},
{"Title": "How do I store NVME drives while it’s not in use?", "Author": "u/Teeeeze", "Content": "I have a few nvme drives that are not currently used lying around in my house. But I think there’s a certain way to store and preserve it but not sure.\n  \n\n    I searched on the internet and YouTube but no clue."},
{"Title": "Looking for a scanner that can handle a 40-year collection of documents according to my needs.", "Author": "u/SergeantYoshi", "Content": "Hello dear community,\n  \n\n    I have spent the last few weeks extensively researching scanners and now I have my second one here. I first had a ScanSnap ix1600 and now I have the Epson ES-580W. Both are great scanners, although I like the ES-580W a bit better because it has a web interface. But now I have reached the point where I don't want to bring every existing scanner into my house just to see if it has the functions I want, simply because the internet doesn't provide enough information. Therefore, I am reaching out to you for help.\n  \n\n    I need a scanner that allows me to create a large number of different profiles, in which I can then scan to a network folder. The reason is that my family and I have a wide variety of different documents that all need to be scanned directly into the corresponding folders (around 60+ profiles/shortcuts). The ScanSnap only has a handful of profiles and even though the Epson has 300 contacts, I can ultimately only create 48 presets. And I would like to be able to customize the file prefixes for each profile.\n  \n\n    I am hoping the community can help me find a suitable scanner. It should have what the previous two had, but additionally, it is important to me that it:\n  \n\n\n\n\n\n    Has a web server where I can make my settings (create profiles, etc.)\n  \n\n\n\n\n\n    Has a lot of Network Folder Shortcuts. Or alot of Shortcuts in General.\n  \n\n\n\n\n\n    Can scan receipts well\n  \n\n\n\n\n\n    Can handle no less than 30 pages\n  \n\n\n\n\n\n    The Epson was pleasantly quiet, so it would be great if it wasn't too loud (not a main criterion)\n  \n\n\n\n\n\n    The cheaper, the better, but given the price range I am currently considering, I expect to find something around €800 or less with the desired features.\n  \n\n    I look forward to your responses and hope that people can help me out."},
{"Title": "Help with portable music storage", "Author": "u/tejasdharmabum", "Content": "Hello! I have a large music collection (mostly CDs) that I’m backing up, and I’ve been putting some on a USB drive to shuffle on my commuting drive, I live in a rural area so streaming is not an option. However the Texas heat seems to be getting to my flash drives and I have to replace them about twice a year. Is there a better quality drive that won’t break the bank too much, can hold about 3000 songs and doesn’t eff-up that often? I have to leave it in my truck, I work on construction sites so nowhere to store it and not really safe to bring it with me.. Thanks y’all!"},
{"Title": "nas motherboard with sff 8643 to 4* nvme Pcie adapter", "Author": "u/Hilarsky", "Content": "So, just after I bought 1165g7 nas from topton I found this from CWWK, which on paper looks amazing to me.\nIn theory it supports up to 6x nvme with this odd extension board you can buy with this bundle, however they're stating on product page that it doesn't support pcie 4.0 nvme drives (which sounds like bs to me )\n  \n\n    My question is , does anyone has this board ? Works ok ? Anyone seen any information regarding sff 8643 -> to pcie ? google produces only garbage results ...\n  \n\n\nhttps://www.aliexpress.com/item/1005007029671776.html?pdp_npi=4%40dis%21GBP%21%EF%BF%A1321.66%21%EF%BF%A1160.83%21%21%21398.00%21199.00%21%40210384cc17168245681252058e0b43%2112000039151333112%21sh%21UK%210%21"},
{"Title": "Can I use SATA drives directly without enclosure for data back ups?", "Author": "u/tealbull", "Content": "I'm currently in need of around 30TB of storage to archive completed project data and free up my RAID volumes, which I use for active projects.\n  \n\n    I've looked into external desktop drive options from LaCie, WD, and Seagate, but they are quite pricey. I'm considering buying 3.5inch SATA drives and using a SATA to USB connector (which I already have) to offload the data. I've found that 18TB SATA drives are significantly cheaper (2-3 times) compared to external desktop drive solutions from LaCie, WD, or Seagate.\n  \n\n    Is this a good idea? What might be some disadvantages of doing this?"},
{"Title": "What is the best (safe, but priority on space efficient) way to store a large quantity (around 1.2k) optical discs", "Author": "u/A_Big_Igloo", "Content": "Title says it. I have just shy of 1.2K discs that I have digitized for my media server, but I'd like to keep the originals in case I discover an error in digitization or server failure. I currently have four 3d printed spindles that hold around 300 each but they're uncovered and the design doesn't allow for a cover. Is anyone aware of either retail spindles that have covers that I can buy without having to buy a bunch of blank discs that I'd just throw out in a 300ish capacity, or some other space efficient storage system? I don't anticipate the need to access them any time soon, hence the spindles.\n  \n\n    I have avoided books because they are so space inefficient, I can fit twice the amount of discs in spindles that I can in the same space of books. Are there other methods that I haven't even considered?"},
{"Title": "Anyone know how to read this old disk?", "Author": "u/GloomyAction", "Content": "No content"},
{"Title": "5 TB drive went from 100 mb/s transfers to now 60", "Author": "u/Soolidus", "Content": "WD HDD. Got slower and slower the closer it got to full capacity, which I thought was normal, but I recently deleted 3 TBs worth and it's still the same. Any way to fix it? Is this normal?"},
{"Title": "Win10, how can I have more drive letters for backblaze?", "Author": "u/covered1028", "Content": "Right now I am plugging each drive 1 by 1 and have backblaze back up each drive while I figure out my setup but I will run out of drive letters soon.\n  \n\n    One solution I thought about was that when I run out of drive letters, I will reuse a drive letter and for that drive make a new folder moving all data in there so I would know what data I lost and I can restore it by going through the time machine thing."},
{"Title": "Is there a noticeable difference between 150 and 400 MB/s?", "Author": "u/cannotperson", "Content": "I'm looking at \nhttps://www.amazon.com/SanDisk-Ultra-Dual-Drive-Type-C/dp/B0842P5GG5\n and there are two options, one for 150 and another for 400 MB/s read speed. The main purpose will be storing backup files and downloaded files from the web.\n  \n\n    For a $30 USD price increase, is the 400 MB/s flash drive worth it?"},
{"Title": "What is a good program to download a neocities website?", "Author": "u/Acceptable_Cook_8112", "Content": "hey i have been struggling to download a neo cities website i want because i tried doing it with htttrack and it didnt work because it didnt give me alll the sources /; idk how to download it with the full sources. im downloading it because i wanna edit the code and modify it so it can fit my aesthetic lol"},
{"Title": "Finally built a desktop. Stuffed it with all my old laptop drives. 32TB, I may have a problem.", "Author": "u/DR650SE", "Content": "No content"},
{"Title": "Preserve online games", "Author": "u/Occhako", "Content": "Hi so a game I've been playing for 7 years, Love Live SIF, got shut down. And I lost everything that got me scared about this happening to other games i play like genshin, obey me, Honkai: Star Rail and love and deepspace.\n  \n\n    I want to be able to make a copy of the game that can run locally so that if the game ever closes it's servers i can keep playing content that i already own.\n  \n\n    So like i don't mind if there's no updates, i just don't want to lose my hardwork because the company can't afford to keep the servers or they just shut down with no explanation.\n  \n\n    How would i go about doing that or learning how to do that. If someone could point me in the right direction that would be great. I should probably stop playing these kind of games and spending money on them, but all the good mobile and PC games these days keep requiring an internet to play the game even if it's a single player."},
{"Title": "Can the \"WD_BLACK D10 Game Drive for Xbox 12TB\" be used as a normal external drive?", "Author": "u/Pinguinina", "Content": "With a PC or Mac for regular files, etc.\n  \n\n    It has Xbox branding and is bigger than the \"PC/Console version\" so I don't know if it has some sort of formatting or block built into it that prevents it from just being used as an external.\n  \n\n    I've had the 8TB for a while but I need more space. It's reasonably portable considering the size which is something I need and as far as I'm aware it includes a good drive. I'm open to alternative suggestions though but it needs to be portable and not really more expensive."},
{"Title": "Data access: SSD vs HDD once plugged in – thoughts?", "Author": "u/Future-Cod-7565", "Content": "Hello fellow hoarders,\n  \n\n    Please could someone help me with this: I have a 2TB SanDisk SSD and a 5TB Seagate HDD. Both full of data (both almost filled up). When plugged into my laptop (MacBook Pro 2017, 16GB RAM, 4 USB-C ports) the access time to the data significantly varies: while for both disks the root is readily available the moment you click the disk icon and open the drive, for the SSD drive it takes a while (sometimes rather long while, I'd say) to show the contents of a folder, while for the HDD it takes no time at all. This surprises me greatly, for what I used to think (mechanic-wise) the HDD having moving parts, spindle and platters and head to position, it should take longer to locate the data, when the SSD having no need to position the head and all that it should be a split second to give me access to the data in a folder. Can this be related to how my OS (macOS Monterey 12.7.5) accesses the drives? Anyone with the same \"issue\" (can't name it a real issue since I do have access to the data)? Please advise.\n  \n\n    Thank you!"},
{"Title": "Anyone know why my DigiBeta DVW-A510 deck is just giving blank gray for the video signal?", "Author": "u/AriFeblowitzVFX", "Content": "No content"},
{"Title": "Cheapest short term 100TB storage with good bandwidth", "Author": "u/CategoryHoliday9210", "Content": "I need to have preferably SSD of 100TB -200TB storage.\n  \n\n    Can you share where I can get the best bang for my buck?\n  \n\n    I am not planning to buy it as I don't think I can manage it for a long time. I would need it for 2-3 months and My connection speed is not great down 300mbps. So looking for online solution.\n  \n\n    Edit: since a lot people are curious about SSD, it would be various databases so speed is kind of important , I wish I could do it in RAM but SSD would do."},
{"Title": "LTO 5 Class Tape Drive or Hot Swapping a bunch of 1.2TB 2.5\" 10k SAS Drives?", "Author": "u/Empire_Fable", "Content": "Good day every one.  Thank you for letting me in the community.  I just started dabbling with archiving data\n  \n\n    I'm currently archiving some rather big compressed files 200+ GB.  Weighing some options.  I considered buying a HP LTO 5 class tape drive(Its more in my price range then the newer ones) .  Looking at the Tape media cost, I'm seeing maybe a better option to just get a bunch of hotswappable 2.5\"  1.2Tb SAS drives for a older HP dl360.  Then just hot swapping them out like tapes.  I really did want a tape drive though.  Any one know of a good benefit to a tape drive other then them being super cool?"},
{"Title": "1fichier to store 100-200gb of data in the cloud for cheap", "Author": "u/greyfeather9", "Content": "Hey, after looking at multiple services I think 1fichier seems fit. I just want to store a cloud backup of some stuff, the limiting factor is a 50gb zip with some sites having limitations on filesize, but fichier limit is 300gb. the zip will stay as is but I will be doing daily/weekly uploads of 2gb backups or so.\n  \n\n    just wanted to ask your opinion on their service, thanks."},
{"Title": "Sagittarius NAS Case Review and Build Tips", "Author": "u/Ben4425", "Content": "I recently rebuilt my NAS by moving it from a Fractal Node 804 case into the Sagittarius NAS case available from AliExpress. The Node 804 was a good case, with great temps, but swapping hard drives around was a pain. The 804 is also ginormous.\n  \n\n    So, why the Sagittarius? It met my requirements for MATX, eight externally accessible drive bays, and what appeared to be good drive cooling. I also considered:\n  \n\n\n\n\n\n    Audheid K7. Only had two 92mm fans and some reviews reported high drive temps. Also required buying a Flex PSU.\n  \n\n\n\n\n\n    Audheid 8-Bay 2023 Edition. Provides better cooling with two 120mm fans but still required a Flex PSU if you wanted all 8 drive bays.\n  \n\n\n\n\n\n    Jonsbo N4. Only 4 bays were externally accessible and it only has \none\n 120mm fan.\n  \n\n\n\n\n\n    Overall, I'm happy with the Sagittarius case. Its very compact yet it holds 8 drives, an MATX motherboard, and \nfour\n 120mm fans. My drive and CPU temps are excellent.\n  \n\n    But, you really need to plan your build because there's \nno\n documentation, no cable management, and because some connectors are hidden by other components. If you don't plug in your cables as you build then you'll never get to them later after the build is complete. You also need think about air flow which I'll discuss after documenting my build.\n  \n\n    Time for some photos, starting with the empty case.\n  \nEmpty Case\n\n    The two small rectangular holes in the upper and bottom left are all you have for routing cables from this, the motherboard side, to the hard drives on the other side. I ran 4 SATA cables through each of these holes.\n  \n\n    My motherboard mounts 4 of its SATA Ports along the edge so I had to plug those in \nbefore\n installing the motherboard itself. Otherwise, those connectors would have been practically inaccessible:\n  \nMotherboard Edge Connector Issues\n\n    The case supports two 2.5 SSD drives that are screwed to the bottom of the case. But, if you do, they will be flush to the case so plugging in cables will be near impossible. I purchased some 1/4\" nylon standoffs and longer M3-10 screws to elevate the SSDs a bit. It was still a pain to plug in the cables (because they are toward the bottom of this photo) but it worked:\n  \nhttps://preview.redd.it/sagittarius-nas-case-review-and-build-tips-v0-31oe40fbxq2d1.jpg\n\n    I routed all my SATA and fan cables next. I have 10 SATA ports total, two for SSDs and 8 for HDDs. Four of those interfaces are on an ASM-1064 PCIe add-on board and the rest are on the motherboard.\n  \n\n    Then, it was time for the power supply. I \nstrongly\n suggest using a modular SFX power supply that typically comes with shorter cables. Long, or unnecessary, cables will be an issue because there's no place to put them. Also note you should plug in the EPS power cable \nbefore\n you install the power supply because you'll never get to it afterward:\n  \nEPS Power Connector\n\n    Also make sure you route the SATA power cable before installing the power supply.\n  \n\n    Last, install the fans. Standard 25mm thickness fans just barely clear the main motherboard power cable at the bottom of this picture. Also note I installed fan grills on all my fans otherwise (for my airflow) the cables would have hit the fan blades:\n  \nFinished Interior\n\n    Now, about the \"drive sleds\". This case only provides rubber bushings and screws to fasten those bushings to the sides of your hard drives. They also provide a metal plate with a bend that acts as the handle to pull the drive from the case:\n  \n\"Drive Sled\"\n\n    This is \nreally\n basic but I found it works well.\n  \n\n    Wrapping up, here's a photo of the finished product. You can see the slots on the right that hold the rubber bushings that are attached to the hard drives.\n  \nFinal Result w/o Drive Bay Cover\n\n    I installed four 120mm Phanteks fans (from my old Node 804) into this case and \nall\n of them are configured to exhaust air \nfrom\n the case. There are two behind the grill on the left of this picture and you can see that the fan screws just go through the grating holes. Air for the left side of the case is pulled in through holes in the rear and a large grating on the left side of the case (not visible here). So, on the left, air is pulled from the side and down towards the CPU and motherboard before exhausting out the front.\n  \n\n    On the right, there are two fans behind the hard drive cage. They too exhaust air that is pulled from the front of the case, past the hard drives, and then blown out the rear. There's maybe 5mm space between the drives so airflow is unimpeded. At 22c ambient, my idle drive temps vary from 24c to 27c. Not bad!\n  \n\n    As I said earlier, I'm happy. The case is very compact (about 300x260x265 mm), holds eight 3.5\" drives, two 2.5\" SSDs, and runs cool. For about $180, which included shipping to Massachusetts, I think it was a good purchase. That said, it isn't perfect:\n  \n\n\n\n\n\n    No cable management features.\n  \n\n\n\n\n\n    No fans are included, you must provide your own.\n  \n\n\n\n\n\n    Standard ATX PSU are supported but IMHO are impractical due to the larger PSU size and longer cables. Cable management would be a \nmess\n.\n  \n\n\n\n\n\n    FYI, the case has one USB 3.0 Type A port and one USB-C port on the front. Both of these are wired to the \nsame\n USB 3.0 motherboard cable so the USB-C port will be limited to USB 3.0 speeds (5 Gbps). I.e. the USB-C port is wired to a USB 3.0 port on the motherboard."},
{"Title": "What are expected SMART values for Seagate Recertified Drives?", "Author": "u/ELO_Space", "Content": "I recently bought a Seagate Ironwolf Pro Recertified drive (ST18000nt001), and the SMART results are worrying me a bit.. In particular with the seek error rate. Is this normal for a Seagate drive and how it reports raw values, or should I return it? (2 year warranty, plus I still am in the return period)\n  \nhttps://preview.redd.it/what-are-expected-smart-values-for-seagate-recertified-v0-l756opbzlt2d1.png"},
{"Title": "Using NIB but older SSD / HDD manufactured in 2021 / 2022 ?", "Author": "u/instagigated", "Content": "Thoughts on using drives manufactured some years ago? Is there greater risk of data corruption/loss vs. using drives manufactured in the past 12 months?\n  \n\n    I received two drives recently:\n  \n\n\n\n\n\n    Sandisk 1 TB portable SSD (2021)\n  \n\n\n\n\n\n    WD 16 TB external HDD (2022)\n  \n\n\n\n\n\n    Should I return and get something manufactured more recently?"},
{"Title": "SingleFile vs Save Page WE?", "Author": "u/eldomtom2", "Content": "I'm using Save Page WE at the moment, is there a good reason to switch?"},
{"Title": "LTO5 Drive Repeatedly Clicks?", "Author": "u/1823alex", "Content": "No content"},
{"Title": "2 x Raid5 in mirror or in seperate servers and weekly backups", "Author": "u/Adorok", "Content": "i currently have 2x 16tb hdds in a mirror + a seperate disk for weekly backups (full backups, i dont want incremental backups), and the space is slowly running out. Buying bigger drives would be more expensive, than just buying 3 additional drives. I have a spare server, splitting between servers would only increase the power bill.\n  \n\n    By putting them in a mirror, i could increase read speed and have a lower electricity consumption. On the other hand, if my psu fails, all drives could theorethicaly fail at once.\n  \n\n    What do you guys think / would you do?"},
{"Title": "RAID 6 + 3, 2, 1 rule. Check my understanding?", "Author": "u/tddammo1", "Content": "Hi all, learning *much* more about RAID etc now that I'm upgrading from essentially raid 0 across 3 pi's into a new system that has the potential for 13 drive bays (at some point).\n  \n\n    As I'm learning, I want to verify I understand (some) of how the interaction of RAID 6 and the 3,2,1 rule can be applied.\n  \n\n    I'm perfectly okay with if this idea is wrong, and that's fine.\n  \n\n    Assumptions: All raid drives are 1TB, running RAID 6, using 4 drives\n  \n3 Copies\n\n\n\n\n\n    Obviously the first one is RAID 6 1TB, allowing for 2 TB storage, 2TB protection. (HDD)\n  \n\n\n\n\n\n    Second backup: Should this be *another* RAID 6 node? Or can this be a single 2TB drive (SSD)\n  \n\n\n\n\n\n    Offsite backup: Similarly, can this be a 2TB drive\n  \n\n\n\n\n\n    Essentially when using 3, 2, 1 rule should we be mimicking RAID? Or is it safe to have these drives be single drives (yes, now we've gone from double redundancy to single point of failure, which is why I'm asking)\n  \n\n    Thanks!"},
{"Title": "What are the best free tools for creating a perfect bit-for-bit copy of a CD, including copy protection?", "Author": "u/KeptinGL6", "Content": "?"},
{"Title": "Help with portable music storage", "Author": "u/tejasdharmabum", "Content": "Hello! I have a large music collection (mostly CDs) that I’m backing up, and I’ve been putting some on a USB drive to shuffle on my commuting drive, I live in a rural area so streaming is not an option. However the Texas heat seems to be getting to my flash drives and I have to replace them about twice a year. Is there a better quality drive that won’t break the bank too much, can hold about 3000 songs and doesn’t eff-up that often? I have to leave it in my truck, I work on construction sites so nowhere to store it and not really safe to bring it with me.. Thanks y’all!"},
{"Title": "nas motherboard with sff 8643 to 4* nvme Pcie adapter", "Author": "u/Hilarsky", "Content": "So, just after I bought 1165g7 nas from topton I found this from CWWK, which on paper looks amazing to me.\nIn theory it supports up to 6x nvme with this odd extension board you can buy with this bundle, however they're stating on product page that it doesn't support pcie 4.0 nvme drives (which sounds like bs to me )\n  \n\n    My question is , does anyone has this board ? Works ok ? Anyone seen any information regarding sff 8643 -> to pcie ? google produces only garbage results ...\n  \n\n\nhttps://www.aliexpress.com/item/1005007029671776.html?pdp_npi=4%40dis%21GBP%21%EF%BF%A1321.66%21%EF%BF%A1160.83%21%21%21398.00%21199.00%21%40210384cc17168245681252058e0b43%2112000039151333112%21sh%21UK%210%21"},
{"Title": "Can I use SATA drives directly without enclosure for data back ups?", "Author": "u/tealbull", "Content": "I'm currently in need of around 30TB of storage to archive completed project data and free up my RAID volumes, which I use for active projects.\n  \n\n    I've looked into external desktop drive options from LaCie, WD, and Seagate, but they are quite pricey. I'm considering buying 3.5inch SATA drives and using a SATA to USB connector (which I already have) to offload the data. I've found that 18TB SATA drives are significantly cheaper (2-3 times) compared to external desktop drive solutions from LaCie, WD, or Seagate.\n  \n\n    Is this a good idea? What might be some disadvantages of doing this?"},
{"Title": "What is the best (safe, but priority on space efficient) way to store a large quantity (around 1.2k) optical discs", "Author": "u/A_Big_Igloo", "Content": "Title says it. I have just shy of 1.2K discs that I have digitized for my media server, but I'd like to keep the originals in case I discover an error in digitization or server failure. I currently have four 3d printed spindles that hold around 300 each but they're uncovered and the design doesn't allow for a cover. Is anyone aware of either retail spindles that have covers that I can buy without having to buy a bunch of blank discs that I'd just throw out in a 300ish capacity, or some other space efficient storage system? I don't anticipate the need to access them any time soon, hence the spindles.\n  \n\n    I have avoided books because they are so space inefficient, I can fit twice the amount of discs in spindles that I can in the same space of books. Are there other methods that I haven't even considered?"},
{"Title": "Anyone know how to read this old disk?", "Author": "u/GloomyAction", "Content": "No content"},
{"Title": "5 TB drive went from 100 mb/s transfers to now 60", "Author": "u/Soolidus", "Content": "WD HDD. Got slower and slower the closer it got to full capacity, which I thought was normal, but I recently deleted 3 TBs worth and it's still the same. Any way to fix it? Is this normal?"},
{"Title": "Win10, how can I have more drive letters for backblaze?", "Author": "u/covered1028", "Content": "Right now I am plugging each drive 1 by 1 and have backblaze back up each drive while I figure out my setup but I will run out of drive letters soon.\n  \n\n    One solution I thought about was that when I run out of drive letters, I will reuse a drive letter and for that drive make a new folder moving all data in there so I would know what data I lost and I can restore it by going through the time machine thing."},
{"Title": "Is there a noticeable difference between 150 and 400 MB/s?", "Author": "u/cannotperson", "Content": "I'm looking at \nhttps://www.amazon.com/SanDisk-Ultra-Dual-Drive-Type-C/dp/B0842P5GG5\n and there are two options, one for 150 and another for 400 MB/s read speed. The main purpose will be storing backup files and downloaded files from the web.\n  \n\n    For a $30 USD price increase, is the 400 MB/s flash drive worth it?"},
{"Title": "What is a good program to download a neocities website?", "Author": "u/Acceptable_Cook_8112", "Content": "hey i have been struggling to download a neo cities website i want because i tried doing it with htttrack and it didnt work because it didnt give me alll the sources /; idk how to download it with the full sources. im downloading it because i wanna edit the code and modify it so it can fit my aesthetic lol"},
{"Title": "Finally built a desktop. Stuffed it with all my old laptop drives. 32TB, I may have a problem.", "Author": "u/DR650SE", "Content": "No content"},
{"Title": "Preserve online games", "Author": "u/Occhako", "Content": "Hi so a game I've been playing for 7 years, Love Live SIF, got shut down. And I lost everything that got me scared about this happening to other games i play like genshin, obey me, Honkai: Star Rail and love and deepspace.\n  \n\n    I want to be able to make a copy of the game that can run locally so that if the game ever closes it's servers i can keep playing content that i already own.\n  \n\n    So like i don't mind if there's no updates, i just don't want to lose my hardwork because the company can't afford to keep the servers or they just shut down with no explanation.\n  \n\n    How would i go about doing that or learning how to do that. If someone could point me in the right direction that would be great. I should probably stop playing these kind of games and spending money on them, but all the good mobile and PC games these days keep requiring an internet to play the game even if it's a single player."},
{"Title": "Can the \"WD_BLACK D10 Game Drive for Xbox 12TB\" be used as a normal external drive?", "Author": "u/Pinguinina", "Content": "With a PC or Mac for regular files, etc.\n  \n\n    It has Xbox branding and is bigger than the \"PC/Console version\" so I don't know if it has some sort of formatting or block built into it that prevents it from just being used as an external.\n  \n\n    I've had the 8TB for a while but I need more space. It's reasonably portable considering the size which is something I need and as far as I'm aware it includes a good drive. I'm open to alternative suggestions though but it needs to be portable and not really more expensive."},
{"Title": "Data access: SSD vs HDD once plugged in – thoughts?", "Author": "u/Future-Cod-7565", "Content": "Hello fellow hoarders,\n  \n\n    Please could someone help me with this: I have a 2TB SanDisk SSD and a 5TB Seagate HDD. Both full of data (both almost filled up). When plugged into my laptop (MacBook Pro 2017, 16GB RAM, 4 USB-C ports) the access time to the data significantly varies: while for both disks the root is readily available the moment you click the disk icon and open the drive, for the SSD drive it takes a while (sometimes rather long while, I'd say) to show the contents of a folder, while for the HDD it takes no time at all. This surprises me greatly, for what I used to think (mechanic-wise) the HDD having moving parts, spindle and platters and head to position, it should take longer to locate the data, when the SSD having no need to position the head and all that it should be a split second to give me access to the data in a folder. Can this be related to how my OS (macOS Monterey 12.7.5) accesses the drives? Anyone with the same \"issue\" (can't name it a real issue since I do have access to the data)? Please advise.\n  \n\n    Thank you!"},
{"Title": "Anyone know why my DigiBeta DVW-A510 deck is just giving blank gray for the video signal?", "Author": "u/AriFeblowitzVFX", "Content": "No content"},
{"Title": "Cheapest short term 100TB storage with good bandwidth", "Author": "u/CategoryHoliday9210", "Content": "I need to have preferably SSD of 100TB -200TB storage.\n  \n\n    Can you share where I can get the best bang for my buck?\n  \n\n    I am not planning to buy it as I don't think I can manage it for a long time. I would need it for 2-3 months and My connection speed is not great down 300mbps. So looking for online solution.\n  \n\n    Edit: since a lot people are curious about SSD, it would be various databases so speed is kind of important , I wish I could do it in RAM but SSD would do."},
{"Title": "LTO 5 Class Tape Drive or Hot Swapping a bunch of 1.2TB 2.5\" 10k SAS Drives?", "Author": "u/Empire_Fable", "Content": "Good day every one.  Thank you for letting me in the community.  I just started dabbling with archiving data\n  \n\n    I'm currently archiving some rather big compressed files 200+ GB.  Weighing some options.  I considered buying a HP LTO 5 class tape drive(Its more in my price range then the newer ones) .  Looking at the Tape media cost, I'm seeing maybe a better option to just get a bunch of hotswappable 2.5\"  1.2Tb SAS drives for a older HP dl360.  Then just hot swapping them out like tapes.  I really did want a tape drive though.  Any one know of a good benefit to a tape drive other then them being super cool?"},
{"Title": "1fichier to store 100-200gb of data in the cloud for cheap", "Author": "u/greyfeather9", "Content": "Hey, after looking at multiple services I think 1fichier seems fit. I just want to store a cloud backup of some stuff, the limiting factor is a 50gb zip with some sites having limitations on filesize, but fichier limit is 300gb. the zip will stay as is but I will be doing daily/weekly uploads of 2gb backups or so.\n  \n\n    just wanted to ask your opinion on their service, thanks."},
{"Title": "Sagittarius NAS Case Review and Build Tips", "Author": "u/Ben4425", "Content": "I recently rebuilt my NAS by moving it from a Fractal Node 804 case into the Sagittarius NAS case available from AliExpress. The Node 804 was a good case, with great temps, but swapping hard drives around was a pain. The 804 is also ginormous.\n  \n\n    So, why the Sagittarius? It met my requirements for MATX, eight externally accessible drive bays, and what appeared to be good drive cooling. I also considered:\n  \n\n\n\n\n\n    Audheid K7. Only had two 92mm fans and some reviews reported high drive temps. Also required buying a Flex PSU.\n  \n\n\n\n\n\n    Audheid 8-Bay 2023 Edition. Provides better cooling with two 120mm fans but still required a Flex PSU if you wanted all 8 drive bays.\n  \n\n\n\n\n\n    Jonsbo N4. Only 4 bays were externally accessible and it only has \none\n 120mm fan.\n  \n\n\n\n\n\n    Overall, I'm happy with the Sagittarius case. Its very compact yet it holds 8 drives, an MATX motherboard, and \nfour\n 120mm fans. My drive and CPU temps are excellent.\n  \n\n    But, you really need to plan your build because there's \nno\n documentation, no cable management, and because some connectors are hidden by other components. If you don't plug in your cables as you build then you'll never get to them later after the build is complete. You also need think about air flow which I'll discuss after documenting my build.\n  \n\n    Time for some photos, starting with the empty case.\n  \nEmpty Case\n\n    The two small rectangular holes in the upper and bottom left are all you have for routing cables from this, the motherboard side, to the hard drives on the other side. I ran 4 SATA cables through each of these holes.\n  \n\n    My motherboard mounts 4 of its SATA Ports along the edge so I had to plug those in \nbefore\n installing the motherboard itself. Otherwise, those connectors would have been practically inaccessible:\n  \nMotherboard Edge Connector Issues\n\n    The case supports two 2.5 SSD drives that are screwed to the bottom of the case. But, if you do, they will be flush to the case so plugging in cables will be near impossible. I purchased some 1/4\" nylon standoffs and longer M3-10 screws to elevate the SSDs a bit. It was still a pain to plug in the cables (because they are toward the bottom of this photo) but it worked:\n  \nhttps://preview.redd.it/sagittarius-nas-case-review-and-build-tips-v0-31oe40fbxq2d1.jpg\n\n    I routed all my SATA and fan cables next. I have 10 SATA ports total, two for SSDs and 8 for HDDs. Four of those interfaces are on an ASM-1064 PCIe add-on board and the rest are on the motherboard.\n  \n\n    Then, it was time for the power supply. I \nstrongly\n suggest using a modular SFX power supply that typically comes with shorter cables. Long, or unnecessary, cables will be an issue because there's no place to put them. Also note you should plug in the EPS power cable \nbefore\n you install the power supply because you'll never get to it afterward:\n  \nEPS Power Connector\n\n    Also make sure you route the SATA power cable before installing the power supply.\n  \n\n    Last, install the fans. Standard 25mm thickness fans just barely clear the main motherboard power cable at the bottom of this picture. Also note I installed fan grills on all my fans otherwise (for my airflow) the cables would have hit the fan blades:\n  \nFinished Interior\n\n    Now, about the \"drive sleds\". This case only provides rubber bushings and screws to fasten those bushings to the sides of your hard drives. They also provide a metal plate with a bend that acts as the handle to pull the drive from the case:\n  \n\"Drive Sled\"\n\n    This is \nreally\n basic but I found it works well.\n  \n\n    Wrapping up, here's a photo of the finished product. You can see the slots on the right that hold the rubber bushings that are attached to the hard drives.\n  \nFinal Result w/o Drive Bay Cover\n\n    I installed four 120mm Phanteks fans (from my old Node 804) into this case and \nall\n of them are configured to exhaust air \nfrom\n the case. There are two behind the grill on the left of this picture and you can see that the fan screws just go through the grating holes. Air for the left side of the case is pulled in through holes in the rear and a large grating on the left side of the case (not visible here). So, on the left, air is pulled from the side and down towards the CPU and motherboard before exhausting out the front.\n  \n\n    On the right, there are two fans behind the hard drive cage. They too exhaust air that is pulled from the front of the case, past the hard drives, and then blown out the rear. There's maybe 5mm space between the drives so airflow is unimpeded. At 22c ambient, my idle drive temps vary from 24c to 27c. Not bad!\n  \n\n    As I said earlier, I'm happy. The case is very compact (about 300x260x265 mm), holds eight 3.5\" drives, two 2.5\" SSDs, and runs cool. For about $180, which included shipping to Massachusetts, I think it was a good purchase. That said, it isn't perfect:\n  \n\n\n\n\n\n    No cable management features.\n  \n\n\n\n\n\n    No fans are included, you must provide your own.\n  \n\n\n\n\n\n    Standard ATX PSU are supported but IMHO are impractical due to the larger PSU size and longer cables. Cable management would be a \nmess\n.\n  \n\n\n\n\n\n    FYI, the case has one USB 3.0 Type A port and one USB-C port on the front. Both of these are wired to the \nsame\n USB 3.0 motherboard cable so the USB-C port will be limited to USB 3.0 speeds (5 Gbps). I.e. the USB-C port is wired to a USB 3.0 port on the motherboard."},
{"Title": "What are expected SMART values for Seagate Recertified Drives?", "Author": "u/ELO_Space", "Content": "I recently bought a Seagate Ironwolf Pro Recertified drive (ST18000nt001), and the SMART results are worrying me a bit.. In particular with the seek error rate. Is this normal for a Seagate drive and how it reports raw values, or should I return it? (2 year warranty, plus I still am in the return period)\n  \nhttps://preview.redd.it/what-are-expected-smart-values-for-seagate-recertified-v0-l756opbzlt2d1.png"},
{"Title": "Using NIB but older SSD / HDD manufactured in 2021 / 2022 ?", "Author": "u/instagigated", "Content": "Thoughts on using drives manufactured some years ago? Is there greater risk of data corruption/loss vs. using drives manufactured in the past 12 months?\n  \n\n    I received two drives recently:\n  \n\n\n\n\n\n    Sandisk 1 TB portable SSD (2021)\n  \n\n\n\n\n\n    WD 16 TB external HDD (2022)\n  \n\n\n\n\n\n    Should I return and get something manufactured more recently?"},
{"Title": "SingleFile vs Save Page WE?", "Author": "u/eldomtom2", "Content": "I'm using Save Page WE at the moment, is there a good reason to switch?"},
{"Title": "LTO5 Drive Repeatedly Clicks?", "Author": "u/1823alex", "Content": "No content"},
{"Title": "2 x Raid5 in mirror or in seperate servers and weekly backups", "Author": "u/Adorok", "Content": "i currently have 2x 16tb hdds in a mirror + a seperate disk for weekly backups (full backups, i dont want incremental backups), and the space is slowly running out. Buying bigger drives would be more expensive, than just buying 3 additional drives. I have a spare server, splitting between servers would only increase the power bill.\n  \n\n    By putting them in a mirror, i could increase read speed and have a lower electricity consumption. On the other hand, if my psu fails, all drives could theorethicaly fail at once.\n  \n\n    What do you guys think / would you do?"},
{"Title": "RAID 6 + 3, 2, 1 rule. Check my understanding?", "Author": "u/tddammo1", "Content": "Hi all, learning *much* more about RAID etc now that I'm upgrading from essentially raid 0 across 3 pi's into a new system that has the potential for 13 drive bays (at some point).\n  \n\n    As I'm learning, I want to verify I understand (some) of how the interaction of RAID 6 and the 3,2,1 rule can be applied.\n  \n\n    I'm perfectly okay with if this idea is wrong, and that's fine.\n  \n\n    Assumptions: All raid drives are 1TB, running RAID 6, using 4 drives\n  \n3 Copies\n\n\n\n\n\n    Obviously the first one is RAID 6 1TB, allowing for 2 TB storage, 2TB protection. (HDD)\n  \n\n\n\n\n\n    Second backup: Should this be *another* RAID 6 node? Or can this be a single 2TB drive (SSD)\n  \n\n\n\n\n\n    Offsite backup: Similarly, can this be a 2TB drive\n  \n\n\n\n\n\n    Essentially when using 3, 2, 1 rule should we be mimicking RAID? Or is it safe to have these drives be single drives (yes, now we've gone from double redundancy to single point of failure, which is why I'm asking)\n  \n\n    Thanks!"},
{"Title": "What are the best free tools for creating a perfect bit-for-bit copy of a CD, including copy protection?", "Author": "u/KeptinGL6", "Content": "?"},
{"Title": "my solution to hoarding music", "Author": "u/admin_NLboy", "Content": "https://github.com/nlboy1/.album-filetype\n\n\n\n    meet a tinyy new project of mine: .album, pretty simple, its just a renamed zip file which vlc can open, i think this can help some people out there who are juggling with 100+gb of flacs/mp3s or even wavs (me lol). so uuh please ggive feedback"},
{"Title": "Personal cloud storage", "Author": "u/Temporary-Fennel-785", "Content": "I have a few other friends that are fellow data hoarders, and we had a paid for google drive that held hundreds of GB of stuff that we would share back and forth. However it was apparently terminated by google (I don't have the full story, I wasn't the owner) Is there a way we could create our own server that would provide the same service? Something that could store all our files and allow our group spread across the states to access it."},
{"Title": "Mini-DV: Transcode or keep native codec?", "Author": "u/vanillapenguins", "Content": "The native codec of the video is DV25, which is neither lossless or open. For preservation purposes it would be better to transcode the video to FFV1 or another codec that is lossless, open source and commonly used.\n  \n\n    However, I have read that transcoding from DV25 does not guarantee that the technical metadata is preserved. That is data of about the camera, recording date and time, and video settings. I guess this depends on the settings - but since transcoding is more about the pixel data (?) it might not cover this extra metadata?\n  \n\n    Would you recommend me to archive the video in the native codec or transcode to a more preservation-friendly format?"},
{"Title": "Compatibility between SATA Add-On Cards & NAS OSes (TrueNAS, Unraid, etc)?", "Author": "u/McFlyParadox", "Content": "I am just starting work on my first DIY NAS. It's going to either run Plex directly, or host files for Plex (still figuring that part out). I selected the \nSilverstone CS382\n for the case, because I liked it size; that it had 8x hot swap drive bays; has a slot for a slim ODD so that I can do some limited BDR rips for cold storage; and that the motherboard tray is inverted, potentially allowing for full-length GPUs if I decide to run Plex directly (I end up transcoding a lot because I need subtitles on). The only thing I don't really care for is that the largest motherboard it can accept is mATX, which has less to do with the size and more to do with current trends that exist on modern mATX boards.\n  \n\n    Basically, most modern mATX boards seem to sacrifice SATA port count in favor of dedicating the PCIe lanes to NVMe slots instead. I get it: between their speed and lack of cables, NVMe \nare\n pretty neat (*rim shot*), but not really what I need for this build. It seems that most mATX boards top out around 4x SATA ports (LGA 1700 Intel mATX boards seem to top out at 4x; some AM5 AMD mATX boards will go up to 6x, but most are 4x), and instead offer 2-3x NVMe slots instead. So what I am wondering is this:\n  \n\n    Has anyone tried using SATA add-on cards in a situation like this? Not a RAID card, just \"here is some SATA ports and a chip a tie them into the PCIe lanes\".\n  \n\n    I've found a couple of items like the \nVantec M.2 PCIe Gen3x2 to 5 ports SATA III expansion card\n that \nlook\n like they might get me up to 9x SATA ports, which will be enough to get me my 8x hotswap bays operational and the slim ODD drive. But what I am concerned about is that 4x of the SATA ports will be \"proper\" ones on the motherboard and 5x will be \"add-ons\", and I am not sure how that might affect a RAID 5 or 6 array.\n  \n\n    Side note that may change people's answers: there is a non-zero chance that if I decide to run Plex directly on this box, I may just make it a server running Ubuntu or Windows instead, and figure out either a software RAID 5 or 6, JBOD, or just plain drives and remote backup."},
{"Title": "Backup to Google drive", "Author": "u/Low_Start_3087", "Content": "Trying to sync 5Tb 500k files to Google drive with Win10 desktop apps. It works for about 250k files but after that it seems like the sync app is broken down and nothing happens. It only utilize a lot of memory and CPU.\n  \n\n    I use the backup feature and not sync with GD.\n  \n\n    I’m aware of the 750GB a day limit and this is something else. Doing same thing with Dropbox works fine even if they have a soft 250k limit and Google drive 500k.\n  \n\n    Is there any good way to sync/backup files to Google drive? I have tried Goodsync but it constantly think most of the files has change every time I do an analyze even if they don’t.\n  \n\n    Please help! Since I have GD it would be nice to be able to use it as an extra clone of my files."},
{"Title": "New Backup Solution (Time to go LTO? Offsite)", "Author": "u/cyong", "Content": "Its time to re-evaluate the backup situation. My previous offsite backup (relatives place remote server) is no longer an option. So its time to evolve.\n  \n\n    I have about 250TB Unraid that I think I should take to a LTO setup. (Somehow...) And what I am thinking I want to do is to have some tape that I backup to once (or twice) a year and store offsite... and then another set of tapes that does more of a monthly backup and stays onsite.\n  \n\n    Given the amount of data I think LTO makes the most sense. But I honestly have no idea what to look for hardware, or software wise, or how to approach the matter in order to accomplish my goal. Do i need a desktop drive connected to PC running software there? Or a tape library in a rack? or????"},
{"Title": "Why do new PC cases have both 3.5inch and 2.5inch HDD drive mounts?", "Author": "u/SpatulaFlip", "Content": "May be a dumb question but I’m in the process of planning out my build for a home server/NAS and was looking at PC cases that can hold a decent number of drives.\n  \n\n    Why do PC cases have slots for both 3.5inch and 2.5inch drive mounts? Do people generally use both kinds in their systems? Or is it more of a space thing? Thanks 😅"},
{"Title": "Is this speed normal? I am running a Write test on HDSentinel on WD My Passport", "Author": "u/sammorrison9800", "Content": "No content"},
{"Title": "Family Archivists: Best storage for 321 backups for posterity?", "Author": "u/CharlesGoo20201210", "Content": "I'm organizing my family archives for several branches of my family tree. This is really just files and directories organized in a loose way such that different branches of the family can read or write to their \"sub-trees\". This is mainly photos, pdfs, and plain text or markdown with stories, history, and metadata.\n  \n\n    I'm primarily using Google drive (and groups and contacts) to manage all this. I realized I need to trust google less and create a 321-backup as in \nhttps://www.veeam.com/blog/321-backup-rule.html\n \"three copies, two media types, one off-site\".  Note that \"for two media types\" here means more than one provider service (i.e. not just google).\n  \n\n    Questions:\n  \n\n\n\n\n\n    Do you use a storage service that looks similar, with plain old: files, folders, users, groups, permissions (read, write, admin) that you're happy with?  That covers this requirement\n  \n\n\n\n\n\n    Do you have a good automated way to copy from google drive to create backups periodically?  That preserves security data (possibly versioning too). This could be to my own RAID/NAS at home.\n  \n\n\n\n\n\n    Is there any service in the cloud that backs up directly from google drive for you (for a price) that works well?\n  \n\n\n\n\n\n    Encryption: do you know of a seamless service that allows one to automatically add a layer of zero-trust security to particular folders on google drive (or elsewhere). E.g. Some documents are financial and sensitive enough that we'd like extra security, but it's a big pain to encrypt/decrypt these locally then upload/download to the shared area.\n  \n\n\n\n\n\n    Thanks for any insights!"},
{"Title": "A PWL solution that worked for me, and alternative drives", "Author": "u/flossy_cake", "Content": "I have the 12TB WD Red Plus drive.  It thumps every 5 seconds due to PWL.  It is annoying.  I was able to shut it up with this specific type of anti shock bracket which suspends the drive on rubber posts from all 4 sides.   You will need a 5.25\" bay in your PC case which are getting rarer these days.\n  \nAvailable at the usual places like ebay, amazon, aliexpress etc.\n\n    WARNING:  do not necessarily expect it to be a miracle solution for you straight away.  I have two 5.25\" bays and if I mount it in the top one I can still hear the thump.  If I use the bottom bay it is completely silent.   I don't know why.  I think it is something to do with resonation inside the case.   In the bottom silent bay I can put my ear right up to it and I hear no thump at all.  I can't explain it.  There is some trick to getting the drive suspended in just the right way that makes it not transfer any vibration.  I have read on some silent PC review site that people were suspending their drives in mid air inside the case with elastic bands.  Maybe it's like that.   When you are mounting the drive on the posts, inspect each post to make sure each one is making a perfect circular maximal contact patch on all 4 sides.  If one of the posts is bending slightly its contact patch will be smaller. It is easy to be slightly off and I think that affects how much vibration gets damped.\n  \n\n    Now for the alternatives:  I have two Western Digital 8TB blues (current model) which seem to not have PWL thump that I can tell.  Maybe they do, but I cannot hear it.   Or maybe it does it so rarely and quietly that I cannot tell it is happening.   But the 8TB blues have more platter spinning whoosh noise like \"hhhhhhhhhh\" so the 12TB red plus with silenced PWL is actually quieter.\n  \n\n    I will keep playing around with my top bay to get to the bottom of why it's still thumping despite the rubber mount.  Maybe one of the rubber posts went out of alignment or something.  I have it in the bottom bay right now and I can tell you there is no thump at all, none.  The drive has not gone to sleep.\n  \n\n    I was going to buy a second 12TB WD Red Plus but then I thought if they both thump every 5 seconds there is no guarantee both their thumps would be in sync so it could actually result in a thump every 2.5 seconds!   Imagine having four of them, it would be a thump every 1.25 seconds, oh my goodness!"},
{"Title": "(cross-post from HN) When would 1GB HDD have cost $100?", "Author": "u/stevecondy123", "Content": "Someone's trying to track down when a 1GB HDD would have cost $100. Figured this community may know.\n  \n\n\nhttps://news.ycombinator.com/item?id=40446887"},
{"Title": "Expanding my Nas", "Author": "u/lgittens", "Content": "A couple years ago I miss judged my storage space needs. I should have bought a 8 bay nas but only purchased a four bay. I currently run plex off a ds418. 2x8tb and 2x18tb hybrid raid. I also have a 10tb currently not being used. Not sure what my next step should be\n  \n\n\n\n\n\n    Buy a two bay raid enclosure and a 10tb drive. This should last me a couple years. However I'm not sure what to get and if this may cause some lag while streeming.\n  \n\n\n\n\n\n    Buy 2x18tb drives or larger. Then I will have 3 drives not doing anything. This seems like a big waste until I upgrade my Nas which should be in a few years\n  \n\n\n\n\n\n    2.Replace my Nas with a 8bay nas and buy another 10tb drive. This is not my favorite option as this will be the most expensive. My current Nas I would have to find a good home for.\n  \n\n    Somthing else to note is that my pc already has plenty of hd space. My goal is to use my pc for sorting and move all data to the Nas for storage.\n  \n\n    Any thoughts or suggestions would be appreciated."},
{"Title": "How to save a redgifs GIF", "Author": "u/Dragonkindren1", "Content": "Just change the watch in the url to ifr and then right click and save video"},
{"Title": "I have a horrible confession to make", "Author": "u/ByteArchivist", "Content": "I love deleting things.\n  \n\n    After I download an archive of data I love going through it and choosing what is interesting to me, or might be interesting, and what is not. Seeing the amount of free space on my drives go up as I delete things is such a fun feeling.\n  \n\n    If I ever must stand trial my only defense will be that everything I decide to keep gets saved forever in triplicate. But serial killers have their own twisted justifications for their heinous actions too.\n  \n\n    I understand this is a mortal sin here, so I will excuse myself now before being detained."},
{"Title": "How can I rip this walkthrough from this site?", "Author": "u/molitar", "Content": "https://www.yountl.xyz/biniku/walkthrough\n\n\n\n    I have never seen anyone go through such a nightmare to stop someone from copying a walkthrough."},
{"Title": "How do I merge old backups?", "Author": "u/Teh_Original", "Content": "I have maintained backups of my old computers over the years, and they are on one of my current PC's hard drives. Sometimes I was using multiple computers at the same time and they were never synchronized (and therefore have different folder structures sometimes), but had some of the same data on each computer.\n  \n\n    I'd like to merge all of my backups together (probably with my current PC's file system) and eliminate the duplicates. What's the best methodology for doing this? Are there tools for this?"},
{"Title": "Data-hoarding for the struggling college student?", "Author": "u/BigTigerM", "Content": "Hi! My name’s Tiger, and I’m struggling to keep my data stored.\n  \n\n    Every external storage device I’ve purchased has eventually had to be sent to repair services and be promptly replaced within a two to four year span - I’m now on my third harddrive, and have decided that I need a change to my approach.\n  \n\n    I am a college student with tons of personal digital memorabilia, from movies to OSTs and historical documents. After a period of time, the drives I’ve bought have consistently taken ages to mount & unmount, face a myriad of widely-spanning technical problems, and then promptly refuse to work. This has led to the decision that they will never, \never\n leave my areas of residence for fear of some whimsically-inclined failure. So I’m down on my luck, and thought I’d ask y’all for help since you folk seem dedicated enough to have some tips!! :D\n  \n\n    I suppose a list of what I’m generally looking for in a storage device would be helpful:\n  \n\n\n\n\n\n    Can be safely relocated, but incredibly rarely\n  \n\n\n\n\n\n    Can be accessed with immediacy (ie direct cables and not network shenanigans)\n  \n\n\n\n\n\n    Loads files at an incredibly accessible speed\n  \n\n\n\n\n\n    Preferably functions out of the box, some set-up is fine if it needs updates or a wizard, hesitant if it requires additional purchases\n  \n\n\n\n\n\n    Doesn’t require a 24/7 connection to a computer\n  \n\n\n\n\n\n    Is not OS-dependant, can be formatted to be read by anything\n  \n\n\n\n\n\n    Offers 5TB of storage or more\n  \n\n\n\n\n\n    Thank y’all so much for reading!! TwT If I sound douchey, do let me know."},
{"Title": "Question about usable space after raid5", "Author": "u/jchocolate99", "Content": "I'm trying to set up my new 6 bay NAS. I have four 20TB and two 4TB. When I set it up for raid 5 it says my usable space is only 20TB. Why wouldn't I have 64TB of useable space? I'm really new to all this and just trying to get an understanding"},
{"Title": "Warning: Internxt removing features and offer no refund on lifetime plans (cloud storage scam)", "Author": "u/hi-pi", "Content": "The automatic photo upload from your phone feature was the primary selling point when I chose internxt, plus what I thought was a low price for a lifetime 10TB.\n  \n\n    This feature is now removed entirely with no plan to return after I have only had the \"lifetime\" plan for 2 months. I understand things change, so I reached out to politely request a refund and they said it was out of the 30 day window for a refund. So I am 60 days into a \"lifetime\" subscription and they will not do even a partial refund, after they removed the most important feature they sold me.\n  \n\n    Amazing business plan, offer many wonderful features and then remove them once you have customers money.\n  \n\n    I would like to point out that the photo upload worked terribly and inconsistently to begin with, and I really should have canceled much sooner, but I wanted to give a new company the benefit of the doubt. Also they recently released webdav, but it requires running your own server, which kind of defeats the purpose of webdav. Practically every other service lets you upload many different ways and deal with your own encryption.\n  \n\n    I made a terrible mistake and am out $1000. I should have listened to people's warnings that Internxt was not good, and that it was a waste of money. I really was foolish and Internxt did an evil bait and switch.\n  \n\n    Do not give Internxt your money! pcloud, icecloud, koofr are all much more qualified companies"},
{"Title": "How susceptible are stored, unpowered hard drives to vibrations from a subwoofer?", "Author": "u/Gamba_Kufu_of_Huru", "Content": "So I have a little home theater with a 12\" subwoofer, and in the same room, around 3 meters away is where my hard drives are stored, in a drawer. For security reasons they need to be in this room so they can't simply be moved for now.\n  \n\n    I never play any music or movies or anything when they're plugged in and in use of course. I just want to know if they are safe from the vibrations when stored away. I listen at pretty reasonable volumes I think but ofc some movies can get very loud and bassy.\n  \n\n    They work and I have no issues or anything, it's just me being the big worrier I am am wondering if they somehow may be getting some subtle damage over time that may cause issues down the line or reduce the lifespan etc."},
{"Title": "People with really big music collections, how do you even load them in your music player?", "Author": "u/inhalingsounds", "Content": "I was thinking about this. If you have, say, 1M+ songs, even if they are mp3, how do they even load in any player? Even for foobar2000 which is very slim and optimized, wouldn't it take forever to load that amount of 10+ TB, process the metadata and have it in memory?\n  \n\n    How about players like MediaMonkey that also digest all metatags? Doesn't this volume just crash the program completely?"},
{"Title": "How to change drive enclosure but preserve the SoftRAID Volume?", "Author": "u/tealbull", "Content": "I have two U.2 SSDs in RAID 0 in my OWC Thunderbay Flex 8 using SoftRaid. I recently got an OWC U.2 Mercury Dual enclosure. I want to move these U.2 SSDs from the thunderbay to the mercury.\n  \n\n    But I want to ensure the RAID 0 volume and data remains intact. Since it is a SoftRaid volume, I’m guessing the info will carry over when I change enclosures. What are some precautions I should take? Any steps I should follow?\n  \n\n    I will definitely keep a back up of the data on the RAID 0 volume"},
{"Title": "Is getting a 4 bay NAS, using 2 slots, and then filling the 2 when I need more space possible?", "Author": "u/_cant_talk", "Content": "To save money, I’ll only buy drives for 2 slots, use raid 1, and when I need more space I’ll add more drives and use raid 5\n  \n\n    Is that possible or will changing raid configurations screw everything up?\n  \n\n    I don’t need a ton of storage right now, maybe 10TB, but I know I’ll need 40tb in the next 2 years or so"},
{"Title": "Dedicated network transfer tool?", "Author": "u/Darwinmate", "Content": "Several times a week machine(s) generate between 20 to 500gig of data that needs to be transferred to a large NAS. Currently I have an rsync script that runs continuosly monitoring for changes looped in a bash script with \n--partial\n to pick up where it left off.\n  \n\n    However this is more of a hack. \nrsync\n is more a syrnconisation tool than a dedicated network transfer tool. So while it works great, it has issues resulting from frequent dropouts. It works okay but I'm after something more robust that can withtstand network dropouts.\n  \n\n    To complicate matters, the NAS is running (ReFS)[\nhttps://en.wikipedia.org/wiki/ReFS]\n, the machines which generate the data run window10, others run weird Centos DE and finally the last one is ubuntu. All transfer to the ReFS. Ideally the tool would work on Windows/Linux/MacOS.\n  \n\n    I have only one contender: \nhttps://github.com/fast-data-transfer/fdt\n\n\n\n    Speed is not priority but stability and tracbility is.\n  \n\n    Any recommendations?"},
{"Title": "Any archive format that is particularly faster for searching/selective extraction?", "Author": "u/evolution2015", "Content": "Is there an archive format that is faster than ZIP for selectively extracting a few files or search the archive for file names when the archive is large (100GB+) and contains tens of thousands of files?"},
{"Title": "my solution to hoarding music", "Author": "u/admin_NLboy", "Content": "https://github.com/nlboy1/.album-filetype\n\n\n\n    meet a tinyy new project of mine: .album, pretty simple, its just a renamed zip file which vlc can open, i think this can help some people out there who are juggling with 100+gb of flacs/mp3s or even wavs (me lol). so uuh please ggive feedback"},
{"Title": "Personal cloud storage", "Author": "u/Temporary-Fennel-785", "Content": "I have a few other friends that are fellow data hoarders, and we had a paid for google drive that held hundreds of GB of stuff that we would share back and forth. However it was apparently terminated by google (I don't have the full story, I wasn't the owner) Is there a way we could create our own server that would provide the same service? Something that could store all our files and allow our group spread across the states to access it."},
{"Title": "Mini-DV: Transcode or keep native codec?", "Author": "u/vanillapenguins", "Content": "The native codec of the video is DV25, which is neither lossless or open. For preservation purposes it would be better to transcode the video to FFV1 or another codec that is lossless, open source and commonly used.\n  \n\n    However, I have read that transcoding from DV25 does not guarantee that the technical metadata is preserved. That is data of about the camera, recording date and time, and video settings. I guess this depends on the settings - but since transcoding is more about the pixel data (?) it might not cover this extra metadata?\n  \n\n    Would you recommend me to archive the video in the native codec or transcode to a more preservation-friendly format?"},
{"Title": "Compatibility between SATA Add-On Cards & NAS OSes (TrueNAS, Unraid, etc)?", "Author": "u/McFlyParadox", "Content": "I am just starting work on my first DIY NAS. It's going to either run Plex directly, or host files for Plex (still figuring that part out). I selected the \nSilverstone CS382\n for the case, because I liked it size; that it had 8x hot swap drive bays; has a slot for a slim ODD so that I can do some limited BDR rips for cold storage; and that the motherboard tray is inverted, potentially allowing for full-length GPUs if I decide to run Plex directly (I end up transcoding a lot because I need subtitles on). The only thing I don't really care for is that the largest motherboard it can accept is mATX, which has less to do with the size and more to do with current trends that exist on modern mATX boards.\n  \n\n    Basically, most modern mATX boards seem to sacrifice SATA port count in favor of dedicating the PCIe lanes to NVMe slots instead. I get it: between their speed and lack of cables, NVMe \nare\n pretty neat (*rim shot*), but not really what I need for this build. It seems that most mATX boards top out around 4x SATA ports (LGA 1700 Intel mATX boards seem to top out at 4x; some AM5 AMD mATX boards will go up to 6x, but most are 4x), and instead offer 2-3x NVMe slots instead. So what I am wondering is this:\n  \n\n    Has anyone tried using SATA add-on cards in a situation like this? Not a RAID card, just \"here is some SATA ports and a chip a tie them into the PCIe lanes\".\n  \n\n    I've found a couple of items like the \nVantec M.2 PCIe Gen3x2 to 5 ports SATA III expansion card\n that \nlook\n like they might get me up to 9x SATA ports, which will be enough to get me my 8x hotswap bays operational and the slim ODD drive. But what I am concerned about is that 4x of the SATA ports will be \"proper\" ones on the motherboard and 5x will be \"add-ons\", and I am not sure how that might affect a RAID 5 or 6 array.\n  \n\n    Side note that may change people's answers: there is a non-zero chance that if I decide to run Plex directly on this box, I may just make it a server running Ubuntu or Windows instead, and figure out either a software RAID 5 or 6, JBOD, or just plain drives and remote backup."},
{"Title": "Backup to Google drive", "Author": "u/Low_Start_3087", "Content": "Trying to sync 5Tb 500k files to Google drive with Win10 desktop apps. It works for about 250k files but after that it seems like the sync app is broken down and nothing happens. It only utilize a lot of memory and CPU.\n  \n\n    I use the backup feature and not sync with GD.\n  \n\n    I’m aware of the 750GB a day limit and this is something else. Doing same thing with Dropbox works fine even if they have a soft 250k limit and Google drive 500k.\n  \n\n    Is there any good way to sync/backup files to Google drive? I have tried Goodsync but it constantly think most of the files has change every time I do an analyze even if they don’t.\n  \n\n    Please help! Since I have GD it would be nice to be able to use it as an extra clone of my files."},
{"Title": "New Backup Solution (Time to go LTO? Offsite)", "Author": "u/cyong", "Content": "Its time to re-evaluate the backup situation. My previous offsite backup (relatives place remote server) is no longer an option. So its time to evolve.\n  \n\n    I have about 250TB Unraid that I think I should take to a LTO setup. (Somehow...) And what I am thinking I want to do is to have some tape that I backup to once (or twice) a year and store offsite... and then another set of tapes that does more of a monthly backup and stays onsite.\n  \n\n    Given the amount of data I think LTO makes the most sense. But I honestly have no idea what to look for hardware, or software wise, or how to approach the matter in order to accomplish my goal. Do i need a desktop drive connected to PC running software there? Or a tape library in a rack? or????"},
{"Title": "Why do new PC cases have both 3.5inch and 2.5inch HDD drive mounts?", "Author": "u/SpatulaFlip", "Content": "May be a dumb question but I’m in the process of planning out my build for a home server/NAS and was looking at PC cases that can hold a decent number of drives.\n  \n\n    Why do PC cases have slots for both 3.5inch and 2.5inch drive mounts? Do people generally use both kinds in their systems? Or is it more of a space thing? Thanks 😅"},
{"Title": "Is this speed normal? I am running a Write test on HDSentinel on WD My Passport", "Author": "u/sammorrison9800", "Content": "No content"},
{"Title": "Family Archivists: Best storage for 321 backups for posterity?", "Author": "u/CharlesGoo20201210", "Content": "I'm organizing my family archives for several branches of my family tree. This is really just files and directories organized in a loose way such that different branches of the family can read or write to their \"sub-trees\". This is mainly photos, pdfs, and plain text or markdown with stories, history, and metadata.\n  \n\n    I'm primarily using Google drive (and groups and contacts) to manage all this. I realized I need to trust google less and create a 321-backup as in \nhttps://www.veeam.com/blog/321-backup-rule.html\n \"three copies, two media types, one off-site\".  Note that \"for two media types\" here means more than one provider service (i.e. not just google).\n  \n\n    Questions:\n  \n\n\n\n\n\n    Do you use a storage service that looks similar, with plain old: files, folders, users, groups, permissions (read, write, admin) that you're happy with?  That covers this requirement\n  \n\n\n\n\n\n    Do you have a good automated way to copy from google drive to create backups periodically?  That preserves security data (possibly versioning too). This could be to my own RAID/NAS at home.\n  \n\n\n\n\n\n    Is there any service in the cloud that backs up directly from google drive for you (for a price) that works well?\n  \n\n\n\n\n\n    Encryption: do you know of a seamless service that allows one to automatically add a layer of zero-trust security to particular folders on google drive (or elsewhere). E.g. Some documents are financial and sensitive enough that we'd like extra security, but it's a big pain to encrypt/decrypt these locally then upload/download to the shared area.\n  \n\n\n\n\n\n    Thanks for any insights!"},
{"Title": "A PWL solution that worked for me, and alternative drives", "Author": "u/flossy_cake", "Content": "I have the 12TB WD Red Plus drive.  It thumps every 5 seconds due to PWL.  It is annoying.  I was able to shut it up with this specific type of anti shock bracket which suspends the drive on rubber posts from all 4 sides.   You will need a 5.25\" bay in your PC case which are getting rarer these days.\n  \nAvailable at the usual places like ebay, amazon, aliexpress etc.\n\n    WARNING:  do not necessarily expect it to be a miracle solution for you straight away.  I have two 5.25\" bays and if I mount it in the top one I can still hear the thump.  If I use the bottom bay it is completely silent.   I don't know why.  I think it is something to do with resonation inside the case.   In the bottom silent bay I can put my ear right up to it and I hear no thump at all.  I can't explain it.  There is some trick to getting the drive suspended in just the right way that makes it not transfer any vibration.  I have read on some silent PC review site that people were suspending their drives in mid air inside the case with elastic bands.  Maybe it's like that.   When you are mounting the drive on the posts, inspect each post to make sure each one is making a perfect circular maximal contact patch on all 4 sides.  If one of the posts is bending slightly its contact patch will be smaller. It is easy to be slightly off and I think that affects how much vibration gets damped.\n  \n\n    Now for the alternatives:  I have two Western Digital 8TB blues (current model) which seem to not have PWL thump that I can tell.  Maybe they do, but I cannot hear it.   Or maybe it does it so rarely and quietly that I cannot tell it is happening.   But the 8TB blues have more platter spinning whoosh noise like \"hhhhhhhhhh\" so the 12TB red plus with silenced PWL is actually quieter.\n  \n\n    I will keep playing around with my top bay to get to the bottom of why it's still thumping despite the rubber mount.  Maybe one of the rubber posts went out of alignment or something.  I have it in the bottom bay right now and I can tell you there is no thump at all, none.  The drive has not gone to sleep.\n  \n\n    I was going to buy a second 12TB WD Red Plus but then I thought if they both thump every 5 seconds there is no guarantee both their thumps would be in sync so it could actually result in a thump every 2.5 seconds!   Imagine having four of them, it would be a thump every 1.25 seconds, oh my goodness!"},
{"Title": "(cross-post from HN) When would 1GB HDD have cost $100?", "Author": "u/stevecondy123", "Content": "Someone's trying to track down when a 1GB HDD would have cost $100. Figured this community may know.\n  \n\n\nhttps://news.ycombinator.com/item?id=40446887"},
{"Title": "Expanding my Nas", "Author": "u/lgittens", "Content": "A couple years ago I miss judged my storage space needs. I should have bought a 8 bay nas but only purchased a four bay. I currently run plex off a ds418. 2x8tb and 2x18tb hybrid raid. I also have a 10tb currently not being used. Not sure what my next step should be\n  \n\n\n\n\n\n    Buy a two bay raid enclosure and a 10tb drive. This should last me a couple years. However I'm not sure what to get and if this may cause some lag while streeming.\n  \n\n\n\n\n\n    Buy 2x18tb drives or larger. Then I will have 3 drives not doing anything. This seems like a big waste until I upgrade my Nas which should be in a few years\n  \n\n\n\n\n\n    2.Replace my Nas with a 8bay nas and buy another 10tb drive. This is not my favorite option as this will be the most expensive. My current Nas I would have to find a good home for.\n  \n\n    Somthing else to note is that my pc already has plenty of hd space. My goal is to use my pc for sorting and move all data to the Nas for storage.\n  \n\n    Any thoughts or suggestions would be appreciated."},
{"Title": "How to save a redgifs GIF", "Author": "u/Dragonkindren1", "Content": "Just change the watch in the url to ifr and then right click and save video"},
{"Title": "I have a horrible confession to make", "Author": "u/ByteArchivist", "Content": "I love deleting things.\n  \n\n    After I download an archive of data I love going through it and choosing what is interesting to me, or might be interesting, and what is not. Seeing the amount of free space on my drives go up as I delete things is such a fun feeling.\n  \n\n    If I ever must stand trial my only defense will be that everything I decide to keep gets saved forever in triplicate. But serial killers have their own twisted justifications for their heinous actions too.\n  \n\n    I understand this is a mortal sin here, so I will excuse myself now before being detained."},
{"Title": "How can I rip this walkthrough from this site?", "Author": "u/molitar", "Content": "https://www.yountl.xyz/biniku/walkthrough\n\n\n\n    I have never seen anyone go through such a nightmare to stop someone from copying a walkthrough."},
{"Title": "How do I merge old backups?", "Author": "u/Teh_Original", "Content": "I have maintained backups of my old computers over the years, and they are on one of my current PC's hard drives. Sometimes I was using multiple computers at the same time and they were never synchronized (and therefore have different folder structures sometimes), but had some of the same data on each computer.\n  \n\n    I'd like to merge all of my backups together (probably with my current PC's file system) and eliminate the duplicates. What's the best methodology for doing this? Are there tools for this?"},
{"Title": "Data-hoarding for the struggling college student?", "Author": "u/BigTigerM", "Content": "Hi! My name’s Tiger, and I’m struggling to keep my data stored.\n  \n\n    Every external storage device I’ve purchased has eventually had to be sent to repair services and be promptly replaced within a two to four year span - I’m now on my third harddrive, and have decided that I need a change to my approach.\n  \n\n    I am a college student with tons of personal digital memorabilia, from movies to OSTs and historical documents. After a period of time, the drives I’ve bought have consistently taken ages to mount & unmount, face a myriad of widely-spanning technical problems, and then promptly refuse to work. This has led to the decision that they will never, \never\n leave my areas of residence for fear of some whimsically-inclined failure. So I’m down on my luck, and thought I’d ask y’all for help since you folk seem dedicated enough to have some tips!! :D\n  \n\n    I suppose a list of what I’m generally looking for in a storage device would be helpful:\n  \n\n\n\n\n\n    Can be safely relocated, but incredibly rarely\n  \n\n\n\n\n\n    Can be accessed with immediacy (ie direct cables and not network shenanigans)\n  \n\n\n\n\n\n    Loads files at an incredibly accessible speed\n  \n\n\n\n\n\n    Preferably functions out of the box, some set-up is fine if it needs updates or a wizard, hesitant if it requires additional purchases\n  \n\n\n\n\n\n    Doesn’t require a 24/7 connection to a computer\n  \n\n\n\n\n\n    Is not OS-dependant, can be formatted to be read by anything\n  \n\n\n\n\n\n    Offers 5TB of storage or more\n  \n\n\n\n\n\n    Thank y’all so much for reading!! TwT If I sound douchey, do let me know."},
{"Title": "Question about usable space after raid5", "Author": "u/jchocolate99", "Content": "I'm trying to set up my new 6 bay NAS. I have four 20TB and two 4TB. When I set it up for raid 5 it says my usable space is only 20TB. Why wouldn't I have 64TB of useable space? I'm really new to all this and just trying to get an understanding"},
{"Title": "Warning: Internxt removing features and offer no refund on lifetime plans (cloud storage scam)", "Author": "u/hi-pi", "Content": "The automatic photo upload from your phone feature was the primary selling point when I chose internxt, plus what I thought was a low price for a lifetime 10TB.\n  \n\n    This feature is now removed entirely with no plan to return after I have only had the \"lifetime\" plan for 2 months. I understand things change, so I reached out to politely request a refund and they said it was out of the 30 day window for a refund. So I am 60 days into a \"lifetime\" subscription and they will not do even a partial refund, after they removed the most important feature they sold me.\n  \n\n    Amazing business plan, offer many wonderful features and then remove them once you have customers money.\n  \n\n    I would like to point out that the photo upload worked terribly and inconsistently to begin with, and I really should have canceled much sooner, but I wanted to give a new company the benefit of the doubt. Also they recently released webdav, but it requires running your own server, which kind of defeats the purpose of webdav. Practically every other service lets you upload many different ways and deal with your own encryption.\n  \n\n    I made a terrible mistake and am out $1000. I should have listened to people's warnings that Internxt was not good, and that it was a waste of money. I really was foolish and Internxt did an evil bait and switch.\n  \n\n    Do not give Internxt your money! pcloud, icecloud, koofr are all much more qualified companies"},
{"Title": "How susceptible are stored, unpowered hard drives to vibrations from a subwoofer?", "Author": "u/Gamba_Kufu_of_Huru", "Content": "So I have a little home theater with a 12\" subwoofer, and in the same room, around 3 meters away is where my hard drives are stored, in a drawer. For security reasons they need to be in this room so they can't simply be moved for now.\n  \n\n    I never play any music or movies or anything when they're plugged in and in use of course. I just want to know if they are safe from the vibrations when stored away. I listen at pretty reasonable volumes I think but ofc some movies can get very loud and bassy.\n  \n\n    They work and I have no issues or anything, it's just me being the big worrier I am am wondering if they somehow may be getting some subtle damage over time that may cause issues down the line or reduce the lifespan etc."},
{"Title": "People with really big music collections, how do you even load them in your music player?", "Author": "u/inhalingsounds", "Content": "I was thinking about this. If you have, say, 1M+ songs, even if they are mp3, how do they even load in any player? Even for foobar2000 which is very slim and optimized, wouldn't it take forever to load that amount of 10+ TB, process the metadata and have it in memory?\n  \n\n    How about players like MediaMonkey that also digest all metatags? Doesn't this volume just crash the program completely?"},
{"Title": "How to change drive enclosure but preserve the SoftRAID Volume?", "Author": "u/tealbull", "Content": "I have two U.2 SSDs in RAID 0 in my OWC Thunderbay Flex 8 using SoftRaid. I recently got an OWC U.2 Mercury Dual enclosure. I want to move these U.2 SSDs from the thunderbay to the mercury.\n  \n\n    But I want to ensure the RAID 0 volume and data remains intact. Since it is a SoftRaid volume, I’m guessing the info will carry over when I change enclosures. What are some precautions I should take? Any steps I should follow?\n  \n\n    I will definitely keep a back up of the data on the RAID 0 volume"},
{"Title": "Is getting a 4 bay NAS, using 2 slots, and then filling the 2 when I need more space possible?", "Author": "u/_cant_talk", "Content": "To save money, I’ll only buy drives for 2 slots, use raid 1, and when I need more space I’ll add more drives and use raid 5\n  \n\n    Is that possible or will changing raid configurations screw everything up?\n  \n\n    I don’t need a ton of storage right now, maybe 10TB, but I know I’ll need 40tb in the next 2 years or so"},
{"Title": "Dedicated network transfer tool?", "Author": "u/Darwinmate", "Content": "Several times a week machine(s) generate between 20 to 500gig of data that needs to be transferred to a large NAS. Currently I have an rsync script that runs continuosly monitoring for changes looped in a bash script with \n--partial\n to pick up where it left off.\n  \n\n    However this is more of a hack. \nrsync\n is more a syrnconisation tool than a dedicated network transfer tool. So while it works great, it has issues resulting from frequent dropouts. It works okay but I'm after something more robust that can withtstand network dropouts.\n  \n\n    To complicate matters, the NAS is running (ReFS)[\nhttps://en.wikipedia.org/wiki/ReFS]\n, the machines which generate the data run window10, others run weird Centos DE and finally the last one is ubuntu. All transfer to the ReFS. Ideally the tool would work on Windows/Linux/MacOS.\n  \n\n    I have only one contender: \nhttps://github.com/fast-data-transfer/fdt\n\n\n\n    Speed is not priority but stability and tracbility is.\n  \n\n    Any recommendations?"},
{"Title": "Any archive format that is particularly faster for searching/selective extraction?", "Author": "u/evolution2015", "Content": "Is there an archive format that is faster than ZIP for selectively extracting a few files or search the archive for file names when the archive is large (100GB+) and contains tens of thousands of files?"},
{"Title": "It's been nine years since this post.  What do people think of this idea now?", "Author": "u/Canttalkwhatsapponly", "Content": "Ex: If you buy a 64GB iPhone, you should get 64GB of space on iCloud for free.\n  \n\n    This would encourage people to buy higher capacity phones meaning Apple will make more profit which they can spend on cloud maintenance and expansion etc.. Its a win-win for everyone"},
{"Title": "Help needed for Datahoarding via NAS", "Author": "u/i_xm_nxsh", "Content": "Hey everyone! I did my research and narrowed it down to Synology 923+ to start my data hoarding journey however I recently came across a PC built to use as NAS.\n  \n\n    Now, because of this, I am a bit confused as to which one should I go for since the PC helps me save a lot of money. However, I am not that knowledgeable when it comes to using NAS via TrueNAS, maintaining my NAS-related PC setup etc. I have used a Windows PC Tower (with monitor) in the past but I only used it for 7 years (without any major issues) and changed to a laptop.\n  \n\n    It will be really helpful to know if the PC setup given below is a good choice for its price, good for my use case and if it will consume too much power as a NAS or not. This person is looking for $240 (probably can give the system to me for $220). Below are the system specs with my comments in (brackets):\n  \n\n    CPU: AMD Phenom II X6 1055T 6 Core Processor\n  \n\n    Memory: 16GB (4x4GB) DDR3 (brand not mentioned)\n  \n\n    HBA: LSI SAS[hidden information]i Flashed to IT Mode and acted as a HBA (no idea what this is)\n  \n\n    Supports 8x SATA/SAS 6gb/s Drives. Two SFF_8087 Breakout cables are included.\n  \n\n    Motherboard: Gigabyte GA-890GPA-UD3H with Tower CPU Cooler\n  \n\n    Case: Fractal Design Define R3 with 8 bays for HDDs\n  \n\n    Power Supply: Seasonic 550W PSU\n  \n\n    Thank you so much for reading this far and if you want to read further to know my use cases then here it is:\n  \n\n    My wife is a beginner in photography. She started 2 years back and now has over ~400 GB of photos. I know it's not much but we know that she will need more space soon.\n  \n\n    I have been using Plex (with Plex Pass) through an old laptop which has 2 TB HDD+SSD combined. Sadly, I have to delete videos to make space for new ones.\n  \n\n    I am planning on getting 24TB (8x3) drives to tackle both the use cases mentioned above.\n  \n\n    Thanks in advance for your responses!"},
{"Title": "LTO Tape Capacity - Do tapes lose capacity with use and age?", "Author": "u/fgt67cam", "Content": "I recently purchased a used LTO-5 tape drive and some used tapes. LTO-5 has a rated capacity of 1.5TB (1.36TiB). When I've been writing data to these tapes (uncompressed) and they seem to cap at 1300 GiB which seems to be ~90GiB short. I write the tapes using the command:\n  \ntar cvf - /files-to-write 2> >(tee /Tape.log >&2) | mbuffer -m 14G -L -P 80 > /dev/st0\n\n    I recorded how much data was written to each different tape before I got the \"tar: Exiting with failure status due to previous errors\" message which usually means it has reached the end of the tape and can no longer write anything.\n  \nTape 1: 1391776710636 bytes (1296 GiB)\nTape 2: 1424535198256 bytes (1326 GiB)\nTape 3: 1334993518029 bytes (1243 GiB)\nTape 4: 1383193282217 bytes (1292 GiB)\n\n    The tape drive I'm using is heavily used as well as the tapes. This is the sg_log for one of them:\n  \n    HP        Ultrium 5-SCSI    I6CZ\n\nSupported log pages  [0x0]:\n    0x00        Supported log pages [sp]\n    0x02        Write error [we]\n    0x03        Read error [re]\n    0x0c        Sequential access device [sad]\n    0x0d        Temperature [temp]\n    0x11        DT Device status [dtds]\n    0x12        Tape alert response [tar]\n    0x13        Requested recovery [rr]\n    0x14        Device statistics [ds]\n    0x15        Service buffers information [sbi]\n    0x16        Tape diagnostic data [tdd]\n    0x17        Volume statistics [vs]\n    0x18        Protocol specific port [psp]\n    0x1b        Data compression [dc]\n    0x2e        Tape alert [ta]\n    0x30        Tape usage (lto-5, 6) [tu_]\n    0x31        Tape capacity (lto-5, 6) [tc_]\n    0x32        Data compression (lto-5) [dc_]\n    0x34        Read forward errors (lto-5) [rfe_]\n    0x35        DT Device Error (lto-5, 6) [dtde_]\n    0x3e        Device Status (lto-5, 6) [ds_]\n\nWrite error counter page  [0x2]\n  Errors corrected without substantial delay = 0\n  Errors corrected with possible delays = 0\n  Total rewrites or rereads = 0\n  Total errors corrected = 0\n  Total times correction algorithm processed = 0\n  Total bytes processed = 0\n  Total uncorrected errors = 0\n\nRead error counter page  [0x3]\n  Errors corrected without substantial delay = 0\n  Errors corrected with possible delays = 0\n  Total rewrites or rereads = 0\n  Total errors corrected = 0\n  Total times correction algorithm processed = 0\n  Total bytes processed = 0\n  Total uncorrected errors = 0\n\nSequential access device page (ssc-3)\n  Data bytes received with WRITE commands: 0 GB\n  Data bytes written to media by WRITE commands: 0 GB\n  Data bytes read from media by READ commands: 0 GB\n  Data bytes transferred by READ commands: 0 GB\n  Native capacity from BOP to EOD: 1527775 MB\n  Native capacity from BOP to EW of current partition: 1517690 MB\n  Minimum native capacity from EW to EOP of current partition: 12239 MB\n  Native capacity from BOP to current position: 17654 MB\n  Maximum native capacity in device object buffer: 206 MB\n  Cleaning action not required (or completed)\n\nTemperature page  [0xd]\n  Current temperature = 41 C\n  Reference temperature = <not available>\n\nDT device status page (ssc-3, adc-3) [0x11]\n  Very high frequency data:\n  PAMR=0 HUI=0 MACC=1 CMPR=1 WRTP=0 CRQST=0 CRQRD=0 DINIT=1\n  INXTN=0 RAA=0 MPRSNT=1 MSTD=1 MTHRD=1 MOUNTED=1\n  DT device activity: No DT device activity\n  VS=0 TDDEC=0 EPP=0 ESR=0 RRQST=0 INTFC=0 TAFC=0\n  Very high frequency polling delay:  16 milliseconds\n   DT device ADC data encryption control status (hex only now):\n 00     00 00 00 00 00 00 00 00\n   Key management error data (hex only now):\n 00     00 00 00 00 00 00 00 00  00 00 00 00\n  Primary port 1 status:\n    non-SAS transport, in hex:\n 00     00 00 00 00 00 00 00 00  50 01 10 a0 01 4a a5 9c    ........P....J..\n 10     50 01 10 a0 01 4a a5 9e                             P....J..\n  Primary port 2 status:\n    non-SAS transport, in hex:\n 00     3b 00 00 01 00 00 00 01  50 01 10 a0 01 4a a5 9d    ;.......P....J..\n 10     50 01 10 a0 01 4a a5 9e                             P....J..\n  Primary port 3 status:\n    non-SAS transport, in hex:\n 00     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00    ................\n 10     00 00 00 00 00 00 00 00                             ........\n  Primary port 4 status:\n    non-SAS transport, in hex:\n 00     02 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00    ................\n 10     00 00 00 00 00 00 00 00                             ........\n  Vendor specific [parameter_code=0x8000]:\n 00     80 00 43 06 31 17 00 00  00 02                      ..C.1.....\n  Vendor specific [parameter_code=0x8003]:\n 00     80 03 43 08 00 00 00 00  00 00 00 00                ..C.........\n  Vendor specific [parameter_code=0x8010]:\n 00     80 10 43 08 00 00 00 00  00 00 00 00                ..C.........\n  Vendor specific [parameter_code=0x8020]:\n 00     80 20 43 12 00 00 00 00  00 00 00 00 00 00 00 00    . C.............\n 10     00 00 00 00 00 00                                   ......\n  Vendor specific [parameter_code=0xa101]:\n 00     a1 01 43 04 00 00 00 00                             ..C.....\n  Vendor specific [parameter_code=0xa102]:\n 00     a1 02 43 04 00 00 00 00                             ..C.....\n\nTapeAlert response page (ssc-3, adc-3) [0x12]\n  Flag01h: 0  02h: 0  03h: 0  04h: 0  05h: 0  06h: 0  07h: 0  08h: 0\n  Flag09h: 0  0Ah: 0  0Bh: 0  0Ch: 0  0Dh: 0  0Eh: 0  0Fh: 0  10h: 0\n  Flag11h: 0  12h: 0  13h: 0  14h: 0  15h: 0  16h: 0  17h: 0  18h: 0\n  Flag19h: 0  1Ah: 0  1Bh: 0  1Ch: 0  1Dh: 0  1Eh: 0  1Fh: 0  20h: 0\n  Flag21h: 0  22h: 0  23h: 0  24h: 0  25h: 0  26h: 0  27h: 0  28h: 0\n  Flag29h: 0  2Ah: 0  2Bh: 0  2Ch: 0  2Dh: 0  2Eh: 0  2Fh: 0  30h: 0\n  Flag31h: 0  32h: 0  33h: 0  34h: 0  35h: 0  36h: 0  37h: 0  38h: 0\n  Flag39h: 0  3Ah: 0  3Bh: 0  3Ch: 0  3Dh: 0  3Eh: 0  3Fh: 0  40h: 0\n\nRequested recovery page (ssc-3) [0x13]\n  Recovery procedures:\n    Recovery not requested\n\nDevice statistics page (ssc-3 and adc)\n  Lifetime media loads: 5288\n  Lifetime cleaning operations: 195\n  Lifetime power on hours: 48480\n  Lifetime media motion (head) hours: 12747\n  Lifetime metres of tape processed: 187049835\n  Lifetime media motion (head) hours when incompatible media last loaded: 0\n  Lifetime power on hours when last temperature condition occurred: 0\n  Lifetime power on hours when last power consumption condition occurred: 0\n  Media motion (head) hours since last successful cleaning operation: 66\n  Media motion (head) hours since 2nd to last successful cleaning: 126\n  Media motion (head) hours since 3rd to last successful cleaning: 187\n  Lifetime power on hours when last operator initiated forced reset\n    and/or emergency eject occurred: 20048\n  Lifetime power cycles: 77\n  Volume loads since last parameter reset: 5288\n  Hard write errors: 2\n  Hard read errors: 0\n  Duty cycle sample time (ms): 27276000\n  Read duty cycle: 0\n  Write duty cycle: 0\n  Activity duty cycle: 76\n  Volume not present duty cycle: 15\n  Drive manufacturer's serial number: 0\n  Drive serial number: 0\n  Medium removal prevented: 0\n  Maximum recommended mechanism temperature exceeded: 0\n  Media motion (head) hours for each medium type:\n    Density code: 0x44, Medium type: 0x0\n      Medium motion hours: 0\n    Density code: 0x44, Medium type: 0x1\n      Medium motion hours: 0\n    Density code: 0x46, Medium type: 0x0\n      Medium motion hours: 0\n    Density code: 0x46, Medium type: 0x1\n      Medium motion hours: 0\n    Density code: 0x58, Medium type: 0x0\n      Medium motion hours: 12747\n    Density code: 0x58, Medium type: 0x1\n      Medium motion hours: 0\n\nService buffer information page (adc-3) [0x15]\n  Service buffer identifier: 0x0\n    Buffer id: 0x41, tu=0, nmp=0, nmm=0, offline=0\n    pd=0, code_set: Binary, Service buffer title:\n      DT Device Error Log\n\nTape diagnostics data page (ssc-3) [0x16]\n  Parameter code: 0\n    Density code: 0x58\n    Medium type: 0x0\n    Lifetime media motion hours: 12739\n    Repeat: 0\n    Sense key: 0x3 [Medium Error]\n    Additional sense code: 0x0\n    Additional sense code qualifier: 0x2\n      [Additional sense: End-of-partition/medium detected]\n    Vendor specific code qualifier: 0x5098\n    Product revision level: 1228292954\n    Hours since last clean: 58\n    Operation code: 0x1d\n    Service action: 0x0\n    Medium id number (in hex):\n 00     49 43 32 47 4f 42 6e 36  38 30 00 00 00 00 00 00    IC2GOBn680......\n 10     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00    ................\n    Timestamp origin: 0x0\n    Timestamp:\n 00     00 00 00 09 6f 65\n  Parameter code: 1\n    Density code: 0x58\n    Medium type: 0x0\n    Lifetime media motion hours: 11121\n    Repeat: 0\n    Sense key: 0x3 [Medium Error]\n    Additional sense code: 0xc\n    Additional sense code qualifier: 0x0\n      [Additional sense: Write error]\n    Vendor specific code qualifier: 0x5083\n    Product revision level: 1228292954\n    Hours since last clean: 67\n    Operation code: 0x0\n    Service action: 0x0\n    Medium id number (in hex):\n 00     41 44 37 48 52 56 4e 55  58 4e 00 00 00 00 00 00    AD7HRVNUXN......\n 10     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00    ................\n    Timestamp origin: 0x0\n    Timestamp:\n 00     00 00 fb 62 2c 3e\n  Parameter code: 2\n    Density code: 0x58\n    Medium type: 0x0\n    Lifetime media motion hours: 1261\n    Repeat: 0\n    Sense key: 0x3 [Medium Error]\n    Additional sense code: 0x14\n    Additional sense code qualifier: 0x0\n      [Additional sense: Recorded entity not found]\n    Vendor specific code qualifier: 0x5090\n    Product revision level: 1228290394\n    Hours since last clean: 167\n    Operation code: 0x11\n    Service action: 0x0\n    Medium id number (in hex):\n 00     41 44 37 48 52 56 4e 55  32 4d 00 00 00 00 00 00    AD7HRVNU2M......\n 10     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00    ................\n    Timestamp origin: 0x0\n    Timestamp:\n 00     00 00 00 c9 22 70\n\nVolume statistics page (ssc-4), subpage=0\n  Page valid: 1\n  Thread count: 162\n  Total data sets written: 2916336\n  Total write retries: 20\n  Total unrecovered write errors: 0\n  Total suspended writes: 11\n  Total fatal suspended writes: 0\n  Total data sets read: 1579246\n  Total read retries: 154\n  Total unrecovered read errors: 0\n  Last mount unrecovered write errors: 0\n  Last mount unrecovered read errors: 0\n  Last mount megabytes written: 0\n  Last mount megabytes read: 0\n  Lifetime megabytes written: 7209299\n  Lifetime megabytes read: 3903959\n  Last load write compression ratio: 0\n  Last load read compression ratio: 0\n  Medium mount time: 136669\n  Medium ready time: 136669\n  Total native capacity [MB]: 1529930\n  Total used native capacity [MB]: 1527775\n  Volume serial number: E111229096\n  Tape lot identifier: H1080121\n  Volume barcode: SN3018L5\n  Volume manufacturer: SONY\n  Volume license code: U109\n  Volume personality: Ultrium-5\n  Write protect: 0\n  WORM: 0\n  Maximum recommended tape path temperature exceeded: 0\n  Beginning of medium passes: 1231\n  Middle of medium passes: 929\n  Logical position of first encrypted logical object:\n    partition number: 0, partition record data counter: 0xffffffffffff\n  Logical position of first unencrypted logical object after first\n  encrypted logical object:\n    partition number: 0, partition record data counter: 0xffffffffffff\n  Native capacity partition(s) [MB]:\n    partition number: 0, partition record data counter: 1529930\n  Used native capacity partition(s) [MB]:\n    partition number: 0, partition record data counter: 1527775\n  Vendor specific parameter code (0xf000), payload in hex\n 00     00 01                                               ..\n\n\nData compression page  (ssc-4) [0x1b]\n  Read compression ratio x100: 0\n  Write compression ratio x100: 0\n  Megabytes transferred to server: 0\n  Bytes transferred to server: 0\n  Megabytes read from tape: 0\n  Bytes read from tape: 0\n  Megabytes transferred from server: 0\n  Bytes transferred from server: 0\n  Megabytes written to tape: 0\n  Bytes written to tape: 0\n  Data compression enabled: 0x1\n\nTape alert page (ssc-3) [0x2e]\n  Read warning: 0\n  Write warning: 0\n  Hard error: 0\n  Media: 0\n  Read failure: 0\n  Write failure: 0\n  Media life: 0\n  Not data grade: 0\n  Write protect: 0\n  No removal: 0\n  Cleaning media: 0\n  Unsupported format: 0\n  Recoverable mechanical cartridge failure: 0\n  Unrecoverable mechanical cartridge failure: 0\n  Memory chip in cartridge failure: 0\n  Forced eject: 0\n  Read only format: 0\n  Tape directory corrupted on load: 0\n  Nearing media life: 0\n  Cleaning required: 0\n  Cleaning requested: 0\n  Expired cleaning media: 0\n  Invalid cleaning tape: 0\n  Retension requested: 0\n  Dual port interface error: 0\n  Cooling fan failing: 0\n  Power supply failure: 0\n  Power consumption: 0\n  Drive maintenance: 0\n  Hardware A: 0\n  Hardware B: 0\n  Interface: 0\n  Eject media: 0\n  Microcode update fail: 0\n  Drive humidity: 0\n  Drive temperature: 0\n  Drive voltage: 0\n  Predictive failure: 0\n  Diagnostics required: 0\n  Obsolete (28h): 0\n  Obsolete (29h): 0\n  Obsolete (2Ah): 0\n  Obsolete (2Bh): 0\n  Obsolete (2Ch): 0\n  Obsolete (2Dh): 0\n  Obsolete (2Eh): 0\n  Reserved (2Fh): 0\n  Reserved (30h): 0\n  Reserved (31h): 0\n  Lost statistics: 0\n  Tape directory invalid at unload: 0\n  Tape system area write failure: 0\n  Tape system area read failure: 0\n  No start of data: 0\n  Loading failure: 0\n  Unrecoverable unload failure: 0\n  Automation interface failure: 0\n  Firmware failure: 0\n  WORM medium - integrity check failed: 0\n  WORM medium - overwrite attempted: 0\n  Reserved parameter code 0x3d, flag: 0\n  Reserved parameter code 0x3e, flag: 0\n  Reserved parameter code 0x3f, flag: 0\n  Reserved parameter code 0x40, flag: 0\n\nTape usage page  (LTO-5 and LTO-6 specific) [0x30]\n  Thread count: 162\n  Total data sets written: 2916336\n  Total write retries: 20\n  Total unrecovered write errors: 0\n  Total suspended writes: 11\n  Total fatal suspended writes: 0\n  Total data sets read: 1579246\n  Total read retries: 154\n  Total unrecovered read errors: 0\n\nTape capacity page  (LTO-5 and LTO-6 specific) [0x31]\n  Main partition remaining capacity (in MiB): 2056\n  Alternate partition remaining capacity (in MiB): 0\n  Main partition maximum capacity (in MiB): 1459056\n  Alternate partition maximum capacity (in MiB): 0\n\nData compression page  (LTO-5 specific) [0x32]\n  Read compression ratio x100: 0\n  Write compression ratio x100: 0\n  Megabytes transferred to server: 0\n  Bytes transferred to server: 0\n  Megabytes read from tape: 0\n  Bytes read from tape: 0\n  Megabytes transferred from server: 0\n  Bytes transferred from server: 0\n  Megabytes written to tape: 0\n  Bytes written to tape: 0\n\nUnable to decode page = 0x34, here is hex:\n 00     34 00 00 1e 00 00 60 02  00 00 00 01 60 02 00 00\n 10     00 02 60 02 00 00 00 03  60 02 00 00 00 04 40 02\n 20     05 78\n\nUnable to decode page = 0x35, here is hex:\n 00     35 00 00 74 00 00 43 16  00 00 00 00 00 00 00 00\n 10     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 01\n 20     43 56 00 00 00 00 00 00  00 00 00 00 00 00 00 00\n 30     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00\n 40     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00\n 50     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00\n 60     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00\n 70     00 00 00 00 00 00 00 00\n\nUnable to decode page = 0x3e, here is hex:\n 00     3e 00 00 28 00 00 40 04  00 00 00 00 00 01 40 04\n 10     00 05 01 00 00 02 60 04  00 00 14 a8 00 03 40 04\n 20     ff ff ff ff 00 04 40 04  01 09 02 23\n\n    The tapes write speed is sporadic throughout with writes speeds ranging from 140/MBs all the way down to 40/MBs with the mbuffer 100% remaining full so it's not being starved for data. I don't have any brand new tapes to use or a second tape drive so is it normal for used tapes to lose a lot of capacity and I will just have to account for this with a safer space margin?"},
{"Title": "Loudest HDD available?", "Author": "u/Western_Bass_1491", "Content": "I am giving a iMac a massive storage boost, however all the HDD’s I have are decently quiet. I am looking for one to give it the classic HDD sound, and that actually still exists and isn’t impossible to find. I don’t care about speed or rpm, just the sound and one that won’t make me broke lol"},
{"Title": "New Hard drives not detecting (Not usual issues)", "Author": "u/may9899999", "Content": "I have a PCIE to sata card that supports 8 drives. I had 5 installed on the card that all worked fine. I bought 3 new drives but they aren't being detected. I've tried changed cables with no effect. I've tried adding one at a time, nothing. I'm only seeing the original 5 no matter what I do. I thought maybe unplugging and old one and trying a new one could potentially let me know if I had too many, but then only the 4 drives showed up. They don't show up with fdisk -l, the don't show up in disks or gparted. I tried a USB enclosure to initialize them to see if that would help, and they did initialize, but once connected back to SATA, they don't show up. I'm just really at a loss of what's going on at this point. Below is the link to my previous post that I made trying to fix this issue. OS is Ubuntu 22.04\n  \n\n\nhttps://www.reddit.com/r/Ubuntu/comments/1cz2jlb/new_hard_drive_not_showing_up/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button\n\n\n\n    Edit Issue solved below, TLDR: I needed an adapter power cable (which came in the box but looked like just an extension)"},
{"Title": "Anyone experimented with p2p storage for backup purposes?", "Author": "u/The_B0rg", "Content": "I'm mostly talking about IPFS and systems built on top of it like filecoin and hivenet, both commercial solutions that provide file storage with guarantees over IPFS.\n  \n\n    You can pay in money but lower your costs by providing storage in return in a P2P fashion.\n  \n\n    I truly believe these kinds of services will only get better and are a big part of the future of the internet and data storage. The question is if anyone already has any experience with them and if they are already good enough or not?"},
{"Title": "WD BLACK Hard Drive Failure", "Author": "u/Majestic-Owl-5801", "Content": "I was transferring files from one hard drive to another and had to end the process, but now I cant open up the hard drive I was transferring files from.\n  \n\n    I am sure I corrupted something by ending the process, but it ended on one of the windows that asked to clear space to continue. So it was on a single file rather than in the middle of a file. I clicked skip for all remaining and it froze, it was quite a lot of files. I closed the window because it was frozen, and now it wont show me the files on the drive.\n  \n\n    It will load, show me the remaining space taken up, but wont load any files when I actually open the drive in explorer."},
{"Title": "Best practices with Terracopy? Verify and checksum?", "Author": "u/Bern_Down_the_DNC", "Content": "First time using Teracopy. I was recommended to use this since I can check \"verify files\" and it will do that after copying files on drive 1 and syncing to drive 2.\n  \n\n    Nobody said anything about checksum files. Not sure if it would be beneficial. I will rename files or add more files to the directory later on drive 1, then sync all the files to drive 2 again.\n  \n\n    If I need to do checksum, would I create a checksum for folders on drive 1, then start copy and sync to drive 2 but select \"do checksum at the end\" so it generates a second checksum on drive 2 that I can compare to the checksum from drive 1?\n  \n\n    Also do I need to choose \"store/verify checksum on ADS\"? (And should I use xx3-64 instead of MD5 now?)\n  \n\n    Thank you!"},
{"Title": "I want to expand my zpool in both size and efficiency, could you please help me?", "Author": "u/mathscasual", "Content": "Right  now I have two 16 TB hdds mirrored in raid 1. I want to change my raid configuration to increase speed and size. Give me an excuse to buy 6 more drives(or more) so I have both increased size and speed.\n  \n\n    What raid configuration?\n  \n\n    How many more drives?(can they be larger than 16Tb(was looking at 22TBs)\n  \n\n    cacching?\n  \n\n    Many pleases and thank yous"},
{"Title": "Can you still get Yoyotta with a lifetime license or is it all subscriptions?", "Author": "u/DevilryAscended", "Content": "I saw this post from 6 years ago,\n  \n\n\nhttps://www.reddit.com/r/DataHoarder/comments/a2k5y4/hoarding_to_lto_tape_primer_all_you_wanted_to/\n\n\n\n    Where it listed a price that is definitely higher than their current subscription price. Does anyone know when they made the change? I'm currently doing research into LTO backups/archiving as an option for system we're building out and a key thing I would like to avoid is any subscriptions but I did like how well documented using Yoyotta seemed."},
{"Title": "(UK) 18TB WD Elements @ £14.3 per TB on WD Website", "Author": "u/mrnngbgs", "Content": "You get £50 off if you spend over £300 on WD website. If you pair WD Elements 18TB (currently discounted at £297.99) with their 2 year data recovery plan (£10), you will only pay £258 which equals to £14.33 per TB.\n  \n\n    Finally a good deal! (UK)\n  \n\n    Ends 27th of May"},
{"Title": "How much data duplication do you have? Do you really follow 3-2-1 at home?", "Author": "u/pm_me_xenomorphs", "Content": "For example, i have 3 copies of all my drives that i care about. I have 1 copy on my NAS, 1 copy offline for regular backups and another copy offsite for infrequent backups. In total i have 3 hard drives for every one data. Do you guys actually do this?"},
{"Title": "Tape drives and cartridges - the ultimate endgame?", "Author": "u/the_rodent_incident", "Content": "I'm watching my pile of old hard drives with centuries worth of books, comics, music and movies, which are all gathering dust. And now the intrusive thoughts of replacing them with a somewhat modern solution are starting to appear.\n  \n\n    Just started researching about tape drives, and the first quarter of rabbit's hole is promising.\n  \n\n    They do seem like the best backup solution ever. I can find brand new LTO-4 1.6TB tapes for like $12. Drive goes for about $200. There are better tapes which go from 5 to 10TB, but their drives are also more expensive.\n  \n\n    I love the concept, though. Tapes are pure media, like DVD-RW drives. No electronics on them. They won't die because a spindle motor or a controller chip failed, or a bit flipped in the flash chip holding the firmware. Tapes are ancient retro tech thriving in the solid state age.\n  \n\n    What do you think? Am I deluding myself?"},
{"Title": "How can I fix this error (caused by power cable not being in when rebooted) (Truenas core)", "Author": "u/edwardK1231", "Content": "https://preview.redd.it/how-can-i-fix-this-error-caused-by-power-cable-not-being-in-v0-pdt9i82r8c2d1.png\n\n    There was an error before saying one drive had a failure or something but the whole pool is fine. (makes sense as running Raid Z1)\n  \n\n    The drive is fine I just didn't connect the power after I had added/replaced some fans.\n  \n\n    How can I get rid of the error?\n  \n\n    I have scrubbed the pool but nothing changed. I am a bit of a noob with truenas sorry.\n  \n\n    Thanks in advance for any help."},
{"Title": "Looking for the Wikiread software that could read MediaWiki wikis from JDC Creations", "Author": "u/Mewto17", "Content": "The website is down now. Here is a \nArchive.org link\n. The zip file for the software is corrupt. Does anyone know where I can get it from? Thanks."},
{"Title": "What kind of system is best for low data transfer for a longer time", "Author": "u/BiggieChezes", "Content": "I want to make a setup that lasts for a long time. I believe it would be best not to use a raid setup since it seems silly to have multiple drives running for basically USB 2.0 transfer speeds (Just fast enough to play Blue Rays), and I already have a backup of that data.\n  \n\n    Preferably some external solution, a power cable, and a USB A output so it would be easy to plug into my media box\n  \n\n    For now, I've been using a few USB thumb drives, which did the job. They were slow to transfer too and one of them died (tho it was easy to get it replaced via the manufacturer).\n  \n\n    So I'm basically thinking about some smaller ssd, nvme setup (2tb each drive), but I'm having a hard time finding one that isn't just a single ssd or single nvme enclosure.\n  \n\n    External hard drives also didn't sound so bad. Still, if I wanted a bigger capacity I would be stuck with Seagate One Touch Hubs and the question of how long will it last. In contrast, external SSDs seemed bad since they cost like 100 euros per 1tb while a decent 2tb nvme costs around 120 euros (150 euros if where count the enclosure)."},
{"Title": "Writing family photos to BD-R directly with file explorer in Windows 10? Or use burning software?", "Author": "u/almondbutter4", "Content": "Hi all,\n  \n\n    I have some 25GB BD-R m-discs and a blu-ray burner that I want to use to back up family photos. Has anyone ever used Windows's native ability to burn files to blu-ray? Is it recommended to use software like ImgBurn instead?\n  \n\n    Also, if I do it through file explorer, it seems like I can burn a few files at a time. Has anyone had a problem with burning some files. Ending the session. Then adding additional files to the disc later?\n  \n\n    Thanks!"},
{"Title": "How to set ctbrec to auto record?", "Author": "u/QueenAng429", "Content": "Can someone please explain how to set ctbrec to auto record? There's zero documentation online, and all the posts here of people recommending it are years old without anything other than a recommendation. I can't figure out how to make it auto record, just a manual recording."},
{"Title": "seeing different \"available\" space on ZFS pools depending on whether the host is proxmox or TrueNAS CORE. both pools are 3 drives, PM shows 73% of space available TNC shows 65%. what's up ?", "Author": "u/ImaginaryCheetah", "Content": "good evening,\n  \n\n    title gets my whole question...\n  \n\n    i have two machines, each with 3 drives in a raidZ ZFS pool, but i'm seeing 8% difference in how much space is \"available\", relative to the drive capacity, between a PM or TNC host.\n  \n\n    any ideas what could cause the difference ?"},
{"Title": "Why does the LotR:FotR Extended Edition DVD have two copies of the movie on the disc?", "Author": "u/TrekChris", "Content": "I just got the extended trilogy on DVD, and I wanted to rip them to my computer.  I discovered that there are two copies of the movie stored on the DVD.  Same length, the only difference is that one had more audio streams than the other.  Why would they do this?  They could probably fit the entire extended movie on one disc if they hadn't done this.  I'm using MakeMKV to do the ripping, and this is the first time I've come across this."},
{"Title": "DAS or NAS? Using existing drives in external storage without reformatting.", "Author": "u/PyrolyticCarbon", "Content": "Hi all.\n  \n\n    I've been researching and asking questions regarding NAS drives, and I thought I'd chosen a NAS to purchase. Then, just before I buy, I see that it formats the drives you're installing and there's no way round it, something I can't do.\n  \n\n    I have an 512Gb SSD and two 1TB HDDs filled with data in my old PC. I have a new mini PC and I had hoped to move these into a NAS and access them as is, no reformatting, no RAID - although I may buy another drive and drop it in a 4-bay solution and mirror to that, I have no need or desire for reformatting these drives currently, nor to move to a RAID solution.\n  \n\n    All the NAS units I look at say I have to reformat my drives first. I can't just plug them in and use them. It's a shame as my really old 2-bay Buffalo NAS allowed just that. DAS drives look attractive, but mixing an SSD with HDDs seems harder there and I haven't found one to suit.\n  \n\n    Any thoughts or solutions for the above? Am I missing a NAS that could mix these drives and not require me to reformat? Is there a DAS that would allow SSD and HDD together? Do I have to purchase a NAS with new disks and copy everything across and just throw my current disks out?\n  \n\n    Thank you!"},
{"Title": "New to SAS. Have a lot of them. What is your recommendation for cards to interface them with a desktop PC?", "Author": "u/Sketchy_Uncle", "Content": "No content"},
{"Title": "I copied a hard drive without Terracopy, so now there are two drives with all the same data. Is there any way to verify the data after the fact?", "Author": "u/Bern_Down_the_DNC", "Content": "I forgot to download Terracopy before doing the transfer. Is there a way to easily verify the data hashes for everything at this point?\n  \n\n    Thank you."},
{"Title": "Automatically dump all telegram files", "Author": "u/not-the-real-chopin", "Content": "There are few Telegram groups that are sharing a lot of linux iso I'd like to automatically download them for my iso collection.\n  \n\n    Can you suggest a tool to install on linux for this purpose?"},
{"Title": "Storage advice for home server", "Author": "u/Negative-Main7422", "Content": "Hi, I've just bought a HP Prodesk 400 G5 MT with Intel Core i5-9400T and 16GB RAM. It just shipped. I've seen that it's motherboard has 3 sata connectors on which I hope to connect 3 HDDs in zfs raidz.\n  \n\n    Now being a hardware newbie I don't know know which HDDs to buy and what should I keep in mind. Do 3.5\" HDDs need to be connected to the power supply? And if so, do you know where could I find out if this HP i bought can have 3 HDDs connected to the power supply? And if it can't, do you know any way around this problem?\n  \n\n    Also in the product specifications manual, it lists supported HDDs but only lists up to 2TB 7200rpm 3.5 inch drive. Is there any reason why it shouldn't support a 3TB HDD? Since I've found used 3TB WD reds for 30 euros and I'm looking to buy several."},
{"Title": "It's been nine years since this post.  What do people think of this idea now?", "Author": "u/Canttalkwhatsapponly", "Content": "Ex: If you buy a 64GB iPhone, you should get 64GB of space on iCloud for free.\n  \n\n    This would encourage people to buy higher capacity phones meaning Apple will make more profit which they can spend on cloud maintenance and expansion etc.. Its a win-win for everyone"},
{"Title": "Help needed for Datahoarding via NAS", "Author": "u/i_xm_nxsh", "Content": "Hey everyone! I did my research and narrowed it down to Synology 923+ to start my data hoarding journey however I recently came across a PC built to use as NAS.\n  \n\n    Now, because of this, I am a bit confused as to which one should I go for since the PC helps me save a lot of money. However, I am not that knowledgeable when it comes to using NAS via TrueNAS, maintaining my NAS-related PC setup etc. I have used a Windows PC Tower (with monitor) in the past but I only used it for 7 years (without any major issues) and changed to a laptop.\n  \n\n    It will be really helpful to know if the PC setup given below is a good choice for its price, good for my use case and if it will consume too much power as a NAS or not. This person is looking for $240 (probably can give the system to me for $220). Below are the system specs with my comments in (brackets):\n  \n\n    CPU: AMD Phenom II X6 1055T 6 Core Processor\n  \n\n    Memory: 16GB (4x4GB) DDR3 (brand not mentioned)\n  \n\n    HBA: LSI SAS[hidden information]i Flashed to IT Mode and acted as a HBA (no idea what this is)\n  \n\n    Supports 8x SATA/SAS 6gb/s Drives. Two SFF_8087 Breakout cables are included.\n  \n\n    Motherboard: Gigabyte GA-890GPA-UD3H with Tower CPU Cooler\n  \n\n    Case: Fractal Design Define R3 with 8 bays for HDDs\n  \n\n    Power Supply: Seasonic 550W PSU\n  \n\n    Thank you so much for reading this far and if you want to read further to know my use cases then here it is:\n  \n\n    My wife is a beginner in photography. She started 2 years back and now has over ~400 GB of photos. I know it's not much but we know that she will need more space soon.\n  \n\n    I have been using Plex (with Plex Pass) through an old laptop which has 2 TB HDD+SSD combined. Sadly, I have to delete videos to make space for new ones.\n  \n\n    I am planning on getting 24TB (8x3) drives to tackle both the use cases mentioned above.\n  \n\n    Thanks in advance for your responses!"},
{"Title": "LTO Tape Capacity - Do tapes lose capacity with use and age?", "Author": "u/fgt67cam", "Content": "I recently purchased a used LTO-5 tape drive and some used tapes. LTO-5 has a rated capacity of 1.5TB (1.36TiB). When I've been writing data to these tapes (uncompressed) and they seem to cap at 1300 GiB which seems to be ~90GiB short. I write the tapes using the command:\n  \ntar cvf - /files-to-write 2> >(tee /Tape.log >&2) | mbuffer -m 14G -L -P 80 > /dev/st0\n\n    I recorded how much data was written to each different tape before I got the \"tar: Exiting with failure status due to previous errors\" message which usually means it has reached the end of the tape and can no longer write anything.\n  \nTape 1: 1391776710636 bytes (1296 GiB)\nTape 2: 1424535198256 bytes (1326 GiB)\nTape 3: 1334993518029 bytes (1243 GiB)\nTape 4: 1383193282217 bytes (1292 GiB)\n\n    The tape drive I'm using is heavily used as well as the tapes. This is the sg_log for one of them:\n  \n    HP        Ultrium 5-SCSI    I6CZ\n\nSupported log pages  [0x0]:\n    0x00        Supported log pages [sp]\n    0x02        Write error [we]\n    0x03        Read error [re]\n    0x0c        Sequential access device [sad]\n    0x0d        Temperature [temp]\n    0x11        DT Device status [dtds]\n    0x12        Tape alert response [tar]\n    0x13        Requested recovery [rr]\n    0x14        Device statistics [ds]\n    0x15        Service buffers information [sbi]\n    0x16        Tape diagnostic data [tdd]\n    0x17        Volume statistics [vs]\n    0x18        Protocol specific port [psp]\n    0x1b        Data compression [dc]\n    0x2e        Tape alert [ta]\n    0x30        Tape usage (lto-5, 6) [tu_]\n    0x31        Tape capacity (lto-5, 6) [tc_]\n    0x32        Data compression (lto-5) [dc_]\n    0x34        Read forward errors (lto-5) [rfe_]\n    0x35        DT Device Error (lto-5, 6) [dtde_]\n    0x3e        Device Status (lto-5, 6) [ds_]\n\nWrite error counter page  [0x2]\n  Errors corrected without substantial delay = 0\n  Errors corrected with possible delays = 0\n  Total rewrites or rereads = 0\n  Total errors corrected = 0\n  Total times correction algorithm processed = 0\n  Total bytes processed = 0\n  Total uncorrected errors = 0\n\nRead error counter page  [0x3]\n  Errors corrected without substantial delay = 0\n  Errors corrected with possible delays = 0\n  Total rewrites or rereads = 0\n  Total errors corrected = 0\n  Total times correction algorithm processed = 0\n  Total bytes processed = 0\n  Total uncorrected errors = 0\n\nSequential access device page (ssc-3)\n  Data bytes received with WRITE commands: 0 GB\n  Data bytes written to media by WRITE commands: 0 GB\n  Data bytes read from media by READ commands: 0 GB\n  Data bytes transferred by READ commands: 0 GB\n  Native capacity from BOP to EOD: 1527775 MB\n  Native capacity from BOP to EW of current partition: 1517690 MB\n  Minimum native capacity from EW to EOP of current partition: 12239 MB\n  Native capacity from BOP to current position: 17654 MB\n  Maximum native capacity in device object buffer: 206 MB\n  Cleaning action not required (or completed)\n\nTemperature page  [0xd]\n  Current temperature = 41 C\n  Reference temperature = <not available>\n\nDT device status page (ssc-3, adc-3) [0x11]\n  Very high frequency data:\n  PAMR=0 HUI=0 MACC=1 CMPR=1 WRTP=0 CRQST=0 CRQRD=0 DINIT=1\n  INXTN=0 RAA=0 MPRSNT=1 MSTD=1 MTHRD=1 MOUNTED=1\n  DT device activity: No DT device activity\n  VS=0 TDDEC=0 EPP=0 ESR=0 RRQST=0 INTFC=0 TAFC=0\n  Very high frequency polling delay:  16 milliseconds\n   DT device ADC data encryption control status (hex only now):\n 00     00 00 00 00 00 00 00 00\n   Key management error data (hex only now):\n 00     00 00 00 00 00 00 00 00  00 00 00 00\n  Primary port 1 status:\n    non-SAS transport, in hex:\n 00     00 00 00 00 00 00 00 00  50 01 10 a0 01 4a a5 9c    ........P....J..\n 10     50 01 10 a0 01 4a a5 9e                             P....J..\n  Primary port 2 status:\n    non-SAS transport, in hex:\n 00     3b 00 00 01 00 00 00 01  50 01 10 a0 01 4a a5 9d    ;.......P....J..\n 10     50 01 10 a0 01 4a a5 9e                             P....J..\n  Primary port 3 status:\n    non-SAS transport, in hex:\n 00     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00    ................\n 10     00 00 00 00 00 00 00 00                             ........\n  Primary port 4 status:\n    non-SAS transport, in hex:\n 00     02 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00    ................\n 10     00 00 00 00 00 00 00 00                             ........\n  Vendor specific [parameter_code=0x8000]:\n 00     80 00 43 06 31 17 00 00  00 02                      ..C.1.....\n  Vendor specific [parameter_code=0x8003]:\n 00     80 03 43 08 00 00 00 00  00 00 00 00                ..C.........\n  Vendor specific [parameter_code=0x8010]:\n 00     80 10 43 08 00 00 00 00  00 00 00 00                ..C.........\n  Vendor specific [parameter_code=0x8020]:\n 00     80 20 43 12 00 00 00 00  00 00 00 00 00 00 00 00    . C.............\n 10     00 00 00 00 00 00                                   ......\n  Vendor specific [parameter_code=0xa101]:\n 00     a1 01 43 04 00 00 00 00                             ..C.....\n  Vendor specific [parameter_code=0xa102]:\n 00     a1 02 43 04 00 00 00 00                             ..C.....\n\nTapeAlert response page (ssc-3, adc-3) [0x12]\n  Flag01h: 0  02h: 0  03h: 0  04h: 0  05h: 0  06h: 0  07h: 0  08h: 0\n  Flag09h: 0  0Ah: 0  0Bh: 0  0Ch: 0  0Dh: 0  0Eh: 0  0Fh: 0  10h: 0\n  Flag11h: 0  12h: 0  13h: 0  14h: 0  15h: 0  16h: 0  17h: 0  18h: 0\n  Flag19h: 0  1Ah: 0  1Bh: 0  1Ch: 0  1Dh: 0  1Eh: 0  1Fh: 0  20h: 0\n  Flag21h: 0  22h: 0  23h: 0  24h: 0  25h: 0  26h: 0  27h: 0  28h: 0\n  Flag29h: 0  2Ah: 0  2Bh: 0  2Ch: 0  2Dh: 0  2Eh: 0  2Fh: 0  30h: 0\n  Flag31h: 0  32h: 0  33h: 0  34h: 0  35h: 0  36h: 0  37h: 0  38h: 0\n  Flag39h: 0  3Ah: 0  3Bh: 0  3Ch: 0  3Dh: 0  3Eh: 0  3Fh: 0  40h: 0\n\nRequested recovery page (ssc-3) [0x13]\n  Recovery procedures:\n    Recovery not requested\n\nDevice statistics page (ssc-3 and adc)\n  Lifetime media loads: 5288\n  Lifetime cleaning operations: 195\n  Lifetime power on hours: 48480\n  Lifetime media motion (head) hours: 12747\n  Lifetime metres of tape processed: 187049835\n  Lifetime media motion (head) hours when incompatible media last loaded: 0\n  Lifetime power on hours when last temperature condition occurred: 0\n  Lifetime power on hours when last power consumption condition occurred: 0\n  Media motion (head) hours since last successful cleaning operation: 66\n  Media motion (head) hours since 2nd to last successful cleaning: 126\n  Media motion (head) hours since 3rd to last successful cleaning: 187\n  Lifetime power on hours when last operator initiated forced reset\n    and/or emergency eject occurred: 20048\n  Lifetime power cycles: 77\n  Volume loads since last parameter reset: 5288\n  Hard write errors: 2\n  Hard read errors: 0\n  Duty cycle sample time (ms): 27276000\n  Read duty cycle: 0\n  Write duty cycle: 0\n  Activity duty cycle: 76\n  Volume not present duty cycle: 15\n  Drive manufacturer's serial number: 0\n  Drive serial number: 0\n  Medium removal prevented: 0\n  Maximum recommended mechanism temperature exceeded: 0\n  Media motion (head) hours for each medium type:\n    Density code: 0x44, Medium type: 0x0\n      Medium motion hours: 0\n    Density code: 0x44, Medium type: 0x1\n      Medium motion hours: 0\n    Density code: 0x46, Medium type: 0x0\n      Medium motion hours: 0\n    Density code: 0x46, Medium type: 0x1\n      Medium motion hours: 0\n    Density code: 0x58, Medium type: 0x0\n      Medium motion hours: 12747\n    Density code: 0x58, Medium type: 0x1\n      Medium motion hours: 0\n\nService buffer information page (adc-3) [0x15]\n  Service buffer identifier: 0x0\n    Buffer id: 0x41, tu=0, nmp=0, nmm=0, offline=0\n    pd=0, code_set: Binary, Service buffer title:\n      DT Device Error Log\n\nTape diagnostics data page (ssc-3) [0x16]\n  Parameter code: 0\n    Density code: 0x58\n    Medium type: 0x0\n    Lifetime media motion hours: 12739\n    Repeat: 0\n    Sense key: 0x3 [Medium Error]\n    Additional sense code: 0x0\n    Additional sense code qualifier: 0x2\n      [Additional sense: End-of-partition/medium detected]\n    Vendor specific code qualifier: 0x5098\n    Product revision level: 1228292954\n    Hours since last clean: 58\n    Operation code: 0x1d\n    Service action: 0x0\n    Medium id number (in hex):\n 00     49 43 32 47 4f 42 6e 36  38 30 00 00 00 00 00 00    IC2GOBn680......\n 10     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00    ................\n    Timestamp origin: 0x0\n    Timestamp:\n 00     00 00 00 09 6f 65\n  Parameter code: 1\n    Density code: 0x58\n    Medium type: 0x0\n    Lifetime media motion hours: 11121\n    Repeat: 0\n    Sense key: 0x3 [Medium Error]\n    Additional sense code: 0xc\n    Additional sense code qualifier: 0x0\n      [Additional sense: Write error]\n    Vendor specific code qualifier: 0x5083\n    Product revision level: 1228292954\n    Hours since last clean: 67\n    Operation code: 0x0\n    Service action: 0x0\n    Medium id number (in hex):\n 00     41 44 37 48 52 56 4e 55  58 4e 00 00 00 00 00 00    AD7HRVNUXN......\n 10     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00    ................\n    Timestamp origin: 0x0\n    Timestamp:\n 00     00 00 fb 62 2c 3e\n  Parameter code: 2\n    Density code: 0x58\n    Medium type: 0x0\n    Lifetime media motion hours: 1261\n    Repeat: 0\n    Sense key: 0x3 [Medium Error]\n    Additional sense code: 0x14\n    Additional sense code qualifier: 0x0\n      [Additional sense: Recorded entity not found]\n    Vendor specific code qualifier: 0x5090\n    Product revision level: 1228290394\n    Hours since last clean: 167\n    Operation code: 0x11\n    Service action: 0x0\n    Medium id number (in hex):\n 00     41 44 37 48 52 56 4e 55  32 4d 00 00 00 00 00 00    AD7HRVNU2M......\n 10     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00    ................\n    Timestamp origin: 0x0\n    Timestamp:\n 00     00 00 00 c9 22 70\n\nVolume statistics page (ssc-4), subpage=0\n  Page valid: 1\n  Thread count: 162\n  Total data sets written: 2916336\n  Total write retries: 20\n  Total unrecovered write errors: 0\n  Total suspended writes: 11\n  Total fatal suspended writes: 0\n  Total data sets read: 1579246\n  Total read retries: 154\n  Total unrecovered read errors: 0\n  Last mount unrecovered write errors: 0\n  Last mount unrecovered read errors: 0\n  Last mount megabytes written: 0\n  Last mount megabytes read: 0\n  Lifetime megabytes written: 7209299\n  Lifetime megabytes read: 3903959\n  Last load write compression ratio: 0\n  Last load read compression ratio: 0\n  Medium mount time: 136669\n  Medium ready time: 136669\n  Total native capacity [MB]: 1529930\n  Total used native capacity [MB]: 1527775\n  Volume serial number: E111229096\n  Tape lot identifier: H1080121\n  Volume barcode: SN3018L5\n  Volume manufacturer: SONY\n  Volume license code: U109\n  Volume personality: Ultrium-5\n  Write protect: 0\n  WORM: 0\n  Maximum recommended tape path temperature exceeded: 0\n  Beginning of medium passes: 1231\n  Middle of medium passes: 929\n  Logical position of first encrypted logical object:\n    partition number: 0, partition record data counter: 0xffffffffffff\n  Logical position of first unencrypted logical object after first\n  encrypted logical object:\n    partition number: 0, partition record data counter: 0xffffffffffff\n  Native capacity partition(s) [MB]:\n    partition number: 0, partition record data counter: 1529930\n  Used native capacity partition(s) [MB]:\n    partition number: 0, partition record data counter: 1527775\n  Vendor specific parameter code (0xf000), payload in hex\n 00     00 01                                               ..\n\n\nData compression page  (ssc-4) [0x1b]\n  Read compression ratio x100: 0\n  Write compression ratio x100: 0\n  Megabytes transferred to server: 0\n  Bytes transferred to server: 0\n  Megabytes read from tape: 0\n  Bytes read from tape: 0\n  Megabytes transferred from server: 0\n  Bytes transferred from server: 0\n  Megabytes written to tape: 0\n  Bytes written to tape: 0\n  Data compression enabled: 0x1\n\nTape alert page (ssc-3) [0x2e]\n  Read warning: 0\n  Write warning: 0\n  Hard error: 0\n  Media: 0\n  Read failure: 0\n  Write failure: 0\n  Media life: 0\n  Not data grade: 0\n  Write protect: 0\n  No removal: 0\n  Cleaning media: 0\n  Unsupported format: 0\n  Recoverable mechanical cartridge failure: 0\n  Unrecoverable mechanical cartridge failure: 0\n  Memory chip in cartridge failure: 0\n  Forced eject: 0\n  Read only format: 0\n  Tape directory corrupted on load: 0\n  Nearing media life: 0\n  Cleaning required: 0\n  Cleaning requested: 0\n  Expired cleaning media: 0\n  Invalid cleaning tape: 0\n  Retension requested: 0\n  Dual port interface error: 0\n  Cooling fan failing: 0\n  Power supply failure: 0\n  Power consumption: 0\n  Drive maintenance: 0\n  Hardware A: 0\n  Hardware B: 0\n  Interface: 0\n  Eject media: 0\n  Microcode update fail: 0\n  Drive humidity: 0\n  Drive temperature: 0\n  Drive voltage: 0\n  Predictive failure: 0\n  Diagnostics required: 0\n  Obsolete (28h): 0\n  Obsolete (29h): 0\n  Obsolete (2Ah): 0\n  Obsolete (2Bh): 0\n  Obsolete (2Ch): 0\n  Obsolete (2Dh): 0\n  Obsolete (2Eh): 0\n  Reserved (2Fh): 0\n  Reserved (30h): 0\n  Reserved (31h): 0\n  Lost statistics: 0\n  Tape directory invalid at unload: 0\n  Tape system area write failure: 0\n  Tape system area read failure: 0\n  No start of data: 0\n  Loading failure: 0\n  Unrecoverable unload failure: 0\n  Automation interface failure: 0\n  Firmware failure: 0\n  WORM medium - integrity check failed: 0\n  WORM medium - overwrite attempted: 0\n  Reserved parameter code 0x3d, flag: 0\n  Reserved parameter code 0x3e, flag: 0\n  Reserved parameter code 0x3f, flag: 0\n  Reserved parameter code 0x40, flag: 0\n\nTape usage page  (LTO-5 and LTO-6 specific) [0x30]\n  Thread count: 162\n  Total data sets written: 2916336\n  Total write retries: 20\n  Total unrecovered write errors: 0\n  Total suspended writes: 11\n  Total fatal suspended writes: 0\n  Total data sets read: 1579246\n  Total read retries: 154\n  Total unrecovered read errors: 0\n\nTape capacity page  (LTO-5 and LTO-6 specific) [0x31]\n  Main partition remaining capacity (in MiB): 2056\n  Alternate partition remaining capacity (in MiB): 0\n  Main partition maximum capacity (in MiB): 1459056\n  Alternate partition maximum capacity (in MiB): 0\n\nData compression page  (LTO-5 specific) [0x32]\n  Read compression ratio x100: 0\n  Write compression ratio x100: 0\n  Megabytes transferred to server: 0\n  Bytes transferred to server: 0\n  Megabytes read from tape: 0\n  Bytes read from tape: 0\n  Megabytes transferred from server: 0\n  Bytes transferred from server: 0\n  Megabytes written to tape: 0\n  Bytes written to tape: 0\n\nUnable to decode page = 0x34, here is hex:\n 00     34 00 00 1e 00 00 60 02  00 00 00 01 60 02 00 00\n 10     00 02 60 02 00 00 00 03  60 02 00 00 00 04 40 02\n 20     05 78\n\nUnable to decode page = 0x35, here is hex:\n 00     35 00 00 74 00 00 43 16  00 00 00 00 00 00 00 00\n 10     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 01\n 20     43 56 00 00 00 00 00 00  00 00 00 00 00 00 00 00\n 30     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00\n 40     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00\n 50     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00\n 60     00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00\n 70     00 00 00 00 00 00 00 00\n\nUnable to decode page = 0x3e, here is hex:\n 00     3e 00 00 28 00 00 40 04  00 00 00 00 00 01 40 04\n 10     00 05 01 00 00 02 60 04  00 00 14 a8 00 03 40 04\n 20     ff ff ff ff 00 04 40 04  01 09 02 23\n\n    The tapes write speed is sporadic throughout with writes speeds ranging from 140/MBs all the way down to 40/MBs with the mbuffer 100% remaining full so it's not being starved for data. I don't have any brand new tapes to use or a second tape drive so is it normal for used tapes to lose a lot of capacity and I will just have to account for this with a safer space margin?"},
{"Title": "Loudest HDD available?", "Author": "u/Western_Bass_1491", "Content": "I am giving a iMac a massive storage boost, however all the HDD’s I have are decently quiet. I am looking for one to give it the classic HDD sound, and that actually still exists and isn’t impossible to find. I don’t care about speed or rpm, just the sound and one that won’t make me broke lol"},
{"Title": "New Hard drives not detecting (Not usual issues)", "Author": "u/may9899999", "Content": "I have a PCIE to sata card that supports 8 drives. I had 5 installed on the card that all worked fine. I bought 3 new drives but they aren't being detected. I've tried changed cables with no effect. I've tried adding one at a time, nothing. I'm only seeing the original 5 no matter what I do. I thought maybe unplugging and old one and trying a new one could potentially let me know if I had too many, but then only the 4 drives showed up. They don't show up with fdisk -l, the don't show up in disks or gparted. I tried a USB enclosure to initialize them to see if that would help, and they did initialize, but once connected back to SATA, they don't show up. I'm just really at a loss of what's going on at this point. Below is the link to my previous post that I made trying to fix this issue. OS is Ubuntu 22.04\n  \n\n\nhttps://www.reddit.com/r/Ubuntu/comments/1cz2jlb/new_hard_drive_not_showing_up/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button\n\n\n\n    Edit Issue solved below, TLDR: I needed an adapter power cable (which came in the box but looked like just an extension)"},
{"Title": "Anyone experimented with p2p storage for backup purposes?", "Author": "u/The_B0rg", "Content": "I'm mostly talking about IPFS and systems built on top of it like filecoin and hivenet, both commercial solutions that provide file storage with guarantees over IPFS.\n  \n\n    You can pay in money but lower your costs by providing storage in return in a P2P fashion.\n  \n\n    I truly believe these kinds of services will only get better and are a big part of the future of the internet and data storage. The question is if anyone already has any experience with them and if they are already good enough or not?"},
{"Title": "WD BLACK Hard Drive Failure", "Author": "u/Majestic-Owl-5801", "Content": "I was transferring files from one hard drive to another and had to end the process, but now I cant open up the hard drive I was transferring files from.\n  \n\n    I am sure I corrupted something by ending the process, but it ended on one of the windows that asked to clear space to continue. So it was on a single file rather than in the middle of a file. I clicked skip for all remaining and it froze, it was quite a lot of files. I closed the window because it was frozen, and now it wont show me the files on the drive.\n  \n\n    It will load, show me the remaining space taken up, but wont load any files when I actually open the drive in explorer."},
{"Title": "Best practices with Terracopy? Verify and checksum?", "Author": "u/Bern_Down_the_DNC", "Content": "First time using Teracopy. I was recommended to use this since I can check \"verify files\" and it will do that after copying files on drive 1 and syncing to drive 2.\n  \n\n    Nobody said anything about checksum files. Not sure if it would be beneficial. I will rename files or add more files to the directory later on drive 1, then sync all the files to drive 2 again.\n  \n\n    If I need to do checksum, would I create a checksum for folders on drive 1, then start copy and sync to drive 2 but select \"do checksum at the end\" so it generates a second checksum on drive 2 that I can compare to the checksum from drive 1?\n  \n\n    Also do I need to choose \"store/verify checksum on ADS\"? (And should I use xx3-64 instead of MD5 now?)\n  \n\n    Thank you!"},
{"Title": "I want to expand my zpool in both size and efficiency, could you please help me?", "Author": "u/mathscasual", "Content": "Right  now I have two 16 TB hdds mirrored in raid 1. I want to change my raid configuration to increase speed and size. Give me an excuse to buy 6 more drives(or more) so I have both increased size and speed.\n  \n\n    What raid configuration?\n  \n\n    How many more drives?(can they be larger than 16Tb(was looking at 22TBs)\n  \n\n    cacching?\n  \n\n    Many pleases and thank yous"},
{"Title": "Can you still get Yoyotta with a lifetime license or is it all subscriptions?", "Author": "u/DevilryAscended", "Content": "I saw this post from 6 years ago,\n  \n\n\nhttps://www.reddit.com/r/DataHoarder/comments/a2k5y4/hoarding_to_lto_tape_primer_all_you_wanted_to/\n\n\n\n    Where it listed a price that is definitely higher than their current subscription price. Does anyone know when they made the change? I'm currently doing research into LTO backups/archiving as an option for system we're building out and a key thing I would like to avoid is any subscriptions but I did like how well documented using Yoyotta seemed."},
{"Title": "(UK) 18TB WD Elements @ £14.3 per TB on WD Website", "Author": "u/mrnngbgs", "Content": "You get £50 off if you spend over £300 on WD website. If you pair WD Elements 18TB (currently discounted at £297.99) with their 2 year data recovery plan (£10), you will only pay £258 which equals to £14.33 per TB.\n  \n\n    Finally a good deal! (UK)\n  \n\n    Ends 27th of May"},
{"Title": "How much data duplication do you have? Do you really follow 3-2-1 at home?", "Author": "u/pm_me_xenomorphs", "Content": "For example, i have 3 copies of all my drives that i care about. I have 1 copy on my NAS, 1 copy offline for regular backups and another copy offsite for infrequent backups. In total i have 3 hard drives for every one data. Do you guys actually do this?"},
{"Title": "Tape drives and cartridges - the ultimate endgame?", "Author": "u/the_rodent_incident", "Content": "I'm watching my pile of old hard drives with centuries worth of books, comics, music and movies, which are all gathering dust. And now the intrusive thoughts of replacing them with a somewhat modern solution are starting to appear.\n  \n\n    Just started researching about tape drives, and the first quarter of rabbit's hole is promising.\n  \n\n    They do seem like the best backup solution ever. I can find brand new LTO-4 1.6TB tapes for like $12. Drive goes for about $200. There are better tapes which go from 5 to 10TB, but their drives are also more expensive.\n  \n\n    I love the concept, though. Tapes are pure media, like DVD-RW drives. No electronics on them. They won't die because a spindle motor or a controller chip failed, or a bit flipped in the flash chip holding the firmware. Tapes are ancient retro tech thriving in the solid state age.\n  \n\n    What do you think? Am I deluding myself?"},
{"Title": "How can I fix this error (caused by power cable not being in when rebooted) (Truenas core)", "Author": "u/edwardK1231", "Content": "https://preview.redd.it/how-can-i-fix-this-error-caused-by-power-cable-not-being-in-v0-pdt9i82r8c2d1.png\n\n    There was an error before saying one drive had a failure or something but the whole pool is fine. (makes sense as running Raid Z1)\n  \n\n    The drive is fine I just didn't connect the power after I had added/replaced some fans.\n  \n\n    How can I get rid of the error?\n  \n\n    I have scrubbed the pool but nothing changed. I am a bit of a noob with truenas sorry.\n  \n\n    Thanks in advance for any help."},
{"Title": "Looking for the Wikiread software that could read MediaWiki wikis from JDC Creations", "Author": "u/Mewto17", "Content": "The website is down now. Here is a \nArchive.org link\n. The zip file for the software is corrupt. Does anyone know where I can get it from? Thanks."},
{"Title": "What kind of system is best for low data transfer for a longer time", "Author": "u/BiggieChezes", "Content": "I want to make a setup that lasts for a long time. I believe it would be best not to use a raid setup since it seems silly to have multiple drives running for basically USB 2.0 transfer speeds (Just fast enough to play Blue Rays), and I already have a backup of that data.\n  \n\n    Preferably some external solution, a power cable, and a USB A output so it would be easy to plug into my media box\n  \n\n    For now, I've been using a few USB thumb drives, which did the job. They were slow to transfer too and one of them died (tho it was easy to get it replaced via the manufacturer).\n  \n\n    So I'm basically thinking about some smaller ssd, nvme setup (2tb each drive), but I'm having a hard time finding one that isn't just a single ssd or single nvme enclosure.\n  \n\n    External hard drives also didn't sound so bad. Still, if I wanted a bigger capacity I would be stuck with Seagate One Touch Hubs and the question of how long will it last. In contrast, external SSDs seemed bad since they cost like 100 euros per 1tb while a decent 2tb nvme costs around 120 euros (150 euros if where count the enclosure)."},
{"Title": "Writing family photos to BD-R directly with file explorer in Windows 10? Or use burning software?", "Author": "u/almondbutter4", "Content": "Hi all,\n  \n\n    I have some 25GB BD-R m-discs and a blu-ray burner that I want to use to back up family photos. Has anyone ever used Windows's native ability to burn files to blu-ray? Is it recommended to use software like ImgBurn instead?\n  \n\n    Also, if I do it through file explorer, it seems like I can burn a few files at a time. Has anyone had a problem with burning some files. Ending the session. Then adding additional files to the disc later?\n  \n\n    Thanks!"},
{"Title": "How to set ctbrec to auto record?", "Author": "u/QueenAng429", "Content": "Can someone please explain how to set ctbrec to auto record? There's zero documentation online, and all the posts here of people recommending it are years old without anything other than a recommendation. I can't figure out how to make it auto record, just a manual recording."},
{"Title": "seeing different \"available\" space on ZFS pools depending on whether the host is proxmox or TrueNAS CORE. both pools are 3 drives, PM shows 73% of space available TNC shows 65%. what's up ?", "Author": "u/ImaginaryCheetah", "Content": "good evening,\n  \n\n    title gets my whole question...\n  \n\n    i have two machines, each with 3 drives in a raidZ ZFS pool, but i'm seeing 8% difference in how much space is \"available\", relative to the drive capacity, between a PM or TNC host.\n  \n\n    any ideas what could cause the difference ?"},
{"Title": "Why does the LotR:FotR Extended Edition DVD have two copies of the movie on the disc?", "Author": "u/TrekChris", "Content": "I just got the extended trilogy on DVD, and I wanted to rip them to my computer.  I discovered that there are two copies of the movie stored on the DVD.  Same length, the only difference is that one had more audio streams than the other.  Why would they do this?  They could probably fit the entire extended movie on one disc if they hadn't done this.  I'm using MakeMKV to do the ripping, and this is the first time I've come across this."},
{"Title": "DAS or NAS? Using existing drives in external storage without reformatting.", "Author": "u/PyrolyticCarbon", "Content": "Hi all.\n  \n\n    I've been researching and asking questions regarding NAS drives, and I thought I'd chosen a NAS to purchase. Then, just before I buy, I see that it formats the drives you're installing and there's no way round it, something I can't do.\n  \n\n    I have an 512Gb SSD and two 1TB HDDs filled with data in my old PC. I have a new mini PC and I had hoped to move these into a NAS and access them as is, no reformatting, no RAID - although I may buy another drive and drop it in a 4-bay solution and mirror to that, I have no need or desire for reformatting these drives currently, nor to move to a RAID solution.\n  \n\n    All the NAS units I look at say I have to reformat my drives first. I can't just plug them in and use them. It's a shame as my really old 2-bay Buffalo NAS allowed just that. DAS drives look attractive, but mixing an SSD with HDDs seems harder there and I haven't found one to suit.\n  \n\n    Any thoughts or solutions for the above? Am I missing a NAS that could mix these drives and not require me to reformat? Is there a DAS that would allow SSD and HDD together? Do I have to purchase a NAS with new disks and copy everything across and just throw my current disks out?\n  \n\n    Thank you!"},
{"Title": "New to SAS. Have a lot of them. What is your recommendation for cards to interface them with a desktop PC?", "Author": "u/Sketchy_Uncle", "Content": "No content"},
{"Title": "I copied a hard drive without Terracopy, so now there are two drives with all the same data. Is there any way to verify the data after the fact?", "Author": "u/Bern_Down_the_DNC", "Content": "I forgot to download Terracopy before doing the transfer. Is there a way to easily verify the data hashes for everything at this point?\n  \n\n    Thank you."},
{"Title": "Automatically dump all telegram files", "Author": "u/not-the-real-chopin", "Content": "There are few Telegram groups that are sharing a lot of linux iso I'd like to automatically download them for my iso collection.\n  \n\n    Can you suggest a tool to install on linux for this purpose?"},
{"Title": "Storage advice for home server", "Author": "u/Negative-Main7422", "Content": "Hi, I've just bought a HP Prodesk 400 G5 MT with Intel Core i5-9400T and 16GB RAM. It just shipped. I've seen that it's motherboard has 3 sata connectors on which I hope to connect 3 HDDs in zfs raidz.\n  \n\n    Now being a hardware newbie I don't know know which HDDs to buy and what should I keep in mind. Do 3.5\" HDDs need to be connected to the power supply? And if so, do you know where could I find out if this HP i bought can have 3 HDDs connected to the power supply? And if it can't, do you know any way around this problem?\n  \n\n    Also in the product specifications manual, it lists supported HDDs but only lists up to 2TB 7200rpm 3.5 inch drive. Is there any reason why it shouldn't support a 3TB HDD? Since I've found used 3TB WD reds for 30 euros and I'm looking to buy several."},
{"Title": "What would drag-and-drop copying errors result in for personal photos and videos? Is it necessary to copy them with an extra integrity software? Best such software for Mac OS?", "Author": "u/AntarcticNightingale", "Content": "What percentage of drag-and-drop copy result in undetected errors on a MacOS? (Discounting detected errors like sometimes if there are issues with not enough storage, I get a pop up telling me the problem, so that doesn’t count.)\n  \n\n    I’m just copying decades worth of personal photos and videos, and some documents. What would an undetected error be like? Just a single pixel of a picture damaged, a portion of the picture, entire picture, or entire batches of pictures and media?\n  \n\n    If the error rate is something to be concerned about, what is the MacOS equivalent of TetaCopy?"},
{"Title": "Optimal external drive distribution?", "Author": "u/CautiousXperimentor", "Content": "Hello.\n  \n\n    Historically, I’ve had the following USB spinning hard drives (all 2.5”):\n  \n\n\n- WD My Passport: 1 TB:\n personal stuff and old files, as this was my first external drive; this includes photos, videos, class recordings, old images and screenshots, music, software from the 90s and early 2000… stuff that I don’t want to get rid of. It’s at 80% full.\n  \n\n\n- Toshiba Canvio Basics (1TB):\n Movie backups, classified by genre, and game backups. 96% capacity.\n  \n\n\n- Toshiba Canvio Basics\n (yes, I love how good and reliable this model is) (2TB): Series, documentaries and anime backups, as well as other content from the internet such as podcasts or video-podcasts. It’s at 60% of its capacity.\n  \n\n\n- Re-used Hitachi drive (256GB):\n it’s health is low, but it still works, I use it as the only ExFAT drive if I need to use it on a machine that doesn’t support my current files system (APFS). It has a lot of random stuff.\n  \n\n     \n  \n\n    Now, those are the traditional spinning external drives I’ve always had. On the other hand, during the recent years, thanks to different sales, I’ve managed to get the following Samsung T5 and T7 SSDs.\n  \n\n    My plan when I got this new T5 and T7 Samsung SSDs was to be able to carry with me the same information but with much less weight, and keep the older 2.5” hard drives as a long term storage/backup, without actually using them unless when I want to back up something very important.\n  \n\n    My new portable SSDs are the following:\n  \n\n\n-T5 500GB:\n I intend to use it to carry it with me to the university, store class recordings (including video) that usually take 1GB each, and my device has only 128GB on board. I want to use it as a high performance pen-drive.\n  \n\n\n-T5 1TB:\n here, I’d thought to store the same personal data, such as photos or videos or old files that I already have on my WD My Passport (1TB)\n  \n\n\n- T7 2TB:\n intended to use as a media SSD, because of it’s big size. However, I’m not sure if I should use it to store my academical recordings (remember, ~1GB per file), or just put there my favorite movie and series backups. Or maybe both? But having already 1TB 2.5” HDD just for movies, and another 2TB 2.5” HDD for series+anime backups and other Internet video content such as videopodcasts, I’m not sure if putting here my favorite content (duplicate) is wasting this 2TB SSD.\n  \n\n\n-T7 Shield 4TB:\n And when I thought I had enough SSDs to fulfill my needs… I saw a sale on the T7 Shield 4TB SSD, at less than half the price. Obviously, I had to get it. So now I have this 4TB SSD that I can carry with me with EVERYTHING I have on the other SSDs, in just one drive.\n  \n\n    However, when I go to the Uni, the SSD I want to carry with me is the T5 500GB. It’s the cheapest and everything on it will -hopefully- be backed up.\n  \n\n\nMy main doubt is (option A)\n wether to use the T5 1TB SSD for personal stuff that I already have on the WD My PassPort, but that’s not data I use too much. In this case I would use the 2TB SSD for my classes (long term) AND my favorite media content such as movies and shows.\n  \n\n\nThe alternative (option B)\n is to use the T5 1TB for storing my classes long term (short term is what the 500GB is for), and leave the 2TB SSD just for non-personal media.\n  \n\n    In this case (option B), among the personal data from the WD drive, I could make a selection, i.e. all my personal photos and memories and PDFs and documents, and put them on the 4TB drive along with the media stuff and my uni stuff to have everything in one drive.\n  \n\n     \n  \n\n    I could also use this 4TB SSD to sort all the duplicates I have on every hard drive, which I suspect they are a lot. I think it’s easier having all in one drive.\n  \n\n    Don’t worry about privacy, as I’m formatting all the T5 and T7 with encryption and a 16-20 character long password, a different one for each drive.\n  \n\n     \n  \n\n\nHow would you use the 4 SSDs if you were me?\n\n\n\n    You can also comment on my hardware if you want. The Toshiba Canvio Basic were cheap and extraordinarily reliable and silent hard drives that still work perfectly after more than 10 years."},
{"Title": "Any way to make a cheap docking station or something similar?", "Author": "u/BiggieChezes", "Content": "I have a few smaller 256GB, and 512GB scrap hard drives.\n  \n\n    And I wanted to turn them into home theater storage. I thought about a Plex server but decided against it since I only need it for 1 device and the regular PC motherboard (just an old crappy pc) usually didn't have enough sata ports.\n  \n\n    So I'm looking for something (or to make something) that powers the multiple hard drives and sends the storage signal via a single USB A (don't care if it's janky as hell) tho I don't care for redundancy.\n  \n\n    Did think about just buying a few HHD enclosures but tbh I don't like that since every one of them would need a different power cable and they cost a bit. A 256 GB USB would cost the same as getting an enclosure for an old 256GB hard drive.\n  \n\n    And I do mean a cheap option since if it costs nearly 100 euros it's way more price-effective just to buy a 4 TB hard drive with an enclosure."},
{"Title": "Flash NAS help", "Author": "u/Oblec", "Content": "I love to build a NAS with only flash storage. But looking at prices, m2 storage seems to be the way to go 4x 8tb nvme 15-16tb should be enough for me. I also gonna add two 10tb for my surveillance. Im concerned the lifetime of it won’t be that good. Is that an issue?"},
{"Title": "How do you guys keep your files organized?", "Author": "u/ramy_chaos", "Content": "Hi everyone!\n  \n\n    So ive got a bunch of external and internal drives and my pc just feels like a cluttered mess in terms of storage. Ive got files all over the place, some of which are duplicates, and it's driving me nuts. If anyone has any advice, id be super grateful!"},
{"Title": "I thought what I wanted was simple, then I read on here and now I'm confused. Can I get some ELI5 advice on expanding my storage?", "Author": "u/LoliSukhoi", "Content": "All I want is additional storage space for archiving files off of my PC that has some protection against drive failure. What is the simplest method of achieving this?\n  \n\n    Until recently I used a Synology 4 bay NAS but I've outgrown it and since I never used 99% of the features of a NAS, I decided to get a 10 bay IcyBox DAS (I think it's a DAS? It connects via USBC) that I saw on sale along with 4 24TB Seagate drives. My idea was to then use Windows Storage Spaces to create a pool and mirror the drives to add redundancy.\n  \n\n    But then I saw a lot of people on here really don't like Storage Spaces which sent me down a rabbit hole of Googling and reading threads which involved a million acronyms and other words and names I don't understand and now I'm thoroughly confused. Like what's the difference between a DAS and a JBOD? What's a Home Lab? What's ZFS? (I'm just asking these to show the kind of research mess I've ended up in, don't feel the need to spend paragraphs answering them.)\n  \n\n    Is Storage Spaces good enough for what I want? Will it easily allow me to add more drives to the pool down the line? Did I buy the wrong thing? Should I have done something else?"},
{"Title": "how to check are files good or damaged?", "Author": "u/oO0_", "Content": "i do simple backups.\n  \n\n    But how can i check if current files are good? Is there way to check (hash or what) that file should have unless i change file by myself or by some software?\n  \n\n    Most files on Windows/NTFS"},
{"Title": "For a folder of media files, is it possible to get a directory list  with media encoded type? AV1 H264 etc.?", "Author": "u/danuser8", "Content": "Looking for solution in windows"},
{"Title": "i've got a couple HP 4k13c5 HBAs from salvaged machines, which include the onboard cache. but i only see folks praising LSI HBAs on here. should i spend the $35 on a LSI ?", "Author": "u/ImaginaryCheetah", "Content": "\"when in rome\", as they say.\n  \n\n    for someone generally ignorant on good verses bad HBAs, i assume there's a reason for the cult status of LSI, but is there any reason to not use the free HP ones i've got ?\n  \n\n    having onboard cache seems like a useful feature, but might not be worth the potential issue with HP drivers."},
{"Title": "Encryption tool that could output smaller chunks of encrypted blocks?", "Author": "u/SuperElephantX", "Content": "Long story short, need some tools that could securely do file/folder encryption and output as smaller chunks of encrypted blocks.\n  \n\n    Benefits: Easier to track small changes without hashing 1TB of data. Easier to sync to the cloud.\n  \n\n    Had been using \nVeraCrypt\n for ages and worked fine every time (Container's too large).\nAlso heard of \nCryptomator\n, but the reputation of the software made me stepped away from it (Corruption issues)\n  \n\n    Any solutions that you guys could recommend would fit the need of mine?\n  \n\n\n\n\n\n    Backed by secure algo like AES\n  \n\n\n\n\n\n    Auto splitting chunks into smaller file sizes.\n  \n\n\n\n\n\n    Content change only affects the necessary encrypted blocks and not all of them."},
{"Title": "Migrating Drobo user saying thanks for the help, and one more question", "Author": "u/Splitsurround", "Content": "Thanks for the guidance towards my new DAS, friends. It took a while for me to really understand the options, software raid vs hardware, how many bays I needed, the limitations of  it, etc. So I've settled on the Terramaster 6 bay DAS  D6-320. I will put 6 16TB drives in it. I'll be using Softraid with it, thus my next question:\n  \n\n    since softraid doesn't do raid 6 yet, what flavor would you recommend for me? I need at least one disk failure protection, but wouldn't hate two. I don't understand what some of the raid options mean by \"at least one disk protection\" fwiw. Looking for the most usable space with the most comprehensive \"realistic\" protection\n  \n\n    Thanks again, and looking forward to getting moved to something stable"},
{"Title": "PSA: 14TB WD Red Plus (WD140EFGX) back in stock at Western Digital", "Author": "u/SimplyDown", "Content": "https://www.westerndigital.com/products/internal-drives/wd-red-plus-sata-3-5-hdd?sku=WD140EFGX\n\n\n\n    Just posting in case anyone else has been trying to get their hands on one since they've all but disappeared over the past year.  If you're wondering why it's anything special, it's the largest reasonably quiet HD if you're looking for a low noise solution compared to the typical enterprise HD.\n  \n\n    I logged into my WD account and added 5 to my cart.  Checked back a couple of times over a few hours and WD ended up emailing me a 15% off one time discount code to finish checking out.  I'm also receiving 18% rewards on Western Digital through Capital One Shopping (after window shopping Western Digital site a few times on the app).  Not sure if this is normal or some special push for Memorial Day Weekend.   But final price for me ends up at $220.15 + tax plus $39.63 in rewards per HD."},
{"Title": "Is cloud storage/sync and online backup redundant?", "Author": "u/AreaMuppet", "Content": "I've used Google Drive sparingly for years but recently upgraded to a Google One 2TB account to give me and my family more storage and syncing capability across devices, as well as allowing me to consolidate all of the files on my laptop - which includes all of the \"family management\" documents, photos, videos, etc. - in one place rather than split up so I could stay under my 15GB free Google account limit.\n  \n\n    For years I have also used online backup. I've used IDrive in recent years (I've seen some complaints here, but I've found it to be fine, if a bit clunky) and Carbonite before that.\n  \n\n    But with my IDrive renewal coming up, I have wondered if having both Google Drive and IDrive are redundant. Years ago, I recall reading that online backup was still necessary because cloud storage wasn't reliable. But it seems like cloud storage has come a long way in terms of reliability and features, like file versioning and retrieval in case of loss.\n  \n\n    I've looked extensively and been surprised not to find much information on that question. Is there a consensus? (I should add that I also back up to an external hard drive so I do maintain multiple copies.)"},
{"Title": "Just bought a 1TB Samsung 980 PRO. Should I return it?", "Author": "u/greencalx8", "Content": "So basically I read about all the firmware issues and kinda scared me. I did my research inside this subreddit before buying it, but now I have doubts, even though I shouldn't have any problems since it was manufactured in October 2023. What are your thoughts? Should I return it? I didn't have any more options available (cost me 88€).\n  \n\n    Forgot to say that I'm using it with Immich to back up all my pictures, and it will be on 24/7.\n  \n\n    Thanks in advance."},
{"Title": "Transferring iCloud to PC not going very well", "Author": "u/NegativeNiek", "Content": "So my iCloud has been full for a while, and I wanted to transfer everything to my local pc storage, so I requested my data as rar files, and eventually got those, unzipped them and everything, but now I just have these 6 25gb folders with images and videos from random dates (because the dates didn't save and I don't know how to sort on EXIF data) and I don't even know how to find the most recent saved image inbetween them all.. Could someone maybe help me figure out how to get all these dates back into place?"},
{"Title": "Alternative to paperless-ngx for archiving magazines?", "Author": "u/GibtNixZuSehen", "Content": "Is there any good alternative to paperless-ngx for archiving >5000 magazines and books in pdf format?\n  \n\n    Would be nice to have full text search over all documents.\n  \n\n    I'm running an paperless-ngx container on my proxmox server but several pdfs take ages to ocr and indexing. Still have >4500 files to go and the files I added so far took several days to complete."},
{"Title": "Why is SSD price increasing from last year?", "Author": "u/AntarcticNightingale", "Content": "I was looking at the SSD I bought last year and found them generally increased from the past year by almost $100. What caused this? Just curious.\n  \n\n\nhttps://camelcamelcamel.com/product/B09VLJ7VBM\n\n\n\n\nhttps://camelcamelcamel.com/product/B0BHZQGN26"},
{"Title": "30+ usb hard drives, 20+ years of hoarding.", "Author": "u/password_too_short", "Content": "so i've amassed just over 30 usb 2.5\" hard drives. i'm in my mid 30's and i use them to store basically every tv show and move i've ever watched.\n  \n\n    and yep, i do re-watch stuff.\n  \n\n    none of them have failed yet. except my music drive that makes a high pitched whine sometimes and lots of beeps...yeah i might replace that...but haven't yet.\n  \n\n    for some reason i don't hoard games i've played though.  i seem to value movies and tv and music more.\n  \n\n    anyone else with a shelf of drives? what do you store?"},
{"Title": "The WD PWL water torture THUMP!", "Author": "u/Prime_Objective666", "Content": "I was shocked at how loud the WD Pre-emptive Wear Levelling thump was! My 18Tb Elements got sent back. I then got in touch with Seagate and asked how they compere - I thought I would share my experience here in May 2024 and hope it helps:\n  \n\n\nMe:\n\n\n\n\nHi - I just got shocked about a WD 18Tb PWL thump every 5 seconds which I cannot cope with soundwise. So I am looking to Seagate to see if you offer 14+TB drives that do not have regular PWL thump sounds. I dont care about access noise nor motor whirr noise but PWL every 5 secs is like Chinese Water Torture! The ONLY issue is regular Pre-emptive Wear Levelling noises - and NOT access or drive noise\n\n\n\n\n\n\nSeagate Agent:\n\n\n\n\nUpon checking with the concern technical team, our technical team requested to inform you that, you will get a minimum sound with a lite vibration in our drives. As this sound will occur in all the hard drives, It will not be unusual like WD and this sound will not be disturbing to you. Other than that you can buy any Seagate drives according to the capacity and usage. PWL sounds will not occur in Seagate. But you can hear some minimum sort of sound and vibration can be heard slightly when the drive is in a silent room. You need not worry, you will not face any PWL sound issue in Seagate.\n\n\n\n\n\n\nMe:\n\n\n\n\nSecond question: what is the best large drive that copes with regular power cycles? In my usage, the drive will be attached to a USB external dock cabinet which powers down the drive after 20 mins of non-use. This will occur 20 times a day, Out of the SG range, what copes best?\n\n\n\n\n\n\nSeagate Agent:\n\n\n\n\nUpon checking, Seagate does not recommend to use the drives in the USB dock or using splitters or any other external connectors. We recommend and request you to use the drives directly to the host device."},
{"Title": "Having trouble copying video files to flash drive.", "Author": "u/Fantastic-Notice-756", "Content": "So, a while back I got a 2TB flash drive from a friend. I needed a new one because I was having corruption trouble with the 1TB flash drive that I'd been using. Anything I backed up to the 1TB drive would be corrupted upon reconnecting the drive to my laptop  There wasn't much on the 1TB drive, but I did have a lot of videos downloaded from YT that were clean. I thought the corruption might've been carried over, so I decided to alphabetically re download all the videos onto the 2 TB drive. Re downloading the videos going fine until I hit a bit of a snag.\n  \n\n    I'd gotten to the R and S part of the video title alphabet. After I pasted some video files onto the 2TB drive I noticed there was external corruption being caused. I know this because I tried to paste a rar of the pc version of neversoft's spider-man game onto the drive (It was the lightest game I could think of) and the archive ended up being corrupt. I can tell when it's a clean paste, because the rar will paste slowly and the green meter resembles a set of waves, but when it's a corrupted paste, it'll look more like a straight line. I took those files off the drive, re pasted the archive and the rar was just fine. I re downloaded the files, some of them were copied to the drive and didn't cause any corruption, but others would still cause corruption. I even pasted some video files from the 1TB drive and some of them would be fine, but others would have the same corruption result.\n  \n\n    I don't know if this is malware related or if it has something to do with the allocation unit size, But I have no idea how to fix it. And what's worse is that I have no way of knowing which files the 2TB drive will accept or not. I can't back anything up until this is fixed and my desktop doesn't have enough space. Any help at all will be appreciated."},
{"Title": "Is it better to sleep drives or leave them spinning in between infrequent uses?", "Author": "u/Streetamp_Lamoose", "Content": "I'm pretty new to using larger drive arrays and this seemed like the kind of place where people have things figured out. My apologies if this is basic knowledge, but my internet searching didn't seem to reveal a consensus.\nI have a Mac Studio that I use as my main machine with 14+ Tb (out of 36Tb total) of mostly RAW photos stored on a 4-Bay OWC Thunderbay enclosure (Raid 5 via SoftRaid). This enclosure is directly connected to the mac via a Thunderbolt 3 (type-C connector) to the Mac. What drives me crazy is that, for reasons unknown to me, all day everyday, the drives seem to be spinning up, spinning down, spinning up, spinning down. Rest for 2 minutes, then spin up again and down again. I had been sleeping the Mac and allowing it to sleep my disks, but no matter what settings I tried it always woke from sleep about every 5 minutes, and would spin up the drive array, only to immediately go back to sleep and deactivate them. After about 2 years of this, My Hitachi drives eventually had catastrophic failures, and corrupted HFS+ volumes. I was able to recover most of the data from various backup schemes. I decided to replace the 4 drives with Segate Datacenter Exos Enterprise drives, thinking that I would change my approach and never allow the mac to sleep (just the displays). I hoped this would mean that the drives would stay powered up and always spinning, so hopefully avoiding the massive wear and tear I was getting before through constant power cycling and mechanical acceleration. My plan seems to be failing. I never sleep the Mac, and I've tried every setting I can find in the UI menus. Even if I haven't touched the machine in days, it is still spinning up, spinning down, spinning up, spinning down every minute or so. And to make matters worse, these Enterprise drives are LOUD. My poor daughter, who tries to sleep in the room next to my computer can hear the drives all night \"Growling\" at her, crunching, and spasming and spinning loudly, even when I haven't asked to access the volumes in days. I know modern OS'es run things in the background, like indexing, Time Machine, search optimization, caching stuff, etc. But is it really so constant? And why can't I seem to prevent the drives from ever turning off, which I assume (power waste aside) would be better for the health of the drives?\nI just want to have a large Raid 5 drive directly connected to my desktop machine, with a fast connection for things like 8k video editing, and not feel like the drives are constantly power cycling themselves into an early grave. I've got to be missing something obvious here..."},
{"Title": "I want to be able to host my own personal “short video” collection and be able to scroll like TikTok.", "Author": "u/Unlikelyusername3", "Content": "New to this. I’m looking for a program that allows me to stream videos from my pc similar to Plex, but with scrollable videos more similar to TikTok for some short….clips.\n  \n\n    I haven’t seen what I’m looking for on google so I figured I’d ask the experts here. :)"},
{"Title": "DVD Case Storage", "Author": "u/Parking-Mirror3283", "Content": "Hi guys, might be a little bit strange and not sure if there's anywhere better to ask this, but i was wondering if anybody had an idea of where to get a solid storage box for full DVD sized cases as opposed to just the discs themselves?\n  \n\n    Have a bunch of PS2/Xbox/360 games collected and i want to do something better than just having them loose in a box but have had no luck finding anything."},
{"Title": "What’s your drive health checklist?", "Author": "u/Educational_Tap4663", "Content": "I’m planning on shucking a group of external hard drives to use in a homelab server I’m building. When you get a new, used, or refurbished hard drive, what are you go-to commands, tools, or processes to assess its health and performance? I’ve found several software applications, but I thought the experts of DataHoarder would know best. Cheers"},
{"Title": "Help me understand size of Pool and Volume", "Author": "u/Hakihiko", "Content": "Premise: early I tried to post in the qnap subreddit, but there isn't much movement there in this moment. So I take a chance to ask here, hoping someone can help me.\n  \n\n    Hi,\n  \n\n    I have a qnap TS-653A with a the firmware version 5.1.5.\n  \n\n    Recently I switched from 5x6TB to 5x18TB using RAID 5. Following guides online, I expanded the pool and now in the specifications it tells me that I have a Capacity of 65.45TB, Allocated 64.21TB and Unallocated 1.24TB.\n  \n\n    My DataVol1 (I have just a single volume), after the resize to increase the volume to the maximum possible size, has a Capacity of 62.99TB.\n  \n\n    Is it normal to have 1.24TB more on the pool that I cannot use to increase further the capacity of my volume? Can I use it in any way?\n  \n\n    Also, since today I used always a Thick volume. If I'll change to Thin, will I be able to use more space (aka that unallocated portion of the pool)?\n  \n\n    Thank you"},
{"Title": "What would drag-and-drop copying errors result in for personal photos and videos? Is it necessary to copy them with an extra integrity software? Best such software for Mac OS?", "Author": "u/AntarcticNightingale", "Content": "What percentage of drag-and-drop copy result in undetected errors on a MacOS? (Discounting detected errors like sometimes if there are issues with not enough storage, I get a pop up telling me the problem, so that doesn’t count.)\n  \n\n    I’m just copying decades worth of personal photos and videos, and some documents. What would an undetected error be like? Just a single pixel of a picture damaged, a portion of the picture, entire picture, or entire batches of pictures and media?\n  \n\n    If the error rate is something to be concerned about, what is the MacOS equivalent of TetaCopy?"},
{"Title": "Optimal external drive distribution?", "Author": "u/CautiousXperimentor", "Content": "Hello.\n  \n\n    Historically, I’ve had the following USB spinning hard drives (all 2.5”):\n  \n\n\n- WD My Passport: 1 TB:\n personal stuff and old files, as this was my first external drive; this includes photos, videos, class recordings, old images and screenshots, music, software from the 90s and early 2000… stuff that I don’t want to get rid of. It’s at 80% full.\n  \n\n\n- Toshiba Canvio Basics (1TB):\n Movie backups, classified by genre, and game backups. 96% capacity.\n  \n\n\n- Toshiba Canvio Basics\n (yes, I love how good and reliable this model is) (2TB): Series, documentaries and anime backups, as well as other content from the internet such as podcasts or video-podcasts. It’s at 60% of its capacity.\n  \n\n\n- Re-used Hitachi drive (256GB):\n it’s health is low, but it still works, I use it as the only ExFAT drive if I need to use it on a machine that doesn’t support my current files system (APFS). It has a lot of random stuff.\n  \n\n     \n  \n\n    Now, those are the traditional spinning external drives I’ve always had. On the other hand, during the recent years, thanks to different sales, I’ve managed to get the following Samsung T5 and T7 SSDs.\n  \n\n    My plan when I got this new T5 and T7 Samsung SSDs was to be able to carry with me the same information but with much less weight, and keep the older 2.5” hard drives as a long term storage/backup, without actually using them unless when I want to back up something very important.\n  \n\n    My new portable SSDs are the following:\n  \n\n\n-T5 500GB:\n I intend to use it to carry it with me to the university, store class recordings (including video) that usually take 1GB each, and my device has only 128GB on board. I want to use it as a high performance pen-drive.\n  \n\n\n-T5 1TB:\n here, I’d thought to store the same personal data, such as photos or videos or old files that I already have on my WD My Passport (1TB)\n  \n\n\n- T7 2TB:\n intended to use as a media SSD, because of it’s big size. However, I’m not sure if I should use it to store my academical recordings (remember, ~1GB per file), or just put there my favorite movie and series backups. Or maybe both? But having already 1TB 2.5” HDD just for movies, and another 2TB 2.5” HDD for series+anime backups and other Internet video content such as videopodcasts, I’m not sure if putting here my favorite content (duplicate) is wasting this 2TB SSD.\n  \n\n\n-T7 Shield 4TB:\n And when I thought I had enough SSDs to fulfill my needs… I saw a sale on the T7 Shield 4TB SSD, at less than half the price. Obviously, I had to get it. So now I have this 4TB SSD that I can carry with me with EVERYTHING I have on the other SSDs, in just one drive.\n  \n\n    However, when I go to the Uni, the SSD I want to carry with me is the T5 500GB. It’s the cheapest and everything on it will -hopefully- be backed up.\n  \n\n\nMy main doubt is (option A)\n wether to use the T5 1TB SSD for personal stuff that I already have on the WD My PassPort, but that’s not data I use too much. In this case I would use the 2TB SSD for my classes (long term) AND my favorite media content such as movies and shows.\n  \n\n\nThe alternative (option B)\n is to use the T5 1TB for storing my classes long term (short term is what the 500GB is for), and leave the 2TB SSD just for non-personal media.\n  \n\n    In this case (option B), among the personal data from the WD drive, I could make a selection, i.e. all my personal photos and memories and PDFs and documents, and put them on the 4TB drive along with the media stuff and my uni stuff to have everything in one drive.\n  \n\n     \n  \n\n    I could also use this 4TB SSD to sort all the duplicates I have on every hard drive, which I suspect they are a lot. I think it’s easier having all in one drive.\n  \n\n    Don’t worry about privacy, as I’m formatting all the T5 and T7 with encryption and a 16-20 character long password, a different one for each drive.\n  \n\n     \n  \n\n\nHow would you use the 4 SSDs if you were me?\n\n\n\n    You can also comment on my hardware if you want. The Toshiba Canvio Basic were cheap and extraordinarily reliable and silent hard drives that still work perfectly after more than 10 years."},
{"Title": "Any way to make a cheap docking station or something similar?", "Author": "u/BiggieChezes", "Content": "I have a few smaller 256GB, and 512GB scrap hard drives.\n  \n\n    And I wanted to turn them into home theater storage. I thought about a Plex server but decided against it since I only need it for 1 device and the regular PC motherboard (just an old crappy pc) usually didn't have enough sata ports.\n  \n\n    So I'm looking for something (or to make something) that powers the multiple hard drives and sends the storage signal via a single USB A (don't care if it's janky as hell) tho I don't care for redundancy.\n  \n\n    Did think about just buying a few HHD enclosures but tbh I don't like that since every one of them would need a different power cable and they cost a bit. A 256 GB USB would cost the same as getting an enclosure for an old 256GB hard drive.\n  \n\n    And I do mean a cheap option since if it costs nearly 100 euros it's way more price-effective just to buy a 4 TB hard drive with an enclosure."},
{"Title": "Flash NAS help", "Author": "u/Oblec", "Content": "I love to build a NAS with only flash storage. But looking at prices, m2 storage seems to be the way to go 4x 8tb nvme 15-16tb should be enough for me. I also gonna add two 10tb for my surveillance. Im concerned the lifetime of it won’t be that good. Is that an issue?"},
{"Title": "How do you guys keep your files organized?", "Author": "u/ramy_chaos", "Content": "Hi everyone!\n  \n\n    So ive got a bunch of external and internal drives and my pc just feels like a cluttered mess in terms of storage. Ive got files all over the place, some of which are duplicates, and it's driving me nuts. If anyone has any advice, id be super grateful!"},
{"Title": "I thought what I wanted was simple, then I read on here and now I'm confused. Can I get some ELI5 advice on expanding my storage?", "Author": "u/LoliSukhoi", "Content": "All I want is additional storage space for archiving files off of my PC that has some protection against drive failure. What is the simplest method of achieving this?\n  \n\n    Until recently I used a Synology 4 bay NAS but I've outgrown it and since I never used 99% of the features of a NAS, I decided to get a 10 bay IcyBox DAS (I think it's a DAS? It connects via USBC) that I saw on sale along with 4 24TB Seagate drives. My idea was to then use Windows Storage Spaces to create a pool and mirror the drives to add redundancy.\n  \n\n    But then I saw a lot of people on here really don't like Storage Spaces which sent me down a rabbit hole of Googling and reading threads which involved a million acronyms and other words and names I don't understand and now I'm thoroughly confused. Like what's the difference between a DAS and a JBOD? What's a Home Lab? What's ZFS? (I'm just asking these to show the kind of research mess I've ended up in, don't feel the need to spend paragraphs answering them.)\n  \n\n    Is Storage Spaces good enough for what I want? Will it easily allow me to add more drives to the pool down the line? Did I buy the wrong thing? Should I have done something else?"},
{"Title": "how to check are files good or damaged?", "Author": "u/oO0_", "Content": "i do simple backups.\n  \n\n    But how can i check if current files are good? Is there way to check (hash or what) that file should have unless i change file by myself or by some software?\n  \n\n    Most files on Windows/NTFS"},
{"Title": "For a folder of media files, is it possible to get a directory list  with media encoded type? AV1 H264 etc.?", "Author": "u/danuser8", "Content": "Looking for solution in windows"},
{"Title": "i've got a couple HP 4k13c5 HBAs from salvaged machines, which include the onboard cache. but i only see folks praising LSI HBAs on here. should i spend the $35 on a LSI ?", "Author": "u/ImaginaryCheetah", "Content": "\"when in rome\", as they say.\n  \n\n    for someone generally ignorant on good verses bad HBAs, i assume there's a reason for the cult status of LSI, but is there any reason to not use the free HP ones i've got ?\n  \n\n    having onboard cache seems like a useful feature, but might not be worth the potential issue with HP drivers."},
{"Title": "Encryption tool that could output smaller chunks of encrypted blocks?", "Author": "u/SuperElephantX", "Content": "Long story short, need some tools that could securely do file/folder encryption and output as smaller chunks of encrypted blocks.\n  \n\n    Benefits: Easier to track small changes without hashing 1TB of data. Easier to sync to the cloud.\n  \n\n    Had been using \nVeraCrypt\n for ages and worked fine every time (Container's too large).\nAlso heard of \nCryptomator\n, but the reputation of the software made me stepped away from it (Corruption issues)\n  \n\n    Any solutions that you guys could recommend would fit the need of mine?\n  \n\n\n\n\n\n    Backed by secure algo like AES\n  \n\n\n\n\n\n    Auto splitting chunks into smaller file sizes.\n  \n\n\n\n\n\n    Content change only affects the necessary encrypted blocks and not all of them."},
{"Title": "Migrating Drobo user saying thanks for the help, and one more question", "Author": "u/Splitsurround", "Content": "Thanks for the guidance towards my new DAS, friends. It took a while for me to really understand the options, software raid vs hardware, how many bays I needed, the limitations of  it, etc. So I've settled on the Terramaster 6 bay DAS  D6-320. I will put 6 16TB drives in it. I'll be using Softraid with it, thus my next question:\n  \n\n    since softraid doesn't do raid 6 yet, what flavor would you recommend for me? I need at least one disk failure protection, but wouldn't hate two. I don't understand what some of the raid options mean by \"at least one disk protection\" fwiw. Looking for the most usable space with the most comprehensive \"realistic\" protection\n  \n\n    Thanks again, and looking forward to getting moved to something stable"},
{"Title": "PSA: 14TB WD Red Plus (WD140EFGX) back in stock at Western Digital", "Author": "u/SimplyDown", "Content": "https://www.westerndigital.com/products/internal-drives/wd-red-plus-sata-3-5-hdd?sku=WD140EFGX\n\n\n\n    Just posting in case anyone else has been trying to get their hands on one since they've all but disappeared over the past year.  If you're wondering why it's anything special, it's the largest reasonably quiet HD if you're looking for a low noise solution compared to the typical enterprise HD.\n  \n\n    I logged into my WD account and added 5 to my cart.  Checked back a couple of times over a few hours and WD ended up emailing me a 15% off one time discount code to finish checking out.  I'm also receiving 18% rewards on Western Digital through Capital One Shopping (after window shopping Western Digital site a few times on the app).  Not sure if this is normal or some special push for Memorial Day Weekend.   But final price for me ends up at $220.15 + tax plus $39.63 in rewards per HD."},
{"Title": "Is cloud storage/sync and online backup redundant?", "Author": "u/AreaMuppet", "Content": "I've used Google Drive sparingly for years but recently upgraded to a Google One 2TB account to give me and my family more storage and syncing capability across devices, as well as allowing me to consolidate all of the files on my laptop - which includes all of the \"family management\" documents, photos, videos, etc. - in one place rather than split up so I could stay under my 15GB free Google account limit.\n  \n\n    For years I have also used online backup. I've used IDrive in recent years (I've seen some complaints here, but I've found it to be fine, if a bit clunky) and Carbonite before that.\n  \n\n    But with my IDrive renewal coming up, I have wondered if having both Google Drive and IDrive are redundant. Years ago, I recall reading that online backup was still necessary because cloud storage wasn't reliable. But it seems like cloud storage has come a long way in terms of reliability and features, like file versioning and retrieval in case of loss.\n  \n\n    I've looked extensively and been surprised not to find much information on that question. Is there a consensus? (I should add that I also back up to an external hard drive so I do maintain multiple copies.)"},
{"Title": "Just bought a 1TB Samsung 980 PRO. Should I return it?", "Author": "u/greencalx8", "Content": "So basically I read about all the firmware issues and kinda scared me. I did my research inside this subreddit before buying it, but now I have doubts, even though I shouldn't have any problems since it was manufactured in October 2023. What are your thoughts? Should I return it? I didn't have any more options available (cost me 88€).\n  \n\n    Forgot to say that I'm using it with Immich to back up all my pictures, and it will be on 24/7.\n  \n\n    Thanks in advance."},
{"Title": "Transferring iCloud to PC not going very well", "Author": "u/NegativeNiek", "Content": "So my iCloud has been full for a while, and I wanted to transfer everything to my local pc storage, so I requested my data as rar files, and eventually got those, unzipped them and everything, but now I just have these 6 25gb folders with images and videos from random dates (because the dates didn't save and I don't know how to sort on EXIF data) and I don't even know how to find the most recent saved image inbetween them all.. Could someone maybe help me figure out how to get all these dates back into place?"},
{"Title": "Alternative to paperless-ngx for archiving magazines?", "Author": "u/GibtNixZuSehen", "Content": "Is there any good alternative to paperless-ngx for archiving >5000 magazines and books in pdf format?\n  \n\n    Would be nice to have full text search over all documents.\n  \n\n    I'm running an paperless-ngx container on my proxmox server but several pdfs take ages to ocr and indexing. Still have >4500 files to go and the files I added so far took several days to complete."},
{"Title": "Why is SSD price increasing from last year?", "Author": "u/AntarcticNightingale", "Content": "I was looking at the SSD I bought last year and found them generally increased from the past year by almost $100. What caused this? Just curious.\n  \n\n\nhttps://camelcamelcamel.com/product/B09VLJ7VBM\n\n\n\n\nhttps://camelcamelcamel.com/product/B0BHZQGN26"},
{"Title": "30+ usb hard drives, 20+ years of hoarding.", "Author": "u/password_too_short", "Content": "so i've amassed just over 30 usb 2.5\" hard drives. i'm in my mid 30's and i use them to store basically every tv show and move i've ever watched.\n  \n\n    and yep, i do re-watch stuff.\n  \n\n    none of them have failed yet. except my music drive that makes a high pitched whine sometimes and lots of beeps...yeah i might replace that...but haven't yet.\n  \n\n    for some reason i don't hoard games i've played though.  i seem to value movies and tv and music more.\n  \n\n    anyone else with a shelf of drives? what do you store?"},
{"Title": "The WD PWL water torture THUMP!", "Author": "u/Prime_Objective666", "Content": "I was shocked at how loud the WD Pre-emptive Wear Levelling thump was! My 18Tb Elements got sent back. I then got in touch with Seagate and asked how they compere - I thought I would share my experience here in May 2024 and hope it helps:\n  \n\n\nMe:\n\n\n\n\nHi - I just got shocked about a WD 18Tb PWL thump every 5 seconds which I cannot cope with soundwise. So I am looking to Seagate to see if you offer 14+TB drives that do not have regular PWL thump sounds. I dont care about access noise nor motor whirr noise but PWL every 5 secs is like Chinese Water Torture! The ONLY issue is regular Pre-emptive Wear Levelling noises - and NOT access or drive noise\n\n\n\n\n\n\nSeagate Agent:\n\n\n\n\nUpon checking with the concern technical team, our technical team requested to inform you that, you will get a minimum sound with a lite vibration in our drives. As this sound will occur in all the hard drives, It will not be unusual like WD and this sound will not be disturbing to you. Other than that you can buy any Seagate drives according to the capacity and usage. PWL sounds will not occur in Seagate. But you can hear some minimum sort of sound and vibration can be heard slightly when the drive is in a silent room. You need not worry, you will not face any PWL sound issue in Seagate.\n\n\n\n\n\n\nMe:\n\n\n\n\nSecond question: what is the best large drive that copes with regular power cycles? In my usage, the drive will be attached to a USB external dock cabinet which powers down the drive after 20 mins of non-use. This will occur 20 times a day, Out of the SG range, what copes best?\n\n\n\n\n\n\nSeagate Agent:\n\n\n\n\nUpon checking, Seagate does not recommend to use the drives in the USB dock or using splitters or any other external connectors. We recommend and request you to use the drives directly to the host device."},
{"Title": "Having trouble copying video files to flash drive.", "Author": "u/Fantastic-Notice-756", "Content": "So, a while back I got a 2TB flash drive from a friend. I needed a new one because I was having corruption trouble with the 1TB flash drive that I'd been using. Anything I backed up to the 1TB drive would be corrupted upon reconnecting the drive to my laptop  There wasn't much on the 1TB drive, but I did have a lot of videos downloaded from YT that were clean. I thought the corruption might've been carried over, so I decided to alphabetically re download all the videos onto the 2 TB drive. Re downloading the videos going fine until I hit a bit of a snag.\n  \n\n    I'd gotten to the R and S part of the video title alphabet. After I pasted some video files onto the 2TB drive I noticed there was external corruption being caused. I know this because I tried to paste a rar of the pc version of neversoft's spider-man game onto the drive (It was the lightest game I could think of) and the archive ended up being corrupt. I can tell when it's a clean paste, because the rar will paste slowly and the green meter resembles a set of waves, but when it's a corrupted paste, it'll look more like a straight line. I took those files off the drive, re pasted the archive and the rar was just fine. I re downloaded the files, some of them were copied to the drive and didn't cause any corruption, but others would still cause corruption. I even pasted some video files from the 1TB drive and some of them would be fine, but others would have the same corruption result.\n  \n\n    I don't know if this is malware related or if it has something to do with the allocation unit size, But I have no idea how to fix it. And what's worse is that I have no way of knowing which files the 2TB drive will accept or not. I can't back anything up until this is fixed and my desktop doesn't have enough space. Any help at all will be appreciated."},
{"Title": "Is it better to sleep drives or leave them spinning in between infrequent uses?", "Author": "u/Streetamp_Lamoose", "Content": "I'm pretty new to using larger drive arrays and this seemed like the kind of place where people have things figured out. My apologies if this is basic knowledge, but my internet searching didn't seem to reveal a consensus.\nI have a Mac Studio that I use as my main machine with 14+ Tb (out of 36Tb total) of mostly RAW photos stored on a 4-Bay OWC Thunderbay enclosure (Raid 5 via SoftRaid). This enclosure is directly connected to the mac via a Thunderbolt 3 (type-C connector) to the Mac. What drives me crazy is that, for reasons unknown to me, all day everyday, the drives seem to be spinning up, spinning down, spinning up, spinning down. Rest for 2 minutes, then spin up again and down again. I had been sleeping the Mac and allowing it to sleep my disks, but no matter what settings I tried it always woke from sleep about every 5 minutes, and would spin up the drive array, only to immediately go back to sleep and deactivate them. After about 2 years of this, My Hitachi drives eventually had catastrophic failures, and corrupted HFS+ volumes. I was able to recover most of the data from various backup schemes. I decided to replace the 4 drives with Segate Datacenter Exos Enterprise drives, thinking that I would change my approach and never allow the mac to sleep (just the displays). I hoped this would mean that the drives would stay powered up and always spinning, so hopefully avoiding the massive wear and tear I was getting before through constant power cycling and mechanical acceleration. My plan seems to be failing. I never sleep the Mac, and I've tried every setting I can find in the UI menus. Even if I haven't touched the machine in days, it is still spinning up, spinning down, spinning up, spinning down every minute or so. And to make matters worse, these Enterprise drives are LOUD. My poor daughter, who tries to sleep in the room next to my computer can hear the drives all night \"Growling\" at her, crunching, and spasming and spinning loudly, even when I haven't asked to access the volumes in days. I know modern OS'es run things in the background, like indexing, Time Machine, search optimization, caching stuff, etc. But is it really so constant? And why can't I seem to prevent the drives from ever turning off, which I assume (power waste aside) would be better for the health of the drives?\nI just want to have a large Raid 5 drive directly connected to my desktop machine, with a fast connection for things like 8k video editing, and not feel like the drives are constantly power cycling themselves into an early grave. I've got to be missing something obvious here..."},
{"Title": "I want to be able to host my own personal “short video” collection and be able to scroll like TikTok.", "Author": "u/Unlikelyusername3", "Content": "New to this. I’m looking for a program that allows me to stream videos from my pc similar to Plex, but with scrollable videos more similar to TikTok for some short….clips.\n  \n\n    I haven’t seen what I’m looking for on google so I figured I’d ask the experts here. :)"},
{"Title": "DVD Case Storage", "Author": "u/Parking-Mirror3283", "Content": "Hi guys, might be a little bit strange and not sure if there's anywhere better to ask this, but i was wondering if anybody had an idea of where to get a solid storage box for full DVD sized cases as opposed to just the discs themselves?\n  \n\n    Have a bunch of PS2/Xbox/360 games collected and i want to do something better than just having them loose in a box but have had no luck finding anything."},
{"Title": "What’s your drive health checklist?", "Author": "u/Educational_Tap4663", "Content": "I’m planning on shucking a group of external hard drives to use in a homelab server I’m building. When you get a new, used, or refurbished hard drive, what are you go-to commands, tools, or processes to assess its health and performance? I’ve found several software applications, but I thought the experts of DataHoarder would know best. Cheers"},
{"Title": "Help me understand size of Pool and Volume", "Author": "u/Hakihiko", "Content": "Premise: early I tried to post in the qnap subreddit, but there isn't much movement there in this moment. So I take a chance to ask here, hoping someone can help me.\n  \n\n    Hi,\n  \n\n    I have a qnap TS-653A with a the firmware version 5.1.5.\n  \n\n    Recently I switched from 5x6TB to 5x18TB using RAID 5. Following guides online, I expanded the pool and now in the specifications it tells me that I have a Capacity of 65.45TB, Allocated 64.21TB and Unallocated 1.24TB.\n  \n\n    My DataVol1 (I have just a single volume), after the resize to increase the volume to the maximum possible size, has a Capacity of 62.99TB.\n  \n\n    Is it normal to have 1.24TB more on the pool that I cannot use to increase further the capacity of my volume? Can I use it in any way?\n  \n\n    Also, since today I used always a Thick volume. If I'll change to Thin, will I be able to use more space (aka that unallocated portion of the pool)?\n  \n\n    Thank you"},
{"Title": "Finding duplicate folders and partially-duplicate folders", "Author": "u/big-sugoi", "Content": "I've got 18 years of unorganized backups that I'm trying to sift through (deleting 95+% of it all). A lot of folders have 2-4 duplicates in bizarre completely different directories, usually hastily backed up without care when reinstalling windows every few years. Sometimes 1 duplicate was partially sifted through to clean up.\n  \n\n    Please god what do I do to make this easier. I don't want automated deletion I wanna do that part myself."},
{"Title": "Risks by using a old pc as a Nas", "Author": "u/Juaniesteban", "Content": "I have a lot of old labtops i dont use and some very old computers. Can i posibly use them as a nas? Is there a possibility that the computer dies?"},
{"Title": "Program to renew magnetic strength of bits on HDD (to counteract datarot)", "Author": "u/unable_To_Username", "Content": "Bing Chat always comes up with programs that are for data recovery or whiping without traces... but I just want a program that: Read binary... and Write binary at the exact same spot you've red it. (to newly write the magnetic information, to counteract loss of magentic field strength over years)"},
{"Title": "End of en era, Google Drive", "Author": "u/Boogertwilliams", "Content": "My old unlimited Google Drive went read only about a year ago. Been keeping the 100TB plex library still active as read only. Now finally, the message came it will be deleted in 30 days. Was a good run. But so many options now anyway, I wont really miss it. Plex Debrid, Stremio + Torrentio. Only the rarer stuff I had found over the years I put somewhere else. So long and thanks for all the fish.\n  \n\n    I have learned that I dont HAVE to be a datahoarder, lol. Just \"get what I need when I need it\""},
{"Title": "Tired of Dropbox, need something cheaper (long term)", "Author": "u/Archmaxy", "Content": "Hi guys,\n  \n\n    I've been paying monthly for Dropbox for several years now, and it's becoming a bit annoying. I am also buying a house soon and I don't mind to make a single purchase for something and be cheaper off in the long, as opposed to keeping my monthly outgoing higher because of a subscription like this.\n  \n\n\n\n    I would very much appreciate any advice to migrate to a NAS for example, as I've heard that's the most comon alternative. But I really don't know.\n  \n\n    Thanks in advance!"},
{"Title": "Help with Hard drive expansion SAS expander or new HBA card", "Author": "u/Cody112233X", "Content": "So I currently have the HBA LSI Logic SAS9211-8I  and have decided to buy more drives 16 in total I was wondering should i just buy an SAS expander like the Intel RES2SV240 or should I just buy the HBA LSI 9300-16I The HBA card is suppose to come in It mode already I think I would need to update the firmware of  the SAS expander. What would be the better option most of the drives are exos 20 tb on Truenas scale I dont know if that makes a difference. Thank for the Input."},
{"Title": "New vs used hard drive", "Author": "u/linbeg", "Content": "How do you guys select the terabyte HDD Storage that you guys use? Do you guys always buy new or are you OK with used? And if used are you worried about the driving breaking or what are the steps that you guys take to make sure that they used one will be ok and reliable? Would love to get y’all’s input !"},
{"Title": "To 'stress test' a new Sandisk Extreme PRO 2TB portable SSD to check whether it's defective, before actually using it?", "Author": "u/SaarN", "Content": "I bought this drive \nlast year\n because it was on sale and came with 5 years of warranty (and they're way cheaper now due to the bad rep), and I've just found out it has HW issues.\n  \n\n    Although WD website states that my drive's firmware doesn't need to be updated, I've seen people complaining about losing data while using up-to-date drives.\n  \n\n    How should I tackle this? It's supposed to be a portable backup drive - but it's totally worthless if I can't trust it to keep my files safe.\n  \n\n    I thought of testing the drive before putting it into actual use. Like fill it up a few times and then formatting - over and over.\n  \n\n    I don't want to kill it by exceeding the writes\\reads limits, but to make it sweat a bit and check whether it's trustworthy to be used as a.. portable drive.\n  \n\n    What do you guys think? Any suggestions?"},
{"Title": "Question: Backing up a Drivepool Pool", "Author": "u/Tsusai", "Content": "Since a Drivepool pool doesn't support VSS, how are you backing up your data?\n  \n\n    I've currently spun up a Veeam B&R VM (for synthetic full), backing up the individual volumes (can't do file backup), but the incrementals in the past 3 days since it was setup have been oddly high for not adding any data to the volumes (30-60GB).\n  \n\n    I've pondered using my licensed copy of macrium to perform synthetic file-based incrementals (complains about VSS but it carries on), but I wonder what everyone else with Drivepool does\n  \n\n    Edit: I currently have Crashplan as a online backup.  This would be for an offsite in the same city setup (currently using Truenas & Tailscale)"},
{"Title": "[DIY DAS USB-C enclosure] SATA to USB adapter with no power?", "Author": "u/jfromeo", "Content": "I am planning to build a DIY DAS with external USB-C connection to host, just like some solutions out there, for example the IcyBox IB-3810-C31\n  \nhttps://preview.redd.it/diy-das-usb-c-enclosure-sata-to-usb-adapter-with-no-power-v0-1vx9qmg1jy1d1.jpg\n\n    I know the way to go for data integrity is SATA/SAS controller/HBA, but USB-C is enough for my needs (JBOD with 1-2 simultaneous read access to mkv files, no writes at all).\n  \n\n    I have a spare SilverStone DS380B with its 8-bay hotswap backplane, along with a SilverStone SFX 500W Gold power supply. I plan to power on the system with a Supermicro CSE-PTJBOD card, with power output for the 3x120mm fans I have installed in the case.\n  \nhttps://preview.redd.it/diy-das-usb-c-enclosure-sata-to-usb-adapter-with-no-power-v0-18q935qyjy1d1.jpg\n\n    But I cannot find a way to transform the SATA outputs of the backplane to USB inputs in a USB hub which I plan to install inside the case. All the cables and interfaces SATA-to-USB I find, include the power adaptor, which does not fit the backplane SATA connections of the backplane.\n  \n\n    I would need 8 x cable adapter like the Startech one, but without the SATA power part, does it exist?\n  \nhttps://preview.redd.it/diy-das-usb-c-enclosure-sata-to-usb-adapter-with-no-power-v0-z2zpg6mbky1d1.jpg\n\n    Thanks in advance."},
{"Title": "Update Synology OS if you're using it. Several CVE's", "Author": "u/PaganLinuxGeek", "Content": "If you're using a Synology NAS, update. Several CVE posted with some issues on the OS."},
{"Title": "Migrating from Windows based NAS to Unraid", "Author": "u/CodeJBDA", "Content": "Hi All,\n  \n\n    I am moving my whole server from a windows 11 base to unRaid.\n  \n\n    I am currently using the program call drivepool to pool my 8hdds together so that Plex can look at one location. My worry is that when had to reinstall windows I had a ton of issues with ownership of the files. I am hoping to avoid that when going to unraid. Any thoughts?"},
{"Title": "What is the best method to download all saved media on Reddit in 2024?", "Author": "u/Fxxxk2023", "Content": "Hello, I want to backup all media I saved on my Reddit account. Sadly it seems as a lot of options died with Reddits crackdown on API use. What is the best way to automatically download media from all saved posts on my account?"},
{"Title": "This USB flash drive can only store 8KB of data, but will last you 200 years", "Author": "u/tzfld", "Content": "No content"},
{"Title": "best array type for me?", "Author": "u/FearlessENT33", "Content": "i currently have a server running omv, with a zfs pool with a 4tb and 2x 2tb, for a total of 8tb however there is no parity or backup so if a drive fails it all goes kaput.\n  \n\n    which means replacing- i want to upgrade my storage and have a better solution for potential drive failures, while potentially being expandable in the future. most of my data is movies / tv / music that can be reacquired, critical data is small and is backed up.\n  \n\n    my budget isn’t massive, i’ve only just started working full time, so have potentially been looking at 3x 8tb drives in a raid-z1 array, for 16tb useable. being able to add in another drive in the future would also be good, and i think raidz1 would allow this, but hopefully by that point i can just afford a completely new server.\n  \n\n    is this a good plan? or would there be a better array i could do? any advice would be much appreciated, thanks"},
{"Title": "My community didn’t quite appreciate my new data hoarder case. I geeked out over 14 modular drive bays. Lol", "Author": "u/MikeTheTech", "Content": "No content"},
{"Title": "Will burning a 1080p video on a DVD-R still make it autoplay when opened on PC?", "Author": "u/Skidbladmir", "Content": "So I know that in order for it to be played on common DVD players the video needs to be encoded in a specific format (with a max 720p resolution) but if I just want the video to be played on normal PCs will that allow me to burn a high resolution video onto the disk?"},
{"Title": "Explain Enterprise SSDs", "Author": "u/Culbrelai", "Content": "Alright so I don’t understand how this works.\n  \n\n    8tb consumer nvme pcie4 m.2 ssds run the gamut from $850 to about $1100. Sabrent Rocket, Team, and so on.\n  \n\n    They are all about 7000mbs sequential write, 6600 read.\n  \n\n    8tb is the max size as of 2024 it seems.\n  \n\n    There are also SATA ssds which also top out at 8tb and are massively slower than the NVME, but about $620 for a Samsung QVO 8tb.\n  \n\n    Meanwhile\n  \n\n\nhttps://www.amazon.com/SOLIDIGM-D5-P5430-15-36-TB-Intensive/dp/B0C6BR89C2/ref=mp_s_a_1_8?crid=BBQOQ2PIYQDC&dib=eyJ2IjoiMSJ9.ylEfhDF9TJGI_8EwgLEBHUXoDzf17amHeqJMISzMk2x7tf7hXg1PgheTCstANtyVpEAD28qRj_TYx1CvOTh1hZbsgSteo1rgvqG8UQugG6-wnRrhgmph4dr-4AxHVAP6ebCn0J4ZQ83fvJcw2ZFnLBcaagyvJ_amnEjwjrB_Jszlx1cPmEOZmVoXaHjaUgaY839fH40SQWInIifesfAEag.o2h7SYjhTQoKgyvfpAGEtn7Mu2zDsfs4Gn3XrXFZKfQ&dib_tag=se&keywords=Solidigm&qid=1716304607&sprefix=solidigm%2Caps%2C115&sr=8-8\n\n\n\n    This enterprise drive is double the capacity of the sabrent, for $1500 instead of the $2200 you’d need in m.2 to match. Half as fast in writes. Would take one less m.2 slot than the dual m.2 solution and therefore more lanes could be used elsewhere. Would need a relatively cheap m.2/u.2 adapter. Has higher durability ratings and longer warranties than the consumer options.\n  \n\n    Why are high capacity SSDs only offered to enterprises? I don’t get it. Is there no consumer demand for SSDs greater than 8tb? What’s the catch? I’m close to just buying one of these and replacing 3 m.2 steam game drives with it."},
{"Title": "Which software RAIDs allow triple parity?", "Author": "u/reddit_faa7777", "Content": "Out of all the software raids, which ones allow having 3 (or maybe 4) parity drives, amongst like 16+ drives?\n  \n\n    I'm thinking of doing this on Windows 11. I won't be using Linux as it's easier installing my VPN on Windows.\n  \n\n    I'm not a huge fan of Snapraid because..... when doing important tasks I like to use a GUI."},
{"Title": "Long-term storage and organization of CD/DVD/B BLU-RAY.", "Author": "u/KaleMercer", "Content": "I have a massive collection of movies, music, TV shows, and assorted disc-based media. There is little to no resale values so I'm not even interested in trying, But at the same time I'm not just going to chuck them in the trash is that would just be wasteful And I paid for these.\n  \n\n    Looking for suggestions, opinions, and or recommendations for organization/ storage of the discs of themselves. I want to get them out of their cases as they take up a massive amount of space.\n  \n\n    I was thinking about just getting one of the large disks cases but was wondering if there was anything more interesting?"},
{"Title": "Kiwix wikipedia zim file ends up being corrupted no matter what", "Author": "u/kaczynski_machine", "Content": "Hi guys, I have recently gained an interest to download alal of wikipedia just in case. So i chose to use Kiwix using the .zim file from:\n  \n\n\nhttps://download.kiwix.org/zim/wikipedia/\n,  en_all_maxi_2024-01.zim.\n  \n\n    Downloading it is all fine and great, And in fact once it is downloaded on either of my computers (Yes, I tried on both my laptop and on my desktop.) I am able to open it using Kiwix and read it.\n  \n\n    But obviously I want to keep the zim file safe so I can have it ready at a moments notice without needing to download it every time... So I've tried to put it on my SSD.\n  \n\n    SO I guess the issue I'm having is when I try to copy the .zim file onto my disk, it seemingly went fine with no obvious mistakes. But then I disconnect the external ssd from my Desktop and connect it to my laptop to open it there (my way of testing if it is being kept safe on the disk.) and everytime some specific new error shows up when I try to open it in Kiwix. Sometimes its outright corrupted, sometimes it's missing articles. Like putting it on the SSD corrupted the .zim file somehow. Which would be a bummer because this external ssd  is new and works like a charm usually, its just somehow not working for this specific file.\n  \n\n    A few notes:\nI have already tried compressing the file into .7r or .zip. Same type of corruption occurs after interacting with the SSD.\n  \n\n    The SSD: 1TB, connected to my computer using a usb-c to USB cable. it is external.\n  \n\n    I already ran \"chkdsk D: /f\"  for the disk to check for any bad sectors, but the program reported zero bad sectors and said everything is fine.\n  \n\n    I have also tried to reformat the drive to both NTFS and exFat. Nothing works. I'm so dissapointed. And feel stupid. Please help me, thank you! Have a pleasant day."},
{"Title": "Mechanical Engineer looking for other DataHoarders for Engineering Knowledge", "Author": "u/Liizam", "Content": "Hi there, I’m new to data hoarding. I’ve noticed some of the design guides and other useful info disappearing from the internet and being places behind paid pdfs sites.\n  \n\n    I would love to connect to other engineers on here to see what we can do. I have a pile of knowledge I’ve been collection throughout the years."},
{"Title": "High capacity HDD for workstation- surveillance drive? Enterprise? ~20+ tb", "Author": "u/theseawoof", "Content": "Noticed that these drives tend to be the ones that easily have up to 24tb or so. I need a large HDD of around 20-24tb to hold my music and video software, VSTs, samples, video footage and assets, etc. Right now my case is maxed out with HDDs and I've had two consumer Seagate drives fail within recent years. I am willing to spend the ~$500 for one drive of high capacity if there is no downside.\n  \n\n    Someone recommended WD Purple, saying that surveillance drives hold up to constant usage, but someone else mentioned that they have a slightly lower read speed. What would you choose for something if high capacity and longevity that is going to hold up to usage and not just general storage?"},
{"Title": "How to extract raw files from multiple DVDs at the same time?", "Author": "u/TRUE_BIT", "Content": "I have approx 6k DVDs that need the raw files extracted from them. These aren't movies, just acting as storage media.\n  \n\n    They will be transferred locally or to a network share.\n  \n\n    I was thinking about getting multiple DVD to USB devices (5-8, depending on what would be most performant).\n  \n\n    I feel like I would be at the mercy of the USB transfer speeds. I'm not sure if USB-C will be available.\n  \n\n    Is there a better way to do this? Is there an optimal way to get the most out of my transfer speeds? A coworker suggested looking into leveraging VMs but I don't see how that would help."},
{"Title": "Any 16TB SSD Options Out There?", "Author": "u/ShiitakeTheMushroom", "Content": "I'm looking for a 16TB or larger SSD, but haven't been able to find anything larger than 8TB. Any good options out there that folks have been using?"},
{"Title": "Finding duplicate folders and partially-duplicate folders", "Author": "u/big-sugoi", "Content": "I've got 18 years of unorganized backups that I'm trying to sift through (deleting 95+% of it all). A lot of folders have 2-4 duplicates in bizarre completely different directories, usually hastily backed up without care when reinstalling windows every few years. Sometimes 1 duplicate was partially sifted through to clean up.\n  \n\n    Please god what do I do to make this easier. I don't want automated deletion I wanna do that part myself."},
{"Title": "Risks by using a old pc as a Nas", "Author": "u/Juaniesteban", "Content": "I have a lot of old labtops i dont use and some very old computers. Can i posibly use them as a nas? Is there a possibility that the computer dies?"},
{"Title": "Program to renew magnetic strength of bits on HDD (to counteract datarot)", "Author": "u/unable_To_Username", "Content": "Bing Chat always comes up with programs that are for data recovery or whiping without traces... but I just want a program that: Read binary... and Write binary at the exact same spot you've red it. (to newly write the magnetic information, to counteract loss of magentic field strength over years)"},
{"Title": "End of en era, Google Drive", "Author": "u/Boogertwilliams", "Content": "My old unlimited Google Drive went read only about a year ago. Been keeping the 100TB plex library still active as read only. Now finally, the message came it will be deleted in 30 days. Was a good run. But so many options now anyway, I wont really miss it. Plex Debrid, Stremio + Torrentio. Only the rarer stuff I had found over the years I put somewhere else. So long and thanks for all the fish.\n  \n\n    I have learned that I dont HAVE to be a datahoarder, lol. Just \"get what I need when I need it\""},
{"Title": "Tired of Dropbox, need something cheaper (long term)", "Author": "u/Archmaxy", "Content": "Hi guys,\n  \n\n    I've been paying monthly for Dropbox for several years now, and it's becoming a bit annoying. I am also buying a house soon and I don't mind to make a single purchase for something and be cheaper off in the long, as opposed to keeping my monthly outgoing higher because of a subscription like this.\n  \n\n\n\n    I would very much appreciate any advice to migrate to a NAS for example, as I've heard that's the most comon alternative. But I really don't know.\n  \n\n    Thanks in advance!"},
{"Title": "Help with Hard drive expansion SAS expander or new HBA card", "Author": "u/Cody112233X", "Content": "So I currently have the HBA LSI Logic SAS9211-8I  and have decided to buy more drives 16 in total I was wondering should i just buy an SAS expander like the Intel RES2SV240 or should I just buy the HBA LSI 9300-16I The HBA card is suppose to come in It mode already I think I would need to update the firmware of  the SAS expander. What would be the better option most of the drives are exos 20 tb on Truenas scale I dont know if that makes a difference. Thank for the Input."},
{"Title": "New vs used hard drive", "Author": "u/linbeg", "Content": "How do you guys select the terabyte HDD Storage that you guys use? Do you guys always buy new or are you OK with used? And if used are you worried about the driving breaking or what are the steps that you guys take to make sure that they used one will be ok and reliable? Would love to get y’all’s input !"},
{"Title": "To 'stress test' a new Sandisk Extreme PRO 2TB portable SSD to check whether it's defective, before actually using it?", "Author": "u/SaarN", "Content": "I bought this drive \nlast year\n because it was on sale and came with 5 years of warranty (and they're way cheaper now due to the bad rep), and I've just found out it has HW issues.\n  \n\n    Although WD website states that my drive's firmware doesn't need to be updated, I've seen people complaining about losing data while using up-to-date drives.\n  \n\n    How should I tackle this? It's supposed to be a portable backup drive - but it's totally worthless if I can't trust it to keep my files safe.\n  \n\n    I thought of testing the drive before putting it into actual use. Like fill it up a few times and then formatting - over and over.\n  \n\n    I don't want to kill it by exceeding the writes\\reads limits, but to make it sweat a bit and check whether it's trustworthy to be used as a.. portable drive.\n  \n\n    What do you guys think? Any suggestions?"},
{"Title": "Question: Backing up a Drivepool Pool", "Author": "u/Tsusai", "Content": "Since a Drivepool pool doesn't support VSS, how are you backing up your data?\n  \n\n    I've currently spun up a Veeam B&R VM (for synthetic full), backing up the individual volumes (can't do file backup), but the incrementals in the past 3 days since it was setup have been oddly high for not adding any data to the volumes (30-60GB).\n  \n\n    I've pondered using my licensed copy of macrium to perform synthetic file-based incrementals (complains about VSS but it carries on), but I wonder what everyone else with Drivepool does\n  \n\n    Edit: I currently have Crashplan as a online backup.  This would be for an offsite in the same city setup (currently using Truenas & Tailscale)"},
{"Title": "[DIY DAS USB-C enclosure] SATA to USB adapter with no power?", "Author": "u/jfromeo", "Content": "I am planning to build a DIY DAS with external USB-C connection to host, just like some solutions out there, for example the IcyBox IB-3810-C31\n  \nhttps://preview.redd.it/diy-das-usb-c-enclosure-sata-to-usb-adapter-with-no-power-v0-1vx9qmg1jy1d1.jpg\n\n    I know the way to go for data integrity is SATA/SAS controller/HBA, but USB-C is enough for my needs (JBOD with 1-2 simultaneous read access to mkv files, no writes at all).\n  \n\n    I have a spare SilverStone DS380B with its 8-bay hotswap backplane, along with a SilverStone SFX 500W Gold power supply. I plan to power on the system with a Supermicro CSE-PTJBOD card, with power output for the 3x120mm fans I have installed in the case.\n  \nhttps://preview.redd.it/diy-das-usb-c-enclosure-sata-to-usb-adapter-with-no-power-v0-18q935qyjy1d1.jpg\n\n    But I cannot find a way to transform the SATA outputs of the backplane to USB inputs in a USB hub which I plan to install inside the case. All the cables and interfaces SATA-to-USB I find, include the power adaptor, which does not fit the backplane SATA connections of the backplane.\n  \n\n    I would need 8 x cable adapter like the Startech one, but without the SATA power part, does it exist?\n  \nhttps://preview.redd.it/diy-das-usb-c-enclosure-sata-to-usb-adapter-with-no-power-v0-z2zpg6mbky1d1.jpg\n\n    Thanks in advance."},
{"Title": "Update Synology OS if you're using it. Several CVE's", "Author": "u/PaganLinuxGeek", "Content": "If you're using a Synology NAS, update. Several CVE posted with some issues on the OS."},
{"Title": "Migrating from Windows based NAS to Unraid", "Author": "u/CodeJBDA", "Content": "Hi All,\n  \n\n    I am moving my whole server from a windows 11 base to unRaid.\n  \n\n    I am currently using the program call drivepool to pool my 8hdds together so that Plex can look at one location. My worry is that when had to reinstall windows I had a ton of issues with ownership of the files. I am hoping to avoid that when going to unraid. Any thoughts?"},
{"Title": "What is the best method to download all saved media on Reddit in 2024?", "Author": "u/Fxxxk2023", "Content": "Hello, I want to backup all media I saved on my Reddit account. Sadly it seems as a lot of options died with Reddits crackdown on API use. What is the best way to automatically download media from all saved posts on my account?"},
{"Title": "This USB flash drive can only store 8KB of data, but will last you 200 years", "Author": "u/tzfld", "Content": "No content"},
{"Title": "best array type for me?", "Author": "u/FearlessENT33", "Content": "i currently have a server running omv, with a zfs pool with a 4tb and 2x 2tb, for a total of 8tb however there is no parity or backup so if a drive fails it all goes kaput.\n  \n\n    which means replacing- i want to upgrade my storage and have a better solution for potential drive failures, while potentially being expandable in the future. most of my data is movies / tv / music that can be reacquired, critical data is small and is backed up.\n  \n\n    my budget isn’t massive, i’ve only just started working full time, so have potentially been looking at 3x 8tb drives in a raid-z1 array, for 16tb useable. being able to add in another drive in the future would also be good, and i think raidz1 would allow this, but hopefully by that point i can just afford a completely new server.\n  \n\n    is this a good plan? or would there be a better array i could do? any advice would be much appreciated, thanks"},
{"Title": "My community didn’t quite appreciate my new data hoarder case. I geeked out over 14 modular drive bays. Lol", "Author": "u/MikeTheTech", "Content": "No content"},
{"Title": "Will burning a 1080p video on a DVD-R still make it autoplay when opened on PC?", "Author": "u/Skidbladmir", "Content": "So I know that in order for it to be played on common DVD players the video needs to be encoded in a specific format (with a max 720p resolution) but if I just want the video to be played on normal PCs will that allow me to burn a high resolution video onto the disk?"},
{"Title": "Explain Enterprise SSDs", "Author": "u/Culbrelai", "Content": "Alright so I don’t understand how this works.\n  \n\n    8tb consumer nvme pcie4 m.2 ssds run the gamut from $850 to about $1100. Sabrent Rocket, Team, and so on.\n  \n\n    They are all about 7000mbs sequential write, 6600 read.\n  \n\n    8tb is the max size as of 2024 it seems.\n  \n\n    There are also SATA ssds which also top out at 8tb and are massively slower than the NVME, but about $620 for a Samsung QVO 8tb.\n  \n\n    Meanwhile\n  \n\n\nhttps://www.amazon.com/SOLIDIGM-D5-P5430-15-36-TB-Intensive/dp/B0C6BR89C2/ref=mp_s_a_1_8?crid=BBQOQ2PIYQDC&dib=eyJ2IjoiMSJ9.ylEfhDF9TJGI_8EwgLEBHUXoDzf17amHeqJMISzMk2x7tf7hXg1PgheTCstANtyVpEAD28qRj_TYx1CvOTh1hZbsgSteo1rgvqG8UQugG6-wnRrhgmph4dr-4AxHVAP6ebCn0J4ZQ83fvJcw2ZFnLBcaagyvJ_amnEjwjrB_Jszlx1cPmEOZmVoXaHjaUgaY839fH40SQWInIifesfAEag.o2h7SYjhTQoKgyvfpAGEtn7Mu2zDsfs4Gn3XrXFZKfQ&dib_tag=se&keywords=Solidigm&qid=1716304607&sprefix=solidigm%2Caps%2C115&sr=8-8\n\n\n\n    This enterprise drive is double the capacity of the sabrent, for $1500 instead of the $2200 you’d need in m.2 to match. Half as fast in writes. Would take one less m.2 slot than the dual m.2 solution and therefore more lanes could be used elsewhere. Would need a relatively cheap m.2/u.2 adapter. Has higher durability ratings and longer warranties than the consumer options.\n  \n\n    Why are high capacity SSDs only offered to enterprises? I don’t get it. Is there no consumer demand for SSDs greater than 8tb? What’s the catch? I’m close to just buying one of these and replacing 3 m.2 steam game drives with it."},
{"Title": "Which software RAIDs allow triple parity?", "Author": "u/reddit_faa7777", "Content": "Out of all the software raids, which ones allow having 3 (or maybe 4) parity drives, amongst like 16+ drives?\n  \n\n    I'm thinking of doing this on Windows 11. I won't be using Linux as it's easier installing my VPN on Windows.\n  \n\n    I'm not a huge fan of Snapraid because..... when doing important tasks I like to use a GUI."},
{"Title": "Long-term storage and organization of CD/DVD/B BLU-RAY.", "Author": "u/KaleMercer", "Content": "I have a massive collection of movies, music, TV shows, and assorted disc-based media. There is little to no resale values so I'm not even interested in trying, But at the same time I'm not just going to chuck them in the trash is that would just be wasteful And I paid for these.\n  \n\n    Looking for suggestions, opinions, and or recommendations for organization/ storage of the discs of themselves. I want to get them out of their cases as they take up a massive amount of space.\n  \n\n    I was thinking about just getting one of the large disks cases but was wondering if there was anything more interesting?"},
{"Title": "Kiwix wikipedia zim file ends up being corrupted no matter what", "Author": "u/kaczynski_machine", "Content": "Hi guys, I have recently gained an interest to download alal of wikipedia just in case. So i chose to use Kiwix using the .zim file from:\n  \n\n\nhttps://download.kiwix.org/zim/wikipedia/\n,  en_all_maxi_2024-01.zim.\n  \n\n    Downloading it is all fine and great, And in fact once it is downloaded on either of my computers (Yes, I tried on both my laptop and on my desktop.) I am able to open it using Kiwix and read it.\n  \n\n    But obviously I want to keep the zim file safe so I can have it ready at a moments notice without needing to download it every time... So I've tried to put it on my SSD.\n  \n\n    SO I guess the issue I'm having is when I try to copy the .zim file onto my disk, it seemingly went fine with no obvious mistakes. But then I disconnect the external ssd from my Desktop and connect it to my laptop to open it there (my way of testing if it is being kept safe on the disk.) and everytime some specific new error shows up when I try to open it in Kiwix. Sometimes its outright corrupted, sometimes it's missing articles. Like putting it on the SSD corrupted the .zim file somehow. Which would be a bummer because this external ssd  is new and works like a charm usually, its just somehow not working for this specific file.\n  \n\n    A few notes:\nI have already tried compressing the file into .7r or .zip. Same type of corruption occurs after interacting with the SSD.\n  \n\n    The SSD: 1TB, connected to my computer using a usb-c to USB cable. it is external.\n  \n\n    I already ran \"chkdsk D: /f\"  for the disk to check for any bad sectors, but the program reported zero bad sectors and said everything is fine.\n  \n\n    I have also tried to reformat the drive to both NTFS and exFat. Nothing works. I'm so dissapointed. And feel stupid. Please help me, thank you! Have a pleasant day."},
{"Title": "Mechanical Engineer looking for other DataHoarders for Engineering Knowledge", "Author": "u/Liizam", "Content": "Hi there, I’m new to data hoarding. I’ve noticed some of the design guides and other useful info disappearing from the internet and being places behind paid pdfs sites.\n  \n\n    I would love to connect to other engineers on here to see what we can do. I have a pile of knowledge I’ve been collection throughout the years."},
{"Title": "High capacity HDD for workstation- surveillance drive? Enterprise? ~20+ tb", "Author": "u/theseawoof", "Content": "Noticed that these drives tend to be the ones that easily have up to 24tb or so. I need a large HDD of around 20-24tb to hold my music and video software, VSTs, samples, video footage and assets, etc. Right now my case is maxed out with HDDs and I've had two consumer Seagate drives fail within recent years. I am willing to spend the ~$500 for one drive of high capacity if there is no downside.\n  \n\n    Someone recommended WD Purple, saying that surveillance drives hold up to constant usage, but someone else mentioned that they have a slightly lower read speed. What would you choose for something if high capacity and longevity that is going to hold up to usage and not just general storage?"},
{"Title": "How to extract raw files from multiple DVDs at the same time?", "Author": "u/TRUE_BIT", "Content": "I have approx 6k DVDs that need the raw files extracted from them. These aren't movies, just acting as storage media.\n  \n\n    They will be transferred locally or to a network share.\n  \n\n    I was thinking about getting multiple DVD to USB devices (5-8, depending on what would be most performant).\n  \n\n    I feel like I would be at the mercy of the USB transfer speeds. I'm not sure if USB-C will be available.\n  \n\n    Is there a better way to do this? Is there an optimal way to get the most out of my transfer speeds? A coworker suggested looking into leveraging VMs but I don't see how that would help."},
{"Title": "Any 16TB SSD Options Out There?", "Author": "u/ShiitakeTheMushroom", "Content": "I'm looking for a 16TB or larger SSD, but haven't been able to find anything larger than 8TB. Any good options out there that folks have been using?"},
{"Title": "WD My Book Duo eating drives :(", "Author": "u/No_Reflection1510", "Content": "I have had this 16TB My Book Duo (2x 8TB drives mirrored) for about 4 years. I only use it to store old photos and video that I don't want to lose but also for Time Machine backups.\n  \n\n    A few months ago one ofthe drives died so I got a replacement (see below). The raid rebuilt itself in a few days and I thought it was golden again. A week or two goes by and the other drive dies. So I get another of the same drive replace/rebuild and figured NOW I'm golden.\n  \n\n    Fast fwd to now, I've got another drive failure. This is getting pretty old.  So I guess I'm just looking for some advice. Should I keep trusting this WD enclosure and get yet another replacement drive? Should I abandon it and switch to something else? I really just don't want to lose this data.\n  \n\n    I'd like to just shove all this data into Google Drive and be done with external enclosures for this but ~8TB is a lot to upload and would take my little uplink weeks or months to do so and it seems likely that my one remaining drive would fail in that timeframe :-(\n  \n\n    Replacement drives were both: \nWestern Digital 8TB WD Red Plus NAS Internal Hard Drive HDD - 5640 RPM, SATA 6 Gb/s, CMR, 256 MB Cache, 3.5\" - WD80EFPX"},
{"Title": "I want to automatically back up the contents of one external hard drive to another in a different house. Which software would let me do this?", "Author": "u/PradleyBitts", "Content": "I don't really want sync, i.e I don't want something that gets deleted on one drive to get deleted on another. Just want all the content added to one hard drive backed up to another in a different house automatically."},
{"Title": "backing up folders to S3 (compatible software), weekly, with terminal", "Author": "u/leurs247", "Content": "Hi all,\n  \n\n    I have some important files (not much atm, about 5GB) I want to upload to a (secure) online storage (cheap if possible).\n  \n\n    I already have the data on my local machine (macbook pro) and an external harddrive, but I want an online storage solution as well.\n  \n\n    I have used aws S3 before (for my work) so I have some knowledge. I could make a bucket to store the data.\n  \n\n    Is there any interesting (free) software I can use (on a mac) to backup some folders to s3. I have mountainduck on my laptop but only in trial.\n  \n\n    Another possible solution is to create a bash script to upload specific folders to s3 (not necessarily aws, could also be digitalocean) on an regular basis. I could possibly make a script with rclone, is this a good usecase for this?\n  \n\n    I could add a cronjob (like every sunday at 01AM) but my laptop is probably in sleep mode at that time, how can I create a script that runs at sunday 01AM OR when I first start my laptop after that time?\n  \n\n    Thanks!"},
{"Title": "Data recovery on failed drives - is it ever practical or reasonably priced for a regular joe?", "Author": "u/riftwave77", "Content": "I have two old drives that failed years ago that i've been keeping around on the off chance that HDD recovery ever gets cheap enough for me to consider it.\n  \n\n    am I just wasting my time?"},
{"Title": "i've got a J4025 w/8GB memory i want to use for a backup NAS. is TrueNAS CORE viable, or do i need lighter weight freeBSD/openZFS combo ? no other services planned, but wanting compression & encryption", "Author": "u/ImaginaryCheetah", "Content": "title says it all :)\n  \n\n    any of you folks running TrueNAS on a J4025, or does the little guy not have enough juice ?"},
{"Title": "Help: Scaling Up My Storage Rig: From Synology DS920+ to Custom Build with Hot Swap", "Author": "u/Doh_facepalm_admin", "Content": "I've hit a bit of a snag in my data hoarding journey and need some advice. I started off with a Synology DS920+ in 2020, equipped it with 4x6 TB drives, and soon found myself upgrading to 4x10 TB drives as my media and container needs grew. I've been heavily using PLEX, SONARR, RADARR, among other containers, and it's been fantastic so far.\n  \n\n    However, I'm now planning to dive into 4K transcoding, enhance my setup with more RAM for network labs, and maybe even host a gaming server. The demand on my current system is skyrocketing, and once again, I'm running out of space.\n  \n\n    I'm contemplating building a custom PC since the price seems comparable to getting an 8-bay Synology unit, but I'm really hung up on finding the right case. I'd prefer something that isn't a tower due to space constraints and aesthetics, but most importantly, I need it to support hot swapping. As my data hoarding isn't slowing down any time soon, I want to easily add more drives and replace any that fail without shutting down the system.\n  \n\n    Has anyone here tackled a similar upgrade or built their own high-capacity, hot-swappable storage system? I'd love to hear about your experiences, particularly about your choice of cases and any setup tips you might have for someone looking to transition from a NAS to a custom build.\n  \n\n    Thanks in advance for any suggestions or insights!"},
{"Title": "Need desperate help recovering an old photo", "Author": "u/dmc1155", "Content": "First of all i don't know if this is the correct subreddit to ask my question, but i've been desperately searching for my old motorola razer for more than a year now and i've finally found it. This razer phone of mine has a picture of my dog that i am very desperate to recover ever since she passed. The little information i remember about the picture is that it was set as a wallpaper and i wanted to know if it is possible to extract it from the phone someway. The phone turns on and i get greeted with an unskippable \"insert sim\" pop up. Is there any program where i can download the phone's contents or maybe something like the phone's nand where i can then find the wallpaper and save it?"},
{"Title": "38% of webpages that existed in 2013 are no longer accessible a decade later", "Author": "u/retrac1324", "Content": "No content"},
{"Title": "Did I make a mistake getting the WUH721816ALE6L1 not the ALE04 or is the drive from ServerPartDeals bad?", "Author": "u/mlgSD", "Content": "I'm posting this here as you all seem to know about these Ultrastar datacenter drives. Did I make a mistake getting the WUH721816ALE6L1 not the ALE04 or is the drive from ServerPartDeals bad? The L1 is a \"self-encrypting drive\". It's supposed to be \"refurbished\" by WDC and has a new WDC label that says \"Recertified 12 NOV 2023\" and P/N 0F24861  FW:870.\n  \n\n    I previously bought two 14TB  WUH721414ALE604 drives from Amazon before I learned of \nServerPartDeals.com\n here (thanks guys!). I ran Spinrite 6.1 Level 5 on both. Each took about almost a week to do. Level 5 checks every sector, recovers (if possible) unreadable data, inverts it, writes it, reads it, verifies it, then rewrites and re-verifies each sector. One of them was fine and the other had some bad sectors at the very end so I returned it.\n  \n\n    I was thinking I should have bought a 16TB one, so after returning the 14TB to Amazon, I bought the WUH721816ALE6L1 from ServerPartDeals on Friday and got it today, Monday. Free 2nd Day Air. Very cool! I especially liked that they say it's \"Manufacturer Recertified\".\n  \n\n    Spinrite can see the drive and reads it's configuration from the drive electronics. It knows it's 16TB and how many bytes and sectors it has. It tests every drive it can recognize to be sure it can read and write sectors on each drive. However when it tests the 16TB drive to verify it can read and write the drive's sectors, that fails.\n  \n\n    I've tried this on two different systems with the same result. I did a quick test in Linux trying to 'dd' another drive to it, but it complained it can't access the drive saying that maybe it is DRM'd. The same 'dd' command works just fine with the 14TB drive.\n  \n\n    Is there something I need to do to the drive to make it work or is it just bad and needs to be returned?\n  \n\n    My apologies if I should post this elsewhere.\n  \nWDC Recertified HC550 16TB\nWUH721816A:EL1 fails Spinrite 6.1 data transfer verification"},
{"Title": "2U 4x3.5 hdd expansion 14\" depth?", "Author": "u/chinzw", "Content": "Does this exist? I've been searching everywhere, can't find anything that fits the bill.\n  \n\n    I need to add more storage to my server, my rack is 15\" deep, with plug i get about 14\" usable.\n  \n\n    Im looking to spend no more than 1000$ all in (no drives)."},
{"Title": "Samsung T7 help", "Author": "u/Creative_Emu3851", "Content": "No content"},
{"Title": "I built a self hosted version of AWS S3 using only open source technology and Raspberry Pis thats compatible with the official AWS S3 SDK", "Author": "u/Anthonyb-s3", "Content": "No content"},
{"Title": "Need advice about a DIY NAS", "Author": "u/-empty-head", "Content": "https://preview.redd.it/need-advice-about-a-diy-nas-v0-i1wla3ypmm1d1.jpg\n\n    A couple months ago a friend of mine gave me his TERRAMASTER D4-300 drive enclosure, I was thinking about getting a SBC / mini pc, or something similar and turning it into a jankie DIY NAS.\n  \n\n    The hardware I currently have for the project is, 4TB HDD × 4 and the drive enclosure\n  \n\n    My use case is pretty simple I just want mass networked bulk storage, with basic resilience In case of loss of a single drive.\n  \n\n    But I have a couple of questions about this Idea I've been having, befor I do this.\n  \n\n\n\n\n\n    I want to do this on a bit of a tight budget, so I would like some hardware suggestions.\n  \n\n\n\n\n\n    Is it actually going to work and be reasonably reliable?\n  \n\n\n\n\n\n    And any other thoughts or ideas would be very much appreciated?"},
{"Title": "Is the 2TB Seagate Barracuda 3.5 fine for my case?", "Author": "u/typcalthowawayacount", "Content": "I wanted to give a DIY Nas a try and it seems it's recommended to have a NAS specific hard drives like WD or Seagate RED, but that's if you're using it 24/7 which isn't my case. I'll be using to \nrarely\n to store videos and images on the fly, and my MOBO does support power on by PME which allows me to turn the PC on by PCI/PCIE LAn or modem card.\n  \n\n    So with that, a the 2TB Seagate Barracude should be fine then?\n  \n\n    The other hardware on my PC:\n  \n\n    MOBO: F1A55-M LX3 R2.0\n  \n\n    CPU: A4-3400\n  \n\n    RAM: 12 GB of DDR3\n  \n\n    Storage: 500GB HDD (OS)"},
{"Title": "How does p2p connection actually works on CGNAT network.", "Author": "u/Mukun00", "Content": "Hello guys,\n  \n\n    I have recently found a p2p file transfer website \nhttps://send-anywhere.com/\n .\nIn Webrtc we can't able to transfer the files through p2p while connected with CGNAT connection, but this site allows p2p even with CGNAT connection, I wonder what protocol they been used to work with CGNAT connections.\n  \n\n    Do you guys any Idea which protocol or method they used to work on CGNAT connections.\n  \n\n    Thank in advance."},
{"Title": "Is this any good? WD Red WE30EFRX + Synology DS213j", "Author": "u/Germasiansensation", "Content": "No content"},
{"Title": "Old DIY Media Server is Kaput. Looking for Advice!", "Author": "u/HightopNinja", "Content": "Hi all,\n  \n\n    Last week, my beast of an old machine decided to give up the ghost. This machine served as both a media server (DVD/Blu-ray rips and music) and as a HTPC in my living room (used for watching media on the server and watching streaming services).\n  \n\n    I managed to pull the data off the drives and am currently running some tests on them to make sure there are no issues. (They are older drives, and quite small by today's standards).\n  \n\n    Thankfully, no data lost!\n  \n\n    I'm trying to figure out the best solution for myself going forward. Should I go NAS for storage and grab a mini-pc (N100 Beelink or similar) for the living room? Should I build a new HTPC/Server? (it would need to be somewhat cost effective)\n  \n\n    The main uses I need are:\nSharing of media over our home network (in house only)\nI'd like to run a Jellyfin or Plex server to serve that media\nData Storage (pictures, family movies, work projects)\n  \n\n    I'm not looking to share files remotely and there would be a max of 2 users accessing the data on our home network.\n  \n\n    Unfortunately, I wasn't able to salvage anything but the mechanical drives from the system. (MB was fried and video card was ancient).\n  \n\n    Supplies I already have but am not married to:\nRadeon 6800 XT (given from a friend's old system)\n1TB NVME Drive - Western Digital Blue\n3x 1TB Mechanical Drives - Western Digital Black -- Want to ditch these for something more robust\n3TB Mechanical Drive - Western Digital Black -- Same as above\n  \n\n    Any thoughts/ideas would be greatly appreciated, as all my data is currently living on my current system and it's backed up on various external drives (not ideal).\n  \n\n    Thanks!"},
{"Title": "Which WD Elements External Desktop HDD should I buy for longevity?", "Author": "u/AntarcticNightingale", "Content": "[SOLVED!! Better buy an internal drive. Also here is my \nnew question about which internal drive to pick\n.]\n  \n\n    Buying a large externally powered Desktop HDD will be for making a backup, before I invest a ton of time, money, and energy into a longtime NAS solution, it will be a quick solution for now.  (Yes I know the general advice that the best brand is having another copy regardless of brand. But with that said ...)\n  \n\n\n\n\n\n    Is it true for externally powered HDD, that Western Digital is more reliable in general than Seagate or any other brands?\n  \n\n\n\n\n\n    Is it true that it's better to get a WD Elements Desktop than a WD My Book because My Book had encryption which is kinda of a headache if we need to ever do data recovery? (Since I don't need my data to be encrypted.)\n  \n\n\n\n\n\n    So there are \nthe following choices for the WD Elements Desktop\n: 6, 8, 10, 12, 14, 16, 18, 20, 22 TB. \nGiven price is not a concern, which size would be the best for quality and longevity?\n Because I have read that if the data is too dense, it's more likely to break or something? I can buy multiple of the smaller size if smaller sizes are more reliable.\n  \n\n\n\n\n\n    Thanks!"},
{"Title": "NAS bay vs just build a new system?", "Author": "u/tddammo1", "Content": "Hi all,\n  \n\n    My current method is I have a pi 4 hooked up via USB 3.0 to an external 2TB seagate HDD. Eventually I know I want to expand, and my question is should I get a big (low power) PC and go that route? (E.g. something with 4-6 bays) or would something like a dedicated external NAS bay be better value for my $$$.\n  \n\n    Which do people generally recommend and why?\n  \n\n    Note: I do have a dedicated ML rig that does all my processing etc when converting and compressing videos, this system is STRICTLY hosting jellyfin"},
{"Title": "Transforming a QLC SSD to SLC for dramatically increased endurance", "Author": "u/johnklos", "Content": "No content"},
{"Title": "How to get the URL to this video? Nothing seems to be able to pick it up", "Author": "u/airkuroko", "Content": "Link: \nhttps://watchreplay.net/suns-vs-clippers-west-1st-round-game-1-april-16-2023/19471/\n\n\n\n    I'm trying to download this video of an NBA game. On this site is an embedded video with 3 sources to choose from on the top right. Source 1 and source 3 work.\n  \n\n    But I can't find the URL to the video for either source 1 or 3. I've played the video while having enabled multiple extensions on Chrome and Firefox, and none of these extensions can detect the link to the video.\n  \n\n    Does anyone know how to get the URL to this video?"},
{"Title": "Tool for renaming files/movies with common schema", "Author": "u/BlossomingPsyche", "Content": "Let's say you regularly have files with extraneous tags that you might want to remove (ie renaming something from MyDVDMovieRip1981/MyDVDMovieRip1981.x264.mkv and with perhaps a script /  command (I can do this on Os X with an application called Alfred) rename the folder, file and categorize it in the way I want (ie Horror, Scifi) so my Alien1994Bluray/AlienRip1994.mkv would get stripped of the tags and then renamed with a naming scheme like if I wanted to do a scifi rename on my mac I would type \"shift-command space to activate alfred then \"sort Alien 1984 1080p Scifi\" which then renames the selected folder to Alien [1080P] [SCI-FI] [USA] [1984] and the file to Alien 1984 1080P.mkv which then gets dropped into plex. Is there something that will let me rename files/folders with a 'format' like this for PC ? Kind of like automator or alfred or raycast for Os X ?"},
{"Title": "How can I extract and download ALL images from websites gallery?", "Author": "u/atribecallednet", "Content": "How can I extract and download ALL images from these WW2 sites below?\n  \n\n\n\n\nhttps://albumwar2.com/\n\n\n\n\nhttps://ww2db.com/photo.php"},
{"Title": "List of ALL COLORS of WD internal HDD drives: which ones have the best long term reliability? Is CMR or SMR more reliable? How about best RMP and cache for reliability?", "Author": "u/AntarcticNightingale", "Content": "I'm looking to buy a large (or several smaller) internal HDD for backups, before I invest a ton of time and money for a NAS solution, it will be a quick solution for now. (Yes I know the general advice that the best brand is having another copy regardless of brand. But with that said ...)\n  \n\n    I have no idea what all the colors of WD internal drives mean. Sometimes I see a color being trashed on this subreddit, but I don't remember.\n  \n\n\n\n\n\n    Is it true for externally powered HDD, that Western Digital is more reliable in general than other brands? If not, what is the most reliable brand and which internal drive should I get from it?\n  \n\n\n\n\n\n    Is it true that WD internal drives don't have encryption? Which is good for me because encryption is a headache if we ever need data recovery and I don't have any sensitive stuff that needs encryption.\n  \n\n\n\n\n\n    Is a faster RPM (7200) more reliable than a slower RPM (5400 or 5640)? Does cache size matter?\n  \n\n\n\n\n\n\nIs it true that CMR is more reliable than SMR? I don't care about speed or cost\n and size is a minor concern (because I can always buy multiples of a good small drive). I just want to have the highest chance of my data not go poof.\n  \n\n\n\n\n\n\nWhat are the best Western Digital internal drive colors in terms of long-term reliability?\n  Do storage capacity and cache size (64, 128, or 256MB) affects reliability too? I have made the following list based on Amazon's best selling WD drives:\n  \n\n\n\n\n\n\n\n\n\n\nWD Blue PC 3.5\" HDD\n\n\n\n\n\n\n\n    54,500 ratings, 4.6 average, 80% 5 star, 4% 1 star\n  \n\n\n\n\n\n    8 TB with 5640 RMP and 256 MB cache WD80EAAZ\n  \n\n\n\n\n\n    3-6 TB with 5400 RMP and 256 MB cache WD30EZAX, WD40EZAX, WD60EZAX, respectively\n  \n\n\n\n\n\n    2 TB with 7200 RMP and 256 MB cache WD20EZBX\n  \n\n\n\n\n\n\n\n\n\n\nWD Blue PC 3.5\" HDD\n \nI don't know why there is a second different link for WD Blue\n\n\n\n\n\n\n\n    23,600 ratings, 4.6 average, 81% 5 star, 4% 1 star\n  \n\n\n\n\n\n    1, 3, 4 or 6 TB with 5400 RMP and 64 MB cache WD10EZRZ, WD30EZRZ, WD40EZRZ, WD60EZRZ\n  \n\n\n\n\n\n    2 TB with 5400 RMP and 256 MB cache WD20EZAZ\n  \n\n\n\n\n\n\n\n\n\n\nWD Black Performance Gaming 3.5\" HDD\n\n\n\n\n\n\n\n    14,700 ratings, 4.6 average, 80% 5 star, 6% 1 star\n  \n\n\n\n\n\n    4, 6, or 10 TB with 7200 RPM and 256 MB cache WD4005FZBX, WD6003FZBX, WD101FZBX\n  \n\n\n\n\n\n    6 or 8 TB with 7200 RPM and 128 MB cache WD6004FZWX, WD8002FZWX\n  \n\n\n\n\n\n    1, or 2 TB with 7200 RPM and 64 MB cache WD1003FZEX, WD2003FZEX\n  \n\n\n\n\n\n\n\n\n\n\nWD Purple Surveillance 3.5\" HDD\n\n\n\n\n\n\n\n    13,500 ratings, 4.6 average, 80% 5 star, 5% 1 star\n  \n\n\n\n\n\n    14 TB with 7200 RMP and 512 MB cache\n  \n\n\n\n\n\n    10 TB with 7200 RMP and 256 MB cache\n  \n\n\n\n\n\n    8 TB with 5400 RMP and 256 MB cache\n  \n\n\n\n\n\n    6 TB with 5400 RMP and 256 MB cache or 5640 RMP and 128 MB cache\n  \n\n\n\n\n\n    1-4 TB with 5400 RMP and 64 or 256 MB cache\n  \n\n\n\n\n\n\n\n\n\n\nWD Red Plus 3.5\" HDD\n\n\n\n\n\n\n\n    9,100 ratings, 4.6 average, 80% 5 star, 5% 1 star\n  \n\n\n\n\n\n    12 TB with 7200 RMP and 512 MB cache WD120EFBX\n  \n\n\n\n\n\n    10 TB with 7200 RMP and 256 MB cache\n  \n\n\n\n\n\n    8 TB with 5640 RMP and 256 MB cache\n  \n\n\n\n\n\n    6 TB with 5400 RMP and 256 MB cache or 5640 RMP and 128 MB cache\n  \n\n\n\n\n\n    4 TB with 5640 RMP and 128 or 256 MB cache\n  \n\n\n\n\n\n    2 or 3 TB with 5400 RMP and 128 MB cache\n  \n\n\n\n\n\n    1 or 2 TB with 5400 RMP and 64 MB cache\n  \n\n\n\n\n\n\n\n\n\n\nWD Red Pro 3.5\" HDD CMR\n\n\n\n\n\n\n\n    1,700 ratings, 4.5 average, 78% 5 star, 8% 1 star\n  \n\n\n\n\n\n    14, 20, 22, or 24 TB with 7200 RMP and 512 MB cache WD240KFGX\n  \n\n\n\n\n\n    4-16, or 18 TB with 7200 RMP and 256 MB cache\n  \n\n\n\n\n\n    2 TB with 7200 RMP and 64 MB cache\n  \n\n\n\n\n\n\n\n\n\n\nWD Purple Pro Surveillance 3.5\" HDD\n\n\n\n\n\n\n\n    630 ratings, 4.6 average, 81% 5 star, 7% 1 star\n  \n\n\n\n\n\n    14 - 22 TB with 7200 RMP and 512 MB cache WD221PURP\n  \n\n\n\n\n\n    8 - 12 TB with 7200 RMP and 256 MB cache\n  \n\n\n\n\n\n\n\n\n\n\nWD Gold Enterprise 3.5\" HDD\n\n\n\n\n\n\n\n    NO ratings!\n  \n\n\n\n\n\n    8 TB with 7200 RMP and 256 MB cache WD8005FRYZ\n  \n\n\n\n\n\n\n\n\n\n    let me know if I missed any other reliable drives to compare, especially if it's better than any listed here, regardless of brand.\n  \n\n\n\n\n\n    I have no idea the purpose of so many colors is. I have no idea why some are marketed only for surveillance or gaming, or enterprise. As you can see, the ratings are very similar.\n  \n\n    Please let me know which one(s) is/are the most reliable!\n  \n\n    Thank you so much!!"},
{"Title": "Have you ever thought \"is this worth it?\"", "Author": "u/banisheduser", "Content": "I have some media files saved, but I am very unlikely to ever watch them.\n  \n\n    However, I know they're not available from the official site any more.\n  \n\n    I sort of feel a responsibility to keep them archived but at the same time, I do wonder why I am bothering.\n  \n\n    Have you ever felt this way about some data you've hoarded and what was the outcome?"},
{"Title": "WD My Book Duo eating drives :(", "Author": "u/No_Reflection1510", "Content": "I have had this 16TB My Book Duo (2x 8TB drives mirrored) for about 4 years. I only use it to store old photos and video that I don't want to lose but also for Time Machine backups.\n  \n\n    A few months ago one ofthe drives died so I got a replacement (see below). The raid rebuilt itself in a few days and I thought it was golden again. A week or two goes by and the other drive dies. So I get another of the same drive replace/rebuild and figured NOW I'm golden.\n  \n\n    Fast fwd to now, I've got another drive failure. This is getting pretty old.  So I guess I'm just looking for some advice. Should I keep trusting this WD enclosure and get yet another replacement drive? Should I abandon it and switch to something else? I really just don't want to lose this data.\n  \n\n    I'd like to just shove all this data into Google Drive and be done with external enclosures for this but ~8TB is a lot to upload and would take my little uplink weeks or months to do so and it seems likely that my one remaining drive would fail in that timeframe :-(\n  \n\n    Replacement drives were both: \nWestern Digital 8TB WD Red Plus NAS Internal Hard Drive HDD - 5640 RPM, SATA 6 Gb/s, CMR, 256 MB Cache, 3.5\" - WD80EFPX"},
{"Title": "I want to automatically back up the contents of one external hard drive to another in a different house. Which software would let me do this?", "Author": "u/PradleyBitts", "Content": "I don't really want sync, i.e I don't want something that gets deleted on one drive to get deleted on another. Just want all the content added to one hard drive backed up to another in a different house automatically."},
{"Title": "backing up folders to S3 (compatible software), weekly, with terminal", "Author": "u/leurs247", "Content": "Hi all,\n  \n\n    I have some important files (not much atm, about 5GB) I want to upload to a (secure) online storage (cheap if possible).\n  \n\n    I already have the data on my local machine (macbook pro) and an external harddrive, but I want an online storage solution as well.\n  \n\n    I have used aws S3 before (for my work) so I have some knowledge. I could make a bucket to store the data.\n  \n\n    Is there any interesting (free) software I can use (on a mac) to backup some folders to s3. I have mountainduck on my laptop but only in trial.\n  \n\n    Another possible solution is to create a bash script to upload specific folders to s3 (not necessarily aws, could also be digitalocean) on an regular basis. I could possibly make a script with rclone, is this a good usecase for this?\n  \n\n    I could add a cronjob (like every sunday at 01AM) but my laptop is probably in sleep mode at that time, how can I create a script that runs at sunday 01AM OR when I first start my laptop after that time?\n  \n\n    Thanks!"},
{"Title": "Data recovery on failed drives - is it ever practical or reasonably priced for a regular joe?", "Author": "u/riftwave77", "Content": "I have two old drives that failed years ago that i've been keeping around on the off chance that HDD recovery ever gets cheap enough for me to consider it.\n  \n\n    am I just wasting my time?"},
{"Title": "i've got a J4025 w/8GB memory i want to use for a backup NAS. is TrueNAS CORE viable, or do i need lighter weight freeBSD/openZFS combo ? no other services planned, but wanting compression & encryption", "Author": "u/ImaginaryCheetah", "Content": "title says it all :)\n  \n\n    any of you folks running TrueNAS on a J4025, or does the little guy not have enough juice ?"},
{"Title": "Help: Scaling Up My Storage Rig: From Synology DS920+ to Custom Build with Hot Swap", "Author": "u/Doh_facepalm_admin", "Content": "I've hit a bit of a snag in my data hoarding journey and need some advice. I started off with a Synology DS920+ in 2020, equipped it with 4x6 TB drives, and soon found myself upgrading to 4x10 TB drives as my media and container needs grew. I've been heavily using PLEX, SONARR, RADARR, among other containers, and it's been fantastic so far.\n  \n\n    However, I'm now planning to dive into 4K transcoding, enhance my setup with more RAM for network labs, and maybe even host a gaming server. The demand on my current system is skyrocketing, and once again, I'm running out of space.\n  \n\n    I'm contemplating building a custom PC since the price seems comparable to getting an 8-bay Synology unit, but I'm really hung up on finding the right case. I'd prefer something that isn't a tower due to space constraints and aesthetics, but most importantly, I need it to support hot swapping. As my data hoarding isn't slowing down any time soon, I want to easily add more drives and replace any that fail without shutting down the system.\n  \n\n    Has anyone here tackled a similar upgrade or built their own high-capacity, hot-swappable storage system? I'd love to hear about your experiences, particularly about your choice of cases and any setup tips you might have for someone looking to transition from a NAS to a custom build.\n  \n\n    Thanks in advance for any suggestions or insights!"},
{"Title": "Need desperate help recovering an old photo", "Author": "u/dmc1155", "Content": "First of all i don't know if this is the correct subreddit to ask my question, but i've been desperately searching for my old motorola razer for more than a year now and i've finally found it. This razer phone of mine has a picture of my dog that i am very desperate to recover ever since she passed. The little information i remember about the picture is that it was set as a wallpaper and i wanted to know if it is possible to extract it from the phone someway. The phone turns on and i get greeted with an unskippable \"insert sim\" pop up. Is there any program where i can download the phone's contents or maybe something like the phone's nand where i can then find the wallpaper and save it?"},
{"Title": "38% of webpages that existed in 2013 are no longer accessible a decade later", "Author": "u/retrac1324", "Content": "No content"},
{"Title": "Did I make a mistake getting the WUH721816ALE6L1 not the ALE04 or is the drive from ServerPartDeals bad?", "Author": "u/mlgSD", "Content": "I'm posting this here as you all seem to know about these Ultrastar datacenter drives. Did I make a mistake getting the WUH721816ALE6L1 not the ALE04 or is the drive from ServerPartDeals bad? The L1 is a \"self-encrypting drive\". It's supposed to be \"refurbished\" by WDC and has a new WDC label that says \"Recertified 12 NOV 2023\" and P/N 0F24861  FW:870.\n  \n\n    I previously bought two 14TB  WUH721414ALE604 drives from Amazon before I learned of \nServerPartDeals.com\n here (thanks guys!). I ran Spinrite 6.1 Level 5 on both. Each took about almost a week to do. Level 5 checks every sector, recovers (if possible) unreadable data, inverts it, writes it, reads it, verifies it, then rewrites and re-verifies each sector. One of them was fine and the other had some bad sectors at the very end so I returned it.\n  \n\n    I was thinking I should have bought a 16TB one, so after returning the 14TB to Amazon, I bought the WUH721816ALE6L1 from ServerPartDeals on Friday and got it today, Monday. Free 2nd Day Air. Very cool! I especially liked that they say it's \"Manufacturer Recertified\".\n  \n\n    Spinrite can see the drive and reads it's configuration from the drive electronics. It knows it's 16TB and how many bytes and sectors it has. It tests every drive it can recognize to be sure it can read and write sectors on each drive. However when it tests the 16TB drive to verify it can read and write the drive's sectors, that fails.\n  \n\n    I've tried this on two different systems with the same result. I did a quick test in Linux trying to 'dd' another drive to it, but it complained it can't access the drive saying that maybe it is DRM'd. The same 'dd' command works just fine with the 14TB drive.\n  \n\n    Is there something I need to do to the drive to make it work or is it just bad and needs to be returned?\n  \n\n    My apologies if I should post this elsewhere.\n  \nWDC Recertified HC550 16TB\nWUH721816A:EL1 fails Spinrite 6.1 data transfer verification"},
{"Title": "2U 4x3.5 hdd expansion 14\" depth?", "Author": "u/chinzw", "Content": "Does this exist? I've been searching everywhere, can't find anything that fits the bill.\n  \n\n    I need to add more storage to my server, my rack is 15\" deep, with plug i get about 14\" usable.\n  \n\n    Im looking to spend no more than 1000$ all in (no drives)."},
{"Title": "Samsung T7 help", "Author": "u/Creative_Emu3851", "Content": "No content"},
{"Title": "I built a self hosted version of AWS S3 using only open source technology and Raspberry Pis thats compatible with the official AWS S3 SDK", "Author": "u/Anthonyb-s3", "Content": "No content"},
{"Title": "Need advice about a DIY NAS", "Author": "u/-empty-head", "Content": "https://preview.redd.it/need-advice-about-a-diy-nas-v0-i1wla3ypmm1d1.jpg\n\n    A couple months ago a friend of mine gave me his TERRAMASTER D4-300 drive enclosure, I was thinking about getting a SBC / mini pc, or something similar and turning it into a jankie DIY NAS.\n  \n\n    The hardware I currently have for the project is, 4TB HDD × 4 and the drive enclosure\n  \n\n    My use case is pretty simple I just want mass networked bulk storage, with basic resilience In case of loss of a single drive.\n  \n\n    But I have a couple of questions about this Idea I've been having, befor I do this.\n  \n\n\n\n\n\n    I want to do this on a bit of a tight budget, so I would like some hardware suggestions.\n  \n\n\n\n\n\n    Is it actually going to work and be reasonably reliable?\n  \n\n\n\n\n\n    And any other thoughts or ideas would be very much appreciated?"},
{"Title": "Is the 2TB Seagate Barracuda 3.5 fine for my case?", "Author": "u/typcalthowawayacount", "Content": "I wanted to give a DIY Nas a try and it seems it's recommended to have a NAS specific hard drives like WD or Seagate RED, but that's if you're using it 24/7 which isn't my case. I'll be using to \nrarely\n to store videos and images on the fly, and my MOBO does support power on by PME which allows me to turn the PC on by PCI/PCIE LAn or modem card.\n  \n\n    So with that, a the 2TB Seagate Barracude should be fine then?\n  \n\n    The other hardware on my PC:\n  \n\n    MOBO: F1A55-M LX3 R2.0\n  \n\n    CPU: A4-3400\n  \n\n    RAM: 12 GB of DDR3\n  \n\n    Storage: 500GB HDD (OS)"},
{"Title": "How does p2p connection actually works on CGNAT network.", "Author": "u/Mukun00", "Content": "Hello guys,\n  \n\n    I have recently found a p2p file transfer website \nhttps://send-anywhere.com/\n .\nIn Webrtc we can't able to transfer the files through p2p while connected with CGNAT connection, but this site allows p2p even with CGNAT connection, I wonder what protocol they been used to work with CGNAT connections.\n  \n\n    Do you guys any Idea which protocol or method they used to work on CGNAT connections.\n  \n\n    Thank in advance."},
{"Title": "Is this any good? WD Red WE30EFRX + Synology DS213j", "Author": "u/Germasiansensation", "Content": "No content"},
{"Title": "Old DIY Media Server is Kaput. Looking for Advice!", "Author": "u/HightopNinja", "Content": "Hi all,\n  \n\n    Last week, my beast of an old machine decided to give up the ghost. This machine served as both a media server (DVD/Blu-ray rips and music) and as a HTPC in my living room (used for watching media on the server and watching streaming services).\n  \n\n    I managed to pull the data off the drives and am currently running some tests on them to make sure there are no issues. (They are older drives, and quite small by today's standards).\n  \n\n    Thankfully, no data lost!\n  \n\n    I'm trying to figure out the best solution for myself going forward. Should I go NAS for storage and grab a mini-pc (N100 Beelink or similar) for the living room? Should I build a new HTPC/Server? (it would need to be somewhat cost effective)\n  \n\n    The main uses I need are:\nSharing of media over our home network (in house only)\nI'd like to run a Jellyfin or Plex server to serve that media\nData Storage (pictures, family movies, work projects)\n  \n\n    I'm not looking to share files remotely and there would be a max of 2 users accessing the data on our home network.\n  \n\n    Unfortunately, I wasn't able to salvage anything but the mechanical drives from the system. (MB was fried and video card was ancient).\n  \n\n    Supplies I already have but am not married to:\nRadeon 6800 XT (given from a friend's old system)\n1TB NVME Drive - Western Digital Blue\n3x 1TB Mechanical Drives - Western Digital Black -- Want to ditch these for something more robust\n3TB Mechanical Drive - Western Digital Black -- Same as above\n  \n\n    Any thoughts/ideas would be greatly appreciated, as all my data is currently living on my current system and it's backed up on various external drives (not ideal).\n  \n\n    Thanks!"},
{"Title": "Which WD Elements External Desktop HDD should I buy for longevity?", "Author": "u/AntarcticNightingale", "Content": "[SOLVED!! Better buy an internal drive. Also here is my \nnew question about which internal drive to pick\n.]\n  \n\n    Buying a large externally powered Desktop HDD will be for making a backup, before I invest a ton of time, money, and energy into a longtime NAS solution, it will be a quick solution for now.  (Yes I know the general advice that the best brand is having another copy regardless of brand. But with that said ...)\n  \n\n\n\n\n\n    Is it true for externally powered HDD, that Western Digital is more reliable in general than Seagate or any other brands?\n  \n\n\n\n\n\n    Is it true that it's better to get a WD Elements Desktop than a WD My Book because My Book had encryption which is kinda of a headache if we need to ever do data recovery? (Since I don't need my data to be encrypted.)\n  \n\n\n\n\n\n    So there are \nthe following choices for the WD Elements Desktop\n: 6, 8, 10, 12, 14, 16, 18, 20, 22 TB. \nGiven price is not a concern, which size would be the best for quality and longevity?\n Because I have read that if the data is too dense, it's more likely to break or something? I can buy multiple of the smaller size if smaller sizes are more reliable.\n  \n\n\n\n\n\n    Thanks!"},
{"Title": "NAS bay vs just build a new system?", "Author": "u/tddammo1", "Content": "Hi all,\n  \n\n    My current method is I have a pi 4 hooked up via USB 3.0 to an external 2TB seagate HDD. Eventually I know I want to expand, and my question is should I get a big (low power) PC and go that route? (E.g. something with 4-6 bays) or would something like a dedicated external NAS bay be better value for my $$$.\n  \n\n    Which do people generally recommend and why?\n  \n\n    Note: I do have a dedicated ML rig that does all my processing etc when converting and compressing videos, this system is STRICTLY hosting jellyfin"},
{"Title": "Transforming a QLC SSD to SLC for dramatically increased endurance", "Author": "u/johnklos", "Content": "No content"},
{"Title": "How to get the URL to this video? Nothing seems to be able to pick it up", "Author": "u/airkuroko", "Content": "Link: \nhttps://watchreplay.net/suns-vs-clippers-west-1st-round-game-1-april-16-2023/19471/\n\n\n\n    I'm trying to download this video of an NBA game. On this site is an embedded video with 3 sources to choose from on the top right. Source 1 and source 3 work.\n  \n\n    But I can't find the URL to the video for either source 1 or 3. I've played the video while having enabled multiple extensions on Chrome and Firefox, and none of these extensions can detect the link to the video.\n  \n\n    Does anyone know how to get the URL to this video?"},
{"Title": "Tool for renaming files/movies with common schema", "Author": "u/BlossomingPsyche", "Content": "Let's say you regularly have files with extraneous tags that you might want to remove (ie renaming something from MyDVDMovieRip1981/MyDVDMovieRip1981.x264.mkv and with perhaps a script /  command (I can do this on Os X with an application called Alfred) rename the folder, file and categorize it in the way I want (ie Horror, Scifi) so my Alien1994Bluray/AlienRip1994.mkv would get stripped of the tags and then renamed with a naming scheme like if I wanted to do a scifi rename on my mac I would type \"shift-command space to activate alfred then \"sort Alien 1984 1080p Scifi\" which then renames the selected folder to Alien [1080P] [SCI-FI] [USA] [1984] and the file to Alien 1984 1080P.mkv which then gets dropped into plex. Is there something that will let me rename files/folders with a 'format' like this for PC ? Kind of like automator or alfred or raycast for Os X ?"},
{"Title": "How can I extract and download ALL images from websites gallery?", "Author": "u/atribecallednet", "Content": "How can I extract and download ALL images from these WW2 sites below?\n  \n\n\n\n\nhttps://albumwar2.com/\n\n\n\n\nhttps://ww2db.com/photo.php"},
{"Title": "List of ALL COLORS of WD internal HDD drives: which ones have the best long term reliability? Is CMR or SMR more reliable? How about best RMP and cache for reliability?", "Author": "u/AntarcticNightingale", "Content": "I'm looking to buy a large (or several smaller) internal HDD for backups, before I invest a ton of time and money for a NAS solution, it will be a quick solution for now. (Yes I know the general advice that the best brand is having another copy regardless of brand. But with that said ...)\n  \n\n    I have no idea what all the colors of WD internal drives mean. Sometimes I see a color being trashed on this subreddit, but I don't remember.\n  \n\n\n\n\n\n    Is it true for externally powered HDD, that Western Digital is more reliable in general than other brands? If not, what is the most reliable brand and which internal drive should I get from it?\n  \n\n\n\n\n\n    Is it true that WD internal drives don't have encryption? Which is good for me because encryption is a headache if we ever need data recovery and I don't have any sensitive stuff that needs encryption.\n  \n\n\n\n\n\n    Is a faster RPM (7200) more reliable than a slower RPM (5400 or 5640)? Does cache size matter?\n  \n\n\n\n\n\n\nIs it true that CMR is more reliable than SMR? I don't care about speed or cost\n and size is a minor concern (because I can always buy multiples of a good small drive). I just want to have the highest chance of my data not go poof.\n  \n\n\n\n\n\n\nWhat are the best Western Digital internal drive colors in terms of long-term reliability?\n  Do storage capacity and cache size (64, 128, or 256MB) affects reliability too? I have made the following list based on Amazon's best selling WD drives:\n  \n\n\n\n\n\n\n\n\n\n\nWD Blue PC 3.5\" HDD\n\n\n\n\n\n\n\n    54,500 ratings, 4.6 average, 80% 5 star, 4% 1 star\n  \n\n\n\n\n\n    8 TB with 5640 RMP and 256 MB cache WD80EAAZ\n  \n\n\n\n\n\n    3-6 TB with 5400 RMP and 256 MB cache WD30EZAX, WD40EZAX, WD60EZAX, respectively\n  \n\n\n\n\n\n    2 TB with 7200 RMP and 256 MB cache WD20EZBX\n  \n\n\n\n\n\n\n\n\n\n\nWD Blue PC 3.5\" HDD\n \nI don't know why there is a second different link for WD Blue\n\n\n\n\n\n\n\n    23,600 ratings, 4.6 average, 81% 5 star, 4% 1 star\n  \n\n\n\n\n\n    1, 3, 4 or 6 TB with 5400 RMP and 64 MB cache WD10EZRZ, WD30EZRZ, WD40EZRZ, WD60EZRZ\n  \n\n\n\n\n\n    2 TB with 5400 RMP and 256 MB cache WD20EZAZ\n  \n\n\n\n\n\n\n\n\n\n\nWD Black Performance Gaming 3.5\" HDD\n\n\n\n\n\n\n\n    14,700 ratings, 4.6 average, 80% 5 star, 6% 1 star\n  \n\n\n\n\n\n    4, 6, or 10 TB with 7200 RPM and 256 MB cache WD4005FZBX, WD6003FZBX, WD101FZBX\n  \n\n\n\n\n\n    6 or 8 TB with 7200 RPM and 128 MB cache WD6004FZWX, WD8002FZWX\n  \n\n\n\n\n\n    1, or 2 TB with 7200 RPM and 64 MB cache WD1003FZEX, WD2003FZEX\n  \n\n\n\n\n\n\n\n\n\n\nWD Purple Surveillance 3.5\" HDD\n\n\n\n\n\n\n\n    13,500 ratings, 4.6 average, 80% 5 star, 5% 1 star\n  \n\n\n\n\n\n    14 TB with 7200 RMP and 512 MB cache\n  \n\n\n\n\n\n    10 TB with 7200 RMP and 256 MB cache\n  \n\n\n\n\n\n    8 TB with 5400 RMP and 256 MB cache\n  \n\n\n\n\n\n    6 TB with 5400 RMP and 256 MB cache or 5640 RMP and 128 MB cache\n  \n\n\n\n\n\n    1-4 TB with 5400 RMP and 64 or 256 MB cache\n  \n\n\n\n\n\n\n\n\n\n\nWD Red Plus 3.5\" HDD\n\n\n\n\n\n\n\n    9,100 ratings, 4.6 average, 80% 5 star, 5% 1 star\n  \n\n\n\n\n\n    12 TB with 7200 RMP and 512 MB cache WD120EFBX\n  \n\n\n\n\n\n    10 TB with 7200 RMP and 256 MB cache\n  \n\n\n\n\n\n    8 TB with 5640 RMP and 256 MB cache\n  \n\n\n\n\n\n    6 TB with 5400 RMP and 256 MB cache or 5640 RMP and 128 MB cache\n  \n\n\n\n\n\n    4 TB with 5640 RMP and 128 or 256 MB cache\n  \n\n\n\n\n\n    2 or 3 TB with 5400 RMP and 128 MB cache\n  \n\n\n\n\n\n    1 or 2 TB with 5400 RMP and 64 MB cache\n  \n\n\n\n\n\n\n\n\n\n\nWD Red Pro 3.5\" HDD CMR\n\n\n\n\n\n\n\n    1,700 ratings, 4.5 average, 78% 5 star, 8% 1 star\n  \n\n\n\n\n\n    14, 20, 22, or 24 TB with 7200 RMP and 512 MB cache WD240KFGX\n  \n\n\n\n\n\n    4-16, or 18 TB with 7200 RMP and 256 MB cache\n  \n\n\n\n\n\n    2 TB with 7200 RMP and 64 MB cache\n  \n\n\n\n\n\n\n\n\n\n\nWD Purple Pro Surveillance 3.5\" HDD\n\n\n\n\n\n\n\n    630 ratings, 4.6 average, 81% 5 star, 7% 1 star\n  \n\n\n\n\n\n    14 - 22 TB with 7200 RMP and 512 MB cache WD221PURP\n  \n\n\n\n\n\n    8 - 12 TB with 7200 RMP and 256 MB cache\n  \n\n\n\n\n\n\n\n\n\n\nWD Gold Enterprise 3.5\" HDD\n\n\n\n\n\n\n\n    NO ratings!\n  \n\n\n\n\n\n    8 TB with 7200 RMP and 256 MB cache WD8005FRYZ\n  \n\n\n\n\n\n\n\n\n\n    let me know if I missed any other reliable drives to compare, especially if it's better than any listed here, regardless of brand.\n  \n\n\n\n\n\n    I have no idea the purpose of so many colors is. I have no idea why some are marketed only for surveillance or gaming, or enterprise. As you can see, the ratings are very similar.\n  \n\n    Please let me know which one(s) is/are the most reliable!\n  \n\n    Thank you so much!!"},
{"Title": "Have you ever thought \"is this worth it?\"", "Author": "u/banisheduser", "Content": "I have some media files saved, but I am very unlikely to ever watch them.\n  \n\n    However, I know they're not available from the official site any more.\n  \n\n    I sort of feel a responsibility to keep them archived but at the same time, I do wonder why I am bothering.\n  \n\n    Have you ever felt this way about some data you've hoarded and what was the outcome?"},
{"Title": "Best way to “refresh” 750 TB of HDDs?", "Author": "u/Nautricity", "Content": "Recently got ahold of A LOT of FREE server equipment, with drives, resulting in me now having nearly a petabyte of total storage combined. I’m very new to RAIDs and server setups in general.\n  \n\n    My question for now is, what’s the best way to refresh these drives to achieve optimal performance before deploying them? Most of these drives have multiple 10s of thousands of hours on them.\n  \n\n    I have a mix of Apple Xserve RAID, Dell PowerEdge, HP ProLiant, Cisco UCS, etc branded servers and RAID arrays, ranging from 250 GB HDDs all the way up to 8 TB HDDs.\n  \n\n    Is there any sort of specific software that’s recommended to “refurbish” these drives in mass? Bonus points for macOS (64 bit) and OS X (32 bit) compatibility!\n  \n\n    Thank you all for any help as I’m very new to this!"},
{"Title": "How do you deal with replaced drives?", "Author": "u/DazedWithCoffee", "Content": "I've got a 4TB disk that just degraded my RAIDZ2 pool with 16 read errors. I've got a replacement ready and the appropriate backups already in place, so there's no risk of data loss. My question is this: what to do with this drive? I'd hate to toss it, but I don't particularly trust it anymore. Has anyone found a low-waste strategy for dealing with these things?"},
{"Title": "More info about the height of the new 6TB 2.5\" WD drive", "Author": "u/Far_Marsupial6303", "Content": "Posting for visibility as an addendum to this thread. \nhttps://www.reddit.com/r/DataHoarder/comments/1cu2301/finally_after_seven_years_a_6tb_25inch_external/\n\n\n\n    I was looking at the WD site and noticed they have other models beyond the WD Black external and there are spec sheets for them. They are not listed\n  \n\n    To those who wonder why the height is important, max 15mm height for 2.5\" drives has been the standard for may years and is the largest height allowed in 2.5\" enclosures.\n  \n\n    The 5TB MyPassport case is 19.2mm and the drive is 15mm. The 6TB is 20.6mm so the drive is probably 16 or 16.5mm to accommodate the additional platter. I suspect this may allow them to fit snuggly in some 15mm cases. For reference, the lowest height 3.5\" drive is 19.5mm.\n  \n\n\nhttps://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/wd/product/external-storage/my_passport/my-passport-phdd-usb-c/data-sheet-my-passport-phdd-usb-c.pdf\n\n\n\n\nhttps://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/wd/product/external-storage/wd-black-p10-game-drive-for-xbox-usb-3-2-hdd/data-sheet-wd-black-p10-game-drive-for-xbox-usb-3-2-hdd.pdf\n\n\n\n    Pricewise, the \"bargain\" ;-p, is the Elements SE at 169.99MSRP, vs $129.99 for the 5TB."},
{"Title": "Powering down archive pools when not in use.", "Author": "u/dtf_0", "Content": "I was wondering if any NAS hardware/software allows a user to configure powering-down drives/enclosures for storage pools designed for archiving.\n  \n\n    I am a robotics engineer. I have a lot of old sensor data that is used very infrequently. Whenever we release a new release, we run a simulation against old data to ensure there are no regressions. However, this data is only touched at max 30 days per year.\n  \n\n    Currently, I manually turn on my archive NAS when need, run my test, move any new data to the archive, and power down the NAS manually.\n  \n\n    I am curious if there is any hardware or software that can do this automatically. I am thinking of something like a disk enclosure or disk shelf that contains an 'archive pool.' When I access the archive pool, the enclosure powers up, attaches the pool to the NAS, and works as normal. Then, after some delay, the pool detaches and powers down.\n  \n\n    This is more about power consumption than wear and tear. I currently average about ten years of life out of my drives. They start their lives as constantly spinning drives in my primary NAS, and then when I replace those drives with larger ones, they move to the archive NAS, which runs infrequently."},
{"Title": "hgst 12tb refurbished not going standby", "Author": "u/zannare", "Content": "I recently purchased a refurbished HGST 12tb hard disk (HUH721212ALE601) to use as an additional parity disk in my Snapraid setup\n\nit seems to work well, the smart is ok and completed the sync without problems (about 23 hours) but I was unable to make it go to standby automatically\n\nI tried all the APM values ​​from 1 to 127 (default was 254) but nothing changes\nI tried various settings of the time in which it should go to standy with smartctl, but nothing\nmanual standy works with both smartctl and hdparm\n\nthe hard disk makes a \"tick\" every 5 seconds\nhttps://vocaroo.com/148gEPXcUo36"},
{"Title": "Any Advice - Sabrent 5 bay docking station upgrade", "Author": "u/SCDUDELEX", "Content": "Current status:  Using the 5 Bay station... been working very well (and yes have a 6 Bay NAS as well, different functions in my system):\n  \n\n    I need to expand the bay capacity and assuming others have gotten to this point.  Question is, pros and cons of adding another Sabrent 5 bay and using the second USB C to connect the two.   Versus, retiring the 5 bay and swapping it out for the 10 bay model.\n  \n\n    Obviously it's nearly twice the cost to grab the 10 Bay, but that choice would leave me with the \"old 5 bay\"; to maybe do something with.   But is the single usb connection an advantage over the daisy chain of two 5 bays?\n  \n\n    Anything else I should consider?\n  \n\n    Thanks in advance..."},
{"Title": "Whatsapp ICloud Backup to PC?", "Author": "u/Lj_theoneandonly", "Content": "I've followed the guides on this sub for extracting whatsapp backup on android to pc with success. But i haven't seen as much useful discussion around trying to do the same with iPhone. I currently have a couple gb of whatsapp data in my icloud that I encrypted using the 64 digit key. I was looking for ways to take this encrypted backup out of my old iphone but the process doesn't seem to be straightforward. All i've found online were a bunch of third party sites like \"Dr Fone\" which several posts here have vouched for as a scam. So uhhh is there anything else I can do? I wouldn't mind jailbreaking the phone since it's an old one anyway. Thanks in advance for any help!"},
{"Title": "Plex server/build to run arrs", "Author": "Unknown author", "Content": "https://www.amazon.com/gp/product/B01NCESRJX/ref=ox_sc_saved_image_4?smid=A1ZYJ2SSCYE072&psc=1\n\n\n\n\nhttps://www.amazon.com/gp/product/B07LBXP8KZ/ref=ox_sc_saved_image_7?smid=ADT2TM5FCS88L&psc=1\n\n\n\n\nhttps://www.amazon.com/gp/product/B0BRQSWSFQ/ref=ox_sc_saved_image_3?smid=ATVPDKIKX0DER&th=1\n\n\n\n\nhttps://www.amazon.com/Expansion-Controller-Adapter-Splitter-Windows/dp/B0CPC2YLBJ/ref=sr_1_5?crid=1743QI3GMOT9A&dib=eyJ2IjoiMSJ9.cwPeFFKR905GlWuzCZZ90fDEDW0gmLnNiz32tX2qxVe8tZk1FsE4pBGCKj6qeO6tJY7hPucioGRtIPanw0zE0gi5RtMrhvFxX_JO2Kas2r15AMg92x8Gxd-Dk2VoFGZR4S3qaY0eT8qEhvGRhMEPeihGtUY-SgqrSMbwC0HXDvLRvriQqdaXo5ZM624jCN9FzQG-EPAjqZQvu20tzyohQLYNaVmRnY8X6f7NXo1DuBuylBdl_tEeKaW9ih7Eb8qYtWbVANh1NDTPwdEMut_TgI7lizZptl1c0IrnWzthZe0.TlGNxlwUwl0RczFhkZsZcm0kIEEWIT7CccQg4wPB3FQ&dib_tag=se&keywords=sata%2Bexpansion%2Bcard%2Basm&qid=1716180089&sprefix=sata%2Bexpansion%2Bcard%2Basm%2Caps%2C133&sr=8-5&th=1\n\n\n\n    Already have the ram and psu and an m.2 drive, that cpu is more than plenty right? I will probably end up installing Linux to take advantage of proper tone mapping. any other recommendations?"},
{"Title": "SeaGate Expansion 2 Tb 12$ are it worth and what risk ?", "Author": "u/Merchant_Lawrence", "Content": "Hello everyone, i currently try set up my own nas for archive stuff and on tight budget around 55$ i found on local online shop offer seagate expansion (without mentioning what number or series) 2 tb for just 12 $, it have good rating, are it good choice for long term or it not good ? thanks.\n  \n\n    link on that local online shop (it say tosiba but option available are seagate) : \nhttps://shopee.co.id/Hardisk-Eksternal-Toshiba-2TB-1TB-HDD-USB-3.0-Portable-External-Hard-Drive-Hard-disk-i.997456609.22981243111?sp_atk=abc600c5-5d08-4044-ba64-5c73626f8ba5&xptdk=abc600c5-5d08-4044-ba64-5c73626f8ba5"},
{"Title": "Preserving SketchFab Viewer Experience Offline, with Annotations", "Author": "u/wellnowholdon", "Content": "Hello hello,\n  \n\n    If this is in the wrong place let me know.\n  \n\n    Recently, I subscribed to a website with some embedded SketchFab models available for viewing and interaction. Resultingly, it appears that I have been granted (for an expensive and limited time) indirect access to a very rich repository of engineering models that feature various diagrams, cutaways, animations, and annotations.\n  \n\n    This access allows for interacting with a variety of models, viewing associated educational annotations, and watching demonstrative animations that illustrate the working principles of the modeled object.\n  \n\n    Using Chrome, via the Network tab, I am able to see some line items of interest. These are firstly, *.binz files, alongside what appear to my eye to be associated texture maps, normal files, and so on as a variety of .jpeg files. There are also links to the \nsketchfab.com\n domain and similarly structured API calls.\n  \n\n    I am aware and have investigated the path leading to .binz extraction and conversion. That is not what I'm interested in. It is not a raw 3D model that I am seeking, it is this comprehensive experience. Having access to the base model is all well and good, but what I would like to do is preserve this \"SketchFab Viewer\" experience even after my membership ends with this website.\n  \n\n    So, I would like to ask assistance.\n  \n\n\nIf possible, could pointers be provided to a way for me to preserve offline the material I currently have access to? Alternatively, is there a method to somehow extract a SketchFab link that will persist after my membership expires?\n\n\n\n    Thank you."},
{"Title": "Is it bad for an external HDD to spin while idling?", "Author": "u/BobbythebreinHeenan", "Content": "I’ve used external hard drives (almost always western digital) most of my life. One thing I’ve always noticed is that even when a drive isn’t in use, it will be spinning.\n  \n\n    Is a drive that’s spinning while not in use bad? Is it better to disconnect it from the computer when not in use? Would just unplugging it from the computer sufficient? Or do i need to also disconnect it from power?\n  \n\n    I’ve never had a hard drive fail on me btw."},
{"Title": "Most effective way of using multiple storage devices", "Author": "u/csyst", "Content": "I am looking forward a solution so i can combine multiple harddrives and access them as one drive/mount. Of course something like RAID 0 or LVM would solve this requirement, but I don’t want to loose all the data of all drives in case one drive fails, only the data of the failed drive. But since both variants use striping both ways don’t work, i guess? Also I want to be able to extend the „virtual“ drive later and I don’t want to loose space for redundancy, since I can get all the files again.\n  \n\n    Perhaps someone has an idea? Is there anything like a filesystem or mechanism that merges the drives on the fly?"},
{"Title": "Is a used 71% health 1tb Transcend m.2 nvme worth it for $26?", "Author": "u/ahmadmughal0", "Content": "What the title says, also it's in a third world country so it's not soo cheap for me, but cheaper than a new one. Is it a good catch? A 256gb ssd will be fine for me since I have a 1tb hdd buts it's slow/5400 rpm, in 2017 hp omen) but I'm wondering should i get this cheap with 71%health or a 256gb one new?"},
{"Title": "Trashy setups, mine.", "Author": "u/laggyservice", "Content": "No content"},
{"Title": "how to i set up a regular backup in WIN 11 of a folder.", "Author": "u/BatteryAcidEnj0yer", "Content": "I have a folder of \"family pictures\" and would like to have i back up automatically every few days from an m.2 ssd to a HDD (in the same PC) . The folder is about 200Gb+ so I'd be best if It would only copy new files.\n  \n\n    Preferably using built in tools or opensource solutions\n  \n\n    I'm using windows built in solution ( backup and restore (windows 7)) but I'm unsure if there is a better, more efficient and/or more reliable solution"},
{"Title": "Can anyone help me with some ideas on how to condense my storage into one place? As well, as recommendations of cloud providers", "Author": "u/Coloradozonian", "Content": "Hey there! I'm trying to simplify my digital storage, use one provide,  and cut down on subscriptions. As a photographer, mom, and blogger, So naturally 've accumulated a ton of photos, files, and albums, but they're all over the place between iCloud & Google One, I pay 2TB with each provider! Sometimes my photos do not upload to both clouds, and i go crazy trying to find it.\n  \n\n    I'd love to consolidate everything into one service, but I'm not sure how to transfer my entire Google account (about 290 GB, on a family plan) to iCloud. Or vice versa! Is there an easy way to do this? Maybe an app or a hack that can help? I'm somewhat  tech-savvy, but, I'd appreciate any guidance!\n  \n\n    Also, I recently switched to Verizon 5G Internet, which is great, but it slows down our devices during the day if I drag and drop files from drive to iCloud on my computer.  So, I need to transfer files at night, which is a real pain.\n  \n\n    Any advice or recommendations would be a lifesaver! Thanks in advance!"},
{"Title": "LTO-5 slow write speed, trying to find bottleneck", "Author": "u/fgt67cam", "Content": "I recently purchased a LTO-5 tape drive to back up some HDDs. The drive itself is working and connected via FC using a QLE2562 PCI-E.\n  \n\n    My plan was to original create a SAS RAID 0 to temp store the files being written to tape from the offline HDDs but I've had issues with the P410 controller not working so for now will have to connect the offline SATA drives to the server (Proliant ML330 G6).\n  \n\n    The drives I'm using aren't fast (ST3500312CS) but I did a read speed test using dd if=mytestfile of=/dev/null bs=1M count=1024 and they're getting around 80-90/MBs and online speed results show roughly the same. It's not fast but should be enough to do one backup copy before trying to fix the SAS issue.\n  \n\n    I've timed how long it's taking for it to do each file and the results:\n  \nFile 1 - 309 seconds - 10,045,430,602 bytes ~32.5/MBs\nFile 2 - 291 seconds - 13,597,137,146 bytes ~46.7/MBs\nFile 3 - 302 seconds - 13,967,991,165 bytes ~46.2/MBs\nFile 4 - 94 seconds - 4,526,005,392 bytes ~48.1/MBs\nFile 5 - 113 seconds - 5,139,777,083 bytes ~45.4/MBs\nFile 6 - 107 seconds - 4,917,953,848 bytes ~45.9/MBs\n\n    As first it seemed like the culprit was the HDDs so I installed a Samsung EVO 850. It scored 226/MBs with the same read test so much faster than the HDDs. I then had it write a 34GB file to tape and it took 528 seconds (not including tape rewind time) coming in at ~69.1/MBs which is still slow so I don't think the bottle neck is the SATA drives. The FC card is showing the link speed as 8Gbps and even if it was 1Gbps it's still too slow so I don't think it could be that. All that's left is the tape drive or Debian/drivers/software. I'm using \"tar cvf /dev/st0\" to write data to the tape.\n  \n\n\nEDIT 22/05/24\n\n\n\n    I've since built a new computer with more modern hardware to see if it made a difference using a 5280K, 16GB RAM and GA-X99M-Gaming5. Tested with a 2TB HDD and RAM drive, both scored ~106/MBs which seems to be the maximum it can do. I don't know what speeds are good for LTO-5 and if you can realistically get anywhere close to maximum of 140/MBs."},
{"Title": "backup multiple windows and Linux machines, and several loose HDD/SSD/CD/DVD onto a single windows machine (not NAS, not cloud)", "Author": "u/tater1337", "Content": "Honestly I tried searching here, but either I get confused or I cannot tell is the solution will fit my needs\n  \n\n    I have\n[windows]\nmy main PC\nwork laptop\na second home machine that does some tasks that I don't want on the main PC (like housing all the backups)\npersonal laptop\na bunch of loose hard drives, both SSD and HDD with data that I might want in the future(grandparents disks full of photos type stuff)\na PC set up as a DVR for a bunch of security cameras(not wanting to save the footage, just an easy restore if something breaks and a reinstall is needed)\n  \n\n    Linux\na couple of PCs used for Minecraft servers\na PC set up for home assistant\na couple of netbooks, some have software for 3d printers, CNC machines, Laser engravers, etc\na whole load of raspberry pi's with various weird stuff\n  \n\n    a stack of DVDs and CDs that I'd like to have backup copied in case of physical damage\n  \n\n    right now I have some backups of some machines, but I have not been able to get everything backed up\n  \n\n    my plan\ntake my recently purchased 16tb drive and dump everything on that, then get another drive to copy the first (or expand)....THEN set up a backup physically somewhere else\n  \n\n    what are my options? I've cloned drives with FileZilla, but only on a \"copy this HDD to a SSD to improve old machine\", not for backups\nI tried to get windows backup to try to backup my main PC to the secondary PC, but it fails more often than it works\n  \n\n    getting Linux and windows to play nicely together seems like black magic. more comfortable in windows than Linux\n  \n\n    tutorials, software options desired, dedicated NAS hardware solutions or cloud are not"},
{"Title": "Trying to find some forgotten RAID subsystem firmware.", "Author": "u/Zone_Purifier", "Content": "In an attempt to make it work properly with some newer drives, I've been hunting for the latest SAS firmware for a AXUS Y3-24S6SF8 RAID Subunit. AXUS is a former subsidiary of ASUS, one which hasn't been around since 2014 and might have some connection with Areca. This search has taken me to internet archive, ASUS, Areca, and random russian server hardware sites in search for this firmware. I've found some interesting leads and dead end phone numbers and emails, but nothing that yields the .bin (probably) that I need to update the system. If anyone has access to these files or might have ideas of where I can get firmware for such a seemingly obscure device, that would be great. Here's what I've found so far:\n  \n\n\nAXUS Website, latest archive\n\n\n\n\nYOTTA III Firmware Page Archive\n\n\n\n\nAXUS Closure Notice\n\n\n\n\nAXUS Final Contact Information Notice\n\n\n\n\nYOTTA 3 User Manual\n\n\n\n    And some system info from the unit itself:\n  \nhttps://preview.redd.it/trying-to-find-some-forgotten-raid-subsystem-firmware-v0-vymbg5rh0c1d1.png\nhttps://preview.redd.it/trying-to-find-some-forgotten-raid-subsystem-firmware-v0-oi55a5rh0c1d1.png"},
{"Title": "Crucial X6, X9 or another for photos and videos backup?", "Author": "u/3dforlife", "Content": "Hi there!\n  \n\n    I've had several internal and external HDDs that I used to backup my photos and videos. However, almost all have died the last years. I just can't stand them anymore. For reference, I've bought two Seagate Barracuda Green 4TB, and I've sent them 3 times already to be replaced...\n  \n\n    At the moment I have 1,3TB of photos and videos in a WD Blue 4TB, and I edit photos and videos with it.\n  \n\n    Therefore, I'm thinking of buying a SSD to backup my media, since I haven't had any problems with them (granted, I've only used them as main drives).\n  \n\n    Is the Crucial X6 (119 € 2TB) a good choice? It's on sale right now, but I've read that the cache depletes after having had 250GB written. After that, it writes at 40MBps, if I'm not mistaken. It is also QLC, which might affect longevity.\n  \n\n    Regarding the X9 (144€ 2TB), I can't find any review...\n  \n\n    I have bought the X9 pro (174€ 2TB) for my work, and it's very good, but it might be overkill for backups.\n  \n\n    A redditor, u/\nJohnnieLouHansen\n said that if I didn't need the speed of an SSD and wanted reliability, to go with Western Digital Enterprise drives, gold. He also said that he has put them in customer PCs. One pair are going on 10 years at 10 hours per day and another set ran 24/7 for 6 years.\n  \n\n    I searched for them on Amazon, and used Fakespot; the reviews were graded D, i.e., not reliable any highly deceptive: \nhttps://amzn.eu/d/fHMwwAj\n What conclusion can I take from this?\n  \n\n    What do you recommend? Any of these, some other?"},
{"Title": "17.1 TB \"size on disk\" on a 12TB drive", "Author": "u/useless_shoehorn", "Content": "Hi. I have a bunch of movies on a 12TB drive. Some of them didn't finish torrenting in windows/NTFS. I wanted to extend this drive in windows, but my block size was too small (4096). I have since repented and spun up a TrueNas server with the other 12TB drive (1M block size). However, as I'm copying to it I'm running out of space. Even if every file needed another 1M for the block size change, that's only 70GB right? What am I missing? How is the size on disk 17.1TB? What does that even mean?\n  \nhttps://preview.redd.it/17-1-tb-size-on-disk-on-a-12tb-drive-v0-ufx8hwhwp71d1.png\nhttps://preview.redd.it/17-1-tb-size-on-disk-on-a-12tb-drive-v0-p070vuhwp71d1.png"},
{"Title": "Strategy with hoarding and digesting large chunk of (small in size but large in number) folders and files", "Author": "u/cod201", "Content": "tldr: extracted more than 1.4 mils folder ( each inside have files)  into single folder in NTFS, ridiculous bad IO performance. Divided into 500 folders and got better IO, but i know i'm, dumb. Ask for better approach.\n  \n\n    Hi,\n  \n\n    I am using NTFS on Windows to run an research but i'm facing performance decrease, maybe due to data and index fragmentation.\n  \n\n    I receive multiple ZIP files everyday to extract, inside zip file is multiple folder, each folder is an unit of data for us to digest using Python, and upload them to Elastic (these in bright cyan).\n  \na brief structure of my data\n\n    Because the server is headless, i just recognized the problem when i connected it again, when it reached 1,5 millions folders, approx. 1.5TB  inside JUST A SINGLE folder. (about 7TBs waiting to extracting but i stopped it)\n  \nhttps://preview.redd.it/strategy-with-hoarding-and-digesting-large-chunk-of-small-v0-cu59lxq1kc1d1.png\n\n    So, when I move/ rename.. a folder, it is extremely lagging, moving a small file barely took more than hour. Just view the properties take more than 1GB of RAM.\n  \nhttps://preview.redd.it/strategy-with-hoarding-and-digesting-large-chunk-of-small-v0-ocwa17rujc1d1.png\n\n    I've just moving these data into other disc and dividing into 500 folders, based on its name (from AA to ZZ), the performance just got better, but idk is there any better ways to storage and using these data?\n  \n\n    I use Python to work with these file (maybe upgrading to C#/go.. for better multi threaded performance) and after digesting, i would storage it for about 6-12 months before delete it.\n  \n\n    I know my strategy is somewhat inefficient, so i'm asking if i could make it better. Thanks"},
{"Title": "FPF: I see your trashy setup, and submit my own for disapproval.", "Author": "u/Lanky-Antelope7006", "Content": "No content"},
{"Title": "When they ask you why", "Author": "u/eidolons", "Content": "You tell them this is why."},
{"Title": "Megs, Gigs, _____, ______?", "Author": "u/cheater00", "Content": "It's very annoying that there isn't a good short word for \"Terabytes\" or \"Petabytes\".\n  \n\n    This is my momentary frustration and I thought I'd come here to complain about it."},
{"Title": "Best way to “refresh” 750 TB of HDDs?", "Author": "u/Nautricity", "Content": "Recently got ahold of A LOT of FREE server equipment, with drives, resulting in me now having nearly a petabyte of total storage combined. I’m very new to RAIDs and server setups in general.\n  \n\n    My question for now is, what’s the best way to refresh these drives to achieve optimal performance before deploying them? Most of these drives have multiple 10s of thousands of hours on them.\n  \n\n    I have a mix of Apple Xserve RAID, Dell PowerEdge, HP ProLiant, Cisco UCS, etc branded servers and RAID arrays, ranging from 250 GB HDDs all the way up to 8 TB HDDs.\n  \n\n    Is there any sort of specific software that’s recommended to “refurbish” these drives in mass? Bonus points for macOS (64 bit) and OS X (32 bit) compatibility!\n  \n\n    Thank you all for any help as I’m very new to this!"},
{"Title": "How do you deal with replaced drives?", "Author": "u/DazedWithCoffee", "Content": "I've got a 4TB disk that just degraded my RAIDZ2 pool with 16 read errors. I've got a replacement ready and the appropriate backups already in place, so there's no risk of data loss. My question is this: what to do with this drive? I'd hate to toss it, but I don't particularly trust it anymore. Has anyone found a low-waste strategy for dealing with these things?"},
{"Title": "More info about the height of the new 6TB 2.5\" WD drive", "Author": "u/Far_Marsupial6303", "Content": "Posting for visibility as an addendum to this thread. \nhttps://www.reddit.com/r/DataHoarder/comments/1cu2301/finally_after_seven_years_a_6tb_25inch_external/\n\n\n\n    I was looking at the WD site and noticed they have other models beyond the WD Black external and there are spec sheets for them. They are not listed\n  \n\n    To those who wonder why the height is important, max 15mm height for 2.5\" drives has been the standard for may years and is the largest height allowed in 2.5\" enclosures.\n  \n\n    The 5TB MyPassport case is 19.2mm and the drive is 15mm. The 6TB is 20.6mm so the drive is probably 16 or 16.5mm to accommodate the additional platter. I suspect this may allow them to fit snuggly in some 15mm cases. For reference, the lowest height 3.5\" drive is 19.5mm.\n  \n\n\nhttps://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/wd/product/external-storage/my_passport/my-passport-phdd-usb-c/data-sheet-my-passport-phdd-usb-c.pdf\n\n\n\n\nhttps://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/wd/product/external-storage/wd-black-p10-game-drive-for-xbox-usb-3-2-hdd/data-sheet-wd-black-p10-game-drive-for-xbox-usb-3-2-hdd.pdf\n\n\n\n    Pricewise, the \"bargain\" ;-p, is the Elements SE at 169.99MSRP, vs $129.99 for the 5TB."},
{"Title": "Powering down archive pools when not in use.", "Author": "u/dtf_0", "Content": "I was wondering if any NAS hardware/software allows a user to configure powering-down drives/enclosures for storage pools designed for archiving.\n  \n\n    I am a robotics engineer. I have a lot of old sensor data that is used very infrequently. Whenever we release a new release, we run a simulation against old data to ensure there are no regressions. However, this data is only touched at max 30 days per year.\n  \n\n    Currently, I manually turn on my archive NAS when need, run my test, move any new data to the archive, and power down the NAS manually.\n  \n\n    I am curious if there is any hardware or software that can do this automatically. I am thinking of something like a disk enclosure or disk shelf that contains an 'archive pool.' When I access the archive pool, the enclosure powers up, attaches the pool to the NAS, and works as normal. Then, after some delay, the pool detaches and powers down.\n  \n\n    This is more about power consumption than wear and tear. I currently average about ten years of life out of my drives. They start their lives as constantly spinning drives in my primary NAS, and then when I replace those drives with larger ones, they move to the archive NAS, which runs infrequently."},
{"Title": "hgst 12tb refurbished not going standby", "Author": "u/zannare", "Content": "I recently purchased a refurbished HGST 12tb hard disk (HUH721212ALE601) to use as an additional parity disk in my Snapraid setup\n\nit seems to work well, the smart is ok and completed the sync without problems (about 23 hours) but I was unable to make it go to standby automatically\n\nI tried all the APM values ​​from 1 to 127 (default was 254) but nothing changes\nI tried various settings of the time in which it should go to standy with smartctl, but nothing\nmanual standy works with both smartctl and hdparm\n\nthe hard disk makes a \"tick\" every 5 seconds\nhttps://vocaroo.com/148gEPXcUo36"},
{"Title": "Any Advice - Sabrent 5 bay docking station upgrade", "Author": "u/SCDUDELEX", "Content": "Current status:  Using the 5 Bay station... been working very well (and yes have a 6 Bay NAS as well, different functions in my system):\n  \n\n    I need to expand the bay capacity and assuming others have gotten to this point.  Question is, pros and cons of adding another Sabrent 5 bay and using the second USB C to connect the two.   Versus, retiring the 5 bay and swapping it out for the 10 bay model.\n  \n\n    Obviously it's nearly twice the cost to grab the 10 Bay, but that choice would leave me with the \"old 5 bay\"; to maybe do something with.   But is the single usb connection an advantage over the daisy chain of two 5 bays?\n  \n\n    Anything else I should consider?\n  \n\n    Thanks in advance..."},
{"Title": "Whatsapp ICloud Backup to PC?", "Author": "u/Lj_theoneandonly", "Content": "I've followed the guides on this sub for extracting whatsapp backup on android to pc with success. But i haven't seen as much useful discussion around trying to do the same with iPhone. I currently have a couple gb of whatsapp data in my icloud that I encrypted using the 64 digit key. I was looking for ways to take this encrypted backup out of my old iphone but the process doesn't seem to be straightforward. All i've found online were a bunch of third party sites like \"Dr Fone\" which several posts here have vouched for as a scam. So uhhh is there anything else I can do? I wouldn't mind jailbreaking the phone since it's an old one anyway. Thanks in advance for any help!"},
{"Title": "Plex server/build to run arrs", "Author": "Unknown author", "Content": "https://www.amazon.com/gp/product/B01NCESRJX/ref=ox_sc_saved_image_4?smid=A1ZYJ2SSCYE072&psc=1\n\n\n\n\nhttps://www.amazon.com/gp/product/B07LBXP8KZ/ref=ox_sc_saved_image_7?smid=ADT2TM5FCS88L&psc=1\n\n\n\n\nhttps://www.amazon.com/gp/product/B0BRQSWSFQ/ref=ox_sc_saved_image_3?smid=ATVPDKIKX0DER&th=1\n\n\n\n\nhttps://www.amazon.com/Expansion-Controller-Adapter-Splitter-Windows/dp/B0CPC2YLBJ/ref=sr_1_5?crid=1743QI3GMOT9A&dib=eyJ2IjoiMSJ9.cwPeFFKR905GlWuzCZZ90fDEDW0gmLnNiz32tX2qxVe8tZk1FsE4pBGCKj6qeO6tJY7hPucioGRtIPanw0zE0gi5RtMrhvFxX_JO2Kas2r15AMg92x8Gxd-Dk2VoFGZR4S3qaY0eT8qEhvGRhMEPeihGtUY-SgqrSMbwC0HXDvLRvriQqdaXo5ZM624jCN9FzQG-EPAjqZQvu20tzyohQLYNaVmRnY8X6f7NXo1DuBuylBdl_tEeKaW9ih7Eb8qYtWbVANh1NDTPwdEMut_TgI7lizZptl1c0IrnWzthZe0.TlGNxlwUwl0RczFhkZsZcm0kIEEWIT7CccQg4wPB3FQ&dib_tag=se&keywords=sata%2Bexpansion%2Bcard%2Basm&qid=1716180089&sprefix=sata%2Bexpansion%2Bcard%2Basm%2Caps%2C133&sr=8-5&th=1\n\n\n\n    Already have the ram and psu and an m.2 drive, that cpu is more than plenty right? I will probably end up installing Linux to take advantage of proper tone mapping. any other recommendations?"},
{"Title": "SeaGate Expansion 2 Tb 12$ are it worth and what risk ?", "Author": "u/Merchant_Lawrence", "Content": "Hello everyone, i currently try set up my own nas for archive stuff and on tight budget around 55$ i found on local online shop offer seagate expansion (without mentioning what number or series) 2 tb for just 12 $, it have good rating, are it good choice for long term or it not good ? thanks.\n  \n\n    link on that local online shop (it say tosiba but option available are seagate) : \nhttps://shopee.co.id/Hardisk-Eksternal-Toshiba-2TB-1TB-HDD-USB-3.0-Portable-External-Hard-Drive-Hard-disk-i.997456609.22981243111?sp_atk=abc600c5-5d08-4044-ba64-5c73626f8ba5&xptdk=abc600c5-5d08-4044-ba64-5c73626f8ba5"},
{"Title": "Preserving SketchFab Viewer Experience Offline, with Annotations", "Author": "u/wellnowholdon", "Content": "Hello hello,\n  \n\n    If this is in the wrong place let me know.\n  \n\n    Recently, I subscribed to a website with some embedded SketchFab models available for viewing and interaction. Resultingly, it appears that I have been granted (for an expensive and limited time) indirect access to a very rich repository of engineering models that feature various diagrams, cutaways, animations, and annotations.\n  \n\n    This access allows for interacting with a variety of models, viewing associated educational annotations, and watching demonstrative animations that illustrate the working principles of the modeled object.\n  \n\n    Using Chrome, via the Network tab, I am able to see some line items of interest. These are firstly, *.binz files, alongside what appear to my eye to be associated texture maps, normal files, and so on as a variety of .jpeg files. There are also links to the \nsketchfab.com\n domain and similarly structured API calls.\n  \n\n    I am aware and have investigated the path leading to .binz extraction and conversion. That is not what I'm interested in. It is not a raw 3D model that I am seeking, it is this comprehensive experience. Having access to the base model is all well and good, but what I would like to do is preserve this \"SketchFab Viewer\" experience even after my membership ends with this website.\n  \n\n    So, I would like to ask assistance.\n  \n\n\nIf possible, could pointers be provided to a way for me to preserve offline the material I currently have access to? Alternatively, is there a method to somehow extract a SketchFab link that will persist after my membership expires?\n\n\n\n    Thank you."},
{"Title": "Is it bad for an external HDD to spin while idling?", "Author": "u/BobbythebreinHeenan", "Content": "I’ve used external hard drives (almost always western digital) most of my life. One thing I’ve always noticed is that even when a drive isn’t in use, it will be spinning.\n  \n\n    Is a drive that’s spinning while not in use bad? Is it better to disconnect it from the computer when not in use? Would just unplugging it from the computer sufficient? Or do i need to also disconnect it from power?\n  \n\n    I’ve never had a hard drive fail on me btw."},
{"Title": "Most effective way of using multiple storage devices", "Author": "u/csyst", "Content": "I am looking forward a solution so i can combine multiple harddrives and access them as one drive/mount. Of course something like RAID 0 or LVM would solve this requirement, but I don’t want to loose all the data of all drives in case one drive fails, only the data of the failed drive. But since both variants use striping both ways don’t work, i guess? Also I want to be able to extend the „virtual“ drive later and I don’t want to loose space for redundancy, since I can get all the files again.\n  \n\n    Perhaps someone has an idea? Is there anything like a filesystem or mechanism that merges the drives on the fly?"},
{"Title": "Is a used 71% health 1tb Transcend m.2 nvme worth it for $26?", "Author": "u/ahmadmughal0", "Content": "What the title says, also it's in a third world country so it's not soo cheap for me, but cheaper than a new one. Is it a good catch? A 256gb ssd will be fine for me since I have a 1tb hdd buts it's slow/5400 rpm, in 2017 hp omen) but I'm wondering should i get this cheap with 71%health or a 256gb one new?"},
{"Title": "Trashy setups, mine.", "Author": "u/laggyservice", "Content": "No content"},
{"Title": "how to i set up a regular backup in WIN 11 of a folder.", "Author": "u/BatteryAcidEnj0yer", "Content": "I have a folder of \"family pictures\" and would like to have i back up automatically every few days from an m.2 ssd to a HDD (in the same PC) . The folder is about 200Gb+ so I'd be best if It would only copy new files.\n  \n\n    Preferably using built in tools or opensource solutions\n  \n\n    I'm using windows built in solution ( backup and restore (windows 7)) but I'm unsure if there is a better, more efficient and/or more reliable solution"},
{"Title": "Can anyone help me with some ideas on how to condense my storage into one place? As well, as recommendations of cloud providers", "Author": "u/Coloradozonian", "Content": "Hey there! I'm trying to simplify my digital storage, use one provide,  and cut down on subscriptions. As a photographer, mom, and blogger, So naturally 've accumulated a ton of photos, files, and albums, but they're all over the place between iCloud & Google One, I pay 2TB with each provider! Sometimes my photos do not upload to both clouds, and i go crazy trying to find it.\n  \n\n    I'd love to consolidate everything into one service, but I'm not sure how to transfer my entire Google account (about 290 GB, on a family plan) to iCloud. Or vice versa! Is there an easy way to do this? Maybe an app or a hack that can help? I'm somewhat  tech-savvy, but, I'd appreciate any guidance!\n  \n\n    Also, I recently switched to Verizon 5G Internet, which is great, but it slows down our devices during the day if I drag and drop files from drive to iCloud on my computer.  So, I need to transfer files at night, which is a real pain.\n  \n\n    Any advice or recommendations would be a lifesaver! Thanks in advance!"},
{"Title": "LTO-5 slow write speed, trying to find bottleneck", "Author": "u/fgt67cam", "Content": "I recently purchased a LTO-5 tape drive to back up some HDDs. The drive itself is working and connected via FC using a QLE2562 PCI-E.\n  \n\n    My plan was to original create a SAS RAID 0 to temp store the files being written to tape from the offline HDDs but I've had issues with the P410 controller not working so for now will have to connect the offline SATA drives to the server (Proliant ML330 G6).\n  \n\n    The drives I'm using aren't fast (ST3500312CS) but I did a read speed test using dd if=mytestfile of=/dev/null bs=1M count=1024 and they're getting around 80-90/MBs and online speed results show roughly the same. It's not fast but should be enough to do one backup copy before trying to fix the SAS issue.\n  \n\n    I've timed how long it's taking for it to do each file and the results:\n  \nFile 1 - 309 seconds - 10,045,430,602 bytes ~32.5/MBs\nFile 2 - 291 seconds - 13,597,137,146 bytes ~46.7/MBs\nFile 3 - 302 seconds - 13,967,991,165 bytes ~46.2/MBs\nFile 4 - 94 seconds - 4,526,005,392 bytes ~48.1/MBs\nFile 5 - 113 seconds - 5,139,777,083 bytes ~45.4/MBs\nFile 6 - 107 seconds - 4,917,953,848 bytes ~45.9/MBs\n\n    As first it seemed like the culprit was the HDDs so I installed a Samsung EVO 850. It scored 226/MBs with the same read test so much faster than the HDDs. I then had it write a 34GB file to tape and it took 528 seconds (not including tape rewind time) coming in at ~69.1/MBs which is still slow so I don't think the bottle neck is the SATA drives. The FC card is showing the link speed as 8Gbps and even if it was 1Gbps it's still too slow so I don't think it could be that. All that's left is the tape drive or Debian/drivers/software. I'm using \"tar cvf /dev/st0\" to write data to the tape.\n  \n\n\nEDIT 22/05/24\n\n\n\n    I've since built a new computer with more modern hardware to see if it made a difference using a 5280K, 16GB RAM and GA-X99M-Gaming5. Tested with a 2TB HDD and RAM drive, both scored ~106/MBs which seems to be the maximum it can do. I don't know what speeds are good for LTO-5 and if you can realistically get anywhere close to maximum of 140/MBs."},
{"Title": "backup multiple windows and Linux machines, and several loose HDD/SSD/CD/DVD onto a single windows machine (not NAS, not cloud)", "Author": "u/tater1337", "Content": "Honestly I tried searching here, but either I get confused or I cannot tell is the solution will fit my needs\n  \n\n    I have\n[windows]\nmy main PC\nwork laptop\na second home machine that does some tasks that I don't want on the main PC (like housing all the backups)\npersonal laptop\na bunch of loose hard drives, both SSD and HDD with data that I might want in the future(grandparents disks full of photos type stuff)\na PC set up as a DVR for a bunch of security cameras(not wanting to save the footage, just an easy restore if something breaks and a reinstall is needed)\n  \n\n    Linux\na couple of PCs used for Minecraft servers\na PC set up for home assistant\na couple of netbooks, some have software for 3d printers, CNC machines, Laser engravers, etc\na whole load of raspberry pi's with various weird stuff\n  \n\n    a stack of DVDs and CDs that I'd like to have backup copied in case of physical damage\n  \n\n    right now I have some backups of some machines, but I have not been able to get everything backed up\n  \n\n    my plan\ntake my recently purchased 16tb drive and dump everything on that, then get another drive to copy the first (or expand)....THEN set up a backup physically somewhere else\n  \n\n    what are my options? I've cloned drives with FileZilla, but only on a \"copy this HDD to a SSD to improve old machine\", not for backups\nI tried to get windows backup to try to backup my main PC to the secondary PC, but it fails more often than it works\n  \n\n    getting Linux and windows to play nicely together seems like black magic. more comfortable in windows than Linux\n  \n\n    tutorials, software options desired, dedicated NAS hardware solutions or cloud are not"},
{"Title": "Trying to find some forgotten RAID subsystem firmware.", "Author": "u/Zone_Purifier", "Content": "In an attempt to make it work properly with some newer drives, I've been hunting for the latest SAS firmware for a AXUS Y3-24S6SF8 RAID Subunit. AXUS is a former subsidiary of ASUS, one which hasn't been around since 2014 and might have some connection with Areca. This search has taken me to internet archive, ASUS, Areca, and random russian server hardware sites in search for this firmware. I've found some interesting leads and dead end phone numbers and emails, but nothing that yields the .bin (probably) that I need to update the system. If anyone has access to these files or might have ideas of where I can get firmware for such a seemingly obscure device, that would be great. Here's what I've found so far:\n  \n\n\nAXUS Website, latest archive\n\n\n\n\nYOTTA III Firmware Page Archive\n\n\n\n\nAXUS Closure Notice\n\n\n\n\nAXUS Final Contact Information Notice\n\n\n\n\nYOTTA 3 User Manual\n\n\n\n    And some system info from the unit itself:\n  \nhttps://preview.redd.it/trying-to-find-some-forgotten-raid-subsystem-firmware-v0-vymbg5rh0c1d1.png\nhttps://preview.redd.it/trying-to-find-some-forgotten-raid-subsystem-firmware-v0-oi55a5rh0c1d1.png"},
{"Title": "Crucial X6, X9 or another for photos and videos backup?", "Author": "u/3dforlife", "Content": "Hi there!\n  \n\n    I've had several internal and external HDDs that I used to backup my photos and videos. However, almost all have died the last years. I just can't stand them anymore. For reference, I've bought two Seagate Barracuda Green 4TB, and I've sent them 3 times already to be replaced...\n  \n\n    At the moment I have 1,3TB of photos and videos in a WD Blue 4TB, and I edit photos and videos with it.\n  \n\n    Therefore, I'm thinking of buying a SSD to backup my media, since I haven't had any problems with them (granted, I've only used them as main drives).\n  \n\n    Is the Crucial X6 (119 € 2TB) a good choice? It's on sale right now, but I've read that the cache depletes after having had 250GB written. After that, it writes at 40MBps, if I'm not mistaken. It is also QLC, which might affect longevity.\n  \n\n    Regarding the X9 (144€ 2TB), I can't find any review...\n  \n\n    I have bought the X9 pro (174€ 2TB) for my work, and it's very good, but it might be overkill for backups.\n  \n\n    A redditor, u/\nJohnnieLouHansen\n said that if I didn't need the speed of an SSD and wanted reliability, to go with Western Digital Enterprise drives, gold. He also said that he has put them in customer PCs. One pair are going on 10 years at 10 hours per day and another set ran 24/7 for 6 years.\n  \n\n    I searched for them on Amazon, and used Fakespot; the reviews were graded D, i.e., not reliable any highly deceptive: \nhttps://amzn.eu/d/fHMwwAj\n What conclusion can I take from this?\n  \n\n    What do you recommend? Any of these, some other?"},
{"Title": "17.1 TB \"size on disk\" on a 12TB drive", "Author": "u/useless_shoehorn", "Content": "Hi. I have a bunch of movies on a 12TB drive. Some of them didn't finish torrenting in windows/NTFS. I wanted to extend this drive in windows, but my block size was too small (4096). I have since repented and spun up a TrueNas server with the other 12TB drive (1M block size). However, as I'm copying to it I'm running out of space. Even if every file needed another 1M for the block size change, that's only 70GB right? What am I missing? How is the size on disk 17.1TB? What does that even mean?\n  \nhttps://preview.redd.it/17-1-tb-size-on-disk-on-a-12tb-drive-v0-ufx8hwhwp71d1.png\nhttps://preview.redd.it/17-1-tb-size-on-disk-on-a-12tb-drive-v0-p070vuhwp71d1.png"},
{"Title": "Strategy with hoarding and digesting large chunk of (small in size but large in number) folders and files", "Author": "u/cod201", "Content": "tldr: extracted more than 1.4 mils folder ( each inside have files)  into single folder in NTFS, ridiculous bad IO performance. Divided into 500 folders and got better IO, but i know i'm, dumb. Ask for better approach.\n  \n\n    Hi,\n  \n\n    I am using NTFS on Windows to run an research but i'm facing performance decrease, maybe due to data and index fragmentation.\n  \n\n    I receive multiple ZIP files everyday to extract, inside zip file is multiple folder, each folder is an unit of data for us to digest using Python, and upload them to Elastic (these in bright cyan).\n  \na brief structure of my data\n\n    Because the server is headless, i just recognized the problem when i connected it again, when it reached 1,5 millions folders, approx. 1.5TB  inside JUST A SINGLE folder. (about 7TBs waiting to extracting but i stopped it)\n  \nhttps://preview.redd.it/strategy-with-hoarding-and-digesting-large-chunk-of-small-v0-cu59lxq1kc1d1.png\n\n    So, when I move/ rename.. a folder, it is extremely lagging, moving a small file barely took more than hour. Just view the properties take more than 1GB of RAM.\n  \nhttps://preview.redd.it/strategy-with-hoarding-and-digesting-large-chunk-of-small-v0-ocwa17rujc1d1.png\n\n    I've just moving these data into other disc and dividing into 500 folders, based on its name (from AA to ZZ), the performance just got better, but idk is there any better ways to storage and using these data?\n  \n\n    I use Python to work with these file (maybe upgrading to C#/go.. for better multi threaded performance) and after digesting, i would storage it for about 6-12 months before delete it.\n  \n\n    I know my strategy is somewhat inefficient, so i'm asking if i could make it better. Thanks"},
{"Title": "FPF: I see your trashy setup, and submit my own for disapproval.", "Author": "u/Lanky-Antelope7006", "Content": "No content"},
{"Title": "When they ask you why", "Author": "u/eidolons", "Content": "You tell them this is why."},
{"Title": "Megs, Gigs, _____, ______?", "Author": "u/cheater00", "Content": "It's very annoying that there isn't a good short word for \"Terabytes\" or \"Petabytes\".\n  \n\n    This is my momentary frustration and I thought I'd come here to complain about it."},
{"Title": "Comparing the data on two different hard drives", "Author": "u/Not-The-Dark-Lord-7", "Content": "Hi all,\n  \n\n    I am new to this sub so please forgive me if this isn’t the right place or the right way to ask this question. Basically, I currently have an  Apple 2021 M1 iMac with 1 TB of storage, and I would like to backup my data. I can buy a $65 2 TB Seagate HDD, a $20 enclosure, use time machine to backup my data, and this would be a good solution (right? I’m saying these things as I understand them, but please correct anything I say that’s not entirely accurate). However, I have an old 1 TB HDD from an old iMac, because I swapped the HDD for an SSD. I think it might be convenient to use this for my backups instead. However, I’m like 90% I need to wipe and reformat the drive first, because when I just plug it in, it doesn’t show up on Time Machine. I’ve looked at the drive, and it seems like pretty much all of the data on it is on my current computer. However, I don’t want to lose any files that might only be on the HDD, and while I’m like 90% certain that all the data on the HDD is also on my iMac, I’d like to make certain before wiping it. So, two questions here:\n  \n\n\n\n\n\n    What is the easiest way to check and see if all the data on the HDD is also on the SSD?\n  \n\n\n\n\n\n    Do I even need to do that? Should I just bite the bullet and get a new 2 TB HDD? The HDD doesn’t support SMART so I can’t see exactly how many total read/writes are on it, but I’m fairly certain it really isn’t that many, so that isn’t a big concern of mine. Newer drives like the ones I was looking at from Seagate support SMART, so I guess that might be better for monitoring the drive’s health. Also, I’m only using about 250 GB on my SSD right now, the 1 TB HDD is large enough for backups.\n  \n\n\n\n\n\n    I look forward to being enlightened by this community!"},
{"Title": "Fate of the Internet Archive", "Author": "u/Coolkatisa2511", "Content": "Now that the music lawsuit is going to happen, will this be the thing to kill the Internet Archive? Universal is a powerful company with a lot of money and they can easily kill off the website. What do you think will happen if/when the Internet Archive loses?"},
{"Title": "Nas advice", "Author": "u/foxhound13", "Content": "Complete newbie here, looking to purchase a Nas purely for storing and streaming video content to my laptop, what I'm trying to understand is the following:\n  \n\n    Lots of the cheaper options have 1gb ram, will that do for standard video play back from the device to a computer. (standard size files no 4k likely no VR) I'm not sure if ram is even a bottleneck here or not.\n  \n\n    Might be silly but How viable is using a torrent program to download video content to the NAS and is there any considerations i might want to make especially around download speed (Im fine with a lan connection if recommended)\n  \n\n    Do most NAS units come with password Protection software/abilities and a Lan port\n  \n\n    I'm in the market for an 8tb nas with drives included (4tb actual storage 4 redundancy I think) and room to grow for the cheapest possible if anyone has any recommendations.\n  \n\n    I don't think i require plex or any fancy ui stuff just straight up storage I can play video files from, any help is appriciated."},
{"Title": "Downsized from 5TB to 100GB on OneDrive Edu - Seeking Storage Solutions on a Budget!", "Author": "u/cuong3101", "Content": "I’m in a bit of a pickle and could use your collective wisdom. My OneDrive Edu account, which was my digital haven with 5TB of space, has been abruptly downsized to a mere 100GB. This change came without warning, as I missed the memo about Microsoft scaling down storage for educational institutions.\n  \n\n    Here’s my current setup:\n  \n\n\n\n\n\n    Three 3.5 inch 1TB HDDs (one’s a dedicated movie library)\n  \n\n\n\n\n\n    A 500GB Samsung 860 Evo SSD\n  \n\n\n\n\n\n    A “2.5 / 3.5 inch 2 Bay USB3.0 1 to 1 Clone Hard Drive Dock” (sans RAID, so it’s just two separate drives)\n  \n\n\n\n\n\n    With my OneDrive now bursting at the seams with 1.3TB-1.5TB of data, I’m exploring storage alternatives that won’t break the bank. The NAS Synology DS220j or DS223j are within my financial reach, but they offer only two hard drive slots.\n  \n\n    There’s also an old family computer gathering dust back home, powered by an i5 (6th or 8th gen) and a 300W power supply of dubious origin. It’s been out of action for a while, and I’m not even sure it’s still operational. Reviving it would mean having it shipped over, which is a 4-5 day wait.\n  \n\n    So, dear Redditors, what’s my best move here? Should I invest in a budget NAS, attempt to resurrect the old PC, or is there another ingenious solution I haven’t considered?\n  \n\n    UPDATE:\nThanks for everyone's comments, after a week has passed I update the current situation as follows.\n  \n\n\n\n\n\n\nTemporarily\n: I have manually backed up all data on OneDrive to 2 1TB hard drives. My data is temporarily safe.\n  \n\n\n\n\n\n\nFuture\n: Maybe I will find a way to take advantage of the old computer at home to use up the remaining hard drives and have access to the data in the other two hard drives at all times. If that doesn't work, I'm thinking of buying Synology's DS423 NAS device.\n  \n\n\n\n\n\n    The best-case scenario is that I could have 2 separate devices (1 Synology NAS and 1 NAS from my old computer), put them in 2 separate places and hope to find a way to sync them. In the long run, I will look into some more cloud storage packages to back up data from the other 2 devices. So I can have 3 copies of data: 1 on my personal computer that can be accessed at all times, 1 on the NAS device and 1 on the cloud. Hopefully this way I won't have to worry about data being at risk of being lost in the future.\n  \n\n    UPDATE 2:\n  \n\n    I was wondering why everyone suggested a 6TB hard drive to me so much. Then I realized that my poor English writing made people misunderstand that I needed to back up 5TB of data from OneDrive instead of 1.5TB."},
{"Title": "Trust me, I'm not always this trashy 😁", "Author": "u/zaca21", "Content": "No content"},
{"Title": "Seeking Advice on Optimizing my Storage Configuration in Proxmox with TrueNAS Scale and ZFS", "Author": "u/Vegan_Salad69", "Content": "Hi everyone,\n  \n\n    I’ve been homelabbing for about three years now and I’m looking for some advice on optimizing my storage setup. Here’s a quick overview of my current configuration:\n  \n\n\nServer:\n Dell R750\n  \n\n\n\n\n\n\nFront:\n Twelve 3.5\" SATA/SAS bays\n  \n\n\n\n\n\n\nRear:\n Four 2.5\" SATA/SAS bays\n  \n\n\n\n\n\n\nRAID Card:\n PERC 350H (supports RAID 1, 0, 10) (don’t worry, I use it in passthrough mode and it works so far, even on ZFS. Yes, I know that’s also a problem, and I plan to buy an HBA or use the RAID card for its intended purpose)\n  \n\n\n\n\n\n\n4x 10Gig SFP+ Networking\n via DAC SFP+ Moduels (For more info on that i have a post of my entire homelab on my Profile)\n  \n\n\n\n\n\n\nDrives:\n\n\n\n\n\n\n\n    Eight 4TB HDDs\n  \n\n\n\n\n\n    Two 3TB HDDs\n  \n\n\n\n\n\n    Two 2TB HDDs\n  \n\n\n\n\n\n    Two SAS 600GB HDDs\n  \n\n\n\n\n\n    Two 2TB SATA SSDs\n  \n\n\n\n\n\n\nCurrent Setup:\n\n\n\n\n\n\n\n    Proxmox as the hypervisor\n  \n\n\n\n\n\n    TrueNAS Scale as a VM with passthrough for ZFS\n  \n\n\n\n\n\n    I’m facing potential performance issues because TrueNAS Scale is virtualized. I’m considering a few options and would love your input:\n  \n\n\n\n\n\n\nInstalling Proxmox on SSDs:\n Utilizing the SSDs for the OS to leverage their speed for the hypervisor.\n  \n\n\n\n\n\n\nUsing SAS drives as cache:\n Taking advantage of the 12Gbps speed for caching to enhance overall performance.\n  \n\n\n\n\n\n\nDirect ZFS on Proxmox:\n Managing the drives directly in Proxmox with ZFS, but I’m concerned about losing functionalities like SMB sharing, permissions management, and user administration.\n  \n\n\n\n\n\n\nI also have an old Synology RS2818RP+ that I could use:\n\n\n\n\n\n\n\n    Synology NAS with 16 bays and 10GbE connectivity.\n  \n\n\n\n\n\n    Equipped with the E10M20-T1 (a 10Gig Network card with 2x 2TB NVMe SSDs for network cache).\n  \n\n\n\n\n\n    Considering moving all large HDDs to the Synology and using it as the main storage, and only hosting the VMs' main system on the Dell's SSDs (so each VM gets 32GB; the main storage is on the Synology).\n  \n\n\n\n\n\n    Direct 10GbE connection to the Dell R750 for high-speed access. (Block Access)\n  \n\n\n\n\n\n\nPotential Solutions:\n\n\n\n\n\n\n\n\nBare Metal TrueNAS Scale:\n Install TrueNAS directly on the server for maximum performance, but lose the flexibility of Proxmox.\n  \n\n\n\n\n\n\nProxmox with ZFS and Containers/VMs:\n Use Proxmox with ZFS for storage and handle additional services (SMB, permissions, Nextcloud) via LXC containers or VMs.\n  \n\n\n\n\n\n\nHybrid Approach:\n Keep Proxmox with ZFS pools, and run a VM for TrueNAS Scale to manage SMB and NFS, with other services running in containers/VMs on Proxmox.\n  \n\n\n\n\n\n\nLeveraging Synology NAS:\n\n\n\n\n\n\n\n    Use the Synology as the main storage system with 10GbE connectivity to the Dell R750.\n  \n\n\n\n\n\n    Utilize the NVMe SSD cache on the Synology for improved performance.\n  \n\n\n\n\n\n    Keep the SSDs and SAS drives in the Dell R750 for caching and high-speed storage needs.\n  \n\n\n\n\n\n\n\n\n\n    I’d love to hear your thoughts on these approaches or any other suggestions you might have. What would be the best way to balance performance, flexibility, and power efficiency in this setup?\n  \n\n    Thanks in advance for your help! I hope you all have a good weekend. Best wishes, keep hoarding.\n  \n\n\n\n\n\n    a VeganSalat"},
{"Title": "Finding good deals for HDDs and SSDs?", "Author": "u/Neurrone", "Content": "I currently have 4 x 4TB Seagate Ironwolfs and am looking to expand.\n  \n\n\n\n\n\n    Are there price trackers that I could use to get a sense of what a good deal would be, in terms of price per TB? Something that can send alerts when prices drop below a certain level would be an added bonus\n  \n\n\n\n\n\n    How safe is it to use used drives? They are half the price of new ones, but might fail more quickly."},
{"Title": "Optical Archiving", "Author": "Unknown author", "Content": "Just learned of the new DM for Archiving Blu-ray standard that should last 100 years. This is the player/burner Pioneer BDR-WX01DM JIS X6257 Compliant DM for Archive. Y'all may know this, but just decided to share, share your usage and impresions please."},
{"Title": "New CDs can hold 1+ petabytes of storage", "Author": "u/GiantJupiter45", "Content": "No content"},
{"Title": "There Is No Good Reason To Just Let Unsupported Video Games Die", "Author": "u/AbolishDisney", "Content": "No content"},
{"Title": "Finally... after seven years, a 6TB 2.5-inch external hard drive has made it to market.", "Author": "u/Torley_", "Content": "No content"},
{"Title": "The ArchiveTeam has a \"cost shameboard\" of the top users who are incurring the highest costs for the Internet Archive", "Author": "u/BananaBus43", "Content": "No content"},
{"Title": "IBM LTO4 TS2340 Error Code 5 - drive doesn't work", "Author": "u/awesomefreeman", "Content": "I bought drive via mail without checking it 😫. When turned on, it shows error code 5, which corresponds to a hardware problem. I completely disassembled the drive, but could not find the reason. The mechanics inside are good, cassettes can be inserted and removed.\n  \n\n    The diagnostic program ITDT showed the same error. I don’t know what to do, has anyone encountered a similar problem?\n  \nhttps://preview.redd.it/ibm-lto4-ts2340-error-code-5-drive-doesnt-work-v0-knqoyrl5l61d1.jpg\nhttps://preview.redd.it/ibm-lto4-ts2340-error-code-5-drive-doesnt-work-v0-zexu05b9l61d1.jpg\n\n    UPDATE: Entring and exiting maintence mode helped. But after insert cartridge  I've got the same error appears\n  \nhttps://preview.redd.it/ibm-lto4-ts2340-error-code-5-drive-doesnt-work-v0-a6q0sqcyp61d1.png"},
{"Title": "Downloading Fullsize Pastperfectonline Images?", "Author": "u/Acrobatic_Owl_4101", "Content": "Hello, in the past I've seen various posts and websites on how to get fullsize images from behind the times museums that post VGA quality images that are mere thumbnails in today's modern screens.  I have not seen tips for getting images from Past Perfect Online sites though.  Does anyone know how I'd get a bigger image than the small \"zoom in\" I get clicking the image?"},
{"Title": "Reusing drives from a WD EX2 Ultra", "Author": "u/Physical_Taste_4487", "Content": "Hi. I currently have a WD My Cloud EX2 Ultra and want to move on from it. It has 2x16TB setup as JBOD. (Full of data) How do I go about using drives in a new enclosure? Is there any way of doing this whilst preserving the data? Or will I have to transfer the data to something else first? I don’t mind doing this if I have to as long as I can use the drives in some other NAS/Enclosure once it’s all done.\n  \n\n    Any advice much appreciated."},
{"Title": "Is it possible that some day in the distant future, we will have an archive with all the data that was ever uploaded to the internet (also deleted data) that is accessible by anyone?", "Author": "u/NeroD_175", "Content": "I just thought about how cool it would be if something like that existed. Just imagining being able to download whatever I'm thinking about instantly just by typing in a few keywords to find it, regardless if it was deleted or not.. Sure there would probably be some issues with that, like privacy concerns etc. but to me, data is memory and memories are by far the most valuable thing we have as human beings. As a datahoarder who has lost precious data/memories before, this is my ultimate fantasy."},
{"Title": "Sort photos into folders based on EXIFs Description", "Author": "u/SympatheticLion", "Content": "Hey Fellow Hoarders,\n  \n\n    I'm looking for an open source solution to sort 1000's of mid journey photos to group similar photos and put them into folders automagically based on metadata/EXIF description. The description is quite detailed and it would be ideal if it can be used to also rename the file too.\n  \n\n    I've been looking into photoprism, digikam, darktable and can't figure out which one will work for this purpose. Photoprism so far can recognize faces and group them, but not add it into a folder based on exif description.\n  \n\n    Anyone know of a solution that would work? Thanks in advance!!"},
{"Title": "Yes or no for NAS?", "Author": "u/gunzaj", "Content": "No content"},
{"Title": "Extreme Picture Finder Saving video in multiple files", "Author": "u/ReyArthurLXIX", "Content": "Extreme Picture Finder is saving videos in multiple files, an index followed by several videos named video0, video1 and so on, how can i save it all as 1 video?"},
{"Title": "Dell R720XD - Backplane HBA Card Query", "Author": "u/willdab34st", "Content": "Hi, I was going to purchase a second controller for my R720XD, front disk container and backplane is a perc mini mono setup. However I remembered I pulled a few SAS HBA's out of it when I got it. They are Dell g164p 6GB/S HBA cards, apparently they are the same board as the more common H200E just with no internal headers, just external.\n  \n\n    I'm thinking I can use these instead of purchasing another card, but unsure how I would hook this up, as far as I can deduce I'll need to plug in a backplane somewhere in the rear for the SATA board and I'll have to route the cables from outside the chassis. The g164p cards have a type of sfp connector, assuming this is standard for connecting backplanes etc and buying a backplane off of eBay for R720XD will work with this?\n  \n\n    Related question, I would assume it's not possible to split the front drive bays so some are served with different controllers? If not then I'd have to mount new drives for the HBA controller in the rear somewhere, there does look established slots there already, 2.5\"."},
{"Title": "Advice on building a DAS", "Author": "u/the_mcm", "Content": "I’m about to head off to college and want to have a single place for storage with some redundancy. I know it’d be best to have some sort of offisite backup, but I don’t really have the money for that right now judging by the amount of files I need to store.\n  \n\n    I’d mostly be storing a lot of video projects (abt 6tb+ currently), hoping to also do some editing off of the DAS, along with playing and storing a decent bit of dvd/blu ray rips (abt 2+ tb and growing). I’d also probably have a decent but more of other miscellaneous music, videos, etc to store.\n  \n\n    Doing some limited research I saw good things about the OWC Mercury quad paired with OWC’s SoftRaid to do a RAID5 set up.\n  \n\n    Pricing things out, it seems like I could get 4 WD Red 8tb HDDs along with the OWC enclosure for right around my budget of about $1k, and would give me 24tb usable space.\n  \n\n    Does this seem like a reasonable set up for my needs, and would RAID5 be good if I’ll be writing and reading from the DAS often? Thanks."},
{"Title": "Will storing large files in a NAS wear out hard drives faster?", "Author": "u/Hostile_18", "Content": "Hi all. New to all this. Got my media NAS and am trying to decide between good x254 encodes at around 1.2-2.2gb or full 1080p remux episodes at around 7-12gb. My question is will the quality difference be worth it, and also will it significantly reduce the hard drives lifespan? I've got 6x 20tb Exos drives that have a work load of 550tb a year for 5 years, I guess half that if you run parity once a month. All this and that's not even counting huge 4k remux files. The X-files 1080p remux from the Blu-Ray discs is like 2tb alone.\n  \n\n    What's anyone elses experience hosting large media files? Have the hard drives held up over time? I have about 6 clients outside the local network, if that makes a significant difference."},
{"Title": "Good software for magazine scanning?", "Author": "u/vier86", "Content": "I am about to embark on a journey to scan and upload a large cache of magazines I have inherited onto \nhttps://archive.org/\n.\n  \n\n    The plan is to debind each magazine and scan them on a flatbed Canon CanoScan 9000f.\n  \n\n\n\n\n\n    What software would be best to use for this?\n  \n\n\n\n\n\n    Should I convert each to a PDF, TIFF, JPEG?\n  \n\n\n\n\n\n    Anything else I should know?"},
{"Title": "Data consolidation – home set-up - Mac and DAS", "Author": "u/intastellaburst", "Content": "I have searched through previous posts but they were all either really old or didn’t address this kind of setup.\n  \n\n    I want to consolidate decades of data from different sources and put it all together on a DAS (or similar) that can plug into a 2018 MacBook Pro (with USB-C).\n  \n\n    I’m going with DAS-to-computer setup because I intend to use Backblaze to keep the whole thing backed up to the cloud for low-cost (directly connected drives are included in their unlimited backup and only need to be plugged in once a year to stay backed up).\n  \n\n    Ideally, I’d like around 10 TB, but I’m unsure how to get there.\n  \n\n    I was hoping to use SSD drives or M.2 in some kind of enclosure but they may be too expensive. It sounds like software RAID is better, but I’m unsure how to get that going on a Mac, and I’m not sure which enclosure/drives to get.\n  \n\n    Oh yes, and the main consideration is cost - I need to do this on the cheap, even if it's a little improvised or rough around the edges.\n  \n\n    I don’t need screaming speed, but I do want to move and access many photos and videos without having to wait.\n  \n\n    If 2 or 3 large and slow SATA drives on a particular RAID setup gets me good enough performance through USB-3 or Thunderbolt, that’s also fine.\n  \n\n    There are so many options, and I’m a little bamboozled.\n  \n\n    So in summary:\n  \n\n\n\n\n\n    looking for hardware and Mac RAID suggestions\n  \n\n\n\n\n\n    DAS connected to a Mac with USB-C\n  \n\n\n\n\n\n    Around 10 TB\n  \n\n\n\n\n\n    Fast transfer, but not too expensive\n  \n\n\n\n\n\n    Happy to build and find parts\n  \n\n\n\n\n\n    Any thoughts?"},
{"Title": "efficient and visually pleasing way to combine all the images I downloaded from a Pinterest board?", "Author": "u/Late_Repair_9899", "Content": "Firstly, I have found my home.\n  \n\n    Secondly, I save hundreds of images and MP4s monthly. I like to see them digitally (and often print them when I can) because they inspire my art and life and imagination (but also who am I kidding it's a part of the hoarding cycle).\n  \n\n    I have been using the straight-up Photoshop Contact batch process, but they're always the same size and you can't include the MP4s. I also don't want to spend time on ANY of it (other than satisfying printing and cutting and looking)... so canva templates are OUT.\n  \n\n    Anything out there that would automate hundreds of images at once?"},
{"Title": "Comparing the data on two different hard drives", "Author": "u/Not-The-Dark-Lord-7", "Content": "Hi all,\n  \n\n    I am new to this sub so please forgive me if this isn’t the right place or the right way to ask this question. Basically, I currently have an  Apple 2021 M1 iMac with 1 TB of storage, and I would like to backup my data. I can buy a $65 2 TB Seagate HDD, a $20 enclosure, use time machine to backup my data, and this would be a good solution (right? I’m saying these things as I understand them, but please correct anything I say that’s not entirely accurate). However, I have an old 1 TB HDD from an old iMac, because I swapped the HDD for an SSD. I think it might be convenient to use this for my backups instead. However, I’m like 90% I need to wipe and reformat the drive first, because when I just plug it in, it doesn’t show up on Time Machine. I’ve looked at the drive, and it seems like pretty much all of the data on it is on my current computer. However, I don’t want to lose any files that might only be on the HDD, and while I’m like 90% certain that all the data on the HDD is also on my iMac, I’d like to make certain before wiping it. So, two questions here:\n  \n\n\n\n\n\n    What is the easiest way to check and see if all the data on the HDD is also on the SSD?\n  \n\n\n\n\n\n    Do I even need to do that? Should I just bite the bullet and get a new 2 TB HDD? The HDD doesn’t support SMART so I can’t see exactly how many total read/writes are on it, but I’m fairly certain it really isn’t that many, so that isn’t a big concern of mine. Newer drives like the ones I was looking at from Seagate support SMART, so I guess that might be better for monitoring the drive’s health. Also, I’m only using about 250 GB on my SSD right now, the 1 TB HDD is large enough for backups.\n  \n\n\n\n\n\n    I look forward to being enlightened by this community!"},
{"Title": "Fate of the Internet Archive", "Author": "u/Coolkatisa2511", "Content": "Now that the music lawsuit is going to happen, will this be the thing to kill the Internet Archive? Universal is a powerful company with a lot of money and they can easily kill off the website. What do you think will happen if/when the Internet Archive loses?"},
{"Title": "Nas advice", "Author": "u/foxhound13", "Content": "Complete newbie here, looking to purchase a Nas purely for storing and streaming video content to my laptop, what I'm trying to understand is the following:\n  \n\n    Lots of the cheaper options have 1gb ram, will that do for standard video play back from the device to a computer. (standard size files no 4k likely no VR) I'm not sure if ram is even a bottleneck here or not.\n  \n\n    Might be silly but How viable is using a torrent program to download video content to the NAS and is there any considerations i might want to make especially around download speed (Im fine with a lan connection if recommended)\n  \n\n    Do most NAS units come with password Protection software/abilities and a Lan port\n  \n\n    I'm in the market for an 8tb nas with drives included (4tb actual storage 4 redundancy I think) and room to grow for the cheapest possible if anyone has any recommendations.\n  \n\n    I don't think i require plex or any fancy ui stuff just straight up storage I can play video files from, any help is appriciated."},
{"Title": "Downsized from 5TB to 100GB on OneDrive Edu - Seeking Storage Solutions on a Budget!", "Author": "u/cuong3101", "Content": "I’m in a bit of a pickle and could use your collective wisdom. My OneDrive Edu account, which was my digital haven with 5TB of space, has been abruptly downsized to a mere 100GB. This change came without warning, as I missed the memo about Microsoft scaling down storage for educational institutions.\n  \n\n    Here’s my current setup:\n  \n\n\n\n\n\n    Three 3.5 inch 1TB HDDs (one’s a dedicated movie library)\n  \n\n\n\n\n\n    A 500GB Samsung 860 Evo SSD\n  \n\n\n\n\n\n    A “2.5 / 3.5 inch 2 Bay USB3.0 1 to 1 Clone Hard Drive Dock” (sans RAID, so it’s just two separate drives)\n  \n\n\n\n\n\n    With my OneDrive now bursting at the seams with 1.3TB-1.5TB of data, I’m exploring storage alternatives that won’t break the bank. The NAS Synology DS220j or DS223j are within my financial reach, but they offer only two hard drive slots.\n  \n\n    There’s also an old family computer gathering dust back home, powered by an i5 (6th or 8th gen) and a 300W power supply of dubious origin. It’s been out of action for a while, and I’m not even sure it’s still operational. Reviving it would mean having it shipped over, which is a 4-5 day wait.\n  \n\n    So, dear Redditors, what’s my best move here? Should I invest in a budget NAS, attempt to resurrect the old PC, or is there another ingenious solution I haven’t considered?\n  \n\n    UPDATE:\nThanks for everyone's comments, after a week has passed I update the current situation as follows.\n  \n\n\n\n\n\n\nTemporarily\n: I have manually backed up all data on OneDrive to 2 1TB hard drives. My data is temporarily safe.\n  \n\n\n\n\n\n\nFuture\n: Maybe I will find a way to take advantage of the old computer at home to use up the remaining hard drives and have access to the data in the other two hard drives at all times. If that doesn't work, I'm thinking of buying Synology's DS423 NAS device.\n  \n\n\n\n\n\n    The best-case scenario is that I could have 2 separate devices (1 Synology NAS and 1 NAS from my old computer), put them in 2 separate places and hope to find a way to sync them. In the long run, I will look into some more cloud storage packages to back up data from the other 2 devices. So I can have 3 copies of data: 1 on my personal computer that can be accessed at all times, 1 on the NAS device and 1 on the cloud. Hopefully this way I won't have to worry about data being at risk of being lost in the future.\n  \n\n    UPDATE 2:\n  \n\n    I was wondering why everyone suggested a 6TB hard drive to me so much. Then I realized that my poor English writing made people misunderstand that I needed to back up 5TB of data from OneDrive instead of 1.5TB."},
{"Title": "Trust me, I'm not always this trashy 😁", "Author": "u/zaca21", "Content": "No content"},
{"Title": "Seeking Advice on Optimizing my Storage Configuration in Proxmox with TrueNAS Scale and ZFS", "Author": "u/Vegan_Salad69", "Content": "Hi everyone,\n  \n\n    I’ve been homelabbing for about three years now and I’m looking for some advice on optimizing my storage setup. Here’s a quick overview of my current configuration:\n  \n\n\nServer:\n Dell R750\n  \n\n\n\n\n\n\nFront:\n Twelve 3.5\" SATA/SAS bays\n  \n\n\n\n\n\n\nRear:\n Four 2.5\" SATA/SAS bays\n  \n\n\n\n\n\n\nRAID Card:\n PERC 350H (supports RAID 1, 0, 10) (don’t worry, I use it in passthrough mode and it works so far, even on ZFS. Yes, I know that’s also a problem, and I plan to buy an HBA or use the RAID card for its intended purpose)\n  \n\n\n\n\n\n\n4x 10Gig SFP+ Networking\n via DAC SFP+ Moduels (For more info on that i have a post of my entire homelab on my Profile)\n  \n\n\n\n\n\n\nDrives:\n\n\n\n\n\n\n\n    Eight 4TB HDDs\n  \n\n\n\n\n\n    Two 3TB HDDs\n  \n\n\n\n\n\n    Two 2TB HDDs\n  \n\n\n\n\n\n    Two SAS 600GB HDDs\n  \n\n\n\n\n\n    Two 2TB SATA SSDs\n  \n\n\n\n\n\n\nCurrent Setup:\n\n\n\n\n\n\n\n    Proxmox as the hypervisor\n  \n\n\n\n\n\n    TrueNAS Scale as a VM with passthrough for ZFS\n  \n\n\n\n\n\n    I’m facing potential performance issues because TrueNAS Scale is virtualized. I’m considering a few options and would love your input:\n  \n\n\n\n\n\n\nInstalling Proxmox on SSDs:\n Utilizing the SSDs for the OS to leverage their speed for the hypervisor.\n  \n\n\n\n\n\n\nUsing SAS drives as cache:\n Taking advantage of the 12Gbps speed for caching to enhance overall performance.\n  \n\n\n\n\n\n\nDirect ZFS on Proxmox:\n Managing the drives directly in Proxmox with ZFS, but I’m concerned about losing functionalities like SMB sharing, permissions management, and user administration.\n  \n\n\n\n\n\n\nI also have an old Synology RS2818RP+ that I could use:\n\n\n\n\n\n\n\n    Synology NAS with 16 bays and 10GbE connectivity.\n  \n\n\n\n\n\n    Equipped with the E10M20-T1 (a 10Gig Network card with 2x 2TB NVMe SSDs for network cache).\n  \n\n\n\n\n\n    Considering moving all large HDDs to the Synology and using it as the main storage, and only hosting the VMs' main system on the Dell's SSDs (so each VM gets 32GB; the main storage is on the Synology).\n  \n\n\n\n\n\n    Direct 10GbE connection to the Dell R750 for high-speed access. (Block Access)\n  \n\n\n\n\n\n\nPotential Solutions:\n\n\n\n\n\n\n\n\nBare Metal TrueNAS Scale:\n Install TrueNAS directly on the server for maximum performance, but lose the flexibility of Proxmox.\n  \n\n\n\n\n\n\nProxmox with ZFS and Containers/VMs:\n Use Proxmox with ZFS for storage and handle additional services (SMB, permissions, Nextcloud) via LXC containers or VMs.\n  \n\n\n\n\n\n\nHybrid Approach:\n Keep Proxmox with ZFS pools, and run a VM for TrueNAS Scale to manage SMB and NFS, with other services running in containers/VMs on Proxmox.\n  \n\n\n\n\n\n\nLeveraging Synology NAS:\n\n\n\n\n\n\n\n    Use the Synology as the main storage system with 10GbE connectivity to the Dell R750.\n  \n\n\n\n\n\n    Utilize the NVMe SSD cache on the Synology for improved performance.\n  \n\n\n\n\n\n    Keep the SSDs and SAS drives in the Dell R750 for caching and high-speed storage needs.\n  \n\n\n\n\n\n\n\n\n\n    I’d love to hear your thoughts on these approaches or any other suggestions you might have. What would be the best way to balance performance, flexibility, and power efficiency in this setup?\n  \n\n    Thanks in advance for your help! I hope you all have a good weekend. Best wishes, keep hoarding.\n  \n\n\n\n\n\n    a VeganSalat"},
{"Title": "Finding good deals for HDDs and SSDs?", "Author": "u/Neurrone", "Content": "I currently have 4 x 4TB Seagate Ironwolfs and am looking to expand.\n  \n\n\n\n\n\n    Are there price trackers that I could use to get a sense of what a good deal would be, in terms of price per TB? Something that can send alerts when prices drop below a certain level would be an added bonus\n  \n\n\n\n\n\n    How safe is it to use used drives? They are half the price of new ones, but might fail more quickly."},
{"Title": "Optical Archiving", "Author": "Unknown author", "Content": "Just learned of the new DM for Archiving Blu-ray standard that should last 100 years. This is the player/burner Pioneer BDR-WX01DM JIS X6257 Compliant DM for Archive. Y'all may know this, but just decided to share, share your usage and impresions please."},
{"Title": "New CDs can hold 1+ petabytes of storage", "Author": "u/GiantJupiter45", "Content": "No content"},
{"Title": "There Is No Good Reason To Just Let Unsupported Video Games Die", "Author": "u/AbolishDisney", "Content": "No content"},
{"Title": "Finally... after seven years, a 6TB 2.5-inch external hard drive has made it to market.", "Author": "u/Torley_", "Content": "No content"},
{"Title": "The ArchiveTeam has a \"cost shameboard\" of the top users who are incurring the highest costs for the Internet Archive", "Author": "u/BananaBus43", "Content": "No content"},
{"Title": "IBM LTO4 TS2340 Error Code 5 - drive doesn't work", "Author": "u/awesomefreeman", "Content": "I bought drive via mail without checking it 😫. When turned on, it shows error code 5, which corresponds to a hardware problem. I completely disassembled the drive, but could not find the reason. The mechanics inside are good, cassettes can be inserted and removed.\n  \n\n    The diagnostic program ITDT showed the same error. I don’t know what to do, has anyone encountered a similar problem?\n  \nhttps://preview.redd.it/ibm-lto4-ts2340-error-code-5-drive-doesnt-work-v0-knqoyrl5l61d1.jpg\nhttps://preview.redd.it/ibm-lto4-ts2340-error-code-5-drive-doesnt-work-v0-zexu05b9l61d1.jpg\n\n    UPDATE: Entring and exiting maintence mode helped. But after insert cartridge  I've got the same error appears\n  \nhttps://preview.redd.it/ibm-lto4-ts2340-error-code-5-drive-doesnt-work-v0-a6q0sqcyp61d1.png"},
{"Title": "Downloading Fullsize Pastperfectonline Images?", "Author": "u/Acrobatic_Owl_4101", "Content": "Hello, in the past I've seen various posts and websites on how to get fullsize images from behind the times museums that post VGA quality images that are mere thumbnails in today's modern screens.  I have not seen tips for getting images from Past Perfect Online sites though.  Does anyone know how I'd get a bigger image than the small \"zoom in\" I get clicking the image?"},
{"Title": "Reusing drives from a WD EX2 Ultra", "Author": "u/Physical_Taste_4487", "Content": "Hi. I currently have a WD My Cloud EX2 Ultra and want to move on from it. It has 2x16TB setup as JBOD. (Full of data) How do I go about using drives in a new enclosure? Is there any way of doing this whilst preserving the data? Or will I have to transfer the data to something else first? I don’t mind doing this if I have to as long as I can use the drives in some other NAS/Enclosure once it’s all done.\n  \n\n    Any advice much appreciated."},
{"Title": "Is it possible that some day in the distant future, we will have an archive with all the data that was ever uploaded to the internet (also deleted data) that is accessible by anyone?", "Author": "u/NeroD_175", "Content": "I just thought about how cool it would be if something like that existed. Just imagining being able to download whatever I'm thinking about instantly just by typing in a few keywords to find it, regardless if it was deleted or not.. Sure there would probably be some issues with that, like privacy concerns etc. but to me, data is memory and memories are by far the most valuable thing we have as human beings. As a datahoarder who has lost precious data/memories before, this is my ultimate fantasy."},
{"Title": "Sort photos into folders based on EXIFs Description", "Author": "u/SympatheticLion", "Content": "Hey Fellow Hoarders,\n  \n\n    I'm looking for an open source solution to sort 1000's of mid journey photos to group similar photos and put them into folders automagically based on metadata/EXIF description. The description is quite detailed and it would be ideal if it can be used to also rename the file too.\n  \n\n    I've been looking into photoprism, digikam, darktable and can't figure out which one will work for this purpose. Photoprism so far can recognize faces and group them, but not add it into a folder based on exif description.\n  \n\n    Anyone know of a solution that would work? Thanks in advance!!"},
{"Title": "Yes or no for NAS?", "Author": "u/gunzaj", "Content": "No content"},
{"Title": "Extreme Picture Finder Saving video in multiple files", "Author": "u/ReyArthurLXIX", "Content": "Extreme Picture Finder is saving videos in multiple files, an index followed by several videos named video0, video1 and so on, how can i save it all as 1 video?"},
{"Title": "Dell R720XD - Backplane HBA Card Query", "Author": "u/willdab34st", "Content": "Hi, I was going to purchase a second controller for my R720XD, front disk container and backplane is a perc mini mono setup. However I remembered I pulled a few SAS HBA's out of it when I got it. They are Dell g164p 6GB/S HBA cards, apparently they are the same board as the more common H200E just with no internal headers, just external.\n  \n\n    I'm thinking I can use these instead of purchasing another card, but unsure how I would hook this up, as far as I can deduce I'll need to plug in a backplane somewhere in the rear for the SATA board and I'll have to route the cables from outside the chassis. The g164p cards have a type of sfp connector, assuming this is standard for connecting backplanes etc and buying a backplane off of eBay for R720XD will work with this?\n  \n\n    Related question, I would assume it's not possible to split the front drive bays so some are served with different controllers? If not then I'd have to mount new drives for the HBA controller in the rear somewhere, there does look established slots there already, 2.5\"."},
{"Title": "Advice on building a DAS", "Author": "u/the_mcm", "Content": "I’m about to head off to college and want to have a single place for storage with some redundancy. I know it’d be best to have some sort of offisite backup, but I don’t really have the money for that right now judging by the amount of files I need to store.\n  \n\n    I’d mostly be storing a lot of video projects (abt 6tb+ currently), hoping to also do some editing off of the DAS, along with playing and storing a decent bit of dvd/blu ray rips (abt 2+ tb and growing). I’d also probably have a decent but more of other miscellaneous music, videos, etc to store.\n  \n\n    Doing some limited research I saw good things about the OWC Mercury quad paired with OWC’s SoftRaid to do a RAID5 set up.\n  \n\n    Pricing things out, it seems like I could get 4 WD Red 8tb HDDs along with the OWC enclosure for right around my budget of about $1k, and would give me 24tb usable space.\n  \n\n    Does this seem like a reasonable set up for my needs, and would RAID5 be good if I’ll be writing and reading from the DAS often? Thanks."},
{"Title": "Will storing large files in a NAS wear out hard drives faster?", "Author": "u/Hostile_18", "Content": "Hi all. New to all this. Got my media NAS and am trying to decide between good x254 encodes at around 1.2-2.2gb or full 1080p remux episodes at around 7-12gb. My question is will the quality difference be worth it, and also will it significantly reduce the hard drives lifespan? I've got 6x 20tb Exos drives that have a work load of 550tb a year for 5 years, I guess half that if you run parity once a month. All this and that's not even counting huge 4k remux files. The X-files 1080p remux from the Blu-Ray discs is like 2tb alone.\n  \n\n    What's anyone elses experience hosting large media files? Have the hard drives held up over time? I have about 6 clients outside the local network, if that makes a significant difference."},
{"Title": "Good software for magazine scanning?", "Author": "u/vier86", "Content": "I am about to embark on a journey to scan and upload a large cache of magazines I have inherited onto \nhttps://archive.org/\n.\n  \n\n    The plan is to debind each magazine and scan them on a flatbed Canon CanoScan 9000f.\n  \n\n\n\n\n\n    What software would be best to use for this?\n  \n\n\n\n\n\n    Should I convert each to a PDF, TIFF, JPEG?\n  \n\n\n\n\n\n    Anything else I should know?"},
{"Title": "Data consolidation – home set-up - Mac and DAS", "Author": "u/intastellaburst", "Content": "I have searched through previous posts but they were all either really old or didn’t address this kind of setup.\n  \n\n    I want to consolidate decades of data from different sources and put it all together on a DAS (or similar) that can plug into a 2018 MacBook Pro (with USB-C).\n  \n\n    I’m going with DAS-to-computer setup because I intend to use Backblaze to keep the whole thing backed up to the cloud for low-cost (directly connected drives are included in their unlimited backup and only need to be plugged in once a year to stay backed up).\n  \n\n    Ideally, I’d like around 10 TB, but I’m unsure how to get there.\n  \n\n    I was hoping to use SSD drives or M.2 in some kind of enclosure but they may be too expensive. It sounds like software RAID is better, but I’m unsure how to get that going on a Mac, and I’m not sure which enclosure/drives to get.\n  \n\n    Oh yes, and the main consideration is cost - I need to do this on the cheap, even if it's a little improvised or rough around the edges.\n  \n\n    I don’t need screaming speed, but I do want to move and access many photos and videos without having to wait.\n  \n\n    If 2 or 3 large and slow SATA drives on a particular RAID setup gets me good enough performance through USB-3 or Thunderbolt, that’s also fine.\n  \n\n    There are so many options, and I’m a little bamboozled.\n  \n\n    So in summary:\n  \n\n\n\n\n\n    looking for hardware and Mac RAID suggestions\n  \n\n\n\n\n\n    DAS connected to a Mac with USB-C\n  \n\n\n\n\n\n    Around 10 TB\n  \n\n\n\n\n\n    Fast transfer, but not too expensive\n  \n\n\n\n\n\n    Happy to build and find parts\n  \n\n\n\n\n\n    Any thoughts?"},
{"Title": "efficient and visually pleasing way to combine all the images I downloaded from a Pinterest board?", "Author": "u/Late_Repair_9899", "Content": "Firstly, I have found my home.\n  \n\n    Secondly, I save hundreds of images and MP4s monthly. I like to see them digitally (and often print them when I can) because they inspire my art and life and imagination (but also who am I kidding it's a part of the hoarding cycle).\n  \n\n    I have been using the straight-up Photoshop Contact batch process, but they're always the same size and you can't include the MP4s. I also don't want to spend time on ANY of it (other than satisfying printing and cutting and looking)... so canva templates are OUT.\n  \n\n    Anything out there that would automate hundreds of images at once?"},
{"Title": "Stablebit Drivepool error", "Author": "u/Earbuduserr", "Content": "Anyone know what to do to get rid of this error?, Ive tried pressing duplicate now and automatically\n  \nhttps://preview.redd.it/stablebit-drivepool-error-v0-auic8rk4s01d1.png"},
{"Title": "Need help Kasa download 30 days for possible neglect at managed care home resulting in death", "Author": "u/Yurt_lady", "Content": "I have a problem. I had a Kasa in my husband’s room at a memory care facility. I have Kasa care and an SD card.\n  \n\n    My husband passed away on Sunday. The Kasa camera is great but the software is crap. I need to download 30 days of videos and it seems that I have to do it one at a time. I can’t do that.\n  \n\n    Is there a way to write a batch file or something to download them? Can I hire someone from this group to download the videos? This is a nightmare."},
{"Title": "DPI and archiving family photo prints", "Author": "u/Hoagiewave", "Content": "I need help picking out hardware. I'm going to be scanning some prints, I don't need to worry about film. I come from a normal family of illiterates that throw the negatives out when the prints are made. I'm not that close with my family and I'm not going to be inheriting most of these pictures so it is likely I wont easily ever have a chance to see these pictures again when my grandmother is gone.\n  \n\n    So while I have the chance I want to do this right and max out the quality of the scans I'm going to get. I've tried to figure this out by myself but it would be nice to get some other opinions. It seems like the Epson v600 might be good enough that it can capture more than enough data than prints can give. The v850 seems have slightly deeper resolution for shades of dark. A decent amount of the pictures will be black and white.\n  \n\n    Are there any other options I'm missing? It seems a bit strange that a 15 year old scanner would be the best option on the market. Does the 850 produce tangibly better results? Because of the context I want to do this as best I can now. Lastly what resolution should I aim for to have master scans? Thank you"},
{"Title": "copy utility with check boxes or exclusions", "Author": "u/jedihermit", "Content": "I'm looking for something that can select a subset of my rom folder and optionally exclude subfolders from each. For example I want to pick 5-10 folders but omit the video folders in each to save space on the target. These are typically linux systems but I have access to the folders in windows too."},
{"Title": "WD Wireless Pro NAS functionality not working, but usb is working?", "Author": "u/requirehelpwithstuff", "Content": "I searched around and saw some similar reddit posts here so I'm hoping this is my best shot to post it here as well.\n  \n\n    I have an old wireless pro that I havent used in a long time, so I swapped the hard drive in it and the wireless functionality seems like it has disappeared. The blinking leds indicates that the device boots and goes solid meaning it's broadcasting wifi, but I don't see anything to connect to. It works when plugged via usb with no issues.\n  \n\n    I tried 'updating' the firmware and resetting it, and i \nthink\n it went thru, but still nothing. The last time I used it, I remember doing something similar and got to a point where i was able to see the wifi but never connected to it (didnt know the password was SN as a youtube guide said it was the ID of the hdd).\n  \n\n    Old hardware and don't really expect a hard answer, but any ideas are welcomed."},
{"Title": "How do I format a drive with 512e/4kn (22TB Seagate Exos X22)", "Author": "u/lintstah1337", "Content": "I am upgrading my old HDD to a bigger capacity.\n  \n\n    I am trying to clone an old HDD (18TB Seagate Exos X18) and would like to only use 1 partition.\n  \n\n    The cloning software has an option for \"4k alightnment\".\n  \n\n    Should I use 4k alignment?"},
{"Title": "Merging 35.2K Text files into one 604 GB monstrous text file.", "Author": "u/Latter-Ambassador-65", "Content": "I have no idea how I'm going to do this please comment.\n  \n\n    note : the drive im doing this on only has 117gb left on it\n  \n\n    avg file size 15mb - 10gb\n  \n\n    found a fix with sqlitebrowser ( doesn't merge into 1 text file but it works if you're just trying to search for something in the files )\n  \n\n\nhttps://sqlitebrowser.org/"},
{"Title": "External 2TB SSD Kingston vs 4TB HDD Toshiba Canvio", "Author": "u/droom2", "Content": "Both are at a discount, SSD $150usd and HDD $125usd. I'm on a budget, but I need to replace my old 1TB HDD external disk which started to fail after 10 years. I use it for 3Dmax library and backups"},
{"Title": "Compressing old avi files", "Author": "u/Pfftwhy", "Content": "Hey guys, as stated in the title I want to compress a lot of old avi files to a more space efficient format.\n  \n\n    I would like to keep as much quality as possible since the files itself are shot around 2005, my main concern is if i further reduce the quality the videos will be barely watchable.\n  \n\n    What would be the best way of doing this?\n  \n\n    EDIT\nRephrased to make my question clearer\n  \n\n    EDIT 2:\nVideo is interlaced & uses DV\n  \n\n    EDIT 3:\n  \n\n    ran mediainfo on one of the files as an example:\n  \nFormat                                   : AVI\nFormat/Info                              : Audio Video Interleave\nCommercial name                          : DVCAM\nFormat profile                           : OpenDML\nFormat settings                          : WaveFormatEx\nFile size                                : 19.1 GiB\nDuration                                 : 1 h 31 min\nOverall bit rate mode                    : Constant\nOverall bit rate                         : 29.8 Mb/s\nFrame rate                               : 25.000 FPS\nRecorded date                            : 2004-05-05 12:45:54.000\nIsTruncated                              : Yes\n\nVideo\nID                                       : 0\nFormat                                   : DV\nCommercial name                          : DVCAM\nCodec ID                                 : dvsd\nCodec ID/Hint                            : Sony\nDuration                                 : 1 h 31 min\nBit rate mode                            : Constant\nBit rate                                 : 24.4 Mb/s\nWidth                                    : 720 pixels\nHeight                                   : 576 pixels\nDisplay aspect ratio                     : 4:3\nFrame rate mode                          : Constant\nFrame rate                               : 25.000 FPS\nStandard                                 : PAL\nColor space                              : YUV\nChroma subsampling                       : 4:2:0\nBit depth                                : 8 bits\nScan type                                : Interlaced\nScan order                               : Bottom Field First\nCompression mode                         : Lossy\nBits/(Pixel*Frame)                       : 2.357\nTime code of first frame                 : 00:00:18:20\nTime code source                         : Subcode time code\nStream size                              : 18.4 GiB (97%)\nEncoding settings                        : ae mode=full automatic / wb mode=automatic / white balance= / fcm=manual focus\n\nAudio\nID                                       : 1\nFormat                                   : PCM\nFormat settings                          : Little / Signed\nCodec ID                                 : 1\nDuration                                 : 1 h 31 min\nBit rate mode                            : Constant\nBit rate                                 : 1 024 kb/s\nChannel(s)                               : 2 channels\nSampling rate                            : 32.0 kHz\nBit depth                                : 16 bits\nStream size                              : 670 MiB (3%)\nAlignment                                : Aligned on interleaves\nInterleave, duration                     : 240  ms (6.00 video frames)"},
{"Title": "How to decrypt video files?", "Author": "u/VibWhore", "Content": "So there's this educational institution which has provided me with a number of video lectures in a special format that can only be accessed throught an application called \"Player\" by HSC-PK available on Microsoft Store.\n  \n\n    I have those videos downloaded on my device but they are in a special format, which can only be accessed through the \"Player\" by entering the credentials in it.\n  \n\n    Is there anyway that I can figure out to convert those files into a normal .MP4 format through which I can open it and use it normally?"},
{"Title": "Is this a relabeled Ultrastar HC570?", "Author": "u/slash8793", "Content": "I bought what was supposed to be a 22TB Ultrastar HC570 from an Ebay seller. What I received appears to be from a shucked external drive. Before I return it, can anyone tell me if it's just a relabeled HC570?\n  \n\n    The model number is WD220EDGZ, and underneath it says \"SATA 6Gb/s IU HA570\". No mention of the Ultrastar name anywhere on the label. That's fine if it's the exact same thing, but I'm not sure it is. Did I get a lower quality drive? Thanks."},
{"Title": "seagate exos refurbished read speed hitting 130MBps", "Author": "u/honelnik", "Content": "I just got a refurbished exos ST16000NM000D (I can't find any datasheet, which quite bothers me) for my elitedesk 800 G4 and I am running the crypto-test from \nhttps://wiki.archlinux.org/title/Badblocks#Alternatives\n .\n  \n\n    After the intial 280-ish MBps write speeds (going down somewhere to 200), I am currently running the compare step and again, from 270-280 MBps in the begininng I am hitting 130 MBps speeds after some 13hrs of running:\n  \n\n\ntps kB_read/s kB_wrtn/s kB_dscd/s kB_read kB_wrtn kB_dscd Device\n\n\n\n\n1079.00 134.9M 0.0k 0.0k 134.9M 0.0k 0.0k sdd\n\n\n\n    first time I am building a server with such a large drive so I do not have anything to compare it with.\n  \n\n    Does it get this slow over sustained read and at the end of a drive?"},
{"Title": "Has anyone noticed a sigificant decrease in USB drive reliability? many DOA's..", "Author": "u/appletechgeek", "Content": "Has anyone noticed a sigificant increase in problems with USB drives as of late?\n  \n\n    i know USB drives are never reliable to begin with, but it's become so bad that i'd rather use a USB to sata/m.2 adapter than consider usb drives to make even small transfers between machines,\n  \n\n    all usb drive's i buy new either come DOA, or die within a extremely short time span,\n  \n\n    i thought it was my machine at first, but at this point it's been happening to 5+ machines consistently\n  \n\n    mac's and pc's. whatever, the drives would either not get detected, or fail format's and get stuck in a raw state, or pretend they are being constantly accessed while they are not,\n  \n\n    this happens to sandisk and philips brand usb drives, both usb 2.0 and 3.0 drive's. both small 16 gig and bigger 64/128 gig drive's,\n  \n\n    anyone been experiecing the same?"},
{"Title": "Need some help with mergerfs + sonarr - keep a tv show on one drive?", "Author": "u/fillilutten", "Content": "MergerFS is set to default existing path - most free space.\n  \n\n    I have 3 disks in this mergerfs pool where one disk is full. I ran into a problem when sonarr tried to import a new season to a show that is already on the full disk. I would like to keep a whole show on the same drive but I of course don't care to have different shows on different drives. I solved it by manually moving the whole show to the /tv folder on a drive with free space. But are there any solution to automate this?\n  \n\n\n\n    Thanks!"},
{"Title": "Alternatives to Real-Debrid?", "Author": "u/Few_Landscape_573", "Content": "Do you guys know any good ones that don’t log users info?\n  \n\n    I’m worried about security data breaches about my personal info."},
{"Title": "How do I store family photos?", "Author": "u/Wonder_Pretty", "Content": "First off I know nothing about computers, hard drives, cloud storage etc. But, I need help to understand how to store my family photos long term. My aunt passed away last Friday. I'm at her visitation right now. My sisters and my other aunt put together a few photo boards of my aunt. And seeing all of the photos reminds me that I seriously need to learn how to protect my family photos, videos, family history, my own personal files, etc. I know that I need to make multiple copies and use multiple ways of store things,  hard drives, cloud storage, external hard drives. Apart from that I know absolutely nothing about computers, I don't even have a computer. Currently I have things stored on a few thumb drives and I know I shouldn't rely on those for storage. Please help.\n  \n\n    Update: I want to thank everyone for their advice and suggestions. I'm sorry that I haven't replied to everyone's comments. Life is bit hectic at the moment. When I get some free time I'll be able to read and process everyone's comments. Again thank you all for your help I really appreciate it right now."},
{"Title": "Cheap external ssds > 4TB?", "Author": "u/newtoaster", "Content": "So we are selling the house and moving into an RV to travel full time. My PLEX server is a mac mini that currently has a 4 drive external enclosure that runs crazy hot and has a fan that sounds like a leaf blower. Power is at a premium off grid, so I want to replace it with something solid state. I need more than 4TB (6 would do). Whats my cheapest option at the moment for something thats not trash?"},
{"Title": "What's a reasonbale size for an external HDD?", "Author": "u/szetadom", "Content": "Hello!\n  \n\n    I'm planning on buying an external HDD to make a backup of my phone, photos, important documents, text files, etc. I don't know how big of an HDD to buy? I think I'll need about 2TBs of storage in the foreseeable future so I was thinking about getting a 4TB drive and call it a day. My question is that is it worth for me to buy a disk with more storage capacity like 8 TB or even larger?"},
{"Title": "What is the most data you have used in a month?", "Author": "u/Embire", "Content": "I am the CEO of one of Africa's largest ISP's and last month we clocked our highest data user ever. 98,1TB.  Keep in mind, we only sell 4G and 5G wireless connectivity.  I know that for a Fibre company, this is pretty normal.  \nWhat is the most data you have ever used on your Mobile plan per month?"},
{"Title": "Solution To Growing Collection Of WD Elements External Drives?", "Author": "u/It_Is_JAMES", "Content": "With limited desk space and power outlets, I currently have 4 WD Elements external drives stacked on top of each other, ranging from 10-18TB. Wanting to get a 5th, but realizing that this probably isn't an ideal solution for heat or longevity of the drives.\n  \n\n    Currently, everything is going into a powered USB hub and connecting to my laptop. Was wondering what solutions are available that are worth looking into, that offer the best value for the price. NAS? A USB hard drive bay? Or, would buying a couple extra externals really not be a problem? I'll probably only buy 2 more drives before building a desktop that could hold a lot of the drives internally anyway."},
{"Title": "I can't mount this partition, I might have encrypted it via VeraCrypt but it's not taking my usual passwords. Am I screwed?", "Author": "u/RandomADHDaddy", "Content": "No content"},
{"Title": "Open source datasharing service", "Author": "Unknown author", "Content": "Hey guys! I have noticed that there is not much in the realm of open source datasharing services, so I created a Django REST / React app that allows for upload, download, reviewing, etc, of files. Not sure if would be useful to people. Also, please feel free add features. This is meant to be an open source project that allows research labs / people to share and review datasets without needing to pay for any online subscriptions. \nhttps://github.com/lxaw/DataDock"},
{"Title": "I just uploaded to The Internet Archive the most complete collection of games and software by Wiering Software.", "Author": "u/Impossible_Salary_38", "Content": "I just uploaded to The Internet Archive the most complete collection of games and software of Wiering Software company who made classic well known games for MS-DOS and ported them to other platforms like Android, Flash and Windows. The collection contains all the different versions of each game for each platform, plus it has the registered (complete) version of the games Super Angelo and Super Worms for DOS and a modded full version of Charlie the Duck for android.\n  \n\n    Since most of the games are shareware (demo), I think most people like me could only play the demo version of Super Angelo, limited to 3 levels only, since the shareware version is the easiest to find. The complete version has way more levels and the final ending. The Flash version of Super Angelo is also complete. Some of the games can't be be purchased anymore and remain in their demo version like Olaf & Elmar In the Castle of Nabokos.\n  \n\n    Some of the games include their user's manual, level maps (Super Worms) or source code (Mario & Luigi and Mario!!!). There are also two tools included, one for editing tiles, sprites and maps and another just for navigating folders with icons.\n  \n\n\nComplete collection of Wiering Software games and software"},
{"Title": "So i can copy EVERYTHING on my D:/ drive into my backup storage, except for these 2 folders that gives the error (yes, they're portable p*rn games). Is my 2 years old evo 870 failing? even though the games still works just fine.", "Author": "u/Arctic-Warfare9000", "Content": "https://preview.redd.it/so-i-can-copy-everything-on-my-d-drive-into-my-backup-v0-zg8xhn1oct0d1.png\nhttps://preview.redd.it/so-i-can-copy-everything-on-my-d-drive-into-my-backup-v0-utizoqbbbt0d1.png\n\n    I just can't do anything with the files (copy, move, del) except for the fact that I can still open anything inside like folders, text files, and even play both games with no issues.\n  \n\n    I'm currently in the process of backing up my personal files because i'm planning to assemble my newly bought pc parts and I want to do a fresh install on it. Planning to wipe the evo 870 ssd and do a fresh install on it and use it as my main storage.\n  \n\n    Both folders amount to 250gb in size. Is my SSD failing? how do i check?"},
{"Title": "Re-formatting SMR HDD as NTFS, or just keeping as exFAT?", "Author": "u/Caesar_35", "Content": "So, all of my previous drives have been your run-of-the-mill 2.5\" portables, all pre-formatted NTFS. I only use them for backup purposes, so phone pictures, game screenshots, some files, etc, which I manually copy across to two drives (muh redundancy). Lots of small files basically. My dutiful 2TB drive's recently gotten the dreaded red line of \"your space's running out\", and I saw a good deal on an 8TB 3.5\" external so jumped on it. However, it comes pre-formatted exFAT, which I'm aware isn't as well regarded as NTFS. I've only ever seen them on flashdrives myself. It's also an SMR drive (spooky, I know), so I'm not sure if NTFS or exFAT makes a difference there.\n  \n\n    Basically my question is, is it really worth while re-formatting to NTFS, or can I just keep it exFAT? This is going to be the backup drive of my backup drive, but I'd still rather it not get corrupted or have any other issues down the line. I'd also rather not unnecessarily spend time re-formatting it if there's not much reason to. I mean, I figure it \nshould\n be fine since that's how it came out the box, but better safe than sorry. It's one of those newer-era Seagate Expansions with the diagonal lines, if that makes any difference.\n  \n\n    And lastly, if I do go the route of re-formatting, would a quick format be fine given it's never been used for anything? And any guidelines for allocation unit size, being an SMR drive (is smaller/larger size better)?\n  \n\n    Thanks all!"},
{"Title": "Stablebit Drivepool error", "Author": "u/Earbuduserr", "Content": "Anyone know what to do to get rid of this error?, Ive tried pressing duplicate now and automatically\n  \nhttps://preview.redd.it/stablebit-drivepool-error-v0-auic8rk4s01d1.png"},
{"Title": "Need help Kasa download 30 days for possible neglect at managed care home resulting in death", "Author": "u/Yurt_lady", "Content": "I have a problem. I had a Kasa in my husband’s room at a memory care facility. I have Kasa care and an SD card.\n  \n\n    My husband passed away on Sunday. The Kasa camera is great but the software is crap. I need to download 30 days of videos and it seems that I have to do it one at a time. I can’t do that.\n  \n\n    Is there a way to write a batch file or something to download them? Can I hire someone from this group to download the videos? This is a nightmare."},
{"Title": "DPI and archiving family photo prints", "Author": "u/Hoagiewave", "Content": "I need help picking out hardware. I'm going to be scanning some prints, I don't need to worry about film. I come from a normal family of illiterates that throw the negatives out when the prints are made. I'm not that close with my family and I'm not going to be inheriting most of these pictures so it is likely I wont easily ever have a chance to see these pictures again when my grandmother is gone.\n  \n\n    So while I have the chance I want to do this right and max out the quality of the scans I'm going to get. I've tried to figure this out by myself but it would be nice to get some other opinions. It seems like the Epson v600 might be good enough that it can capture more than enough data than prints can give. The v850 seems have slightly deeper resolution for shades of dark. A decent amount of the pictures will be black and white.\n  \n\n    Are there any other options I'm missing? It seems a bit strange that a 15 year old scanner would be the best option on the market. Does the 850 produce tangibly better results? Because of the context I want to do this as best I can now. Lastly what resolution should I aim for to have master scans? Thank you"},
{"Title": "copy utility with check boxes or exclusions", "Author": "u/jedihermit", "Content": "I'm looking for something that can select a subset of my rom folder and optionally exclude subfolders from each. For example I want to pick 5-10 folders but omit the video folders in each to save space on the target. These are typically linux systems but I have access to the folders in windows too."},
{"Title": "WD Wireless Pro NAS functionality not working, but usb is working?", "Author": "u/requirehelpwithstuff", "Content": "I searched around and saw some similar reddit posts here so I'm hoping this is my best shot to post it here as well.\n  \n\n    I have an old wireless pro that I havent used in a long time, so I swapped the hard drive in it and the wireless functionality seems like it has disappeared. The blinking leds indicates that the device boots and goes solid meaning it's broadcasting wifi, but I don't see anything to connect to. It works when plugged via usb with no issues.\n  \n\n    I tried 'updating' the firmware and resetting it, and i \nthink\n it went thru, but still nothing. The last time I used it, I remember doing something similar and got to a point where i was able to see the wifi but never connected to it (didnt know the password was SN as a youtube guide said it was the ID of the hdd).\n  \n\n    Old hardware and don't really expect a hard answer, but any ideas are welcomed."},
{"Title": "How do I format a drive with 512e/4kn (22TB Seagate Exos X22)", "Author": "u/lintstah1337", "Content": "I am upgrading my old HDD to a bigger capacity.\n  \n\n    I am trying to clone an old HDD (18TB Seagate Exos X18) and would like to only use 1 partition.\n  \n\n    The cloning software has an option for \"4k alightnment\".\n  \n\n    Should I use 4k alignment?"},
{"Title": "Merging 35.2K Text files into one 604 GB monstrous text file.", "Author": "u/Latter-Ambassador-65", "Content": "I have no idea how I'm going to do this please comment.\n  \n\n    note : the drive im doing this on only has 117gb left on it\n  \n\n    avg file size 15mb - 10gb\n  \n\n    found a fix with sqlitebrowser ( doesn't merge into 1 text file but it works if you're just trying to search for something in the files )\n  \n\n\nhttps://sqlitebrowser.org/"},
{"Title": "External 2TB SSD Kingston vs 4TB HDD Toshiba Canvio", "Author": "u/droom2", "Content": "Both are at a discount, SSD $150usd and HDD $125usd. I'm on a budget, but I need to replace my old 1TB HDD external disk which started to fail after 10 years. I use it for 3Dmax library and backups"},
{"Title": "Compressing old avi files", "Author": "u/Pfftwhy", "Content": "Hey guys, as stated in the title I want to compress a lot of old avi files to a more space efficient format.\n  \n\n    I would like to keep as much quality as possible since the files itself are shot around 2005, my main concern is if i further reduce the quality the videos will be barely watchable.\n  \n\n    What would be the best way of doing this?\n  \n\n    EDIT\nRephrased to make my question clearer\n  \n\n    EDIT 2:\nVideo is interlaced & uses DV\n  \n\n    EDIT 3:\n  \n\n    ran mediainfo on one of the files as an example:\n  \nFormat                                   : AVI\nFormat/Info                              : Audio Video Interleave\nCommercial name                          : DVCAM\nFormat profile                           : OpenDML\nFormat settings                          : WaveFormatEx\nFile size                                : 19.1 GiB\nDuration                                 : 1 h 31 min\nOverall bit rate mode                    : Constant\nOverall bit rate                         : 29.8 Mb/s\nFrame rate                               : 25.000 FPS\nRecorded date                            : 2004-05-05 12:45:54.000\nIsTruncated                              : Yes\n\nVideo\nID                                       : 0\nFormat                                   : DV\nCommercial name                          : DVCAM\nCodec ID                                 : dvsd\nCodec ID/Hint                            : Sony\nDuration                                 : 1 h 31 min\nBit rate mode                            : Constant\nBit rate                                 : 24.4 Mb/s\nWidth                                    : 720 pixels\nHeight                                   : 576 pixels\nDisplay aspect ratio                     : 4:3\nFrame rate mode                          : Constant\nFrame rate                               : 25.000 FPS\nStandard                                 : PAL\nColor space                              : YUV\nChroma subsampling                       : 4:2:0\nBit depth                                : 8 bits\nScan type                                : Interlaced\nScan order                               : Bottom Field First\nCompression mode                         : Lossy\nBits/(Pixel*Frame)                       : 2.357\nTime code of first frame                 : 00:00:18:20\nTime code source                         : Subcode time code\nStream size                              : 18.4 GiB (97%)\nEncoding settings                        : ae mode=full automatic / wb mode=automatic / white balance= / fcm=manual focus\n\nAudio\nID                                       : 1\nFormat                                   : PCM\nFormat settings                          : Little / Signed\nCodec ID                                 : 1\nDuration                                 : 1 h 31 min\nBit rate mode                            : Constant\nBit rate                                 : 1 024 kb/s\nChannel(s)                               : 2 channels\nSampling rate                            : 32.0 kHz\nBit depth                                : 16 bits\nStream size                              : 670 MiB (3%)\nAlignment                                : Aligned on interleaves\nInterleave, duration                     : 240  ms (6.00 video frames)"},
{"Title": "How to decrypt video files?", "Author": "u/VibWhore", "Content": "So there's this educational institution which has provided me with a number of video lectures in a special format that can only be accessed throught an application called \"Player\" by HSC-PK available on Microsoft Store.\n  \n\n    I have those videos downloaded on my device but they are in a special format, which can only be accessed through the \"Player\" by entering the credentials in it.\n  \n\n    Is there anyway that I can figure out to convert those files into a normal .MP4 format through which I can open it and use it normally?"},
{"Title": "Is this a relabeled Ultrastar HC570?", "Author": "u/slash8793", "Content": "I bought what was supposed to be a 22TB Ultrastar HC570 from an Ebay seller. What I received appears to be from a shucked external drive. Before I return it, can anyone tell me if it's just a relabeled HC570?\n  \n\n    The model number is WD220EDGZ, and underneath it says \"SATA 6Gb/s IU HA570\". No mention of the Ultrastar name anywhere on the label. That's fine if it's the exact same thing, but I'm not sure it is. Did I get a lower quality drive? Thanks."},
{"Title": "seagate exos refurbished read speed hitting 130MBps", "Author": "u/honelnik", "Content": "I just got a refurbished exos ST16000NM000D (I can't find any datasheet, which quite bothers me) for my elitedesk 800 G4 and I am running the crypto-test from \nhttps://wiki.archlinux.org/title/Badblocks#Alternatives\n .\n  \n\n    After the intial 280-ish MBps write speeds (going down somewhere to 200), I am currently running the compare step and again, from 270-280 MBps in the begininng I am hitting 130 MBps speeds after some 13hrs of running:\n  \n\n\ntps kB_read/s kB_wrtn/s kB_dscd/s kB_read kB_wrtn kB_dscd Device\n\n\n\n\n1079.00 134.9M 0.0k 0.0k 134.9M 0.0k 0.0k sdd\n\n\n\n    first time I am building a server with such a large drive so I do not have anything to compare it with.\n  \n\n    Does it get this slow over sustained read and at the end of a drive?"},
{"Title": "Has anyone noticed a sigificant decrease in USB drive reliability? many DOA's..", "Author": "u/appletechgeek", "Content": "Has anyone noticed a sigificant increase in problems with USB drives as of late?\n  \n\n    i know USB drives are never reliable to begin with, but it's become so bad that i'd rather use a USB to sata/m.2 adapter than consider usb drives to make even small transfers between machines,\n  \n\n    all usb drive's i buy new either come DOA, or die within a extremely short time span,\n  \n\n    i thought it was my machine at first, but at this point it's been happening to 5+ machines consistently\n  \n\n    mac's and pc's. whatever, the drives would either not get detected, or fail format's and get stuck in a raw state, or pretend they are being constantly accessed while they are not,\n  \n\n    this happens to sandisk and philips brand usb drives, both usb 2.0 and 3.0 drive's. both small 16 gig and bigger 64/128 gig drive's,\n  \n\n    anyone been experiecing the same?"},
{"Title": "Need some help with mergerfs + sonarr - keep a tv show on one drive?", "Author": "u/fillilutten", "Content": "MergerFS is set to default existing path - most free space.\n  \n\n    I have 3 disks in this mergerfs pool where one disk is full. I ran into a problem when sonarr tried to import a new season to a show that is already on the full disk. I would like to keep a whole show on the same drive but I of course don't care to have different shows on different drives. I solved it by manually moving the whole show to the /tv folder on a drive with free space. But are there any solution to automate this?\n  \n\n\n\n    Thanks!"},
{"Title": "Alternatives to Real-Debrid?", "Author": "u/Few_Landscape_573", "Content": "Do you guys know any good ones that don’t log users info?\n  \n\n    I’m worried about security data breaches about my personal info."},
{"Title": "How do I store family photos?", "Author": "u/Wonder_Pretty", "Content": "First off I know nothing about computers, hard drives, cloud storage etc. But, I need help to understand how to store my family photos long term. My aunt passed away last Friday. I'm at her visitation right now. My sisters and my other aunt put together a few photo boards of my aunt. And seeing all of the photos reminds me that I seriously need to learn how to protect my family photos, videos, family history, my own personal files, etc. I know that I need to make multiple copies and use multiple ways of store things,  hard drives, cloud storage, external hard drives. Apart from that I know absolutely nothing about computers, I don't even have a computer. Currently I have things stored on a few thumb drives and I know I shouldn't rely on those for storage. Please help.\n  \n\n    Update: I want to thank everyone for their advice and suggestions. I'm sorry that I haven't replied to everyone's comments. Life is bit hectic at the moment. When I get some free time I'll be able to read and process everyone's comments. Again thank you all for your help I really appreciate it right now."},
{"Title": "Cheap external ssds > 4TB?", "Author": "u/newtoaster", "Content": "So we are selling the house and moving into an RV to travel full time. My PLEX server is a mac mini that currently has a 4 drive external enclosure that runs crazy hot and has a fan that sounds like a leaf blower. Power is at a premium off grid, so I want to replace it with something solid state. I need more than 4TB (6 would do). Whats my cheapest option at the moment for something thats not trash?"},
{"Title": "What's a reasonbale size for an external HDD?", "Author": "u/szetadom", "Content": "Hello!\n  \n\n    I'm planning on buying an external HDD to make a backup of my phone, photos, important documents, text files, etc. I don't know how big of an HDD to buy? I think I'll need about 2TBs of storage in the foreseeable future so I was thinking about getting a 4TB drive and call it a day. My question is that is it worth for me to buy a disk with more storage capacity like 8 TB or even larger?"},
{"Title": "What is the most data you have used in a month?", "Author": "u/Embire", "Content": "I am the CEO of one of Africa's largest ISP's and last month we clocked our highest data user ever. 98,1TB.  Keep in mind, we only sell 4G and 5G wireless connectivity.  I know that for a Fibre company, this is pretty normal.  \nWhat is the most data you have ever used on your Mobile plan per month?"},
{"Title": "Solution To Growing Collection Of WD Elements External Drives?", "Author": "u/It_Is_JAMES", "Content": "With limited desk space and power outlets, I currently have 4 WD Elements external drives stacked on top of each other, ranging from 10-18TB. Wanting to get a 5th, but realizing that this probably isn't an ideal solution for heat or longevity of the drives.\n  \n\n    Currently, everything is going into a powered USB hub and connecting to my laptop. Was wondering what solutions are available that are worth looking into, that offer the best value for the price. NAS? A USB hard drive bay? Or, would buying a couple extra externals really not be a problem? I'll probably only buy 2 more drives before building a desktop that could hold a lot of the drives internally anyway."},
{"Title": "I can't mount this partition, I might have encrypted it via VeraCrypt but it's not taking my usual passwords. Am I screwed?", "Author": "u/RandomADHDaddy", "Content": "No content"},
{"Title": "Open source datasharing service", "Author": "Unknown author", "Content": "Hey guys! I have noticed that there is not much in the realm of open source datasharing services, so I created a Django REST / React app that allows for upload, download, reviewing, etc, of files. Not sure if would be useful to people. Also, please feel free add features. This is meant to be an open source project that allows research labs / people to share and review datasets without needing to pay for any online subscriptions. \nhttps://github.com/lxaw/DataDock"},
{"Title": "I just uploaded to The Internet Archive the most complete collection of games and software by Wiering Software.", "Author": "u/Impossible_Salary_38", "Content": "I just uploaded to The Internet Archive the most complete collection of games and software of Wiering Software company who made classic well known games for MS-DOS and ported them to other platforms like Android, Flash and Windows. The collection contains all the different versions of each game for each platform, plus it has the registered (complete) version of the games Super Angelo and Super Worms for DOS and a modded full version of Charlie the Duck for android.\n  \n\n    Since most of the games are shareware (demo), I think most people like me could only play the demo version of Super Angelo, limited to 3 levels only, since the shareware version is the easiest to find. The complete version has way more levels and the final ending. The Flash version of Super Angelo is also complete. Some of the games can't be be purchased anymore and remain in their demo version like Olaf & Elmar In the Castle of Nabokos.\n  \n\n    Some of the games include their user's manual, level maps (Super Worms) or source code (Mario & Luigi and Mario!!!). There are also two tools included, one for editing tiles, sprites and maps and another just for navigating folders with icons.\n  \n\n\nComplete collection of Wiering Software games and software"},
{"Title": "So i can copy EVERYTHING on my D:/ drive into my backup storage, except for these 2 folders that gives the error (yes, they're portable p*rn games). Is my 2 years old evo 870 failing? even though the games still works just fine.", "Author": "u/Arctic-Warfare9000", "Content": "https://preview.redd.it/so-i-can-copy-everything-on-my-d-drive-into-my-backup-v0-zg8xhn1oct0d1.png\nhttps://preview.redd.it/so-i-can-copy-everything-on-my-d-drive-into-my-backup-v0-utizoqbbbt0d1.png\n\n    I just can't do anything with the files (copy, move, del) except for the fact that I can still open anything inside like folders, text files, and even play both games with no issues.\n  \n\n    I'm currently in the process of backing up my personal files because i'm planning to assemble my newly bought pc parts and I want to do a fresh install on it. Planning to wipe the evo 870 ssd and do a fresh install on it and use it as my main storage.\n  \n\n    Both folders amount to 250gb in size. Is my SSD failing? how do i check?"},
{"Title": "Re-formatting SMR HDD as NTFS, or just keeping as exFAT?", "Author": "u/Caesar_35", "Content": "So, all of my previous drives have been your run-of-the-mill 2.5\" portables, all pre-formatted NTFS. I only use them for backup purposes, so phone pictures, game screenshots, some files, etc, which I manually copy across to two drives (muh redundancy). Lots of small files basically. My dutiful 2TB drive's recently gotten the dreaded red line of \"your space's running out\", and I saw a good deal on an 8TB 3.5\" external so jumped on it. However, it comes pre-formatted exFAT, which I'm aware isn't as well regarded as NTFS. I've only ever seen them on flashdrives myself. It's also an SMR drive (spooky, I know), so I'm not sure if NTFS or exFAT makes a difference there.\n  \n\n    Basically my question is, is it really worth while re-formatting to NTFS, or can I just keep it exFAT? This is going to be the backup drive of my backup drive, but I'd still rather it not get corrupted or have any other issues down the line. I'd also rather not unnecessarily spend time re-formatting it if there's not much reason to. I mean, I figure it \nshould\n be fine since that's how it came out the box, but better safe than sorry. It's one of those newer-era Seagate Expansions with the diagonal lines, if that makes any difference.\n  \n\n    And lastly, if I do go the route of re-formatting, would a quick format be fine given it's never been used for anything? And any guidelines for allocation unit size, being an SMR drive (is smaller/larger size better)?\n  \n\n    Thanks all!"},
{"Title": "Stablebit Drivepool error", "Author": "u/Earbuduserr", "Content": "Anyone know what to do to get rid of this error?, Ive tried pressing duplicate now and automatically\n  \nhttps://preview.redd.it/stablebit-drivepool-error-v0-auic8rk4s01d1.png"},
{"Title": "Need help Kasa download 30 days for possible neglect at managed care home resulting in death", "Author": "u/Yurt_lady", "Content": "I have a problem. I had a Kasa in my husband’s room at a memory care facility. I have Kasa care and an SD card.\n  \n\n    My husband passed away on Sunday. The Kasa camera is great but the software is crap. I need to download 30 days of videos and it seems that I have to do it one at a time. I can’t do that.\n  \n\n    Is there a way to write a batch file or something to download them? Can I hire someone from this group to download the videos? This is a nightmare."},
{"Title": "DPI and archiving family photo prints", "Author": "u/Hoagiewave", "Content": "I need help picking out hardware. I'm going to be scanning some prints, I don't need to worry about film. I come from a normal family of illiterates that throw the negatives out when the prints are made. I'm not that close with my family and I'm not going to be inheriting most of these pictures so it is likely I wont easily ever have a chance to see these pictures again when my grandmother is gone.\n  \n\n    So while I have the chance I want to do this right and max out the quality of the scans I'm going to get. I've tried to figure this out by myself but it would be nice to get some other opinions. It seems like the Epson v600 might be good enough that it can capture more than enough data than prints can give. The v850 seems have slightly deeper resolution for shades of dark. A decent amount of the pictures will be black and white.\n  \n\n    Are there any other options I'm missing? It seems a bit strange that a 15 year old scanner would be the best option on the market. Does the 850 produce tangibly better results? Because of the context I want to do this as best I can now. Lastly what resolution should I aim for to have master scans? Thank you"},
{"Title": "copy utility with check boxes or exclusions", "Author": "u/jedihermit", "Content": "I'm looking for something that can select a subset of my rom folder and optionally exclude subfolders from each. For example I want to pick 5-10 folders but omit the video folders in each to save space on the target. These are typically linux systems but I have access to the folders in windows too."},
{"Title": "WD Wireless Pro NAS functionality not working, but usb is working?", "Author": "u/requirehelpwithstuff", "Content": "I searched around and saw some similar reddit posts here so I'm hoping this is my best shot to post it here as well.\n  \n\n    I have an old wireless pro that I havent used in a long time, so I swapped the hard drive in it and the wireless functionality seems like it has disappeared. The blinking leds indicates that the device boots and goes solid meaning it's broadcasting wifi, but I don't see anything to connect to. It works when plugged via usb with no issues.\n  \n\n    I tried 'updating' the firmware and resetting it, and i \nthink\n it went thru, but still nothing. The last time I used it, I remember doing something similar and got to a point where i was able to see the wifi but never connected to it (didnt know the password was SN as a youtube guide said it was the ID of the hdd).\n  \n\n    Old hardware and don't really expect a hard answer, but any ideas are welcomed."},
{"Title": "How do I format a drive with 512e/4kn (22TB Seagate Exos X22)", "Author": "u/lintstah1337", "Content": "I am upgrading my old HDD to a bigger capacity.\n  \n\n    I am trying to clone an old HDD (18TB Seagate Exos X18) and would like to only use 1 partition.\n  \n\n    The cloning software has an option for \"4k alightnment\".\n  \n\n    Should I use 4k alignment?"},
{"Title": "Merging 35.2K Text files into one 604 GB monstrous text file.", "Author": "u/Latter-Ambassador-65", "Content": "I have no idea how I'm going to do this please comment.\n  \n\n    note : the drive im doing this on only has 117gb left on it\n  \n\n    avg file size 15mb - 10gb\n  \n\n    found a fix with sqlitebrowser ( doesn't merge into 1 text file but it works if you're just trying to search for something in the files )\n  \n\n\nhttps://sqlitebrowser.org/"},
{"Title": "External 2TB SSD Kingston vs 4TB HDD Toshiba Canvio", "Author": "u/droom2", "Content": "Both are at a discount, SSD $150usd and HDD $125usd. I'm on a budget, but I need to replace my old 1TB HDD external disk which started to fail after 10 years. I use it for 3Dmax library and backups"},
{"Title": "Compressing old avi files", "Author": "u/Pfftwhy", "Content": "Hey guys, as stated in the title I want to compress a lot of old avi files to a more space efficient format.\n  \n\n    I would like to keep as much quality as possible since the files itself are shot around 2005, my main concern is if i further reduce the quality the videos will be barely watchable.\n  \n\n    What would be the best way of doing this?\n  \n\n    EDIT\nRephrased to make my question clearer\n  \n\n    EDIT 2:\nVideo is interlaced & uses DV\n  \n\n    EDIT 3:\n  \n\n    ran mediainfo on one of the files as an example:\n  \nFormat                                   : AVI\nFormat/Info                              : Audio Video Interleave\nCommercial name                          : DVCAM\nFormat profile                           : OpenDML\nFormat settings                          : WaveFormatEx\nFile size                                : 19.1 GiB\nDuration                                 : 1 h 31 min\nOverall bit rate mode                    : Constant\nOverall bit rate                         : 29.8 Mb/s\nFrame rate                               : 25.000 FPS\nRecorded date                            : 2004-05-05 12:45:54.000\nIsTruncated                              : Yes\n\nVideo\nID                                       : 0\nFormat                                   : DV\nCommercial name                          : DVCAM\nCodec ID                                 : dvsd\nCodec ID/Hint                            : Sony\nDuration                                 : 1 h 31 min\nBit rate mode                            : Constant\nBit rate                                 : 24.4 Mb/s\nWidth                                    : 720 pixels\nHeight                                   : 576 pixels\nDisplay aspect ratio                     : 4:3\nFrame rate mode                          : Constant\nFrame rate                               : 25.000 FPS\nStandard                                 : PAL\nColor space                              : YUV\nChroma subsampling                       : 4:2:0\nBit depth                                : 8 bits\nScan type                                : Interlaced\nScan order                               : Bottom Field First\nCompression mode                         : Lossy\nBits/(Pixel*Frame)                       : 2.357\nTime code of first frame                 : 00:00:18:20\nTime code source                         : Subcode time code\nStream size                              : 18.4 GiB (97%)\nEncoding settings                        : ae mode=full automatic / wb mode=automatic / white balance= / fcm=manual focus\n\nAudio\nID                                       : 1\nFormat                                   : PCM\nFormat settings                          : Little / Signed\nCodec ID                                 : 1\nDuration                                 : 1 h 31 min\nBit rate mode                            : Constant\nBit rate                                 : 1 024 kb/s\nChannel(s)                               : 2 channels\nSampling rate                            : 32.0 kHz\nBit depth                                : 16 bits\nStream size                              : 670 MiB (3%)\nAlignment                                : Aligned on interleaves\nInterleave, duration                     : 240  ms (6.00 video frames)"},
{"Title": "How to decrypt video files?", "Author": "u/VibWhore", "Content": "So there's this educational institution which has provided me with a number of video lectures in a special format that can only be accessed throught an application called \"Player\" by HSC-PK available on Microsoft Store.\n  \n\n    I have those videos downloaded on my device but they are in a special format, which can only be accessed through the \"Player\" by entering the credentials in it.\n  \n\n    Is there anyway that I can figure out to convert those files into a normal .MP4 format through which I can open it and use it normally?"},
{"Title": "Is this a relabeled Ultrastar HC570?", "Author": "u/slash8793", "Content": "I bought what was supposed to be a 22TB Ultrastar HC570 from an Ebay seller. What I received appears to be from a shucked external drive. Before I return it, can anyone tell me if it's just a relabeled HC570?\n  \n\n    The model number is WD220EDGZ, and underneath it says \"SATA 6Gb/s IU HA570\". No mention of the Ultrastar name anywhere on the label. That's fine if it's the exact same thing, but I'm not sure it is. Did I get a lower quality drive? Thanks."},
{"Title": "seagate exos refurbished read speed hitting 130MBps", "Author": "u/honelnik", "Content": "I just got a refurbished exos ST16000NM000D (I can't find any datasheet, which quite bothers me) for my elitedesk 800 G4 and I am running the crypto-test from \nhttps://wiki.archlinux.org/title/Badblocks#Alternatives\n .\n  \n\n    After the intial 280-ish MBps write speeds (going down somewhere to 200), I am currently running the compare step and again, from 270-280 MBps in the begininng I am hitting 130 MBps speeds after some 13hrs of running:\n  \n\n\ntps kB_read/s kB_wrtn/s kB_dscd/s kB_read kB_wrtn kB_dscd Device\n\n\n\n\n1079.00 134.9M 0.0k 0.0k 134.9M 0.0k 0.0k sdd\n\n\n\n    first time I am building a server with such a large drive so I do not have anything to compare it with.\n  \n\n    Does it get this slow over sustained read and at the end of a drive?"},
{"Title": "Has anyone noticed a sigificant decrease in USB drive reliability? many DOA's..", "Author": "u/appletechgeek", "Content": "Has anyone noticed a sigificant increase in problems with USB drives as of late?\n  \n\n    i know USB drives are never reliable to begin with, but it's become so bad that i'd rather use a USB to sata/m.2 adapter than consider usb drives to make even small transfers between machines,\n  \n\n    all usb drive's i buy new either come DOA, or die within a extremely short time span,\n  \n\n    i thought it was my machine at first, but at this point it's been happening to 5+ machines consistently\n  \n\n    mac's and pc's. whatever, the drives would either not get detected, or fail format's and get stuck in a raw state, or pretend they are being constantly accessed while they are not,\n  \n\n    this happens to sandisk and philips brand usb drives, both usb 2.0 and 3.0 drive's. both small 16 gig and bigger 64/128 gig drive's,\n  \n\n    anyone been experiecing the same?"},
{"Title": "Need some help with mergerfs + sonarr - keep a tv show on one drive?", "Author": "u/fillilutten", "Content": "MergerFS is set to default existing path - most free space.\n  \n\n    I have 3 disks in this mergerfs pool where one disk is full. I ran into a problem when sonarr tried to import a new season to a show that is already on the full disk. I would like to keep a whole show on the same drive but I of course don't care to have different shows on different drives. I solved it by manually moving the whole show to the /tv folder on a drive with free space. But are there any solution to automate this?\n  \n\n\n\n    Thanks!"},
{"Title": "Alternatives to Real-Debrid?", "Author": "u/Few_Landscape_573", "Content": "Do you guys know any good ones that don’t log users info?\n  \n\n    I’m worried about security data breaches about my personal info."},
{"Title": "How do I store family photos?", "Author": "u/Wonder_Pretty", "Content": "First off I know nothing about computers, hard drives, cloud storage etc. But, I need help to understand how to store my family photos long term. My aunt passed away last Friday. I'm at her visitation right now. My sisters and my other aunt put together a few photo boards of my aunt. And seeing all of the photos reminds me that I seriously need to learn how to protect my family photos, videos, family history, my own personal files, etc. I know that I need to make multiple copies and use multiple ways of store things,  hard drives, cloud storage, external hard drives. Apart from that I know absolutely nothing about computers, I don't even have a computer. Currently I have things stored on a few thumb drives and I know I shouldn't rely on those for storage. Please help.\n  \n\n    Update: I want to thank everyone for their advice and suggestions. I'm sorry that I haven't replied to everyone's comments. Life is bit hectic at the moment. When I get some free time I'll be able to read and process everyone's comments. Again thank you all for your help I really appreciate it right now."},
{"Title": "Cheap external ssds > 4TB?", "Author": "u/newtoaster", "Content": "So we are selling the house and moving into an RV to travel full time. My PLEX server is a mac mini that currently has a 4 drive external enclosure that runs crazy hot and has a fan that sounds like a leaf blower. Power is at a premium off grid, so I want to replace it with something solid state. I need more than 4TB (6 would do). Whats my cheapest option at the moment for something thats not trash?"},
{"Title": "What's a reasonbale size for an external HDD?", "Author": "u/szetadom", "Content": "Hello!\n  \n\n    I'm planning on buying an external HDD to make a backup of my phone, photos, important documents, text files, etc. I don't know how big of an HDD to buy? I think I'll need about 2TBs of storage in the foreseeable future so I was thinking about getting a 4TB drive and call it a day. My question is that is it worth for me to buy a disk with more storage capacity like 8 TB or even larger?"},
{"Title": "What is the most data you have used in a month?", "Author": "u/Embire", "Content": "I am the CEO of one of Africa's largest ISP's and last month we clocked our highest data user ever. 98,1TB.  Keep in mind, we only sell 4G and 5G wireless connectivity.  I know that for a Fibre company, this is pretty normal.  \nWhat is the most data you have ever used on your Mobile plan per month?"},
{"Title": "Solution To Growing Collection Of WD Elements External Drives?", "Author": "u/It_Is_JAMES", "Content": "With limited desk space and power outlets, I currently have 4 WD Elements external drives stacked on top of each other, ranging from 10-18TB. Wanting to get a 5th, but realizing that this probably isn't an ideal solution for heat or longevity of the drives.\n  \n\n    Currently, everything is going into a powered USB hub and connecting to my laptop. Was wondering what solutions are available that are worth looking into, that offer the best value for the price. NAS? A USB hard drive bay? Or, would buying a couple extra externals really not be a problem? I'll probably only buy 2 more drives before building a desktop that could hold a lot of the drives internally anyway."},
{"Title": "I can't mount this partition, I might have encrypted it via VeraCrypt but it's not taking my usual passwords. Am I screwed?", "Author": "u/RandomADHDaddy", "Content": "No content"},
{"Title": "Open source datasharing service", "Author": "Unknown author", "Content": "Hey guys! I have noticed that there is not much in the realm of open source datasharing services, so I created a Django REST / React app that allows for upload, download, reviewing, etc, of files. Not sure if would be useful to people. Also, please feel free add features. This is meant to be an open source project that allows research labs / people to share and review datasets without needing to pay for any online subscriptions. \nhttps://github.com/lxaw/DataDock"},
{"Title": "I just uploaded to The Internet Archive the most complete collection of games and software by Wiering Software.", "Author": "u/Impossible_Salary_38", "Content": "I just uploaded to The Internet Archive the most complete collection of games and software of Wiering Software company who made classic well known games for MS-DOS and ported them to other platforms like Android, Flash and Windows. The collection contains all the different versions of each game for each platform, plus it has the registered (complete) version of the games Super Angelo and Super Worms for DOS and a modded full version of Charlie the Duck for android.\n  \n\n    Since most of the games are shareware (demo), I think most people like me could only play the demo version of Super Angelo, limited to 3 levels only, since the shareware version is the easiest to find. The complete version has way more levels and the final ending. The Flash version of Super Angelo is also complete. Some of the games can't be be purchased anymore and remain in their demo version like Olaf & Elmar In the Castle of Nabokos.\n  \n\n    Some of the games include their user's manual, level maps (Super Worms) or source code (Mario & Luigi and Mario!!!). There are also two tools included, one for editing tiles, sprites and maps and another just for navigating folders with icons.\n  \n\n\nComplete collection of Wiering Software games and software"},
{"Title": "So i can copy EVERYTHING on my D:/ drive into my backup storage, except for these 2 folders that gives the error (yes, they're portable p*rn games). Is my 2 years old evo 870 failing? even though the games still works just fine.", "Author": "u/Arctic-Warfare9000", "Content": "https://preview.redd.it/so-i-can-copy-everything-on-my-d-drive-into-my-backup-v0-zg8xhn1oct0d1.png\nhttps://preview.redd.it/so-i-can-copy-everything-on-my-d-drive-into-my-backup-v0-utizoqbbbt0d1.png\n\n    I just can't do anything with the files (copy, move, del) except for the fact that I can still open anything inside like folders, text files, and even play both games with no issues.\n  \n\n    I'm currently in the process of backing up my personal files because i'm planning to assemble my newly bought pc parts and I want to do a fresh install on it. Planning to wipe the evo 870 ssd and do a fresh install on it and use it as my main storage.\n  \n\n    Both folders amount to 250gb in size. Is my SSD failing? how do i check?"},
{"Title": "Re-formatting SMR HDD as NTFS, or just keeping as exFAT?", "Author": "u/Caesar_35", "Content": "So, all of my previous drives have been your run-of-the-mill 2.5\" portables, all pre-formatted NTFS. I only use them for backup purposes, so phone pictures, game screenshots, some files, etc, which I manually copy across to two drives (muh redundancy). Lots of small files basically. My dutiful 2TB drive's recently gotten the dreaded red line of \"your space's running out\", and I saw a good deal on an 8TB 3.5\" external so jumped on it. However, it comes pre-formatted exFAT, which I'm aware isn't as well regarded as NTFS. I've only ever seen them on flashdrives myself. It's also an SMR drive (spooky, I know), so I'm not sure if NTFS or exFAT makes a difference there.\n  \n\n    Basically my question is, is it really worth while re-formatting to NTFS, or can I just keep it exFAT? This is going to be the backup drive of my backup drive, but I'd still rather it not get corrupted or have any other issues down the line. I'd also rather not unnecessarily spend time re-formatting it if there's not much reason to. I mean, I figure it \nshould\n be fine since that's how it came out the box, but better safe than sorry. It's one of those newer-era Seagate Expansions with the diagonal lines, if that makes any difference.\n  \n\n    And lastly, if I do go the route of re-formatting, would a quick format be fine given it's never been used for anything? And any guidelines for allocation unit size, being an SMR drive (is smaller/larger size better)?\n  \n\n    Thanks all!"},
{"Title": "Will they ever change the sizing descriptions to actual space available?", "Author": "u/Strange_Advisor_", "Content": "I understand the gap with you buy a 10TB hard drive you get 9TB of actual usable space, but with the growth in the size of hard drives the gap is getting more and more. And lots of people seem to not realize they ARE getting what they pay for. So I cant help but wonder if they will ever change the naming convention to actual available space just to appease the masses?"},
{"Title": "Any software/programs that can \"rank\" files?", "Author": "u/ProjectSpaceRain", "Content": "I know this sounds kind of stupid but I'm wondering if there's anything that can organize or in this case 'rank' files based on given value. Let's say I want file A to be ranked 'Gold'  and file B to rank 'Silver'. It's almost similar to file tagging but really isn't. File tagging just tags whatever keyword is assigned to a file and doesn't actually 'rank' them, you'd want Gold to be above silver,...or something like that."},
{"Title": "Corrupted Nvme Bwin SSD showing as \"no media\" with 0b", "Author": "u/IsaacYPunto", "Content": "I got a dual boot system with win11 and ubuntu 23, everything was ok till yesterday when I powered off the system and then it showed a message like \"kernel must be mounted before\" then i restarted the system again  and the disk dissapeared. I tried to reformat it but even it doesn't appear in the UEFI. I tried to read it in Mac and Linux systems but nothing, then i try it on Windows and it shows a drive but an error message says \"cant get access to F:\\, incorrect function\" when I try to open it. On DiskManager appears as \"No media\" I think it can't mount it or it is not initialized for some reason. I tried to use Gparted, testdisk and EasyUS data recovery as well but it doesn't appear in any of them. Is there a solution? Ty soo much."},
{"Title": "Seeking Help Extracting Dog Photos from CCTV Footage (120GB, ~1 Month)", "Author": "u/BubblyJubsWhale", "Content": "Hi all,\n  \n\n    I'm hoping to find a way to extract images/clips of my dog from about 120GB of home CCTV as MP4 files (roughly one month's worth). He recently passed, and I want to preserve any memories I can.\n  \n\n    I have a home lab server and access to a RTX GPU, so I'm open to software, scripts, or even machine learning for animal detection (if feasible). The footage is mostly static shots of my living room, so automating the search would be amazing.\n  \n\n    I'm aware this might not be the most typical DataHoarder topic, but I'm hoping someone here has experience or ideas that could help. Any recommendations or advice are greatly appreciated!\n  \n\n    Thanks!"},
{"Title": "Shut Down NAS after Years running for a Vacation break?", "Author": "u/cometa73", "Content": "We are planning to take several vacations in the coming weeks. During this time, I would like to turn off everything in our household, as electricity prices in my country (Germany) are very high. Dev-Servers, APs, FW, etc. should not be a problem, but I have some concerns about my two NAS devices. NAS1 (Synology) with 2x4TB has been running continuously for 5.8 years without any issues, while NAS2 (QNAP) 2x12TB has been running for about 9 months.\n  \n\n    What is the life expectancy of the HDDs, especially for NAS1, if the HDDs have been running for almost 6 years and will now be off for about 10 weeks? I’m not concerned about data security; all data is backed up multiple times. I want to save some energy; although I can forego the savings if I have to buy new disks right after the vacation trip.\n  \n\n    Has anyone experience with this? Can I shut down the NAS devices? What do you recommend?"},
{"Title": "Been buying cheap SSDs on Ali and Temu", "Author": "u/ThyRhubarb", "Content": "I avoid Western brands especially Samsung which are the mostly fakes ones (really what's with all those 1080 pros). Got a $80 crucial p3 plus 2tb, $35 1 tb Fanxiang s660 off a pricing glitch from Temu. Apart from delayed shipping ($5 credit for me lol) product confirmed to be real with testing and device id. The Fanxiang got slightly faster read but slower write than the Crucial about 2.4 vs 2.8GB/s seq write 1GB (in a asm246X usb4 enclosure). Crucial one runs way hotter though while the Fanxiang stays cool even under load. 2x benchmark followed by 5 min SSD cloning from 200GB"},
{"Title": "Download hi-res image from Smithsonian website?", "Author": "u/Kresling", "Content": "I'd appreciate advice on how to get the full-size image files from the Smithsonian website:\n  \n\n\nhttps://www.si.edu/object/group-photo-gallery-200-artists-provincetown-massachusetts:AAADCD_item_5861\n\n\n\n    I tried JDownloader and WFDownloader, but no luck so far."},
{"Title": "Should I have redundancy in a NAS if I have a physical copy in a separate location?", "Author": "u/TheSoupGuyMan", "Content": "I am planning on setting up my first NAS, and I was wondering if redundancy is still recommended even if I have a copy of the data updated regularly (~once a week)."},
{"Title": "Commercial grade photo scanners?", "Author": "u/crossfitdood", "Content": "Hey everyone.\n  \n\n    So I recently got into data hoarding. It first started with a Plex server, then i archived ALL of my photos. When I was showing my archived photos to my family in the Synology photos app, my grandma asked if I could digitize her thousands upon thousands of photos. Then she spread the word to her emblem club and elks lodge friends that I was doing it for her and now a half dozen of her friends want me to do theirs too. They offered to pay me for the service.\n  \n\n    I was looking at scanners, and it seems like consumer grade scanners are a hit and miss. They are either too slow, or the ones that are fast leave marks on the originals. I tried looking up commercial grade scanners but I'm not able to find anything. I'm sure they're expensive, but I've been wanting to start a side business for my wife, so that she can quit her current job and be at home with the kids more. So I'm willing to invest in a good quality machine if the market is there."},
{"Title": "Storage Spaces + SSD array + cache drive?", "Author": "u/olo99", "Content": "Building a new rig that among other things will be used for storage as well.\nPlan is to get a 9500-16i HBA card (IT-mode) and connecting 6 x SSD (SATA 2.5\") to it.\n  \n\n    I have previously only used hardware RAID but this time I want to give Windows and StorageSpaces a shot. The storage is mainly an initial backup (also have cloud and offline) + all movies/shows for Plex Media Server.\n  \n\n\n\n\n\n    First question. Is Windows Storage Spaces a good choice for software raid? From what I understand configuration through powershell is a must and then parity can be set up to mimic RAID 5 or 6?\n  \n\n\n\n\n\n    I am using WD RED SSD. These do not have PLP unfortunately (dont have the money do buy enterprise drives with PLP).  Would there be any benefit of adding a NVME SSD with PLP to use as a cache drive for the pool?  I am not really clear on whether having a PLP capable drive as cache write would be enough to protect the whole array if there's an unexpected outage?\n  \n\n\n\n\n\n    If cache drive, I read somewhere that two drives are needed for this in WSS? Is this true?\nIf the cache drive with PLP wouldn't protect the whole array, is there any point at all of using additional cache drive for a SSD array?\n  \n\n\n\n\n\n    Should I look elsewhere for some other RAID/parity solution? I need Windows 11 to be used on the rig so ZFS is not an option for example.    Other recommendations have been drivepool and snapraid. I want this running on windows 11 that's the only dealbreaker, apart from that I am open to any suggestion :)\n  \n\n\n\n\n\n    Really appreciate any advice and insight!"},
{"Title": "ISO extra to MKV/ MP4 ?", "Author": "u/positivename", "Content": "So depsite my best efforts to get my kid to put dvds away ...well many of you already know. So I am backing up DVDS. Thing is the kid LOVES the special features. So I've ripped a couple ISOs and I have a player on the computer but the kid wants to play on the TV. So I guess my question is kind of a two pronged apporach here.\n  \n\n\n\n\n\n    do I just burn the ISO to a DVD and it will just play on my player like normal?\n  \n\n\n\n\n\n    They do want to watch the movies so is there some kind of service where I can convert some of the ISO to mp4/mkv so I can just throw it on a thumb drive? My dvd player has a thumb drive player. I don't suppose there is a way to get the special features as a mkv/mp4 right?  A lot of the things they like to do on the DVDE are the games that are special features. I'm pretty clueless on the matter.\n  \n\n\n\n\n\n    I appreciate anyone's response."},
{"Title": "Suspicious recert drive from SPD?", "Author": "u/imdjay", "Content": "Could be i'm being a bit paranoid here, i'm just looking for some other folk's experience to see if this is out of the ordinary:\n  \n\n    I've gotten a few dozen drives from serverpartdeals this year, and all have been OK, great packaging, acceptable surface wear, and clearly wiped smart info.\n  \n\n    One drive though that i got which was the last of their stock, had 7 power on counts with 19 hours in operation, way more than any other drive i've gotten from them. That, and there was kapton tape already applied to pin3, something that i'd expect WD would remove during the recert process(not familiar with their track record of thoroughness in this regard)\n  \n\n    So, is this abnormal, or business as usual?"},
{"Title": "Storing photos/videos while preventing bitrot", "Author": "u/h0wg0esit", "Content": "Hello all, I am trying to find an effective way (under $1000) to backup about 500gb of old photos/videos. My main concern is bitrot or having something happen where the files are unreadable in 20-30 years. At first, I was looking at M-Discs, but it looks like there is concern about a change in mfg techniques. My next idea is to use external hard drives. Is there a way to setup 1 to 3 external hard drives to check for bit errors and correct them? Or can I use say a 4 tb hard drive, split it into 3 partitions and have it check for errors in 1 partition against the other 2? I read that zfs might be a solution but don’t know where to start."},
{"Title": "Music Hoarders: New Pioneer CD Drive", "Author": "u/_kochino", "Content": "Mission: get new external drive to rip my CDs into digital library\n  \n\n    I came across the Pioneer BDR-XD08B ($120 USD) and I wasn’t sure if anyone has used this drive yet? It’s hasn’t made its way into the list of highly accurate rippers due to how new it is. I’m wondering if this is overkill or if I get a cheaper drive, will I one day regret not having bought the higher quality drive to rip in my library"},
{"Title": "Just bought 2 of these ultracheap drives to put in a raid 1 in my pc. Would it also make sense to fill up a nas with 4 or 8 of them? They have 5 year warranty through Amazon Renewed.", "Author": "u/werdmouf", "Content": "No content"},
{"Title": "What Websites & Apps that were very popular are now no longer around", "Author": "u/Embarrassed-Bend3014", "Content": "I know Vine was one of the big ones.\n  \n\n    I would love to hear of other websites that masses used that are now abandoned,archived or just completely deleted now."},
{"Title": "Toshiba Demos HDDs with a Capacity of Over 30TB Using HAMR & MAM", "Author": "u/ethereal_trespasser", "Content": "No content"},
{"Title": "Looking for Google photo alternatives", "Author": "u/HownottodoAnal", "Content": "15GBs really isn't a lot and my phone doesn't have enough space. I don't have the funds either, so does anyone know about an app similar to Google photos but offers more free space?"},
{"Title": "Cloud service that provides one way sync", "Author": "u/MachineThatGoesP1ng", "Content": "Looking for a cloud that has one way sync option, while preferably having 2 way sync option as well (PC -> Cloud, Cloud -> PC, Cloud <--> PC). Anything out there?"},
{"Title": "Silverstone SG11 - 30 TB Home Server", "Author": "u/magnusGRN", "Content": "No content"},
{"Title": "Have you ever seen any data \"gaslighting\"?", "Author": "u/Atticus104", "Content": "Just curious if in the course of yall's data hoarding ventures, you have noticed something that you hoarded that has been drastically altered in the public dataosphere."},
{"Title": "How do I learn about computers enough to start data hoarding?", "Author": "u/Adderall_Cowboy", "Content": "Please don’t delete this, sorry for the annoying novice post.\n  \n\n    I don’t have enough tech literacy yet to begin datahoarding, and I don’t know where to learn.\n  \n\n    I’ve read through the wiki, and it’s too advanced for me and assumes too much tech literacy.\n  \n\n    Here is my example: I want to use youtube dl to download an entire channel’s videos. It’s 900 YouTube videos.\n  \n\n    However, I do not have enough storage space on my MacBook to download all of this. I could save it to iCloud or mega, but before I can do that I need to first download it onto my laptop before I save it to some cloud service right?\n  \n\n    So, I don’t know what to do. Do I buy an external hard drive? And if I do, then what? Do I like plug that into my computer and the YouTube videos download to that? Or remove my current hard drive from my laptop and replace it with the new one? Or can I have two hard drives running at the same time on my laptop?\n  \n\n    Is there like a datahoarding for dummies I can read? I need to increase my tech literacy, but I want to do this specifically for the purpose of \ndatahoarding.\n I am not interested in building my own pc, or programming, or any of the other genres of computer tech."},
{"Title": "Building a dual PC/NAS setup, pros & cons?", "Author": "u/DiligentRope", "Content": "I'm looking to use my old gaming PC also as a home NAS (dual NAS/gaming PC use), though most resources I've found only talk about turning an old PC into a dedicated NAS. Would appreciate general advice, and if someone could point me in the right direction.\n  \n\n    I'm looking to just use the NAS for home personal and family use for backing up files, from my PCs, external drives, USBs, etc., not really for movies, entertainment, or anything else at least for now. Also really need it so I can access my files from anywhere in the world (do I use a VPN for this?). Though I also want to use this system to occasionally use it as a windows PC (internet browsing, gaming, etc.). Electricity consumption isn't an issue btw.\n  \n\n    PC specs:\n  \n\n\n\n\n\n    intel i7 2600\n  \n\n\n\n\n\n    8gb ddr3 RAM (may upgrade to 32gb, not sure)\n  \n\n\n\n\n\n    2tb hdd (will buy another 4tb hdd for dual hdd, + ssd to boot from)\n  \n\n\n\n\n\n    AMD Vega 64"},
{"Title": "I made Mac app to search all my screenshots and downloads with AI", "Author": "u/stonkLabs", "Content": "I keep a lot of images and videos on my Mac (mostly screenshots + images/videos in my Downloads folder) , but I have so many that they're hard to search. It really got out of hand when I started posting memes.\n  \n\n    The Mac Photos app only supports search for stuff in your Photos Library, so I built an app to search all my non-Apple photos. Considering adding functionality to index an external hard drive, but that's a longer-term project.\n  \n\n    Including a demo below. Happy to send you along copy if you're interested in trying it out.\n  \n\n    Demo: \nhttps://www.youtube.com/watch?v=EIUgPNHOKKc\n\n\n\n    More info: \nhttps://desktopdocs.com/"},
{"Title": "Anyone using TrueNAS/Truecharts and would like to help setup Browsertrix Cloud?", "Author": "u/igmyeongui", "Content": "I would love to he able to save parts of the internet too but I'm unable to get it to work."},
{"Title": "Will they ever change the sizing descriptions to actual space available?", "Author": "u/Strange_Advisor_", "Content": "I understand the gap with you buy a 10TB hard drive you get 9TB of actual usable space, but with the growth in the size of hard drives the gap is getting more and more. And lots of people seem to not realize they ARE getting what they pay for. So I cant help but wonder if they will ever change the naming convention to actual available space just to appease the masses?"},
{"Title": "Any software/programs that can \"rank\" files?", "Author": "u/ProjectSpaceRain", "Content": "I know this sounds kind of stupid but I'm wondering if there's anything that can organize or in this case 'rank' files based on given value. Let's say I want file A to be ranked 'Gold'  and file B to rank 'Silver'. It's almost similar to file tagging but really isn't. File tagging just tags whatever keyword is assigned to a file and doesn't actually 'rank' them, you'd want Gold to be above silver,...or something like that."},
{"Title": "Corrupted Nvme Bwin SSD showing as \"no media\" with 0b", "Author": "u/IsaacYPunto", "Content": "I got a dual boot system with win11 and ubuntu 23, everything was ok till yesterday when I powered off the system and then it showed a message like \"kernel must be mounted before\" then i restarted the system again  and the disk dissapeared. I tried to reformat it but even it doesn't appear in the UEFI. I tried to read it in Mac and Linux systems but nothing, then i try it on Windows and it shows a drive but an error message says \"cant get access to F:\\, incorrect function\" when I try to open it. On DiskManager appears as \"No media\" I think it can't mount it or it is not initialized for some reason. I tried to use Gparted, testdisk and EasyUS data recovery as well but it doesn't appear in any of them. Is there a solution? Ty soo much."},
{"Title": "Seeking Help Extracting Dog Photos from CCTV Footage (120GB, ~1 Month)", "Author": "u/BubblyJubsWhale", "Content": "Hi all,\n  \n\n    I'm hoping to find a way to extract images/clips of my dog from about 120GB of home CCTV as MP4 files (roughly one month's worth). He recently passed, and I want to preserve any memories I can.\n  \n\n    I have a home lab server and access to a RTX GPU, so I'm open to software, scripts, or even machine learning for animal detection (if feasible). The footage is mostly static shots of my living room, so automating the search would be amazing.\n  \n\n    I'm aware this might not be the most typical DataHoarder topic, but I'm hoping someone here has experience or ideas that could help. Any recommendations or advice are greatly appreciated!\n  \n\n    Thanks!"},
{"Title": "Shut Down NAS after Years running for a Vacation break?", "Author": "u/cometa73", "Content": "We are planning to take several vacations in the coming weeks. During this time, I would like to turn off everything in our household, as electricity prices in my country (Germany) are very high. Dev-Servers, APs, FW, etc. should not be a problem, but I have some concerns about my two NAS devices. NAS1 (Synology) with 2x4TB has been running continuously for 5.8 years without any issues, while NAS2 (QNAP) 2x12TB has been running for about 9 months.\n  \n\n    What is the life expectancy of the HDDs, especially for NAS1, if the HDDs have been running for almost 6 years and will now be off for about 10 weeks? I’m not concerned about data security; all data is backed up multiple times. I want to save some energy; although I can forego the savings if I have to buy new disks right after the vacation trip.\n  \n\n    Has anyone experience with this? Can I shut down the NAS devices? What do you recommend?"},
{"Title": "Been buying cheap SSDs on Ali and Temu", "Author": "u/ThyRhubarb", "Content": "I avoid Western brands especially Samsung which are the mostly fakes ones (really what's with all those 1080 pros). Got a $80 crucial p3 plus 2tb, $35 1 tb Fanxiang s660 off a pricing glitch from Temu. Apart from delayed shipping ($5 credit for me lol) product confirmed to be real with testing and device id. The Fanxiang got slightly faster read but slower write than the Crucial about 2.4 vs 2.8GB/s seq write 1GB (in a asm246X usb4 enclosure). Crucial one runs way hotter though while the Fanxiang stays cool even under load. 2x benchmark followed by 5 min SSD cloning from 200GB"},
{"Title": "Download hi-res image from Smithsonian website?", "Author": "u/Kresling", "Content": "I'd appreciate advice on how to get the full-size image files from the Smithsonian website:\n  \n\n\nhttps://www.si.edu/object/group-photo-gallery-200-artists-provincetown-massachusetts:AAADCD_item_5861\n\n\n\n    I tried JDownloader and WFDownloader, but no luck so far."},
{"Title": "Should I have redundancy in a NAS if I have a physical copy in a separate location?", "Author": "u/TheSoupGuyMan", "Content": "I am planning on setting up my first NAS, and I was wondering if redundancy is still recommended even if I have a copy of the data updated regularly (~once a week)."},
{"Title": "Commercial grade photo scanners?", "Author": "u/crossfitdood", "Content": "Hey everyone.\n  \n\n    So I recently got into data hoarding. It first started with a Plex server, then i archived ALL of my photos. When I was showing my archived photos to my family in the Synology photos app, my grandma asked if I could digitize her thousands upon thousands of photos. Then she spread the word to her emblem club and elks lodge friends that I was doing it for her and now a half dozen of her friends want me to do theirs too. They offered to pay me for the service.\n  \n\n    I was looking at scanners, and it seems like consumer grade scanners are a hit and miss. They are either too slow, or the ones that are fast leave marks on the originals. I tried looking up commercial grade scanners but I'm not able to find anything. I'm sure they're expensive, but I've been wanting to start a side business for my wife, so that she can quit her current job and be at home with the kids more. So I'm willing to invest in a good quality machine if the market is there."},
{"Title": "Storage Spaces + SSD array + cache drive?", "Author": "u/olo99", "Content": "Building a new rig that among other things will be used for storage as well.\nPlan is to get a 9500-16i HBA card (IT-mode) and connecting 6 x SSD (SATA 2.5\") to it.\n  \n\n    I have previously only used hardware RAID but this time I want to give Windows and StorageSpaces a shot. The storage is mainly an initial backup (also have cloud and offline) + all movies/shows for Plex Media Server.\n  \n\n\n\n\n\n    First question. Is Windows Storage Spaces a good choice for software raid? From what I understand configuration through powershell is a must and then parity can be set up to mimic RAID 5 or 6?\n  \n\n\n\n\n\n    I am using WD RED SSD. These do not have PLP unfortunately (dont have the money do buy enterprise drives with PLP).  Would there be any benefit of adding a NVME SSD with PLP to use as a cache drive for the pool?  I am not really clear on whether having a PLP capable drive as cache write would be enough to protect the whole array if there's an unexpected outage?\n  \n\n\n\n\n\n    If cache drive, I read somewhere that two drives are needed for this in WSS? Is this true?\nIf the cache drive with PLP wouldn't protect the whole array, is there any point at all of using additional cache drive for a SSD array?\n  \n\n\n\n\n\n    Should I look elsewhere for some other RAID/parity solution? I need Windows 11 to be used on the rig so ZFS is not an option for example.    Other recommendations have been drivepool and snapraid. I want this running on windows 11 that's the only dealbreaker, apart from that I am open to any suggestion :)\n  \n\n\n\n\n\n    Really appreciate any advice and insight!"},
{"Title": "ISO extra to MKV/ MP4 ?", "Author": "u/positivename", "Content": "So depsite my best efforts to get my kid to put dvds away ...well many of you already know. So I am backing up DVDS. Thing is the kid LOVES the special features. So I've ripped a couple ISOs and I have a player on the computer but the kid wants to play on the TV. So I guess my question is kind of a two pronged apporach here.\n  \n\n\n\n\n\n    do I just burn the ISO to a DVD and it will just play on my player like normal?\n  \n\n\n\n\n\n    They do want to watch the movies so is there some kind of service where I can convert some of the ISO to mp4/mkv so I can just throw it on a thumb drive? My dvd player has a thumb drive player. I don't suppose there is a way to get the special features as a mkv/mp4 right?  A lot of the things they like to do on the DVDE are the games that are special features. I'm pretty clueless on the matter.\n  \n\n\n\n\n\n    I appreciate anyone's response."},
{"Title": "Suspicious recert drive from SPD?", "Author": "u/imdjay", "Content": "Could be i'm being a bit paranoid here, i'm just looking for some other folk's experience to see if this is out of the ordinary:\n  \n\n    I've gotten a few dozen drives from serverpartdeals this year, and all have been OK, great packaging, acceptable surface wear, and clearly wiped smart info.\n  \n\n    One drive though that i got which was the last of their stock, had 7 power on counts with 19 hours in operation, way more than any other drive i've gotten from them. That, and there was kapton tape already applied to pin3, something that i'd expect WD would remove during the recert process(not familiar with their track record of thoroughness in this regard)\n  \n\n    So, is this abnormal, or business as usual?"},
{"Title": "Storing photos/videos while preventing bitrot", "Author": "u/h0wg0esit", "Content": "Hello all, I am trying to find an effective way (under $1000) to backup about 500gb of old photos/videos. My main concern is bitrot or having something happen where the files are unreadable in 20-30 years. At first, I was looking at M-Discs, but it looks like there is concern about a change in mfg techniques. My next idea is to use external hard drives. Is there a way to setup 1 to 3 external hard drives to check for bit errors and correct them? Or can I use say a 4 tb hard drive, split it into 3 partitions and have it check for errors in 1 partition against the other 2? I read that zfs might be a solution but don’t know where to start."},
{"Title": "Music Hoarders: New Pioneer CD Drive", "Author": "u/_kochino", "Content": "Mission: get new external drive to rip my CDs into digital library\n  \n\n    I came across the Pioneer BDR-XD08B ($120 USD) and I wasn’t sure if anyone has used this drive yet? It’s hasn’t made its way into the list of highly accurate rippers due to how new it is. I’m wondering if this is overkill or if I get a cheaper drive, will I one day regret not having bought the higher quality drive to rip in my library"},
{"Title": "Just bought 2 of these ultracheap drives to put in a raid 1 in my pc. Would it also make sense to fill up a nas with 4 or 8 of them? They have 5 year warranty through Amazon Renewed.", "Author": "u/werdmouf", "Content": "No content"},
{"Title": "What Websites & Apps that were very popular are now no longer around", "Author": "u/Embarrassed-Bend3014", "Content": "I know Vine was one of the big ones.\n  \n\n    I would love to hear of other websites that masses used that are now abandoned,archived or just completely deleted now."},
{"Title": "Toshiba Demos HDDs with a Capacity of Over 30TB Using HAMR & MAM", "Author": "u/ethereal_trespasser", "Content": "No content"},
{"Title": "Looking for Google photo alternatives", "Author": "u/HownottodoAnal", "Content": "15GBs really isn't a lot and my phone doesn't have enough space. I don't have the funds either, so does anyone know about an app similar to Google photos but offers more free space?"},
{"Title": "Cloud service that provides one way sync", "Author": "u/MachineThatGoesP1ng", "Content": "Looking for a cloud that has one way sync option, while preferably having 2 way sync option as well (PC -> Cloud, Cloud -> PC, Cloud <--> PC). Anything out there?"},
{"Title": "Silverstone SG11 - 30 TB Home Server", "Author": "u/magnusGRN", "Content": "No content"},
{"Title": "Have you ever seen any data \"gaslighting\"?", "Author": "u/Atticus104", "Content": "Just curious if in the course of yall's data hoarding ventures, you have noticed something that you hoarded that has been drastically altered in the public dataosphere."},
{"Title": "How do I learn about computers enough to start data hoarding?", "Author": "u/Adderall_Cowboy", "Content": "Please don’t delete this, sorry for the annoying novice post.\n  \n\n    I don’t have enough tech literacy yet to begin datahoarding, and I don’t know where to learn.\n  \n\n    I’ve read through the wiki, and it’s too advanced for me and assumes too much tech literacy.\n  \n\n    Here is my example: I want to use youtube dl to download an entire channel’s videos. It’s 900 YouTube videos.\n  \n\n    However, I do not have enough storage space on my MacBook to download all of this. I could save it to iCloud or mega, but before I can do that I need to first download it onto my laptop before I save it to some cloud service right?\n  \n\n    So, I don’t know what to do. Do I buy an external hard drive? And if I do, then what? Do I like plug that into my computer and the YouTube videos download to that? Or remove my current hard drive from my laptop and replace it with the new one? Or can I have two hard drives running at the same time on my laptop?\n  \n\n    Is there like a datahoarding for dummies I can read? I need to increase my tech literacy, but I want to do this specifically for the purpose of \ndatahoarding.\n I am not interested in building my own pc, or programming, or any of the other genres of computer tech."},
{"Title": "Building a dual PC/NAS setup, pros & cons?", "Author": "u/DiligentRope", "Content": "I'm looking to use my old gaming PC also as a home NAS (dual NAS/gaming PC use), though most resources I've found only talk about turning an old PC into a dedicated NAS. Would appreciate general advice, and if someone could point me in the right direction.\n  \n\n    I'm looking to just use the NAS for home personal and family use for backing up files, from my PCs, external drives, USBs, etc., not really for movies, entertainment, or anything else at least for now. Also really need it so I can access my files from anywhere in the world (do I use a VPN for this?). Though I also want to use this system to occasionally use it as a windows PC (internet browsing, gaming, etc.). Electricity consumption isn't an issue btw.\n  \n\n    PC specs:\n  \n\n\n\n\n\n    intel i7 2600\n  \n\n\n\n\n\n    8gb ddr3 RAM (may upgrade to 32gb, not sure)\n  \n\n\n\n\n\n    2tb hdd (will buy another 4tb hdd for dual hdd, + ssd to boot from)\n  \n\n\n\n\n\n    AMD Vega 64"},
{"Title": "I made Mac app to search all my screenshots and downloads with AI", "Author": "u/stonkLabs", "Content": "I keep a lot of images and videos on my Mac (mostly screenshots + images/videos in my Downloads folder) , but I have so many that they're hard to search. It really got out of hand when I started posting memes.\n  \n\n    The Mac Photos app only supports search for stuff in your Photos Library, so I built an app to search all my non-Apple photos. Considering adding functionality to index an external hard drive, but that's a longer-term project.\n  \n\n    Including a demo below. Happy to send you along copy if you're interested in trying it out.\n  \n\n    Demo: \nhttps://www.youtube.com/watch?v=EIUgPNHOKKc\n\n\n\n    More info: \nhttps://desktopdocs.com/"},
{"Title": "Anyone using TrueNAS/Truecharts and would like to help setup Browsertrix Cloud?", "Author": "u/igmyeongui", "Content": "I would love to he able to save parts of the internet too but I'm unable to get it to work."},
{"Title": "Selectively or entirely download Youtube videos from channels, playlists", "Author": "u/ph0tone", "Content": "YT Channel Downloader\n is a cross-platform open source desktop application built to simplify the process of downloading YouTube content. It utilizes \nyt-dlp\n, \nscrapetube\n, and \npytube\n under the hood, paired with an easy-to-use graphical interface. This tool aims to offer you a seamless experience to get your favorite video and audio content offline. You can selectively or fully download channels, playlists, or individual videos, opt for audio-only tracks, and customize the quality of your video or audio. More improvements are on the way!\n  \n\n\nhttps://github.com/hyperfield/yt-channel-downloader\nFor Windows, Linux and macOS users, please refer to the installation instructions in the Readme. On Windows, you can either download and launch the Python code directly or use the pre-made installer available in the Releases section.\n  \n\n    Suggestions for new features, bug reports, and ideas for improvements are welcome :)\n  \nhttps://preview.redd.it/selectively-or-entirely-download-youtube-videos-from-v0-vdnmm6syzm0d1.png"},
{"Title": "Probably a stupid question (m-disc)", "Author": "u/Acceptable-South2892", "Content": "I'm looking at setting up an m-disc oriented archive (along with existing cloud and local storage).\n  \n\n    Given that I'm in the process of hoarding historical familial information, which is 100% media (documents, scans, videos, pictures etc) I'm naturally wondering if a conventional 'plug-into-your-tv' bluray player would support the bdxl medium. Naturally, it would have to have all the codecs for the storage to work. The merits of being able to make an mdisk full of family history for sharing purposes could be ideal if it's the case & the potential of storing it in a fireproof safe with a portable bluray player is pretty tempting too.\n  \n\n    It's a stupidly simple question, and probably innately obvious but I can't find anything concrete anywhere. So please excuse my ignorance on the subject as I pretty much blinked through the existence of bluray until now.\n  \n\n    TLDR: Can you view media burned on a bdxl in a standard home theater style bluray player?"},
{"Title": "Seagate Sent Me a Hard Drive", "Author": "u/Yummychickenblue", "Content": "Earlier this year I RMAd a hard drive to Seagate, and they sent out a replacement. Today I got another drive of the same model, with a return packing slip. I never got an email about it, and there's no record in my account of ordering it. I spoke with Seagate support and they say the serial number is for a new hard drive, and their best guess is that a friend got it for me (lol). What should I do with it? My name is on the billing statement, so I don't wanna be charged"},
{"Title": "Digitally archiving a museum space", "Author": "u/Majestic-Owl-5801", "Content": "I am trying to digitally archive a museum being torn down, and possibly make a 3d walkthrough of it.\n  \n\n    I will have high res photos of the items and the placards, and will have Insta360 x3 footage of the interior walking around. I also plan to use my iPhone 12pro to make a LiDAR file of the interior space.\n  \n\n    TLDR: ITC in San Antonio being torn down, trying to 3D document and archive it all.\n  \n\n    Any pointers or tips are appreciated!"},
{"Title": "Looking for advice on ways to organize media folder", "Author": "u/worlock_", "Content": "Hello, I have quite a large collection of media (around 9TB worth).\n  \n\n    I spent time creating a folder structure to organize all the files by studio, creator, favorites, etc. on my 8TB drive. Of course, not enough space on that single drive for new media, so it just piles up on random folders. I don't mind getting another dedicated drive - but I'm trying to see what kinds of file systems and organization might be better.\nI'm trying to avoid having to create the same file structure on the second drive to organize new media.\n  \n\n    Ideally, I'm trying to understand if there's a solution that I can use to create an organization that is expandable, meaning that I can just create folders, and if I need more space, I can just add more storage drives. Is this like a RAID system?\n  \n\n    i'm pretty rookie when it comes to advanced storage options so I appreciate any help!"},
{"Title": "SSD in Sabrent enclosure is plugged into an ALWAYS ON USB 2.0 port on Micca Speck G2 TV box, is this possibly decreasing the life of the sata SSD compared to if the USB powered off when the box is off?", "Author": "u/Bern_Down_the_DNC", "Content": "Just making sure that theTeamgroup EX2 sata SSD is going to sleep, either because of it's own firmware or because of the enclosure when the TV box is off but USB port is still powered on. (Unfortunately there is no firmware based options for powering off the port with the box, and no firmware updates.)\n  \n\n    Thank you."},
{"Title": "Raid 0 Array (1TB HDDs x 2) with 8TB HDD for Backups", "Author": "u/Low-Writing3449", "Content": "I've found myself processing 4K video and am needing more performance than my single 8TB HDD can deliver.  As a result, I looked into RAID 0 to boost performance, but I don't want to be SOL if one of my drives fail.  I don't have the money to be purchasing more 8TB drives, so my thought is to use two 1TB HDDs for a RAID 0 array to be used while I'm editing, then use the 8TB HDD for backups.\n  \n\n    Any thoughts on this?  Any good way to ensure my data is being backed up onto the 8TB drive as new data is written to the RAID 0 Array?\n  \n\n    Also, if it matters, I'm on a Win 11 PC.\n  \n\n    Thanks in advance!"},
{"Title": "Google Workspace Storage is a Scam", "Author": "u/truecolourpainting", "Content": "Google Workspace Storage Scam\n\n\n\n    Google is scamming millions of consumers by reducing the storage space they paid for and forcing them to a new subscription that's 500% more expensive. Worse, they continue to charge for the old storage space.\n  \n\n    I've had a Google Workspace account for 8 years. Despite paying for cloud storage, Google is now refusing to provide the service. A supervisor admitted on a recorded call that they will not honor the storage plan I paid for over the past 8 years, even though they still charge me. This is blatant fraud, and Google seems to think they're above the law.\n  \n\n    They stripped me of my storage and demanded I pay a 500% price increase plus a fee per user. If I don't comply, they'll delete all my 1TB of data and close my account. This new policy and contract were never agreed upon by me, despite my 8-year loyalty.\n  \n\n    This is how mega-corporations treat consumers, and the government does nothing to stop them. Google is committing fraud on a massive scale, as admitted by their supervisor.\n  \n\n    I've decided to go public, sell all my Google shares, and urge others to dump Google stock. Let's see how they react to a boycott.\n  \nGoogleFraud #GoogleScam #BoycottGoogle #ConsumerRights #CorporateGreed #TechScam #GoogleWorkspaceScam"},
{"Title": "Odroid HC2 - APM (Advanced Power Managment)", "Author": "u/mikesmith929", "Content": "Using an Odroid HC2 with a Western Digital 6TB WD Red NAS drive\n  \n\n    I have Open Media Vault installed on it via Armbian Bookworm.\n  \n\n    I ran \nsudo hdparm -B /dev/sda\n\n\n\n    And the hard drive says I have no APM support for spindown.\n  \n\n    I've asked in the Odroid forum about how to spindown hard drives \"properly\" they suggested using hd-idle.\n  \n\n    But that opens the question if I \nshould even be spinning down the hard drives\n?\n  \n\n    This Odroid will be my offsite backup, plus my Nextcloud server. Backups to and from the hard drive will run every day and of course random nextcloud access, whenever I need something from the \"cloud\".\n  \n\n    I have two other 4 bay NAS's one the primary server for \"videos\" while the other is my backup of \"videos\" plus backup of my computer data.\n  \n\n    The video NAS is accessed say a couple times a day and my local backup server is backed up daily\n  \n\n    So I have say 9 drives all Western Digital Reds NAS drives.\n  \n\n    What is the consensus here about spinning down the drives? Should I bother or just leave them as they are? What are the pros and cons?\n  \n\n    Thanks for any help you can give.\n  \n\n    I did search for spindown but didn't find much."},
{"Title": "I cannot connect to my NAS from Windows, but I can from everything else. I've been stuck for hours and I cannot think of where else to look.", "Author": "u/Insulifting", "Content": "Aplogoies if this isn't the right sub, I'm not sure where else to ask.\n  \n\n    I've started to dabble in setting up some NAS using an spare Raspbery Pi 4 (I know it's not the most effective but I wanted to see if I could at least get it running with some small storage before I splurge), and I'm able to connect on most devices except my main desktop. I can't work out why, but it's clearly something on my desktops configuration that's stopping it.\n  \n\n    The odd thing is I can SSH into it just fine, works like a charm, when I try to map the network drive and enter the credentials it just puts me back to the enter credentials screen and I know for a fact they're correct since I'm using them to SSH into it.\n  \n\n    Would anyone have any suggestions? I've tried changing firewall settings, disabling anti-virus, and changing NTLM connection settings in Group Policy as per a forum I found but none of that worked."},
{"Title": "Bypass Google Drive download prevention", "Author": "u/BrolyBoy", "Content": "Is there a way to properly download photos you have access to but not prevented downloading?\n  \n\n    There’s an artist that puts up images in Drive but prevents downloading but I do want to save them in case they take it down.\n  \n\n    I know that you can obtain parts of the photo by using the Inspect tabs, but I also want to easily and quickly bulk download the images. I’ve also looked on YouTube but the closest they get is bypassing the download limit using the Starred folder, which does not work when applied to “download prevented” files."},
{"Title": "Lto tape budget archive", "Author": "u/Lord_Of_ReBass", "Content": "I need some kind of cheap data setup for my movies and music.  It’s getting outta hand fast and I’ve been curious about lot tape. Been noticing you can get lto 5-6 drive pretty reasonable and the cartridges are a steal compared to my 3.5in hdd. Would this be a viable option for movies I don’t watch often and only access once in a while. Make a copy of it and watch the copy or something. I just need some kind of reliable budget friendly storage. And I have a 10tb drive alr."},
{"Title": "Immich", "Author": "u/steviefaux", "Content": "Anyone heard of this? Seems Louis Rossmann as got them to join Futo now. Have always trusted Louis. He had the app GrayJay develop, all open source and free but if you want you can pay. I'm cheap and even I've paid for a GrayJay license.\n  \n\n    Looks like this is the exact same model. Will be free but they'd rather you also pay if you can.\n  \n\n\nhttps://www.youtube.com/watch?v=F_2oydlnpCQ"},
{"Title": "OS does not see HP LSI SAS 1078 MegaRaid", "Author": "u/awesomefreeman", "Content": "I received this board with the LTO-3 streamer. Trying to connect it in PCI-e slot, but system does not detect the board. Tried it on Windows 7, 10, Proxmox and It does not appear in the terminal or device manager.. The board is heating up, I don’t see any external damage.\n  \n\n    Is it dead?\n  \n\n    Motherboard - B150M \nPro4V\n · \nASRock\n\n\n\n\nCPU-\n Intel Pentium G4400\n  \nhttps://preview.redd.it/os-does-not-see-hp-lsi-sas-1078-megaraid-v0-k79u1hjsmg0d1.jpg\nhttps://preview.redd.it/os-does-not-see-hp-lsi-sas-1078-megaraid-v0-7szh17ihmg0d1.png"},
{"Title": "How to securely erase Sandisk Extreme Pro before selling?", "Author": "u/stevecondy123", "Content": "I read \nhere\n that:\n  \n\n\n\n    The only way to truly erase data on an SSD is to use the ATA Secure Erase commands.\n  \n\n\nQuestion: how do I do that for Sandisk Extreme Pro (I'm on macOS).\n\n    I found a similar question asked \nhere\n, but I was hoping for answers that I could either run in the terminal (not a VM) or click-ops (e.g. macOS would have some built-in way as it does for spinning HDD's)."},
{"Title": "Duplex scanners that show measurements in scan???", "Author": "u/Stevealot", "Content": "Has anyone ever heard of this? I’m looking for something like a ruler on the side and top that would show the both dimensions of the item scanned. Is this an option on any scanner? It would save me so much time and could be a game changer for me. Thanks for your help!"},
{"Title": "soon i will be archiving a whole lot of betamax tape, will my setup be fine for digitizing?", "Author": "u/dankestofstolenmemes", "Content": "No content"},
{"Title": "Best strategy for using 2x1TB & 1x2TB SSD for hoarding purposes", "Author": "u/gizia", "Content": "edit\n: \nall of them are SSDs, I mentioned in the title\n\n\n\n    hello, guys. I'm needing help to utilize those SSDs to archive, protect, and keep copy of data and software.\nPlease also consider the following:\n  \n\n\n\n\n\n    Encryption\n  \n\n\n\n\n\n    Preserving data integrity\n  \n\n\n\n\n\n    Most important data will be 500GB at most\n  \n\n\n\n\n\n    I've Windows PC, but I can afford Mac\n  \n\n\n\n\n\n    Recommended Tools/Software for managing data"},
{"Title": "Is there a basic way to check for corruption in files you've had in storage/ use? (basic questions from newb)", "Author": "u/Sesemebun", "Content": "So I have always hated forgetting or losing things, moreso than the average person. I buy books I like, write down the names of things, and will soon be converting my physical media (vhs/dvd/etc) to digital to have it in multiple places. I assume most here are of the same mindset as me, though maybe more dedicated. After being thoroughly confused by the wiki, and combing through old posts, I thought I should just ask a few questions.\n  \n\n    I don't really need help with the actual copying part, there are plenty of guides out there (makeMKV seems to be the best suggestion for DVDs in this sub, according the wiki). I have also looked around for the actual storage device. I don't have enough data to be worth getting a server rack, and the more \"manual\" forms seem slow  (like mdisc) since I plan to tap into these fairly often. What I will end up doing is probably having a couple USB drives, each with a copy of my \"cache\" of stuff, be it photos or movies or games or whatnot. Probably every 5 years I will just copy everything over to a new drive, to counteract any kind of physical deterioration with the drive (my research seems to point that they are finnicky when it comes to how long they can last). These caches will be large enough to not be worth combing through every time I copy stuff to check it works. At the time that I transfer the data, is there any kind of non-invasive software I can run the files through to make sure they are still readable? Because I don't want to go to look at a photo and see that 10 years ago it got corrupted and is gone.\n  \n\n    TL;DR\n  \n\n    I want to keep my stuff on USB drives to access often, but replace every 5 years. What can I do to ensure I don't lose whatever is on the drives? Or are there better options for this scenario than a flash drive?\n  \n\n    (Thank you for your help, but please keep terminology and such on a low level, I am not my grandfather, but I am not super well versed with this kind of stuff)"},
{"Title": "Can't find VideoID for BrightCove player video", "Author": "u/Karlox2", "Content": "I'm trying to download the video embeded in this page: \nhttps://video.repubblica.it/spettacoli-e-cultura/angelina-mango-e-l-urlo-liberatorio-alla-finale-dell-eurovison-il-video-dal-backstage/469184/470138\n\n\n\n    I followed the URL template method but with no luck since I couldn't find the video id when opening the brightcove player menu. Can anyone help me out?"},
{"Title": "DIY vs. PreBuilt NAS (total noob question)", "Author": "u/NY-RatFucker", "Content": "Hi everyone. Need some help.\n  \n\n    I want to get a nas to backup my pc’s data (movies, music, videos, family photos, etc). Would also like to be able to access it remotely. I need about 8 tb of storage, think I may need more down the road but probably not.\n  \n\n    I am very familiar with pc building and thought about just building one myself with one of my old pcs lying around (2 drives in RAID1 on an old i3 workstation pc).\n  \n\n    But I’m also reading how simple and easy the pre builts are, is it worth it to just get a 2 or 4 bay synology or the like and use that?\n  \n\n    I am not too concerned about budget but I wouldn’t mind a cheap DIY if it would be a fun project to learn.\n  \n\n    Any help would be great, just need some guidance"},
{"Title": "How to batch download from PIXIV without pixivutil?", "Author": "u/Cr4zko", "Content": "I run Windows 8.1 and that doesn't let me use pixivutil anymore. So sad."},
{"Title": "can get WD Cloud OS products for -60%. is it worth it ?", "Author": "u/Exatio", "Content": "Specifically these\n  \n\n\nMy Cloud Home\n\n\n\n\nMy Cloud Expert Series EX2 Ultra\n\n\n\n    Knowing the security breach stuff & the fact that the OS is to be discontinued very soon, should I get them or no, and if yes what can I do with these without risking anything ?"},
{"Title": "Best YT channels/videos for NAS setup and use for complete beginners? HELP ME PLS", "Author": "u/husker3in4", "Content": "Hey all, I need a storage solution, I have external drives for my data overload, but I want something always on and always connected to my computer. I don't quite understand how a NAS works or all the cool things it can do, but what I do like, from what I'm reading, is that the NAS can provide parity protection if I choose SHR during setup, right? I will use 4 disks, in one of the 4 bay NAS from Synology.\n  \n\n    The other thing: I want the NAS to show up in my File Explorer (Windows 10), like the whole NAS. I keep seeing people talk about their home folder, and that you can map your home folder to your File Explorer, but I want to see the whole NAS on my File Explorer, so I can click it like another drive, and drag and drop files to the main NAS or into my home folder.\n  \n\n    BTW, this is strictly for home use, just myself on it. Given that knowledge, what is the difference between putting folders on the main directory of the NAS vs into my home folder? Is there some security or performance advantage or disadvantage to one or the other? I think I understand the purpose of the home folder, is to keep several users files separated and private from each other, but again, it will just be me on the NAS.I had my son set up Plex on my PC, and I am reading this is something that can run on the NAS as well, so I might do that too if I can figure it out. Other than that, I just need to transfer files back and forth to the NAS via File Explorer, sometimes files that are 10 or 20gb in size. I admit I'm a data hoarder so if this NAS can work in this way, I'd likely set up different folders for all of my data overflow that won't fit on my computer's internal drives.\n  \n\n    I understand how Windows 10 works as a home user but again, I'm a complete newbie to networking and NAS, and get confused pretty quickly when I start reading about all the advanced options and even get lost watching videos about all the seemingly millions of settings, security etc.Who do you recommend for YT videos explaining how it works, easy way to set it up and run for home use, single user etc? I looked at the Space Rex guy already. I don't know if It's how he presents the information or what but I can't follow him very well.The one thing I got from SpaceRex is that is he way smarter than I am, and he offers a service to set it up but for $300 an hour! If I were to find someone who could do it for a much more reasonable price, is that wise, or am I asking for trouble?The movie War Games from the 80s keeps flashing thru my mind, when they find the original programmer who snuck in thru a \"backdoor\" left in the system in case he needed to get back in...."},
{"Title": "Book Scanning: A guide about light?", "Author": "u/DontAskForTheMoon", "Content": "Hi. Imagine a very simple set up, a book opened 180° on a table and being scanned by a phone from above, also 180° (usually just the necessary pages and not the whole book, but they can be still like 100+ pages at times). No extra programs, just normal photos.\n  \n\n    I recently struggle heavily with especially modern scientific books. Their paper is not made of trees anymore, but they feel like thin plastic - the same material as most magazines are made of.\n  \n\n    Those magazine-like pages have a heavily disgusting light reflection potential. How exactly could I configure the light (like angle and its strength) to reduce those reflections? (Post-processing to black and white isn't possible, since those books contain coloured images, so I want to keep the original colours as they are)\n  \n\n    I already looked for setups, most of them are very professional and they have professional cameras etc. They also just use light on each page with desk-lamps. But it never looked like they are using special lens filters.\n  \n\n    If there is no way to reduce reflection with basic methods (like angle and strength of light, or phone camera settings), then my last option would be Polarizing Gel. But if there were solutions without extra costs, I would prefer them."},
{"Title": "Selectively or entirely download Youtube videos from channels, playlists", "Author": "u/ph0tone", "Content": "YT Channel Downloader\n is a cross-platform open source desktop application built to simplify the process of downloading YouTube content. It utilizes \nyt-dlp\n, \nscrapetube\n, and \npytube\n under the hood, paired with an easy-to-use graphical interface. This tool aims to offer you a seamless experience to get your favorite video and audio content offline. You can selectively or fully download channels, playlists, or individual videos, opt for audio-only tracks, and customize the quality of your video or audio. More improvements are on the way!\n  \n\n\nhttps://github.com/hyperfield/yt-channel-downloader\nFor Windows, Linux and macOS users, please refer to the installation instructions in the Readme. On Windows, you can either download and launch the Python code directly or use the pre-made installer available in the Releases section.\n  \n\n    Suggestions for new features, bug reports, and ideas for improvements are welcome :)\n  \nhttps://preview.redd.it/selectively-or-entirely-download-youtube-videos-from-v0-vdnmm6syzm0d1.png"},
{"Title": "Probably a stupid question (m-disc)", "Author": "u/Acceptable-South2892", "Content": "I'm looking at setting up an m-disc oriented archive (along with existing cloud and local storage).\n  \n\n    Given that I'm in the process of hoarding historical familial information, which is 100% media (documents, scans, videos, pictures etc) I'm naturally wondering if a conventional 'plug-into-your-tv' bluray player would support the bdxl medium. Naturally, it would have to have all the codecs for the storage to work. The merits of being able to make an mdisk full of family history for sharing purposes could be ideal if it's the case & the potential of storing it in a fireproof safe with a portable bluray player is pretty tempting too.\n  \n\n    It's a stupidly simple question, and probably innately obvious but I can't find anything concrete anywhere. So please excuse my ignorance on the subject as I pretty much blinked through the existence of bluray until now.\n  \n\n    TLDR: Can you view media burned on a bdxl in a standard home theater style bluray player?"},
{"Title": "Seagate Sent Me a Hard Drive", "Author": "u/Yummychickenblue", "Content": "Earlier this year I RMAd a hard drive to Seagate, and they sent out a replacement. Today I got another drive of the same model, with a return packing slip. I never got an email about it, and there's no record in my account of ordering it. I spoke with Seagate support and they say the serial number is for a new hard drive, and their best guess is that a friend got it for me (lol). What should I do with it? My name is on the billing statement, so I don't wanna be charged"},
{"Title": "Digitally archiving a museum space", "Author": "u/Majestic-Owl-5801", "Content": "I am trying to digitally archive a museum being torn down, and possibly make a 3d walkthrough of it.\n  \n\n    I will have high res photos of the items and the placards, and will have Insta360 x3 footage of the interior walking around. I also plan to use my iPhone 12pro to make a LiDAR file of the interior space.\n  \n\n    TLDR: ITC in San Antonio being torn down, trying to 3D document and archive it all.\n  \n\n    Any pointers or tips are appreciated!"},
{"Title": "Looking for advice on ways to organize media folder", "Author": "u/worlock_", "Content": "Hello, I have quite a large collection of media (around 9TB worth).\n  \n\n    I spent time creating a folder structure to organize all the files by studio, creator, favorites, etc. on my 8TB drive. Of course, not enough space on that single drive for new media, so it just piles up on random folders. I don't mind getting another dedicated drive - but I'm trying to see what kinds of file systems and organization might be better.\nI'm trying to avoid having to create the same file structure on the second drive to organize new media.\n  \n\n    Ideally, I'm trying to understand if there's a solution that I can use to create an organization that is expandable, meaning that I can just create folders, and if I need more space, I can just add more storage drives. Is this like a RAID system?\n  \n\n    i'm pretty rookie when it comes to advanced storage options so I appreciate any help!"},
{"Title": "SSD in Sabrent enclosure is plugged into an ALWAYS ON USB 2.0 port on Micca Speck G2 TV box, is this possibly decreasing the life of the sata SSD compared to if the USB powered off when the box is off?", "Author": "u/Bern_Down_the_DNC", "Content": "Just making sure that theTeamgroup EX2 sata SSD is going to sleep, either because of it's own firmware or because of the enclosure when the TV box is off but USB port is still powered on. (Unfortunately there is no firmware based options for powering off the port with the box, and no firmware updates.)\n  \n\n    Thank you."},
{"Title": "Raid 0 Array (1TB HDDs x 2) with 8TB HDD for Backups", "Author": "u/Low-Writing3449", "Content": "I've found myself processing 4K video and am needing more performance than my single 8TB HDD can deliver.  As a result, I looked into RAID 0 to boost performance, but I don't want to be SOL if one of my drives fail.  I don't have the money to be purchasing more 8TB drives, so my thought is to use two 1TB HDDs for a RAID 0 array to be used while I'm editing, then use the 8TB HDD for backups.\n  \n\n    Any thoughts on this?  Any good way to ensure my data is being backed up onto the 8TB drive as new data is written to the RAID 0 Array?\n  \n\n    Also, if it matters, I'm on a Win 11 PC.\n  \n\n    Thanks in advance!"},
{"Title": "Google Workspace Storage is a Scam", "Author": "u/truecolourpainting", "Content": "Google Workspace Storage Scam\n\n\n\n    Google is scamming millions of consumers by reducing the storage space they paid for and forcing them to a new subscription that's 500% more expensive. Worse, they continue to charge for the old storage space.\n  \n\n    I've had a Google Workspace account for 8 years. Despite paying for cloud storage, Google is now refusing to provide the service. A supervisor admitted on a recorded call that they will not honor the storage plan I paid for over the past 8 years, even though they still charge me. This is blatant fraud, and Google seems to think they're above the law.\n  \n\n    They stripped me of my storage and demanded I pay a 500% price increase plus a fee per user. If I don't comply, they'll delete all my 1TB of data and close my account. This new policy and contract were never agreed upon by me, despite my 8-year loyalty.\n  \n\n    This is how mega-corporations treat consumers, and the government does nothing to stop them. Google is committing fraud on a massive scale, as admitted by their supervisor.\n  \n\n    I've decided to go public, sell all my Google shares, and urge others to dump Google stock. Let's see how they react to a boycott.\n  \nGoogleFraud #GoogleScam #BoycottGoogle #ConsumerRights #CorporateGreed #TechScam #GoogleWorkspaceScam"},
{"Title": "Odroid HC2 - APM (Advanced Power Managment)", "Author": "u/mikesmith929", "Content": "Using an Odroid HC2 with a Western Digital 6TB WD Red NAS drive\n  \n\n    I have Open Media Vault installed on it via Armbian Bookworm.\n  \n\n    I ran \nsudo hdparm -B /dev/sda\n\n\n\n    And the hard drive says I have no APM support for spindown.\n  \n\n    I've asked in the Odroid forum about how to spindown hard drives \"properly\" they suggested using hd-idle.\n  \n\n    But that opens the question if I \nshould even be spinning down the hard drives\n?\n  \n\n    This Odroid will be my offsite backup, plus my Nextcloud server. Backups to and from the hard drive will run every day and of course random nextcloud access, whenever I need something from the \"cloud\".\n  \n\n    I have two other 4 bay NAS's one the primary server for \"videos\" while the other is my backup of \"videos\" plus backup of my computer data.\n  \n\n    The video NAS is accessed say a couple times a day and my local backup server is backed up daily\n  \n\n    So I have say 9 drives all Western Digital Reds NAS drives.\n  \n\n    What is the consensus here about spinning down the drives? Should I bother or just leave them as they are? What are the pros and cons?\n  \n\n    Thanks for any help you can give.\n  \n\n    I did search for spindown but didn't find much."},
{"Title": "I cannot connect to my NAS from Windows, but I can from everything else. I've been stuck for hours and I cannot think of where else to look.", "Author": "u/Insulifting", "Content": "Aplogoies if this isn't the right sub, I'm not sure where else to ask.\n  \n\n    I've started to dabble in setting up some NAS using an spare Raspbery Pi 4 (I know it's not the most effective but I wanted to see if I could at least get it running with some small storage before I splurge), and I'm able to connect on most devices except my main desktop. I can't work out why, but it's clearly something on my desktops configuration that's stopping it.\n  \n\n    The odd thing is I can SSH into it just fine, works like a charm, when I try to map the network drive and enter the credentials it just puts me back to the enter credentials screen and I know for a fact they're correct since I'm using them to SSH into it.\n  \n\n    Would anyone have any suggestions? I've tried changing firewall settings, disabling anti-virus, and changing NTLM connection settings in Group Policy as per a forum I found but none of that worked."},
{"Title": "Bypass Google Drive download prevention", "Author": "u/BrolyBoy", "Content": "Is there a way to properly download photos you have access to but not prevented downloading?\n  \n\n    There’s an artist that puts up images in Drive but prevents downloading but I do want to save them in case they take it down.\n  \n\n    I know that you can obtain parts of the photo by using the Inspect tabs, but I also want to easily and quickly bulk download the images. I’ve also looked on YouTube but the closest they get is bypassing the download limit using the Starred folder, which does not work when applied to “download prevented” files."},
{"Title": "Lto tape budget archive", "Author": "u/Lord_Of_ReBass", "Content": "I need some kind of cheap data setup for my movies and music.  It’s getting outta hand fast and I’ve been curious about lot tape. Been noticing you can get lto 5-6 drive pretty reasonable and the cartridges are a steal compared to my 3.5in hdd. Would this be a viable option for movies I don’t watch often and only access once in a while. Make a copy of it and watch the copy or something. I just need some kind of reliable budget friendly storage. And I have a 10tb drive alr."},
{"Title": "Immich", "Author": "u/steviefaux", "Content": "Anyone heard of this? Seems Louis Rossmann as got them to join Futo now. Have always trusted Louis. He had the app GrayJay develop, all open source and free but if you want you can pay. I'm cheap and even I've paid for a GrayJay license.\n  \n\n    Looks like this is the exact same model. Will be free but they'd rather you also pay if you can.\n  \n\n\nhttps://www.youtube.com/watch?v=F_2oydlnpCQ"},
{"Title": "OS does not see HP LSI SAS 1078 MegaRaid", "Author": "u/awesomefreeman", "Content": "I received this board with the LTO-3 streamer. Trying to connect it in PCI-e slot, but system does not detect the board. Tried it on Windows 7, 10, Proxmox and It does not appear in the terminal or device manager.. The board is heating up, I don’t see any external damage.\n  \n\n    Is it dead?\n  \n\n    Motherboard - B150M \nPro4V\n · \nASRock\n\n\n\n\nCPU-\n Intel Pentium G4400\n  \nhttps://preview.redd.it/os-does-not-see-hp-lsi-sas-1078-megaraid-v0-k79u1hjsmg0d1.jpg\nhttps://preview.redd.it/os-does-not-see-hp-lsi-sas-1078-megaraid-v0-7szh17ihmg0d1.png"},
{"Title": "How to securely erase Sandisk Extreme Pro before selling?", "Author": "u/stevecondy123", "Content": "I read \nhere\n that:\n  \n\n\n\n    The only way to truly erase data on an SSD is to use the ATA Secure Erase commands.\n  \n\n\nQuestion: how do I do that for Sandisk Extreme Pro (I'm on macOS).\n\n    I found a similar question asked \nhere\n, but I was hoping for answers that I could either run in the terminal (not a VM) or click-ops (e.g. macOS would have some built-in way as it does for spinning HDD's)."},
{"Title": "Duplex scanners that show measurements in scan???", "Author": "u/Stevealot", "Content": "Has anyone ever heard of this? I’m looking for something like a ruler on the side and top that would show the both dimensions of the item scanned. Is this an option on any scanner? It would save me so much time and could be a game changer for me. Thanks for your help!"},
{"Title": "soon i will be archiving a whole lot of betamax tape, will my setup be fine for digitizing?", "Author": "u/dankestofstolenmemes", "Content": "No content"},
{"Title": "Best strategy for using 2x1TB & 1x2TB SSD for hoarding purposes", "Author": "u/gizia", "Content": "edit\n: \nall of them are SSDs, I mentioned in the title\n\n\n\n    hello, guys. I'm needing help to utilize those SSDs to archive, protect, and keep copy of data and software.\nPlease also consider the following:\n  \n\n\n\n\n\n    Encryption\n  \n\n\n\n\n\n    Preserving data integrity\n  \n\n\n\n\n\n    Most important data will be 500GB at most\n  \n\n\n\n\n\n    I've Windows PC, but I can afford Mac\n  \n\n\n\n\n\n    Recommended Tools/Software for managing data"},
{"Title": "Is there a basic way to check for corruption in files you've had in storage/ use? (basic questions from newb)", "Author": "u/Sesemebun", "Content": "So I have always hated forgetting or losing things, moreso than the average person. I buy books I like, write down the names of things, and will soon be converting my physical media (vhs/dvd/etc) to digital to have it in multiple places. I assume most here are of the same mindset as me, though maybe more dedicated. After being thoroughly confused by the wiki, and combing through old posts, I thought I should just ask a few questions.\n  \n\n    I don't really need help with the actual copying part, there are plenty of guides out there (makeMKV seems to be the best suggestion for DVDs in this sub, according the wiki). I have also looked around for the actual storage device. I don't have enough data to be worth getting a server rack, and the more \"manual\" forms seem slow  (like mdisc) since I plan to tap into these fairly often. What I will end up doing is probably having a couple USB drives, each with a copy of my \"cache\" of stuff, be it photos or movies or games or whatnot. Probably every 5 years I will just copy everything over to a new drive, to counteract any kind of physical deterioration with the drive (my research seems to point that they are finnicky when it comes to how long they can last). These caches will be large enough to not be worth combing through every time I copy stuff to check it works. At the time that I transfer the data, is there any kind of non-invasive software I can run the files through to make sure they are still readable? Because I don't want to go to look at a photo and see that 10 years ago it got corrupted and is gone.\n  \n\n    TL;DR\n  \n\n    I want to keep my stuff on USB drives to access often, but replace every 5 years. What can I do to ensure I don't lose whatever is on the drives? Or are there better options for this scenario than a flash drive?\n  \n\n    (Thank you for your help, but please keep terminology and such on a low level, I am not my grandfather, but I am not super well versed with this kind of stuff)"},
{"Title": "Can't find VideoID for BrightCove player video", "Author": "u/Karlox2", "Content": "I'm trying to download the video embeded in this page: \nhttps://video.repubblica.it/spettacoli-e-cultura/angelina-mango-e-l-urlo-liberatorio-alla-finale-dell-eurovison-il-video-dal-backstage/469184/470138\n\n\n\n    I followed the URL template method but with no luck since I couldn't find the video id when opening the brightcove player menu. Can anyone help me out?"},
{"Title": "DIY vs. PreBuilt NAS (total noob question)", "Author": "u/NY-RatFucker", "Content": "Hi everyone. Need some help.\n  \n\n    I want to get a nas to backup my pc’s data (movies, music, videos, family photos, etc). Would also like to be able to access it remotely. I need about 8 tb of storage, think I may need more down the road but probably not.\n  \n\n    I am very familiar with pc building and thought about just building one myself with one of my old pcs lying around (2 drives in RAID1 on an old i3 workstation pc).\n  \n\n    But I’m also reading how simple and easy the pre builts are, is it worth it to just get a 2 or 4 bay synology or the like and use that?\n  \n\n    I am not too concerned about budget but I wouldn’t mind a cheap DIY if it would be a fun project to learn.\n  \n\n    Any help would be great, just need some guidance"},
{"Title": "How to batch download from PIXIV without pixivutil?", "Author": "u/Cr4zko", "Content": "I run Windows 8.1 and that doesn't let me use pixivutil anymore. So sad."},
{"Title": "can get WD Cloud OS products for -60%. is it worth it ?", "Author": "u/Exatio", "Content": "Specifically these\n  \n\n\nMy Cloud Home\n\n\n\n\nMy Cloud Expert Series EX2 Ultra\n\n\n\n    Knowing the security breach stuff & the fact that the OS is to be discontinued very soon, should I get them or no, and if yes what can I do with these without risking anything ?"},
{"Title": "Best YT channels/videos for NAS setup and use for complete beginners? HELP ME PLS", "Author": "u/husker3in4", "Content": "Hey all, I need a storage solution, I have external drives for my data overload, but I want something always on and always connected to my computer. I don't quite understand how a NAS works or all the cool things it can do, but what I do like, from what I'm reading, is that the NAS can provide parity protection if I choose SHR during setup, right? I will use 4 disks, in one of the 4 bay NAS from Synology.\n  \n\n    The other thing: I want the NAS to show up in my File Explorer (Windows 10), like the whole NAS. I keep seeing people talk about their home folder, and that you can map your home folder to your File Explorer, but I want to see the whole NAS on my File Explorer, so I can click it like another drive, and drag and drop files to the main NAS or into my home folder.\n  \n\n    BTW, this is strictly for home use, just myself on it. Given that knowledge, what is the difference between putting folders on the main directory of the NAS vs into my home folder? Is there some security or performance advantage or disadvantage to one or the other? I think I understand the purpose of the home folder, is to keep several users files separated and private from each other, but again, it will just be me on the NAS.I had my son set up Plex on my PC, and I am reading this is something that can run on the NAS as well, so I might do that too if I can figure it out. Other than that, I just need to transfer files back and forth to the NAS via File Explorer, sometimes files that are 10 or 20gb in size. I admit I'm a data hoarder so if this NAS can work in this way, I'd likely set up different folders for all of my data overflow that won't fit on my computer's internal drives.\n  \n\n    I understand how Windows 10 works as a home user but again, I'm a complete newbie to networking and NAS, and get confused pretty quickly when I start reading about all the advanced options and even get lost watching videos about all the seemingly millions of settings, security etc.Who do you recommend for YT videos explaining how it works, easy way to set it up and run for home use, single user etc? I looked at the Space Rex guy already. I don't know if It's how he presents the information or what but I can't follow him very well.The one thing I got from SpaceRex is that is he way smarter than I am, and he offers a service to set it up but for $300 an hour! If I were to find someone who could do it for a much more reasonable price, is that wise, or am I asking for trouble?The movie War Games from the 80s keeps flashing thru my mind, when they find the original programmer who snuck in thru a \"backdoor\" left in the system in case he needed to get back in...."},
{"Title": "Book Scanning: A guide about light?", "Author": "u/DontAskForTheMoon", "Content": "Hi. Imagine a very simple set up, a book opened 180° on a table and being scanned by a phone from above, also 180° (usually just the necessary pages and not the whole book, but they can be still like 100+ pages at times). No extra programs, just normal photos.\n  \n\n    I recently struggle heavily with especially modern scientific books. Their paper is not made of trees anymore, but they feel like thin plastic - the same material as most magazines are made of.\n  \n\n    Those magazine-like pages have a heavily disgusting light reflection potential. How exactly could I configure the light (like angle and its strength) to reduce those reflections? (Post-processing to black and white isn't possible, since those books contain coloured images, so I want to keep the original colours as they are)\n  \n\n    I already looked for setups, most of them are very professional and they have professional cameras etc. They also just use light on each page with desk-lamps. But it never looked like they are using special lens filters.\n  \n\n    If there is no way to reduce reflection with basic methods (like angle and strength of light, or phone camera settings), then my last option would be Polarizing Gel. But if there were solutions without extra costs, I would prefer them."},
{"Title": "Size of SLC dynamic cache as for Samsung 980 Pro", "Author": "u/Biyeuy", "Content": "Have seen one opinion that Samsung 980 SSD has dynamic SLC whose size reaches high percentage of drive storage capacity. Size remarkably higher than in case of for instance 970 EVO Plus.\n  \n\n    Any idea / knowledge if same applies to 980PRO?  1 and 2 TB drives under consideration."},
{"Title": "UPDATE: Dagobah ARCHIVED! Should I post to archive.org?", "Author": "u/TheAllPurposePopo", "Content": "No content"},
{"Title": "Does anyone know a method to download threads from a mybb forum?", "Author": "u/zuperfly", "Content": "Sometimes an account is required too"},
{"Title": "help simulating bitrod", "Author": "Unknown author", "Content": "good afternoon,\n  \n\n    i would like to test mdadm/raid/zfs and need to simulate bitrod (like this video) any idea how can i do it?\n  \n\n    thank you\n  \n\n\nhttps://www.youtube.com/watch?v=l55GfAwa8RI&list=WL&index=1"},
{"Title": "What's the best way to clone a secondary drive?", "Author": "u/PioApocalypse", "Content": "I hoard a lot of data on my secondary 3 TB HDD, some of which is not even backed-up as it's not really \nthat\n important. Now my drive is failing and I've bought a new one to replace it.\n  \n\n    The old drive was formatted in NTFS for use with both Linux (Mint) and Windows, while the new one (also 3 TB) will probably be formatted in BTRFS (there's an unofficial driver for Win10-11). I'd like to copy the data \nas-is\n - including meta-data - from the old drive to the new one.\n  \n\n    Can I even use Clonezilla if the filesystem is different on source and destination partitions? Would it be better to use \ndd\n or straight up \ncp -a\n?\nIn short how do I do it?"},
{"Title": "The Birth, Boom and Bust of the Hard Disk Drive", "Author": "u/the320x200", "Content": "https://youtu.be/yt5t84Z7u_I?si=CFJpCK4HOnhGgRqY\n\n\n\n    Nice mealtime video going through HDD history."},
{"Title": "Storage for portable hard drives?", "Author": "u/eldomtom2", "Content": "I have several portable hard drives. I was wondering if anyone on this subreddit knew anything about storage racks etc. to keep portable drives organised."},
{"Title": "Backing up my cloud drive (Linux, rclone, btrfs?)", "Author": "u/Wild_Ribbon", "Content": "So far I tested my luck having all my family pictures in a single pCloud drive. On my way to 3-2-1 I decided to improve that by having a local clone of it (another cloud backup once I decide which one you buy), and I have questions on how to do that safely and efficiently. Most Google searches give me cloud offerings or full OS backup with lots of tinkering.\n  \n\n    I have around 250gb of data collected over several years, so I don't expect it to grow super fast, and it's only me adding pictures every other week or so. I bought a 1tb external disk to do the backups. My local disk do not have all of the data, the only place that have it in its entirety is pCloud.\n  \n\n    I use Ubuntu and I'm not a guru, so I'm looking for a solution that is reasonably easy, to avoid having a backup that I couldn't figure out how to restore. And for now I intend to backup myself every month or so, then later I can add a cron job or something.\n  \n\n    First, to take the data out of pCloud I tested rclone and it seemed to work great. I can do a sync with it to add and eventually remove pictures I excluded from pCloud, maybe use interactive mode to ensure nothing is being inadvertently deleted (at least while I use it interactive mode). Suggestions on this?\n  \n\n    Second and my greatest doubt, how to store it in the disk? I'd like something with incremental backups, and that ideally adds some layer of protection against disk degradation, data corruption and such. I came across BTRFS and it sounded like a natural fit. I can format the disk with it, then do  periodic snapshots, then maybe a full backup every once in a while. Any good suggestion on how to do that, filesystem flags to enable, something instead of BTRFS, etc? Also, what's a good way to know that the backups are working properly?"},
{"Title": "I can't download from Mediafire with JDownloader", "Author": "u/RayquazaAndDeoxysFan", "Content": "Help, I can't seem to download the folder with JDownloader, whenever I add the link I get this file \"Content offline!shared\" what should I do?\n  \n\n    Also, the link has the file ID's separated by commas."},
{"Title": "External HDD timing out - need advice", "Author": "u/Ok_Video8420", "Content": "The issue:\n\n\n\n    I've been trying to back up some files from an old 4TB external hard drive. This drive had been unaccessed for a few years; a few months ago, I put about 500GB onto the drive and there were no issues. However, now as I'm trying to manually clone the drive to create a duplicate, the drive is having issues. Read times are slow and Task Manager says the drive is constantly being written to; my PC always detects the drive when I plug it in, but it sometimes times out before I can actually open the drive. At other times, I can access the drive and it will copy files over, but slowly. As well, if the drive is plugged in when I try to turn off the computer, the PC will stall before turning off and I've had to manually press the power button to shut it off. Finally, I've seen the following errors pop up as I've tried to access the drive/copy files:\n  \n\n\n\n\n\n    Location Not Available - Data Error (cyclic redundancy check)\n  \n\n\n\n\n\n    Drive is not accessible - The parameter is incorrect\n  \n\n\n\n\n\n    Error 0x80070079 - The Semaphore Timeout period has expired\n  \n\n\n\n\n\n    Can't read from the source file or disk\n  \n\n\n\n\n\n\nAttempted troubleshooting:\n\n\n\n    I tried running CHKDSK but it also wouldn't run (which, as I've done more research, seems like the wrong solution). No physical issues that I can detect (just a normal hum, no clicks or anything), and changing cables doesn't help. Lastly, it seems like if I let the drive rest for a few days, the drive runs closer to normal.\n  \n\n    Can anyone provide insight into what's going on, and/or provide a solution? Most of the drive I believe is already duplicated in other locations, but unfortunately there's about 100GB that's probably not backed up anywhere else. Thanks!"},
{"Title": "Are all USB connected enclosures unreliable?", "Author": "u/Bern_Down_the_DNC", "Content": "Recently I posted about trying to avoid individual encosures. The drive can come loose inside if you move it in/out of a storage box, they can overheat badly if the fan stops working, etc.\n  \n\n    (\nhttps://www.reddit.com/r/DataHoarder/comments/1cq41rj/ive_had_it_with_individual_external_enclosures/\n)\nI wanted to use sata to usb adapters with an open frame because it would be easier to add drives (while enclosures have a max number of slots and you have to buy a larger enclosure if you need more).\n  \n\n    This was met with people saying that is the worst way to do it and that they have a high chance of errors, random disconnects, and shared bandwith. And instead I should get a 4 slot enclosure. But I've read the reviews on the models that people suggested.... and they all seem to have those same problems.\n  \n\n    Here is a thread from 3 years ago where people are talking about multi-slot enclosures corrupting drives. (\nhttps://www.reddit.com/r/DataHoarder/comments/oty6em/any_recommendations_for_a_simple_nonraid_4_bay_35/\n)\n  \n\n    A couple comments did mention that esata seems to be more reliable than usb. But I wanted to get more opinions - can usb multi-slot enclosures be reliable? I don't want to do raid. I just want to sync the same files across 2 drives for media library, and 2 more drives for personal files. I will just be tranferring 10 gigs or so per month to one drive, then copying to the twin, then verifying the data.\n  \n\n    Should I give up on enclosures? Or do I just need to buy a good usb cable to prevent random disconnects? If enclosures can't be reliable for important data, should I set up a server and then transfer over the local network? I'm open to esata  but I only have a regular sata port on the motherboard, so I would need a pcie adapter.\n  \n\n    Thanks for reading."},
{"Title": "Current pending sector count errors, into dead drive 2 days later?", "Author": "u/DumbUnemployedLoser", "Content": "So, just to give some context as to how my luck has been, a couple of months ago, I had a hard drive showing signs of failure. I rushed to buy a new drive and landed on a 6TB WD drive [WD60EFPX], which I paid a decent penny for [pc parts are expensive here]. I managed to get most of the data out of the old drive into the new one, the old drive actually died at the tail end of the backup process, but ok, I still managed to get most of the data out.\n  \n\n    Fast forward to last saturday, 2 months later. Something I left downloading overnight wasn't finished when I woke up and was giving a cycling redundancy error. I checked CrystalDiskInfo and there it was, Current Pending Sector count at 200.\n  \n\n    Then I decided to order an external hard drive so that I could backup the most critical stuff and fully format the drive. A few hours before the external HDD gets here, the WD hard drive dies and my PC won't boot with it plugged, at all. It will show up in the bios, but that's about it.\n  \n\n    I'm assuming it's over? Any chance at all that this could be something else? bad sata port? bad sata cable? Moody hard drive lol? I've already started the RMA procedure, just waiting to hear back from the company.\n  \n\n    In hindsight I should have taken the 2 hour drive to buy the external drive in person. I live kind of remotely, anything PC related requires a trip. But I got lazy and that's what happens. This is the first time a piece of hardware just up and fails on me within 2 months of use. I guess it's bound to happen at some point."},
{"Title": "Using HBA SAS card as SAS target?", "Author": "u/fernandolcx", "Content": "Sorry if this is a dumb question, but I was thinking about the meaning of \"IT firmware\" as \"Initiator/Target\" in storage terminology.\n  \n\n    Let's say I want to build my own SAS-attached DAS.\n  \n\n    Does this means, for example, that I'm able to create software-defined volumes and expose these virtual \"drives\" using SAS bus/protocol and attach to another server, say, with one DELL H200E?"},
{"Title": "Nas advice , >Gbe, Link Aggregation", "Author": "u/Spacemole", "Content": "I need some networking help. I had a Synology DS916+ (8GB), with 4 x 8 TB ironwolves in raid 5 (SHR). It died (won’t power on, power cable seems fine), and now I need a new NAS. I am also looking to optimise my small network to increase the usability of the NAS.\nI use two laptops ( Mac and Windows) and try to keep all my files on the NAS rather than on the devices. I fly drones and often have to transfer a few hundred gigabytes on and off the NAS for storage or editing videos. I have generally been disappointed with the transfer speeds of the old unit over Gbe.\n  \n\n    I created a scuffed \ndiagram\n of my network. I would love to make my own NAS and get homeassistant off the old laptop that runs it, but my apartment is small. I have been looking at the \nDS923+\n, \nDS1522+\n and \nDS1621+\n. The latter has an extra bay, and two extra GbE ports.\n  \n\n    Is upgrading any of these things going to help me with transfer speeds for my use cases:\n(Transferring large files, editing from the NAS, Steam remote play)\n  \n\n    1 - Either NAS being much faster due to the processor.\n2 - Using link aggregation on the NAS, with a new compatible Gbe switch (and the benefits of 2 vs. 4 Gbe ports).\n3 - Using link aggregation on my laptops via 2x ethernet connections to the switch, with an extra Gbe dongle.\n3 - Buying a 2.5Gbe switch, (with link aggregation?).\n4 - Buying a 2.5Gbe USB C dongle ( and also potentially using link aggrigation).\n5 - Buying the (expensive) 10Gbe module for either DiskStation.\n6 - Adding different name drives to these more modern NAS.\n  \n\n    I am willing to use a number of these solutions, such as buying a 2.5 switch and dongle, running 4xGbe link aggregation on the NAS, and using 2 cables from my laptop on a new switch.\n  \n\n    I am unsure how effective any of this will be. If anyone can shed some light on this stuff, or give advice on these NAS, I would appreciate it."},
{"Title": "Help us DataHoarder, you're our only hope...", "Author": "u/CriticalMemory", "Content": "Hey folks, thanks for reading.  I'm hopeful this doesn't go too far awry of rule 8.\n  \n\n    Several of my friends and I have been trying without a lot of success to mirror a PHPBB that's about to get shut down.  So far, we've either gathered too much data, or too little using HTTRack.  Our last run had nearly 700GB for ~70k posts on the bulletin board, while our first attempts only captured the top level links.  We know this is a lack of knowledge on our part, but we're running out of time to experiment to dial this in.  We've reached out to the company who is running the PHPBB to try to get them to work with us, and are still hopeful we can do that, but for the moment self-servicing seems like our only option.\n  \n\n    It's important to us to save this because it's a lot of historical and useful information for an RPG we play (called Dungeon Crawl Classics).  The company is migrating to discord for all of it's discussions, but for someone who just wants to go read on topics, that's not so helpful.  The site itself is \nhttps://goodman-games.com/forum/\n\n\n\n    We're stuck.  Can anyone help us out or give us some pointers? Hell, I'm even willing to put money towards this to get an expert to help, but because I don't know exactly what to ask for know that could go sideways pretty easily.\n  \n\n    Thanks in advance!"},
{"Title": "Interesting GitHub Repositories", "Author": "u/BellLongworth", "Content": "I discovered \nStacks Project\n over at GitHub. Also see \nthe webpage\n.\n  \n\n    Git repositories of this kind are easy to hoard and some could be very interesting. Personally I'm interested less in backing up all kinds of code packages, but more in knowledge bases like stacks.\n  \n\n    Anything else you guys can recommend?"},
{"Title": "A program that I can use to automatically index files of a certain format within a directory tree into an excel file or something similar?", "Author": "u/thebigscorp1", "Content": "Right now I have a huge folder tree with all the Youtube videos (20k+) I've downloaded over the years. They're sorted into video genre and YT channels and such.\n  \n\n    All the videos have the date at the front and the YT id at the back. I'd like for a program to automatically index them all into something like an excel folder, and to be able to append new videos (whether automatically or every time I run the script).\n  \n\n    You'd have columns like video length, size, file path, uploader, link to original video, availability of original video, and such. I'd like for all this info to be able to change with each script use."},
{"Title": "Have these HDD's been delivered properly?", "Author": "u/TrollingJoker", "Content": "I'm working on building a storage server and I bought 3 HDD's from Amazon but they were delivered in a plastic bag with each HDD individually packaged in an anti static bag with thin bubble wrap. It seemed okay but they can easily get knocked around in the bag.\n  \n\n    Is this normal? I expected a box along with the anti static bags and bubble wrap.\n  \n\n    [Edit] Amazon was both seller and shipper in this transaction."},
{"Title": "Docker container user permissions", "Author": "u/BDB-ISR-", "Content": "I followed OMV-extras' \nmanual\n to create a docker container for deluge (bt client). They recommend for security reasons to use a different user in it's own group for each container.\n  \n\n    The thing is shared folders are created as belonging to root/users, to which the container user has no permissions. Setting the user to have rw on the shared folders from OMV's web UI did nothing (not sure how it's suppose to since it's not owning or part of the owning group). The only way to fix this was to add the user to the shares' ACL. This just feels wrong, also that's not as described in the manual. Without the ACL, deluge is unaware of the permissions issue (since on the container side it's root), but nothing is downloaded or uploaded and trying to move storage location leads to errors.\n  \n\n    Is the manual wrong or did I miss something?\n  \n\n    Edit: Ps. with the ACL, downloaded files are created as owned by container-user / users, which is odd since the container user is not part of users, but at least that works for accessing via users' members."},
{"Title": "Is there a 3.5 HDD case that turns off and on with the PC?", "Author": "u/Automatic_Ad_621", "Content": "As per the title, is there an external box for HDD 3.5 (2bay) that turns on and off together with the PC to which it is connected?"},
{"Title": "Best Sata expansion card at this time?", "Author": "u/Heinosity11", "Content": "Hey all,\n  \n\n    So yea I did look first at some recent posts, but didnt find any super recent. I have a mobo with 6 onboard SATA ports and now need more because i need to increase my storage. I use windows 10 (yea i know its not unraid/truenas etc). I am not very excited of the options out there, but maybe im not looking in the right place. Btw, the card doesnt need to be RAID compliant...Just need it to not have IO errors and work correctly lol. Looking for maybe a 6 port card, but could do with a 4...And yes I have a pcie 3x4 slot for the expansion card on my mobo that doesnt conflict bandwidth with other things. From amazon I found this one by \"IO Crest\" (tried to link the page, but i think my post got removed for that-sorry huge reddit noob). Seems better then most because it has a 4.4 star review and lots of reviews...Another question I have though is which chipset is the best/most reliable? Looking at just this sale page there are JMB, MV and ASM. Obviously there could be others I am unaware of. Price really isnt a huge concern in the sense that if I can get a super tried and true/industry standard one for a little more i definitely would be down to do that. Anyways, thank you in advance for ur guys wisdom. I honestly was also debating swapping the drives with those 30tb seagate mozaic drives that are about to come out, but im not too keen on being the very first adopter.. Any other input or wisdom is always welcome! :) :)"},
{"Title": "Any notebook [2.5] hdd with more than 4TB?", "Author": "u/pilifida", "Content": "Hello all, i am a photo and video hoarder and i am starting to lack space on my laptop. I have an M2 ssd coupled with a 2TB WD 2.5 hdd in it. Those 2tb are for photos and videos only but now it.s getting full. Any advice for a 2.5 hdd with at least 4TB (i trust WD, somehow i distrust samsung and seagate - but couldn.t find any WD notebook 4tb hdds)? As i constantly edit my photos and videos i prefer an \"inner\" solution, not an external hdd - i already have 3 of those but they are only for backup. Any advice is wellcomed. Thx!"},
{"Title": "While everyone else struggles with Amazon Chinese 'TV to PC' garbage for analog capture, I just got the real king for CAD$20 at a flea market.  The old man asked me 'what is it?' after he accepted my money.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "HBA LSI Card Control Panel, Is There One?", "Author": "u/Rodnys_Danger666", "Content": "Does a hba card have a Control Panel and do I need software to do that? My card came Pre-Flashed. I bought one from AoS 2 years ago. And it works. My HDDs are plugged in and working fine. I have 3 new hdd I'm going to install after I do some research into what I find out here. They are going to replace 3 older drives of different sizes. There will be 6 hdd overall, 42 TB overall, less Useable.\n  \n\n    I figure it's time to step my server game up and see if I can control the hdd thru the hba card. I've seen some on yt use software to customize things. Mine will be for movies and music only. No gaming.\n  \n\n    This is a HTPC. it's all it does. Movies and Music. Stored in the hdd and streaming both. No gaming, no webz, except for streaming. I'm not using any kind of storage software for RAID  of any kind.\n  \n\n    Is it worth it to control things thru the card or just let windows do things?\n  \n\n\n\n\n\n    6TB WD Reds x3, 2TB, 4TB WD Blue? x2. replacing 2&4 tb w/ 8 TBx3 Seagate barracuda\n  \n\n\n\n\n\n\nGenuine LSI 6Gbps SAS HBA LSI 9201-8i (=9211-8i) P20 IT Mode ZFS FreeNAS unRAID\n\n\n\n\n\n\n\n    i5-11400 Win 11 Pro\n  \n\n\n\n\n\n    Z590M Pro4\n  \n\n\n\n\n\n    64GB ram\n  \n\n\n\n\n\n    4070 Ti Super"},
{"Title": "Insane brain scan file sizes in the future...", "Author": "u/d7e7r7", "Content": "Full scan of \n1 cubic millimeter\n of brain tissue took \n1.4 petabytes of data\n - \ntechspot\n\n\n\n    We did the back-of-napkin math on what ramping up this experiment to the entire brain would cost, and the scale is impossibly large - \n1.6 zettabytes of storage costing $50 billion and spanning 140 acres\n, making it the largest data center on the planet. - \nTom's Hardware\n\n\nhttps://preview.redd.it/insane-brain-scan-file-sizes-in-the-future-v0-8cd5g3st1vzc1.jpg"},
{"Title": "Size of SLC dynamic cache as for Samsung 980 Pro", "Author": "u/Biyeuy", "Content": "Have seen one opinion that Samsung 980 SSD has dynamic SLC whose size reaches high percentage of drive storage capacity. Size remarkably higher than in case of for instance 970 EVO Plus.\n  \n\n    Any idea / knowledge if same applies to 980PRO?  1 and 2 TB drives under consideration."},
{"Title": "UPDATE: Dagobah ARCHIVED! Should I post to archive.org?", "Author": "u/TheAllPurposePopo", "Content": "No content"},
{"Title": "Does anyone know a method to download threads from a mybb forum?", "Author": "u/zuperfly", "Content": "Sometimes an account is required too"},
{"Title": "help simulating bitrod", "Author": "Unknown author", "Content": "good afternoon,\n  \n\n    i would like to test mdadm/raid/zfs and need to simulate bitrod (like this video) any idea how can i do it?\n  \n\n    thank you\n  \n\n\nhttps://www.youtube.com/watch?v=l55GfAwa8RI&list=WL&index=1"},
{"Title": "What's the best way to clone a secondary drive?", "Author": "u/PioApocalypse", "Content": "I hoard a lot of data on my secondary 3 TB HDD, some of which is not even backed-up as it's not really \nthat\n important. Now my drive is failing and I've bought a new one to replace it.\n  \n\n    The old drive was formatted in NTFS for use with both Linux (Mint) and Windows, while the new one (also 3 TB) will probably be formatted in BTRFS (there's an unofficial driver for Win10-11). I'd like to copy the data \nas-is\n - including meta-data - from the old drive to the new one.\n  \n\n    Can I even use Clonezilla if the filesystem is different on source and destination partitions? Would it be better to use \ndd\n or straight up \ncp -a\n?\nIn short how do I do it?"},
{"Title": "The Birth, Boom and Bust of the Hard Disk Drive", "Author": "u/the320x200", "Content": "https://youtu.be/yt5t84Z7u_I?si=CFJpCK4HOnhGgRqY\n\n\n\n    Nice mealtime video going through HDD history."},
{"Title": "Storage for portable hard drives?", "Author": "u/eldomtom2", "Content": "I have several portable hard drives. I was wondering if anyone on this subreddit knew anything about storage racks etc. to keep portable drives organised."},
{"Title": "Backing up my cloud drive (Linux, rclone, btrfs?)", "Author": "u/Wild_Ribbon", "Content": "So far I tested my luck having all my family pictures in a single pCloud drive. On my way to 3-2-1 I decided to improve that by having a local clone of it (another cloud backup once I decide which one you buy), and I have questions on how to do that safely and efficiently. Most Google searches give me cloud offerings or full OS backup with lots of tinkering.\n  \n\n    I have around 250gb of data collected over several years, so I don't expect it to grow super fast, and it's only me adding pictures every other week or so. I bought a 1tb external disk to do the backups. My local disk do not have all of the data, the only place that have it in its entirety is pCloud.\n  \n\n    I use Ubuntu and I'm not a guru, so I'm looking for a solution that is reasonably easy, to avoid having a backup that I couldn't figure out how to restore. And for now I intend to backup myself every month or so, then later I can add a cron job or something.\n  \n\n    First, to take the data out of pCloud I tested rclone and it seemed to work great. I can do a sync with it to add and eventually remove pictures I excluded from pCloud, maybe use interactive mode to ensure nothing is being inadvertently deleted (at least while I use it interactive mode). Suggestions on this?\n  \n\n    Second and my greatest doubt, how to store it in the disk? I'd like something with incremental backups, and that ideally adds some layer of protection against disk degradation, data corruption and such. I came across BTRFS and it sounded like a natural fit. I can format the disk with it, then do  periodic snapshots, then maybe a full backup every once in a while. Any good suggestion on how to do that, filesystem flags to enable, something instead of BTRFS, etc? Also, what's a good way to know that the backups are working properly?"},
{"Title": "I can't download from Mediafire with JDownloader", "Author": "u/RayquazaAndDeoxysFan", "Content": "Help, I can't seem to download the folder with JDownloader, whenever I add the link I get this file \"Content offline!shared\" what should I do?\n  \n\n    Also, the link has the file ID's separated by commas."},
{"Title": "External HDD timing out - need advice", "Author": "u/Ok_Video8420", "Content": "The issue:\n\n\n\n    I've been trying to back up some files from an old 4TB external hard drive. This drive had been unaccessed for a few years; a few months ago, I put about 500GB onto the drive and there were no issues. However, now as I'm trying to manually clone the drive to create a duplicate, the drive is having issues. Read times are slow and Task Manager says the drive is constantly being written to; my PC always detects the drive when I plug it in, but it sometimes times out before I can actually open the drive. At other times, I can access the drive and it will copy files over, but slowly. As well, if the drive is plugged in when I try to turn off the computer, the PC will stall before turning off and I've had to manually press the power button to shut it off. Finally, I've seen the following errors pop up as I've tried to access the drive/copy files:\n  \n\n\n\n\n\n    Location Not Available - Data Error (cyclic redundancy check)\n  \n\n\n\n\n\n    Drive is not accessible - The parameter is incorrect\n  \n\n\n\n\n\n    Error 0x80070079 - The Semaphore Timeout period has expired\n  \n\n\n\n\n\n    Can't read from the source file or disk\n  \n\n\n\n\n\n\nAttempted troubleshooting:\n\n\n\n    I tried running CHKDSK but it also wouldn't run (which, as I've done more research, seems like the wrong solution). No physical issues that I can detect (just a normal hum, no clicks or anything), and changing cables doesn't help. Lastly, it seems like if I let the drive rest for a few days, the drive runs closer to normal.\n  \n\n    Can anyone provide insight into what's going on, and/or provide a solution? Most of the drive I believe is already duplicated in other locations, but unfortunately there's about 100GB that's probably not backed up anywhere else. Thanks!"},
{"Title": "Are all USB connected enclosures unreliable?", "Author": "u/Bern_Down_the_DNC", "Content": "Recently I posted about trying to avoid individual encosures. The drive can come loose inside if you move it in/out of a storage box, they can overheat badly if the fan stops working, etc.\n  \n\n    (\nhttps://www.reddit.com/r/DataHoarder/comments/1cq41rj/ive_had_it_with_individual_external_enclosures/\n)\nI wanted to use sata to usb adapters with an open frame because it would be easier to add drives (while enclosures have a max number of slots and you have to buy a larger enclosure if you need more).\n  \n\n    This was met with people saying that is the worst way to do it and that they have a high chance of errors, random disconnects, and shared bandwith. And instead I should get a 4 slot enclosure. But I've read the reviews on the models that people suggested.... and they all seem to have those same problems.\n  \n\n    Here is a thread from 3 years ago where people are talking about multi-slot enclosures corrupting drives. (\nhttps://www.reddit.com/r/DataHoarder/comments/oty6em/any_recommendations_for_a_simple_nonraid_4_bay_35/\n)\n  \n\n    A couple comments did mention that esata seems to be more reliable than usb. But I wanted to get more opinions - can usb multi-slot enclosures be reliable? I don't want to do raid. I just want to sync the same files across 2 drives for media library, and 2 more drives for personal files. I will just be tranferring 10 gigs or so per month to one drive, then copying to the twin, then verifying the data.\n  \n\n    Should I give up on enclosures? Or do I just need to buy a good usb cable to prevent random disconnects? If enclosures can't be reliable for important data, should I set up a server and then transfer over the local network? I'm open to esata  but I only have a regular sata port on the motherboard, so I would need a pcie adapter.\n  \n\n    Thanks for reading."},
{"Title": "Current pending sector count errors, into dead drive 2 days later?", "Author": "u/DumbUnemployedLoser", "Content": "So, just to give some context as to how my luck has been, a couple of months ago, I had a hard drive showing signs of failure. I rushed to buy a new drive and landed on a 6TB WD drive [WD60EFPX], which I paid a decent penny for [pc parts are expensive here]. I managed to get most of the data out of the old drive into the new one, the old drive actually died at the tail end of the backup process, but ok, I still managed to get most of the data out.\n  \n\n    Fast forward to last saturday, 2 months later. Something I left downloading overnight wasn't finished when I woke up and was giving a cycling redundancy error. I checked CrystalDiskInfo and there it was, Current Pending Sector count at 200.\n  \n\n    Then I decided to order an external hard drive so that I could backup the most critical stuff and fully format the drive. A few hours before the external HDD gets here, the WD hard drive dies and my PC won't boot with it plugged, at all. It will show up in the bios, but that's about it.\n  \n\n    I'm assuming it's over? Any chance at all that this could be something else? bad sata port? bad sata cable? Moody hard drive lol? I've already started the RMA procedure, just waiting to hear back from the company.\n  \n\n    In hindsight I should have taken the 2 hour drive to buy the external drive in person. I live kind of remotely, anything PC related requires a trip. But I got lazy and that's what happens. This is the first time a piece of hardware just up and fails on me within 2 months of use. I guess it's bound to happen at some point."},
{"Title": "Using HBA SAS card as SAS target?", "Author": "u/fernandolcx", "Content": "Sorry if this is a dumb question, but I was thinking about the meaning of \"IT firmware\" as \"Initiator/Target\" in storage terminology.\n  \n\n    Let's say I want to build my own SAS-attached DAS.\n  \n\n    Does this means, for example, that I'm able to create software-defined volumes and expose these virtual \"drives\" using SAS bus/protocol and attach to another server, say, with one DELL H200E?"},
{"Title": "Nas advice , >Gbe, Link Aggregation", "Author": "u/Spacemole", "Content": "I need some networking help. I had a Synology DS916+ (8GB), with 4 x 8 TB ironwolves in raid 5 (SHR). It died (won’t power on, power cable seems fine), and now I need a new NAS. I am also looking to optimise my small network to increase the usability of the NAS.\nI use two laptops ( Mac and Windows) and try to keep all my files on the NAS rather than on the devices. I fly drones and often have to transfer a few hundred gigabytes on and off the NAS for storage or editing videos. I have generally been disappointed with the transfer speeds of the old unit over Gbe.\n  \n\n    I created a scuffed \ndiagram\n of my network. I would love to make my own NAS and get homeassistant off the old laptop that runs it, but my apartment is small. I have been looking at the \nDS923+\n, \nDS1522+\n and \nDS1621+\n. The latter has an extra bay, and two extra GbE ports.\n  \n\n    Is upgrading any of these things going to help me with transfer speeds for my use cases:\n(Transferring large files, editing from the NAS, Steam remote play)\n  \n\n    1 - Either NAS being much faster due to the processor.\n2 - Using link aggregation on the NAS, with a new compatible Gbe switch (and the benefits of 2 vs. 4 Gbe ports).\n3 - Using link aggregation on my laptops via 2x ethernet connections to the switch, with an extra Gbe dongle.\n3 - Buying a 2.5Gbe switch, (with link aggregation?).\n4 - Buying a 2.5Gbe USB C dongle ( and also potentially using link aggrigation).\n5 - Buying the (expensive) 10Gbe module for either DiskStation.\n6 - Adding different name drives to these more modern NAS.\n  \n\n    I am willing to use a number of these solutions, such as buying a 2.5 switch and dongle, running 4xGbe link aggregation on the NAS, and using 2 cables from my laptop on a new switch.\n  \n\n    I am unsure how effective any of this will be. If anyone can shed some light on this stuff, or give advice on these NAS, I would appreciate it."},
{"Title": "Help us DataHoarder, you're our only hope...", "Author": "u/CriticalMemory", "Content": "Hey folks, thanks for reading.  I'm hopeful this doesn't go too far awry of rule 8.\n  \n\n    Several of my friends and I have been trying without a lot of success to mirror a PHPBB that's about to get shut down.  So far, we've either gathered too much data, or too little using HTTRack.  Our last run had nearly 700GB for ~70k posts on the bulletin board, while our first attempts only captured the top level links.  We know this is a lack of knowledge on our part, but we're running out of time to experiment to dial this in.  We've reached out to the company who is running the PHPBB to try to get them to work with us, and are still hopeful we can do that, but for the moment self-servicing seems like our only option.\n  \n\n    It's important to us to save this because it's a lot of historical and useful information for an RPG we play (called Dungeon Crawl Classics).  The company is migrating to discord for all of it's discussions, but for someone who just wants to go read on topics, that's not so helpful.  The site itself is \nhttps://goodman-games.com/forum/\n\n\n\n    We're stuck.  Can anyone help us out or give us some pointers? Hell, I'm even willing to put money towards this to get an expert to help, but because I don't know exactly what to ask for know that could go sideways pretty easily.\n  \n\n    Thanks in advance!"},
{"Title": "Interesting GitHub Repositories", "Author": "u/BellLongworth", "Content": "I discovered \nStacks Project\n over at GitHub. Also see \nthe webpage\n.\n  \n\n    Git repositories of this kind are easy to hoard and some could be very interesting. Personally I'm interested less in backing up all kinds of code packages, but more in knowledge bases like stacks.\n  \n\n    Anything else you guys can recommend?"},
{"Title": "A program that I can use to automatically index files of a certain format within a directory tree into an excel file or something similar?", "Author": "u/thebigscorp1", "Content": "Right now I have a huge folder tree with all the Youtube videos (20k+) I've downloaded over the years. They're sorted into video genre and YT channels and such.\n  \n\n    All the videos have the date at the front and the YT id at the back. I'd like for a program to automatically index them all into something like an excel folder, and to be able to append new videos (whether automatically or every time I run the script).\n  \n\n    You'd have columns like video length, size, file path, uploader, link to original video, availability of original video, and such. I'd like for all this info to be able to change with each script use."},
{"Title": "Have these HDD's been delivered properly?", "Author": "u/TrollingJoker", "Content": "I'm working on building a storage server and I bought 3 HDD's from Amazon but they were delivered in a plastic bag with each HDD individually packaged in an anti static bag with thin bubble wrap. It seemed okay but they can easily get knocked around in the bag.\n  \n\n    Is this normal? I expected a box along with the anti static bags and bubble wrap.\n  \n\n    [Edit] Amazon was both seller and shipper in this transaction."},
{"Title": "Docker container user permissions", "Author": "u/BDB-ISR-", "Content": "I followed OMV-extras' \nmanual\n to create a docker container for deluge (bt client). They recommend for security reasons to use a different user in it's own group for each container.\n  \n\n    The thing is shared folders are created as belonging to root/users, to which the container user has no permissions. Setting the user to have rw on the shared folders from OMV's web UI did nothing (not sure how it's suppose to since it's not owning or part of the owning group). The only way to fix this was to add the user to the shares' ACL. This just feels wrong, also that's not as described in the manual. Without the ACL, deluge is unaware of the permissions issue (since on the container side it's root), but nothing is downloaded or uploaded and trying to move storage location leads to errors.\n  \n\n    Is the manual wrong or did I miss something?\n  \n\n    Edit: Ps. with the ACL, downloaded files are created as owned by container-user / users, which is odd since the container user is not part of users, but at least that works for accessing via users' members."},
{"Title": "Is there a 3.5 HDD case that turns off and on with the PC?", "Author": "u/Automatic_Ad_621", "Content": "As per the title, is there an external box for HDD 3.5 (2bay) that turns on and off together with the PC to which it is connected?"},
{"Title": "Best Sata expansion card at this time?", "Author": "u/Heinosity11", "Content": "Hey all,\n  \n\n    So yea I did look first at some recent posts, but didnt find any super recent. I have a mobo with 6 onboard SATA ports and now need more because i need to increase my storage. I use windows 10 (yea i know its not unraid/truenas etc). I am not very excited of the options out there, but maybe im not looking in the right place. Btw, the card doesnt need to be RAID compliant...Just need it to not have IO errors and work correctly lol. Looking for maybe a 6 port card, but could do with a 4...And yes I have a pcie 3x4 slot for the expansion card on my mobo that doesnt conflict bandwidth with other things. From amazon I found this one by \"IO Crest\" (tried to link the page, but i think my post got removed for that-sorry huge reddit noob). Seems better then most because it has a 4.4 star review and lots of reviews...Another question I have though is which chipset is the best/most reliable? Looking at just this sale page there are JMB, MV and ASM. Obviously there could be others I am unaware of. Price really isnt a huge concern in the sense that if I can get a super tried and true/industry standard one for a little more i definitely would be down to do that. Anyways, thank you in advance for ur guys wisdom. I honestly was also debating swapping the drives with those 30tb seagate mozaic drives that are about to come out, but im not too keen on being the very first adopter.. Any other input or wisdom is always welcome! :) :)"},
{"Title": "Any notebook [2.5] hdd with more than 4TB?", "Author": "u/pilifida", "Content": "Hello all, i am a photo and video hoarder and i am starting to lack space on my laptop. I have an M2 ssd coupled with a 2TB WD 2.5 hdd in it. Those 2tb are for photos and videos only but now it.s getting full. Any advice for a 2.5 hdd with at least 4TB (i trust WD, somehow i distrust samsung and seagate - but couldn.t find any WD notebook 4tb hdds)? As i constantly edit my photos and videos i prefer an \"inner\" solution, not an external hdd - i already have 3 of those but they are only for backup. Any advice is wellcomed. Thx!"},
{"Title": "While everyone else struggles with Amazon Chinese 'TV to PC' garbage for analog capture, I just got the real king for CAD$20 at a flea market.  The old man asked me 'what is it?' after he accepted my money.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "HBA LSI Card Control Panel, Is There One?", "Author": "u/Rodnys_Danger666", "Content": "Does a hba card have a Control Panel and do I need software to do that? My card came Pre-Flashed. I bought one from AoS 2 years ago. And it works. My HDDs are plugged in and working fine. I have 3 new hdd I'm going to install after I do some research into what I find out here. They are going to replace 3 older drives of different sizes. There will be 6 hdd overall, 42 TB overall, less Useable.\n  \n\n    I figure it's time to step my server game up and see if I can control the hdd thru the hba card. I've seen some on yt use software to customize things. Mine will be for movies and music only. No gaming.\n  \n\n    This is a HTPC. it's all it does. Movies and Music. Stored in the hdd and streaming both. No gaming, no webz, except for streaming. I'm not using any kind of storage software for RAID  of any kind.\n  \n\n    Is it worth it to control things thru the card or just let windows do things?\n  \n\n\n\n\n\n    6TB WD Reds x3, 2TB, 4TB WD Blue? x2. replacing 2&4 tb w/ 8 TBx3 Seagate barracuda\n  \n\n\n\n\n\n\nGenuine LSI 6Gbps SAS HBA LSI 9201-8i (=9211-8i) P20 IT Mode ZFS FreeNAS unRAID\n\n\n\n\n\n\n\n    i5-11400 Win 11 Pro\n  \n\n\n\n\n\n    Z590M Pro4\n  \n\n\n\n\n\n    64GB ram\n  \n\n\n\n\n\n    4070 Ti Super"},
{"Title": "Insane brain scan file sizes in the future...", "Author": "u/d7e7r7", "Content": "Full scan of \n1 cubic millimeter\n of brain tissue took \n1.4 petabytes of data\n - \ntechspot\n\n\n\n    We did the back-of-napkin math on what ramping up this experiment to the entire brain would cost, and the scale is impossibly large - \n1.6 zettabytes of storage costing $50 billion and spanning 140 acres\n, making it the largest data center on the planet. - \nTom's Hardware\n\n\nhttps://preview.redd.it/insane-brain-scan-file-sizes-in-the-future-v0-8cd5g3st1vzc1.jpg"},
{"Title": "Converting Hi8 tape of father to digital!", "Author": "u/audioyay", "Content": "Hi! So I was just given a Sony TRV67 Camcorder with a Hi8 tape that has a video of my father reading a bed time story to my sister and I when we were babies. He passed away a few years ago and when I saw this tape I bawled like a baby. I am pretty good with tech but all of this is pretty before my time. I looked at the megathread here and have done some research online but I still feel lost. I want to convert this tape to digital so that I can send it to my sister who lives across the country. Any suggestions would help me a lot. I don't have very much money and I'd probably only really convert this tape and any others that crop up. Sorry if this post is against the rules, I really am just clueless here"},
{"Title": "A Working Twitter Media Gallery Viewer without login?", "Author": "u/SherbetTiger", "Content": "There used to be tons of these but twitpic and sotwe are gone now ever since musk took over twitter."},
{"Title": "Download Video for Personal Use", "Author": "u/Necessary_Handle_614", "Content": "I am trying to download Videos from \ntabii.com\n for personal use but I am unable to download it if anyone can help?"},
{"Title": "Collect/export ~500 TikTok comments in one spreadsheet (the tools online have a 200 comment limit)", "Author": "u/worcestershiresauce-", "Content": "Hey :)\n  \n\n    I want to put comments from under a tiktok video into a spreadsheet. Ive asked for favourite recipes and got over 500 so i want to put them in a list to randomly pick ones to try out.\n  \n\n    Started putting the Comments in a List by hand and after a looong time almost went insane and had barely any comments added. I then looked for tools online but only found ones that have a limit of 50, 100 or 200. Everything over that costs a fee and i am currently not that well off money wise to justify spending money for exporting comments while cutting down basically everywhere in life right now.\n  \n\n    If anyone knows a free tool, website etc. that can export 537 comments and save my sanity i would be the happiest girl alive!\n  \n\n    Thank you in advance"},
{"Title": "USB enclosures and drive letters", "Author": "u/8trackthrowback", "Content": "I’m not ready for NAS but was considering a 4-bay usb enclosure. Let’s say I put 4 drives in it: when I plug it into a windows machine does it come up as 4 different drive letters?\n  \n\n    This would be good because then if I’m doing a periodic manual backup I know how to put the data on separate drives.\n  \n\n    Or when I plug it in do all 4 “combine” into one drive letter?\n  \n\n    This would be easier for stuff like Plex but then how would I backup without knowing where it’s going?"},
{"Title": "Amateur Prebuilt Raid/ZFS Solutions?", "Author": "u/AquaticTree", "Content": "Hey reddit! I've been running through posts here and having trouble identifying a simple solution for preserving data integrity on 1 or 2 5tb hard drives (both would have backups at a friend's house).\n  \n\n    Are there ready-made solutions to just get raid and zfs (is zfs a form of raid or an additional process?) working for these drives without going through building a system out and learning commands?\n  \n\n    More speficically delving into zfs(what I assume to be the preferred method of corruption protection) is coming up with a set of incomprehensible computer jargon that I'm having a difficult time wrapping my head around. Are the consumer oriented prebuilt raid setups using this by default? How difficult is getting zfs running on one of these for someone not proficient in coding or online command usage?"},
{"Title": "Bulk downloading archive.org URLs of a site?", "Author": "u/AndrewTatesCumshot", "Content": "Hi, there is this website on archive.org that I'm looking to download all of its files. The page where you get the calendar results and then go to URLs, where you get multiple pages of files listed which you can sort by date, search by type, etc, and you have to click each one of them, which would then lead you to the calendar page again and you have to seek a date that has a download link. This particular one has thousands and it would take forever.\n  \n\n    Is there some kind of program or browser extension that could just grab all of the links and start downloading the files for me? I searched for such and found a post where somebody recommended JDownloader but I don't think it's meant for the job I'm looking to be done, or at least I have no idea how to use it for this particular purpose. Any suggestions?"},
{"Title": "Robocopy or Mirror for photography/videographer backups", "Author": "u/MontereyBayPortraits", "Content": "Hello all! I currently have 5TB worth of data and have been using Robocopy every night to backup to a second drive.  I just bought 2x 18TB Western Digitals and am debating over using Robocopy again, or using Windows Raid 1 to mirror the drives.  I am wary of a direct mirror in that it will duplicate any deletion I do to the main drive.  My current Robocopy script doesn't copy any deletions to the second drive which make me feel safer.  Any thought on which method I should use going forward?\n  \n\n    Heres my current script to backup my E: drive to my D: drive every evening\n  \n\n    cmd /k ROBOCOPY E: D: /E /MT /R:3 /W:5 /NS /NC /NFL /NDL /NP /XD /xd \"System Volume Information \" E:\\SoftwareInstalls E:\\SteamLibrary E:\\$RECYCLE.BIN\\ /LOG+:\\Robocopy\\log.txt pause"},
{"Title": "M-Disc questions.", "Author": "u/Pacman_Frog", "Content": "I feel like M-Disc is my best option for some backups outside of having discs pressed.\n  \n\n    That said, someone walk me through M-Disc? I would like to get real, solid M-Disc DVDs, CD's, Blurays. DO 8GB inkjet DVD exist? What is the equivalent 100gb bluray? Do m-disc cd's even exist?"},
{"Title": "cost effective solution to high bandwidth, medium volume storage", "Author": "u/2pointWinner", "Content": "I'm in a predicament that requires an enormous amount of footage that I refuse to have less than one backup of. I'm making and having to store about 40-50gb of footage per day for three and a half months. It is being edited into five segments of about equal length. Each segment will be edited in sequential order so footage stored will only need to be retrieved/stored every couple of months.\n  \n\n    I have about 600GB of storage on a M.2 that I will be editing off of that will act as temporary storage while I edit. (aka: can't be used as a backup)\n  \n\n    Here are the drives I have:\n1TB high speed HDD (80% full, plugged directly into desktop)\n6TB medium speed HDD (10% full, plugged directly into desktop)\n2x4TB WD Red NAS HDD (not plugged in, waiting to be used)\n  \n\n    I would be wildly uncomfortable having this footage in less than two places, as I'm sure many of you in this sub would understand.\n  \n\n    Should I buy \nsomething like this\n? Will that provide enough bandwidth for my predicament?"},
{"Title": "New drives keep falling", "Author": "u/FaceMRI", "Content": "I bought 3 new Seagate HDD 5TB drives\n  \n\n    I have 4 million files ( 200 GB). I've lost 2 new drives already each in the same way. The files start copying over ( on the 2nd or 3rd) day the drives stop working, and copying fails.\n  \n\n    Finder DiskUtilty says disks are corrupted. The source of trush Disk is now dead, and I only have about 40% of my data on a 2nd disk.\n  \n\n    60% data is now lost and 300$ and days of backing up wasted. And getting back that list data is about 400$.\n  \n\n    Is Seagate just junk ? I'm so angry lol"},
{"Title": "Looking for shockproof/drop proof single 3.5\" hard drive case/enclosure that connects with regular SATA", "Author": "u/lintstah1337", "Content": "Most case/enclosure I see uses USB, but I want SATA (not eSATA)"},
{"Title": "How to attach host's (Linux) optical drive to a (Windows) VM in virt-manager?", "Author": "u/2299165976", "Content": "I'm running Windows 11 in \nvirt-manager\n on Fedora 40. Windows 11 installed without any additional configuration, but I can't get my SATA blu-ray drive detected in the VM. I have to use various Windows-only ripping tools, some of which don't run in Wine to any degree.\n  \n\n    The closest I got is with \nRedhat's documentation\n, but the block device  \n/dev/sr0\n doesn't appear to be visible to Windows after adding the device in the VM settings.\n  \n\n    virt-manager 4.1.0"},
{"Title": "WFDownloader: How to download all media from page link of a certain pattern?", "Author": "u/ideas_r_bulletproof", "Content": "Say I have 100 page links of this pattern: \nexample.com/page/<pagenumber>\n\n\n\n    How do I download media from all those pages? I can go the batch links route but I have to type the link 100 times. Eg: \nexample.com/page/1, ... example.com/page/100\n.\n  \n\n    Or, I can go the crawler route but then again it crawls the entire website,  \nexample.com/*\n, not just \nexample.com/page/<pagenumber>\n.\n  \n\n    What I want: I want to say download all media from these pages: \nexample.com/page/[1-100]\n.\n  \n\n    How can I do it?"},
{"Title": "figured out how to mount a drive into the OG pixel", "Author": "u/master-hax", "Content": "i wanted to increase the longevity of the flash storage in my pixel, so i mounted an external drive into it\n  \n\n\npicture\n\n\n\n    next step: remove the battery...\n  \n\n    EDIT: \nhttps://github.com/master-hax/pixel-backup-gang"},
{"Title": "what would be the recommended drive size limit for Raid5", "Author": "u/deliverator216", "Content": "I have a Terramaster F4-210 that I only use for storage for Plex (PMS is on a separate machine) I understand that Raid5 is not recommended for large drive sizes, but for the moment, the Terramaster is what I've got.\n  \n\n    How big of a drive can I put in and still be able to run recovery safely? I do have a backup so I'm not that worried about the data, I'm worried about having an unexpected additional drive expense.\n  \n\n    thoughts?"},
{"Title": "Wikipedia Archive Including Past Revisions?", "Author": "u/PumpALump", "Content": "I know that it's possible to download an archive of just the text of Wikipedia that's about 50 GB, but before I try downloading it, I figure I'd at least ask here if it includes the previous revisions of every given page, or just the latest one?\n  \n\n    I'd like an archive that includes all the past revisions."},
{"Title": "Just found out I have unlimited G drive storage and am trying to figure out how to use it with my Home-lab. Any ideas?", "Author": "u/Dat_Cool_Guy33", "Content": "Okay I'll try to explain the situation as best I can. I've always wanted to get into Data Hoarding but storing things on Local Physical Media isn't really possible for me at the moment. However, I do have a Basic Home lab setup with a Raspberry pi and a GMKtek Mini PC. The Raspberry Pi  has been set up as a \nPi Hosted\n Home Lab. So as a little makeshift NAS, I hooked up a 2TB SSD to it and upload / download data to it through a File Browser container that points to it. Unfortunately no redundancy at all.\n  \n\n    Then, Just today, I remembered my Old College account was still accessible and has unlimited storage available (or at least more than I'll ever use rn). So Here's what I'm thinking....is there any way to link my GDrive to my Home-lab NAS? specifically I would like some sort of system where it kind of acts like a one-drive or g drive for desktop relationship where my local nas is the client and my Gdrive is the cloud storage server.\n  \n\n    Basically I want this to be my flow of data:\n  \n\n\n\n\n\n    I store data on my Nas and whatever I use regularly stays on there\n  \n\n\n\n\n\n    Regularly my Local NAS is backed up and fully and securely encrypted to G-Drive\n  \n\n\n\n\n\n    Over time if I'm not using a file for lets say 30 days or so, The Nas storage used for that file gets cleared but if I want to access it later,  my Nas can just pull it from G-Drive, unencrypt it, and make it available to me again.\n  \n\n\n\n\n\n    My gut is telling me there's some system out there that can do what I'm looking for but I'm not sure what it would be.\n  \n\n    Also side note, I know that Duplicati and Rclone are a thing but I have other people that use my NAS for storage already and I want to keep it easy to manage where I don't have to dig through TB's of archives to pull a specific file their looking for or something.\n  \n\n    TL;DR: Is there any way for me to combine my existing NAS with my unlimited G-Drive account and link it up in the same way Onedrive for desktop can sync files to a client machine when being used and unsync files when not being used and keep them on G-Drive? With good encryption if possible because I'm paranoid of google having that much of my data lol?"},
{"Title": "$1/TB find at local Bin Store", "Author": "u/bozey07", "Content": "No content"},
{"Title": "Toshiba Refurb Hard Drive Numbering", "Author": "u/joetaxpayer", "Content": "I am considering buying refurb drives. Server Part Deals has \"MD08ACA16TR\" which they list as an enterprise drive, 16TB. But I looked at the Toshiba web site and there is no mention of this model number.\n  \n\n    Does Server Part Deals re-number drives to their own numbering? Is this just an MG series Toshiba drive?"},
{"Title": "Nintendo Switch files corrupt after recovering them from odd deletion.", "Author": "u/AfricanToilet", "Content": "Hello, all.\n  \n\n    Because the Nintendo Switch gives the option to screenshot and create 30-second long videos; I did that compulsively whilst I was playing 'Breathe of the Wild' (And other games, too, but not as many).\n  \n\n    Because I tend to be a digital hoarder, I keep them all neat in folders on my External Hard Drive. Every video and image I took on my Switch still resides there.\n  \n\n    Somehow (And I still don't know this happened because I didn't do anything) a couple of the folders got deleted and permanently removed. I obviously 'downloaded' a recovery software and got them all back, BUT; nothing having to do with soft or hardware can go smoothy - there's always [at least] one difficulty:\nThe files are now corrupt.\n  \n\n    Every video and image I took from 'Breath of the Wild' are now corrupt.\n  \n\n    How did this happen and how can I uncorrupt them, please?\n  \n\n    Many thanks in advance my life is in shambles.\n  \n\n    OS: MacOSX 10.13 High Sierra"},
{"Title": "I've had it with individual external enclosures. What's the best way to power my external setup without 4 wall warts?", "Author": "u/Bern_Down_the_DNC", "Content": "I want to be able to run 4 3.5\" drives at once. I need to power 4 of these sata to usb adapters (SABRENT USB 3.2 Type A to SATA/U.2 SSD Adapter Cable with 12V/2A Power Supply [EC-U2SA])\n  \n\n    I'd like to be able to just plug it in with 1 cord into the outlet instead of having to figure out how to plug in 4 wall warts. So I need a 1 plug to 4 dc jack (5.4mm) to reliably power all four at once. The wall wart that comes with the sabrent adapter says 2A 24W.\n  \n\n    Bonus points for suggestions on ways to make each hard drive have an individual power switch.\n  \n\n    Thank you!"},
{"Title": "downloading video streams divided into parts?", "Author": "u/unwissend2001", "Content": "When streaming sites use mp4 files directly you can download them per developer tools in the network tab.\n  \n\n    Many video hosting sites use ts or xhr format to stream videos divided in many small chunks.\n  \n\n    How do download them?"},
{"Title": "Digitizing PAL Video8 using OBS yields a 5:4 aspect ratio?", "Author": "u/YAZEED-IX", "Content": "I'm using s-video to USB to digitize PAL video8 tapes I have. From what I can see by testing different Canvas resolutions (setting the the height at 1080 as I plan on uploading it to YouTube), the height most appropriate is 1350 — shouldn't it be 1440 to produce 4:3 aspect ratio? When I try to do this I get extra black bars on the sides."},
{"Title": "Archive Discord Group Chats to another Server channel", "Author": "u/lurkintheair", "Content": "No content"},
{"Title": "Converting Hi8 tape of father to digital!", "Author": "u/audioyay", "Content": "Hi! So I was just given a Sony TRV67 Camcorder with a Hi8 tape that has a video of my father reading a bed time story to my sister and I when we were babies. He passed away a few years ago and when I saw this tape I bawled like a baby. I am pretty good with tech but all of this is pretty before my time. I looked at the megathread here and have done some research online but I still feel lost. I want to convert this tape to digital so that I can send it to my sister who lives across the country. Any suggestions would help me a lot. I don't have very much money and I'd probably only really convert this tape and any others that crop up. Sorry if this post is against the rules, I really am just clueless here"},
{"Title": "A Working Twitter Media Gallery Viewer without login?", "Author": "u/SherbetTiger", "Content": "There used to be tons of these but twitpic and sotwe are gone now ever since musk took over twitter."},
{"Title": "Download Video for Personal Use", "Author": "u/Necessary_Handle_614", "Content": "I am trying to download Videos from \ntabii.com\n for personal use but I am unable to download it if anyone can help?"},
{"Title": "Collect/export ~500 TikTok comments in one spreadsheet (the tools online have a 200 comment limit)", "Author": "u/worcestershiresauce-", "Content": "Hey :)\n  \n\n    I want to put comments from under a tiktok video into a spreadsheet. Ive asked for favourite recipes and got over 500 so i want to put them in a list to randomly pick ones to try out.\n  \n\n    Started putting the Comments in a List by hand and after a looong time almost went insane and had barely any comments added. I then looked for tools online but only found ones that have a limit of 50, 100 or 200. Everything over that costs a fee and i am currently not that well off money wise to justify spending money for exporting comments while cutting down basically everywhere in life right now.\n  \n\n    If anyone knows a free tool, website etc. that can export 537 comments and save my sanity i would be the happiest girl alive!\n  \n\n    Thank you in advance"},
{"Title": "USB enclosures and drive letters", "Author": "u/8trackthrowback", "Content": "I’m not ready for NAS but was considering a 4-bay usb enclosure. Let’s say I put 4 drives in it: when I plug it into a windows machine does it come up as 4 different drive letters?\n  \n\n    This would be good because then if I’m doing a periodic manual backup I know how to put the data on separate drives.\n  \n\n    Or when I plug it in do all 4 “combine” into one drive letter?\n  \n\n    This would be easier for stuff like Plex but then how would I backup without knowing where it’s going?"},
{"Title": "Amateur Prebuilt Raid/ZFS Solutions?", "Author": "u/AquaticTree", "Content": "Hey reddit! I've been running through posts here and having trouble identifying a simple solution for preserving data integrity on 1 or 2 5tb hard drives (both would have backups at a friend's house).\n  \n\n    Are there ready-made solutions to just get raid and zfs (is zfs a form of raid or an additional process?) working for these drives without going through building a system out and learning commands?\n  \n\n    More speficically delving into zfs(what I assume to be the preferred method of corruption protection) is coming up with a set of incomprehensible computer jargon that I'm having a difficult time wrapping my head around. Are the consumer oriented prebuilt raid setups using this by default? How difficult is getting zfs running on one of these for someone not proficient in coding or online command usage?"},
{"Title": "Bulk downloading archive.org URLs of a site?", "Author": "u/AndrewTatesCumshot", "Content": "Hi, there is this website on archive.org that I'm looking to download all of its files. The page where you get the calendar results and then go to URLs, where you get multiple pages of files listed which you can sort by date, search by type, etc, and you have to click each one of them, which would then lead you to the calendar page again and you have to seek a date that has a download link. This particular one has thousands and it would take forever.\n  \n\n    Is there some kind of program or browser extension that could just grab all of the links and start downloading the files for me? I searched for such and found a post where somebody recommended JDownloader but I don't think it's meant for the job I'm looking to be done, or at least I have no idea how to use it for this particular purpose. Any suggestions?"},
{"Title": "Robocopy or Mirror for photography/videographer backups", "Author": "u/MontereyBayPortraits", "Content": "Hello all! I currently have 5TB worth of data and have been using Robocopy every night to backup to a second drive.  I just bought 2x 18TB Western Digitals and am debating over using Robocopy again, or using Windows Raid 1 to mirror the drives.  I am wary of a direct mirror in that it will duplicate any deletion I do to the main drive.  My current Robocopy script doesn't copy any deletions to the second drive which make me feel safer.  Any thought on which method I should use going forward?\n  \n\n    Heres my current script to backup my E: drive to my D: drive every evening\n  \n\n    cmd /k ROBOCOPY E: D: /E /MT /R:3 /W:5 /NS /NC /NFL /NDL /NP /XD /xd \"System Volume Information \" E:\\SoftwareInstalls E:\\SteamLibrary E:\\$RECYCLE.BIN\\ /LOG+:\\Robocopy\\log.txt pause"},
{"Title": "M-Disc questions.", "Author": "u/Pacman_Frog", "Content": "I feel like M-Disc is my best option for some backups outside of having discs pressed.\n  \n\n    That said, someone walk me through M-Disc? I would like to get real, solid M-Disc DVDs, CD's, Blurays. DO 8GB inkjet DVD exist? What is the equivalent 100gb bluray? Do m-disc cd's even exist?"},
{"Title": "cost effective solution to high bandwidth, medium volume storage", "Author": "u/2pointWinner", "Content": "I'm in a predicament that requires an enormous amount of footage that I refuse to have less than one backup of. I'm making and having to store about 40-50gb of footage per day for three and a half months. It is being edited into five segments of about equal length. Each segment will be edited in sequential order so footage stored will only need to be retrieved/stored every couple of months.\n  \n\n    I have about 600GB of storage on a M.2 that I will be editing off of that will act as temporary storage while I edit. (aka: can't be used as a backup)\n  \n\n    Here are the drives I have:\n1TB high speed HDD (80% full, plugged directly into desktop)\n6TB medium speed HDD (10% full, plugged directly into desktop)\n2x4TB WD Red NAS HDD (not plugged in, waiting to be used)\n  \n\n    I would be wildly uncomfortable having this footage in less than two places, as I'm sure many of you in this sub would understand.\n  \n\n    Should I buy \nsomething like this\n? Will that provide enough bandwidth for my predicament?"},
{"Title": "New drives keep falling", "Author": "u/FaceMRI", "Content": "I bought 3 new Seagate HDD 5TB drives\n  \n\n    I have 4 million files ( 200 GB). I've lost 2 new drives already each in the same way. The files start copying over ( on the 2nd or 3rd) day the drives stop working, and copying fails.\n  \n\n    Finder DiskUtilty says disks are corrupted. The source of trush Disk is now dead, and I only have about 40% of my data on a 2nd disk.\n  \n\n    60% data is now lost and 300$ and days of backing up wasted. And getting back that list data is about 400$.\n  \n\n    Is Seagate just junk ? I'm so angry lol"},
{"Title": "Looking for shockproof/drop proof single 3.5\" hard drive case/enclosure that connects with regular SATA", "Author": "u/lintstah1337", "Content": "Most case/enclosure I see uses USB, but I want SATA (not eSATA)"},
{"Title": "How to attach host's (Linux) optical drive to a (Windows) VM in virt-manager?", "Author": "u/2299165976", "Content": "I'm running Windows 11 in \nvirt-manager\n on Fedora 40. Windows 11 installed without any additional configuration, but I can't get my SATA blu-ray drive detected in the VM. I have to use various Windows-only ripping tools, some of which don't run in Wine to any degree.\n  \n\n    The closest I got is with \nRedhat's documentation\n, but the block device  \n/dev/sr0\n doesn't appear to be visible to Windows after adding the device in the VM settings.\n  \n\n    virt-manager 4.1.0"},
{"Title": "WFDownloader: How to download all media from page link of a certain pattern?", "Author": "u/ideas_r_bulletproof", "Content": "Say I have 100 page links of this pattern: \nexample.com/page/<pagenumber>\n\n\n\n    How do I download media from all those pages? I can go the batch links route but I have to type the link 100 times. Eg: \nexample.com/page/1, ... example.com/page/100\n.\n  \n\n    Or, I can go the crawler route but then again it crawls the entire website,  \nexample.com/*\n, not just \nexample.com/page/<pagenumber>\n.\n  \n\n    What I want: I want to say download all media from these pages: \nexample.com/page/[1-100]\n.\n  \n\n    How can I do it?"},
{"Title": "figured out how to mount a drive into the OG pixel", "Author": "u/master-hax", "Content": "i wanted to increase the longevity of the flash storage in my pixel, so i mounted an external drive into it\n  \n\n\npicture\n\n\n\n    next step: remove the battery...\n  \n\n    EDIT: \nhttps://github.com/master-hax/pixel-backup-gang"},
{"Title": "what would be the recommended drive size limit for Raid5", "Author": "u/deliverator216", "Content": "I have a Terramaster F4-210 that I only use for storage for Plex (PMS is on a separate machine) I understand that Raid5 is not recommended for large drive sizes, but for the moment, the Terramaster is what I've got.\n  \n\n    How big of a drive can I put in and still be able to run recovery safely? I do have a backup so I'm not that worried about the data, I'm worried about having an unexpected additional drive expense.\n  \n\n    thoughts?"},
{"Title": "Wikipedia Archive Including Past Revisions?", "Author": "u/PumpALump", "Content": "I know that it's possible to download an archive of just the text of Wikipedia that's about 50 GB, but before I try downloading it, I figure I'd at least ask here if it includes the previous revisions of every given page, or just the latest one?\n  \n\n    I'd like an archive that includes all the past revisions."},
{"Title": "Just found out I have unlimited G drive storage and am trying to figure out how to use it with my Home-lab. Any ideas?", "Author": "u/Dat_Cool_Guy33", "Content": "Okay I'll try to explain the situation as best I can. I've always wanted to get into Data Hoarding but storing things on Local Physical Media isn't really possible for me at the moment. However, I do have a Basic Home lab setup with a Raspberry pi and a GMKtek Mini PC. The Raspberry Pi  has been set up as a \nPi Hosted\n Home Lab. So as a little makeshift NAS, I hooked up a 2TB SSD to it and upload / download data to it through a File Browser container that points to it. Unfortunately no redundancy at all.\n  \n\n    Then, Just today, I remembered my Old College account was still accessible and has unlimited storage available (or at least more than I'll ever use rn). So Here's what I'm thinking....is there any way to link my GDrive to my Home-lab NAS? specifically I would like some sort of system where it kind of acts like a one-drive or g drive for desktop relationship where my local nas is the client and my Gdrive is the cloud storage server.\n  \n\n    Basically I want this to be my flow of data:\n  \n\n\n\n\n\n    I store data on my Nas and whatever I use regularly stays on there\n  \n\n\n\n\n\n    Regularly my Local NAS is backed up and fully and securely encrypted to G-Drive\n  \n\n\n\n\n\n    Over time if I'm not using a file for lets say 30 days or so, The Nas storage used for that file gets cleared but if I want to access it later,  my Nas can just pull it from G-Drive, unencrypt it, and make it available to me again.\n  \n\n\n\n\n\n    My gut is telling me there's some system out there that can do what I'm looking for but I'm not sure what it would be.\n  \n\n    Also side note, I know that Duplicati and Rclone are a thing but I have other people that use my NAS for storage already and I want to keep it easy to manage where I don't have to dig through TB's of archives to pull a specific file their looking for or something.\n  \n\n    TL;DR: Is there any way for me to combine my existing NAS with my unlimited G-Drive account and link it up in the same way Onedrive for desktop can sync files to a client machine when being used and unsync files when not being used and keep them on G-Drive? With good encryption if possible because I'm paranoid of google having that much of my data lol?"},
{"Title": "$1/TB find at local Bin Store", "Author": "u/bozey07", "Content": "No content"},
{"Title": "Toshiba Refurb Hard Drive Numbering", "Author": "u/joetaxpayer", "Content": "I am considering buying refurb drives. Server Part Deals has \"MD08ACA16TR\" which they list as an enterprise drive, 16TB. But I looked at the Toshiba web site and there is no mention of this model number.\n  \n\n    Does Server Part Deals re-number drives to their own numbering? Is this just an MG series Toshiba drive?"},
{"Title": "Nintendo Switch files corrupt after recovering them from odd deletion.", "Author": "u/AfricanToilet", "Content": "Hello, all.\n  \n\n    Because the Nintendo Switch gives the option to screenshot and create 30-second long videos; I did that compulsively whilst I was playing 'Breathe of the Wild' (And other games, too, but not as many).\n  \n\n    Because I tend to be a digital hoarder, I keep them all neat in folders on my External Hard Drive. Every video and image I took on my Switch still resides there.\n  \n\n    Somehow (And I still don't know this happened because I didn't do anything) a couple of the folders got deleted and permanently removed. I obviously 'downloaded' a recovery software and got them all back, BUT; nothing having to do with soft or hardware can go smoothy - there's always [at least] one difficulty:\nThe files are now corrupt.\n  \n\n    Every video and image I took from 'Breath of the Wild' are now corrupt.\n  \n\n    How did this happen and how can I uncorrupt them, please?\n  \n\n    Many thanks in advance my life is in shambles.\n  \n\n    OS: MacOSX 10.13 High Sierra"},
{"Title": "I've had it with individual external enclosures. What's the best way to power my external setup without 4 wall warts?", "Author": "u/Bern_Down_the_DNC", "Content": "I want to be able to run 4 3.5\" drives at once. I need to power 4 of these sata to usb adapters (SABRENT USB 3.2 Type A to SATA/U.2 SSD Adapter Cable with 12V/2A Power Supply [EC-U2SA])\n  \n\n    I'd like to be able to just plug it in with 1 cord into the outlet instead of having to figure out how to plug in 4 wall warts. So I need a 1 plug to 4 dc jack (5.4mm) to reliably power all four at once. The wall wart that comes with the sabrent adapter says 2A 24W.\n  \n\n    Bonus points for suggestions on ways to make each hard drive have an individual power switch.\n  \n\n    Thank you!"},
{"Title": "downloading video streams divided into parts?", "Author": "u/unwissend2001", "Content": "When streaming sites use mp4 files directly you can download them per developer tools in the network tab.\n  \n\n    Many video hosting sites use ts or xhr format to stream videos divided in many small chunks.\n  \n\n    How do download them?"},
{"Title": "Digitizing PAL Video8 using OBS yields a 5:4 aspect ratio?", "Author": "u/YAZEED-IX", "Content": "I'm using s-video to USB to digitize PAL video8 tapes I have. From what I can see by testing different Canvas resolutions (setting the the height at 1080 as I plan on uploading it to YouTube), the height most appropriate is 1350 — shouldn't it be 1440 to produce 4:3 aspect ratio? When I try to do this I get extra black bars on the sides."},
{"Title": "Archive Discord Group Chats to another Server channel", "Author": "u/lurkintheair", "Content": "No content"},
{"Title": "Is transferring old tapes to digital via A/V out port a thing?", "Author": "u/teethtoe", "Content": "No content"},
{"Title": "Wfdownloader Pixiv Login cookies", "Author": "u/Swiftmaker", "Content": "I trying to get the pixiv login cookies imported into wfdownloader but I need some help on how do I properly import the cookies. Any Answers?"},
{"Title": "When you come across r/datahorder looking for an external HDD 😅", "Author": "u/M4dh77r", "Content": "No content"},
{"Title": "Cryptomator vault not updating with latest files?", "Author": "u/kkgmgfn", "Content": "I have a vault lets say \"MyVault\" and I have 2 files A and B in the unlocked vault.\n  \n\n\n\n\n\n    Now I backup it to cloud.\n  \n\n\n\n\n\n    I then delete B and add C. I backup it up again to cloud.\n  \n\n\n\n\n\n    Now when I get the vault files from cloud and decrypt it it still shows A and B?\n  \n\n\n\n\n\n    PS: I am using IDrive 360 endpint backup as backup on Windows."},
{"Title": "I crave an offline internet", "Author": "u/AshleyCakeGamin", "Content": "Like actually. My genuine dream is to have all of my favorite media stored on huge server/external hardware. Movies, YouTube videos, music and such that I could burn onto DVDs and give out anytime I want to. It’s really hard but when I have time I try my hand at achieving small bits of that but my long-term goal for the future is to eventually get people to help out or be a part of a team that did this \n(this is not me recruiting, or asking for archival help)\n I know this seems unachievable but even just a small fraction would be amazing.\n  \n\n    I somewhat have an idea of how I would organize it, although I’d like to hear if anyone has a like-minded dream and how they would — or even ways that would make this slightly more easier than manually downloading a video after video. (There’s other stuff, but it is primarily videos. I don’t have enough drives in my arsenal to download over 720p rn)\n  \n\n    EDIT: If anyone has tips for setting up a downloading stream to send files to a server via uploading it indirectly, that would also be amazing."},
{"Title": "Finding 16tb exos drives suddenly more difficult on amazon?", "Author": "u/TLunchFTW", "Content": "Title.  Went to buy another and so far I've purchased two that ended up being SAS.  It's getting annoying."},
{"Title": "Syncing between Seedbox and NAS", "Author": "u/KyAoD", "Content": "Hi all,\n  \n\n    How do you sync between your seedbed and your NAS? I used Resilio with a read only folder on my seedbox. But then I deleted a bunch of things on the seedbox, and they got deleted on my NAS, not fun to loose 1TB.\n  \n\n    I'm using Synology seedbox."},
{"Title": "how to download a website so that all image and html files are in one folder?", "Author": "u/imsodumb321", "Content": "ok so background: I run a media archive blog/social media page where I archive and share photos from random blogs I find on the internet.\n  \n\n    I used to download everything manually, so each page I downloaded would be organized nicely on my hard drive like this:\n  \n\n\n\n    downloads-->websitename.com-->year-->month-->blog post name-->blogpost.html and blogpostimage.jpg\n  \n\n\n\n    this organizational system makes my life a million times easier, but it's time consuming and tedious as fuck to download all of these webpages manually.\n  \n\n    so, I've been experimenting with tools like httrack and sitesucker to download blogs instead.\n  \n\n    obviously this is much less time consuming on my end when it comes to actually downloading things, but I then have to spend an equal amount of time reorganizing all the files on my hard drive because httrack puts all the images in random spots that are nested in like a dozen folders.  and that makes it a pain to find the images I want to share.\n  \n\n    so, I'm wondering: does anyone have any tools or suggestions that can scrape a website while also keeping things somewhat organized in terms of file management?  fwiw I'm on mac, so certain tools like cyotek webcopy I can't use."},
{"Title": "Is it possible to always anticipate drive failure?", "Author": "u/Terakahn", "Content": "I've never personally had a drive fail. But it's always been a concern. I usually switch to new drives frequently enough that it hasn't been an issue. And more recently been backing things up. It's part of the reason I've looked into raid setups. But is it possible to know when a drive is going to have issues and replace it proactively?\n  \n\n    I assume there are drive health markers that will show when a drive is more at risk for failure, but I don't know how reliable, accurate, precise they are.\n  \n\n    I have some hdds that are, at this point not being used, but are 15 years old and haven't had any problems. Drives I used as system drives once upon a time, then later media storage and finally put it an enclosure. But the size was so small it wasn't worth using anymore."},
{"Title": "UnionFS, MHDDFS, DrivePool - Best drive pooling for Apple Silicon / macOS", "Author": "u/boldcookiecutter", "Content": "Has anyone here had luck pooling drives on Apple Silicon?\n  \n\n    I'm trying to pool the data from 10+ mismatch-sized drives into one single mount point and haven't had any luck finding a way to do while maintaining write access to the drives via that same pooled directory. SnapRaid has drive pooling using symlinks which works well for read access, but I need both read and write from the same location.\n  \n\n     \n  \n\n    MHDDFS via MacPorts doesn't seem to install at all on Apple ARM architecture. I've tried replacing a ton of missing libraries & functions, but am still running into issues. DrivePool isn't supported natively and using via virtualization won't work for my drives due to most of them being either APFS or HFS+.\n  \n\n     \n  \n\n    Can't seem to find a solution here and reformatting the drives to ExFAT isn't really an option for me at the moment.\n  \n\n    Edit: Meant to update this thread. I was able to get UnionFS working well on Apple Silicon and it seems that is working without issue."},
{"Title": "Upgrading SnapRAID parity disks to bigger disks", "Author": "u/forwardslashroot", "Content": "All my disks are LUKS encrypted. I have two 14TB parity disks on my SnapRAID. I bought two 22TB disks 3 months ago. I want to swap my two 14TB from parity to data disks and make the two 22TB as my new parity disks.\n  \n\n    What I have done so far with the two 22TB are the following in order:\n  \n\n\n\n\n\n    Created a GPT partition via \nfdisk\n\n\n\n\n\n\n\n    LUKS encrypt the partition \ncryptsetup -y -v /dev/sdi1\n and \ncryptsetup -y -v /dev/sdj1\n\n\n\n\n\n\n\n    Opened the encrypted disk \ncryptsetup luksOpen /dev/sdi1 luks_parity3\n and \ncryptsetup luksOpen /dev/sdj1 luks_parity4\n\n\n\n\n\n\n\n    Created a filesystem \nmkfs.xfs -L PARITY3 /dev/mapper/luks_parity3\n and \nmkfs.xfs -L PARITY4 /dev/mapper/luks_parity4\n\n\n\n\n\n\n\n    I have not added the new disk to fstab and crypttab yet. I am also going to be using Clevis to auto decrypt the new disks. The question that I have are:\n  \n\n\n\n\n\n    Can I change the luksOpen names from \nluks_parity3\n to \nluks_parity1\n and \nluks_parity4\n to \nluks_parity2\n?\n  \n\n\n\n\n\n    Can I change the filesystem labels from \nPARITY3\n to \nPARITY\n and \nPARITY4\n to \nPARITY2\n?\n  \n\n\n\n\n\n    I think I can change the labels by using the \nxfs_admin -L PARITY /dev/mapper/luks_parity\n assuming that I could change the luksOpen luks_parity3 name to luks_parity.\n  \n\n    Is there anything I should know about before proceeding?"},
{"Title": "Maxing SAS and SATA HDDs in an Unraid Server", "Author": "u/CodeJBDA", "Content": "Hi All,\n  \n\n    I am in the process of building a new NAS with some HDDs that I already have, however I want to get some more (obviously lol), I found a great deal on some 14tb SAS drive. I have yet to use those but from what I have seen, they are not that much different to SATA drive, mainly the connector.\n  \n\n    I have alread got my HBA Card the \nLSI 9206-16e\n and some \nSFF8644 to SATA cables\n for my current HDDs. Am I right in saying that I will need SFF8644 to SAS cable (\nexample here\n) to properly connect. They appear to also have molex connectors for power.\n  \n\n    Id there any problem with going this route, I will be using Unraid as the OS on my NAS and the HDDs are of varying capacities (6TB to 14tb)"},
{"Title": "Archive of corrupt pictures that mysteriously came good - any ideas why?", "Author": "u/Bob_Spud", "Content": "Any ideas why an unrelated restore would \"uncorrupt\" lots of files.\n  \n\n    Have about a 60+GB archive of photos sitting in a win10 laptop directory structure that were known to be corrupt.  They had been corrupt from months. Roughly 70% of the pics had chunks missing, vertical or horizontal colour bands some transparent some solid and other assorted visual corruption.  Today I decided to do a restore.\n  \n\n    Restored the archive to a different location on the same laptop SSD. The restore was a virtual disk mount of a system image backup (from the built-in win7 system backup util).  Once the restore was completed I went back to the corrupt archive expecting to blow it away and found everything back to normal, all corruption gone.\n  \n\n    Gave the SSD a health check - no errors or anything suspicious.\n  \n\n    Last week restored a couple of individual pics from the same system image backup it had no impact on the corrupt archive."},
{"Title": "Way to store 60TB (not including 1-2-3 rule 😬) the most cost effective way", "Author": "u/Ok-Security-1260", "Content": "Hi, im a bit new to data hoarding but need to store 60TB not including the 1-2-3 rule. I would like it to be $1000 or less and have found some things that seem annoyingly close to that (like $100 close). I would like my data to be archived permanently but only need this for 2-5 years which seems like the duration of most hdds, ssds, etc. before i get enough money to possibly get more archival grade media (in which case ill most likely come back to this subreddit. Ive seen people say that they found $10 per terabyte which I don’t know how they found that (especially with the trusted WD, seagate, and seagate brands) because the least i could find is like $25 per terabyte. Thanks,"},
{"Title": "Is this dell poweredge r510 deal worth it?", "Author": "u/OkEfficiency1200", "Content": "Dell PowerEdge R510\n  \n\n    2x Xeon X5676 @ 3.07Ghz\n  \n\n    128gb DDR3 ram\n  \n\n    120gb Kingston boot drive\n  \n\n    12 – 4tb SAS drives\n  \n\n    Loaded with TrueNAS Scale 23.10.2\n  \n\n    For $460\n  \n\n    I'm looking to load a jellyfin server on it for media. Maybe even phone backups as well. Also attempt (if there is remaining room) to put a game server on it.\n  \n\n    Any help is appreciated!"},
{"Title": "Difference between r40 and rs40", "Author": "u/sulphide0", "Content": "looking to buy a high-speed scanner for 4x6 photo prints and narrowed it down to the canon rs40 and r40. The r40 is much cheaper so wondering what the difference is. Thanks."},
{"Title": "Reliable Online Storage", "Author": "u/foolsdata", "Content": "What is the most reliable online storage that everyone uses for important files and photos ? I want to create an account to upload old hard drive too and possibly let family access from other states. As of May 2024"},
{"Title": "No way to use IDrive endpoint backup on Unraid ie. using docker?", "Author": "u/kkgmgfn", "Content": "There is a community supported docker container for Crash Plan. It works great. I found 2 such containers for IDrive but they dont work. Also there is a bin file in them which doesn't have source code.\n  \n\n    TL;DR Using IDrive endpoint on Unraid."},
{"Title": "BD-R 25GB Help", "Author": "u/SLVR_EZIO", "Content": "Has anyone used Verbatim VBR130RP50V4 discs and are they reliable for storing data?\n  \n\n    What type of recordable format is it: HTL or LTH?\n  \n\n\nhttps://www.amazon.co.jp/-/en/Verbatim-VBR130RP50V4-Recording-Blu-ray-Printable/dp/B008F5M2OY/"},
{"Title": "1080p x264 vs 720p x265", "Author": "u/kapil_g_87", "Content": "I'm in the process of updating some of my media.\n  \n\n    Which of these options is better? Does 720p have better detail being encoded in x265? Or would 1080p x264 be better in terms of detail/granularity?\n  \n\n    I know I would need to look into the other factors like bit rate and fps etc but for now just trying to find out which option I should be trying to go for.\n  \n\n    Thanks"},
{"Title": "Generational Digital Archive", "Author": "u/Bethany41420", "Content": "I’m 17 and my dad made a digital archive of my baby pictures and videos from the mid 2000’s. I’ve always wanted to do the same thing and have all my pictures i’ve taken from the past present and future to go into it. I keep Every. Single. Picture i take. I like to think of showing them to my kids in the future. I can’t use the platform my dad did because it’s outdated and doesn’t sell anymore. I’m not technological at all. I know how to work my phone and some of my mac but i don’t know any fancy words or softwares to use. (i have no idea if it’s even called software) I want a platform that will last Years and be easy for my future generations to transition to another if they ever have to in the future. I also want to be able to access it from my phone whenever. Please helpppp thanksss"},
{"Title": "Anyone bought Toshiba MG09 or MG10 on Alternate?", "Author": "u/AlexFigas", "Content": "Hey everyone,\n  \n\n    I'm curious if anyone here has purchased the Toshiba MG09 or MG10 from Alternate.de. I've heard some rumors floating around that Toshiba doesn't provide warranty to individual buyers. Can anyone confirm if Alternate.de offers warranty for these drives? And if they do, what's the duration of the warranty?\n  \n\n    Thanks in advance!"},
{"Title": "Jonsbo N4 Build", "Author": "u/Timely_Recipe_4924", "Content": "No content"},
{"Title": "I need a NAS with 3 functions: read/writing files, FTP server for my scanner, and print server. Does it have to be a Synology or QNAP?", "Author": "u/MammothAnalysis", "Content": "We currently have a DAS with a shared folder that I have shared across the network of 5 PCs.\n  \n\n    There is also a multifunction printer/scanner on the network. It currently scans to an FTP location, and, I believe it is possible to scan to a shared location.\n  \n\n    I can attach the printer directly to network, but I could also potentially attach it to the NAS.\n  \n\n    Do I need fancy NAS solution like that from QNAP or, probably more likely a Synology?\n  \n\n    We only need to have access to files on the shared drive, and thats it. We don't require any other functionality.\n  \n\n    The only reason I require a NAS is so that I can have a 4 bay setup that can do RAID. We will likely never cross 1 TB of data since it is only documents, but I am still planning on installing 4x 2TB in a RAID 5 implementation for minimal data loss in case of drive failure, as the current implementation has been running for at least 10 years."},
{"Title": "Just going through some old drives…", "Author": "u/iwantansi", "Content": "Using hard disk sentinel to run a read surface test on each drive..\n  \n\n    Im debating to I really even  bother to keep drives under 500gb at this point?\n  \n\n    Also i have a handful of PATA drives, where i dont even have cables/tester to test them with\n  \n\n\npix"},
{"Title": "Is transferring old tapes to digital via A/V out port a thing?", "Author": "u/teethtoe", "Content": "No content"},
{"Title": "Wfdownloader Pixiv Login cookies", "Author": "u/Swiftmaker", "Content": "I trying to get the pixiv login cookies imported into wfdownloader but I need some help on how do I properly import the cookies. Any Answers?"},
{"Title": "When you come across r/datahorder looking for an external HDD 😅", "Author": "u/M4dh77r", "Content": "No content"},
{"Title": "Cryptomator vault not updating with latest files?", "Author": "u/kkgmgfn", "Content": "I have a vault lets say \"MyVault\" and I have 2 files A and B in the unlocked vault.\n  \n\n\n\n\n\n    Now I backup it to cloud.\n  \n\n\n\n\n\n    I then delete B and add C. I backup it up again to cloud.\n  \n\n\n\n\n\n    Now when I get the vault files from cloud and decrypt it it still shows A and B?\n  \n\n\n\n\n\n    PS: I am using IDrive 360 endpint backup as backup on Windows."},
{"Title": "I crave an offline internet", "Author": "u/AshleyCakeGamin", "Content": "Like actually. My genuine dream is to have all of my favorite media stored on huge server/external hardware. Movies, YouTube videos, music and such that I could burn onto DVDs and give out anytime I want to. It’s really hard but when I have time I try my hand at achieving small bits of that but my long-term goal for the future is to eventually get people to help out or be a part of a team that did this \n(this is not me recruiting, or asking for archival help)\n I know this seems unachievable but even just a small fraction would be amazing.\n  \n\n    I somewhat have an idea of how I would organize it, although I’d like to hear if anyone has a like-minded dream and how they would — or even ways that would make this slightly more easier than manually downloading a video after video. (There’s other stuff, but it is primarily videos. I don’t have enough drives in my arsenal to download over 720p rn)\n  \n\n    EDIT: If anyone has tips for setting up a downloading stream to send files to a server via uploading it indirectly, that would also be amazing."},
{"Title": "Finding 16tb exos drives suddenly more difficult on amazon?", "Author": "u/TLunchFTW", "Content": "Title.  Went to buy another and so far I've purchased two that ended up being SAS.  It's getting annoying."},
{"Title": "Syncing between Seedbox and NAS", "Author": "u/KyAoD", "Content": "Hi all,\n  \n\n    How do you sync between your seedbed and your NAS? I used Resilio with a read only folder on my seedbox. But then I deleted a bunch of things on the seedbox, and they got deleted on my NAS, not fun to loose 1TB.\n  \n\n    I'm using Synology seedbox."},
{"Title": "how to download a website so that all image and html files are in one folder?", "Author": "u/imsodumb321", "Content": "ok so background: I run a media archive blog/social media page where I archive and share photos from random blogs I find on the internet.\n  \n\n    I used to download everything manually, so each page I downloaded would be organized nicely on my hard drive like this:\n  \n\n\n\n    downloads-->websitename.com-->year-->month-->blog post name-->blogpost.html and blogpostimage.jpg\n  \n\n\n\n    this organizational system makes my life a million times easier, but it's time consuming and tedious as fuck to download all of these webpages manually.\n  \n\n    so, I've been experimenting with tools like httrack and sitesucker to download blogs instead.\n  \n\n    obviously this is much less time consuming on my end when it comes to actually downloading things, but I then have to spend an equal amount of time reorganizing all the files on my hard drive because httrack puts all the images in random spots that are nested in like a dozen folders.  and that makes it a pain to find the images I want to share.\n  \n\n    so, I'm wondering: does anyone have any tools or suggestions that can scrape a website while also keeping things somewhat organized in terms of file management?  fwiw I'm on mac, so certain tools like cyotek webcopy I can't use."},
{"Title": "Is it possible to always anticipate drive failure?", "Author": "u/Terakahn", "Content": "I've never personally had a drive fail. But it's always been a concern. I usually switch to new drives frequently enough that it hasn't been an issue. And more recently been backing things up. It's part of the reason I've looked into raid setups. But is it possible to know when a drive is going to have issues and replace it proactively?\n  \n\n    I assume there are drive health markers that will show when a drive is more at risk for failure, but I don't know how reliable, accurate, precise they are.\n  \n\n    I have some hdds that are, at this point not being used, but are 15 years old and haven't had any problems. Drives I used as system drives once upon a time, then later media storage and finally put it an enclosure. But the size was so small it wasn't worth using anymore."},
{"Title": "UnionFS, MHDDFS, DrivePool - Best drive pooling for Apple Silicon / macOS", "Author": "u/boldcookiecutter", "Content": "Has anyone here had luck pooling drives on Apple Silicon?\n  \n\n    I'm trying to pool the data from 10+ mismatch-sized drives into one single mount point and haven't had any luck finding a way to do while maintaining write access to the drives via that same pooled directory. SnapRaid has drive pooling using symlinks which works well for read access, but I need both read and write from the same location.\n  \n\n     \n  \n\n    MHDDFS via MacPorts doesn't seem to install at all on Apple ARM architecture. I've tried replacing a ton of missing libraries & functions, but am still running into issues. DrivePool isn't supported natively and using via virtualization won't work for my drives due to most of them being either APFS or HFS+.\n  \n\n     \n  \n\n    Can't seem to find a solution here and reformatting the drives to ExFAT isn't really an option for me at the moment.\n  \n\n    Edit: Meant to update this thread. I was able to get UnionFS working well on Apple Silicon and it seems that is working without issue."},
{"Title": "Upgrading SnapRAID parity disks to bigger disks", "Author": "u/forwardslashroot", "Content": "All my disks are LUKS encrypted. I have two 14TB parity disks on my SnapRAID. I bought two 22TB disks 3 months ago. I want to swap my two 14TB from parity to data disks and make the two 22TB as my new parity disks.\n  \n\n    What I have done so far with the two 22TB are the following in order:\n  \n\n\n\n\n\n    Created a GPT partition via \nfdisk\n\n\n\n\n\n\n\n    LUKS encrypt the partition \ncryptsetup -y -v /dev/sdi1\n and \ncryptsetup -y -v /dev/sdj1\n\n\n\n\n\n\n\n    Opened the encrypted disk \ncryptsetup luksOpen /dev/sdi1 luks_parity3\n and \ncryptsetup luksOpen /dev/sdj1 luks_parity4\n\n\n\n\n\n\n\n    Created a filesystem \nmkfs.xfs -L PARITY3 /dev/mapper/luks_parity3\n and \nmkfs.xfs -L PARITY4 /dev/mapper/luks_parity4\n\n\n\n\n\n\n\n    I have not added the new disk to fstab and crypttab yet. I am also going to be using Clevis to auto decrypt the new disks. The question that I have are:\n  \n\n\n\n\n\n    Can I change the luksOpen names from \nluks_parity3\n to \nluks_parity1\n and \nluks_parity4\n to \nluks_parity2\n?\n  \n\n\n\n\n\n    Can I change the filesystem labels from \nPARITY3\n to \nPARITY\n and \nPARITY4\n to \nPARITY2\n?\n  \n\n\n\n\n\n    I think I can change the labels by using the \nxfs_admin -L PARITY /dev/mapper/luks_parity\n assuming that I could change the luksOpen luks_parity3 name to luks_parity.\n  \n\n    Is there anything I should know about before proceeding?"},
{"Title": "Maxing SAS and SATA HDDs in an Unraid Server", "Author": "u/CodeJBDA", "Content": "Hi All,\n  \n\n    I am in the process of building a new NAS with some HDDs that I already have, however I want to get some more (obviously lol), I found a great deal on some 14tb SAS drive. I have yet to use those but from what I have seen, they are not that much different to SATA drive, mainly the connector.\n  \n\n    I have alread got my HBA Card the \nLSI 9206-16e\n and some \nSFF8644 to SATA cables\n for my current HDDs. Am I right in saying that I will need SFF8644 to SAS cable (\nexample here\n) to properly connect. They appear to also have molex connectors for power.\n  \n\n    Id there any problem with going this route, I will be using Unraid as the OS on my NAS and the HDDs are of varying capacities (6TB to 14tb)"},
{"Title": "Archive of corrupt pictures that mysteriously came good - any ideas why?", "Author": "u/Bob_Spud", "Content": "Any ideas why an unrelated restore would \"uncorrupt\" lots of files.\n  \n\n    Have about a 60+GB archive of photos sitting in a win10 laptop directory structure that were known to be corrupt.  They had been corrupt from months. Roughly 70% of the pics had chunks missing, vertical or horizontal colour bands some transparent some solid and other assorted visual corruption.  Today I decided to do a restore.\n  \n\n    Restored the archive to a different location on the same laptop SSD. The restore was a virtual disk mount of a system image backup (from the built-in win7 system backup util).  Once the restore was completed I went back to the corrupt archive expecting to blow it away and found everything back to normal, all corruption gone.\n  \n\n    Gave the SSD a health check - no errors or anything suspicious.\n  \n\n    Last week restored a couple of individual pics from the same system image backup it had no impact on the corrupt archive."},
{"Title": "Way to store 60TB (not including 1-2-3 rule 😬) the most cost effective way", "Author": "u/Ok-Security-1260", "Content": "Hi, im a bit new to data hoarding but need to store 60TB not including the 1-2-3 rule. I would like it to be $1000 or less and have found some things that seem annoyingly close to that (like $100 close). I would like my data to be archived permanently but only need this for 2-5 years which seems like the duration of most hdds, ssds, etc. before i get enough money to possibly get more archival grade media (in which case ill most likely come back to this subreddit. Ive seen people say that they found $10 per terabyte which I don’t know how they found that (especially with the trusted WD, seagate, and seagate brands) because the least i could find is like $25 per terabyte. Thanks,"},
{"Title": "Is this dell poweredge r510 deal worth it?", "Author": "u/OkEfficiency1200", "Content": "Dell PowerEdge R510\n  \n\n    2x Xeon X5676 @ 3.07Ghz\n  \n\n    128gb DDR3 ram\n  \n\n    120gb Kingston boot drive\n  \n\n    12 – 4tb SAS drives\n  \n\n    Loaded with TrueNAS Scale 23.10.2\n  \n\n    For $460\n  \n\n    I'm looking to load a jellyfin server on it for media. Maybe even phone backups as well. Also attempt (if there is remaining room) to put a game server on it.\n  \n\n    Any help is appreciated!"},
{"Title": "Difference between r40 and rs40", "Author": "u/sulphide0", "Content": "looking to buy a high-speed scanner for 4x6 photo prints and narrowed it down to the canon rs40 and r40. The r40 is much cheaper so wondering what the difference is. Thanks."},
{"Title": "Reliable Online Storage", "Author": "u/foolsdata", "Content": "What is the most reliable online storage that everyone uses for important files and photos ? I want to create an account to upload old hard drive too and possibly let family access from other states. As of May 2024"},
{"Title": "No way to use IDrive endpoint backup on Unraid ie. using docker?", "Author": "u/kkgmgfn", "Content": "There is a community supported docker container for Crash Plan. It works great. I found 2 such containers for IDrive but they dont work. Also there is a bin file in them which doesn't have source code.\n  \n\n    TL;DR Using IDrive endpoint on Unraid."},
{"Title": "BD-R 25GB Help", "Author": "u/SLVR_EZIO", "Content": "Has anyone used Verbatim VBR130RP50V4 discs and are they reliable for storing data?\n  \n\n    What type of recordable format is it: HTL or LTH?\n  \n\n\nhttps://www.amazon.co.jp/-/en/Verbatim-VBR130RP50V4-Recording-Blu-ray-Printable/dp/B008F5M2OY/"},
{"Title": "1080p x264 vs 720p x265", "Author": "u/kapil_g_87", "Content": "I'm in the process of updating some of my media.\n  \n\n    Which of these options is better? Does 720p have better detail being encoded in x265? Or would 1080p x264 be better in terms of detail/granularity?\n  \n\n    I know I would need to look into the other factors like bit rate and fps etc but for now just trying to find out which option I should be trying to go for.\n  \n\n    Thanks"},
{"Title": "Generational Digital Archive", "Author": "u/Bethany41420", "Content": "I’m 17 and my dad made a digital archive of my baby pictures and videos from the mid 2000’s. I’ve always wanted to do the same thing and have all my pictures i’ve taken from the past present and future to go into it. I keep Every. Single. Picture i take. I like to think of showing them to my kids in the future. I can’t use the platform my dad did because it’s outdated and doesn’t sell anymore. I’m not technological at all. I know how to work my phone and some of my mac but i don’t know any fancy words or softwares to use. (i have no idea if it’s even called software) I want a platform that will last Years and be easy for my future generations to transition to another if they ever have to in the future. I also want to be able to access it from my phone whenever. Please helpppp thanksss"},
{"Title": "Anyone bought Toshiba MG09 or MG10 on Alternate?", "Author": "u/AlexFigas", "Content": "Hey everyone,\n  \n\n    I'm curious if anyone here has purchased the Toshiba MG09 or MG10 from Alternate.de. I've heard some rumors floating around that Toshiba doesn't provide warranty to individual buyers. Can anyone confirm if Alternate.de offers warranty for these drives? And if they do, what's the duration of the warranty?\n  \n\n    Thanks in advance!"},
{"Title": "Jonsbo N4 Build", "Author": "u/Timely_Recipe_4924", "Content": "No content"},
{"Title": "I need a NAS with 3 functions: read/writing files, FTP server for my scanner, and print server. Does it have to be a Synology or QNAP?", "Author": "u/MammothAnalysis", "Content": "We currently have a DAS with a shared folder that I have shared across the network of 5 PCs.\n  \n\n    There is also a multifunction printer/scanner on the network. It currently scans to an FTP location, and, I believe it is possible to scan to a shared location.\n  \n\n    I can attach the printer directly to network, but I could also potentially attach it to the NAS.\n  \n\n    Do I need fancy NAS solution like that from QNAP or, probably more likely a Synology?\n  \n\n    We only need to have access to files on the shared drive, and thats it. We don't require any other functionality.\n  \n\n    The only reason I require a NAS is so that I can have a 4 bay setup that can do RAID. We will likely never cross 1 TB of data since it is only documents, but I am still planning on installing 4x 2TB in a RAID 5 implementation for minimal data loss in case of drive failure, as the current implementation has been running for at least 10 years."},
{"Title": "Just going through some old drives…", "Author": "u/iwantansi", "Content": "Using hard disk sentinel to run a read surface test on each drive..\n  \n\n    Im debating to I really even  bother to keep drives under 500gb at this point?\n  \n\n    Also i have a handful of PATA drives, where i dont even have cables/tester to test them with\n  \n\n\npix"},
{"Title": "Are unknown docker images for cloud backup safe?", "Author": "u/kkgmgfn", "Content": "I needed to use IDrive with unraid so I got an unofficial image from docker hub, thought the source code is on github I saw a bin file that it downloads from a site. The setup didn't work properly. But anyways to set it uo in command line it asked me my IDrive email, password and private encryption key? Is my dara safe? I have changed password though, private key cannot be changed."},
{"Title": "what is lto?", "Author": "u/vasilisgotthesause", "Content": "Hi!!! newbie here and i was wondering if someone can educate me a little on lto technology and what it does is it too old to be used? is it worth it? what do all the different versions mean? and why does everyone say that they are to expensive??"},
{"Title": "Cheap 8 drive NVMe PCIe card?", "Author": "u/c3l3x", "Content": "I have a bunch of 4TB NVMe drives that I want to stick on a single card to add to one of my computers.  I don't need RAID.  Even speed isn't important.  Just looking for a way to have them all available.  Any suggestions?"},
{"Title": "Is there any external HDD case for +5 drives with high speed usb connection?", "Author": "u/DrKersh", "Content": "I dont need a NAS, I don't want extra features like raid, nor use as plex server, etc\n  \n\n    I just want to put inside 5/6 drives and access to them from any computer using just a USB 3 high speed port\n  \n\n    Everything I see, are NAS with absurd prices of 800 for a 4 drive, when I just want to put the drives outside my case computer and nothing else. I refuse to pay for a case of just 4 sata 3.5 bays 3x the cost of the highest end computer case which will also have space for 8 drives.\n  \n\n    any idea?"},
{"Title": "How would you go to archive the cyanide and happiness stuff?", "Author": "u/seronlover", "Content": "A comics archive from 2005-2019 is on the archive.\n  \n\n    For the videos, there is of course the youtube channel and yt-dlp.\n  \n\n    The thing is there seem to be a lot of compilations and reruns of older content, making downloading all 1.400 videos a bit overkill.\n  \n\n    So I wanted to ask if anyone else already attempted to archive their stuff.\n  \n\n    The way I see it , i can use yt-dlp and filters to download the following: C&H Season Classics | Cyanide & Happiness Cyanide & Happiness Shorts A few of the of playlists (I am just not sure how much of that is already part of the \"shorts\")\n  \n\n    Compilations are skippable if I go for the shorts, i guess.\n  \n\n    I am just worried of missing unique content, thinking it is part of somwhting i already have, then deleting it by mistake."},
{"Title": "5TB WesternDigital Hard drive fell, I can't open a folder without it freezing.", "Author": "u/platfus118", "Content": "Years of work in this thing, Including a recent huge project of mine that I'm determined to save. The harddrive still works but whenever I try and back something up from it, the speed drops from 38MB/s to 355KB/s and repeating. Is there any way to save it? At least save the data that's on it.\n  \n\n    Thank you."},
{"Title": "Duplicate photo vs screenshot of original", "Author": "u/Sydonis", "Content": "Hey.  My go-to for a while was Duplicate Photos Fixer Pro.  Love the UI of it, and it kinda does the job in terms of functionality.  But I've had alot of frustrations with it for a while, and recently found out that redditors/reviewers deem it pretty ineffective.  Been perusing multiple duplicate photo/file finder posts and found a bunch of recommendations I'm going to try.  Czkawka seems to come up a bunch.\n  \n\n    Though there are a few comments about effectiveness of similarity, something no one touches on is the similarity between original vs. screenshot of original;\n  \n\n    Ie. My partner has a bad habit of opening facebook photos on her phone then screenshotting it, rather than simply downloading the photo.  This usually creates additional details within this image: different dimensions, exif details, and details within the photo (black borders, cell symbols/buttons/icons, hovering chat icons, etc.)\n  \n\n    I've used a couple photo finder apps, and even on low similarity settings, the apps cant seem to recognize the photos.  Wondering if anyone has any insight on this?  Don't want to download 10 different apps just to find out none of them (or the very last one) can do it.\n  \n\n    Appreciate the help"},
{"Title": "SambaXP 2024 Conference talks are now available on youtube. A great set of talks on all aspects of Samba and the SMB protocol, including contributions from Microsoft.", "Author": "u/jra_samba_org", "Content": "No content"},
{"Title": "Why do people post multiple versions of the same thing in different quality?", "Author": "u/Rob_Mortuary", "Content": "I've always wondered why somebody would take the time to post a Blu-ray rip in xvid format in 2024? Another example, is when these encoders will post a show, and then they'll share the season in 480p, 720p, and 1080p...why??? Who out there is honestly looking for a 480p copy of a brand new Blu-ray release? Furthermore, with updated formats like HEVC x265, what is the point of encoding files in x264 at this point? Maybe there's a method to the madness I'm just not seeing?"},
{"Title": "Raid 5 Array Auto Rebuilding Immediately After Creation (Normal?)", "Author": "u/LegendarySwordsman2", "Content": "TL;DR After creating a raid 5 array it immediately starts rebuilding the third drive which slows down the raid array to a halt. Is this behavior purposeful?\n  \n\n    I made my first setup into becoming a true data hoarder and bought 3 16TB Seagate Exos drives + a 5 bay DAS.\n  \n\n    Bear in mind I'm still relatively new to Raid. I'm running Ubuntu and using Mdadm with a raid 5 setup. I added a few movies to the drive and then transfered perfectly fine at around 100-150MB/s. I then tried playing them directly from that computer, however it would constantly buffer and at times not load at all. I then tried moving those movies back to my internal drive and it transferred at around 50-100KB/s.\n  \n\n    I decided to remove the raid array and try using the drives on their own, which worked perfectly fine. transfer speeds were back up to around 150MB/s and the media files played great without stuttering or buffering.\n  \n\n    I re-created the raid array, this timing using btrfs instead of ext4 (which is what I used last time) thinking that could make a difference. It didn't and the same issues persisted.\n  \n\n    After confronting ChatGPT about the issue I found out there was a details command for Mdadm. After running that I noticed the state was \"clean, degraded, recovering\" and that the third drive was currently rebuilding. Which didn't make any sense to me as I had literally just created the array, also I already tested each drive individually before assembling the array by running a benchmark test as well as adding some .mkv files to each drive and playing them. None of the drives had any issues.\n  \n\n    This also explains why I was having buffering and transfer issues with the drive. Since it's currently being used already to rebuild the third drive. \"System Monitor\" shows a constant read rate of around 150MB/s and a read rate of around 80MB/s.\n  \n\n    I assume the third drive is supposed to be the redundant drive, so is this rebuilding part of initialization or something? Or is this not supposed to be happening? The rebuilding process is also taking an extremely long time, I've waited around 30-40 minutes and it's only at 2%."},
{"Title": "SoftRAID RAID 5 (MacOS on Apple M1), 3x4 TB drives, all backed up to backblaze unli backup. What are my odds of failure?", "Author": "u/seresusly", "Content": "https://wintelguy.com/raidmttdl.pl \nhttps://www.servethehome.com/raid-calculator/raid-reliability-calculator-simple-mttdl-model/\n\n    I saw these two tools and they're providing wildly different odds of success.\n  \n\n    Are probabilities already in percentage for the wintel site? Or is 0.47 probability = 47% chance of read error during rebuild?\n  \n\n    Right now, I'm using an M1 Mac mini with 2 pcs. 2-bay USB 3.0 drive docks, 3 pcs 4TB drives are in them, and one 512gb SSD for download caching before being moved onto the SoftRAID RAID 5 HFS+ array.\n  \n\n    I wanted to get your thoughts if this is okay. Any suggestions? More drives? RAID 6 instead?\n  \n\n    What's the real probability of data loss in 5 years?"},
{"Title": "How do i download all of the blob: files from a website", "Author": "u/JamesJenkins55", "Content": "The blob: files can be found on the inspect element network tab and clicking save as for each individual one saves it just fine. However, there are 12,000 files and I do not want to hand-save all of these files. Are there alternate methods?"},
{"Title": "Need to backup around 300gb FREE", "Author": "u/EldenZIP", "Content": "My PC is crashing constantly and I need to factory reset my PC so it wont crash anymore. I have about 300gb of videos and pictures on my PC though and no way to back them up via external storage or any sort of cloud. One Drive only offers 5gb on the free version and I dont know too much about other cloud storages. I really just need something to back up 300gb, reset my PC, download the 300gb and then delete the software again. Is there anything like it? I also dont want to do the \"Free Trial Cheese\""},
{"Title": "WD Elements vs Ultrastar DC in enclosure for external storage", "Author": "u/Mycroft2046", "Content": "I am looking for about 5 20TB external drives for cold storage. However, I live in India where 20TB drives are not quite easy to find. I was considering WD Elements because they seem pretty cheap in the US, but in India, they cost about $500. However, Ultrastar DC HC560 is available here at a much more reasonable price of $390. But I will need an enclosure for those. I would like to know if WD Elements are worth the premium, or worth the hassle of importing them from the US. What are the shortcomings of using Ultrastar DC as cold storage? And if I go with Ultrastar DC drives, what's a decent enclosure that I can get for them?"},
{"Title": "Cloud to tape service?", "Author": "u/gjvnq1", "Content": "Is there any service that lets me upload my data (say 10 TB at a time) and get a copy of it on an LTO tape via the mail?\n  \n\n    I feel like this could be very useful for archiving high resolution copies of rare media."},
{"Title": "How to move ~15 TBs of data efficiently?", "Author": "u/rudeer_poke", "Content": "I am about to move my data to a new storage system. Most likely it will happen via a 1 Gig network connection as my 10 Gig gear will take a few months to arrive.\n  \n\n    My concern is, that last time when I was copying over some 2 TBs of data locally, between two drives via rsync, it took like 2 days because of lot of small files. So copying over the whole data via network could take like weeks, while changes such as regular backups, downloads, etc. are happening to the source file system.\n  \n\n    How should I approach this to have some reasonable transfer rates and minimal downtime, while keeping file permissions and stuff like that?"},
{"Title": "Reliable Backup System for Media Storage - Seeking Advice", "Author": "u/FigNewtonion", "Content": "Hello everyone,\n  \n\n    I could use some advice on setting up a reliable backup system.\n  \n\n    For quite some time, I've relied on an 8TB Western Digital Elements external hard drive to store all my media, primarily movies and TV shows. While it has served me well thus far, I'm aware that it's only a matter of time before it fails, and I'd like to be prepared.\n  \n\n    My plan is to employ two hard drives: one as primary storage for ongoing media consumption, and the other as a backup. I intend to manually run rsync every few days to keep the backup current. Although many suggest an offsite backup as well, I'm comfortable with just one backup for now.\n  \n\n    Initially, I was considering another Western Digital Elements external drive, but after reading some critiques of external drives' reliability, I'm inclined to explore a different approach. It seems that investing in high-quality internal hard drives and housing them in an enclosure might be more dependable.\n  \n\n    This brings me to the idea of using an enclosure without RAID functionality. I understand that RAID is not a backup solution, and that's not what I'm after. I envision an enclosure that can accommodate two individual drives, each accessible separately for manual backup operations. These drives could be swapped out for a new drive at any time.\n  \n\n    An enclosure would be convenient, keeping both drives together and eliminating the need to handle an additional drive every time I back up. However, I'm aware that with most enclosures, both drives typically connect through a single controller. If that controller were to fail, it could potentially compromise both drives, so I need a solution that mitigates this risk.\n  \n\n    My primary use case is watching movies, without the need for additional software. I prefer my drives to be inactive when not in use (off, no-power), only spinning up when I decide to watch something.\n  \n\n    Considering all this:\n  \n\n\n\n\n\n    Is there an enclosure that meets my needs, or do I have this all wrong?\n  \n\n\n\n\n\n    What considerations should be made with respect to the connection types to the drives (USB 3.0, SATA, or stuff I don't know about) etc?\n  \n\n\n\n\n\n    Given I watch media, what considerations should be made about the RPM of the hard drives? Or other factors I'm unaware of?\n  \n\n\n\n\n\n    Currently, I have about 4TB of data (not a lot but I'd like to get bigger drives to future proof).\n  \n\n    Need someone to point me in the right direction - any insights or suggestions would be greatly appreciated."},
{"Title": "VirtualDub screen turns black when starting capture", "Author": "u/mnsrmnsr", "Content": "Hey everyone,\n  \n\n    I'm having a bit of trouble capture composite video with VirtualDub. When I select my source, I can see the video image and everything works correctly, until I start the video capture, the screen turns black and the captured video is all black. I tried disabling the preview while capturing, it didn't solve the problem. My capture card has an s-video input and TV cable/antenna input. Both work as expected before and during capturing. I tried using an adapter to convert from RCA to S-Video, it works but the image is very blocky and looks bad, while the composite image when displayed looks correct (my VCR has only a composite output).\n  \n\n    If I open VDub and the last selected source was composite, the image is black, I have to change it to TV tuner or S-video and then change it back to composite so I can see the image. But if I open the software and the last selected source was something else (the tuner or S-Video) then I can directly see the image, no need to change to something else and go back. I'm using the card's DirectShow as the device.\n  \n\n    I know my setup is a bit old and by far not the best, but I'm just trying to capture family tapes in the best way I can, and I figured that since I can see the image but I just lose it when I start capturing then it must be a software issue that I might be able to fix... My setup: LG vlk9320w VCR DVD combo Philips SAA7130 capture card Windows 7 on intel i5 Desktop VirtualDub 1.10.4, and VirtualDub2\n  \n\n    I'm trying to make it work with this setup because it's the only one so far that shows me everything that is on the tape and is extremely noise tolerant and doesn't drop frames when encountering noise, it shows me the image exactly as I see it if I were to connect my VCR to the TV. I have a slightly better setup (Blackmagic Intensity Shuttle + TBC + Macbook) but it doesn't allow for much noise.\n  \n\n    Thanks in advance."},
{"Title": "Got a crazy good deal on all these drives, what great deals have you guys gotten?", "Author": "u/Midnight_Prince", "Content": "No content"},
{"Title": "Can MultCloud transfer contents from MEGA link without a login to OneDrive?", "Author": "u/WhyDidIPickThis", "Content": "I'm trying to transfer the entire contents of a MEGA link that has a folder full of files directly to my OneDrive. I've tried putting in the MEGA link directly into MultCloud under Remote Upload (where I can put in torrent files, etc.), but MEGA links don't seem to work the same way. I don't have the login to the MEGA link account; only access to the files to download directly from the link. Any ideas?"},
{"Title": "How do you know you've crossed the line?", "Author": "u/Max-C300", "Content": "Hello everyone, this is my first post in this subreddit. I'm curious about something: How do you know when you've officially crossed the line and have become a data hoarder?\n  \n\n    I mean, does having a four- or six-bay NAS that all of your devices back up to count? Or, for that matter, just having double-digit terabytes worth of content in a Plex server? Does that make you a data hoarder, or just a digital movie enthusiast?"},
{"Title": "What decommissioned enterprise storage servers are people buying these days?", "Author": "u/barnett9", "Content": "A little over a year ago I completed a build of an AMD Epyc Rome white box that I got the cpu and motherboard from a Chinese tech recycler, but I'm thinking about starting up a ceph cluster, and looking around most of the pre-built storage servers that I'm able to find on ebay are ANCIENT. Like circa 2014. Maybe I'm not looking for the right things? Or has the era of old enterprise gear really come to an end with all the shift towards the cloud?\n  \n\n    So, what have you picked up recently that is from this decade and hopefully has some 3.5 inch hot-swap bays and a pcie slot?"},
{"Title": "Efficient Way to Check Video Files for Corruption", "Author": "u/sensibleunicorn", "Content": "I've been reorganizing my media collection to optimize storage and realized I have (multiple times) hoarded the same show or movie etc in multiple formats/quality.\n  \n\n    I've been slowly going through and removing duplicates, but at one point I tried to watch something and realized the file was corrupted. Looked fine at a glance, time stamps and metadata was accurate, but would just stop playing halfway through.\n  \n\n    I've looked up ways to check for corruption in video files specifically, and I've found a couple methods, but they're extremely time consuming and was hoping there was a more efficient solution for dealing with large amounts of data\n  \n\n    tl;dr I'm organizing my media storage need a way to efficiently check for corruption before I delete duplicate files"},
{"Title": "Intel SATA SSD DC S3610 dead? Any hope of revival?", "Author": "u/ikukuru", "Content": "I have a few of these Intel DC S3610 SATA SSD, mostly for applications prone to write amplification. Power on hours and lifetime writes are relatively low for second hand. No reported errors.\n  \n\n    This one in particular was in a usb enclosure and just became unresponsive. The USB enclosure still works with a different drive.\n  \n\n    Connecting to SATA internally does not seem to help, though significantly slows boot when connected.\n  \n\n    Of all my storage over the years, this is the only one to outright die without warning. No signs of life on debian…\n  \n\n    With the positive reputation of Intel SSD I wonder if it is not really dead and I am just missing something?\n  \n\n    But I don’t know what to do to revive it. Any thoughts or advice welcome\n  \n\n    Cheers\n  \n\n\nhttps://imgur.com/a/HUpCVXH"},
{"Title": "Research about data platform for university thesis", "Author": "u/Phacebyaz", "Content": "Hello guys and girls :)\n  \n\n    My name is Augustin, and I'm currently studying and researching how data professionals, like you, can maximize the impact of data platforms.\n  \n\n    I'm working on a concept which aims to create a data platform for marketing use, for an eSport team. The goal would be to provide a platform that simplifies complex data sets and transforms them into actionable insights.\n  \n\n    I'd love to hear your thoughts on the following questions:\n  \n\n\n\n\n\n    What are the biggest challenges you currently face with data platforms?\n  \n\n\n\n\n\n    What features do you find most useful in existing platforms, and what do you wish they could improve?\n  \n\n\n\n\n\n    How important are predictive analytics for your work, and what predictive features do you find valuable?\n  \n\n\n\n\n\n    Your input will directly contribute to refining my research and I'd greatly appreciate your insights! If you have any questions about it, feel free to ask, I will gladly answer!\n  \n\n    Thanks a lot for your time :)\n  \n\n    Augustin"},
{"Title": "Are unknown docker images for cloud backup safe?", "Author": "u/kkgmgfn", "Content": "I needed to use IDrive with unraid so I got an unofficial image from docker hub, thought the source code is on github I saw a bin file that it downloads from a site. The setup didn't work properly. But anyways to set it uo in command line it asked me my IDrive email, password and private encryption key? Is my dara safe? I have changed password though, private key cannot be changed."},
{"Title": "what is lto?", "Author": "u/vasilisgotthesause", "Content": "Hi!!! newbie here and i was wondering if someone can educate me a little on lto technology and what it does is it too old to be used? is it worth it? what do all the different versions mean? and why does everyone say that they are to expensive??"},
{"Title": "Cheap 8 drive NVMe PCIe card?", "Author": "u/c3l3x", "Content": "I have a bunch of 4TB NVMe drives that I want to stick on a single card to add to one of my computers.  I don't need RAID.  Even speed isn't important.  Just looking for a way to have them all available.  Any suggestions?"},
{"Title": "Is there any external HDD case for +5 drives with high speed usb connection?", "Author": "u/DrKersh", "Content": "I dont need a NAS, I don't want extra features like raid, nor use as plex server, etc\n  \n\n    I just want to put inside 5/6 drives and access to them from any computer using just a USB 3 high speed port\n  \n\n    Everything I see, are NAS with absurd prices of 800 for a 4 drive, when I just want to put the drives outside my case computer and nothing else. I refuse to pay for a case of just 4 sata 3.5 bays 3x the cost of the highest end computer case which will also have space for 8 drives.\n  \n\n    any idea?"},
{"Title": "How would you go to archive the cyanide and happiness stuff?", "Author": "u/seronlover", "Content": "A comics archive from 2005-2019 is on the archive.\n  \n\n    For the videos, there is of course the youtube channel and yt-dlp.\n  \n\n    The thing is there seem to be a lot of compilations and reruns of older content, making downloading all 1.400 videos a bit overkill.\n  \n\n    So I wanted to ask if anyone else already attempted to archive their stuff.\n  \n\n    The way I see it , i can use yt-dlp and filters to download the following: C&H Season Classics | Cyanide & Happiness Cyanide & Happiness Shorts A few of the of playlists (I am just not sure how much of that is already part of the \"shorts\")\n  \n\n    Compilations are skippable if I go for the shorts, i guess.\n  \n\n    I am just worried of missing unique content, thinking it is part of somwhting i already have, then deleting it by mistake."},
{"Title": "5TB WesternDigital Hard drive fell, I can't open a folder without it freezing.", "Author": "u/platfus118", "Content": "Years of work in this thing, Including a recent huge project of mine that I'm determined to save. The harddrive still works but whenever I try and back something up from it, the speed drops from 38MB/s to 355KB/s and repeating. Is there any way to save it? At least save the data that's on it.\n  \n\n    Thank you."},
{"Title": "Duplicate photo vs screenshot of original", "Author": "u/Sydonis", "Content": "Hey.  My go-to for a while was Duplicate Photos Fixer Pro.  Love the UI of it, and it kinda does the job in terms of functionality.  But I've had alot of frustrations with it for a while, and recently found out that redditors/reviewers deem it pretty ineffective.  Been perusing multiple duplicate photo/file finder posts and found a bunch of recommendations I'm going to try.  Czkawka seems to come up a bunch.\n  \n\n    Though there are a few comments about effectiveness of similarity, something no one touches on is the similarity between original vs. screenshot of original;\n  \n\n    Ie. My partner has a bad habit of opening facebook photos on her phone then screenshotting it, rather than simply downloading the photo.  This usually creates additional details within this image: different dimensions, exif details, and details within the photo (black borders, cell symbols/buttons/icons, hovering chat icons, etc.)\n  \n\n    I've used a couple photo finder apps, and even on low similarity settings, the apps cant seem to recognize the photos.  Wondering if anyone has any insight on this?  Don't want to download 10 different apps just to find out none of them (or the very last one) can do it.\n  \n\n    Appreciate the help"},
{"Title": "SambaXP 2024 Conference talks are now available on youtube. A great set of talks on all aspects of Samba and the SMB protocol, including contributions from Microsoft.", "Author": "u/jra_samba_org", "Content": "No content"},
{"Title": "Why do people post multiple versions of the same thing in different quality?", "Author": "u/Rob_Mortuary", "Content": "I've always wondered why somebody would take the time to post a Blu-ray rip in xvid format in 2024? Another example, is when these encoders will post a show, and then they'll share the season in 480p, 720p, and 1080p...why??? Who out there is honestly looking for a 480p copy of a brand new Blu-ray release? Furthermore, with updated formats like HEVC x265, what is the point of encoding files in x264 at this point? Maybe there's a method to the madness I'm just not seeing?"},
{"Title": "Raid 5 Array Auto Rebuilding Immediately After Creation (Normal?)", "Author": "u/LegendarySwordsman2", "Content": "TL;DR After creating a raid 5 array it immediately starts rebuilding the third drive which slows down the raid array to a halt. Is this behavior purposeful?\n  \n\n    I made my first setup into becoming a true data hoarder and bought 3 16TB Seagate Exos drives + a 5 bay DAS.\n  \n\n    Bear in mind I'm still relatively new to Raid. I'm running Ubuntu and using Mdadm with a raid 5 setup. I added a few movies to the drive and then transfered perfectly fine at around 100-150MB/s. I then tried playing them directly from that computer, however it would constantly buffer and at times not load at all. I then tried moving those movies back to my internal drive and it transferred at around 50-100KB/s.\n  \n\n    I decided to remove the raid array and try using the drives on their own, which worked perfectly fine. transfer speeds were back up to around 150MB/s and the media files played great without stuttering or buffering.\n  \n\n    I re-created the raid array, this timing using btrfs instead of ext4 (which is what I used last time) thinking that could make a difference. It didn't and the same issues persisted.\n  \n\n    After confronting ChatGPT about the issue I found out there was a details command for Mdadm. After running that I noticed the state was \"clean, degraded, recovering\" and that the third drive was currently rebuilding. Which didn't make any sense to me as I had literally just created the array, also I already tested each drive individually before assembling the array by running a benchmark test as well as adding some .mkv files to each drive and playing them. None of the drives had any issues.\n  \n\n    This also explains why I was having buffering and transfer issues with the drive. Since it's currently being used already to rebuild the third drive. \"System Monitor\" shows a constant read rate of around 150MB/s and a read rate of around 80MB/s.\n  \n\n    I assume the third drive is supposed to be the redundant drive, so is this rebuilding part of initialization or something? Or is this not supposed to be happening? The rebuilding process is also taking an extremely long time, I've waited around 30-40 minutes and it's only at 2%."},
{"Title": "SoftRAID RAID 5 (MacOS on Apple M1), 3x4 TB drives, all backed up to backblaze unli backup. What are my odds of failure?", "Author": "u/seresusly", "Content": "https://wintelguy.com/raidmttdl.pl \nhttps://www.servethehome.com/raid-calculator/raid-reliability-calculator-simple-mttdl-model/\n\n    I saw these two tools and they're providing wildly different odds of success.\n  \n\n    Are probabilities already in percentage for the wintel site? Or is 0.47 probability = 47% chance of read error during rebuild?\n  \n\n    Right now, I'm using an M1 Mac mini with 2 pcs. 2-bay USB 3.0 drive docks, 3 pcs 4TB drives are in them, and one 512gb SSD for download caching before being moved onto the SoftRAID RAID 5 HFS+ array.\n  \n\n    I wanted to get your thoughts if this is okay. Any suggestions? More drives? RAID 6 instead?\n  \n\n    What's the real probability of data loss in 5 years?"},
{"Title": "How do i download all of the blob: files from a website", "Author": "u/JamesJenkins55", "Content": "The blob: files can be found on the inspect element network tab and clicking save as for each individual one saves it just fine. However, there are 12,000 files and I do not want to hand-save all of these files. Are there alternate methods?"},
{"Title": "Need to backup around 300gb FREE", "Author": "u/EldenZIP", "Content": "My PC is crashing constantly and I need to factory reset my PC so it wont crash anymore. I have about 300gb of videos and pictures on my PC though and no way to back them up via external storage or any sort of cloud. One Drive only offers 5gb on the free version and I dont know too much about other cloud storages. I really just need something to back up 300gb, reset my PC, download the 300gb and then delete the software again. Is there anything like it? I also dont want to do the \"Free Trial Cheese\""},
{"Title": "WD Elements vs Ultrastar DC in enclosure for external storage", "Author": "u/Mycroft2046", "Content": "I am looking for about 5 20TB external drives for cold storage. However, I live in India where 20TB drives are not quite easy to find. I was considering WD Elements because they seem pretty cheap in the US, but in India, they cost about $500. However, Ultrastar DC HC560 is available here at a much more reasonable price of $390. But I will need an enclosure for those. I would like to know if WD Elements are worth the premium, or worth the hassle of importing them from the US. What are the shortcomings of using Ultrastar DC as cold storage? And if I go with Ultrastar DC drives, what's a decent enclosure that I can get for them?"},
{"Title": "Cloud to tape service?", "Author": "u/gjvnq1", "Content": "Is there any service that lets me upload my data (say 10 TB at a time) and get a copy of it on an LTO tape via the mail?\n  \n\n    I feel like this could be very useful for archiving high resolution copies of rare media."},
{"Title": "How to move ~15 TBs of data efficiently?", "Author": "u/rudeer_poke", "Content": "I am about to move my data to a new storage system. Most likely it will happen via a 1 Gig network connection as my 10 Gig gear will take a few months to arrive.\n  \n\n    My concern is, that last time when I was copying over some 2 TBs of data locally, between two drives via rsync, it took like 2 days because of lot of small files. So copying over the whole data via network could take like weeks, while changes such as regular backups, downloads, etc. are happening to the source file system.\n  \n\n    How should I approach this to have some reasonable transfer rates and minimal downtime, while keeping file permissions and stuff like that?"},
{"Title": "Reliable Backup System for Media Storage - Seeking Advice", "Author": "u/FigNewtonion", "Content": "Hello everyone,\n  \n\n    I could use some advice on setting up a reliable backup system.\n  \n\n    For quite some time, I've relied on an 8TB Western Digital Elements external hard drive to store all my media, primarily movies and TV shows. While it has served me well thus far, I'm aware that it's only a matter of time before it fails, and I'd like to be prepared.\n  \n\n    My plan is to employ two hard drives: one as primary storage for ongoing media consumption, and the other as a backup. I intend to manually run rsync every few days to keep the backup current. Although many suggest an offsite backup as well, I'm comfortable with just one backup for now.\n  \n\n    Initially, I was considering another Western Digital Elements external drive, but after reading some critiques of external drives' reliability, I'm inclined to explore a different approach. It seems that investing in high-quality internal hard drives and housing them in an enclosure might be more dependable.\n  \n\n    This brings me to the idea of using an enclosure without RAID functionality. I understand that RAID is not a backup solution, and that's not what I'm after. I envision an enclosure that can accommodate two individual drives, each accessible separately for manual backup operations. These drives could be swapped out for a new drive at any time.\n  \n\n    An enclosure would be convenient, keeping both drives together and eliminating the need to handle an additional drive every time I back up. However, I'm aware that with most enclosures, both drives typically connect through a single controller. If that controller were to fail, it could potentially compromise both drives, so I need a solution that mitigates this risk.\n  \n\n    My primary use case is watching movies, without the need for additional software. I prefer my drives to be inactive when not in use (off, no-power), only spinning up when I decide to watch something.\n  \n\n    Considering all this:\n  \n\n\n\n\n\n    Is there an enclosure that meets my needs, or do I have this all wrong?\n  \n\n\n\n\n\n    What considerations should be made with respect to the connection types to the drives (USB 3.0, SATA, or stuff I don't know about) etc?\n  \n\n\n\n\n\n    Given I watch media, what considerations should be made about the RPM of the hard drives? Or other factors I'm unaware of?\n  \n\n\n\n\n\n    Currently, I have about 4TB of data (not a lot but I'd like to get bigger drives to future proof).\n  \n\n    Need someone to point me in the right direction - any insights or suggestions would be greatly appreciated."},
{"Title": "VirtualDub screen turns black when starting capture", "Author": "u/mnsrmnsr", "Content": "Hey everyone,\n  \n\n    I'm having a bit of trouble capture composite video with VirtualDub. When I select my source, I can see the video image and everything works correctly, until I start the video capture, the screen turns black and the captured video is all black. I tried disabling the preview while capturing, it didn't solve the problem. My capture card has an s-video input and TV cable/antenna input. Both work as expected before and during capturing. I tried using an adapter to convert from RCA to S-Video, it works but the image is very blocky and looks bad, while the composite image when displayed looks correct (my VCR has only a composite output).\n  \n\n    If I open VDub and the last selected source was composite, the image is black, I have to change it to TV tuner or S-video and then change it back to composite so I can see the image. But if I open the software and the last selected source was something else (the tuner or S-Video) then I can directly see the image, no need to change to something else and go back. I'm using the card's DirectShow as the device.\n  \n\n    I know my setup is a bit old and by far not the best, but I'm just trying to capture family tapes in the best way I can, and I figured that since I can see the image but I just lose it when I start capturing then it must be a software issue that I might be able to fix... My setup: LG vlk9320w VCR DVD combo Philips SAA7130 capture card Windows 7 on intel i5 Desktop VirtualDub 1.10.4, and VirtualDub2\n  \n\n    I'm trying to make it work with this setup because it's the only one so far that shows me everything that is on the tape and is extremely noise tolerant and doesn't drop frames when encountering noise, it shows me the image exactly as I see it if I were to connect my VCR to the TV. I have a slightly better setup (Blackmagic Intensity Shuttle + TBC + Macbook) but it doesn't allow for much noise.\n  \n\n    Thanks in advance."},
{"Title": "Got a crazy good deal on all these drives, what great deals have you guys gotten?", "Author": "u/Midnight_Prince", "Content": "No content"},
{"Title": "Can MultCloud transfer contents from MEGA link without a login to OneDrive?", "Author": "u/WhyDidIPickThis", "Content": "I'm trying to transfer the entire contents of a MEGA link that has a folder full of files directly to my OneDrive. I've tried putting in the MEGA link directly into MultCloud under Remote Upload (where I can put in torrent files, etc.), but MEGA links don't seem to work the same way. I don't have the login to the MEGA link account; only access to the files to download directly from the link. Any ideas?"},
{"Title": "How do you know you've crossed the line?", "Author": "u/Max-C300", "Content": "Hello everyone, this is my first post in this subreddit. I'm curious about something: How do you know when you've officially crossed the line and have become a data hoarder?\n  \n\n    I mean, does having a four- or six-bay NAS that all of your devices back up to count? Or, for that matter, just having double-digit terabytes worth of content in a Plex server? Does that make you a data hoarder, or just a digital movie enthusiast?"},
{"Title": "What decommissioned enterprise storage servers are people buying these days?", "Author": "u/barnett9", "Content": "A little over a year ago I completed a build of an AMD Epyc Rome white box that I got the cpu and motherboard from a Chinese tech recycler, but I'm thinking about starting up a ceph cluster, and looking around most of the pre-built storage servers that I'm able to find on ebay are ANCIENT. Like circa 2014. Maybe I'm not looking for the right things? Or has the era of old enterprise gear really come to an end with all the shift towards the cloud?\n  \n\n    So, what have you picked up recently that is from this decade and hopefully has some 3.5 inch hot-swap bays and a pcie slot?"},
{"Title": "Efficient Way to Check Video Files for Corruption", "Author": "u/sensibleunicorn", "Content": "I've been reorganizing my media collection to optimize storage and realized I have (multiple times) hoarded the same show or movie etc in multiple formats/quality.\n  \n\n    I've been slowly going through and removing duplicates, but at one point I tried to watch something and realized the file was corrupted. Looked fine at a glance, time stamps and metadata was accurate, but would just stop playing halfway through.\n  \n\n    I've looked up ways to check for corruption in video files specifically, and I've found a couple methods, but they're extremely time consuming and was hoping there was a more efficient solution for dealing with large amounts of data\n  \n\n    tl;dr I'm organizing my media storage need a way to efficiently check for corruption before I delete duplicate files"},
{"Title": "Intel SATA SSD DC S3610 dead? Any hope of revival?", "Author": "u/ikukuru", "Content": "I have a few of these Intel DC S3610 SATA SSD, mostly for applications prone to write amplification. Power on hours and lifetime writes are relatively low for second hand. No reported errors.\n  \n\n    This one in particular was in a usb enclosure and just became unresponsive. The USB enclosure still works with a different drive.\n  \n\n    Connecting to SATA internally does not seem to help, though significantly slows boot when connected.\n  \n\n    Of all my storage over the years, this is the only one to outright die without warning. No signs of life on debian…\n  \n\n    With the positive reputation of Intel SSD I wonder if it is not really dead and I am just missing something?\n  \n\n    But I don’t know what to do to revive it. Any thoughts or advice welcome\n  \n\n    Cheers\n  \n\n\nhttps://imgur.com/a/HUpCVXH"},
{"Title": "Research about data platform for university thesis", "Author": "u/Phacebyaz", "Content": "Hello guys and girls :)\n  \n\n    My name is Augustin, and I'm currently studying and researching how data professionals, like you, can maximize the impact of data platforms.\n  \n\n    I'm working on a concept which aims to create a data platform for marketing use, for an eSport team. The goal would be to provide a platform that simplifies complex data sets and transforms them into actionable insights.\n  \n\n    I'd love to hear your thoughts on the following questions:\n  \n\n\n\n\n\n    What are the biggest challenges you currently face with data platforms?\n  \n\n\n\n\n\n    What features do you find most useful in existing platforms, and what do you wish they could improve?\n  \n\n\n\n\n\n    How important are predictive analytics for your work, and what predictive features do you find valuable?\n  \n\n\n\n\n\n    Your input will directly contribute to refining my research and I'd greatly appreciate your insights! If you have any questions about it, feel free to ask, I will gladly answer!\n  \n\n    Thanks a lot for your time :)\n  \n\n    Augustin"},
{"Title": "Looking for bluray drive", "Author": "u/TheLordDarcy", "Content": "Hello, this probably has been asked before but going through the answers online I got more lost. There is a lot to learn, and I have little time to do my own research so appreciate your patience. I seek your recommendation for an external bluray drive that meet the following requirements (which might not even exist in one drive):\n  \n\n\n\n\n\n    I can use it to view DVD/bluray 4k directly on TV (without PC)\n  \n\n\n\n\n\n    I can connect it to PC to read/write/ rip DVD/bluray 4k\n  \n\n\n\n\n\n    Durable and not slow.\n  \n\n\n\n\n\n    Cost is not a big issue.\n  \n\n\n\n\n\n    Purchase link is appreciated."},
{"Title": "Is this the right place for me?", "Author": "u/Yellow-beef", "Content": "Honestly, I'm wondering if this is the right part of Reddit for me, because I can't bear the idea of belonging to subs that don't have anything to offer me nor do I have anything to offer in return. I do hoard data.\n  \n\n    I hoard academic papers. And I do that because over the years I've noticed that schools of thought change and frankly, just because the ideas of one era are outdated, doesn't mean they lack knowledge we should still access. So I download them and save them because one day I might write a paper and need to reference that.\n  \n\n    But I also love to share. I love love love sharing access to things, it's literally my life's purpose to add to the world library of the internet. I want to upload them to the web so that people can access them for free. Where should I do that?\n  \n\n    If this isn't the right place for this, please let me know where that place is. thanks guys!"},
{"Title": "Should i sell my Synology NAS?", "Author": "u/Asthixity", "Content": "+1-2 TB per month (4K 10:2:2 H264, XAVC S mainly)\n  \n\n    Currently having :\n  \n\n    -S923+ with 2.5GBe\n  \n        -SHR1 4x12 TB // Main server with 10TB of file\n\n    -Truenas Celeron G5905/16GB with 10GBe being built with used stuff i have:\n  \n         -RAIDZ2 8x5TB 2.5 SMR // Backup of Main\n         -RAIDZ1 or Stripped Mirror 4x18TB recertified drives \n\n    -Cold backup to other drives(2.5 SMR USB)\n  \n\n    I'm doing 99% video editing on Davinci resolve, using for now the NAS as an archive or to be started project.\nDoing long form video locally on 2x2TB NVME, project are getting over 2TB so having to split is a nightmare to manage as i need to sometimes, shoot more stuff + parrallel project in the meanwhile.\n  \n\n    Questions:\n  \n\n    -Should i get rid of the DS923+ and simply build 1 Larger Truenas server?\n  \n          1. Is a Celeron G5905 enough for the task of editing through the 10GBe?\n\n         2. Should i upgrade to a Ryzen build(3600/5600) to get the benefits of ECC ram considering my workstation isn't equiped with?\n\n\n\n\n\n    What would be the drive array, considering the 12TB have 20000H running time so basically unsellable/not reliable?"},
{"Title": "Anyone know of a good object storage GUI for Ubuntu?", "Author": "u/danielrosehill", "Content": "Hi guys,\n  \n\n    I want to set up a \"miscellaneous\" object storage bucket for manually backing up all the little bits and pieces not covered by other approaches.\n  \n\n    I use B2 buckets for a lot of backup stuff (and am familiar with CLIs like rclone). But I think it would be really nice to have a GUI just to be able to periodically add/remove buckets without having to do everything over the command line.\n  \n\n    ExpanDrive looked promising but won't \"see\" any of my B2 buckets so ... I'm not tempted to try it out with other services.\n  \n\n    Anything else out there? Something vendor-made would be particularly appealing as it would take away the requirement for the integration to .. you know ... work.\n  \n\n    TIA for any recommendations."},
{"Title": "Best raid setup for me?", "Author": "u/Khodexian", "Content": "Hi, I've posted a few times about similar questions. I was going to use mergerfs and snapraid but it was a bit too complex for me to setup. Particularly the file sorting.\n  \n\n    I have roughly 120tb~ in my server and want to get the max amount of usage space I can while having good redundancy.\n  \n\n    I was hoping to use the same server to run a minecraft server too. I don't know if the raid programs are usually the actual Os or a program you run on Linux. I'd prefer the latter so I can run a server and potential some torrenting.\n  \n\n    Before I had debian but somehow it got a weird bootloader corruption. So I might end up reinstalling everything which sucks. So recommended Linux programs would be appreciated too. (all I remember is docker)\n  \n\n    Any advice on what I should do?"},
{"Title": "Has anyone built the Modular ITX NAS tower?", "Author": "u/JesseJ3D", "Content": "I'm curious... This looks like a fun project but I have some questions that don't seem to be explained via the 3D Printing site where you can buy the case.  Here is the y/o Reddit Post.  A few questions I have is what MB has 13 SATA Ports?  He refers to a ASROCK MB that supports 3.  Sure Add to the 1 PCI slot for 5 more SATA ports.  However the case boasts 13 drives.  Not saying they are wrong but I'm just wondering how?\n  \n\n    Also those side information panels that appear to be an LCD.  Never seen that before anyone got a link?\n  \n\n    Is this a very bad idea?  This could be fun and TrueNAS is a good target for this.\n  \n\n\nhttps://www.reddit.com/r/DataHoarder/comments/1181b68/free_modular_nas_enclosure_stackable_drive/"},
{"Title": "SM SC847 PSU is beeping, replaced it and its still beeping?", "Author": "u/sittingmongoose", "Content": "I have had an SM SC847(or whatever the common 36 bay model is) for a few years now.  I host it in my parents basement and when I went over the other day I noticed the beeping went on, coincidently, as I got there.  I pulled the PSU and swapped the position with the other PSU and same result, that one PSU is beeping like its dead.  So I ordered a replacement(Exact same model as the dead one, except the new one is a REV 1.3 and the old model was a REV 1.1).  It is still beeping though.  Any help would be greatly appreciated!\n  \n\n    Edit: Forgot I had a little WiFi kill switch in between the ups and psu.  That is what died, which made the power cord not work.  Mystery solved!"},
{"Title": "8 external easy stores suddenly not showing in explorer.", "Author": "u/thegameksk", "Content": "When I connect them it shows it's connected In add/remove device. They spin up and make no weird noises. Tried different ports and wires. 2 of them are just out of the wrap. I feel like it's a pc issue but idk what. What are the odds that the 6 ones I've had (oldest 1 yr) and the 2 brand new ones all are just dead?"},
{"Title": "Any software on PC that can do this?? showing stats in circle graphs of file types or something similar. Preferably for images, video and audio files. This is from Aves Libre on android.", "Author": "u/BoxziBurrito", "Content": "No content"},
{"Title": "Using Beyond Compare how should I get it to keep copies of a file with the same name?", "Author": "u/Mysterious-Topic-628", "Content": "I have to synchronize 2 drives to be the same keeping elements from both drives both newer and older because sometimes I work on the copies from the wrong drive. I did a test on a folder before using it for serious things cuz I'm not sure I understand how its working but here:\n  \n\n\nhttps://ibb.co/album/Mc5FnV\n\n\n\n    So in the first pic, I made 2 similar folders on each drive, and then made them slightly different, adding files. Then I opened the main project file on drive 1 and changed something and resaved so the only difference was the modification time\n  \n\n    Then using the Update Both command on Beyond Compare 2, it copied things over to each to make both the same, a combo of both. BUT it seems it messed up on the main project file because now only the one modified at 5:49 \"this to\" AND the undo file that go with it exists. I expected it to keep both, rename a copy or something. This would be disaster if it happened to my real files, good thing I didn't run it on the whole drives yet. Is there an option or something that'd keep both every time there's a same name different time scenario?\n  \n\n    Also, for the future, am i using the best workflow here to save/edit? I got a travel drive, and a at-home drive, that are both essentially used to work off of and backup when my pitiful macbook air storage (256gb) runs low. Sometimes I move a project over to the macbook so i dont have to keep a drive plugged in while in the car and then when I get home offload it back onto the drives, that's how sometimes there's older-but-still-wanna-keep completely different versions on each drive. Then occasionally I manually backup the changes i made from travel drive onto the at-home drive, and barely ever work directly off the macbook unless i forgot to switch it over to a drive. And then rarely I have a bigger drive used only for combining all of it in archives."},
{"Title": "Feedback for Archive NAS Solution", "Author": "u/SkoobahGG", "Content": "I am designing an On Prem archival storage solution and I'm looking for some feedback as to the hardware choices and any suggestions for other potential solutions.\n  \n\n\nRequirements:\n\n\n\n\n\n\n\n    750 TB's of useable storage with about 10% growth YoY.\n  \n\n\n\n\n\n    Redundancy where feasible for a Small Business (i.e. dual controller, hot swappable disks, etc)\n  \n\n\n\n\n\n    Budget ~$20k-30k\n  \n\n\n\n\n\n\nUse Case:\n\n\n\n\n\n\n\n    Archival data, does not need to be Tier 1 or Tier 2 storage\n  \n\n\n\n\n\n    Video Files and Video Projects from Adobe Premier\n  \n\n\n\n\n\n    Image Files\n  \n\n\n\n\n\n\nProposed Solution:\n\n\n\n    Super Micro: SSG-640SP-E1CR60\n  \n\n    OS: TrueNAS Core\n  \nhttps://preview.redd.it/feedback-for-archive-nas-solution-v0-rdiq5zntagzc1.png"},
{"Title": "Help please. vidsrc.to (VidPlay) cant find a way to download videos.", "Author": "u/UNSEiT", "Content": "So I've been thinking about saving videos.\nUsually it's not a problem finding a videos source of some kind from a website and somehow downloading it.\nBut \nvidsrc.to\n is putting up a fight.\n  \n\n    On their actually site, I can't inspect website code properly.\n  \n\n    When I do find a way to inspect the video source link in the code, through other websites which use their video player.\nThere is a link which can open a new website, probably has the file I'm looking for in it.\nBut trying to inspect that code closes that website.\nNot to mention its only a white page.\n  \n\n    I have even gone to try an add-on which is called DownThemAll!\nGot a tip from this subreddit even. But sadly it doesnt work with vidsrc.\nSo I hope I can get some help here."},
{"Title": "Question about 20 TB harddrives", "Author": "Unknown author", "Content": "Hello,\n  \n\n    I have a HTPC, and use it to download and watch movies or TV shows with Kodi. During the day and at night the PC is off. I don't game on it.\n  \n\n    I am looking to add an extra 20 TB harddrive, but there is a big difference in prices for these HDD's.\n  \n\n    The WD Red pro is the most expensive, € 575,-. But the Toshiba MG10 and the Seagate Iron wolf pro are both around € 330,-.\n  \n\n    Why is there such a big price difference? Because the read and writing speeds are almost the same (the WD is even slighty slower than the other 2). Which one should I buy?\n  \n\n    Thank you in advance."},
{"Title": "Building first nas", "Author": "u/extio-Storm", "Content": "I am trying to create an Nas. My budget might as well be zero, with the exception of I just purchased 2 Western digital gold 18 terabyte drives.\n  \n\n    I have a gaming computer I built in 2012, and I intend to multi purpose it for everything. Someone mentioned proxmox, and I was thinking of using that to run something like true nas alongside home assistant, and possibly store security camera video on a partition and possibly even use it as a plex server. The gaming computer has an Asus tuf motherboard, cpu is an i5 4 cores. Oh and a 750 ti card.\n  \n\n    So I'm not asking for a lot of information, but I'm just trying to figure out if this is a horrible idea in some way.\n  \n\n    That and also, what Nas software should I use.\n  \n\n    As a side note I ordered those Western digitals from their website, and it's been like 5 days and it still hasn't even shipped yet... Should I be worried?"},
{"Title": "Can't clone dying drive onto new HDD due to old HDD that freezes", "Author": "u/gab51299", "Content": "Apologies if anything Im doing is wrong, I'm not too familiar with backing up and I'm now paying the price. My old HDD is starting to die (hopefully still salvageable).\n  \n\n    For context, this used to be my main OS drive almost 10 years ago, but after building a new pc I just plugged it in as a secondary drive. Recently the hard drive disappeared after starting my PC; it wasnt appearing in file explorer. A restart later it reappeared, but the PC would experience large lag spikes every 5 minutes or so. Now its at the point where the PC won't boot with the HDD inserted via SATA.\nI temporarily removed it and set the SATA port to be hot-pluggable, so I can plug it in after booting. I tried this and \nany time I'd attempt to open the folders/open up Macrium, the application will just freeze.\n\n\n\n    I was hoping to load up Macrium with a new HDD plugged in, plug in the old hdd via hotplug SATA, and then clone that onto the new HDD and hopefully get a clean copy on a new drive. This doesnt work because like I mentioned, the software freezes as soon as I plug in the HDD, and continues as soon as I remove it.\n  \n\n    What can I do to try to salvage it? Hopefully there's something I can do."},
{"Title": "Way to digitize VHS home videos with current VHS player?", "Author": "u/halfam", "Content": "No content"},
{"Title": "Easiest way to backup disk from windows 11", "Author": "u/cargt3", "Content": "Hi,\n  \n\n    I recently installed windows 11 on new hard drive. I want to backup up old windows 10 disk in case i didnt move some data. I want to store it in single sile. What is bast tool to do this?\n  \n\n    regards"},
{"Title": "Cheap LTO drives form AliExpress: yay or nay?", "Author": "u/gjvnq1", "Content": "I've been seeing some used Dell PowerVault LTO7 drives being sold for cheap on AliExpress and I would like advice on whether or not it's worth to take a gamble on them.\n  \n\n    Interestingly these products listings seem to always come with two models: a cheap LTO7-6T (like under 500 USD) and an expensive LTO8 (like 5-10 kUSD)."},
{"Title": "Anyone tested \"unlimited data\" from the new Xfinity NOW Internet plan?", "Author": "u/Endda", "Content": "As a hoarder at heart, I've been forced to pay Comcast an additional $30 to pay for their unlimited data addon.\n  \n\n    They recently tested a new Internet plan (called NOW Internet) that claims to offer 100Mbps down for $30. And that supposedly includes unlimited data.\n  \n\n    Since that total price is the price of the data cap addon, I've been tempted to switch plans.\n  \n\n    So I'm curious if another have made the switch already. I'd love to hear your experience with it so far"},
{"Title": "Using an external drive for an iPad/Windows cross platform usage; which is more stable, ExFat or APFS (with APFS Paragon for Windows)?", "Author": "u/lolwutdo", "Content": "I've seen that ExFat can be unstable sometimes and corrupt files especially on iPadOS, so I was thinking of going with APFS even though it's not native to Windows and I would have to use a program called APFS Paragon for Windows.\n  \n\n    My only worry is that using something like APFS Paragon might also be unstable since it's not native.\n  \n\n    The drive will be shared back and forth between a Windows PC and an iPad Pro, which format would you pick?"},
{"Title": "Télécharger toutes les vidéos TikTok mise en favoris d'un seul coup sur PC (Windows 11, Firefox) ?", "Author": "u/sypqys", "Content": "Bonjour\nAvec IDM je peux en télécharger une à une mais il y en a trop...\nExiste-t-il un script pour TamperMonkey ou GreaseMonkey qui permette de les télécharger toutes ?\nMerci !!"},
{"Title": "Using HDDs from Pre-Build External HDDs", "Author": "u/CodeJBDA", "Content": "Hi All,\nIn my everlasting pursuit for more space, I was thinking about buying some of \nthese\n, cracking open the case and using the HDDs inside. It seems like a pretty slick idea because the seem to be on sale a lot. The problem I have is that I remember watching a video where the creator tried to go this route but found out the the HDDs were pretty nerfed. For the life of me I cannot find that video to get more details, so I am asking here.\n  \n\n    Would it be a good idea to get those HDDs and put them in my NAS?"},
{"Title": "Used Hard Drives", "Author": "u/B00ster99", "Content": "I've been using USB Drives for storage for a while and got a good deal on a used NAS. I came with some hard drives and I wasn't sure about using them. Any know a good program to fully wipe the drives?\n  \n\n    Since the drives are uses I won't be storing anything I'm not okay with losing but want to make sure there isn't anything that on the drives that could corrupt the data."},
{"Title": "What actually happens when you initiate a hardware raid?", "Author": "u/AcidicVaginaLeakage", "Content": "With my areca card, when I initiate a new raid, it takes a long time to set things up. What's it actually doing in that time?\n  \n\n    Reason I'm curious is because I'm upgrading from 12tb drives to 24 tb drives and after I do the formatting, I encrypt the raid with veracrypt. If that initial format of the cluster is writing random data to every drive in the raid, then I should be able to get away with a quick format on the veracrypt side and save myself the time it takes to write another 200 tb of random data to disk.\n  \n\n    edit: getting downvoted for asking a question? the fk?"},
{"Title": "Télécharger toutes les vidéos TikTok mise en favoris d'un seul coup sur PC (Windows 11, Firefox) ?", "Author": "u/sypqys", "Content": "Bonjour\n  \n\n    Avec IDM je peux en télécharger une à une mais il y en a trop...\nExiste-t-il un script qui permette de les télécharger toutes ?\n  \n\n    Merci !!"},
{"Title": "Looking for bluray drive", "Author": "u/TheLordDarcy", "Content": "Hello, this probably has been asked before but going through the answers online I got more lost. There is a lot to learn, and I have little time to do my own research so appreciate your patience. I seek your recommendation for an external bluray drive that meet the following requirements (which might not even exist in one drive):\n  \n\n\n\n\n\n    I can use it to view DVD/bluray 4k directly on TV (without PC)\n  \n\n\n\n\n\n    I can connect it to PC to read/write/ rip DVD/bluray 4k\n  \n\n\n\n\n\n    Durable and not slow.\n  \n\n\n\n\n\n    Cost is not a big issue.\n  \n\n\n\n\n\n    Purchase link is appreciated."},
{"Title": "Is this the right place for me?", "Author": "u/Yellow-beef", "Content": "Honestly, I'm wondering if this is the right part of Reddit for me, because I can't bear the idea of belonging to subs that don't have anything to offer me nor do I have anything to offer in return. I do hoard data.\n  \n\n    I hoard academic papers. And I do that because over the years I've noticed that schools of thought change and frankly, just because the ideas of one era are outdated, doesn't mean they lack knowledge we should still access. So I download them and save them because one day I might write a paper and need to reference that.\n  \n\n    But I also love to share. I love love love sharing access to things, it's literally my life's purpose to add to the world library of the internet. I want to upload them to the web so that people can access them for free. Where should I do that?\n  \n\n    If this isn't the right place for this, please let me know where that place is. thanks guys!"},
{"Title": "Should i sell my Synology NAS?", "Author": "u/Asthixity", "Content": "+1-2 TB per month (4K 10:2:2 H264, XAVC S mainly)\n  \n\n    Currently having :\n  \n\n    -S923+ with 2.5GBe\n  \n        -SHR1 4x12 TB // Main server with 10TB of file\n\n    -Truenas Celeron G5905/16GB with 10GBe being built with used stuff i have:\n  \n         -RAIDZ2 8x5TB 2.5 SMR // Backup of Main\n         -RAIDZ1 or Stripped Mirror 4x18TB recertified drives \n\n    -Cold backup to other drives(2.5 SMR USB)\n  \n\n    I'm doing 99% video editing on Davinci resolve, using for now the NAS as an archive or to be started project.\nDoing long form video locally on 2x2TB NVME, project are getting over 2TB so having to split is a nightmare to manage as i need to sometimes, shoot more stuff + parrallel project in the meanwhile.\n  \n\n    Questions:\n  \n\n    -Should i get rid of the DS923+ and simply build 1 Larger Truenas server?\n  \n          1. Is a Celeron G5905 enough for the task of editing through the 10GBe?\n\n         2. Should i upgrade to a Ryzen build(3600/5600) to get the benefits of ECC ram considering my workstation isn't equiped with?\n\n\n\n\n\n    What would be the drive array, considering the 12TB have 20000H running time so basically unsellable/not reliable?"},
{"Title": "Anyone know of a good object storage GUI for Ubuntu?", "Author": "u/danielrosehill", "Content": "Hi guys,\n  \n\n    I want to set up a \"miscellaneous\" object storage bucket for manually backing up all the little bits and pieces not covered by other approaches.\n  \n\n    I use B2 buckets for a lot of backup stuff (and am familiar with CLIs like rclone). But I think it would be really nice to have a GUI just to be able to periodically add/remove buckets without having to do everything over the command line.\n  \n\n    ExpanDrive looked promising but won't \"see\" any of my B2 buckets so ... I'm not tempted to try it out with other services.\n  \n\n    Anything else out there? Something vendor-made would be particularly appealing as it would take away the requirement for the integration to .. you know ... work.\n  \n\n    TIA for any recommendations."},
{"Title": "Best raid setup for me?", "Author": "u/Khodexian", "Content": "Hi, I've posted a few times about similar questions. I was going to use mergerfs and snapraid but it was a bit too complex for me to setup. Particularly the file sorting.\n  \n\n    I have roughly 120tb~ in my server and want to get the max amount of usage space I can while having good redundancy.\n  \n\n    I was hoping to use the same server to run a minecraft server too. I don't know if the raid programs are usually the actual Os or a program you run on Linux. I'd prefer the latter so I can run a server and potential some torrenting.\n  \n\n    Before I had debian but somehow it got a weird bootloader corruption. So I might end up reinstalling everything which sucks. So recommended Linux programs would be appreciated too. (all I remember is docker)\n  \n\n    Any advice on what I should do?"},
{"Title": "Has anyone built the Modular ITX NAS tower?", "Author": "u/JesseJ3D", "Content": "I'm curious... This looks like a fun project but I have some questions that don't seem to be explained via the 3D Printing site where you can buy the case.  Here is the y/o Reddit Post.  A few questions I have is what MB has 13 SATA Ports?  He refers to a ASROCK MB that supports 3.  Sure Add to the 1 PCI slot for 5 more SATA ports.  However the case boasts 13 drives.  Not saying they are wrong but I'm just wondering how?\n  \n\n    Also those side information panels that appear to be an LCD.  Never seen that before anyone got a link?\n  \n\n    Is this a very bad idea?  This could be fun and TrueNAS is a good target for this.\n  \n\n\nhttps://www.reddit.com/r/DataHoarder/comments/1181b68/free_modular_nas_enclosure_stackable_drive/"},
{"Title": "SM SC847 PSU is beeping, replaced it and its still beeping?", "Author": "u/sittingmongoose", "Content": "I have had an SM SC847(or whatever the common 36 bay model is) for a few years now.  I host it in my parents basement and when I went over the other day I noticed the beeping went on, coincidently, as I got there.  I pulled the PSU and swapped the position with the other PSU and same result, that one PSU is beeping like its dead.  So I ordered a replacement(Exact same model as the dead one, except the new one is a REV 1.3 and the old model was a REV 1.1).  It is still beeping though.  Any help would be greatly appreciated!\n  \n\n    Edit: Forgot I had a little WiFi kill switch in between the ups and psu.  That is what died, which made the power cord not work.  Mystery solved!"},
{"Title": "8 external easy stores suddenly not showing in explorer.", "Author": "u/thegameksk", "Content": "When I connect them it shows it's connected In add/remove device. They spin up and make no weird noises. Tried different ports and wires. 2 of them are just out of the wrap. I feel like it's a pc issue but idk what. What are the odds that the 6 ones I've had (oldest 1 yr) and the 2 brand new ones all are just dead?"},
{"Title": "Any software on PC that can do this?? showing stats in circle graphs of file types or something similar. Preferably for images, video and audio files. This is from Aves Libre on android.", "Author": "u/BoxziBurrito", "Content": "No content"},
{"Title": "Using Beyond Compare how should I get it to keep copies of a file with the same name?", "Author": "u/Mysterious-Topic-628", "Content": "I have to synchronize 2 drives to be the same keeping elements from both drives both newer and older because sometimes I work on the copies from the wrong drive. I did a test on a folder before using it for serious things cuz I'm not sure I understand how its working but here:\n  \n\n\nhttps://ibb.co/album/Mc5FnV\n\n\n\n    So in the first pic, I made 2 similar folders on each drive, and then made them slightly different, adding files. Then I opened the main project file on drive 1 and changed something and resaved so the only difference was the modification time\n  \n\n    Then using the Update Both command on Beyond Compare 2, it copied things over to each to make both the same, a combo of both. BUT it seems it messed up on the main project file because now only the one modified at 5:49 \"this to\" AND the undo file that go with it exists. I expected it to keep both, rename a copy or something. This would be disaster if it happened to my real files, good thing I didn't run it on the whole drives yet. Is there an option or something that'd keep both every time there's a same name different time scenario?\n  \n\n    Also, for the future, am i using the best workflow here to save/edit? I got a travel drive, and a at-home drive, that are both essentially used to work off of and backup when my pitiful macbook air storage (256gb) runs low. Sometimes I move a project over to the macbook so i dont have to keep a drive plugged in while in the car and then when I get home offload it back onto the drives, that's how sometimes there's older-but-still-wanna-keep completely different versions on each drive. Then occasionally I manually backup the changes i made from travel drive onto the at-home drive, and barely ever work directly off the macbook unless i forgot to switch it over to a drive. And then rarely I have a bigger drive used only for combining all of it in archives."},
{"Title": "Feedback for Archive NAS Solution", "Author": "u/SkoobahGG", "Content": "I am designing an On Prem archival storage solution and I'm looking for some feedback as to the hardware choices and any suggestions for other potential solutions.\n  \n\n\nRequirements:\n\n\n\n\n\n\n\n    750 TB's of useable storage with about 10% growth YoY.\n  \n\n\n\n\n\n    Redundancy where feasible for a Small Business (i.e. dual controller, hot swappable disks, etc)\n  \n\n\n\n\n\n    Budget ~$20k-30k\n  \n\n\n\n\n\n\nUse Case:\n\n\n\n\n\n\n\n    Archival data, does not need to be Tier 1 or Tier 2 storage\n  \n\n\n\n\n\n    Video Files and Video Projects from Adobe Premier\n  \n\n\n\n\n\n    Image Files\n  \n\n\n\n\n\n\nProposed Solution:\n\n\n\n    Super Micro: SSG-640SP-E1CR60\n  \n\n    OS: TrueNAS Core\n  \nhttps://preview.redd.it/feedback-for-archive-nas-solution-v0-rdiq5zntagzc1.png"},
{"Title": "Help please. vidsrc.to (VidPlay) cant find a way to download videos.", "Author": "u/UNSEiT", "Content": "So I've been thinking about saving videos.\nUsually it's not a problem finding a videos source of some kind from a website and somehow downloading it.\nBut \nvidsrc.to\n is putting up a fight.\n  \n\n    On their actually site, I can't inspect website code properly.\n  \n\n    When I do find a way to inspect the video source link in the code, through other websites which use their video player.\nThere is a link which can open a new website, probably has the file I'm looking for in it.\nBut trying to inspect that code closes that website.\nNot to mention its only a white page.\n  \n\n    I have even gone to try an add-on which is called DownThemAll!\nGot a tip from this subreddit even. But sadly it doesnt work with vidsrc.\nSo I hope I can get some help here."},
{"Title": "Question about 20 TB harddrives", "Author": "Unknown author", "Content": "Hello,\n  \n\n    I have a HTPC, and use it to download and watch movies or TV shows with Kodi. During the day and at night the PC is off. I don't game on it.\n  \n\n    I am looking to add an extra 20 TB harddrive, but there is a big difference in prices for these HDD's.\n  \n\n    The WD Red pro is the most expensive, € 575,-. But the Toshiba MG10 and the Seagate Iron wolf pro are both around € 330,-.\n  \n\n    Why is there such a big price difference? Because the read and writing speeds are almost the same (the WD is even slighty slower than the other 2). Which one should I buy?\n  \n\n    Thank you in advance."},
{"Title": "Building first nas", "Author": "u/extio-Storm", "Content": "I am trying to create an Nas. My budget might as well be zero, with the exception of I just purchased 2 Western digital gold 18 terabyte drives.\n  \n\n    I have a gaming computer I built in 2012, and I intend to multi purpose it for everything. Someone mentioned proxmox, and I was thinking of using that to run something like true nas alongside home assistant, and possibly store security camera video on a partition and possibly even use it as a plex server. The gaming computer has an Asus tuf motherboard, cpu is an i5 4 cores. Oh and a 750 ti card.\n  \n\n    So I'm not asking for a lot of information, but I'm just trying to figure out if this is a horrible idea in some way.\n  \n\n    That and also, what Nas software should I use.\n  \n\n    As a side note I ordered those Western digitals from their website, and it's been like 5 days and it still hasn't even shipped yet... Should I be worried?"},
{"Title": "Can't clone dying drive onto new HDD due to old HDD that freezes", "Author": "u/gab51299", "Content": "Apologies if anything Im doing is wrong, I'm not too familiar with backing up and I'm now paying the price. My old HDD is starting to die (hopefully still salvageable).\n  \n\n    For context, this used to be my main OS drive almost 10 years ago, but after building a new pc I just plugged it in as a secondary drive. Recently the hard drive disappeared after starting my PC; it wasnt appearing in file explorer. A restart later it reappeared, but the PC would experience large lag spikes every 5 minutes or so. Now its at the point where the PC won't boot with the HDD inserted via SATA.\nI temporarily removed it and set the SATA port to be hot-pluggable, so I can plug it in after booting. I tried this and \nany time I'd attempt to open the folders/open up Macrium, the application will just freeze.\n\n\n\n    I was hoping to load up Macrium with a new HDD plugged in, plug in the old hdd via hotplug SATA, and then clone that onto the new HDD and hopefully get a clean copy on a new drive. This doesnt work because like I mentioned, the software freezes as soon as I plug in the HDD, and continues as soon as I remove it.\n  \n\n    What can I do to try to salvage it? Hopefully there's something I can do."},
{"Title": "Way to digitize VHS home videos with current VHS player?", "Author": "u/halfam", "Content": "No content"},
{"Title": "Easiest way to backup disk from windows 11", "Author": "u/cargt3", "Content": "Hi,\n  \n\n    I recently installed windows 11 on new hard drive. I want to backup up old windows 10 disk in case i didnt move some data. I want to store it in single sile. What is bast tool to do this?\n  \n\n    regards"},
{"Title": "Cheap LTO drives form AliExpress: yay or nay?", "Author": "u/gjvnq1", "Content": "I've been seeing some used Dell PowerVault LTO7 drives being sold for cheap on AliExpress and I would like advice on whether or not it's worth to take a gamble on them.\n  \n\n    Interestingly these products listings seem to always come with two models: a cheap LTO7-6T (like under 500 USD) and an expensive LTO8 (like 5-10 kUSD)."},
{"Title": "Anyone tested \"unlimited data\" from the new Xfinity NOW Internet plan?", "Author": "u/Endda", "Content": "As a hoarder at heart, I've been forced to pay Comcast an additional $30 to pay for their unlimited data addon.\n  \n\n    They recently tested a new Internet plan (called NOW Internet) that claims to offer 100Mbps down for $30. And that supposedly includes unlimited data.\n  \n\n    Since that total price is the price of the data cap addon, I've been tempted to switch plans.\n  \n\n    So I'm curious if another have made the switch already. I'd love to hear your experience with it so far"},
{"Title": "Using an external drive for an iPad/Windows cross platform usage; which is more stable, ExFat or APFS (with APFS Paragon for Windows)?", "Author": "u/lolwutdo", "Content": "I've seen that ExFat can be unstable sometimes and corrupt files especially on iPadOS, so I was thinking of going with APFS even though it's not native to Windows and I would have to use a program called APFS Paragon for Windows.\n  \n\n    My only worry is that using something like APFS Paragon might also be unstable since it's not native.\n  \n\n    The drive will be shared back and forth between a Windows PC and an iPad Pro, which format would you pick?"},
{"Title": "Télécharger toutes les vidéos TikTok mise en favoris d'un seul coup sur PC (Windows 11, Firefox) ?", "Author": "u/sypqys", "Content": "Bonjour\nAvec IDM je peux en télécharger une à une mais il y en a trop...\nExiste-t-il un script pour TamperMonkey ou GreaseMonkey qui permette de les télécharger toutes ?\nMerci !!"},
{"Title": "Using HDDs from Pre-Build External HDDs", "Author": "u/CodeJBDA", "Content": "Hi All,\nIn my everlasting pursuit for more space, I was thinking about buying some of \nthese\n, cracking open the case and using the HDDs inside. It seems like a pretty slick idea because the seem to be on sale a lot. The problem I have is that I remember watching a video where the creator tried to go this route but found out the the HDDs were pretty nerfed. For the life of me I cannot find that video to get more details, so I am asking here.\n  \n\n    Would it be a good idea to get those HDDs and put them in my NAS?"},
{"Title": "Used Hard Drives", "Author": "u/B00ster99", "Content": "I've been using USB Drives for storage for a while and got a good deal on a used NAS. I came with some hard drives and I wasn't sure about using them. Any know a good program to fully wipe the drives?\n  \n\n    Since the drives are uses I won't be storing anything I'm not okay with losing but want to make sure there isn't anything that on the drives that could corrupt the data."},
{"Title": "What actually happens when you initiate a hardware raid?", "Author": "u/AcidicVaginaLeakage", "Content": "With my areca card, when I initiate a new raid, it takes a long time to set things up. What's it actually doing in that time?\n  \n\n    Reason I'm curious is because I'm upgrading from 12tb drives to 24 tb drives and after I do the formatting, I encrypt the raid with veracrypt. If that initial format of the cluster is writing random data to every drive in the raid, then I should be able to get away with a quick format on the veracrypt side and save myself the time it takes to write another 200 tb of random data to disk.\n  \n\n    edit: getting downvoted for asking a question? the fk?"},
{"Title": "Télécharger toutes les vidéos TikTok mise en favoris d'un seul coup sur PC (Windows 11, Firefox) ?", "Author": "u/sypqys", "Content": "Bonjour\n  \n\n    Avec IDM je peux en télécharger une à une mais il y en a trop...\nExiste-t-il un script qui permette de les télécharger toutes ?\n  \n\n    Merci !!"},
{"Title": "What are some good recommendations for external disc drive/software for ripping 4K & Blu-ray DVDs?", "Author": "u/bovely_argle-bargle", "Content": "I’m in the process of saving my DVD collection in digital form, so far the progress is good for all the standard format discs. But I do have a few 4Ks and Blu-rays that I know are gonna need much more special equipment for the task, only thing is is that there’s so many options available and I don’t know where to start. Any savants out there with good recommendations?"},
{"Title": "Thoughts on an appropriate NAS software solution to replace my current win 2016 server?", "Author": "u/AboutToSnap", "Content": "I'm running a somewhat dated server for my storage and basic apps that I'd like to downsize and modernize. Current setup:\n  \n\n\n\n\n\n    Dual sandy bridge xeons with 16 rdimms (152gb total - not perfectly matched) and a huge e-atx server board\n  \n\n\n\n\n\n    8 SATA storage drives (1x18tb, 1x14tb 1x12tb, 3x8tb, 2x3tb);- I do plan on replacing the two 3tb drives with a single 18tb+ drive soon.\n  \n\n\n\n\n\n    2 OS drives (2x512gb in raid1; probably unnecessary); will probably replace with a NVMe drive (I have a couple sitting around unused)\n  \n\n\n\n\n\n    4U rackmount case with a decent 750w PSU and 11 hotswap bays that I'd like to re-use (I like it, and I have a dedicated in-wall rack I want to continue to utilize)\n  \n\n\n\n\n\n    Windows Server 2016 running StableBit (drive pool, scanner, and cloud drive). All of my other applications run in a hyper-v linux VM.\n  \n\n\n\n\n\n    My problems with this setup are:\n  \n\n\n\n\n\n    Stupid power consumption, even at idle, and a lot of heat. This box lives in a room that has cooling challenges already, and while electricity here isn't super expensive, it isn't free.\n  \n\n\n\n\n\n    Inefficient software setup. I've been out of the IT game for quite a while, but I'm still under the impression that windows server has quite a lot of unnecessary overhead for what I'm doing. Maybe I'm giving too much consideration to this, but I like the idea of a freebsd or linux base OS for rock solid stability and better efficiency.\n  \n\n\n\n\n\n    Inefficient storage redundancy strategy; with StableBit duplicating everything, my ~66.8tb of actual space is effectively cut to ~33.4tb.\n  \n\n\n\n\n\n    While I'm still sorting out hardware options, I know I'm headed in one of two paths:\n  \n\n\n\n\n\n    A low power consumption setup to run as a NAS with my existing drives, and a physically separate box for applications. I know this isn't the most efficient strategy, but I just like the idea. In this case I wouldn't need any containers or VMs on the NAS box.\n  \n\n\n\n\n\n    A moderately powerful (but much more efficient) setup to do both NAS and application functions in one.\n  \n\n\n\n\n\n    Regardless of which direction I choose, I'd like to see if there is another storage solution that can meet my needs and get me off of Windows. I've looked at various options like TrueNAS, Unraid, SnapRaid+MergerFS, etc., but I'm not sure any of them are a perfect fit. My challenges are:\n  \n\n\n\n\n\n    Differing drive sizes (I'm always looking at the \"best value\" hardware, so I fully expect to continue to pick up mismatched drives)\n  \n\n\n\n\n\n    Too many drives for a single parity drive (I think pretty much all of these solutions would want to see two drives used just for parity, and some require them to be the largest drives?)\n  \n\n\n\n\n\n    I do not have anywhere to back up the ~28tb (when not duplicated) of data I currently have, so while not totally mandatory, it would be \nreally\n nice to migrate without losing any data.\n  \n\n\n\n\n\n    I've also had a recommendation that I continue using windows server, but strip it down as much as possible by removing unnecessary features and services. I'm not totally against this, but it's not ideal in my mind.\n  \n\n    Any suggestions on what software might be a good fit for the NAS side of the house? Gotta keep getting my hoarding on but want to figure this out :)"},
{"Title": "Question about occasionaly accessing and backing up my files", "Author": "u/techlover1010", "Content": "i need advice on what to do.\ncurrently using windows 10\ni am ok with a monthly backing up my data and occasionally reading from the backup like copying from the backup to my everyday pc.\ndo i need a nas for this or is there an alternative tool i can use."},
{"Title": "Odd Samba Name Resolution Error", "Author": "u/Ben4425", "Content": "I've encountered the weirdest problem setting up a new Samba server on Debian 12.5 with Samba 4.17.12. Specifically, I can't access shares when I use \njust\n the server's host name but I can access them just fine using the server's fully qualified domain name or its IP address. So:\n  \n\n\n\n\n\n    192.168.20.8: Works\n  \n\n\n\n\n\n    vega.mydomain.com: Works\n  \n\n\n\n\n\n    vega: \nFails\n\n\n\n\n\n\n\n    My client is running Windows 11 and I get the error \"Windows cannot access \\\\vega\" if I use just the server name. If I also specify a share, like \"\\\\vega\\photos\", then I get an \"Enter network credentials\" prompt where I can enter my user name and SMB password. This immediately returns \"Access Denied\" and requests the credentials again.\n  \n\n    What's odd is that the authentication \nsucceeds\n but then I get a weird encryption error:\n  \n\n\n[2024/05/09 09:02:44.311451, 2] ../../source3/auth/auth.c: 324(auth_check_ntlm_password) check_ntlm_password: authentication for user [myuser] -> [myuser] -> [myuser] succeeded\n\n\n\n\n[2024/05/09 09:02:44.322044, 1] ../../source3/smbd/smb2_tcon.c: 245(smbd_smb2_tree_connect) smbd_smb2_tree_connect: reject request to share [IPC$] as 'VEGA\\myuser' without encryption or signing. Disconnecting.\n\n\n\n\n[2024/05/09 09:02:44.322142, 3] ../../source3/smbd/smb2_server.c:3961(smbd_smb2_request_error_ex) smbd_smb2_request_error_ex: smbd_smb2_request_error_ex: idx[1] status[NT_STATUS_ACCESS_DENIED] || at ../../source3/smbd/smb2_tcon.c:151\n\n\n\n    I don't think this is a DNS problem because the client can resolve my '\\\\vega' server and because 'vega' works fine for other uses such as NFS and SSH.\n  \n\n    So, any ideas? I can always use a fully qualified domain name or an IP address but I'd love to understand this because I wasted a couple hours trying to fix my Samba 'smb.conf' file when, apparently, it was just fine and instead there was this weird error with using the host's name.\n  \n\n    P.S. I thought about posting this to \nr/samba\n but that group has about 600 members while \nr/DataHoarder\n has about 700,000."},
{"Title": "2x Raid 1 vs Raid 10 with 4 Drives", "Author": "u/BAR0N_AL0HA", "Content": "I'm getting my first NAS soon and I've been reading up on raid levels and whatnot.\n  \n\n    What are the potential downsides to having 2 Raid 1 pools as opposed to 1 large Raid 10 pool other than having 2 smaller volumes vs 1 large volume?\n  \n\n    The main reason I'm thinking of going this route is because you can lose everything if the wrong 2 drives fail in Raid 10, but if I split it into 2 pools and the wrong 2 drives fail I will only lose half my stuff.\n  \n\n    I will be keeping backups, but I'd rather not have to rebuild everything if something goes wrong.\n  \n\n    What sort of rebuild times would I be looking at with 14TB drives?\n  \n\n    How likely are the drives to fail, really?  Am I just being paranoid and overthinking it?"},
{"Title": "I need to download a website that needs a login/password and is protected with Cloudflare. Didn't work with HTTrack. Is there an extension of some sort or a windows app that could download a website cash in real time while i scroll and load all the pages of said website?", "Author": "u/Digital_Cactus", "Content": "Tried HTTrack and could log in using session cookies (as i think) but can't get past the loading icon, so i think it's the Cloudflare and i can't get in\n  \n\n    The website itself is a pirated copy so no legal problems here\n  \n\n    Can you please help?"},
{"Title": "SanDisk 8TB SSD Desk Drive Review", "Author": "u/It_Is1-24PM", "Content": "No content"},
{"Title": "NAS HDD VS Consumer desktop HDD for storage <1TB (TERL issue)", "Author": "u/sukirti2004", "Content": "I am creating a DIY NAS which will be turned on 24/7 and will be used mostly for backup of my photos and videos and sometimes as plex server to view those old photos and videos.\n  \n\n    I don't require very high storage for this so I am thinking of buying a 1 TB HDD but I am not able to decide which one to buy. I already have a backup of my data to cloud.\n  \n\n    NAS HDD almost serves my purpose but they are expensive and some  have SMR which don't have very good reviews. Also from all that I have read online, NAS HDD are required to be run on some sort of redundancy like raid as  they don't have built-in data protection or recovery systems.\n  \n\n    Then comes normal consumer WD blue type HDD which are not rated to be run 24/7 but have built-in data protection or recovery systems.\n  \n\n    I have searched all the internet and some say you can use a single NAS HDD but some say don't use them so I am really confused right now which one to buy.\n  \n\n    EDIT: It should be TLER."},
{"Title": "3D Printed JBOD Enclosure", "Author": "u/FriedCheese06", "Content": "Just wanted to share a project I'm wrapping up. Essentially, I needed a JBOD enclosure, but didn't want to fork out several hundred on a pre-built enclosure. After digging through this subreddit and a few others, I landed on using an external HBA card along with 3D printing an enclosure. The full setup is:\n  \n\n\n\n\n\n    x8 8 Tb Seagate IronWolf drives (with capacity to go up to 16 drives)\n  \n\n\n\n\n\n    beQuiet! Straight Power 11 650W PSU (had laying around)\n  \n\n\n\n\n\n    Two SFF-8087 to SFF-8088 converter cards\n  \n\n\n\n\n\n    x6 Noctua NF-P12 fans\n  \n\n\n\n\n\n    Right now, I'm using an LSI 9200-8e card on the server side, but looking to swap that to one of the 16e variants down the rode.\n  \n\n    Just dropping this in to say thanks for the posts that helped me get this wrapped up!\n  \n\n\nImgur Album"},
{"Title": "Best software to generate a list of personal media?", "Author": "u/GiantRobotAlien", "Content": "Is there any software that would generate a printable list of all your personal media (example: list of movies, list of tv shows)"},
{"Title": "Can I Scan Slides on a Canon Pixma MG3620?", "Author": "u/YarnDame", "Content": "I have used the scanner on this inexpensive Canon printer to scan some photos and, as far as I can tell, it does an adequate job. I have a few hundred old 35mm slides that I want to digitize.  Is this something I can do on the Canon? I presume I would need to make some kind of template to block out the light around the slides.  Thanks for any advice."},
{"Title": "Beta decks- How much better is S-Video from EDV-7000 compared with composite video from SL-HF900", "Author": "u/AriFeblowitzVFX", "Content": "Hey guys!\nI have a SL-HF900 because I heard it has superior image quality and heard a rumor it had S-video, it does not have S-video- Now I'm wondering how important it is to switch to an S-video deck if I want high quality digitization?\nDoes the superior image quality of the SL-HF900 hold up despite being composite only?  Or should I cough up extra cash for the EDV-7000?"},
{"Title": "YA Slow SSD-to-SSD Transfer Complaint", "Author": "u/bread-it", "Content": "I'm currently transferring 1.3TB of data from one 2TB Samsung T7 SSD to another. Both formatted APFS/GUID Partition map.\n  \n\n    The drives are plugged into an OWC Thunderbolt Hub via ANKER USB C to USB C cables.\n  \n\n    Progress thermometer is estimating 10 hours. That seems super slow.  Any ideas?\n  \n\n    My Mac is running Sonoma. I realize thunderbolt cables would be faster."},
{"Title": "N00B Raid question", "Author": "u/CL4R101", "Content": "Hello Fellow hoarders\n  \n\n    I wanted to ask something that might be n00bish :D, I have a raided archive server currently with 30TB of storage, this is I think 10 slots with 4TB each, in I think Raid 5 or some level of redundancy raid.\n  \n\n    I want to increase that to 18TB per slot, the reason is although only 50% of the 30TB is used currently, as I am switching things up with Proxmox, I over estimate the storage the VMs need meaning it's taking up more storage then originally.\n  \n\n    My question is this, as it's sacrilege to delete data, our religion forbids it and the archival god will smite me :D, (I always say best to hoard data then physical stuff :D).\n  \n\n    Is it safe to replace a 4TB with an 18TB disk, and rebuild the raid and do this 10 times? so you don't lose anything, I do have everything backed up, but recreating proxmox, mounting the disk and rsyncing the files is painstakingly slow, I did it once, I swore never again :D.\n  \n\n    I don't have the authority or budget to buy all 10 disks, but can buy 2 disks every few weeks, until all disks are replaced, the remaining 10 4TB disks will be used on other projects such as the Windows Server (while holding back vomit :D).\n  \n\n    It's worth noting these are SAS drives, I doubt that matters too much."},
{"Title": "need advice on Chinese backplane (U.2, 8639 and sata disks)", "Author": "u/jotkaPL", "Content": "hi\n  \n\n    I need some advice. Will I be able to slot SATA HDD's into this backplane?\n  \n\n    My mainboard has 2 x 8643 and I have 2x 8643<->8643 cables.\n  \n\n    Is this SFF-8639 U.2 compatible with the SATA connector I have in my drives? They say it's SAS/SATA/NVME compatible.\n  \nhttps://preview.redd.it/need-advice-on-chinese-backplane-u-2-8639-and-sata-disks-v0-adkola5g0dzc1.png\n\n    According to what I can see here, sliding SATA drive to 8639 should be electrically and mechanically possible:\n  \n\n\nhttps://www.techtarget.com/searchstorage/definition/U2-SSD-formerly-SFF-8639\n\n\nhttps://preview.redd.it/need-advice-on-chinese-backplane-u-2-8639-and-sata-disks-v0-uxoloyj83dzc1.png"},
{"Title": "How would you go about scraping this audio?", "Author": "u/Flowingblaze", "Content": "I was wondering how would you all go about scraping audio from \nthis website\n? I mainly want it for my Anki deck to learn the language and was curious how others would go about getting the audio files from the website in an efficient way other than using inspect elements \"network\" feature. All audio files are stored at \nhttps://www.talk-lenape.org/associatedmedia/sound/sample_sentence/NUMBER\n or \nhttps://www.talk-lenape.org/associatedmedia/sound/dictionary_entry/NUMBER\n from what I can tell. So It would mean probably just getting a list of all the numbers and downloading from each link. I wonder when would it end though what I mean is, how many audio files are on there website? The highest number I've seen is 16,638 from what I remember. This also assumes that each audio file is uploaded in a 1, 2, 3, 4, 5, etc. order and have been assigned that number in those links that I gave examples of above. Does this make sense?"},
{"Title": "Document scanner that produces sharp, crisp scans", "Author": "u/Lauren-1234", "Content": "Can anyone recommend an ADF duplex document scanner that produces scans with a high fidelity to the original?\n  \n\n    The scans made with every all-in-one I’ve ever owned are low-quality. No matter how much I experiment with the settings, the text still lacks clarity and looks a bit fuzzy. Same with my Canon ImageFormula P-215 with ADF/duplex.\n  \n\n    To get decent looking document scans, is the professional grade Fujitsu ScanSnap our only hope? Please tell me there are less expensive options out there."},
{"Title": "Power cable extender for the 8 bay mediasonic dock?", "Author": "u/thegameksk", "Content": "Just received my dock and the power cable is really small. Is there an extender for the power cable?"},
{"Title": "Backing up Interactive Maps?", "Author": "u/BewareOfThePug", "Content": "How do you backup an interactive map, specifically this:\n  \n\n\nhttps://www.ons.gov.uk/census/maps/"},
{"Title": "Downloading Panopto Lectures from Canvas", "Author": "u/Majestic-Owl-5801", "Content": "Anyone know a program to use to do this? or some steps to get it from the webpage source code?"},
{"Title": "Pioneer BDR-XS07S slim a bad idea for BD-XL M-Disc burning?", "Author": "u/573v0", "Content": "This is a USB-C powered slim drive. I am worried that the etching power will be less than that of a full sized external burner. Just curious if anyone here has any experience using the two or might know the internal science of what's going on in the inside that might sway me away from the slim burner. Thanks :)"},
{"Title": "Low Speed, High Capacity SSD Arrays", "Author": "u/gpmidi", "Content": "tl;dr Thoughts about building out high capacity, low speed, cheap SSD pools!\n  \n\n    I find myself once again looking at building out an array or two of pure SSD. Since my use case is more about random IO and low request latency, I'm thinking 2.5\" SATA/SAS drives in one of my existing 2.5\" MD1200 units. While the 6Gbps\n4\n2 links will be a major limiter in throughput, it's more than meet my performance needs. Plus a bunch of 6 or 8 TiB SATA consumer SSDs in a 2.5\" format will be cheaper than m.2 and the like. Keep in mind, I'd be getting 12-24 of these disks. It'd be ZFS+Lustre+IB on the soft side.\n  \n\n    Thanks folks!"},
{"Title": "Those of you who have cold storage, how do you keep track of file lists?", "Author": "u/nbtm_sh", "Content": "At the moment I'm just using a spreadsheet with the file-lists and drive serial numbers but obviously this solution won't last forever.\n  \n\n    Does anyone have another method that they use?"},
{"Title": "Want to download videos from an event I went to.", "Author": "u/Cr3eperboy", "Content": "So I went to this Disney Fan event last weekend and they had also streamed and recorded the event. I went to the event in person. However in the in person tickets the streamed versions are included. Now after 30 days the videos will be deleted (at least publicly) but I would still like to archive them just in case. I'm not sure what program they use. Here is the link to where the videos can be found: \nStage89.com/stream\n (Mod if I'm not allowed to post links in a post let me know and I will edit it out.) The first 30 seconds can be watched before asking for a streaming ticket."},
{"Title": "DigiKam is too slow for thousands of photos", "Author": "Unknown author", "Content": "I’ve probably read about 20 posts in this sub about photo management software and many of them mention DigiKam.\n  \n\n    I have about 6,000 photos and 200 videos (about 20gb) collected from my immediate family members across various devices. Not all metadata is intact, but it’s not too big of a deal. I was just wondering what the best software is to rename all of these files in this format: \nISODATETIME-0000x\n I’ve gotten this working in DigiKam but it’s just painfully slow, it took like 10 minutes for a few hundred photos. When I was managing this set of files on Windows I was able to use Bulk Rename Utility just fine, but DigiKam just slows to a crawl. Would appreciate any advice, especially from you guys with hundreds of gb of data. Thanks!"},
{"Title": "What are some good recommendations for external disc drive/software for ripping 4K & Blu-ray DVDs?", "Author": "u/bovely_argle-bargle", "Content": "I’m in the process of saving my DVD collection in digital form, so far the progress is good for all the standard format discs. But I do have a few 4Ks and Blu-rays that I know are gonna need much more special equipment for the task, only thing is is that there’s so many options available and I don’t know where to start. Any savants out there with good recommendations?"},
{"Title": "Thoughts on an appropriate NAS software solution to replace my current win 2016 server?", "Author": "u/AboutToSnap", "Content": "I'm running a somewhat dated server for my storage and basic apps that I'd like to downsize and modernize. Current setup:\n  \n\n\n\n\n\n    Dual sandy bridge xeons with 16 rdimms (152gb total - not perfectly matched) and a huge e-atx server board\n  \n\n\n\n\n\n    8 SATA storage drives (1x18tb, 1x14tb 1x12tb, 3x8tb, 2x3tb);- I do plan on replacing the two 3tb drives with a single 18tb+ drive soon.\n  \n\n\n\n\n\n    2 OS drives (2x512gb in raid1; probably unnecessary); will probably replace with a NVMe drive (I have a couple sitting around unused)\n  \n\n\n\n\n\n    4U rackmount case with a decent 750w PSU and 11 hotswap bays that I'd like to re-use (I like it, and I have a dedicated in-wall rack I want to continue to utilize)\n  \n\n\n\n\n\n    Windows Server 2016 running StableBit (drive pool, scanner, and cloud drive). All of my other applications run in a hyper-v linux VM.\n  \n\n\n\n\n\n    My problems with this setup are:\n  \n\n\n\n\n\n    Stupid power consumption, even at idle, and a lot of heat. This box lives in a room that has cooling challenges already, and while electricity here isn't super expensive, it isn't free.\n  \n\n\n\n\n\n    Inefficient software setup. I've been out of the IT game for quite a while, but I'm still under the impression that windows server has quite a lot of unnecessary overhead for what I'm doing. Maybe I'm giving too much consideration to this, but I like the idea of a freebsd or linux base OS for rock solid stability and better efficiency.\n  \n\n\n\n\n\n    Inefficient storage redundancy strategy; with StableBit duplicating everything, my ~66.8tb of actual space is effectively cut to ~33.4tb.\n  \n\n\n\n\n\n    While I'm still sorting out hardware options, I know I'm headed in one of two paths:\n  \n\n\n\n\n\n    A low power consumption setup to run as a NAS with my existing drives, and a physically separate box for applications. I know this isn't the most efficient strategy, but I just like the idea. In this case I wouldn't need any containers or VMs on the NAS box.\n  \n\n\n\n\n\n    A moderately powerful (but much more efficient) setup to do both NAS and application functions in one.\n  \n\n\n\n\n\n    Regardless of which direction I choose, I'd like to see if there is another storage solution that can meet my needs and get me off of Windows. I've looked at various options like TrueNAS, Unraid, SnapRaid+MergerFS, etc., but I'm not sure any of them are a perfect fit. My challenges are:\n  \n\n\n\n\n\n    Differing drive sizes (I'm always looking at the \"best value\" hardware, so I fully expect to continue to pick up mismatched drives)\n  \n\n\n\n\n\n    Too many drives for a single parity drive (I think pretty much all of these solutions would want to see two drives used just for parity, and some require them to be the largest drives?)\n  \n\n\n\n\n\n    I do not have anywhere to back up the ~28tb (when not duplicated) of data I currently have, so while not totally mandatory, it would be \nreally\n nice to migrate without losing any data.\n  \n\n\n\n\n\n    I've also had a recommendation that I continue using windows server, but strip it down as much as possible by removing unnecessary features and services. I'm not totally against this, but it's not ideal in my mind.\n  \n\n    Any suggestions on what software might be a good fit for the NAS side of the house? Gotta keep getting my hoarding on but want to figure this out :)"},
{"Title": "Question about occasionaly accessing and backing up my files", "Author": "u/techlover1010", "Content": "i need advice on what to do.\ncurrently using windows 10\ni am ok with a monthly backing up my data and occasionally reading from the backup like copying from the backup to my everyday pc.\ndo i need a nas for this or is there an alternative tool i can use."},
{"Title": "Odd Samba Name Resolution Error", "Author": "u/Ben4425", "Content": "I've encountered the weirdest problem setting up a new Samba server on Debian 12.5 with Samba 4.17.12. Specifically, I can't access shares when I use \njust\n the server's host name but I can access them just fine using the server's fully qualified domain name or its IP address. So:\n  \n\n\n\n\n\n    192.168.20.8: Works\n  \n\n\n\n\n\n    vega.mydomain.com: Works\n  \n\n\n\n\n\n    vega: \nFails\n\n\n\n\n\n\n\n    My client is running Windows 11 and I get the error \"Windows cannot access \\\\vega\" if I use just the server name. If I also specify a share, like \"\\\\vega\\photos\", then I get an \"Enter network credentials\" prompt where I can enter my user name and SMB password. This immediately returns \"Access Denied\" and requests the credentials again.\n  \n\n    What's odd is that the authentication \nsucceeds\n but then I get a weird encryption error:\n  \n\n\n[2024/05/09 09:02:44.311451, 2] ../../source3/auth/auth.c: 324(auth_check_ntlm_password) check_ntlm_password: authentication for user [myuser] -> [myuser] -> [myuser] succeeded\n\n\n\n\n[2024/05/09 09:02:44.322044, 1] ../../source3/smbd/smb2_tcon.c: 245(smbd_smb2_tree_connect) smbd_smb2_tree_connect: reject request to share [IPC$] as 'VEGA\\myuser' without encryption or signing. Disconnecting.\n\n\n\n\n[2024/05/09 09:02:44.322142, 3] ../../source3/smbd/smb2_server.c:3961(smbd_smb2_request_error_ex) smbd_smb2_request_error_ex: smbd_smb2_request_error_ex: idx[1] status[NT_STATUS_ACCESS_DENIED] || at ../../source3/smbd/smb2_tcon.c:151\n\n\n\n    I don't think this is a DNS problem because the client can resolve my '\\\\vega' server and because 'vega' works fine for other uses such as NFS and SSH.\n  \n\n    So, any ideas? I can always use a fully qualified domain name or an IP address but I'd love to understand this because I wasted a couple hours trying to fix my Samba 'smb.conf' file when, apparently, it was just fine and instead there was this weird error with using the host's name.\n  \n\n    P.S. I thought about posting this to \nr/samba\n but that group has about 600 members while \nr/DataHoarder\n has about 700,000."},
{"Title": "2x Raid 1 vs Raid 10 with 4 Drives", "Author": "u/BAR0N_AL0HA", "Content": "I'm getting my first NAS soon and I've been reading up on raid levels and whatnot.\n  \n\n    What are the potential downsides to having 2 Raid 1 pools as opposed to 1 large Raid 10 pool other than having 2 smaller volumes vs 1 large volume?\n  \n\n    The main reason I'm thinking of going this route is because you can lose everything if the wrong 2 drives fail in Raid 10, but if I split it into 2 pools and the wrong 2 drives fail I will only lose half my stuff.\n  \n\n    I will be keeping backups, but I'd rather not have to rebuild everything if something goes wrong.\n  \n\n    What sort of rebuild times would I be looking at with 14TB drives?\n  \n\n    How likely are the drives to fail, really?  Am I just being paranoid and overthinking it?"},
{"Title": "I need to download a website that needs a login/password and is protected with Cloudflare. Didn't work with HTTrack. Is there an extension of some sort or a windows app that could download a website cash in real time while i scroll and load all the pages of said website?", "Author": "u/Digital_Cactus", "Content": "Tried HTTrack and could log in using session cookies (as i think) but can't get past the loading icon, so i think it's the Cloudflare and i can't get in\n  \n\n    The website itself is a pirated copy so no legal problems here\n  \n\n    Can you please help?"},
{"Title": "SanDisk 8TB SSD Desk Drive Review", "Author": "u/It_Is1-24PM", "Content": "No content"},
{"Title": "NAS HDD VS Consumer desktop HDD for storage <1TB (TERL issue)", "Author": "u/sukirti2004", "Content": "I am creating a DIY NAS which will be turned on 24/7 and will be used mostly for backup of my photos and videos and sometimes as plex server to view those old photos and videos.\n  \n\n    I don't require very high storage for this so I am thinking of buying a 1 TB HDD but I am not able to decide which one to buy. I already have a backup of my data to cloud.\n  \n\n    NAS HDD almost serves my purpose but they are expensive and some  have SMR which don't have very good reviews. Also from all that I have read online, NAS HDD are required to be run on some sort of redundancy like raid as  they don't have built-in data protection or recovery systems.\n  \n\n    Then comes normal consumer WD blue type HDD which are not rated to be run 24/7 but have built-in data protection or recovery systems.\n  \n\n    I have searched all the internet and some say you can use a single NAS HDD but some say don't use them so I am really confused right now which one to buy.\n  \n\n    EDIT: It should be TLER."},
{"Title": "3D Printed JBOD Enclosure", "Author": "u/FriedCheese06", "Content": "Just wanted to share a project I'm wrapping up. Essentially, I needed a JBOD enclosure, but didn't want to fork out several hundred on a pre-built enclosure. After digging through this subreddit and a few others, I landed on using an external HBA card along with 3D printing an enclosure. The full setup is:\n  \n\n\n\n\n\n    x8 8 Tb Seagate IronWolf drives (with capacity to go up to 16 drives)\n  \n\n\n\n\n\n    beQuiet! Straight Power 11 650W PSU (had laying around)\n  \n\n\n\n\n\n    Two SFF-8087 to SFF-8088 converter cards\n  \n\n\n\n\n\n    x6 Noctua NF-P12 fans\n  \n\n\n\n\n\n    Right now, I'm using an LSI 9200-8e card on the server side, but looking to swap that to one of the 16e variants down the rode.\n  \n\n    Just dropping this in to say thanks for the posts that helped me get this wrapped up!\n  \n\n\nImgur Album"},
{"Title": "Best software to generate a list of personal media?", "Author": "u/GiantRobotAlien", "Content": "Is there any software that would generate a printable list of all your personal media (example: list of movies, list of tv shows)"},
{"Title": "Can I Scan Slides on a Canon Pixma MG3620?", "Author": "u/YarnDame", "Content": "I have used the scanner on this inexpensive Canon printer to scan some photos and, as far as I can tell, it does an adequate job. I have a few hundred old 35mm slides that I want to digitize.  Is this something I can do on the Canon? I presume I would need to make some kind of template to block out the light around the slides.  Thanks for any advice."},
{"Title": "Beta decks- How much better is S-Video from EDV-7000 compared with composite video from SL-HF900", "Author": "u/AriFeblowitzVFX", "Content": "Hey guys!\nI have a SL-HF900 because I heard it has superior image quality and heard a rumor it had S-video, it does not have S-video- Now I'm wondering how important it is to switch to an S-video deck if I want high quality digitization?\nDoes the superior image quality of the SL-HF900 hold up despite being composite only?  Or should I cough up extra cash for the EDV-7000?"},
{"Title": "YA Slow SSD-to-SSD Transfer Complaint", "Author": "u/bread-it", "Content": "I'm currently transferring 1.3TB of data from one 2TB Samsung T7 SSD to another. Both formatted APFS/GUID Partition map.\n  \n\n    The drives are plugged into an OWC Thunderbolt Hub via ANKER USB C to USB C cables.\n  \n\n    Progress thermometer is estimating 10 hours. That seems super slow.  Any ideas?\n  \n\n    My Mac is running Sonoma. I realize thunderbolt cables would be faster."},
{"Title": "N00B Raid question", "Author": "u/CL4R101", "Content": "Hello Fellow hoarders\n  \n\n    I wanted to ask something that might be n00bish :D, I have a raided archive server currently with 30TB of storage, this is I think 10 slots with 4TB each, in I think Raid 5 or some level of redundancy raid.\n  \n\n    I want to increase that to 18TB per slot, the reason is although only 50% of the 30TB is used currently, as I am switching things up with Proxmox, I over estimate the storage the VMs need meaning it's taking up more storage then originally.\n  \n\n    My question is this, as it's sacrilege to delete data, our religion forbids it and the archival god will smite me :D, (I always say best to hoard data then physical stuff :D).\n  \n\n    Is it safe to replace a 4TB with an 18TB disk, and rebuild the raid and do this 10 times? so you don't lose anything, I do have everything backed up, but recreating proxmox, mounting the disk and rsyncing the files is painstakingly slow, I did it once, I swore never again :D.\n  \n\n    I don't have the authority or budget to buy all 10 disks, but can buy 2 disks every few weeks, until all disks are replaced, the remaining 10 4TB disks will be used on other projects such as the Windows Server (while holding back vomit :D).\n  \n\n    It's worth noting these are SAS drives, I doubt that matters too much."},
{"Title": "need advice on Chinese backplane (U.2, 8639 and sata disks)", "Author": "u/jotkaPL", "Content": "hi\n  \n\n    I need some advice. Will I be able to slot SATA HDD's into this backplane?\n  \n\n    My mainboard has 2 x 8643 and I have 2x 8643<->8643 cables.\n  \n\n    Is this SFF-8639 U.2 compatible with the SATA connector I have in my drives? They say it's SAS/SATA/NVME compatible.\n  \nhttps://preview.redd.it/need-advice-on-chinese-backplane-u-2-8639-and-sata-disks-v0-adkola5g0dzc1.png\n\n    According to what I can see here, sliding SATA drive to 8639 should be electrically and mechanically possible:\n  \n\n\nhttps://www.techtarget.com/searchstorage/definition/U2-SSD-formerly-SFF-8639\n\n\nhttps://preview.redd.it/need-advice-on-chinese-backplane-u-2-8639-and-sata-disks-v0-uxoloyj83dzc1.png"},
{"Title": "How would you go about scraping this audio?", "Author": "u/Flowingblaze", "Content": "I was wondering how would you all go about scraping audio from \nthis website\n? I mainly want it for my Anki deck to learn the language and was curious how others would go about getting the audio files from the website in an efficient way other than using inspect elements \"network\" feature. All audio files are stored at \nhttps://www.talk-lenape.org/associatedmedia/sound/sample_sentence/NUMBER\n or \nhttps://www.talk-lenape.org/associatedmedia/sound/dictionary_entry/NUMBER\n from what I can tell. So It would mean probably just getting a list of all the numbers and downloading from each link. I wonder when would it end though what I mean is, how many audio files are on there website? The highest number I've seen is 16,638 from what I remember. This also assumes that each audio file is uploaded in a 1, 2, 3, 4, 5, etc. order and have been assigned that number in those links that I gave examples of above. Does this make sense?"},
{"Title": "Document scanner that produces sharp, crisp scans", "Author": "u/Lauren-1234", "Content": "Can anyone recommend an ADF duplex document scanner that produces scans with a high fidelity to the original?\n  \n\n    The scans made with every all-in-one I’ve ever owned are low-quality. No matter how much I experiment with the settings, the text still lacks clarity and looks a bit fuzzy. Same with my Canon ImageFormula P-215 with ADF/duplex.\n  \n\n    To get decent looking document scans, is the professional grade Fujitsu ScanSnap our only hope? Please tell me there are less expensive options out there."},
{"Title": "Power cable extender for the 8 bay mediasonic dock?", "Author": "u/thegameksk", "Content": "Just received my dock and the power cable is really small. Is there an extender for the power cable?"},
{"Title": "Backing up Interactive Maps?", "Author": "u/BewareOfThePug", "Content": "How do you backup an interactive map, specifically this:\n  \n\n\nhttps://www.ons.gov.uk/census/maps/"},
{"Title": "Downloading Panopto Lectures from Canvas", "Author": "u/Majestic-Owl-5801", "Content": "Anyone know a program to use to do this? or some steps to get it from the webpage source code?"},
{"Title": "Pioneer BDR-XS07S slim a bad idea for BD-XL M-Disc burning?", "Author": "u/573v0", "Content": "This is a USB-C powered slim drive. I am worried that the etching power will be less than that of a full sized external burner. Just curious if anyone here has any experience using the two or might know the internal science of what's going on in the inside that might sway me away from the slim burner. Thanks :)"},
{"Title": "Low Speed, High Capacity SSD Arrays", "Author": "u/gpmidi", "Content": "tl;dr Thoughts about building out high capacity, low speed, cheap SSD pools!\n  \n\n    I find myself once again looking at building out an array or two of pure SSD. Since my use case is more about random IO and low request latency, I'm thinking 2.5\" SATA/SAS drives in one of my existing 2.5\" MD1200 units. While the 6Gbps\n4\n2 links will be a major limiter in throughput, it's more than meet my performance needs. Plus a bunch of 6 or 8 TiB SATA consumer SSDs in a 2.5\" format will be cheaper than m.2 and the like. Keep in mind, I'd be getting 12-24 of these disks. It'd be ZFS+Lustre+IB on the soft side.\n  \n\n    Thanks folks!"},
{"Title": "Those of you who have cold storage, how do you keep track of file lists?", "Author": "u/nbtm_sh", "Content": "At the moment I'm just using a spreadsheet with the file-lists and drive serial numbers but obviously this solution won't last forever.\n  \n\n    Does anyone have another method that they use?"},
{"Title": "Want to download videos from an event I went to.", "Author": "u/Cr3eperboy", "Content": "So I went to this Disney Fan event last weekend and they had also streamed and recorded the event. I went to the event in person. However in the in person tickets the streamed versions are included. Now after 30 days the videos will be deleted (at least publicly) but I would still like to archive them just in case. I'm not sure what program they use. Here is the link to where the videos can be found: \nStage89.com/stream\n (Mod if I'm not allowed to post links in a post let me know and I will edit it out.) The first 30 seconds can be watched before asking for a streaming ticket."},
{"Title": "DigiKam is too slow for thousands of photos", "Author": "Unknown author", "Content": "I’ve probably read about 20 posts in this sub about photo management software and many of them mention DigiKam.\n  \n\n    I have about 6,000 photos and 200 videos (about 20gb) collected from my immediate family members across various devices. Not all metadata is intact, but it’s not too big of a deal. I was just wondering what the best software is to rename all of these files in this format: \nISODATETIME-0000x\n I’ve gotten this working in DigiKam but it’s just painfully slow, it took like 10 minutes for a few hundred photos. When I was managing this set of files on Windows I was able to use Bulk Rename Utility just fine, but DigiKam just slows to a crawl. Would appreciate any advice, especially from you guys with hundreds of gb of data. Thanks!"},
{"Title": "New HDD for Seagate Personal Cloud possible?", "Author": "u/ultimateBassMann", "Content": "Hi guys\n  \n\n    The HDD of my personal cloud died recently. The white led was constantly blinking and I couldn't find the devices ip adress on my router. I took out the drive and connected it via SATA USB adapter to my PC. The drive doesn't even get recognized.\n  \n\n    My files are all backed up. Does anyone of you know if I can simply install a new drive and set everything up from scratch? Or is the OS also stored on the dead HDD?\n  \n\n    Edit: I found a solution in \nmy thead\n at \nr/Seagate\n thx to eltano_06"},
{"Title": "Moving from OMV to TrueNAS - advices for my use case?", "Author": "u/rudeer_poke", "Content": "I am a long time OpenMediaVault user, started somewhere around 2015 maybe, running a MergerFS/SnapRAID stack. Recently I have acquired 8 12TB SAS drives and I am considering to move to a striped 2x ZFS RAIDZ1 setup in TrueNAS (once i figure out how to set that up, because it the config seems to offer either stripe, mirror, RAIDZx, etc but not a combination of them).\n  \n\n    My question is related to TrueNAS and its flexibility. I am basically using OMV as plain linux machine that has a convenient web interface for managing storage & shares, but otherwise I am spending most of my time in the debian shell, doing many of the following things:\n  \n\n\n\n\n\n    running docker containers, editing compose files, etc.\n  \n\n\n\n\n\n    temporarily mounting various hard drives with NTFS/ext4/btrfs file systems to copy data from them or perform some tests on them, etc.\n  \n\n\n\n\n\n    running the nvidia container toolkit for HW acceleration\n  \n\n\n\n\n\n    mounting CDs/DVDs for copying data from them onto the main storage array\n  \n\n\n\n\n\n    Now TrueNAS seems to be much more restrictive in this area, forcing the user to the user interface (even SSH access is disabled by default). As far as I noticed, docker support has been removed in favor of the internal Kubernetes-based app store.\n  \n\n    So how likely am I to break TrueNAS doing the above things via the command line? I could move my docker staff to a VM inside of TrueNAS, but for the HW acceleration, external hard drives and optical media I would be still probably stuck on TrueNAS.\n  \n\n    What is the personal experience of those of you who have went trough this change and how did you implement those features under true nas?"},
{"Title": "Good Drives For Storing Media?", "Author": "u/bossx_00", "Content": "I've started collecting films, series, documentaries and comics for quite some time now, and I'm about to run out of storage. At the moment I'm using 4TB Seagate External SSD, but I want something much larger, for instance a 12-24TB drive or multiple drives in a port. Does anyone have recommendations for an external drive(s) for media files that will live for a long time with good care, decent speed, as well as a decent price (CAD) ? I'm on somewhat of a budget but I can stretch if it's a steal."},
{"Title": "capture card thats work good on mac sonoma", "Author": "u/vi-h-s", "Content": "hey guys, i am looking forward a capture card thats work on my mac sonoma almost bought a blackmagic intensity shuttle but reading about it found that doesn’t work in the new mac system… any ideia any help what can i use to digitalize tapes and analog glitches?"},
{"Title": "iCloud shared album link batch download method", "Author": "u/vvrrva", "Content": "i kept searching around for methods to batch download icloud photos from a shared album link and saw a few posts on here by folks asking how to do it, and i found that using jdownloader2 is by far the easiest way to do so."},
{"Title": "Bypass read only in Unlimited GDrive", "Author": "u/tecepeipe", "Content": "Let's say a friend has 10TB on Teams Drive in Google business plan with 1 user, thus 2tb. Which of these options do work if the goal is just to do a minor sync (10gb) from another source like HDD?\n  \n\n    a) move 9TB to trash, update then restore b) create 6 users, update then delete them on same day.\n  \n\n    Has anyone tried either of these? Do I get the bill for 6 additional users?\n  \n\n    Also, c) if I reduce my plan to standard, do I retain the Teams drive?"},
{"Title": "DAS for Movies and Series, connected to the TV via USB", "Author": "u/DiabloFour", "Content": "I'm considering buying a DAS 2 disk setup set to raid 1 for data redundancy, with the primary purpose of holding media to play back on the TV in the bedroom. Is this typically do-able, or am I overlooking something here? I know you can store multimedia on a USB drive and play that on the TV through the USB drive; so surely this would work the same way? It's a Hisense smart tv, from around 2018 I think, so it's not brand new, but it's new enough."},
{"Title": "WD HC560 20TB - Found a guy on local for sale group with half a dozen for sale, $250 each, worth it? Looks like they are still in the plastic wrap, condition listed “like new”", "Author": "u/West_Flounder2840", "Content": "Just wondering if I should buy this guy out or if they ever go on sale for a comparable price.\n  \n\n    I’m in the process of building an Unraid Plex server with 8 bays. All I’m doing is media streaming, not sure if these enterprise tier drives are complete overkill or even appropriate for my use case.\n  \n\n    Anything to look out for? Possible that someone bought a bunch and these are all failed? Scams? Etc.\n  \n\n    They were listed for $280 this morning, person has already dropped the price to $250. Maybe wait it out?"},
{"Title": "Which UPS is best for my NAS?", "Author": "u/NateUrBoi", "Content": "I have a Synology DS423+ and due to recent storms have now considered buying an UPS. I don't know much about the subject, but I wouldn't like to spend more than $200 as that's a bit out of my budget. I use my NAS solely for running a Plex server and hoarding random bits of the internet. I don't need the UPS for anything other than the NAS so a little above the minimum wattage should be fine. I could see it's use to charge a phone or something in a power outage however I'm mainly just looking to protect my hoard. Thanks."},
{"Title": "How can I mange and merge folders/subfolders?", "Author": "u/bulltproof", "Content": "I have 1800 folders (give or take).\nI need to put them into a main folder.\nThe main folders are named\n  \n\n    Alabama\n  \n\n    Oregon\n  \n\n    Idaho\n  \n\n    Washington\n  \n\n    ...etc\n  \n\n    I have folders on other drives named\n  \n\n    Alabama cities\n  \n\n    Alabama parks\n  \n\n    Alabama attractions\n  \n\n    Oregon cities\n  \n\n    Oregon parks\n... you get the idea.\n  \n\n    What I wan to do is put all Alabama folders (cities, parks, attractions) into the main folder Alabama\nAnd do the same for Oregon, Idaho, etc.\n  \n\n    Is there software or a script that can do this for me?"},
{"Title": "Changing audio encode speed", "Author": "u/Captain_Starkiller", "Content": "So I bought a blu ray set from germany, not realizing they encoded it for 25 FPS not the 23.9 we get here in the US. The encoding they did to it changed the audio speed so that everyone's voices are higher pitched.\n  \n\n    I'm trying to fix this problem by re-encoding, but the encoders I have don't alter the pitch when they re-encode to the correct frame rate.\n  \n\n    uh...help?"},
{"Title": "How to gradually upgrade from my bad setup", "Author": "u/evert", "Content": "Apologies if I'm too small for this subreddit, happy to ask this elsewhere!\n  \n\n    Some time ago I built a small NAS with a raspberry pi, after I read about 'shucking' and realized 2 of my external 2TB USB drives actually had SATA drives inside.\n  \n\n    I got excited, and got 2 more drives, shuck them and got this \nSabrent USB 3 bay\n.\n  \n\n    (actually I purchased this device 3 times, because both me and my partner accidentally fried it by plugging in a 48V cable instead of 12V which had the exact same shape).\n  \n\n    I have a RAID1 setup with BTRFS (4TB usable space), and I'm running out of space. I always imagined when this happened I could just get bigger disks, 1 at a time but I'm just realizing that the 2.5\" format is actually not popular and very expensive to get larger disks for.\n  \n\n    What would be an effective way for me to level this up? Should I just bite the bullet and get some 3.5\" USB enclosure? I like the I in RAID and hope I can get something cost effective and nimble that I can slowly invest in, but 2.5\" SATA HDD's connected via USB 3 feels like a dead end."},
{"Title": "Fastest way to mass download hundreds (nearly thousands) of TikTok video links?", "Author": "u/christhebaptist", "Content": "I don't have access to my account anymore, but I do have the data on it, and I had a pretty hefty bookmark collection. There's exactly 962 links in my document, and I'm wondering how I can download them en masse. I can do them one at a time, but that'll be a pain. I'm not the best with computers, but I am willing to learn how to program a bot or run a python script with a proper guide need be. Any help is appreciated. Thanks!"},
{"Title": "New HDD for Seagate Personal Cloud possible?", "Author": "u/ultimateBassMann", "Content": "Hi guys\n  \n\n    The HDD of my personal cloud died recently. The white led was constantly blinking and I couldn't find the devices ip adress on my router. I took out the drive and connected it via SATA USB adapter to my PC. The drive doesn't even get recognized.\n  \n\n    My files are all backed up. Does anyone of you know if I can simply install a new drive and set everything up from scratch? Or is the OS also stored on the dead HDD?\n  \n\n    Edit: I found a solution in \nmy thead\n at \nr/Seagate\n thx to eltano_06"},
{"Title": "Moving from OMV to TrueNAS - advices for my use case?", "Author": "u/rudeer_poke", "Content": "I am a long time OpenMediaVault user, started somewhere around 2015 maybe, running a MergerFS/SnapRAID stack. Recently I have acquired 8 12TB SAS drives and I am considering to move to a striped 2x ZFS RAIDZ1 setup in TrueNAS (once i figure out how to set that up, because it the config seems to offer either stripe, mirror, RAIDZx, etc but not a combination of them).\n  \n\n    My question is related to TrueNAS and its flexibility. I am basically using OMV as plain linux machine that has a convenient web interface for managing storage & shares, but otherwise I am spending most of my time in the debian shell, doing many of the following things:\n  \n\n\n\n\n\n    running docker containers, editing compose files, etc.\n  \n\n\n\n\n\n    temporarily mounting various hard drives with NTFS/ext4/btrfs file systems to copy data from them or perform some tests on them, etc.\n  \n\n\n\n\n\n    running the nvidia container toolkit for HW acceleration\n  \n\n\n\n\n\n    mounting CDs/DVDs for copying data from them onto the main storage array\n  \n\n\n\n\n\n    Now TrueNAS seems to be much more restrictive in this area, forcing the user to the user interface (even SSH access is disabled by default). As far as I noticed, docker support has been removed in favor of the internal Kubernetes-based app store.\n  \n\n    So how likely am I to break TrueNAS doing the above things via the command line? I could move my docker staff to a VM inside of TrueNAS, but for the HW acceleration, external hard drives and optical media I would be still probably stuck on TrueNAS.\n  \n\n    What is the personal experience of those of you who have went trough this change and how did you implement those features under true nas?"},
{"Title": "Good Drives For Storing Media?", "Author": "u/bossx_00", "Content": "I've started collecting films, series, documentaries and comics for quite some time now, and I'm about to run out of storage. At the moment I'm using 4TB Seagate External SSD, but I want something much larger, for instance a 12-24TB drive or multiple drives in a port. Does anyone have recommendations for an external drive(s) for media files that will live for a long time with good care, decent speed, as well as a decent price (CAD) ? I'm on somewhat of a budget but I can stretch if it's a steal."},
{"Title": "capture card thats work good on mac sonoma", "Author": "u/vi-h-s", "Content": "hey guys, i am looking forward a capture card thats work on my mac sonoma almost bought a blackmagic intensity shuttle but reading about it found that doesn’t work in the new mac system… any ideia any help what can i use to digitalize tapes and analog glitches?"},
{"Title": "iCloud shared album link batch download method", "Author": "u/vvrrva", "Content": "i kept searching around for methods to batch download icloud photos from a shared album link and saw a few posts on here by folks asking how to do it, and i found that using jdownloader2 is by far the easiest way to do so."},
{"Title": "Bypass read only in Unlimited GDrive", "Author": "u/tecepeipe", "Content": "Let's say a friend has 10TB on Teams Drive in Google business plan with 1 user, thus 2tb. Which of these options do work if the goal is just to do a minor sync (10gb) from another source like HDD?\n  \n\n    a) move 9TB to trash, update then restore b) create 6 users, update then delete them on same day.\n  \n\n    Has anyone tried either of these? Do I get the bill for 6 additional users?\n  \n\n    Also, c) if I reduce my plan to standard, do I retain the Teams drive?"},
{"Title": "DAS for Movies and Series, connected to the TV via USB", "Author": "u/DiabloFour", "Content": "I'm considering buying a DAS 2 disk setup set to raid 1 for data redundancy, with the primary purpose of holding media to play back on the TV in the bedroom. Is this typically do-able, or am I overlooking something here? I know you can store multimedia on a USB drive and play that on the TV through the USB drive; so surely this would work the same way? It's a Hisense smart tv, from around 2018 I think, so it's not brand new, but it's new enough."},
{"Title": "WD HC560 20TB - Found a guy on local for sale group with half a dozen for sale, $250 each, worth it? Looks like they are still in the plastic wrap, condition listed “like new”", "Author": "u/West_Flounder2840", "Content": "Just wondering if I should buy this guy out or if they ever go on sale for a comparable price.\n  \n\n    I’m in the process of building an Unraid Plex server with 8 bays. All I’m doing is media streaming, not sure if these enterprise tier drives are complete overkill or even appropriate for my use case.\n  \n\n    Anything to look out for? Possible that someone bought a bunch and these are all failed? Scams? Etc.\n  \n\n    They were listed for $280 this morning, person has already dropped the price to $250. Maybe wait it out?"},
{"Title": "Which UPS is best for my NAS?", "Author": "u/NateUrBoi", "Content": "I have a Synology DS423+ and due to recent storms have now considered buying an UPS. I don't know much about the subject, but I wouldn't like to spend more than $200 as that's a bit out of my budget. I use my NAS solely for running a Plex server and hoarding random bits of the internet. I don't need the UPS for anything other than the NAS so a little above the minimum wattage should be fine. I could see it's use to charge a phone or something in a power outage however I'm mainly just looking to protect my hoard. Thanks."},
{"Title": "How can I mange and merge folders/subfolders?", "Author": "u/bulltproof", "Content": "I have 1800 folders (give or take).\nI need to put them into a main folder.\nThe main folders are named\n  \n\n    Alabama\n  \n\n    Oregon\n  \n\n    Idaho\n  \n\n    Washington\n  \n\n    ...etc\n  \n\n    I have folders on other drives named\n  \n\n    Alabama cities\n  \n\n    Alabama parks\n  \n\n    Alabama attractions\n  \n\n    Oregon cities\n  \n\n    Oregon parks\n... you get the idea.\n  \n\n    What I wan to do is put all Alabama folders (cities, parks, attractions) into the main folder Alabama\nAnd do the same for Oregon, Idaho, etc.\n  \n\n    Is there software or a script that can do this for me?"},
{"Title": "Changing audio encode speed", "Author": "u/Captain_Starkiller", "Content": "So I bought a blu ray set from germany, not realizing they encoded it for 25 FPS not the 23.9 we get here in the US. The encoding they did to it changed the audio speed so that everyone's voices are higher pitched.\n  \n\n    I'm trying to fix this problem by re-encoding, but the encoders I have don't alter the pitch when they re-encode to the correct frame rate.\n  \n\n    uh...help?"},
{"Title": "How to gradually upgrade from my bad setup", "Author": "u/evert", "Content": "Apologies if I'm too small for this subreddit, happy to ask this elsewhere!\n  \n\n    Some time ago I built a small NAS with a raspberry pi, after I read about 'shucking' and realized 2 of my external 2TB USB drives actually had SATA drives inside.\n  \n\n    I got excited, and got 2 more drives, shuck them and got this \nSabrent USB 3 bay\n.\n  \n\n    (actually I purchased this device 3 times, because both me and my partner accidentally fried it by plugging in a 48V cable instead of 12V which had the exact same shape).\n  \n\n    I have a RAID1 setup with BTRFS (4TB usable space), and I'm running out of space. I always imagined when this happened I could just get bigger disks, 1 at a time but I'm just realizing that the 2.5\" format is actually not popular and very expensive to get larger disks for.\n  \n\n    What would be an effective way for me to level this up? Should I just bite the bullet and get some 3.5\" USB enclosure? I like the I in RAID and hope I can get something cost effective and nimble that I can slowly invest in, but 2.5\" SATA HDD's connected via USB 3 feels like a dead end."},
{"Title": "Fastest way to mass download hundreds (nearly thousands) of TikTok video links?", "Author": "u/christhebaptist", "Content": "I don't have access to my account anymore, but I do have the data on it, and I had a pretty hefty bookmark collection. There's exactly 962 links in my document, and I'm wondering how I can download them en masse. I can do them one at a time, but that'll be a pain. I'm not the best with computers, but I am willing to learn how to program a bot or run a python script with a proper guide need be. Any help is appreciated. Thanks!"},
{"Title": "Only 12TB usable with 3x 4TB and 1x 8TB RAID5", "Author": "u/Sinnagangsta", "Content": "Hi all\n  \n\n    So I am setting up a RAID5 NAS and I have 3 4TB drives and 1 8TB drive. No hot spare drives. According to a RAID calculator, I will only have 12TB of usable storage, and it says 4TB is unused. This is consistent in the NAS panel, it is showing just under 12TB, why is this? Is that 8TB drive a waste, or am I missing something?\n  \nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-b851t2bway7d1.png\nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-p7soc3bway7d1.png\nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-44fhp3bway7d1.png"},
{"Title": "Looking for a recommendation for inexpensive 2TB SSD (SATA) with decent endurance", "Author": "u/gerdude1", "Content": "Hi,\n  \n\n    I have a few mini pc's (I have a decent size NAS as well) and would like to create CEPH storage, which requires three nodes on ProxMox. Hence I am looking for recommendations for a somehow inexpensive SSD's that have decent endurance (NVME is already used on all three Mini's, but they all have space for 2.5 SSD and a SATA port available). I am in the US and see price points of ~$120 for QLC and $150 for TLC. I have access to Microcenter, but there is very little available and newegg has all the usual suspects available (e.g. 970 Evo Plus).\n  \n\n    Would love to hear about some recommendations.\n  \n\n    Thanks in advance."},
{"Title": "Five Men Convicted of Operating Massive, Illegal Streaming Service That Allegedly Had More Content Than Netflix, Hulu, Vudu and Prime Video Combined", "Author": "u/falco_iii", "Content": "No content"},
{"Title": "Feasibility/Performance of Mini-PC NAS with external HDD/SSD enclosure?", "Author": "u/RXrenesis8", "Content": "Howdy \nr/DataHoarder\n!\n  \n\n    I am still a little baby hoarder with only about 15-20TB of data floating around my noisy 10 year old desktop-turned-HTPC. I was looking to expand to ~30TB (with room to grow of course) for a couple of initiatives and initially had been set on a rack and rackmount server or NAS chassis with a bunch of 3.5\" bays for price-efficient spinning drives.\n  \n\n    The cost though! Racks = $$$ Rackmount Chassis or pre-builts = $$$$!\n  \n\n    Every penny I would save in drive capacity I would pay back in getting a nice (home-office) rack and NAS.\n  \n\n    So I've come to you questioning a pivot point: What do you think about smaller solutions? Specifically I am thinking about a Mini-PC running nnRAID connected to a JBOD enclosure for disks or large/cheap SSDs.\n  \n\n    What's the performance difference between a setup like the above and a low-end rackmount setup (which is at the limit of what I could realistically afford)?\n  \n\n    Any pitfalls I should be aware of?\n  \n\n    Thanks in advance!"},
{"Title": "dm-vdo block-Level deduplication and compression merged into Linux 6.9", "Author": "u/LeichenExpress", "Content": "No content"},
{"Title": "Best option for a \"go bag\" external?", "Author": "u/Vietname", "Content": "I have a couple of small synology NAS's, each has a dedicated drive for regular backups, but i wanted to get a small external drive (ideally SSD) to put my really important data on for emergencies, e.g. the house is on fire and i can only grab a few things.\n  \n\n    What would you recommend?"},
{"Title": "VIA RAID disks question", "Author": "u/thenovum", "Content": "Hey. Is it possible to extract the data from via raid disk members without using a VIA RAID controler? Disks are from 2004."},
{"Title": "Largest SSD is 1,000 TB in 3.5\" size, why not bring 5.25\" mechanical drive?", "Author": "u/Warcraft_Fan", "Content": "The largest hard drive is 30TB but if they would use 5.25\" drive then it'd be possible to get some hundred TB in a standard 5.25\" half height (same as CD and DVD drive)\n  \n\n    Computer cases are still produced with 5.25\" support as some people still need optical drive or possibly tape drive. So what's keeping them from putting out massive 5.25\" hard drives?"},
{"Title": "All of my data storage mediums, if you want I can update every Friday I get a new thing to put on the wall as a weekly thing", "Author": "u/LaundryMan2008", "Content": "No content"},
{"Title": "Should I use cold cloud storage for small backup (4TB)?", "Author": "u/CreativeDog2024", "Content": "I know about the 3-2-1 rule, but I've not been implementing it. I'm a college student with 3 years and 4 TB worth of movies/TV shows that have taken DAYS to download at times.\n  \n\n    I have 2 local backups, one on a segate 5tb and the other on a WD 5tb.\n  \n\n    I don't want to lose these files, I've used a plex add on to export posters and a list of my media but if I were to ever try and get them back from scratch, it would take a long time and I'm not sure I'd ever dedicated that much time.\n  \n\n    I know about aws deep glacier as a last resort and it being pretty high cost to recover, but I don't really plan to ever recover unless I both of my local backups.\n  \n\n\n\n\n\n    What should I know about?\n  \n\n\n\n\n\n    What would you do?"},
{"Title": "Khan Academy Math Library downloading at once", "Author": "u/Aggressive_Green_764", "Content": "Hello guys i don't gonna have internet for a while and i thought about downloading the math library and  i don't wanna do it manually and i wanna do it just like it's on their website not the playlists on youtube\n  \n\n    Is there any way?"},
{"Title": "Has SMR changed in the past few years?", "Author": "u/SirLouen", "Content": "I was reading this post commenting on the differences between SMR and CRM disks.\n  \n\n\nhttps://www.reddit.com/r/HomeServer/comments/hhfoqg/should_i_get_seagate_barracuda_or_seagate/\n\n\n\n\nhttps://www.youtube.com/watch?v=aztTf2gI55k\n\n\n\n    Basically, suggesting that SMR are seriously under classic CRM. But this happened to be like 4 years ago, so I wondered if Seagate has been able to figure out something to improve this for their disk, which is unlikely, but just wondering\n  \n\n    I saw today in my brick and mortar store, a Barracuda Compute 8 TB at $130 and a Barracuda Ironwolf at $190 w/ 8 TB also, so $60 difference for the same storage, not sure if its worth but feels that knowing all the issues attached with SMR (specially for a NAS where it's going to be used these disks), doesn't seem to be a good decision.\n  \n\n    So I wanted to know your opinion."},
{"Title": "500,000 Books Have Been Deleted From The Internet Archive’s Lending Library", "Author": "u/Industrious_Badger", "Content": "No content"},
{"Title": "Get WD Purple for DIY NAS in Raid? Located in India", "Author": "u/The_Bipolar_Guy", "Content": "Building my first DIY NAS. Need 2+2 tb to start off with. Trying to be as cheap as possible. Will be storing all memories and irreplaceable things. Will get an external HDD for offsite backup. Also, I do not care about read write speeds. I just want my data to be safe and backed up at the end of the day for as cheap as possible, I will add new data maybe once a month if not even more rarely. I will be using my old motherboard (6 SATA ports) and processor. Will get a new 500 GB ssd for OS and new RAM.\n  \n\n    Now here is the dilemma. I am from India and WD Purples are selling for 5250 INR each, cheapest. Next up, WD Blue is also selling for 6000+ INR. I can technically afford (but want to avoid at all costs) to get a 10TB UltraStar or EXOS for 22000 INR but I need two physical drives at least and my total storage need for backup right now or even 3 years later will not exceed 4-5TB. so a 10TB HDD will be useless, not to mention spending 45K INR on drives only (which is VERY VERY EXPENSIVE FOR ME).\n  \n\n    I know WD Purple glosses over write errors and can be bad. Chucking is equally expensive, if not more. Should I just get 2x 2tb WD Purple for 10.5K INR and set up my backup server for now. Will add more HDDs later as needed (1-4 years later). Can I do anything to prevent the write errors?\n  \n\n    Also, if there is a cheaper way, especially in the long run, I would appreciate it. Currently I have ~2TB data which grows by like 200-400GB a year. I have thought of BluRay drives but I am unable to procure new BluRay drives cheap enough."},
{"Title": "Question in regard to mergerFS", "Author": "u/leviathan2701", "Content": "Hello,\n  \n\n    I just set up a NAS using Ubuntu 24 LTS, mergerFS & snapRAID. I am new to using Ubuntu, mergerFS & snapRAID but I did follow some guides via YouTube videos on setting them up. The drive pool has been created and snapRAID is working as expected however, I have what may be an easy question that I can't quite figure out.\n  \n\n    Following the guide, the mount point for mergerFS pool is at /mnt/storage which I have no issues accessing and adding/removing files via terminal using sudo or as root however, since the owner of the /mnt/storage location is root, my user account on the machine cannot write files to /mnt/storage and I cannot share it via samba. I know changing the overall permissions to 777 to allow it is risky and not worth it and I'm sure there is another way that I should be writing files to the location without logging in as root but again, I'm new with this and still learning. Any advice/help will be appreciated.\n  \n\n    mergerFS v2.33.5\n  \n\n    edit: was able to resolve the issue with all of your help. Thank you all very much!"},
{"Title": "Honey, I Shrunk My Server", "Author": "u/sylinen", "Content": "No content"},
{"Title": "Zip/ Compress Large Anime Collection", "Author": "u/Big-Durian-5011", "Content": "Hey guys, I have a collection of about 8 TB of anime on my OS od choice, Arch Linux, and was wondering if there was a way I could automatically (manually is fine too) compress all content in a singular folder and store the compresses/ zipper files in another folder.\n  \n\n    Edit: Just to be clear, the reason I want to zip/compress my anime is to back it up, not to download more anime. My plan is to:\n  \n\n\n\n\n\n    Make a copy of my folder of anime\n  \n\n\n\n\n\n    Zip/compress the copied folder\n  \n\n\n\n\n\n    Store the zipped/compressed folder on a seperate storage device (currently being stored in a 14TB hdd).\n  \n\n\n\n\n\n    If possible, set up an automatic process to continously do this process for any new anime I download."},
{"Title": "Looking for help as a vlogging nomad. I film all content in 4k60p and visiting every country in the world. Guesstimating I'll need an additional ~24TB of storage for my remaining 100 countries. Budget: hopefully <$10k?", "Author": "u/immranderson", "Content": "Hey! I've been living exclusively out of my backpack + carryon luggage for the last decade and have been filming my travels as I go along. I've been traveling around the world and have amassed a large collection of 2/4TB Samsung T-Series SSDs which is beginning to bump up against the \nphysical carrying capacity\n in my bags.\n  \n\n    Lucky enough I've got a 128GB Pixel 1 that I use still to this day for daily remote storage + backup, so that has served me well.\n  \n\n    However, I also like to have local backups, and have been trying to shop around for SSDs. I'm trying to keep things as compact as possible, and I'm traveling so have avoided going the HDD route since my stuff can get pretty rough and tumbled quite often. I try not to edit directly off my external drives, and I've got an 8TB M-class macbook pro that I've been lugging around with me around the world.\n  \n\n    I'm trying to figure out how to handle my long term storage needs for the next few years of travel. On average, I'm capturing 100GB - 400GB per week of travel. I'm figuring I've got another 100 countries left to visit around the world, so 100 weeks * ~200GB per country maybe lands me in the ~20TB range of storage I'm anticipating I'll need for the remainder of my travels?\n  \n\n    Does anyone have any suggestions here? Could I get away with getting 2 x 16TB SSDs with external enclosures and that 32TB worth of capacity would generously cover my needs with wiggle room? If so, what SSD + enclosure combo would you recommend?"},
{"Title": "500,000 CDs", "Author": "u/Sliced_Apples", "Content": "Hello, I am working for a startup in the sports industry and we have recently come into the possession of about five hundred thousand cds with 20 year old sports footage.\n  \n\n    We are trying to train an AI model off of them so as such, they need to be digitized.\n  \n\n    I know a little about burning cds but not much. As I have been made aware, this would be “ripping” and not burning.\n  \n\n    What would be the best way to go about doing this? What storage solution would be the best? Any advice is greatly appreciated. I’m happy to answer any questions as well."},
{"Title": "I've got a decent sized physical media collection and unsure if it's worth saving lossless copies of it all", "Author": "u/TripleXero", "Content": "I've spent a stupid amount of time backing up all my DVDs and Blu-rays but I've already capped off an 11TB hard drive and split the extras between drives meant for other stuff and I'm still not done. I don't plan on getting rid of the original physical copies but it's much easier to access them digitally.\n  \n\n    I should also mention what I have backed up has been shrunk down already to decent looking MP4s to shove on iTunes for sleeker organization but I just don't know if it's worth keeping the original 1:1 files after. I shrunk the original files down once and realized after the fact that it wasn't in a flexible or presentable way for some so I'm hesitant to try again or wipe them completely after all the work. Is there maybe a good way to compress them? I've already went through and removed all non-English audio and subtitles"},
{"Title": "I need help identifying this hard drive, and where i can get the right cable.", "Author": "u/Chippomannen", "Content": "No content"},
{"Title": "I have question about ugreen enclosure", "Author": "u/Dismal_Award735", "Content": "No content"},
{"Title": "Question about Pixiv bulk downloading", "Author": "u/_izix", "Content": "Has anyone been blocked or banned from bulk downloading from pixiv?\n  \n\n    I've seen rumors that it may happen, but as far as I've been able to determine, there is no evidence of it actually happening. Is there maybe a hidden limit that's very high?\n  \n\n    I plan to download all images from users I follow with a script to update my archive with any new images every couple days. So far I have downloaded a few thousand images with no issues. Just figured I'd see if anyone has evidence of that happening before I continue.\n  \n\n    EDIT: I am using gallery-dl"},
{"Title": "Sony CCD TRV78E - how to digitize hi8 tapes?", "Author": "u/wtf94ftw", "Content": "Hey!\n  \n\n    So long story short my dad just retired and he wants to digitize his lifelong collection of hi8 tapes.\n  \n\n    I’ve read a lot of things last few days but I’m still not sure what would be the best option (budget friendly…) for the setup.\n  \n\n    Currently he’s been watching those tapes on TV with the sony CCD TRV78E camera, connected with both s-video and RCAs with an HDMI converter (\nhttps://amzn.eu/d/05vz9SBs\n) and everything’s working ok…\n  \n\n    I’m not great at these matters and I’m a bit lost tbh, but my initial idea was to plug the HDMI to a computer and record the screen as the movies are playing with a video capture sofware… which I now doubt to be an option because HDMI port on pcs don’t receive signal, is this right?\n  \n\n    Idk if the best option would be getting a camera that has the FireWire port and plays hi8 tapes or if it would be better to do this any other way, but I’ve read about those usb things not getting so much quality and I’m worried about it.\n  \n\n    Right now movies are playing in a 55” TV with good image quality and audio is perfectly synchronized, if this is relevant info in any way.\n  \n\n    He’s really motivated to do this by himself as he now have a lot of free time, but ofc this means that I’ll have to learn how to do it and teach him so he can continue by himself.\n  \n\n    Sorry, this was a long story after all, and sorry for some eventual english mistake as well!"},
{"Title": "Software for organizing manual backups over the last 10 years?", "Author": "u/PrivateAd990", "Content": "What software is available (paid or free) to help analyze my data on an external HD? it's only about a 1GB but 20+ backups (manually copied files over the years to this HD). MacOS or Linux. Wants:\n  \n\n\n\n\n\n    find data by extension (file type)\n  \n\n\n\n\n\n    find largest files\n  \n\n\n\n\n\n    identifying duplicates and handling it manually\n  \n\n\n\n\n\n    Accepting other tips of how to sift through data. I plan to organize all data to one folder rather than 20 backup folders."},
{"Title": "ServerPartDeals customer service", "Author": "u/demitrixrd", "Content": "I know many people on here already recommended SPD as a source for fair priced disks. I just wanted to add my $.02 after a recent experience with a failed drive I'd purchased a few months ago.\n  \n\n    A week ago I woke up to a TrueNas notification that a drive was faulted. I did some troubleshooting and wasn't able to recover any kind of connection to the drive. Plugging it in to a external adapter resulted in what sounded like a rock tumbler, so clearly it was beyond rescue. I started a RMA with SPD, and went back to work; expecting a few hours delay before hearing anything back. Later I realized I'd missed their almost immediate reply to the RMA request. I explained there was no way provide smart test results, and attached a video of my new rock tumbler. In short order the RMA# was provided. I shipped the faulted drive, and didn't think much of it. The drive was delivered yesterday and my replacement shipped this morning.\n  \n\n    Long story short, big kudos to ServerPartDeals for what is unprecedented customer service in the modern world; and to all the unsure shoppers, spend your money with SPD."},
{"Title": "Migrate from Unraid to OMV, SnapRAID, mergerfs. How to keep hard links, that span between two drives?", "Author": "u/ChrisWreck", "Content": "I'm in the middle of migrating from Unraid to OpenMediaVault, where I'll be using Snapraid and mergerfs.\n  \n\n    I have 3 disks, one parity and two data drives. They're using XFS in Unraid. I want to use ext4 in OMV.\n  \n\n    I have formatted the parity drive to ext4, and planned to move data from disk 1 to the parity drive, then format disk 1 to ext4, and then move all data from disk 2 to disk 1 and make disk 2 the new parity drive for SnapRAID.\n  \n\n    However, I just realized I have hard links from the arr suite, spanning over both data disks ...\n  \n\n    How can I migrate and preserve the hard links? Preferably without having to move all data to one disk in Unraid before migrating.\n  \n\n    EDIT: For those of you wondering why I'm switching, I'm actually switching from Unraid to Proxmox, but I'll use OMV to handle my disks (combination of ZFS and ext4) and shares."},
{"Title": "What's the best way to transfer all my family's iCloud backups and device storages to an external media server?", "Author": "u/sav-tech", "Content": "Currently, the data is on an iMac Mid 2011, Google Photos and iCloud.\n  \n\n    We also have spare devices that we want to recycle. Before doing that, we want to save the data on there and store it externally.\n  \n\n    I am a tech-enthusiast by nature and think that this would be a good opportunity to setup a home lab.\n  \n\n    I understand it may take some effort, but I am thinking of having folders for each person in our family and their data goes into an encrypted folder to access remotely via Mobile, PC and Samsung Smart TV..."},
{"Title": "Best free data integrity tools for validating.", "Author": "u/Captain_Starkiller", "Content": "Can anyone recommend some good tools for validating data integrity as a defense against bit rot?"},
{"Title": "Backup software", "Author": "u/bhudzallmighty", "Content": "I currently have a dedicated optiplex running linux with nextcloud docker for my iphone data. I would like to expand this system to a DIY nas with a single 20tb hdd storage for backup . What is the best software to do so? I would like to be able to backup once a day. Can i back up the whole hdd? Or just folders? Thank you"},
{"Title": "Trying To Digitize Old Cassette Tapes", "Author": "u/boosterbear", "Content": "Hello all! I have been hunting for the right location to ask my many, many questions. This may not be technical enough for this subreddit, but it seemed like the right place to go.\n  \n\n    I'm a big fan of physical media, likely casual to most here but to my friends I am perceived as intensely pro-physical media. As such, whenever people have spare tapes, CDs, DVDs, etc etc, I'm the man they throw them at.\n  \n\n    Unfortunately, I am horribly unfamiliar with the digitization process for everything except for CDs and DVDs, and even then I occasionally have hiccups.\n  \n\n    Recently I purchased the \nJVC RC-EZ38S CD Portable System\n (link to user manual) from a flea market to play some of my tapes and CDs, and realized I had a few tapes I'm unable to find anywhere online. Usually I wouldn't worry about my tapes growing old from wear because I can download songs and save them that way, but these tapes (mostly Halloween tracks) were impossible for me to find elsewhere, so I've been trying to preserve them.\n  \n\n    The JVC product I purchased plays CDs, cassette tapes, and the radio. It has one single 3.5mm jack, a headphone output. I have done some googling, and found my best bet to save the audio is through a combination of cables and Audacity. Unfortunately, my computer only recognizes my aux cord as headphones, and I cannot treat my JVC product as a microphone when using Audacity. I have two cables - one aux with two 3.5mm ends, and one cable that has a male 3.5mm on one end and the other end has two male parts, white and yellow RCA jacks.\n  \n\n    How, if at all, can I use my JVC player to preserve the tapes I have? Is there a special cord combination I may be able to put together that won't put me out of house and home (I'm unemployed and in a somewhat difficult spot financially, even a $20 purchase has me aghast sometimes) or would I be better off looking for a different product to record my tapes? A friend of mine is currently looking to rehome an old car radio with cassette player - Do those typically have RCA plugs, and would that be a way to go about this?\n  \n\n    Anything helps, even just correcting my terms so I can communicate what I'm looking for a little better - I'm in a space where I truly don't know what it is that I don't know. I'd love to be a part of saving some lost media, even if it seems a little silly. People put work into those Halloween tapes, dammit!"},
{"Title": "What are the best options for adding disks to my setup?", "Author": "u/StarLordOfTheDance", "Content": "Is it possible to transition my setup from mergeFs+Snapraid to zfs without a lot of spare storage that I don't have?\n  \n\n    I currently have 2x4TB mergeFs setup, with a 4TB drive for Snapraid parity. (Total 8TB usable storage). - currently holding 7TB of data\n  \n\n    I have purchased 2x4TB more drives. And ideally want to end up in a situation where I have 16TB of usable storage, with 1 parity. (12TB usable would be acceptable but not ideal).\n  \n\n    The mergeFs harddrives are connected to a Ubuntu server. And I am moving the whole lot to a new server running proxmox (that has a Ubuntu server running in VM).\n  \n\n    can anyone help me figure out if it's possible to migrate this to a ZFS pool that will do what I want.\n  \n\n    I also have looked at unRAID because it supports adding disks, but that is its own hypervisor. So are there alternative ways of working that can work inside a proxmox VM?"},
{"Title": "13.5 Volt", "Author": "u/Rayuzan_Mojavec", "Content": "I just got a 3.5 inch HDD. It needed 12 volts external power, but I only have 13.5 power adapter. Is it safe?"},
{"Title": "No M2TS Files on Blu-ray?", "Author": "u/Carsonsgaming", "Content": "https://preview.redd.it/no-m2ts-files-on-blu-ray-v0-1i3wz54rsn7d1.png\n\n    As the title says. I'm not finding one anywhere. These are in a folder called AACS, then there's another folder with a bdmv file but that's it. I'm a complete noob to Blu-ray ripping so I'm hoping I'm just missing something. Only interested in ripping the audio."},
{"Title": "Checking for Wiped SMART Data", "Author": "u/eakall", "Content": "So I recently got 35 2TB SSDs (mostly Samsung EVO 860/870) used and when checking the smart data for them I noticed very low power on hours.  The PoH (80-400hrs) is variable across the large set of drives and TBW is about 2-6TB for most of the drives. I was curious if there’s a way to check if the smart data has been reset?\n  \n\n    It seems a bit suspicious to me that these drives all are so low in PoH. Drives are also manufactured between 2020-2021 ish"},
{"Title": "What is the best NVME SSD controller ?", "Author": "u/Yukinoooo", "Content": "I'm looking for an NVME SSD, 5 years warranty or more and a good controller but I don't know which NVME to choose because there are controllers : \"InnoGrit IG5236\", \"InnoGrit IG5666\", \"Phison E18\", \"Phison E26\" and \"SMI SM2264\""},
{"Title": "Best option for transcoding?", "Author": "u/AbsolutelyNoClue22", "Content": "I want to use Plex to watch my movie library. I need transcoding to watch on the go, and on devices that need it. What is a good solution for this?\n  \n\n    I've thought about buying something like the TL-D800C, connect it to my laptop and run the Plex server from there. Is this a good idea? Is there a cheaper option?\n  \n\n    I'm new to all of this. I appreciate any help."},
{"Title": "Looking for some specific storage design help", "Author": "u/Real_Bad_Horse", "Content": "Hey y'all, I don't know that this is the best place for my question, but I suspect that folks around here will either have advice or know where to point me if I'm better served asking this somewhere else.\n  \n\n    I built out my homelab to learn and get a job in IT. Mission success there. I've since gotten into all kinds of stuff and have a need to rework my storage, but I'm not sure how best to set things up.\n  \n\n    Here's what I'm looking to do:\n  \n\n    Complete separation of storage and compute Compute consists of a handful of VMs running on Proxmox, and critically, a Kubernetes cluster The cluster is currently running in VMs but I have plans to move just about everything into the cluster and move into SFF PCs This is partially why the complete separation is important, for flexibility and future migration\n  \n\n    Here's what I have currently for equipment:\n  \n\n    Brocade switch with 48x 1gbe and 8x10gig sfp 2x 12 bay 3.5\" servers, one with Proxmox, one with TrueNAS 1x 24 bay 2.5\" server Repurposed NetApp 24x 3.5\" chassis, modified to work as DAS 4x 16gb spinners, currently in raidz1 ~32 old 2, 3, and 4gb spinners\n  \n\n    I found that K8s cluster was very unstable with my first setup, which was an iscsi target on the TrueNAS server. The iSCSI share was mounted in Proxmox with LVM to create K8s VM OS and NFS storage for containers. This got much better when I moved to a local 3x SSD zpool on the Proxmox host. I understand that the latency with spinners and over the network was likely the cause, but this doesn't allow for the separation if like.\n  \n\n    Use here is all over - media server is the main thing currently, which for transcoding needs fast seq read/writes, K8s app dev for work, and all kinds of testing containers for work and home. I'd also like to put all VM storage remote as well to play around with some different compute setups. I'd really love to be able to fully wipe Proxmox and try out XCP-ng, or Azure HCI, stuff like that... It's a lab, after all.\n  \n\n    I'm competent enough to implement a solution, but I guess not enough experience yet to design. I'm not afraid of complex setup, but I do need redundancy, particularly if putting these small drives to use as I don't trust them - came for free with the NetApp shelf.\n  \n\n    So... Any suggestions on how to set this up for minimal latency and fast read/write? Ceph? Mirrored ZFS using all those small spinners? Dedicated ZFS pools for each K8s node? Caching layers? Not against additional equipment, within reason, if needed."},
{"Title": "Best at-home manual photo scanner?", "Author": "u/Small_Vermicelli9655", "Content": "Looking to digitize a bunch of old family photos and was hoping for specific scanner suggestions. There’s lots of conflicting information online and I’m not very proficient in this area so was hoping for some insight lol.\n  \n\n    I’ve heard automatic scanners can mark grooves on the photos and would feel more comfortable with a manual one as time is not a priority. Hoping to stay around a $500 price range and resell after use.\n  \n\n    Thank you in advance!!"},
{"Title": "WD Red Plus 8TB vs WD Black 8TB vs IronWolf 8TB?", "Author": "u/GearFourth", "Content": "I ordered a WD Black 8TB, but now the Red Plus is on sale for $34 cheaper, do you guys believe the Black is worth $34 more?\n  \n\n    The biggest difference that I know of is Black has a longer warranty 5 vs 3. Are there any other differences? I would be using them for media storage."},
{"Title": "16x22TB disk MegaRAID data storage ZFS RaidZ2 or HW Raid 60", "Author": "u/Flat-One-7577", "Content": "Hi,\n  \n\n    I am going to build a 16 disk data storage. This will mainly be a \"backup\" to store data for some time and not need to recreate it again. Recreation would be expensive.\n  \n\n    I have few very big files and a lot of small one.\n  \n\n    Main focus is having a lot of storage. I/O is not so important.\n  \n\n    Having 16x 22TB disks attached to a MegaRAID 9500 Controller I am asking myself what would be the prefered setup?\n  \n\n    Variant A:\n  \n\n\n\n\n\n    HW Raid60\n  \n\n\n\n\n\n    on top ZFS\n  \n\n\n\n\n\n    Variant B:\n  \n\n\n\n\n\n    JBOD Mode on Controller for songle Disks\n  \n\n\n\n\n\n    ZFS\n-- create 2 RaidZ2 vdevs (6+2) and stripe them\n  \n\n\n\n\n\n    Variant C:\n  \n\n\n\n\n\n    JBOD Mode on Controller for songle Disks\n  \n\n\n\n\n\n    ZFS\n-- create one RaidZ3 vdev\n  \n\n\n\n\n\n    What would you do?\n  \n\n    Regards,\nJoachim"},
{"Title": "Why is it taking more than a day to transfer 1.6tb?", "Author": "u/RandonBrando", "Content": "I'm trying to transfer 1.6tb from a 2tb WD Easystore (5400rpm) to a 16tb ironwolf pro (7200rpm) with both drives connected through usb C. Both drives formatted in exFAT.\n  \n\n    I'm getting \nKB/s\n bytes/s - 18MB/s max.  \nNEW LOW SCORE\n\n\n\n    I need some help troubleshooting this because I'm not sure what else to check."},
{"Title": "Gallery-dl instagram help", "Author": "u/Graestra", "Content": "I'm trying to scrape an instagram account however gallery-dl isn't downloading all posts from the account. I've tried looking into config settings, but I keep getting errors about double quotes when trying to use a config file, and I'm not sure what the right setting to get it to download all posts is in the first place. Any help would be appreciated."},
{"Title": "ST12000NTZ01 vs ST12000NTA01", "Author": "u/-Rhialto-", "Content": "The Z is sold by Amazon and the A by Best Buy, could it be just that? Same disk but different number depending on reseller?"},
{"Title": "Will adding a new fan to a DAS result in the fan spinning at 100%?", "Author": "u/Apptryiguess", "Content": "I have a DAS and am pretty happy with the temps, but they could be slightly better since the DAS is in a closet and doesn't get that much airflow. My enterprise drives idle at 43-45 C which is ok, but could be a little better.\n  \n\n    So i thought about adding a new and better fan to the enclosure (Icy Box IB-3805-C31), but the fan never changes speeds, literally never. I don't let my drives spin down but if they were to, the fan does stop spinning after a while, afaik that's the only control the DAS has over the fan. So if i were to add a 2000rpm fan, would it instantly shoot up to that rpm and always spin that fast? Is there a way to control fan speed? I can't see the DAS's fan on any program controlling fan speed so that's something...\n  \n\n    Any idea on how it would behave? Any idea if there is a way to controll the fan speed? Thanks."},
{"Title": "CD ripping compression", "Author": "u/nlj1978", "Content": "So going through my old CDs, some of them are previously burned CDs in MP3 format. I have been ripping discs in FLAC format.\n  \n\n    If the ripping software is starting with an MP3 file and ripping to FLAC is that problematic?\n  \n\n    Compressing a compressed file sounds like a bad idea"},
{"Title": "Need to expand storage. Out of SATA but have PCI-E slot.", "Author": "u/DevanteWeary", "Content": "Hey guys. Using mITX motherboard and out of my four SATA ports, and need four more ports to connect four more drives.\n  \n\n    My PCIe slot is free and both m.2 slots are taken.\n  \n\n    What's the best way to get more free SATA ports?\nIt's for my low power streaming server/NAS that is running Unraid.\n  \n\n    Thank you for any advice!"},
{"Title": "Help downloading xvideo profiles/playlists", "Author": "u/Thehobbyist916", "Content": "YT-DLP is only able to download one link at a time\n  \n\n    Anyone have any suggestions or advice?\n  \n\n    Also, I’d like to be able to download YouTube RED content\n  \n\n    Thanks"},
{"Title": "How to Download a video from a private vimeo server?", "Author": "u/diradi", "Content": "I subscribed to an online course service, and the provider uploads the class recordings to the platform through a private Vimeo server. I can watch the classes, but it's practically impossible to download them using traditional methods. I was able to download some videos on the platform using IDM (Internet Download Manager), but lately, whenever I try to download a video, a message appears saying \"Unknown error, please try again.\"\n  \n\n    Can someone help me with a solution? Either a method to download private Vimeo videos or a way to fix the IDM error.\n  \n\n    Thank you."},
{"Title": "Seeking Advice on Cost-Effective Backup Solutions for Multiple Hard Drives (beginner) - Thoughts on Bvckup 2?", "Author": "u/AlvTellez", "Content": "I have several larger hard drives:\n  \n\n\n\n\n\n    5TB portable drive connected to my HTPC for films and series via Plex\n  \n\n\n\n\n\n    Two unused 8TB drives\n  \n\n\n\n\n\n    4TB drive containing important media (that doesn't fit in my laptop and/or is more important)\n  \n\n\n\n\n\n    Initially, I considered getting a Synology NAS, but with less than 10TB of actual data, it seems like overkill, especially since I rarely access this data and usually keep the drives unplugged, except for the 5TB drive that's always connected to my HTPC (I also don't really need a NAS for my Plex needs, since I already have the HTPC as a server for that).\n  \n\n    After reading some posts, I thought about purchasing a license for Bvckup 2, which is more cost-effective and would allow me to use my other drives for backup.\n  \n\n    My plan is to transfer data from the 5TB drive to one of the 8TB drives and periodically back up the data to the other 8TB drive. If I run out of space, I could use the 4TB drive similarly and back up data to the other 5TB drive.\n  \n\n    While this might sound inefficient to experienced data hoarders, how bad/good is this idea? Are there any other software options that could simplify this process, compared to manually copying and pasting data between drives?"},
{"Title": "Seattle video store says it needs to raise $1.8M or face possible closure", "Author": "u/justreddit2024", "Content": "No content"},
{"Title": "Synology DS923+, DS1821+ & DS223j all on sale right now at B&H", "Author": "u/iddrinktothat", "Content": "** The sale has ended. **\n  \n\n    Thought id let you guys know because i havent been seeing a lot of discounts on Synology."},
{"Title": "Today I learned something about shucking", "Author": "u/auridas330", "Content": "I bought two WD elements drives, both are same size, manufacture date, drive number, but one needed me to play with the 3.3v pin to show up.\n  \n\n    Never knew that WD plays Russian roulette with their drives lol"},
{"Title": "Only 12TB usable with 3x 4TB and 1x 8TB RAID5", "Author": "u/Sinnagangsta", "Content": "Hi all\n  \n\n    So I am setting up a RAID5 NAS and I have 3 4TB drives and 1 8TB drive. No hot spare drives. According to a RAID calculator, I will only have 12TB of usable storage, and it says 4TB is unused. This is consistent in the NAS panel, it is showing just under 12TB, why is this? Is that 8TB drive a waste, or am I missing something?\n  \nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-b851t2bway7d1.png\nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-p7soc3bway7d1.png\nhttps://preview.redd.it/only-12tb-usable-with-3x-4tb-and-1x-8tb-raid5-v0-44fhp3bway7d1.png"},
{"Title": "Looking for a recommendation for inexpensive 2TB SSD (SATA) with decent endurance", "Author": "u/gerdude1", "Content": "Hi,\n  \n\n    I have a few mini pc's (I have a decent size NAS as well) and would like to create CEPH storage, which requires three nodes on ProxMox. Hence I am looking for recommendations for a somehow inexpensive SSD's that have decent endurance (NVME is already used on all three Mini's, but they all have space for 2.5 SSD and a SATA port available). I am in the US and see price points of ~$120 for QLC and $150 for TLC. I have access to Microcenter, but there is very little available and newegg has all the usual suspects available (e.g. 970 Evo Plus).\n  \n\n    Would love to hear about some recommendations.\n  \n\n    Thanks in advance."},
{"Title": "Five Men Convicted of Operating Massive, Illegal Streaming Service That Allegedly Had More Content Than Netflix, Hulu, Vudu and Prime Video Combined", "Author": "u/falco_iii", "Content": "No content"},
{"Title": "Feasibility/Performance of Mini-PC NAS with external HDD/SSD enclosure?", "Author": "u/RXrenesis8", "Content": "Howdy \nr/DataHoarder\n!\n  \n\n    I am still a little baby hoarder with only about 15-20TB of data floating around my noisy 10 year old desktop-turned-HTPC. I was looking to expand to ~30TB (with room to grow of course) for a couple of initiatives and initially had been set on a rack and rackmount server or NAS chassis with a bunch of 3.5\" bays for price-efficient spinning drives.\n  \n\n    The cost though! Racks = $$$ Rackmount Chassis or pre-builts = $$$$!\n  \n\n    Every penny I would save in drive capacity I would pay back in getting a nice (home-office) rack and NAS.\n  \n\n    So I've come to you questioning a pivot point: What do you think about smaller solutions? Specifically I am thinking about a Mini-PC running nnRAID connected to a JBOD enclosure for disks or large/cheap SSDs.\n  \n\n    What's the performance difference between a setup like the above and a low-end rackmount setup (which is at the limit of what I could realistically afford)?\n  \n\n    Any pitfalls I should be aware of?\n  \n\n    Thanks in advance!"},
{"Title": "dm-vdo block-Level deduplication and compression merged into Linux 6.9", "Author": "u/LeichenExpress", "Content": "No content"},
{"Title": "Best option for a \"go bag\" external?", "Author": "u/Vietname", "Content": "I have a couple of small synology NAS's, each has a dedicated drive for regular backups, but i wanted to get a small external drive (ideally SSD) to put my really important data on for emergencies, e.g. the house is on fire and i can only grab a few things.\n  \n\n    What would you recommend?"},
{"Title": "VIA RAID disks question", "Author": "u/thenovum", "Content": "Hey. Is it possible to extract the data from via raid disk members without using a VIA RAID controler? Disks are from 2004."},
{"Title": "Largest SSD is 1,000 TB in 3.5\" size, why not bring 5.25\" mechanical drive?", "Author": "u/Warcraft_Fan", "Content": "The largest hard drive is 30TB but if they would use 5.25\" drive then it'd be possible to get some hundred TB in a standard 5.25\" half height (same as CD and DVD drive)\n  \n\n    Computer cases are still produced with 5.25\" support as some people still need optical drive or possibly tape drive. So what's keeping them from putting out massive 5.25\" hard drives?"},
{"Title": "All of my data storage mediums, if you want I can update every Friday I get a new thing to put on the wall as a weekly thing", "Author": "u/LaundryMan2008", "Content": "No content"},
{"Title": "Should I use cold cloud storage for small backup (4TB)?", "Author": "u/CreativeDog2024", "Content": "I know about the 3-2-1 rule, but I've not been implementing it. I'm a college student with 3 years and 4 TB worth of movies/TV shows that have taken DAYS to download at times.\n  \n\n    I have 2 local backups, one on a segate 5tb and the other on a WD 5tb.\n  \n\n    I don't want to lose these files, I've used a plex add on to export posters and a list of my media but if I were to ever try and get them back from scratch, it would take a long time and I'm not sure I'd ever dedicated that much time.\n  \n\n    I know about aws deep glacier as a last resort and it being pretty high cost to recover, but I don't really plan to ever recover unless I both of my local backups.\n  \n\n\n\n\n\n    What should I know about?\n  \n\n\n\n\n\n    What would you do?"},
{"Title": "Khan Academy Math Library downloading at once", "Author": "u/Aggressive_Green_764", "Content": "Hello guys i don't gonna have internet for a while and i thought about downloading the math library and  i don't wanna do it manually and i wanna do it just like it's on their website not the playlists on youtube\n  \n\n    Is there any way?"},
{"Title": "Has SMR changed in the past few years?", "Author": "u/SirLouen", "Content": "I was reading this post commenting on the differences between SMR and CRM disks.\n  \n\n\nhttps://www.reddit.com/r/HomeServer/comments/hhfoqg/should_i_get_seagate_barracuda_or_seagate/\n\n\n\n\nhttps://www.youtube.com/watch?v=aztTf2gI55k\n\n\n\n    Basically, suggesting that SMR are seriously under classic CRM. But this happened to be like 4 years ago, so I wondered if Seagate has been able to figure out something to improve this for their disk, which is unlikely, but just wondering\n  \n\n    I saw today in my brick and mortar store, a Barracuda Compute 8 TB at $130 and a Barracuda Ironwolf at $190 w/ 8 TB also, so $60 difference for the same storage, not sure if its worth but feels that knowing all the issues attached with SMR (specially for a NAS where it's going to be used these disks), doesn't seem to be a good decision.\n  \n\n    So I wanted to know your opinion."},
{"Title": "500,000 Books Have Been Deleted From The Internet Archive’s Lending Library", "Author": "u/Industrious_Badger", "Content": "No content"},
{"Title": "Get WD Purple for DIY NAS in Raid? Located in India", "Author": "u/The_Bipolar_Guy", "Content": "Building my first DIY NAS. Need 2+2 tb to start off with. Trying to be as cheap as possible. Will be storing all memories and irreplaceable things. Will get an external HDD for offsite backup. Also, I do not care about read write speeds. I just want my data to be safe and backed up at the end of the day for as cheap as possible, I will add new data maybe once a month if not even more rarely. I will be using my old motherboard (6 SATA ports) and processor. Will get a new 500 GB ssd for OS and new RAM.\n  \n\n    Now here is the dilemma. I am from India and WD Purples are selling for 5250 INR each, cheapest. Next up, WD Blue is also selling for 6000+ INR. I can technically afford (but want to avoid at all costs) to get a 10TB UltraStar or EXOS for 22000 INR but I need two physical drives at least and my total storage need for backup right now or even 3 years later will not exceed 4-5TB. so a 10TB HDD will be useless, not to mention spending 45K INR on drives only (which is VERY VERY EXPENSIVE FOR ME).\n  \n\n    I know WD Purple glosses over write errors and can be bad. Chucking is equally expensive, if not more. Should I just get 2x 2tb WD Purple for 10.5K INR and set up my backup server for now. Will add more HDDs later as needed (1-4 years later). Can I do anything to prevent the write errors?\n  \n\n    Also, if there is a cheaper way, especially in the long run, I would appreciate it. Currently I have ~2TB data which grows by like 200-400GB a year. I have thought of BluRay drives but I am unable to procure new BluRay drives cheap enough."},
{"Title": "Question in regard to mergerFS", "Author": "u/leviathan2701", "Content": "Hello,\n  \n\n    I just set up a NAS using Ubuntu 24 LTS, mergerFS & snapRAID. I am new to using Ubuntu, mergerFS & snapRAID but I did follow some guides via YouTube videos on setting them up. The drive pool has been created and snapRAID is working as expected however, I have what may be an easy question that I can't quite figure out.\n  \n\n    Following the guide, the mount point for mergerFS pool is at /mnt/storage which I have no issues accessing and adding/removing files via terminal using sudo or as root however, since the owner of the /mnt/storage location is root, my user account on the machine cannot write files to /mnt/storage and I cannot share it via samba. I know changing the overall permissions to 777 to allow it is risky and not worth it and I'm sure there is another way that I should be writing files to the location without logging in as root but again, I'm new with this and still learning. Any advice/help will be appreciated.\n  \n\n    mergerFS v2.33.5\n  \n\n    edit: was able to resolve the issue with all of your help. Thank you all very much!"},
{"Title": "Honey, I Shrunk My Server", "Author": "u/sylinen", "Content": "No content"},
{"Title": "Zip/ Compress Large Anime Collection", "Author": "u/Big-Durian-5011", "Content": "Hey guys, I have a collection of about 8 TB of anime on my OS od choice, Arch Linux, and was wondering if there was a way I could automatically (manually is fine too) compress all content in a singular folder and store the compresses/ zipper files in another folder.\n  \n\n    Edit: Just to be clear, the reason I want to zip/compress my anime is to back it up, not to download more anime. My plan is to:\n  \n\n\n\n\n\n    Make a copy of my folder of anime\n  \n\n\n\n\n\n    Zip/compress the copied folder\n  \n\n\n\n\n\n    Store the zipped/compressed folder on a seperate storage device (currently being stored in a 14TB hdd).\n  \n\n\n\n\n\n    If possible, set up an automatic process to continously do this process for any new anime I download."},
{"Title": "Looking for help as a vlogging nomad. I film all content in 4k60p and visiting every country in the world. Guesstimating I'll need an additional ~24TB of storage for my remaining 100 countries. Budget: hopefully <$10k?", "Author": "u/immranderson", "Content": "Hey! I've been living exclusively out of my backpack + carryon luggage for the last decade and have been filming my travels as I go along. I've been traveling around the world and have amassed a large collection of 2/4TB Samsung T-Series SSDs which is beginning to bump up against the \nphysical carrying capacity\n in my bags.\n  \n\n    Lucky enough I've got a 128GB Pixel 1 that I use still to this day for daily remote storage + backup, so that has served me well.\n  \n\n    However, I also like to have local backups, and have been trying to shop around for SSDs. I'm trying to keep things as compact as possible, and I'm traveling so have avoided going the HDD route since my stuff can get pretty rough and tumbled quite often. I try not to edit directly off my external drives, and I've got an 8TB M-class macbook pro that I've been lugging around with me around the world.\n  \n\n    I'm trying to figure out how to handle my long term storage needs for the next few years of travel. On average, I'm capturing 100GB - 400GB per week of travel. I'm figuring I've got another 100 countries left to visit around the world, so 100 weeks * ~200GB per country maybe lands me in the ~20TB range of storage I'm anticipating I'll need for the remainder of my travels?\n  \n\n    Does anyone have any suggestions here? Could I get away with getting 2 x 16TB SSDs with external enclosures and that 32TB worth of capacity would generously cover my needs with wiggle room? If so, what SSD + enclosure combo would you recommend?"},
{"Title": "500,000 CDs", "Author": "u/Sliced_Apples", "Content": "Hello, I am working for a startup in the sports industry and we have recently come into the possession of about five hundred thousand cds with 20 year old sports footage.\n  \n\n    We are trying to train an AI model off of them so as such, they need to be digitized.\n  \n\n    I know a little about burning cds but not much. As I have been made aware, this would be “ripping” and not burning.\n  \n\n    What would be the best way to go about doing this? What storage solution would be the best? Any advice is greatly appreciated. I’m happy to answer any questions as well."},
{"Title": "I've got a decent sized physical media collection and unsure if it's worth saving lossless copies of it all", "Author": "u/TripleXero", "Content": "I've spent a stupid amount of time backing up all my DVDs and Blu-rays but I've already capped off an 11TB hard drive and split the extras between drives meant for other stuff and I'm still not done. I don't plan on getting rid of the original physical copies but it's much easier to access them digitally.\n  \n\n    I should also mention what I have backed up has been shrunk down already to decent looking MP4s to shove on iTunes for sleeker organization but I just don't know if it's worth keeping the original 1:1 files after. I shrunk the original files down once and realized after the fact that it wasn't in a flexible or presentable way for some so I'm hesitant to try again or wipe them completely after all the work. Is there maybe a good way to compress them? I've already went through and removed all non-English audio and subtitles"},
{"Title": "I need help identifying this hard drive, and where i can get the right cable.", "Author": "u/Chippomannen", "Content": "No content"},
{"Title": "I have question about ugreen enclosure", "Author": "u/Dismal_Award735", "Content": "No content"},
{"Title": "Question about Pixiv bulk downloading", "Author": "u/_izix", "Content": "Has anyone been blocked or banned from bulk downloading from pixiv?\n  \n\n    I've seen rumors that it may happen, but as far as I've been able to determine, there is no evidence of it actually happening. Is there maybe a hidden limit that's very high?\n  \n\n    I plan to download all images from users I follow with a script to update my archive with any new images every couple days. So far I have downloaded a few thousand images with no issues. Just figured I'd see if anyone has evidence of that happening before I continue.\n  \n\n    EDIT: I am using gallery-dl"},
{"Title": "Sony CCD TRV78E - how to digitize hi8 tapes?", "Author": "u/wtf94ftw", "Content": "Hey!\n  \n\n    So long story short my dad just retired and he wants to digitize his lifelong collection of hi8 tapes.\n  \n\n    I’ve read a lot of things last few days but I’m still not sure what would be the best option (budget friendly…) for the setup.\n  \n\n    Currently he’s been watching those tapes on TV with the sony CCD TRV78E camera, connected with both s-video and RCAs with an HDMI converter (\nhttps://amzn.eu/d/05vz9SBs\n) and everything’s working ok…\n  \n\n    I’m not great at these matters and I’m a bit lost tbh, but my initial idea was to plug the HDMI to a computer and record the screen as the movies are playing with a video capture sofware… which I now doubt to be an option because HDMI port on pcs don’t receive signal, is this right?\n  \n\n    Idk if the best option would be getting a camera that has the FireWire port and plays hi8 tapes or if it would be better to do this any other way, but I’ve read about those usb things not getting so much quality and I’m worried about it.\n  \n\n    Right now movies are playing in a 55” TV with good image quality and audio is perfectly synchronized, if this is relevant info in any way.\n  \n\n    He’s really motivated to do this by himself as he now have a lot of free time, but ofc this means that I’ll have to learn how to do it and teach him so he can continue by himself.\n  \n\n    Sorry, this was a long story after all, and sorry for some eventual english mistake as well!"},
{"Title": "Software for organizing manual backups over the last 10 years?", "Author": "u/PrivateAd990", "Content": "What software is available (paid or free) to help analyze my data on an external HD? it's only about a 1GB but 20+ backups (manually copied files over the years to this HD). MacOS or Linux. Wants:\n  \n\n\n\n\n\n    find data by extension (file type)\n  \n\n\n\n\n\n    find largest files\n  \n\n\n\n\n\n    identifying duplicates and handling it manually\n  \n\n\n\n\n\n    Accepting other tips of how to sift through data. I plan to organize all data to one folder rather than 20 backup folders."},
{"Title": "ServerPartDeals customer service", "Author": "u/demitrixrd", "Content": "I know many people on here already recommended SPD as a source for fair priced disks. I just wanted to add my $.02 after a recent experience with a failed drive I'd purchased a few months ago.\n  \n\n    A week ago I woke up to a TrueNas notification that a drive was faulted. I did some troubleshooting and wasn't able to recover any kind of connection to the drive. Plugging it in to a external adapter resulted in what sounded like a rock tumbler, so clearly it was beyond rescue. I started a RMA with SPD, and went back to work; expecting a few hours delay before hearing anything back. Later I realized I'd missed their almost immediate reply to the RMA request. I explained there was no way provide smart test results, and attached a video of my new rock tumbler. In short order the RMA# was provided. I shipped the faulted drive, and didn't think much of it. The drive was delivered yesterday and my replacement shipped this morning.\n  \n\n    Long story short, big kudos to ServerPartDeals for what is unprecedented customer service in the modern world; and to all the unsure shoppers, spend your money with SPD."},
{"Title": "Migrate from Unraid to OMV, SnapRAID, mergerfs. How to keep hard links, that span between two drives?", "Author": "u/ChrisWreck", "Content": "I'm in the middle of migrating from Unraid to OpenMediaVault, where I'll be using Snapraid and mergerfs.\n  \n\n    I have 3 disks, one parity and two data drives. They're using XFS in Unraid. I want to use ext4 in OMV.\n  \n\n    I have formatted the parity drive to ext4, and planned to move data from disk 1 to the parity drive, then format disk 1 to ext4, and then move all data from disk 2 to disk 1 and make disk 2 the new parity drive for SnapRAID.\n  \n\n    However, I just realized I have hard links from the arr suite, spanning over both data disks ...\n  \n\n    How can I migrate and preserve the hard links? Preferably without having to move all data to one disk in Unraid before migrating.\n  \n\n    EDIT: For those of you wondering why I'm switching, I'm actually switching from Unraid to Proxmox, but I'll use OMV to handle my disks (combination of ZFS and ext4) and shares."},
{"Title": "What's the best way to transfer all my family's iCloud backups and device storages to an external media server?", "Author": "u/sav-tech", "Content": "Currently, the data is on an iMac Mid 2011, Google Photos and iCloud.\n  \n\n    We also have spare devices that we want to recycle. Before doing that, we want to save the data on there and store it externally.\n  \n\n    I am a tech-enthusiast by nature and think that this would be a good opportunity to setup a home lab.\n  \n\n    I understand it may take some effort, but I am thinking of having folders for each person in our family and their data goes into an encrypted folder to access remotely via Mobile, PC and Samsung Smart TV..."},
{"Title": "Best free data integrity tools for validating.", "Author": "u/Captain_Starkiller", "Content": "Can anyone recommend some good tools for validating data integrity as a defense against bit rot?"},
{"Title": "Backup software", "Author": "u/bhudzallmighty", "Content": "I currently have a dedicated optiplex running linux with nextcloud docker for my iphone data. I would like to expand this system to a DIY nas with a single 20tb hdd storage for backup . What is the best software to do so? I would like to be able to backup once a day. Can i back up the whole hdd? Or just folders? Thank you"},
{"Title": "Trying To Digitize Old Cassette Tapes", "Author": "u/boosterbear", "Content": "Hello all! I have been hunting for the right location to ask my many, many questions. This may not be technical enough for this subreddit, but it seemed like the right place to go.\n  \n\n    I'm a big fan of physical media, likely casual to most here but to my friends I am perceived as intensely pro-physical media. As such, whenever people have spare tapes, CDs, DVDs, etc etc, I'm the man they throw them at.\n  \n\n    Unfortunately, I am horribly unfamiliar with the digitization process for everything except for CDs and DVDs, and even then I occasionally have hiccups.\n  \n\n    Recently I purchased the \nJVC RC-EZ38S CD Portable System\n (link to user manual) from a flea market to play some of my tapes and CDs, and realized I had a few tapes I'm unable to find anywhere online. Usually I wouldn't worry about my tapes growing old from wear because I can download songs and save them that way, but these tapes (mostly Halloween tracks) were impossible for me to find elsewhere, so I've been trying to preserve them.\n  \n\n    The JVC product I purchased plays CDs, cassette tapes, and the radio. It has one single 3.5mm jack, a headphone output. I have done some googling, and found my best bet to save the audio is through a combination of cables and Audacity. Unfortunately, my computer only recognizes my aux cord as headphones, and I cannot treat my JVC product as a microphone when using Audacity. I have two cables - one aux with two 3.5mm ends, and one cable that has a male 3.5mm on one end and the other end has two male parts, white and yellow RCA jacks.\n  \n\n    How, if at all, can I use my JVC player to preserve the tapes I have? Is there a special cord combination I may be able to put together that won't put me out of house and home (I'm unemployed and in a somewhat difficult spot financially, even a $20 purchase has me aghast sometimes) or would I be better off looking for a different product to record my tapes? A friend of mine is currently looking to rehome an old car radio with cassette player - Do those typically have RCA plugs, and would that be a way to go about this?\n  \n\n    Anything helps, even just correcting my terms so I can communicate what I'm looking for a little better - I'm in a space where I truly don't know what it is that I don't know. I'd love to be a part of saving some lost media, even if it seems a little silly. People put work into those Halloween tapes, dammit!"},
{"Title": "What are the best options for adding disks to my setup?", "Author": "u/StarLordOfTheDance", "Content": "Is it possible to transition my setup from mergeFs+Snapraid to zfs without a lot of spare storage that I don't have?\n  \n\n    I currently have 2x4TB mergeFs setup, with a 4TB drive for Snapraid parity. (Total 8TB usable storage). - currently holding 7TB of data\n  \n\n    I have purchased 2x4TB more drives. And ideally want to end up in a situation where I have 16TB of usable storage, with 1 parity. (12TB usable would be acceptable but not ideal).\n  \n\n    The mergeFs harddrives are connected to a Ubuntu server. And I am moving the whole lot to a new server running proxmox (that has a Ubuntu server running in VM).\n  \n\n    can anyone help me figure out if it's possible to migrate this to a ZFS pool that will do what I want.\n  \n\n    I also have looked at unRAID because it supports adding disks, but that is its own hypervisor. So are there alternative ways of working that can work inside a proxmox VM?"},
{"Title": "13.5 Volt", "Author": "u/Rayuzan_Mojavec", "Content": "I just got a 3.5 inch HDD. It needed 12 volts external power, but I only have 13.5 power adapter. Is it safe?"},
{"Title": "No M2TS Files on Blu-ray?", "Author": "u/Carsonsgaming", "Content": "https://preview.redd.it/no-m2ts-files-on-blu-ray-v0-1i3wz54rsn7d1.png\n\n    As the title says. I'm not finding one anywhere. These are in a folder called AACS, then there's another folder with a bdmv file but that's it. I'm a complete noob to Blu-ray ripping so I'm hoping I'm just missing something. Only interested in ripping the audio."},
{"Title": "Checking for Wiped SMART Data", "Author": "u/eakall", "Content": "So I recently got 35 2TB SSDs (mostly Samsung EVO 860/870) used and when checking the smart data for them I noticed very low power on hours.  The PoH (80-400hrs) is variable across the large set of drives and TBW is about 2-6TB for most of the drives. I was curious if there’s a way to check if the smart data has been reset?\n  \n\n    It seems a bit suspicious to me that these drives all are so low in PoH. Drives are also manufactured between 2020-2021 ish"},
{"Title": "What is the best NVME SSD controller ?", "Author": "u/Yukinoooo", "Content": "I'm looking for an NVME SSD, 5 years warranty or more and a good controller but I don't know which NVME to choose because there are controllers : \"InnoGrit IG5236\", \"InnoGrit IG5666\", \"Phison E18\", \"Phison E26\" and \"SMI SM2264\""},
{"Title": "Best option for transcoding?", "Author": "u/AbsolutelyNoClue22", "Content": "I want to use Plex to watch my movie library. I need transcoding to watch on the go, and on devices that need it. What is a good solution for this?\n  \n\n    I've thought about buying something like the TL-D800C, connect it to my laptop and run the Plex server from there. Is this a good idea? Is there a cheaper option?\n  \n\n    I'm new to all of this. I appreciate any help."},
{"Title": "Looking for some specific storage design help", "Author": "u/Real_Bad_Horse", "Content": "Hey y'all, I don't know that this is the best place for my question, but I suspect that folks around here will either have advice or know where to point me if I'm better served asking this somewhere else.\n  \n\n    I built out my homelab to learn and get a job in IT. Mission success there. I've since gotten into all kinds of stuff and have a need to rework my storage, but I'm not sure how best to set things up.\n  \n\n    Here's what I'm looking to do:\n  \n\n    Complete separation of storage and compute Compute consists of a handful of VMs running on Proxmox, and critically, a Kubernetes cluster The cluster is currently running in VMs but I have plans to move just about everything into the cluster and move into SFF PCs This is partially why the complete separation is important, for flexibility and future migration\n  \n\n    Here's what I have currently for equipment:\n  \n\n    Brocade switch with 48x 1gbe and 8x10gig sfp 2x 12 bay 3.5\" servers, one with Proxmox, one with TrueNAS 1x 24 bay 2.5\" server Repurposed NetApp 24x 3.5\" chassis, modified to work as DAS 4x 16gb spinners, currently in raidz1 ~32 old 2, 3, and 4gb spinners\n  \n\n    I found that K8s cluster was very unstable with my first setup, which was an iscsi target on the TrueNAS server. The iSCSI share was mounted in Proxmox with LVM to create K8s VM OS and NFS storage for containers. This got much better when I moved to a local 3x SSD zpool on the Proxmox host. I understand that the latency with spinners and over the network was likely the cause, but this doesn't allow for the separation if like.\n  \n\n    Use here is all over - media server is the main thing currently, which for transcoding needs fast seq read/writes, K8s app dev for work, and all kinds of testing containers for work and home. I'd also like to put all VM storage remote as well to play around with some different compute setups. I'd really love to be able to fully wipe Proxmox and try out XCP-ng, or Azure HCI, stuff like that... It's a lab, after all.\n  \n\n    I'm competent enough to implement a solution, but I guess not enough experience yet to design. I'm not afraid of complex setup, but I do need redundancy, particularly if putting these small drives to use as I don't trust them - came for free with the NetApp shelf.\n  \n\n    So... Any suggestions on how to set this up for minimal latency and fast read/write? Ceph? Mirrored ZFS using all those small spinners? Dedicated ZFS pools for each K8s node? Caching layers? Not against additional equipment, within reason, if needed."},
{"Title": "Best at-home manual photo scanner?", "Author": "u/Small_Vermicelli9655", "Content": "Looking to digitize a bunch of old family photos and was hoping for specific scanner suggestions. There’s lots of conflicting information online and I’m not very proficient in this area so was hoping for some insight lol.\n  \n\n    I’ve heard automatic scanners can mark grooves on the photos and would feel more comfortable with a manual one as time is not a priority. Hoping to stay around a $500 price range and resell after use.\n  \n\n    Thank you in advance!!"},
{"Title": "WD Red Plus 8TB vs WD Black 8TB vs IronWolf 8TB?", "Author": "u/GearFourth", "Content": "I ordered a WD Black 8TB, but now the Red Plus is on sale for $34 cheaper, do you guys believe the Black is worth $34 more?\n  \n\n    The biggest difference that I know of is Black has a longer warranty 5 vs 3. Are there any other differences? I would be using them for media storage."},
{"Title": "16x22TB disk MegaRAID data storage ZFS RaidZ2 or HW Raid 60", "Author": "u/Flat-One-7577", "Content": "Hi,\n  \n\n    I am going to build a 16 disk data storage. This will mainly be a \"backup\" to store data for some time and not need to recreate it again. Recreation would be expensive.\n  \n\n    I have few very big files and a lot of small one.\n  \n\n    Main focus is having a lot of storage. I/O is not so important.\n  \n\n    Having 16x 22TB disks attached to a MegaRAID 9500 Controller I am asking myself what would be the prefered setup?\n  \n\n    Variant A:\n  \n\n\n\n\n\n    HW Raid60\n  \n\n\n\n\n\n    on top ZFS\n  \n\n\n\n\n\n    Variant B:\n  \n\n\n\n\n\n    JBOD Mode on Controller for songle Disks\n  \n\n\n\n\n\n    ZFS\n-- create 2 RaidZ2 vdevs (6+2) and stripe them\n  \n\n\n\n\n\n    Variant C:\n  \n\n\n\n\n\n    JBOD Mode on Controller for songle Disks\n  \n\n\n\n\n\n    ZFS\n-- create one RaidZ3 vdev\n  \n\n\n\n\n\n    What would you do?\n  \n\n    Regards,\nJoachim"},
{"Title": "Why is it taking more than a day to transfer 1.6tb?", "Author": "u/RandonBrando", "Content": "I'm trying to transfer 1.6tb from a 2tb WD Easystore (5400rpm) to a 16tb ironwolf pro (7200rpm) with both drives connected through usb C. Both drives formatted in exFAT.\n  \n\n    I'm getting \nKB/s\n bytes/s - 18MB/s max.  \nNEW LOW SCORE\n\n\n\n    I need some help troubleshooting this because I'm not sure what else to check."},
{"Title": "Gallery-dl instagram help", "Author": "u/Graestra", "Content": "I'm trying to scrape an instagram account however gallery-dl isn't downloading all posts from the account. I've tried looking into config settings, but I keep getting errors about double quotes when trying to use a config file, and I'm not sure what the right setting to get it to download all posts is in the first place. Any help would be appreciated."},
{"Title": "ST12000NTZ01 vs ST12000NTA01", "Author": "u/-Rhialto-", "Content": "The Z is sold by Amazon and the A by Best Buy, could it be just that? Same disk but different number depending on reseller?"},
{"Title": "Will adding a new fan to a DAS result in the fan spinning at 100%?", "Author": "u/Apptryiguess", "Content": "I have a DAS and am pretty happy with the temps, but they could be slightly better since the DAS is in a closet and doesn't get that much airflow. My enterprise drives idle at 43-45 C which is ok, but could be a little better.\n  \n\n    So i thought about adding a new and better fan to the enclosure (Icy Box IB-3805-C31), but the fan never changes speeds, literally never. I don't let my drives spin down but if they were to, the fan does stop spinning after a while, afaik that's the only control the DAS has over the fan. So if i were to add a 2000rpm fan, would it instantly shoot up to that rpm and always spin that fast? Is there a way to control fan speed? I can't see the DAS's fan on any program controlling fan speed so that's something...\n  \n\n    Any idea on how it would behave? Any idea if there is a way to controll the fan speed? Thanks."},
{"Title": "CD ripping compression", "Author": "u/nlj1978", "Content": "So going through my old CDs, some of them are previously burned CDs in MP3 format. I have been ripping discs in FLAC format.\n  \n\n    If the ripping software is starting with an MP3 file and ripping to FLAC is that problematic?\n  \n\n    Compressing a compressed file sounds like a bad idea"},
{"Title": "Need to expand storage. Out of SATA but have PCI-E slot.", "Author": "u/DevanteWeary", "Content": "Hey guys. Using mITX motherboard and out of my four SATA ports, and need four more ports to connect four more drives.\n  \n\n    My PCIe slot is free and both m.2 slots are taken.\n  \n\n    What's the best way to get more free SATA ports?\nIt's for my low power streaming server/NAS that is running Unraid.\n  \n\n    Thank you for any advice!"},
{"Title": "Help downloading xvideo profiles/playlists", "Author": "u/Thehobbyist916", "Content": "YT-DLP is only able to download one link at a time\n  \n\n    Anyone have any suggestions or advice?\n  \n\n    Also, I’d like to be able to download YouTube RED content\n  \n\n    Thanks"},
{"Title": "How to Download a video from a private vimeo server?", "Author": "u/diradi", "Content": "I subscribed to an online course service, and the provider uploads the class recordings to the platform through a private Vimeo server. I can watch the classes, but it's practically impossible to download them using traditional methods. I was able to download some videos on the platform using IDM (Internet Download Manager), but lately, whenever I try to download a video, a message appears saying \"Unknown error, please try again.\"\n  \n\n    Can someone help me with a solution? Either a method to download private Vimeo videos or a way to fix the IDM error.\n  \n\n    Thank you."},
{"Title": "Seeking Advice on Cost-Effective Backup Solutions for Multiple Hard Drives (beginner) - Thoughts on Bvckup 2?", "Author": "u/AlvTellez", "Content": "I have several larger hard drives:\n  \n\n\n\n\n\n    5TB portable drive connected to my HTPC for films and series via Plex\n  \n\n\n\n\n\n    Two unused 8TB drives\n  \n\n\n\n\n\n    4TB drive containing important media (that doesn't fit in my laptop and/or is more important)\n  \n\n\n\n\n\n    Initially, I considered getting a Synology NAS, but with less than 10TB of actual data, it seems like overkill, especially since I rarely access this data and usually keep the drives unplugged, except for the 5TB drive that's always connected to my HTPC (I also don't really need a NAS for my Plex needs, since I already have the HTPC as a server for that).\n  \n\n    After reading some posts, I thought about purchasing a license for Bvckup 2, which is more cost-effective and would allow me to use my other drives for backup.\n  \n\n    My plan is to transfer data from the 5TB drive to one of the 8TB drives and periodically back up the data to the other 8TB drive. If I run out of space, I could use the 4TB drive similarly and back up data to the other 5TB drive.\n  \n\n    While this might sound inefficient to experienced data hoarders, how bad/good is this idea? Are there any other software options that could simplify this process, compared to manually copying and pasting data between drives?"},
{"Title": "Seattle video store says it needs to raise $1.8M or face possible closure", "Author": "u/justreddit2024", "Content": "No content"},
{"Title": "Synology DS923+, DS1821+ & DS223j all on sale right now at B&H", "Author": "u/iddrinktothat", "Content": "** The sale has ended. **\n  \n\n    Thought id let you guys know because i havent been seeing a lot of discounts on Synology."},
{"Title": "Today I learned something about shucking", "Author": "u/auridas330", "Content": "I bought two WD elements drives, both are same size, manufacture date, drive number, but one needed me to play with the 3.3v pin to show up.\n  \n\n    Never knew that WD plays Russian roulette with their drives lol"},
{"Title": "Storage & Access to childhood memories", "Author": "u/Beautiful-Natural938", "Content": "I have a few external hard drives which store old photos and videos of my childhood and adult life. My digital memories remain isolated on these HD’s, where as I would like to be able to:\n  \n\n\n\n\n\n    Access these files via iPhone & MacBook  anywhere in the world through a secure & private encryption.\n  \n\n\n\n\n\n    Label the files for categorisation purposes.\n  \n\n\n\n\n\n    Share access to friends and family.\n  \n\n\n\n\n\n    I also don’t like the idea of having to pay for a subscription service. I have read NAS systems may be a good option.\n  \n\n    Any advice / recommendations is appreciated?"},
{"Title": "Longevity of Recordable CDs, DVDs and Blu-rays — Canadian Conservation Institute (CCI)", "Author": "u/didyousayboop", "Content": "Important information\n from the Canadian Conservation Institute, an agency of the federal government of Canada.\n  \nTable 2: the relative stability of optical disc formats\n\n\n\n\n\n\n\n            Optical disc formats\n          \n\n            Average longevity\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              CD-R (phthalocyanine dye, gold metal layer)\n            \n\n              >100 years\n            \n\n\n\n\n\n              CD-R (phthalocyanine dye, silver alloy metal layer)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              DVD-R (gold metal layer)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              CD (read-only, such as an audio CD)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              CD-RW (erasable CD)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              BD-RE (erasable Blu-ray)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              DVD+R (silver alloy metal layer)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              CD-R (cyanine or azo dye, silver alloy metal layer)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              DVD+RW (erasable DVD)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              BD-R (non-dye, gold metal layer)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              DVD-R (silver alloy metal layer)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              DVD and BD (read-only, such as a DVD or Blu-ray movie)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              BD-R (dye or non-dye, single layer or dual layer)\n            \n\n              5 to 10 years\n            \n\n\n\n\n\n              DVD-RW (erasable DVD)\n            \n\n              5 to 10 years\n            \n\n\n\n\n\n              DVD+R DL (dual layer)\n            \n\n              5 to 10 years"},
{"Title": "Is it possible to save an online quiz  to offline and use it offline and recieve results?", "Author": "u/dokha", "Content": "It’s important to note thats the kind of assessment pages im talking about are the casual ones such as the fun ones you take on Buzzfeed and the ones you see on astrology sites..\n\n\n\n    I have no idea the correct tools involved and how to use them .. I did try browser addons such as Single File but the offline files never reach the results after taking the quiz.."},
{"Title": "Has anyone archived bash.org quotes?", "Author": "u/syswraith", "Content": "The website seems to be down for a while now. Also my password's *******. What's yours?"},
{"Title": "Organizing drives vs drive sizes vs raids/ZFS/stuff", "Author": "u/PuzzleHeadPistion", "Content": "Hey,\n  \n\n    I've got two NAS and a bunch of drives. One EXOS 16Tb, two Barracuda 8Tb, one IronWolf 6Tb, on WD \"white\" 6Tb and on WD Red 3Tb. My main NAS is a desktop with +6 slots, my second NAS is a 4 bay Asustor.\n  \n\n    Currently I don't use raid/parity of any kind... All drives are single volumes and it just sync's each drive from my main NAS to the second NAS, so I try to make the drive setup equal. However, the recent addition of the EXOS 16Tb kills that.\n  \n\n    Since my main NAS is changing to a FreeBSD/TrueNAS with a ZFS pool, what's the best setup?\n  \n\n    I was thinking maybe 8Tb+8Tb+6Tb+6Tb in the ZFS pool, then 16Tb+3Tb as single volumes on my second NAS. This way drives in the pool are as similar as possible in size and if parity wastes one drive, it will be about the same total capacity as the second NAS.\n  \n\n    Does this make sense?"},
{"Title": "Will youtube ad Injections break music downloads?", "Author": "u/Nerds_r_us45", "Content": "I like downloading some channels in bulk and idk if this will break my ability to hoard music easily or not."},
{"Title": "Using CRC or the like for music backup checking", "Author": "u/__99999", "Content": "Hello, I know about the various ways to get a crc and sha etc. I'm trying to find a program that keeps the same crc if I change the Metadata of the audio file. Does anyone know of one? It can be Linux or win or even a script. Basically I'm backing up and archiving my music like most of you. The issue I'm running into is I update my Metadata on my audio randomly. As I have over 10tbs (I know rookie numbers) I can't sit down and bang it out in 1 sitting so I do it in waves.\n  \n\n    tldr? I'm looking for a program that doesn't alter crc if I change the Metadata of my audio file (mp3 or flac etc)"},
{"Title": "Safest method to wipe out a drive without damaging it? I'm looking for paranoid-level shit.", "Author": "u/500xp1", "Content": "Looking for a method that makes it impossible to recover the wiped data."},
{"Title": "How can I view all DMs in Twitter Archive Data? Not all DMs history shows up.", "Author": "u/niceiambearlythere", "Content": "Hello, I've downloaded my Twitter Archive Data, but not all of the DMs could be seen. It only shows a certain part of the chat, usually the earlier conversations. Is there any way to solve this, so that I can look back on all of the messages again?"},
{"Title": "Software for splitting video files in bulk?", "Author": "u/Comfortable_Ad_6823", "Content": "I am currently ripping my SpongeBob DVDs. For anyone unaware, (almost) all SpongeBob episodes are split into A and B parts. For example, \"Pizza Delivery\" is only episode 5a, with \"Home Sweet Pineapple\" being episode 5b. Two \"segments\" make up one episode.\n  \n\n    Normally this isn't a problem, as each segment in the SpongeBob DVDs has its own .mkv file. That is, until season 9, where there are no .mkv files for individual segments, only the combined episode. This is rather annoying as I don't want to scrub to the half-way mark of the videos just to watch the episode I actually want to see. I've thought of splitting the files in half, but it would be a tedious process as seasons are quite long.\n  \n\n    Are there any programs or tools that would make this easier?"},
{"Title": "Looking for a software to recognize multiple TB of images", "Author": "u/EasyMoney322", "Content": "Hello, I'm looking for a self-hosted software (that also wouldn't upload photos anywhere) that could do image recognition on the fileshare with an acceptable success rate. I was able to find posts on this sub about nsfw bodyparts recognition, but its not what Im looking for.\n  \n\n    What level of recognition? It must be able to tell appart photos of mass events, people, pets, documents, roads, buildings etc. Having them organized by a location metadata, perhaps. Finding similar (almost duplicate, but with different hash) images.\n  \n\n    Would be great if I could select all the tagged images after, re-check them for false-positives, and delete.\n  \n\n    The fileshare is hosted on OpenSuse VM, but I also can deploy and mount it on any other OS on the same server. I have a lot of processing power, but I'd like to avoid training the AI by myself."},
{"Title": "alternative to Cathy or Virtual Volumes view that can do Boolean Search", "Author": "u/another_lease", "Content": "I need to do Boolean search on my unconnected disks.\n  \n\n    E.g., I need to search for files that contain the word \"confidence\" and \"interval\". If I enter `confidence interval` in the search bar,\n  \n\n\n\n\n\n    Cathy will only find files that contain the \nphrase\n \"confidence interval\" in their file name.\n  \n\n\n\n\n\n    Virtual Volumes View will find me files that contain both words anywhere in the file name, but it will also return files that contain \neither\n word in their filename.\n  \n\n\n\n\n\n    I know that Cathy and VVV have come up before on this subreddit. I was wondering if anyone's figured out some \nportable freeware\n that can do Boolean search.\n  \n\n    Thanks in advance."},
{"Title": "Need Help archiving important Norwegian Stenography", "Author": "u/VanillaKirby", "Content": "Hello, I need some assistance with archiving a book containing some of the only documentation of one of the only shorthand systems in the Norwegian Language, Wang-Krogdahl.\n  \n\n    The book is scanned and located in the Norwegian Public Library available here \nhttps://www.nb.no/items/URN:NBN:no-nb_digibok_2016011905022\n\n\n\n    You will need a Norwegian VPN to access the book, (i am using tunnelbear with a free license)\nI do not know of a way to extract these scans of the book from the website, help appreciated."},
{"Title": "Why isn't rsync checksum or the equivalent enough to verify your backups?", "Author": "u/Ninj_Pizz_ha", "Content": "I expect I'll get some flack from people super immersed into this subculture, but why do people still recommend opening up random files in the backup to make sure the backup actually worked? Why isn't rsync -c or the equivalent sufficient? Personally I only open my backups every once in blue moon. Maybe there's some edge case where rsync checksum itself is faulty or something I guess, but that's not on my list of likely concerns tbh."},
{"Title": "$5 worth the risk?", "Author": "u/Long_Instruction_391", "Content": "No content"},
{"Title": "Smart Data Testing Deltas", "Author": "u/ejpman", "Content": "Anyone seen this before? 4 identical new disks with a huge difference in completion time for long smart tests. They are 14TB HC530’s\n  \n\n    admin@NAS[~]$ sudo smartctl -x /dev/sdc | grep 'test remaining.'\n  \n                                        10% of test remaining.\nadmin@UgreenNAS[~]$ sudo smartctl -x /dev/sdb | grep 'test remaining.'\n                                        60% of test remaining.\nadmin@UgreenNAS[~]$ sudo smartctl -x /dev/sdc | grep 'test remaining.'\n                                        10% of test remaining.\nadmin@UgreenNAS[~]$ sudo smartctl -x /dev/sdd | grep 'test remaining.'\n                                        60% of test remaining.```"},
{"Title": "Newbie question: ZFS vs RAID 10 for 4 disks in budget home server", "Author": "u/TruthsTrueTruant", "Content": "I have a little home server, built around a cheapo mini-PC - Intel N100, 16GB RAM, 500GB internal SSD - that I’m finally upgrading the storage on. Storage workload is mainly Plex library, Seafile document/photo storage, and backups of other computers on the network.\n  \n\n    I have 4 12TB HDDs that I was planning on setting up as a RAID1+0, and am debating the pros and cons of going for a full ZFS setup instead (as I understand it, the equivalent would be 1 zpool -> 2 vdevs -> 2 disks each).\n  \n\n    I know that ZFS has the advantage of better integrity protection for bitrot etc., and depending who you ask is simpler to administer. It sounds like ZFS can also have better i/o performance depending on tuning, but I don’t think I really care about that for current workload. However, I know it can also have pretty significant memory and cpu overhead. I haven’t found much info on how much that actually is though, beyond the 1GB/TB rule of thumb for dedup. On a server with these specs, how much performance impact can I expect zfs to actually have? Is it enough to be worth sticking with RAID or is it overblown?"},
{"Title": "Easier to get a NAS or just buy another desktop with lots of storage?", "Author": "u/El_Chupachichis", "Content": "I keep contemplating getting more storage, possibly a NAS.  But I'm not doing actual streaming, just collecting an ever larger amount of images, RAW and jpg (I'm an event photographer hobbyist).\n  \n\n    I would look at the NAS online and see perhaps a cheap 4 bay NAS, then look at the reviews and see a lot of complaints.  Seems like getting a reasonably reliable NAS would be more like getting a high end desktop.\n  \n\n    For those digital hoarders who don't have a lot of streamable data, do you prefer NAS or just a big desktop with a lot of drive slots, and maybe a software RAID?  I tend to be a cheapskate so historically it's always been \"buy another drive that's larger and copy stuff over\" but I really need to start thinking long term."},
{"Title": "I'm using an SD card to USB cable to transfer some photos to my PC but there's only one file with no extension called \"USBC ¬÷\u001f\". Help!", "Author": "u/CorvusTheCryptid", "Content": "The issue is as I describe in the title. I've never had a problem like this before! There's a single file on the device when I plug it in, titled \"USBC ¬÷\u001f\", with no file extension. It's a huge file so I assume that fixing it will allow me access to my files, which have somehow merged into this singular, huge file. Please help, I can't afford to lose these pictures!"},
{"Title": "Youtube server side add injection role out | Where is it already?", "Author": "u/Pommes254", "Content": "I am running ytdlp to archive a large amount of channels and i am kinda worried to contaminate my archive data with add injected versions.\nThe thing is so far i havent seen a single one with it in about 500 videos, i just finished downloading via proxies in germany, uk and japan (downloaded videos that are about 1-2 weeks old that i already have and compared length via script)\n  \n\n\nHow many users really get videos served with direct injected adds currently?\n\n\n\n\nAnd in what regions?\n\n\n\n    I hope a feature gets merged into ytdlp that checks video lengths and alerts if it detects more than +/- 1 sec compared to a known DB like sponsorblock."},
{"Title": "Photo scanning", "Author": "u/dashcash853", "Content": "Is the dpi a huge deal when it comes to this, I know some do 1200 dpi but a lot of the ones in my price range are 600 dpi."},
{"Title": "Internet forums are disappearing because now it's all Reddit and Discord. And that's worrying.", "Author": "u/Run_the_Line", "Content": "No content"},
{"Title": "Best way to back up gallery and general data from phone?", "Author": "u/Topangers", "Content": "I have iCloud but sometimes popups that appear confuse me and it doesn't seem like the images are actually being backed up? I need to make space on my phone but I hoard the images and videos; same with the general data and applications on my device. Any advice would be greatly appreciated! :)"},
{"Title": "chkbit: Check that your files were not corrupted", "Author": "u/laktakk", "Content": "No content"},
{"Title": "What is your automated linux based drive alert solution?", "Author": "u/88rcg", "Content": "I currently have a custom script I created that I run from time to time manually to poll my drives for their SMART data and record it in date stamped text files.\n  \n\n    I however don't know when should I really attempt to RMA my drives and I'd also like to setup some form of automated notification solution where I can get an email that effectively tells me I need to replace a drive.\n  \n\n    I am using a bare metal system with the latest ubuntu server 24.02 LTS and utilize snapraid for a cheap backup solution that provides parity.\n  \n\n    Drives:\n  \nNAME          MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS\nsda             8:0    0 16.4T  0 disk /mnt/disk9\nsdb             8:16   0  9.1T  0 disk /mnt/disk3\nsdc             8:32   0 12.7T  0 disk /mnt/disk4\nsdd             8:48   0  9.1T  0 disk /mnt/disk2\nsde             8:64   0 14.6T  0 disk /mnt/disk7\nsdf             8:80   0 12.7T  0 disk /mnt/disk6\nsdg             8:96   0 12.7T  0 disk /mnt/disk1\nsdh             8:112  0 16.4T  0 disk /mnt/disk12\nsdi             8:128  1 16.4T  0 disk /mnt/disk11\nsdj             8:144  1 16.4T  0 disk /mnt/disk8\nsdk             8:160  1 14.6T  0 disk /mnt/disk5\nsdl             8:176  1 14.6T  0 disk /mnt/disk10\nsdm             8:192  1 16.4T  0 disk /mnt/parity2\nsdn             8:208  1 16.4T  0 disk /mnt/parity3\nsdo             8:224  1  2.3T  0 disk /mnt/temp2\nsdp             8:240  1 16.4T  0 disk /mnt/parity\nnvme1n1       259:0    0  1.8T  0 disk\n├─nvme1n1p1   259:2    0    1G  0 part /boot/efi\n├─nvme1n1p2   259:3    0    1G  0 part\n├─nvme1n1p3   259:4    0    1G  0 part /boot\n└─nvme1n1p4   259:5    0  1.8T  0 part\n  └─vg0-lv--0 252:0    0  1.8T  0 lvm  /\nnvme0n1       259:1    0  1.8T  0 disk /mnt/temp\n\n    Below I've provided my latest report which provides a lot of info but I'd like to rather get some emailed notifications that let me know when to replace, rather than me having to lookup which drive attributes really matter and thresholds.\n  \n\n    latest report: \nhttps://pastebin.com/dwbF2F8u"},
{"Title": "Storage & Access to childhood memories", "Author": "u/Beautiful-Natural938", "Content": "I have a few external hard drives which store old photos and videos of my childhood and adult life. My digital memories remain isolated on these HD’s, where as I would like to be able to:\n  \n\n\n\n\n\n    Access these files via iPhone & MacBook  anywhere in the world through a secure & private encryption.\n  \n\n\n\n\n\n    Label the files for categorisation purposes.\n  \n\n\n\n\n\n    Share access to friends and family.\n  \n\n\n\n\n\n    I also don’t like the idea of having to pay for a subscription service. I have read NAS systems may be a good option.\n  \n\n    Any advice / recommendations is appreciated?"},
{"Title": "Longevity of Recordable CDs, DVDs and Blu-rays — Canadian Conservation Institute (CCI)", "Author": "u/didyousayboop", "Content": "Important information\n from the Canadian Conservation Institute, an agency of the federal government of Canada.\n  \nTable 2: the relative stability of optical disc formats\n\n\n\n\n\n\n\n            Optical disc formats\n          \n\n            Average longevity\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              CD-R (phthalocyanine dye, gold metal layer)\n            \n\n              >100 years\n            \n\n\n\n\n\n              CD-R (phthalocyanine dye, silver alloy metal layer)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              DVD-R (gold metal layer)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              CD (read-only, such as an audio CD)\n            \n\n              50 to 100 years\n            \n\n\n\n\n\n              CD-RW (erasable CD)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              BD-RE (erasable Blu-ray)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              DVD+R (silver alloy metal layer)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              CD-R (cyanine or azo dye, silver alloy metal layer)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              DVD+RW (erasable DVD)\n            \n\n              20 to 50 years\n            \n\n\n\n\n\n              BD-R (non-dye, gold metal layer)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              DVD-R (silver alloy metal layer)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              DVD and BD (read-only, such as a DVD or Blu-ray movie)\n            \n\n              10 to 20 years\n            \n\n\n\n\n\n              BD-R (dye or non-dye, single layer or dual layer)\n            \n\n              5 to 10 years\n            \n\n\n\n\n\n              DVD-RW (erasable DVD)\n            \n\n              5 to 10 years\n            \n\n\n\n\n\n              DVD+R DL (dual layer)\n            \n\n              5 to 10 years"},
{"Title": "Is it possible to save an online quiz  to offline and use it offline and recieve results?", "Author": "u/dokha", "Content": "It’s important to note thats the kind of assessment pages im talking about are the casual ones such as the fun ones you take on Buzzfeed and the ones you see on astrology sites..\n\n\n\n    I have no idea the correct tools involved and how to use them .. I did try browser addons such as Single File but the offline files never reach the results after taking the quiz.."},
{"Title": "Has anyone archived bash.org quotes?", "Author": "u/syswraith", "Content": "The website seems to be down for a while now. Also my password's *******. What's yours?"},
{"Title": "Organizing drives vs drive sizes vs raids/ZFS/stuff", "Author": "u/PuzzleHeadPistion", "Content": "Hey,\n  \n\n    I've got two NAS and a bunch of drives. One EXOS 16Tb, two Barracuda 8Tb, one IronWolf 6Tb, on WD \"white\" 6Tb and on WD Red 3Tb. My main NAS is a desktop with +6 slots, my second NAS is a 4 bay Asustor.\n  \n\n    Currently I don't use raid/parity of any kind... All drives are single volumes and it just sync's each drive from my main NAS to the second NAS, so I try to make the drive setup equal. However, the recent addition of the EXOS 16Tb kills that.\n  \n\n    Since my main NAS is changing to a FreeBSD/TrueNAS with a ZFS pool, what's the best setup?\n  \n\n    I was thinking maybe 8Tb+8Tb+6Tb+6Tb in the ZFS pool, then 16Tb+3Tb as single volumes on my second NAS. This way drives in the pool are as similar as possible in size and if parity wastes one drive, it will be about the same total capacity as the second NAS.\n  \n\n    Does this make sense?"},
{"Title": "Will youtube ad Injections break music downloads?", "Author": "u/Nerds_r_us45", "Content": "I like downloading some channels in bulk and idk if this will break my ability to hoard music easily or not."},
{"Title": "Using CRC or the like for music backup checking", "Author": "u/__99999", "Content": "Hello, I know about the various ways to get a crc and sha etc. I'm trying to find a program that keeps the same crc if I change the Metadata of the audio file. Does anyone know of one? It can be Linux or win or even a script. Basically I'm backing up and archiving my music like most of you. The issue I'm running into is I update my Metadata on my audio randomly. As I have over 10tbs (I know rookie numbers) I can't sit down and bang it out in 1 sitting so I do it in waves.\n  \n\n    tldr? I'm looking for a program that doesn't alter crc if I change the Metadata of my audio file (mp3 or flac etc)"},
{"Title": "Safest method to wipe out a drive without damaging it? I'm looking for paranoid-level shit.", "Author": "u/500xp1", "Content": "Looking for a method that makes it impossible to recover the wiped data."},
{"Title": "How can I view all DMs in Twitter Archive Data? Not all DMs history shows up.", "Author": "u/niceiambearlythere", "Content": "Hello, I've downloaded my Twitter Archive Data, but not all of the DMs could be seen. It only shows a certain part of the chat, usually the earlier conversations. Is there any way to solve this, so that I can look back on all of the messages again?"},
{"Title": "Software for splitting video files in bulk?", "Author": "u/Comfortable_Ad_6823", "Content": "I am currently ripping my SpongeBob DVDs. For anyone unaware, (almost) all SpongeBob episodes are split into A and B parts. For example, \"Pizza Delivery\" is only episode 5a, with \"Home Sweet Pineapple\" being episode 5b. Two \"segments\" make up one episode.\n  \n\n    Normally this isn't a problem, as each segment in the SpongeBob DVDs has its own .mkv file. That is, until season 9, where there are no .mkv files for individual segments, only the combined episode. This is rather annoying as I don't want to scrub to the half-way mark of the videos just to watch the episode I actually want to see. I've thought of splitting the files in half, but it would be a tedious process as seasons are quite long.\n  \n\n    Are there any programs or tools that would make this easier?"},
{"Title": "Looking for a software to recognize multiple TB of images", "Author": "u/EasyMoney322", "Content": "Hello, I'm looking for a self-hosted software (that also wouldn't upload photos anywhere) that could do image recognition on the fileshare with an acceptable success rate. I was able to find posts on this sub about nsfw bodyparts recognition, but its not what Im looking for.\n  \n\n    What level of recognition? It must be able to tell appart photos of mass events, people, pets, documents, roads, buildings etc. Having them organized by a location metadata, perhaps. Finding similar (almost duplicate, but with different hash) images.\n  \n\n    Would be great if I could select all the tagged images after, re-check them for false-positives, and delete.\n  \n\n    The fileshare is hosted on OpenSuse VM, but I also can deploy and mount it on any other OS on the same server. I have a lot of processing power, but I'd like to avoid training the AI by myself."},
{"Title": "alternative to Cathy or Virtual Volumes view that can do Boolean Search", "Author": "u/another_lease", "Content": "I need to do Boolean search on my unconnected disks.\n  \n\n    E.g., I need to search for files that contain the word \"confidence\" and \"interval\". If I enter `confidence interval` in the search bar,\n  \n\n\n\n\n\n    Cathy will only find files that contain the \nphrase\n \"confidence interval\" in their file name.\n  \n\n\n\n\n\n    Virtual Volumes View will find me files that contain both words anywhere in the file name, but it will also return files that contain \neither\n word in their filename.\n  \n\n\n\n\n\n    I know that Cathy and VVV have come up before on this subreddit. I was wondering if anyone's figured out some \nportable freeware\n that can do Boolean search.\n  \n\n    Thanks in advance."},
{"Title": "Need Help archiving important Norwegian Stenography", "Author": "u/VanillaKirby", "Content": "Hello, I need some assistance with archiving a book containing some of the only documentation of one of the only shorthand systems in the Norwegian Language, Wang-Krogdahl.\n  \n\n    The book is scanned and located in the Norwegian Public Library available here \nhttps://www.nb.no/items/URN:NBN:no-nb_digibok_2016011905022\n\n\n\n    You will need a Norwegian VPN to access the book, (i am using tunnelbear with a free license)\nI do not know of a way to extract these scans of the book from the website, help appreciated."},
{"Title": "Why isn't rsync checksum or the equivalent enough to verify your backups?", "Author": "u/Ninj_Pizz_ha", "Content": "I expect I'll get some flack from people super immersed into this subculture, but why do people still recommend opening up random files in the backup to make sure the backup actually worked? Why isn't rsync -c or the equivalent sufficient? Personally I only open my backups every once in blue moon. Maybe there's some edge case where rsync checksum itself is faulty or something I guess, but that's not on my list of likely concerns tbh."},
{"Title": "$5 worth the risk?", "Author": "u/Long_Instruction_391", "Content": "No content"},
{"Title": "Smart Data Testing Deltas", "Author": "u/ejpman", "Content": "Anyone seen this before? 4 identical new disks with a huge difference in completion time for long smart tests. They are 14TB HC530’s\n  \n\n    admin@NAS[~]$ sudo smartctl -x /dev/sdc | grep 'test remaining.'\n  \n                                        10% of test remaining.\nadmin@UgreenNAS[~]$ sudo smartctl -x /dev/sdb | grep 'test remaining.'\n                                        60% of test remaining.\nadmin@UgreenNAS[~]$ sudo smartctl -x /dev/sdc | grep 'test remaining.'\n                                        10% of test remaining.\nadmin@UgreenNAS[~]$ sudo smartctl -x /dev/sdd | grep 'test remaining.'\n                                        60% of test remaining.```"},
{"Title": "Newbie question: ZFS vs RAID 10 for 4 disks in budget home server", "Author": "u/TruthsTrueTruant", "Content": "I have a little home server, built around a cheapo mini-PC - Intel N100, 16GB RAM, 500GB internal SSD - that I’m finally upgrading the storage on. Storage workload is mainly Plex library, Seafile document/photo storage, and backups of other computers on the network.\n  \n\n    I have 4 12TB HDDs that I was planning on setting up as a RAID1+0, and am debating the pros and cons of going for a full ZFS setup instead (as I understand it, the equivalent would be 1 zpool -> 2 vdevs -> 2 disks each).\n  \n\n    I know that ZFS has the advantage of better integrity protection for bitrot etc., and depending who you ask is simpler to administer. It sounds like ZFS can also have better i/o performance depending on tuning, but I don’t think I really care about that for current workload. However, I know it can also have pretty significant memory and cpu overhead. I haven’t found much info on how much that actually is though, beyond the 1GB/TB rule of thumb for dedup. On a server with these specs, how much performance impact can I expect zfs to actually have? Is it enough to be worth sticking with RAID or is it overblown?"},
{"Title": "Easier to get a NAS or just buy another desktop with lots of storage?", "Author": "u/El_Chupachichis", "Content": "I keep contemplating getting more storage, possibly a NAS.  But I'm not doing actual streaming, just collecting an ever larger amount of images, RAW and jpg (I'm an event photographer hobbyist).\n  \n\n    I would look at the NAS online and see perhaps a cheap 4 bay NAS, then look at the reviews and see a lot of complaints.  Seems like getting a reasonably reliable NAS would be more like getting a high end desktop.\n  \n\n    For those digital hoarders who don't have a lot of streamable data, do you prefer NAS or just a big desktop with a lot of drive slots, and maybe a software RAID?  I tend to be a cheapskate so historically it's always been \"buy another drive that's larger and copy stuff over\" but I really need to start thinking long term."},
{"Title": "I'm using an SD card to USB cable to transfer some photos to my PC but there's only one file with no extension called \"USBC ¬÷\u001f\". Help!", "Author": "u/CorvusTheCryptid", "Content": "The issue is as I describe in the title. I've never had a problem like this before! There's a single file on the device when I plug it in, titled \"USBC ¬÷\u001f\", with no file extension. It's a huge file so I assume that fixing it will allow me access to my files, which have somehow merged into this singular, huge file. Please help, I can't afford to lose these pictures!"},
{"Title": "Youtube server side add injection role out | Where is it already?", "Author": "u/Pommes254", "Content": "I am running ytdlp to archive a large amount of channels and i am kinda worried to contaminate my archive data with add injected versions.\nThe thing is so far i havent seen a single one with it in about 500 videos, i just finished downloading via proxies in germany, uk and japan (downloaded videos that are about 1-2 weeks old that i already have and compared length via script)\n  \n\n\nHow many users really get videos served with direct injected adds currently?\n\n\n\n\nAnd in what regions?\n\n\n\n    I hope a feature gets merged into ytdlp that checks video lengths and alerts if it detects more than +/- 1 sec compared to a known DB like sponsorblock."},
{"Title": "Photo scanning", "Author": "u/dashcash853", "Content": "Is the dpi a huge deal when it comes to this, I know some do 1200 dpi but a lot of the ones in my price range are 600 dpi."},
{"Title": "Internet forums are disappearing because now it's all Reddit and Discord. And that's worrying.", "Author": "u/Run_the_Line", "Content": "No content"},
{"Title": "Best way to back up gallery and general data from phone?", "Author": "u/Topangers", "Content": "I have iCloud but sometimes popups that appear confuse me and it doesn't seem like the images are actually being backed up? I need to make space on my phone but I hoard the images and videos; same with the general data and applications on my device. Any advice would be greatly appreciated! :)"},
{"Title": "chkbit: Check that your files were not corrupted", "Author": "u/laktakk", "Content": "No content"},
{"Title": "What is your automated linux based drive alert solution?", "Author": "u/88rcg", "Content": "I currently have a custom script I created that I run from time to time manually to poll my drives for their SMART data and record it in date stamped text files.\n  \n\n    I however don't know when should I really attempt to RMA my drives and I'd also like to setup some form of automated notification solution where I can get an email that effectively tells me I need to replace a drive.\n  \n\n    I am using a bare metal system with the latest ubuntu server 24.02 LTS and utilize snapraid for a cheap backup solution that provides parity.\n  \n\n    Drives:\n  \nNAME          MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS\nsda             8:0    0 16.4T  0 disk /mnt/disk9\nsdb             8:16   0  9.1T  0 disk /mnt/disk3\nsdc             8:32   0 12.7T  0 disk /mnt/disk4\nsdd             8:48   0  9.1T  0 disk /mnt/disk2\nsde             8:64   0 14.6T  0 disk /mnt/disk7\nsdf             8:80   0 12.7T  0 disk /mnt/disk6\nsdg             8:96   0 12.7T  0 disk /mnt/disk1\nsdh             8:112  0 16.4T  0 disk /mnt/disk12\nsdi             8:128  1 16.4T  0 disk /mnt/disk11\nsdj             8:144  1 16.4T  0 disk /mnt/disk8\nsdk             8:160  1 14.6T  0 disk /mnt/disk5\nsdl             8:176  1 14.6T  0 disk /mnt/disk10\nsdm             8:192  1 16.4T  0 disk /mnt/parity2\nsdn             8:208  1 16.4T  0 disk /mnt/parity3\nsdo             8:224  1  2.3T  0 disk /mnt/temp2\nsdp             8:240  1 16.4T  0 disk /mnt/parity\nnvme1n1       259:0    0  1.8T  0 disk\n├─nvme1n1p1   259:2    0    1G  0 part /boot/efi\n├─nvme1n1p2   259:3    0    1G  0 part\n├─nvme1n1p3   259:4    0    1G  0 part /boot\n└─nvme1n1p4   259:5    0  1.8T  0 part\n  └─vg0-lv--0 252:0    0  1.8T  0 lvm  /\nnvme0n1       259:1    0  1.8T  0 disk /mnt/temp\n\n    Below I've provided my latest report which provides a lot of info but I'd like to rather get some emailed notifications that let me know when to replace, rather than me having to lookup which drive attributes really matter and thresholds.\n  \n\n    latest report: \nhttps://pastebin.com/dwbF2F8u"},
{"Title": "Getting creative and hacky with SFF as NAS.", "Author": "u/kkgmgfn", "Content": "Trigger Warning : This post is for DataHoarders + SFF enthusiasts. So please don't come saying get a 2TB NVME, get a 2.5 SATA SSD and yap yap yap.. And I have other systems too. One EATX, One MFF, Two SFF and One HTPC. So I am not a new builder. Posting here since it will be more appropriate than posting in Homelab or DataHoarder sub.\n  \n\n    As we know it we have very limited SFF cases with HDD support. Manufacturers hardly make them anymore.\n  \n\n    Some options that we have today:\n  \n\n    Node 304: Outdated and front panel is very restrictive. 92mm fans in front are noisy as they are 3pin. In my country I can't find any 92mm fan.\n  \n\n    Jonsbo N series: Pat on the back for Jonsbo on launching several SFF NAS cases back to back. They feel like they have restrictive airflow. They aren't available in my country.\n  \n\n    SAMA IM 01 and its copies: Supports 4 - 5. A cheap knock of this is available. But is an option.\n  \n\n    So my question is have you guys though about squeezing extra HDDs in cases like Deepcool CH 160, Coolermaster NR200P etc. For example if I can use rear fan mount for 120 AIO intake then does 120 fan slot above have motherboard has hinges for 3. 5\"HDD? Does it have space to tuck one below a dual slot dual fan GPU. I know 1 3.5\" HDD can go on front panel when I use a SFX PSU. Similarly for NR200P. More suggestions are welcome. I'll use a Noctua L9i or 120 AIO as I have then lying around.\n  \n\n    I wish this post to be open for coming years so people can get ideas and inspiration from the comments."},
{"Title": "Newbie setup questions", "Author": "u/tranrep", "Content": "Hey all, trying to get myself situated and not the most tech-savvy person so apologies in advance if I'm missing the mark. For context, I'm mostly a hobbyist photographer that wants to just keep my data safe and I don't believe I'd have a need for most of what a NAS offers, so I'm looking into DAS/JBOD as a solution. I currently have around 6TB of photo/video I consider \"important\" enough to backup.\n  \n\n    My current setup is just a single 14 TB WD External HD which is not really being backed up anywhere so I'd like to improve my setup.\n  \n\n    At the core, I'm currently planning on doing the following:\n  \n\n\n\n\n\n    Buying a new 8TB HDD that I'll be \"working off of\", and moving all of my existing data into it\n  \n\n\n\n\n\n    Buying a 4 bay DAS, either using 2 drives for now for RAID1 or buying 4 for RAID4/5 (??) to periodically mirror data from the single 8TB drive onto.\n  \n\n\n\n\n\n    Using Backblaze to backup my PC + DAS.\n  \n\n\n\n\n\n    Does this setup make sense for my needs? If it does make sense, does anybody have any particular product recommendations for the DAS/JBOD and if there's any specific thing to look for in the type of drive(s) to purchase? Is this perhaps overkill for the use case? Please let me know if I'm not providing enough information, thanks."},
{"Title": "CD ripping", "Author": "u/nlj1978", "Content": "I have setup a Jellyfin server and have been successfully ripping CDs to flac using EAC.\n  \n\n    EAC does have one issue I haven't figured out. There doesn't seem to be a way to have the contents of one CD ripped into its own folder in the destination.\n  \n\n    Jellyfin's file structure wants each CD in its own folder.\n  \n\n    Is there a method to accomplish this I just haven't found yet?\n  \n\n    If not is there another ripping software that can do this?"},
{"Title": "Bulk image downloader that can download images linked from thumbnails", "Author": "u/xavierhollis", "Content": "Often I find myself checking out a gallery or a post on reddit that has multiple images. By clicking on the thumbnails I can open up larger versions of the same images. But if I want to save the images it gets tedious and time consuming having to go through them all one by one, opening up dozens of webpages or scrolling through each image to save them.\n  \n\n    Is there an app that will basically bulk download ALL the images from a gallery, not simply the thumbnails on that one page, but the higher res images the thumbnails link to?"},
{"Title": "Hydrus network server help?", "Author": "u/Head-Ordinary-4349", "Content": "Does anyone here have any experience translating your local \nHydrus network\n onto a publicly available server? I have made a local database of images which I would like to share and have editable by anyone publicly with a link, however I am very inexperienced in this sort of thing. The user resources describe a  hacky server component that can serve your database over https (as also mentioned \nhere\n), but honestly I have no idea where to even start. I'm wondering if anyone would be able to point me in the right direction or possibly even give me a bit of guidance on how I should proceed? Thanks!"},
{"Title": "Why is XFS not more popular? Are there are any concerns with XFS still?", "Author": "u/ECrispy", "Content": "This is for home desktop usage, not servers/data centers where XFS is far more common.\n  \n\n    performance - in every test I could find, XFS is near the top, beating btrfs/ext4. Its esp good for parallel workloads and almost everything on a modern desktop is like that. The only perf concern I read about is it used to have higher cpu usage for updating metadata but I believe thats been fixed and no longer relevant?\n  \n\n    (I think for most users, performance in benchmarks may not be noticeable and other features matter more, but its still an important consideration)\n  \n\n    SSD/OS installs - XFS is almost as fast as f2fs for these. I see no reason why anyone would use f2fs on anything other than a sd card or on any NAND device with wear leveling.\n  \n\n    CoW/snapshots - this is no doubt a very powerful feature of zfs/btrfs. But I see very little mention of reflinks/snapshots on XFS which can achieve a lot of this. They are not atomic but enough to satisfy a lot of use cases. I don't see support for this in the usual tools like snapper/timeshift either. XFS also has support for deduping. All of this comes without the usual cost of CoW\n  \n\n    other features - dynamic inodes (on ext4 an inode for every 16kb/256kb is wasteful, even if most people never notice it), automatic fsck, journalling (sure, copied from ext3, but thats not a bad thing)\n  \n\n    stability/reliability - I don't think there should be any doubt about this. Its a proven enterprise class fs with a hallowed pedigree and reputation, is now backed by RHEL and has probably seen more active development than most other file systems.\n  \n\n\n\n    The biggest factor seems to be that the default ext4 is good enough, and frankly most people will not care or know about, and should not care, about the underlying fs. There are also distros like Fedora/OpenSuse that used to use XFS as the default and have switched to btrfs. I don't know of anything that uses XFS as default except unRaid now - unRaid is used to manage TBs by home users and that probably says something.\n  \n\n\n\n    The only concerns I've found are -\n  \n\n    a) it doesn't support shrinking a volume. how common is this anyway? I've never seen any home user need to do this, 99% of the time you only need this when you are installing another OS on the same ssd/hdd and need to shrink your current /, which is an advanced use case.\n  \n\n    b)supposedly XFS doesn't handle hw failures. Even on this I found no consensus - some people say its risky and can corrupt with no recovery, others say even with a forced  shutdown its safe. I'm not sure if its any less robust than ext4/btrfs? Is this actually a concern these days?"},
{"Title": "Recertified EXOS X18 constantly reading?", "Author": "u/wiadrovit", "Content": "Hey there Guys,\n  \n\n    I've bought a recertified EXOS X18 12TB for my NAS. The drive isn't exactly loud and it performs as I would expect, but there's one thing that I can't walk past - it acts as if it was doing something, even when completely idle.\n  \n\n    The drive lives in my Sabrent DS-SC5B hdd enclosure which I've been using for over a year now and which I'm very satisfied with.\n  \n\n    Video: \nhttps://imgur.com/a/o39cfd8\n (it's the second one from the top - as you can see its LED is blinking in a regular manner).\n  \n\n    I've read that EXOS drives have their own APM feature which can be disabled using seachest tool. I've managed to successfully disable both EPC as well as the power balance feature, but that didn't change anything, the LED still blinks and I can hear a regular, gentle cracking sound as if something was read/written.\n  \n\n    The drive is mounted on my Debian installation and I've confirmed that no process is using it. What's weird is that activities stop as soon as I unmount the drive (and start again as soon as I mount it back).\n  \n\n    In fact, this is a second drive that does the same thing. I've returned previous one to the seller as I've felt something is not right with it. Both were manufactured (or rather reassembled?) back in March 2024.\n  \n\n    I should add that I have another EXOS drive (X16 16TB sitting in my backup device) and it doesn't act this way.\n  \n\n    Is it normal for these drives or do you think I should return this one as well and go for something else?\n  \n\n    It isn't that much annoying, I am just worried that if the head keeps flying all the time, the drive will wear sooner and might die prematurely.\n  \n\n    Thanks for any advice."},
{"Title": "Any suggestions how to save a streaming video embedded in a news site?", "Author": "u/Basics7", "Content": "There are a couple of videos I want to save from a news site, I OWN the 4K Video Downloader app, but it seems these videos are streaming or something, any downloader I try shows it's multiple bits put together? Js or streaming, something like that.\n  \n\n    But any other downloader extention or app I find that seems to address this kind of site ends up in Google as containing malware. Is there a legit app that I can use or buy to download something that's streaming?\n  \n\n    I've used a few options over the years and figured out how to download from FB, YT, \"The Hub\", almost anywhere... but this one I can't, it's \"streaming\".\n  \n\n    Any programs that are safe (free or not) that would handle this, I'd appreciate being pointed in the right direction."},
{"Title": "Why is RPM emphasized more tha data transfer rate for hard drives?", "Author": "u/Discuzting", "Content": "Hello folks novice here, I googled my question already but I found no answers.\n  \n\n    Why is RPM the focus, instead of stats like sequential/random read/write?\n  \n\n    Could I assume that hard drives with the same RPM and cache, basically performs the same?"},
{"Title": "Video and Audio URLs obtained from yt-dlp -g are downloading very slow. How to fix?", "Author": "u/CoolstarLikesHentai", "Content": "I am trying to get the original video file from a YouTube video by using the \nyt-dlp -g\n command (short for \nyt-dlp --get-url\n) to get the video URL and audio URL. I can successfully get both URLs, but when I download them it downloads very very slow (~150 kb/s). Is there any way I can speed up the download speed?"},
{"Title": "Are there some software that provides multiple download links using VPN at once?", "Author": "u/ElonTastical", "Content": "Let's say you wanna download multiple links from keep2share, but in that site it is limited by single download, you have to wait two hours before you can download another file. Is there a way to bypass this like the idea I mentioned in the title?"},
{"Title": "Backup my network pc's to my OMV Nas", "Author": "u/SbM_Yggdrassil", "Content": "Hi all, I'm at that part of my homelab journey where I've setup a bunch of fun stuff and now I'm starting to think about helpful stuff like backups.\n  \n\n    I have a raspberry pi 4 setup with open media vault and docker running various services. I would like to add one or more services (in containers if necessary) to accomplish the following:\n  \n\n\n\n\n\n    Make an image of bootdrives of my computers on a schedule\n  \n\n\n\n\n\n    save those images to the attached storage.\n  \n\n\n\n\n\n    reimaging solution for recovery\n  \n\n\n\n\n\n\n\n\n\n    Backup secondary, non-bootdrives of my computers (just copying is probably fine)\n  \n\n\n\n\n\n    I'm just wondering how to best add services and which would do it. If I should use syncthing/duplicati + something else or if there is one thing that can do it all. I'm not sure how incremental backups fit in here either but I'd like to implement that to reduce the burden of network traffic (in my home we have to use wi-fi a lot).\n  \n\n    For drive images I've used the free version of Macrium reflect before (and I've heard of acronis), but just on one of my windows pc's. I'd like to have something scheduled from the server side for centralised management.\n  \n\n    Does it make sense what I'm trying to achieve?"},
{"Title": "Feedback for backup plan", "Author": "u/DeadbeatSummer13", "Content": "My dataset is around 10-16tb. I plan on transferring my current externals to 1 big drive. I’m trying to decide if this working drive is going to be internal or external. Regardless, this will be backed up to a 2nd drive daily. Then, the 2nd drive will backup to backblaze daily. A private encryption key will be set on backblaze. Possibly down the road an off-site drive may be added to be backed up weekly and then disconnected and moved off-site.\n  \n\n    Feedback is greatly appreciated. What do you think?"},
{"Title": "Should I purchase a NAS for the data integrity features?", "Author": "u/SystemElegant2703", "Content": "Is it necessary to purchase a NAS if all I'm really interested in are the data integrity features (i.e automatic hash checking/recording, file self-healing, datascrubbing, etc.)? Currently I use MultiPar and backup my data to M-discs. However, I would like greater certainty that the hashes are accurate. For instance, I got a trojan recently and now I'm left questioning if the hundreds of files I've downloaded since my last backup have any data corruption, silent or otherwise. Since it's impossible to know without the features I listed previously, should I consider purchasing a NAS or is there a method I haven't thought of to ensure the same level of data integrity?"},
{"Title": "Help finding data by address", "Author": "u/countesscranberry", "Content": "No idea where to post this, sorry!\n  \n\n    I have a list of about 5,000 addresses. For each one, I want to know the census tract, the voting districts, the region (as defined by my city), and maybe more later on.\n  \n\n    How can I set something up where I can match my list of addresses with a list of all addresses in my state (Ohio), cross-reference all of that other data, and have all of that information spit out for each address for me?\n  \n\n    Really any way to make this process faster would be appreciated. I’ve found some files online from various government agencies but I’m not sure if they are all relevant or useful. What kind of file types am I looking for? I have some maps overlayed in Google Earth so I can look up addresses and find the information that way, but I’m not doing it one by one. I chatted with my IT guy but he’s part time and didn’t have any standout ideas at the time.\n  \n\n    Thank you!"},
{"Title": "Need advise on my Alternative 3-2-1 plan", "Author": "u/OverqualifiedTech353", "Content": "Clear & open your minds - this one's a bit of a doozie...\n  \n\n    So I've recently begun ROM collecting (might as well reveal that since my account is tied to it), and I'm faced with the best way to preserve this data, as well as use it infrequently. Currently the plan is sort of like a 2.5-2-0.5 method:\n  \n\n\n\n\n\n    Leave a copy of smaller ROM sets on my desktop SSD (non-OS), but move everything else:\n  \n\n\n\n\n\n    AND Offload collections (such as <system> handhelds) to 2 or 4TB 3.5\" HDDs depending on the collection size and keep in \"lukewarm\" storage (plug into HDD dock for small updates, otherwise keep offline) [1]\n  \n\n\n\n\n\n    AND from there, copy organized folders to accessible \nmicro SD cards\n for the various \nhandhelds\n (no power most of the time) [2a]\n  \n\n\n\n\n\n    XOR copy organized folders to \nportable HDDs\n for the various \nconsoles\n (off/idle, or online for maybe max 1khrs/yr) [2b]\n  \n\n\n\n\n\n\n\n\n\n    AND Offload copy of entire collection to a large NAS. [3]\n  \n\n\n\n\n\n\n\n\n\n    I have 6x 2TB HDDs, and 8x 4TB HDDs inherited from various places for the [1] and [3] tasks. So:\n  \n\n    [3] For NAS, I am thinking 4TBx6 (-1) = 20TB in RAID5. This would be used for other files and backups as well (that's it's own problem).\n  \n\n    [1] That leaves 2x6TB + 2x4TB = 22TB of curated backup/cold storage. Though I am thinking I leave one or both of the 4TBs for replacement drives in case of failure... so 12TB of 2TB drives.\n  \n\n    That's sufficient for 2x copies (one online [3], one offline [1]) + the 'accessible'/usable copies [2] (kind of satisfying the \"3\" and 2 in 3-2-1). The 1 is a 0.5 since it would be in another room(s), and doing a truely remote location is not really in the picture for me. Really all 3 mediums would be in different rooms, likely.\n  \n\n    My biggest concern is maintaining the 2 (well, 3) cold storage media types. Especially the microSDs, which I cannot find a definitive answer on how to maintain file integrity (seems like power on at least every year?, then somehow do a bit-by-bit rewrite?)\n  \n\n    I've read up on store type archives, and PAR2 type parity. It seems like the best solution for long-term storage for a standalone, non-RAID drive (SD or HDD), would be to create a 10% parity file for every game (zip multi-file games), particularly on the microSDs which are most prone to bit rot.\n  \n\n    I've had a lot of issues with microSDs in the past failing, so I have little faith in them. That means I would be forced to keep a per-card mirror on the NAS most likely (in place of the compressed versions for transfer convenience), and backing up any save games at least annually. But then what? Just wait until I try to access a file that fails? And what about the portable and internal HDDs? How often should I be plugging them back in and doing X?\n  \n\n    tl;dr: How do you maintain microSDs and offline HDDs, how do you validate them, how often do you clone and replace them? And otherwise what would you do differently or add?"},
{"Title": "Ripping dvd/blu-rays question for auto ripping? via bash script", "Author": "u/1michaelbrown", "Content": "I have setup a bash script to autorip so far it is working but with errors. So how would I fix the errors or do this a better way. Errors I am having\n  \nJun 17 20:24:15 markvm5 (udev-worker)[9984]: sr0: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:24:15 markvm5 (udev-worker)[9995]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:26:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] is taking longer than 56s to complete                                                      \nJun 17 20:26:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 is taking a long time                                                                                                     \nJun 17 20:28:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] timed out after 2min 56s, killing                                                          \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 killed                                                                                                                    \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] terminated by signal 9 (KILL).                                                                                                                   \nJun 17 20:41:49 markvm5 (udev-worker)[10159]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                   \nJun 17 20:52:38 markvm5 (udev-worker)[10201]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10205] is taking longer than 47s to complete                                                      \nJun 17 20:52:38 markvm5 systemd-udevd[467]: sr1: Worker [10201] processing SEQNUM=8077 is taking a long time Jun 17 20:24:15 markvm5 (udev-worker)[9984]: sr0: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:24:15 markvm5 (udev-worker)[9995]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:26:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] is taking longer than 56s to complete                                                      \nJun 17 20:26:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 is taking a long time                                                                                                     \nJun 17 20:28:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] timed out after 2min 56s, killing                                                          \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 killed                                                                                                                    \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] terminated by signal 9 (KILL).                                                                                                                   \nJun 17 20:41:49 markvm5 (udev-worker)[10159]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                   \nJun 17 20:52:38 markvm5 (udev-worker)[10201]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10205] is taking longer than 47s to complete                                                      \nJun 17 20:52:38 markvm5 systemd-udevd[467]: sr1: Worker [10201] processing SEQNUM=8077 is taking a long time \n\n    This is the process I used I setup a udev rule\n  \nSUBSYSTEM==\"block\", ENV{ID_CDROM}==\"1\", ACTION==\"change\", RUN+=\"/bin/systemctl start makemkv-rip.service\"SUBSYSTEM==\"block\", ENV{ID_CDROM}==\"1\", ACTION==\"change\", RUN+=\"/bin/systemctl start makemkv-rip.service\"\n\n    and the makemkv-rip.service at\n  \n/etc/systemd/system/makemkv-rip.service`/etc/systemd/system/makemkv-rip.service\n\n[Unit]                                                                                                                                                                                                           \nDescription=AutoRip CD on insertion                                                                                                                                                                              \n                                                                                                                                                                                                                 \n[Service]                                                                                                                                                                                                        \nType=oneshot                                                                                                                                                                                                     \nRemainAfterExit=no                                                                                                                                                                                               \nExecStart=/home/mike/autorip.sh                                                                                                                                                                                  \nExecStop=killall autorip.sh [Unit]                                                                                                                                                                                                           \nDescription=AutoRip CD on insertion                                                                                                                                                                              \n                                                                                                                                                                                                                 \n[Service]                                                                                                                                                                                                        \nType=oneshot                                                                                                                                                                                                     \nRemainAfterExit=no                                                                                                                                                                                               \nExecStart=/home/mike/autorip.sh                                                                                                                                                                                  \nExecStop=killall autorip.sh \n\n    It's weird because the script is working but still get these errors. Also need to figure out how to trigger encoding after rip. Also in my autorip script it is finding titles in ` TINFO` should it be finding them in CINFO."},
{"Title": "Extracting Subtitles from Patreon", "Author": "u/pinkwonderwall", "Content": "Is there a way to rip captions from Patreon videos? I'm talking about Patreon videos I already have access to through a paid subscription. I like to save a video's subtitles as a text file so I can ctrl+F search for a particular word and find the moment that topic is discussed. I've tried Chrome extensions, but none of them work with Patreon. I've also looked for other posts of people asking this question, and it seems like not many people are trying to do this lol. I searched Inspect and Page Source and didn't see any obvious solutions, but I'm inexperienced with that so I may be missing something."},
{"Title": "Exausted and burnt out due to caring for my data", "Author": "u/CreativeDog2024", "Content": "I have about 5TB of movies/tv shows/photos. I have 3 backups: one is my main frequently accessed HDD. Another is another HDD i keep in my drawer and the last is google drive.\n  \n\n    I'm not a programmer so idk how to verify whether there has been data loss but I make sure all the files on each are the same by using freefilesync (mac app). It takes so much time and I don't even know if the files are corrupted or not.\n  \n\n    Is there some cloud option that I can leave my data on and pay $10-15/month to forget about it, using it as a last resort if all my local backups are corrupted?\n  \n\n    I read quite a bit on this and people recommend backblaze (B2 I think, how do i even buy it?), AWS glacier and M-disks.\n  \n\n    I have no idea how to operate any of those because I don't code. I do use rclone for Gdrive though."},
{"Title": "Western Digital DC HC580 (CMR or SMR?) & DS923+", "Author": "u/sulicadiz", "Content": "I just bought a Western Digital DC HC580. I don't know an effective method to know if the drive is CMR or SMR. I have read here in the forum that I should buy a CMR hard drive to use with the NAS (I have a DS923+).\n  \n\n    Another question, before setting the NAS should I introduce all the drives I would be using?\nThe NAS have 4 slots, so I guess the first step would be to buy 4 hard drive then set up the unit. I suppose If I insert 2 drives then the other 2 I would lose data.\n  \n\n    Anyway, total noob here, please help"},
{"Title": "Need an all-in-one podcast downloader replacement for Google Podcasts", "Author": "u/justquestionsbud", "Content": "So, just found out Google Podcasts is shutting down. I loved it, because whatever podcast I wanted, I could just find it in Google Podcats, \nyoutube-dl\n the whole thing, and I don't have to worry about content for months at a time. Now that it's going...seems like the end of my podcast consumption. Any ideas? Pocket Casts doesn't seem to have a browser-based option."},
{"Title": "What Non-NAS storage would you recommend?", "Author": "u/Bloodmoonwolf", "Content": "I currently have less than 800GB across 2 clouds and my laptop. I'm hitting my storage limit on Google and looking for a safe, local option. After losing everything on an old laptop that crashed, I started doing cloud storage, which is now becoming expensive.\n  \n\n    My current laptop is an old HP and I have yet to decide between a new Windows laptop or a Chromebook. I have a Plex library I would like to expand, even bought an external DVD reader to start the library. I don't necessarily need NAS. Plugging something into the TV or my laptop would be fine when I want to watch something on Plex (which isn't very often). The same goes for when I need to do a regular backup of files. I would prefer to buy something once instead of paying a monthly subscription and to not add another constant draw on our power supply.\n  \n\n    Most of the storage is for movies/shows, photos, and PDF scans of documents from when I went paperless. I would like to add music to this once I figure out a few things.\n  \n\n    What type/size/brand of local storage would you recommend for my situation?"},
{"Title": "Best non destructive way to scan books with illustrations and photographs?", "Author": "u/green__problem", "Content": "I have a flatbed scanner and a phone with a quality camera.\n  \n\n    For text-heavy books I use the CamScanner app, and then scan the cover using my flatbed. Non destructive, very effective. For magazines and newspapers, the flatbed is usually enough, as the lack of a solid spine makes scanning with minimal wear very easy.\n  \n\n    Now comes my problem: \nI have a lot of image-heavy books that I want to scan, but I have yet to find a good method to do so.\n\n\n\n    CamScanner is horrid at dealing with illustrations and photographs. The flatbed works \nalright\n, but not great. Because I avoid breaking the book's spine, there are always visible shadows and both text and images become a little blurry when they're close to the hinge.\n  \n\n\nI'm wondering if there's an app similar to CamScanner but more appropriate for photographs? Or a different method altogether.\n\n\n\n    I know some people melt the glue keeping the spine together, scan the pages individually, and then glue everything back on. This wouldn't work for all of the books in my collection- but I have considered trying it on a handful of them. I'm just a little scared of screwing the process up.\n  \n\n    Thanks in advance."},
{"Title": "Dedup utility that FIRST finds duplicates by name/size/date, and THEN compares their content", "Author": "u/Msprg", "Content": "Hello,\n  \n\n    Let me preface with: I know there are a million posts about dedup tools already. Dedup by file content, checksum, attributes, similar photos, similar videos…\n  \n\n    Yet somehow, I failed to find any tools that would be able to first filter out the majority of files that differ in filename / date / size \nand\n \nthen\n on the results make sure that files are 100% surely duplicate by comparing their content.\n  \n\n    I've tried dupeguru, alldup, freefilesync, treesize, czkawka, I tried everything! (By voidtools that is).\n  \n\n    The point is that I'm either missing something, or that none of the tools offer the option I'm looking for.\n  \n\n    So here I am. Once again. Seeking answer to the eternal question: How do you deal with duplicates, fellow Data Hoarders?"},
{"Title": "ytarchive vs yt-dlp on video afterwards", "Author": "u/idle_cat", "Content": "On youtube, I archive livestreams of a channel. Is the live archive recording I get by using ytarchive a higher quality then the video I would get with yt-dlp that's processed afterwards? From my understanding the video goes through youtube's compression. Is the compression really strong in your opinion? I am wondering if it's worth getting the vod to save space.\n  \n\n    Side questions:\n  \n\n    Why do people put --format \"bv*+ba/b\" or something similar to get when yt-dlp already has it set to get the individual best audio and video as the default? \nhttps://github.com/yt-dlp/yt-dlp?tab=readme-ov-file#format-selection"},
{"Title": "Getting creative and hacky with SFF as NAS.", "Author": "u/kkgmgfn", "Content": "Trigger Warning : This post is for DataHoarders + SFF enthusiasts. So please don't come saying get a 2TB NVME, get a 2.5 SATA SSD and yap yap yap.. And I have other systems too. One EATX, One MFF, Two SFF and One HTPC. So I am not a new builder. Posting here since it will be more appropriate than posting in Homelab or DataHoarder sub.\n  \n\n    As we know it we have very limited SFF cases with HDD support. Manufacturers hardly make them anymore.\n  \n\n    Some options that we have today:\n  \n\n    Node 304: Outdated and front panel is very restrictive. 92mm fans in front are noisy as they are 3pin. In my country I can't find any 92mm fan.\n  \n\n    Jonsbo N series: Pat on the back for Jonsbo on launching several SFF NAS cases back to back. They feel like they have restrictive airflow. They aren't available in my country.\n  \n\n    SAMA IM 01 and its copies: Supports 4 - 5. A cheap knock of this is available. But is an option.\n  \n\n    So my question is have you guys though about squeezing extra HDDs in cases like Deepcool CH 160, Coolermaster NR200P etc. For example if I can use rear fan mount for 120 AIO intake then does 120 fan slot above have motherboard has hinges for 3. 5\"HDD? Does it have space to tuck one below a dual slot dual fan GPU. I know 1 3.5\" HDD can go on front panel when I use a SFX PSU. Similarly for NR200P. More suggestions are welcome. I'll use a Noctua L9i or 120 AIO as I have then lying around.\n  \n\n    I wish this post to be open for coming years so people can get ideas and inspiration from the comments."},
{"Title": "Newbie setup questions", "Author": "u/tranrep", "Content": "Hey all, trying to get myself situated and not the most tech-savvy person so apologies in advance if I'm missing the mark. For context, I'm mostly a hobbyist photographer that wants to just keep my data safe and I don't believe I'd have a need for most of what a NAS offers, so I'm looking into DAS/JBOD as a solution. I currently have around 6TB of photo/video I consider \"important\" enough to backup.\n  \n\n    My current setup is just a single 14 TB WD External HD which is not really being backed up anywhere so I'd like to improve my setup.\n  \n\n    At the core, I'm currently planning on doing the following:\n  \n\n\n\n\n\n    Buying a new 8TB HDD that I'll be \"working off of\", and moving all of my existing data into it\n  \n\n\n\n\n\n    Buying a 4 bay DAS, either using 2 drives for now for RAID1 or buying 4 for RAID4/5 (??) to periodically mirror data from the single 8TB drive onto.\n  \n\n\n\n\n\n    Using Backblaze to backup my PC + DAS.\n  \n\n\n\n\n\n    Does this setup make sense for my needs? If it does make sense, does anybody have any particular product recommendations for the DAS/JBOD and if there's any specific thing to look for in the type of drive(s) to purchase? Is this perhaps overkill for the use case? Please let me know if I'm not providing enough information, thanks."},
{"Title": "CD ripping", "Author": "u/nlj1978", "Content": "I have setup a Jellyfin server and have been successfully ripping CDs to flac using EAC.\n  \n\n    EAC does have one issue I haven't figured out. There doesn't seem to be a way to have the contents of one CD ripped into its own folder in the destination.\n  \n\n    Jellyfin's file structure wants each CD in its own folder.\n  \n\n    Is there a method to accomplish this I just haven't found yet?\n  \n\n    If not is there another ripping software that can do this?"},
{"Title": "Bulk image downloader that can download images linked from thumbnails", "Author": "u/xavierhollis", "Content": "Often I find myself checking out a gallery or a post on reddit that has multiple images. By clicking on the thumbnails I can open up larger versions of the same images. But if I want to save the images it gets tedious and time consuming having to go through them all one by one, opening up dozens of webpages or scrolling through each image to save them.\n  \n\n    Is there an app that will basically bulk download ALL the images from a gallery, not simply the thumbnails on that one page, but the higher res images the thumbnails link to?"},
{"Title": "Hydrus network server help?", "Author": "u/Head-Ordinary-4349", "Content": "Does anyone here have any experience translating your local \nHydrus network\n onto a publicly available server? I have made a local database of images which I would like to share and have editable by anyone publicly with a link, however I am very inexperienced in this sort of thing. The user resources describe a  hacky server component that can serve your database over https (as also mentioned \nhere\n), but honestly I have no idea where to even start. I'm wondering if anyone would be able to point me in the right direction or possibly even give me a bit of guidance on how I should proceed? Thanks!"},
{"Title": "Why is XFS not more popular? Are there are any concerns with XFS still?", "Author": "u/ECrispy", "Content": "This is for home desktop usage, not servers/data centers where XFS is far more common.\n  \n\n    performance - in every test I could find, XFS is near the top, beating btrfs/ext4. Its esp good for parallel workloads and almost everything on a modern desktop is like that. The only perf concern I read about is it used to have higher cpu usage for updating metadata but I believe thats been fixed and no longer relevant?\n  \n\n    (I think for most users, performance in benchmarks may not be noticeable and other features matter more, but its still an important consideration)\n  \n\n    SSD/OS installs - XFS is almost as fast as f2fs for these. I see no reason why anyone would use f2fs on anything other than a sd card or on any NAND device with wear leveling.\n  \n\n    CoW/snapshots - this is no doubt a very powerful feature of zfs/btrfs. But I see very little mention of reflinks/snapshots on XFS which can achieve a lot of this. They are not atomic but enough to satisfy a lot of use cases. I don't see support for this in the usual tools like snapper/timeshift either. XFS also has support for deduping. All of this comes without the usual cost of CoW\n  \n\n    other features - dynamic inodes (on ext4 an inode for every 16kb/256kb is wasteful, even if most people never notice it), automatic fsck, journalling (sure, copied from ext3, but thats not a bad thing)\n  \n\n    stability/reliability - I don't think there should be any doubt about this. Its a proven enterprise class fs with a hallowed pedigree and reputation, is now backed by RHEL and has probably seen more active development than most other file systems.\n  \n\n\n\n    The biggest factor seems to be that the default ext4 is good enough, and frankly most people will not care or know about, and should not care, about the underlying fs. There are also distros like Fedora/OpenSuse that used to use XFS as the default and have switched to btrfs. I don't know of anything that uses XFS as default except unRaid now - unRaid is used to manage TBs by home users and that probably says something.\n  \n\n\n\n    The only concerns I've found are -\n  \n\n    a) it doesn't support shrinking a volume. how common is this anyway? I've never seen any home user need to do this, 99% of the time you only need this when you are installing another OS on the same ssd/hdd and need to shrink your current /, which is an advanced use case.\n  \n\n    b)supposedly XFS doesn't handle hw failures. Even on this I found no consensus - some people say its risky and can corrupt with no recovery, others say even with a forced  shutdown its safe. I'm not sure if its any less robust than ext4/btrfs? Is this actually a concern these days?"},
{"Title": "Recertified EXOS X18 constantly reading?", "Author": "u/wiadrovit", "Content": "Hey there Guys,\n  \n\n    I've bought a recertified EXOS X18 12TB for my NAS. The drive isn't exactly loud and it performs as I would expect, but there's one thing that I can't walk past - it acts as if it was doing something, even when completely idle.\n  \n\n    The drive lives in my Sabrent DS-SC5B hdd enclosure which I've been using for over a year now and which I'm very satisfied with.\n  \n\n    Video: \nhttps://imgur.com/a/o39cfd8\n (it's the second one from the top - as you can see its LED is blinking in a regular manner).\n  \n\n    I've read that EXOS drives have their own APM feature which can be disabled using seachest tool. I've managed to successfully disable both EPC as well as the power balance feature, but that didn't change anything, the LED still blinks and I can hear a regular, gentle cracking sound as if something was read/written.\n  \n\n    The drive is mounted on my Debian installation and I've confirmed that no process is using it. What's weird is that activities stop as soon as I unmount the drive (and start again as soon as I mount it back).\n  \n\n    In fact, this is a second drive that does the same thing. I've returned previous one to the seller as I've felt something is not right with it. Both were manufactured (or rather reassembled?) back in March 2024.\n  \n\n    I should add that I have another EXOS drive (X16 16TB sitting in my backup device) and it doesn't act this way.\n  \n\n    Is it normal for these drives or do you think I should return this one as well and go for something else?\n  \n\n    It isn't that much annoying, I am just worried that if the head keeps flying all the time, the drive will wear sooner and might die prematurely.\n  \n\n    Thanks for any advice."},
{"Title": "Any suggestions how to save a streaming video embedded in a news site?", "Author": "u/Basics7", "Content": "There are a couple of videos I want to save from a news site, I OWN the 4K Video Downloader app, but it seems these videos are streaming or something, any downloader I try shows it's multiple bits put together? Js or streaming, something like that.\n  \n\n    But any other downloader extention or app I find that seems to address this kind of site ends up in Google as containing malware. Is there a legit app that I can use or buy to download something that's streaming?\n  \n\n    I've used a few options over the years and figured out how to download from FB, YT, \"The Hub\", almost anywhere... but this one I can't, it's \"streaming\".\n  \n\n    Any programs that are safe (free or not) that would handle this, I'd appreciate being pointed in the right direction."},
{"Title": "Why is RPM emphasized more tha data transfer rate for hard drives?", "Author": "u/Discuzting", "Content": "Hello folks novice here, I googled my question already but I found no answers.\n  \n\n    Why is RPM the focus, instead of stats like sequential/random read/write?\n  \n\n    Could I assume that hard drives with the same RPM and cache, basically performs the same?"},
{"Title": "Video and Audio URLs obtained from yt-dlp -g are downloading very slow. How to fix?", "Author": "u/CoolstarLikesHentai", "Content": "I am trying to get the original video file from a YouTube video by using the \nyt-dlp -g\n command (short for \nyt-dlp --get-url\n) to get the video URL and audio URL. I can successfully get both URLs, but when I download them it downloads very very slow (~150 kb/s). Is there any way I can speed up the download speed?"},
{"Title": "Are there some software that provides multiple download links using VPN at once?", "Author": "u/ElonTastical", "Content": "Let's say you wanna download multiple links from keep2share, but in that site it is limited by single download, you have to wait two hours before you can download another file. Is there a way to bypass this like the idea I mentioned in the title?"},
{"Title": "Backup my network pc's to my OMV Nas", "Author": "u/SbM_Yggdrassil", "Content": "Hi all, I'm at that part of my homelab journey where I've setup a bunch of fun stuff and now I'm starting to think about helpful stuff like backups.\n  \n\n    I have a raspberry pi 4 setup with open media vault and docker running various services. I would like to add one or more services (in containers if necessary) to accomplish the following:\n  \n\n\n\n\n\n    Make an image of bootdrives of my computers on a schedule\n  \n\n\n\n\n\n    save those images to the attached storage.\n  \n\n\n\n\n\n    reimaging solution for recovery\n  \n\n\n\n\n\n\n\n\n\n    Backup secondary, non-bootdrives of my computers (just copying is probably fine)\n  \n\n\n\n\n\n    I'm just wondering how to best add services and which would do it. If I should use syncthing/duplicati + something else or if there is one thing that can do it all. I'm not sure how incremental backups fit in here either but I'd like to implement that to reduce the burden of network traffic (in my home we have to use wi-fi a lot).\n  \n\n    For drive images I've used the free version of Macrium reflect before (and I've heard of acronis), but just on one of my windows pc's. I'd like to have something scheduled from the server side for centralised management.\n  \n\n    Does it make sense what I'm trying to achieve?"},
{"Title": "Feedback for backup plan", "Author": "u/DeadbeatSummer13", "Content": "My dataset is around 10-16tb. I plan on transferring my current externals to 1 big drive. I’m trying to decide if this working drive is going to be internal or external. Regardless, this will be backed up to a 2nd drive daily. Then, the 2nd drive will backup to backblaze daily. A private encryption key will be set on backblaze. Possibly down the road an off-site drive may be added to be backed up weekly and then disconnected and moved off-site.\n  \n\n    Feedback is greatly appreciated. What do you think?"},
{"Title": "Should I purchase a NAS for the data integrity features?", "Author": "u/SystemElegant2703", "Content": "Is it necessary to purchase a NAS if all I'm really interested in are the data integrity features (i.e automatic hash checking/recording, file self-healing, datascrubbing, etc.)? Currently I use MultiPar and backup my data to M-discs. However, I would like greater certainty that the hashes are accurate. For instance, I got a trojan recently and now I'm left questioning if the hundreds of files I've downloaded since my last backup have any data corruption, silent or otherwise. Since it's impossible to know without the features I listed previously, should I consider purchasing a NAS or is there a method I haven't thought of to ensure the same level of data integrity?"},
{"Title": "Help finding data by address", "Author": "u/countesscranberry", "Content": "No idea where to post this, sorry!\n  \n\n    I have a list of about 5,000 addresses. For each one, I want to know the census tract, the voting districts, the region (as defined by my city), and maybe more later on.\n  \n\n    How can I set something up where I can match my list of addresses with a list of all addresses in my state (Ohio), cross-reference all of that other data, and have all of that information spit out for each address for me?\n  \n\n    Really any way to make this process faster would be appreciated. I’ve found some files online from various government agencies but I’m not sure if they are all relevant or useful. What kind of file types am I looking for? I have some maps overlayed in Google Earth so I can look up addresses and find the information that way, but I’m not doing it one by one. I chatted with my IT guy but he’s part time and didn’t have any standout ideas at the time.\n  \n\n    Thank you!"},
{"Title": "Need advise on my Alternative 3-2-1 plan", "Author": "u/OverqualifiedTech353", "Content": "Clear & open your minds - this one's a bit of a doozie...\n  \n\n    So I've recently begun ROM collecting (might as well reveal that since my account is tied to it), and I'm faced with the best way to preserve this data, as well as use it infrequently. Currently the plan is sort of like a 2.5-2-0.5 method:\n  \n\n\n\n\n\n    Leave a copy of smaller ROM sets on my desktop SSD (non-OS), but move everything else:\n  \n\n\n\n\n\n    AND Offload collections (such as <system> handhelds) to 2 or 4TB 3.5\" HDDs depending on the collection size and keep in \"lukewarm\" storage (plug into HDD dock for small updates, otherwise keep offline) [1]\n  \n\n\n\n\n\n    AND from there, copy organized folders to accessible \nmicro SD cards\n for the various \nhandhelds\n (no power most of the time) [2a]\n  \n\n\n\n\n\n    XOR copy organized folders to \nportable HDDs\n for the various \nconsoles\n (off/idle, or online for maybe max 1khrs/yr) [2b]\n  \n\n\n\n\n\n\n\n\n\n    AND Offload copy of entire collection to a large NAS. [3]\n  \n\n\n\n\n\n\n\n\n\n    I have 6x 2TB HDDs, and 8x 4TB HDDs inherited from various places for the [1] and [3] tasks. So:\n  \n\n    [3] For NAS, I am thinking 4TBx6 (-1) = 20TB in RAID5. This would be used for other files and backups as well (that's it's own problem).\n  \n\n    [1] That leaves 2x6TB + 2x4TB = 22TB of curated backup/cold storage. Though I am thinking I leave one or both of the 4TBs for replacement drives in case of failure... so 12TB of 2TB drives.\n  \n\n    That's sufficient for 2x copies (one online [3], one offline [1]) + the 'accessible'/usable copies [2] (kind of satisfying the \"3\" and 2 in 3-2-1). The 1 is a 0.5 since it would be in another room(s), and doing a truely remote location is not really in the picture for me. Really all 3 mediums would be in different rooms, likely.\n  \n\n    My biggest concern is maintaining the 2 (well, 3) cold storage media types. Especially the microSDs, which I cannot find a definitive answer on how to maintain file integrity (seems like power on at least every year?, then somehow do a bit-by-bit rewrite?)\n  \n\n    I've read up on store type archives, and PAR2 type parity. It seems like the best solution for long-term storage for a standalone, non-RAID drive (SD or HDD), would be to create a 10% parity file for every game (zip multi-file games), particularly on the microSDs which are most prone to bit rot.\n  \n\n    I've had a lot of issues with microSDs in the past failing, so I have little faith in them. That means I would be forced to keep a per-card mirror on the NAS most likely (in place of the compressed versions for transfer convenience), and backing up any save games at least annually. But then what? Just wait until I try to access a file that fails? And what about the portable and internal HDDs? How often should I be plugging them back in and doing X?\n  \n\n    tl;dr: How do you maintain microSDs and offline HDDs, how do you validate them, how often do you clone and replace them? And otherwise what would you do differently or add?"},
{"Title": "Ripping dvd/blu-rays question for auto ripping? via bash script", "Author": "u/1michaelbrown", "Content": "I have setup a bash script to autorip so far it is working but with errors. So how would I fix the errors or do this a better way. Errors I am having\n  \nJun 17 20:24:15 markvm5 (udev-worker)[9984]: sr0: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:24:15 markvm5 (udev-worker)[9995]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:26:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] is taking longer than 56s to complete                                                      \nJun 17 20:26:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 is taking a long time                                                                                                     \nJun 17 20:28:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] timed out after 2min 56s, killing                                                          \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 killed                                                                                                                    \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] terminated by signal 9 (KILL).                                                                                                                   \nJun 17 20:41:49 markvm5 (udev-worker)[10159]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                   \nJun 17 20:52:38 markvm5 (udev-worker)[10201]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10205] is taking longer than 47s to complete                                                      \nJun 17 20:52:38 markvm5 systemd-udevd[467]: sr1: Worker [10201] processing SEQNUM=8077 is taking a long time Jun 17 20:24:15 markvm5 (udev-worker)[9984]: sr0: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:24:15 markvm5 (udev-worker)[9995]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                    \nJun 17 20:26:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] is taking longer than 56s to complete                                                      \nJun 17 20:26:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 is taking a long time                                                                                                     \nJun 17 20:28:04 markvm5 (udev-worker)[10091]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10094] timed out after 2min 56s, killing                                                          \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] processing SEQNUM=8075 killed                                                                                                                    \nJun 17 20:28:04 markvm5 systemd-udevd[467]: sr1: Worker [10091] terminated by signal 9 (KILL).                                                                                                                   \nJun 17 20:41:49 markvm5 (udev-worker)[10159]: sr1: Process '/bin/systemctl start makemkv-rip.service' failed with exit code 1.                                                                                   \nJun 17 20:52:38 markvm5 (udev-worker)[10201]: sr1: Spawned process '/bin/systemctl start makemkv-rip.service' [10205] is taking longer than 47s to complete                                                      \nJun 17 20:52:38 markvm5 systemd-udevd[467]: sr1: Worker [10201] processing SEQNUM=8077 is taking a long time \n\n    This is the process I used I setup a udev rule\n  \nSUBSYSTEM==\"block\", ENV{ID_CDROM}==\"1\", ACTION==\"change\", RUN+=\"/bin/systemctl start makemkv-rip.service\"SUBSYSTEM==\"block\", ENV{ID_CDROM}==\"1\", ACTION==\"change\", RUN+=\"/bin/systemctl start makemkv-rip.service\"\n\n    and the makemkv-rip.service at\n  \n/etc/systemd/system/makemkv-rip.service`/etc/systemd/system/makemkv-rip.service\n\n[Unit]                                                                                                                                                                                                           \nDescription=AutoRip CD on insertion                                                                                                                                                                              \n                                                                                                                                                                                                                 \n[Service]                                                                                                                                                                                                        \nType=oneshot                                                                                                                                                                                                     \nRemainAfterExit=no                                                                                                                                                                                               \nExecStart=/home/mike/autorip.sh                                                                                                                                                                                  \nExecStop=killall autorip.sh [Unit]                                                                                                                                                                                                           \nDescription=AutoRip CD on insertion                                                                                                                                                                              \n                                                                                                                                                                                                                 \n[Service]                                                                                                                                                                                                        \nType=oneshot                                                                                                                                                                                                     \nRemainAfterExit=no                                                                                                                                                                                               \nExecStart=/home/mike/autorip.sh                                                                                                                                                                                  \nExecStop=killall autorip.sh \n\n    It's weird because the script is working but still get these errors. Also need to figure out how to trigger encoding after rip. Also in my autorip script it is finding titles in ` TINFO` should it be finding them in CINFO."},
{"Title": "Extracting Subtitles from Patreon", "Author": "u/pinkwonderwall", "Content": "Is there a way to rip captions from Patreon videos? I'm talking about Patreon videos I already have access to through a paid subscription. I like to save a video's subtitles as a text file so I can ctrl+F search for a particular word and find the moment that topic is discussed. I've tried Chrome extensions, but none of them work with Patreon. I've also looked for other posts of people asking this question, and it seems like not many people are trying to do this lol. I searched Inspect and Page Source and didn't see any obvious solutions, but I'm inexperienced with that so I may be missing something."},
{"Title": "Exausted and burnt out due to caring for my data", "Author": "u/CreativeDog2024", "Content": "I have about 5TB of movies/tv shows/photos. I have 3 backups: one is my main frequently accessed HDD. Another is another HDD i keep in my drawer and the last is google drive.\n  \n\n    I'm not a programmer so idk how to verify whether there has been data loss but I make sure all the files on each are the same by using freefilesync (mac app). It takes so much time and I don't even know if the files are corrupted or not.\n  \n\n    Is there some cloud option that I can leave my data on and pay $10-15/month to forget about it, using it as a last resort if all my local backups are corrupted?\n  \n\n    I read quite a bit on this and people recommend backblaze (B2 I think, how do i even buy it?), AWS glacier and M-disks.\n  \n\n    I have no idea how to operate any of those because I don't code. I do use rclone for Gdrive though."},
{"Title": "Western Digital DC HC580 (CMR or SMR?) & DS923+", "Author": "u/sulicadiz", "Content": "I just bought a Western Digital DC HC580. I don't know an effective method to know if the drive is CMR or SMR. I have read here in the forum that I should buy a CMR hard drive to use with the NAS (I have a DS923+).\n  \n\n    Another question, before setting the NAS should I introduce all the drives I would be using?\nThe NAS have 4 slots, so I guess the first step would be to buy 4 hard drive then set up the unit. I suppose If I insert 2 drives then the other 2 I would lose data.\n  \n\n    Anyway, total noob here, please help"},
{"Title": "Need an all-in-one podcast downloader replacement for Google Podcasts", "Author": "u/justquestionsbud", "Content": "So, just found out Google Podcasts is shutting down. I loved it, because whatever podcast I wanted, I could just find it in Google Podcats, \nyoutube-dl\n the whole thing, and I don't have to worry about content for months at a time. Now that it's going...seems like the end of my podcast consumption. Any ideas? Pocket Casts doesn't seem to have a browser-based option."},
{"Title": "What Non-NAS storage would you recommend?", "Author": "u/Bloodmoonwolf", "Content": "I currently have less than 800GB across 2 clouds and my laptop. I'm hitting my storage limit on Google and looking for a safe, local option. After losing everything on an old laptop that crashed, I started doing cloud storage, which is now becoming expensive.\n  \n\n    My current laptop is an old HP and I have yet to decide between a new Windows laptop or a Chromebook. I have a Plex library I would like to expand, even bought an external DVD reader to start the library. I don't necessarily need NAS. Plugging something into the TV or my laptop would be fine when I want to watch something on Plex (which isn't very often). The same goes for when I need to do a regular backup of files. I would prefer to buy something once instead of paying a monthly subscription and to not add another constant draw on our power supply.\n  \n\n    Most of the storage is for movies/shows, photos, and PDF scans of documents from when I went paperless. I would like to add music to this once I figure out a few things.\n  \n\n    What type/size/brand of local storage would you recommend for my situation?"},
{"Title": "Best non destructive way to scan books with illustrations and photographs?", "Author": "u/green__problem", "Content": "I have a flatbed scanner and a phone with a quality camera.\n  \n\n    For text-heavy books I use the CamScanner app, and then scan the cover using my flatbed. Non destructive, very effective. For magazines and newspapers, the flatbed is usually enough, as the lack of a solid spine makes scanning with minimal wear very easy.\n  \n\n    Now comes my problem: \nI have a lot of image-heavy books that I want to scan, but I have yet to find a good method to do so.\n\n\n\n    CamScanner is horrid at dealing with illustrations and photographs. The flatbed works \nalright\n, but not great. Because I avoid breaking the book's spine, there are always visible shadows and both text and images become a little blurry when they're close to the hinge.\n  \n\n\nI'm wondering if there's an app similar to CamScanner but more appropriate for photographs? Or a different method altogether.\n\n\n\n    I know some people melt the glue keeping the spine together, scan the pages individually, and then glue everything back on. This wouldn't work for all of the books in my collection- but I have considered trying it on a handful of them. I'm just a little scared of screwing the process up.\n  \n\n    Thanks in advance."},
{"Title": "Dedup utility that FIRST finds duplicates by name/size/date, and THEN compares their content", "Author": "u/Msprg", "Content": "Hello,\n  \n\n    Let me preface with: I know there are a million posts about dedup tools already. Dedup by file content, checksum, attributes, similar photos, similar videos…\n  \n\n    Yet somehow, I failed to find any tools that would be able to first filter out the majority of files that differ in filename / date / size \nand\n \nthen\n on the results make sure that files are 100% surely duplicate by comparing their content.\n  \n\n    I've tried dupeguru, alldup, freefilesync, treesize, czkawka, I tried everything! (By voidtools that is).\n  \n\n    The point is that I'm either missing something, or that none of the tools offer the option I'm looking for.\n  \n\n    So here I am. Once again. Seeking answer to the eternal question: How do you deal with duplicates, fellow Data Hoarders?"},
{"Title": "ytarchive vs yt-dlp on video afterwards", "Author": "u/idle_cat", "Content": "On youtube, I archive livestreams of a channel. Is the live archive recording I get by using ytarchive a higher quality then the video I would get with yt-dlp that's processed afterwards? From my understanding the video goes through youtube's compression. Is the compression really strong in your opinion? I am wondering if it's worth getting the vod to save space.\n  \n\n    Side questions:\n  \n\n    Why do people put --format \"bv*+ba/b\" or something similar to get when yt-dlp already has it set to get the individual best audio and video as the default? \nhttps://github.com/yt-dlp/yt-dlp?tab=readme-ov-file#format-selection"},
{"Title": "Retire a drive after a single pending sector?", "Author": "u/Most_Mix_7505", "Content": "What would you all do?"},
{"Title": "New drives, questions about testing", "Author": "u/lilbud2000", "Content": "Yesterday I bought my first \"big\" refurb hard drives (2x12TB HGST drives, upgrade from a 2TB and 4TB drive).\n  \n\n    The current plan is to have one in my computer, and use the second as a backup with an external enclosure. Probably not the \"best\" way to do it, but it should suffice in the meantime.\n  \n\n    Currently waiting for them to ship and looking into the whole testing process in the meantime.\n  \n\n    I was wondering what would be the best way to test them, as I've read about a bunch of different ones (like smartctl, Badblocks, HD Sentinel, etc.) And it's making my head spin a bit.\n  \n\n    I guess my questions are as followed:\n  \n\n\n\n\n\n    What/how many tests need to be run on a refurb drive? I've seen some posts listing multiple long tests and others just saying a few SMART tests. Is there any general consensus?\n  \n\n\n\n\n\n    Badblocks is on Linux only, would that work on something like WSL? Or would I have to get a Linux machine/VM setup? I have a Pi 3 collecting dust, could that be used?\n  \n\n\n\n\n\n    How long would testing the drives take? I've seen that a full badblocks 4 pass run can take days or even a week of 24/7 running just for one drive. Does that sound right? I was thinking about using a secondary machine like my old Thinkpad if it was going to take a week. My desktop (where the drive will eventually end up) is in use daily, and I'd be a bit concerned about leaving it on but not killing the test accidentally.\n  \n\n\n\n\n\n    I'm a bit new to all this, only having a 2TB and 4TB drive for the past few years. Any help in making sense of all this would be appreciated."},
{"Title": "Any experience with an Oracle Sun Rack II Power Distribution Unit RMII-PDU24KVA-3-HV\nHelp", "Author": "u/Quadrix_hd", "Content": "Hi everyone,I was looking for a PDU and found an Oracle Sun Rack II Power Distribution Unit RMII-PDU24KVA-3-HV for €60 on eBay. I couldn't find much information about it online, except for some details from the manufacturer. There are no reviews or user experiences available. Has anyone used this model before, or can anyone recommend it?"},
{"Title": "Safe to buy 3 yr old HDD?", "Author": "u/Shumhow", "Content": "Found a seller online selling a 1TB laptop HDD with casing for about 15 USD. Says everything is alright with the HDD, it is from Seagate and 3 years old. I have tried looking up at how old is too old for HDD but I understand there is no definite answer for the 'use'. But would it be advisable to 'buy' one which is 3 years old? I barely have any experience with this, so please do help me out! Thank you!"},
{"Title": "Dual NAS Media Backup + Plex (a bit lost)", "Author": "u/PuzzleHeadPistion", "Content": "Hi,\n  \n\n    I'm a bit lost on how to keep all my data safe.\n  \n\n    Currently I have an old desktop, i5-4690 + ASUS H97 Pro + 16Gb RAM, with 3Tb WD Red + 6Tb IronWolf + 8Tb Barracuda drives and 2.5GbE + 1GbE interfaces. This works as my Plex server and it's where I dump files from the desktop/laptop, it's running on Windows 10 for now, but about to switch to FreeBSD or TrueNAS (or Proxmox?) with ZFS pool.\nNow I've added an Asustor AS1102TL Drivestor 2 Lite (2 bays, 1GbE) which is probably being returned for an AS1104T Drivestor 4 (4 bays, 2,5GbE). It is supposed to be a remote NAS using Wireguard, that's why I didn't care for 1GbE, but the initial backup is taking a LONG time. The price difference is only 100€ for more bays and speed (useful for full copies and full restores if needed). Here there's a 6Tb WD \"white label\" and an 8Tb Barracuda as single volumes (JBOD looks risky and can't use RAID with different drives).\n  \n\n    Part of my issue is which file transfer protocol to use. NFS? My desktop and laptop are Windows, not sure NFS works properly. FTP? Or SMB? SMB is giving me speed issues, not going over 150MBps and for some reason when cloning the 6Tb IronWolf to the 6Tb WD \"white label\" the speed sinks to 10MBps. It's copying RAW photos and videos, like thousands of 50-100Mb files mostly.\n  \n\n    Having file access sorted, what's your recommendation for file transfer/backup? Asustor Backup Plan? Paragon Backup and Recovery? Macrium Reflect? Or, since I already own SyncBackPro, just use that? This question is related to both, from my computers to the main NAS and main NAS to the Asustor.\n  \n\n    A little guidance will be much appreciated, since I want to go through this once and \"forget\". My day job is IT PM so I know my way around a computer, but by far not an expert in this area. ty"},
{"Title": "General Reminder Backups are Important", "Author": "u/TeamSylver", "Content": "Everyone here probably already knows that.\n  \n\n    I've just had all 3 drives in my desktop PC suddenly have problems.\n  \n\n    Thank god I can still read/write to the drives though. It's just god awful slow, especially during data transfers, where it will render the whole OS unusable until it's done.\n  \n\n    So that was a lot of pain and agony to temporarily move everything to the spare PC and laptops I have laying around (PC has 1tb, laptops have 1.5tb and 4.5tb).\n  \n\n    Means I now have no backups at all, since I still haven't finished setting up my work PC to be my off-site backup PC yet (it's basically manage/byo PC at my work BC it's such a small store).\n  \n\n    Annoying as well since that PC hosts my active directory and vaultwarden as well as the file server (thankfully I had a secondary active directory server set up, but no vaultwarden).\n  \n\n    Gotta love Crucial NVMes. All of them only 11 months old. Never again. 2 of 3 RMAs processed but I still gotta get data off of the third (OS drive) before I can post that.\n  \n\n    Edit: Forgot to mention they are Crucial P3 Plus 4TB NVMes"},
{"Title": "Advice on a crazy idea", "Author": "u/Arcau1", "Content": "I have seen a little N100 board with a 4x NVME hat on ali express (also comes in a N305 version)\n  \n\n    I was wondering if it was possible to maybe use the nvme > 6 sata riser cards ive seen also.\n  \n\n    So turning this into a little 24 drive beast of a nas,\n  \n\n    So brain trust of the community i ask you:\n  \n\n    Is this even possible?\n  \n\n    Would it cripple the N100?\n  \n\n    Would the speeds on the disks be just stupid slow?\n  \n\n    Has anyone tried something like this already and have any words of wisdom?\n  \n\n    TIA"},
{"Title": "Compression", "Author": "u/Void-ux", "Content": "Hey, I store a relatively small amount of media (movies and tv), and some of it I likely won't watch for decades.\nMost of it is 1080p, and I keep my fav latest TV shows in 4k. Is there any way to losslessly compress this media? From what I've heard 1080p is best in h.264, which it is. The 4k stuff could be converted to h.265 10-bit, and I have done this with HandBrake, but I'm skeptical of how lossless it is since the file size reductions are ridiculous efficient."},
{"Title": "What's the most HDD failures you've seen in a 6 month period?", "Author": "u/the_Athereon", "Content": "Genuine question. How many of you have had a year as bad as mine so far?\n  \n\n    5 failures. 1 DOA\n  \n\n    Parity 1 and 2 went in January\n  \n\n    The first Replacement Drive was DOA\n  \n\n    Data Disks 5, 8 and 11 have since failed.\n  \n\n    I've been able to recover 90% of the data through the use of my backups and catching the problem in time. But seriously. 6 drives have died on me this year. And we're only half way through the year.\n  \n\n    They're dying so frequently that I can barely afford to replace them.\n  \n\n    Now. For the details.\n  \n\n    Parity Disk 2 had a physical fault of some kind. Reallocated sector counts when from 0 to 256 in one night.\n  \n\n    Parity 1 had a controller board failure (This will be a common cause. I've figured out the problem since this happened.)\n  \n\n    Data Disk 5 kicked the bucket spectacularly. The Seek Error Rate went from 85% accurate, which is the average in my server due to how many disks are in there. To 1% in the span of 3 days. Making it infuriatingly slow to get any data off the drive but still possible.\n  \n\n    Data 8 and 11 both experienced controller board failures. Strange drop outs in connection, hang ups, read and write error flags despite no data corruption either reading or writing. Obviously I couldn't trust those drives anymore.\n  \n\n    But this thing is, only 2 of these failures are genuine faults. The other 3 are my fault.\n  \n\n    The drives that had controller board failures, at least some of them, were due to how much pressure was being put on the sata connectors when I closed the side panel. Yes, I'm serious. In any other circumstance, the Define R6 would have ample room for sata power and data cables at the rear of the case. But when you have 11 drives and all their cables back there, the thickness of the noise dampening foam presses into those cables and puts dangerous amounts of pressure on the connectors.\n  \n\n    I proved this by running read checks on the \"failing drives\" with and without the side panel on. With it off, 1 drive had errors 100% of the time. With it on, all drives showed the same errors. Errors which disappeared when I removed the side panel... SMH.\n  \n\n    So now I need to replace yet more drives, the cables and the case.\n  \n\n    My server is a bottomless money pit. It has to be."},
{"Title": "Has anyone tried a drive bigger than 16TB on an older Areca-RAID-card? (1260)", "Author": "u/flac_rules", "Content": "I have an older Areca Raid-card. The manual claims it supports very large drives with 48 bit LBA, but i also found a google cached search result from the areca site that claims the following:\n  \n\n    \"The maximum capacity of HDDs for Areca RAID controller's old version firmware supports up to 16TB capacity. From firmware version V156-20190124....\"\n  \n\n    The newest firmware for the card is older than v156, but i don't know if this quote is for a particular card or in general, I can't find a complete changelog in the site for the changelog of the card I have.\n  \n\n    So i know it is a bit of a long shot, but has anyone tried a larger than 16TB drive on a Areaca 1260-card or something of around that age? And did it work?"},
{"Title": "Best way to catalogue music", "Author": "u/Foreign_Factor4011", "Content": "I know this might not be the right community to ask this question, so if the moderators need to delete this post, go ahead.\n  \n\n    I have a lot of music on my hard drive (we're talking 1000+ songs) and I'd like to organize everything into playlists.\n  \n\n    Each .mp3 file has metadata and I have software to organize playlists. I think I'll create the folder like this:\n  \n\n\nMusic/Genre/Artist/Album/.mp3 Files\n\n\n\n    Do you think there's a better way to organize it? I did some math and there would be at least 20% artists with maybe 1 music. There's another problem: some tracks aren't even part of an album. How can I improve this, if possible? Is there a better way to do it?"},
{"Title": "How many percent is recommended to free space on HDD with btrfs under GNU/Linux ?", "Author": "u/Yukinoooo", "Content": "I want my HDD to be efficient, good performance, fast, no error messages like impossible to read folders or read mode, bad sectors... If I want to use my HDD, it's for media files like photos, videos, music..."},
{"Title": "HBA or raid card?", "Author": "u/Deep-Egg-6167", "Content": "Hello,\n  \n\n    I'm about to build another system for my movie collection.  I currently have an adaptec 3514-16 with 16x12TB drives in RAID 5.    I'm debating about the size of the drives to get next but I'm guessing I'll get 16x16TB drives in a RAID 5.1 config but I'm not 100% sure   My collection hasn't grown that much in the last 4 years so 50TB will go a long way.\n  \n\n    I've read many debates saying just get an HBA card instead of a RAID card but I've never actually seen any performance (real world statistics) comparing the two.   I'm still open to considering either one but would appreciate anyone who can point me to some real statistics vs opinion or based on what they've heard.   Your opinion may be 100% correct but I'd love some posted benchmarks."},
{"Title": "How do you keep maxview storage manager open?", "Author": "u/Deep-Egg-6167", "Content": "Hello,\n  \n\n    I like to check when a raid is building (takes a couple of days) what percent it is at.  It logs out every 15 minutes or so - any guess how to leave it logged in?"},
{"Title": "YouTube files changed", "Author": "u/clickyk2019", "Content": "I've redownloaded some videos from youtube with yt-dlp (same videos, same yt-dlp options) however when comparing (diff) the files downloaded 6 months ago with the current ones some, but not all, are different. In some cases the new size is almost half of the previous one.\n  \n\n    Does anyone knows if youtube re-encode or modify videos periodically?"},
{"Title": "School-Managed Google Account", "Author": "u/Not-The-Dark-Lord-7", "Content": "Not too sure if this is the right place for this, but I want to hoard my data, so I feel like I’m on the right track. What is the best way to deal with a school-managed google account, in terms of keeping our data? Having recently graduated, I would like to download my stuff from things like Google Drive and Google Docs, as well as maybe a few emails and Google slides. What is the best way to do this? Just manually download everything? No “download all” button anywhere? Also, given that the new institution I’m going to gives students a google account, is there any way to just migrate my stuff from the old school’s account to the new one? That would be really convenient."},
{"Title": "VHS to HDMI upscaller", "Author": "u/Point-Frosty", "Content": "Hey yall! Looking for recommendations on a box that will convert composite coming from my vcr to hdmi. I would like to upscale to 1080.\n  \n\n    I am dealing with old vhs tapes that get snowy at times. I did purchase a Kanex Pro $80 unit and it does pretty good upscaling and interlacing. Unfortunately with my snowy tapes, the unit flashes a big source menu on the screen when snow happens.\n  \n\n    Does anyone know of a 1080 upscaller that won’t flash menu’s on the screen during my capture to OBS? Thanks so much for the advice!"},
{"Title": "Power Disable HDD in QNAP NAS", "Author": "u/CartoonistNo6669", "Content": "I've not gotten either yet, but I'm struggling to figure out of this is compatible.\n  \n\n    I'm planning on getting a TS-435XeU (\nhttps://www.qnap.com/en-us/product/ts-435xeu#\n)\n  \n\n    And filling it with 4x 10TB renewed Ultrastar He10 HDD (\nhttps://a.co/d/8EcBiGu\n) in RAID5.\n  \n\n    I see that these hard drives have Power Disable, and I can't find a concrete indication on QNAP's website if the NAS supports those.\n  \n\n    Any advice here?"},
{"Title": "Ripping entire Russian Encyclopedia - viable?", "Author": "u/gulisav", "Content": "I'm not extremely tech savy, so I have some possibly silly questions.\n  \n\n    Two days ago it's been announced that Great Russian Encyclopedia has been given no funding this year at all and the encyclopedia will be discontinued. (The encyclopedia is a heir to the Great Soviet Encyclopedia, and is fairly decent as far as general encyclopedias go.) \nApparently\n Russia has bigger priorities than funding an encyclopedia... So, I think I might try my hand at saving the encyclopedia's online edition, before it 404s. Now, there are two domains, bigenc and old.bigenc (both .ru domains), and I'll focus on the latter. It seems fairly simple to rip, because each encyclopedic article has a corresponding PDF file, with the URLs only changing their final number (with 6 or 7 digits). I could produce a list of all the possible URLs in Excel. However, if I were to feed that list to a download manager, I'm wondering if that would cause any serious issues on the part of the server. There's probably close to a hundred thousand articles available on the site, and the downloader would also have to check possibly millions of URLs that contain no PDFs. Would this be like a sort of borderline DDOS attack? Could my requests be blocked?\n  \n\n    Furthermore, even if I rip all that stuff, it would result in thousands of files with nothing in particular to identify them, as the filenames are just numbers. Is there a way to derive the article titles from the text within the PDFs (which ofc include the title of the article) and rename the files accordingly?\n  \n\n    (The PDFs themselves are small in size, so I'm not worrying about space constraints.)"},
{"Title": "External, internal hard drives", "Author": "u/WriteCodeBroh", "Content": "Let’s say a friend of mine was thinking about, hypothetically of course, buying a used workstation off of Facebook marketplace. And a lot of those modern used workstations don’t have a whole lot of space for hard drives.\n  \n\n    What if this friend drilled a hole in the side of the case, ran the required power and data cables (SATA probably) out to a custom built case with a backplane and a whole bunch of hard drives?\n  \n\n    I assume there are EMI and short related risks but frankly I’ve seen people run whole computers on open wooden racks with fans blowing on the components, function just fine for years, also don’t plan to touch/move things much and they’ll be off the floor and out of the way.\n  \n\n    So anyway, all that being said, how stupid of an idea is this?"},
{"Title": "Adobe Document Cloud help", "Author": "u/MatooMan", "Content": "Looking to download local copies to my PC from the following publications, anyone able to help me find an automated way to do this? An add on or program ideally.\n  \n\n    Thanks\n  \n\n\nhttps://archives.thepipingcentre.co.uk/publications"},
{"Title": "Mini PC as NAS, good idea?", "Author": "u/smartyee", "Content": "No content"},
{"Title": "Have joined the club", "Author": "u/mdwkelly", "Content": "Good day all.\n  \n\n    Well I have joined the club and am now the proud owner of a Supermicro 45 Bay JBOD Expansion Server Shelf 847E16-RJBOD1 with ~30 drives and ~460TB. Currently have it hooked up via 2 SFF-8088 to SFF-8088 cables to a LSI 9201-16e 6Gbps 16-lane external SAS HBA installed in my \"server\".\n  \n\n    This is replacing my previous setup with the same \"server\", 2 x LSI 9201-16e 6Gbps 16-lane external SAS HBA cards with 8 x SFF-8088 to 4 SATA cables running to 8 x RSV-SATA-Cage-34 that are/were on a couple of shelves.\n  \n\n    Been up and running for about a week and thoughts so far are:\n  \n\n\n\n\n\n    It looks cool in the 4-post 42U rack\n  \n\n\n\n\n\n    It is loud! (I knew it was loud but that holy s#$% moment when you first power it up)\n  \n\n\n\n\n\n    snapraid backup/scrub is only happening at about 2/3 the speed of before (sort of knew this as well)\n  \n\n\n\n\n\n    that was a lot of screws to remove the drives from the RSV caddies and screw them into the JBOD caddies.\n  \n\n\n\n\n\n    It looks cool!\n  \n\n\n\n\n\n    As mentioned, I have it hooked up via 2 SFF-8088 to SFF-8088 cables, one for each backplane, and am wondering if I can hook up the other 2 SFF-8088 ports on the JBOD with two more cables to get some additional speed. I did read the manual it it discusses the other two ports are used for daisy-chaining but you never know.\n  \n\n    Not being one to let well enough alone, I am now on the journey to repackage my two \"servers\", one from above and the other used for acquiring linux ISO's, into a couple of 2U cases so I can get them nicely into the rack.\n  \n\n    For the latter, am thinking about a \nRackChoice MicroATX/Mini-ITX 2U Rackmount Server Chassis\n as I am running a mitx MB and a couple of 3.5 drives and a couple of SSD's with no add-on cards so should fit just nice.\n  \n\n    For the former, the \"server\" hooked to the JBOD, I am looking at this \nRackChoice 2U Rackmount Server Chassis\n as it allows full height cards to be used via PCI riser so I can keep using the HBA card I already have. The other option I am looking at is picking up a LSI SAS 9300-8e 12Gb/s SATA/SAS and a couple SFF-8644 to Mini SAS SFF-8088 cables and a 2nd \nRackChoice MicroATX/Mini-ITX 2U Rackmount Server Chassis\n but I am not sure if the SAS3 HBA is backwards compatible with SAS2 backplanes.\n  \n\n    Anyway, the adventure continues ....\n  \n\n    Thanks"},
{"Title": "Ripping dubs from dvd and adding to movies", "Author": "u/Wibble_Webble", "Content": "Hi, i want to start a project but i have no idea where to start. I have a barbie movie collection that has dubs in my native language. I found that someone has remastered these movies in HD and i have already downloaded them. The movies are however in English. I want to rip the audio track from the dvd's but just of the main movie and replace the original audio track from the remastered movies. I've already tried to rip the movie with handbreak but the mp4 file came out choppy in image and in audio. I also don't know how to replace the original audio track once i have successfully  ripped the audio from the dvd as well as sync it. I've read about using ffmpeg but i have no experience with it except for yt-dlp. If anyone can provide an incredibly dumbed down explanation, i would really appreciate it."},
{"Title": "Archiving Steam games that natively do not have DRM?", "Author": "u/Gwyn777", "Content": "Hello!\n  \n\n    I recently bought Cruelty Squad from steam. It is DRM free from the get go.\n  \n\n    What files do I need to save to archive the game?\n  \n\n    Something where I could theoretically uninstall steam, download it from my storage, then play without steam.\n  \n\n    Thank you for any help!"},
{"Title": "Retire a drive after a single pending sector?", "Author": "u/Most_Mix_7505", "Content": "What would you all do?"},
{"Title": "New drives, questions about testing", "Author": "u/lilbud2000", "Content": "Yesterday I bought my first \"big\" refurb hard drives (2x12TB HGST drives, upgrade from a 2TB and 4TB drive).\n  \n\n    The current plan is to have one in my computer, and use the second as a backup with an external enclosure. Probably not the \"best\" way to do it, but it should suffice in the meantime.\n  \n\n    Currently waiting for them to ship and looking into the whole testing process in the meantime.\n  \n\n    I was wondering what would be the best way to test them, as I've read about a bunch of different ones (like smartctl, Badblocks, HD Sentinel, etc.) And it's making my head spin a bit.\n  \n\n    I guess my questions are as followed:\n  \n\n\n\n\n\n    What/how many tests need to be run on a refurb drive? I've seen some posts listing multiple long tests and others just saying a few SMART tests. Is there any general consensus?\n  \n\n\n\n\n\n    Badblocks is on Linux only, would that work on something like WSL? Or would I have to get a Linux machine/VM setup? I have a Pi 3 collecting dust, could that be used?\n  \n\n\n\n\n\n    How long would testing the drives take? I've seen that a full badblocks 4 pass run can take days or even a week of 24/7 running just for one drive. Does that sound right? I was thinking about using a secondary machine like my old Thinkpad if it was going to take a week. My desktop (where the drive will eventually end up) is in use daily, and I'd be a bit concerned about leaving it on but not killing the test accidentally.\n  \n\n\n\n\n\n    I'm a bit new to all this, only having a 2TB and 4TB drive for the past few years. Any help in making sense of all this would be appreciated."},
{"Title": "Any experience with an Oracle Sun Rack II Power Distribution Unit RMII-PDU24KVA-3-HV\nHelp", "Author": "u/Quadrix_hd", "Content": "Hi everyone,I was looking for a PDU and found an Oracle Sun Rack II Power Distribution Unit RMII-PDU24KVA-3-HV for €60 on eBay. I couldn't find much information about it online, except for some details from the manufacturer. There are no reviews or user experiences available. Has anyone used this model before, or can anyone recommend it?"},
{"Title": "Safe to buy 3 yr old HDD?", "Author": "u/Shumhow", "Content": "Found a seller online selling a 1TB laptop HDD with casing for about 15 USD. Says everything is alright with the HDD, it is from Seagate and 3 years old. I have tried looking up at how old is too old for HDD but I understand there is no definite answer for the 'use'. But would it be advisable to 'buy' one which is 3 years old? I barely have any experience with this, so please do help me out! Thank you!"},
{"Title": "Dual NAS Media Backup + Plex (a bit lost)", "Author": "u/PuzzleHeadPistion", "Content": "Hi,\n  \n\n    I'm a bit lost on how to keep all my data safe.\n  \n\n    Currently I have an old desktop, i5-4690 + ASUS H97 Pro + 16Gb RAM, with 3Tb WD Red + 6Tb IronWolf + 8Tb Barracuda drives and 2.5GbE + 1GbE interfaces. This works as my Plex server and it's where I dump files from the desktop/laptop, it's running on Windows 10 for now, but about to switch to FreeBSD or TrueNAS (or Proxmox?) with ZFS pool.\nNow I've added an Asustor AS1102TL Drivestor 2 Lite (2 bays, 1GbE) which is probably being returned for an AS1104T Drivestor 4 (4 bays, 2,5GbE). It is supposed to be a remote NAS using Wireguard, that's why I didn't care for 1GbE, but the initial backup is taking a LONG time. The price difference is only 100€ for more bays and speed (useful for full copies and full restores if needed). Here there's a 6Tb WD \"white label\" and an 8Tb Barracuda as single volumes (JBOD looks risky and can't use RAID with different drives).\n  \n\n    Part of my issue is which file transfer protocol to use. NFS? My desktop and laptop are Windows, not sure NFS works properly. FTP? Or SMB? SMB is giving me speed issues, not going over 150MBps and for some reason when cloning the 6Tb IronWolf to the 6Tb WD \"white label\" the speed sinks to 10MBps. It's copying RAW photos and videos, like thousands of 50-100Mb files mostly.\n  \n\n    Having file access sorted, what's your recommendation for file transfer/backup? Asustor Backup Plan? Paragon Backup and Recovery? Macrium Reflect? Or, since I already own SyncBackPro, just use that? This question is related to both, from my computers to the main NAS and main NAS to the Asustor.\n  \n\n    A little guidance will be much appreciated, since I want to go through this once and \"forget\". My day job is IT PM so I know my way around a computer, but by far not an expert in this area. ty"},
{"Title": "General Reminder Backups are Important", "Author": "u/TeamSylver", "Content": "Everyone here probably already knows that.\n  \n\n    I've just had all 3 drives in my desktop PC suddenly have problems.\n  \n\n    Thank god I can still read/write to the drives though. It's just god awful slow, especially during data transfers, where it will render the whole OS unusable until it's done.\n  \n\n    So that was a lot of pain and agony to temporarily move everything to the spare PC and laptops I have laying around (PC has 1tb, laptops have 1.5tb and 4.5tb).\n  \n\n    Means I now have no backups at all, since I still haven't finished setting up my work PC to be my off-site backup PC yet (it's basically manage/byo PC at my work BC it's such a small store).\n  \n\n    Annoying as well since that PC hosts my active directory and vaultwarden as well as the file server (thankfully I had a secondary active directory server set up, but no vaultwarden).\n  \n\n    Gotta love Crucial NVMes. All of them only 11 months old. Never again. 2 of 3 RMAs processed but I still gotta get data off of the third (OS drive) before I can post that.\n  \n\n    Edit: Forgot to mention they are Crucial P3 Plus 4TB NVMes"},
{"Title": "Advice on a crazy idea", "Author": "u/Arcau1", "Content": "I have seen a little N100 board with a 4x NVME hat on ali express (also comes in a N305 version)\n  \n\n    I was wondering if it was possible to maybe use the nvme > 6 sata riser cards ive seen also.\n  \n\n    So turning this into a little 24 drive beast of a nas,\n  \n\n    So brain trust of the community i ask you:\n  \n\n    Is this even possible?\n  \n\n    Would it cripple the N100?\n  \n\n    Would the speeds on the disks be just stupid slow?\n  \n\n    Has anyone tried something like this already and have any words of wisdom?\n  \n\n    TIA"},
{"Title": "Compression", "Author": "u/Void-ux", "Content": "Hey, I store a relatively small amount of media (movies and tv), and some of it I likely won't watch for decades.\nMost of it is 1080p, and I keep my fav latest TV shows in 4k. Is there any way to losslessly compress this media? From what I've heard 1080p is best in h.264, which it is. The 4k stuff could be converted to h.265 10-bit, and I have done this with HandBrake, but I'm skeptical of how lossless it is since the file size reductions are ridiculous efficient."},
{"Title": "What's the most HDD failures you've seen in a 6 month period?", "Author": "u/the_Athereon", "Content": "Genuine question. How many of you have had a year as bad as mine so far?\n  \n\n    5 failures. 1 DOA\n  \n\n    Parity 1 and 2 went in January\n  \n\n    The first Replacement Drive was DOA\n  \n\n    Data Disks 5, 8 and 11 have since failed.\n  \n\n    I've been able to recover 90% of the data through the use of my backups and catching the problem in time. But seriously. 6 drives have died on me this year. And we're only half way through the year.\n  \n\n    They're dying so frequently that I can barely afford to replace them.\n  \n\n    Now. For the details.\n  \n\n    Parity Disk 2 had a physical fault of some kind. Reallocated sector counts when from 0 to 256 in one night.\n  \n\n    Parity 1 had a controller board failure (This will be a common cause. I've figured out the problem since this happened.)\n  \n\n    Data Disk 5 kicked the bucket spectacularly. The Seek Error Rate went from 85% accurate, which is the average in my server due to how many disks are in there. To 1% in the span of 3 days. Making it infuriatingly slow to get any data off the drive but still possible.\n  \n\n    Data 8 and 11 both experienced controller board failures. Strange drop outs in connection, hang ups, read and write error flags despite no data corruption either reading or writing. Obviously I couldn't trust those drives anymore.\n  \n\n    But this thing is, only 2 of these failures are genuine faults. The other 3 are my fault.\n  \n\n    The drives that had controller board failures, at least some of them, were due to how much pressure was being put on the sata connectors when I closed the side panel. Yes, I'm serious. In any other circumstance, the Define R6 would have ample room for sata power and data cables at the rear of the case. But when you have 11 drives and all their cables back there, the thickness of the noise dampening foam presses into those cables and puts dangerous amounts of pressure on the connectors.\n  \n\n    I proved this by running read checks on the \"failing drives\" with and without the side panel on. With it off, 1 drive had errors 100% of the time. With it on, all drives showed the same errors. Errors which disappeared when I removed the side panel... SMH.\n  \n\n    So now I need to replace yet more drives, the cables and the case.\n  \n\n    My server is a bottomless money pit. It has to be."},
{"Title": "Has anyone tried a drive bigger than 16TB on an older Areca-RAID-card? (1260)", "Author": "u/flac_rules", "Content": "I have an older Areca Raid-card. The manual claims it supports very large drives with 48 bit LBA, but i also found a google cached search result from the areca site that claims the following:\n  \n\n    \"The maximum capacity of HDDs for Areca RAID controller's old version firmware supports up to 16TB capacity. From firmware version V156-20190124....\"\n  \n\n    The newest firmware for the card is older than v156, but i don't know if this quote is for a particular card or in general, I can't find a complete changelog in the site for the changelog of the card I have.\n  \n\n    So i know it is a bit of a long shot, but has anyone tried a larger than 16TB drive on a Areaca 1260-card or something of around that age? And did it work?"},
{"Title": "Best way to catalogue music", "Author": "u/Foreign_Factor4011", "Content": "I know this might not be the right community to ask this question, so if the moderators need to delete this post, go ahead.\n  \n\n    I have a lot of music on my hard drive (we're talking 1000+ songs) and I'd like to organize everything into playlists.\n  \n\n    Each .mp3 file has metadata and I have software to organize playlists. I think I'll create the folder like this:\n  \n\n\nMusic/Genre/Artist/Album/.mp3 Files\n\n\n\n    Do you think there's a better way to organize it? I did some math and there would be at least 20% artists with maybe 1 music. There's another problem: some tracks aren't even part of an album. How can I improve this, if possible? Is there a better way to do it?"},
{"Title": "How many percent is recommended to free space on HDD with btrfs under GNU/Linux ?", "Author": "u/Yukinoooo", "Content": "I want my HDD to be efficient, good performance, fast, no error messages like impossible to read folders or read mode, bad sectors... If I want to use my HDD, it's for media files like photos, videos, music..."},
{"Title": "HBA or raid card?", "Author": "u/Deep-Egg-6167", "Content": "Hello,\n  \n\n    I'm about to build another system for my movie collection.  I currently have an adaptec 3514-16 with 16x12TB drives in RAID 5.    I'm debating about the size of the drives to get next but I'm guessing I'll get 16x16TB drives in a RAID 5.1 config but I'm not 100% sure   My collection hasn't grown that much in the last 4 years so 50TB will go a long way.\n  \n\n    I've read many debates saying just get an HBA card instead of a RAID card but I've never actually seen any performance (real world statistics) comparing the two.   I'm still open to considering either one but would appreciate anyone who can point me to some real statistics vs opinion or based on what they've heard.   Your opinion may be 100% correct but I'd love some posted benchmarks."},
{"Title": "How do you keep maxview storage manager open?", "Author": "u/Deep-Egg-6167", "Content": "Hello,\n  \n\n    I like to check when a raid is building (takes a couple of days) what percent it is at.  It logs out every 15 minutes or so - any guess how to leave it logged in?"},
{"Title": "YouTube files changed", "Author": "u/clickyk2019", "Content": "I've redownloaded some videos from youtube with yt-dlp (same videos, same yt-dlp options) however when comparing (diff) the files downloaded 6 months ago with the current ones some, but not all, are different. In some cases the new size is almost half of the previous one.\n  \n\n    Does anyone knows if youtube re-encode or modify videos periodically?"},
{"Title": "School-Managed Google Account", "Author": "u/Not-The-Dark-Lord-7", "Content": "Not too sure if this is the right place for this, but I want to hoard my data, so I feel like I’m on the right track. What is the best way to deal with a school-managed google account, in terms of keeping our data? Having recently graduated, I would like to download my stuff from things like Google Drive and Google Docs, as well as maybe a few emails and Google slides. What is the best way to do this? Just manually download everything? No “download all” button anywhere? Also, given that the new institution I’m going to gives students a google account, is there any way to just migrate my stuff from the old school’s account to the new one? That would be really convenient."},
{"Title": "VHS to HDMI upscaller", "Author": "u/Point-Frosty", "Content": "Hey yall! Looking for recommendations on a box that will convert composite coming from my vcr to hdmi. I would like to upscale to 1080.\n  \n\n    I am dealing with old vhs tapes that get snowy at times. I did purchase a Kanex Pro $80 unit and it does pretty good upscaling and interlacing. Unfortunately with my snowy tapes, the unit flashes a big source menu on the screen when snow happens.\n  \n\n    Does anyone know of a 1080 upscaller that won’t flash menu’s on the screen during my capture to OBS? Thanks so much for the advice!"},
{"Title": "Power Disable HDD in QNAP NAS", "Author": "u/CartoonistNo6669", "Content": "I've not gotten either yet, but I'm struggling to figure out of this is compatible.\n  \n\n    I'm planning on getting a TS-435XeU (\nhttps://www.qnap.com/en-us/product/ts-435xeu#\n)\n  \n\n    And filling it with 4x 10TB renewed Ultrastar He10 HDD (\nhttps://a.co/d/8EcBiGu\n) in RAID5.\n  \n\n    I see that these hard drives have Power Disable, and I can't find a concrete indication on QNAP's website if the NAS supports those.\n  \n\n    Any advice here?"},
{"Title": "Ripping entire Russian Encyclopedia - viable?", "Author": "u/gulisav", "Content": "I'm not extremely tech savy, so I have some possibly silly questions.\n  \n\n    Two days ago it's been announced that Great Russian Encyclopedia has been given no funding this year at all and the encyclopedia will be discontinued. (The encyclopedia is a heir to the Great Soviet Encyclopedia, and is fairly decent as far as general encyclopedias go.) \nApparently\n Russia has bigger priorities than funding an encyclopedia... So, I think I might try my hand at saving the encyclopedia's online edition, before it 404s. Now, there are two domains, bigenc and old.bigenc (both .ru domains), and I'll focus on the latter. It seems fairly simple to rip, because each encyclopedic article has a corresponding PDF file, with the URLs only changing their final number (with 6 or 7 digits). I could produce a list of all the possible URLs in Excel. However, if I were to feed that list to a download manager, I'm wondering if that would cause any serious issues on the part of the server. There's probably close to a hundred thousand articles available on the site, and the downloader would also have to check possibly millions of URLs that contain no PDFs. Would this be like a sort of borderline DDOS attack? Could my requests be blocked?\n  \n\n    Furthermore, even if I rip all that stuff, it would result in thousands of files with nothing in particular to identify them, as the filenames are just numbers. Is there a way to derive the article titles from the text within the PDFs (which ofc include the title of the article) and rename the files accordingly?\n  \n\n    (The PDFs themselves are small in size, so I'm not worrying about space constraints.)"},
{"Title": "External, internal hard drives", "Author": "u/WriteCodeBroh", "Content": "Let’s say a friend of mine was thinking about, hypothetically of course, buying a used workstation off of Facebook marketplace. And a lot of those modern used workstations don’t have a whole lot of space for hard drives.\n  \n\n    What if this friend drilled a hole in the side of the case, ran the required power and data cables (SATA probably) out to a custom built case with a backplane and a whole bunch of hard drives?\n  \n\n    I assume there are EMI and short related risks but frankly I’ve seen people run whole computers on open wooden racks with fans blowing on the components, function just fine for years, also don’t plan to touch/move things much and they’ll be off the floor and out of the way.\n  \n\n    So anyway, all that being said, how stupid of an idea is this?"},
{"Title": "Adobe Document Cloud help", "Author": "u/MatooMan", "Content": "Looking to download local copies to my PC from the following publications, anyone able to help me find an automated way to do this? An add on or program ideally.\n  \n\n    Thanks\n  \n\n\nhttps://archives.thepipingcentre.co.uk/publications"},
{"Title": "Mini PC as NAS, good idea?", "Author": "u/smartyee", "Content": "No content"},
{"Title": "Have joined the club", "Author": "u/mdwkelly", "Content": "Good day all.\n  \n\n    Well I have joined the club and am now the proud owner of a Supermicro 45 Bay JBOD Expansion Server Shelf 847E16-RJBOD1 with ~30 drives and ~460TB. Currently have it hooked up via 2 SFF-8088 to SFF-8088 cables to a LSI 9201-16e 6Gbps 16-lane external SAS HBA installed in my \"server\".\n  \n\n    This is replacing my previous setup with the same \"server\", 2 x LSI 9201-16e 6Gbps 16-lane external SAS HBA cards with 8 x SFF-8088 to 4 SATA cables running to 8 x RSV-SATA-Cage-34 that are/were on a couple of shelves.\n  \n\n    Been up and running for about a week and thoughts so far are:\n  \n\n\n\n\n\n    It looks cool in the 4-post 42U rack\n  \n\n\n\n\n\n    It is loud! (I knew it was loud but that holy s#$% moment when you first power it up)\n  \n\n\n\n\n\n    snapraid backup/scrub is only happening at about 2/3 the speed of before (sort of knew this as well)\n  \n\n\n\n\n\n    that was a lot of screws to remove the drives from the RSV caddies and screw them into the JBOD caddies.\n  \n\n\n\n\n\n    It looks cool!\n  \n\n\n\n\n\n    As mentioned, I have it hooked up via 2 SFF-8088 to SFF-8088 cables, one for each backplane, and am wondering if I can hook up the other 2 SFF-8088 ports on the JBOD with two more cables to get some additional speed. I did read the manual it it discusses the other two ports are used for daisy-chaining but you never know.\n  \n\n    Not being one to let well enough alone, I am now on the journey to repackage my two \"servers\", one from above and the other used for acquiring linux ISO's, into a couple of 2U cases so I can get them nicely into the rack.\n  \n\n    For the latter, am thinking about a \nRackChoice MicroATX/Mini-ITX 2U Rackmount Server Chassis\n as I am running a mitx MB and a couple of 3.5 drives and a couple of SSD's with no add-on cards so should fit just nice.\n  \n\n    For the former, the \"server\" hooked to the JBOD, I am looking at this \nRackChoice 2U Rackmount Server Chassis\n as it allows full height cards to be used via PCI riser so I can keep using the HBA card I already have. The other option I am looking at is picking up a LSI SAS 9300-8e 12Gb/s SATA/SAS and a couple SFF-8644 to Mini SAS SFF-8088 cables and a 2nd \nRackChoice MicroATX/Mini-ITX 2U Rackmount Server Chassis\n but I am not sure if the SAS3 HBA is backwards compatible with SAS2 backplanes.\n  \n\n    Anyway, the adventure continues ....\n  \n\n    Thanks"},
{"Title": "Ripping dubs from dvd and adding to movies", "Author": "u/Wibble_Webble", "Content": "Hi, i want to start a project but i have no idea where to start. I have a barbie movie collection that has dubs in my native language. I found that someone has remastered these movies in HD and i have already downloaded them. The movies are however in English. I want to rip the audio track from the dvd's but just of the main movie and replace the original audio track from the remastered movies. I've already tried to rip the movie with handbreak but the mp4 file came out choppy in image and in audio. I also don't know how to replace the original audio track once i have successfully  ripped the audio from the dvd as well as sync it. I've read about using ffmpeg but i have no experience with it except for yt-dlp. If anyone can provide an incredibly dumbed down explanation, i would really appreciate it."},
{"Title": "Archiving Steam games that natively do not have DRM?", "Author": "u/Gwyn777", "Content": "Hello!\n  \n\n    I recently bought Cruelty Squad from steam. It is DRM free from the get go.\n  \n\n    What files do I need to save to archive the game?\n  \n\n    Something where I could theoretically uninstall steam, download it from my storage, then play without steam.\n  \n\n    Thank you for any help!"},
{"Title": "What is your preferred way to archive YouTube videos?", "Author": "u/EfficiencyFine3560", "Content": "Do you just run yt-dlp on a channel and put each channel in its own folder? Do you have a more elaborate directory strcuture? Do you use archive scripts to save stuff like comments and description? Please let me know your system!"},
{"Title": "VHS to DVD/Digital", "Author": "u/Djinnimania", "Content": "For context, I dropped the ball recently by forgetting both Mother’s Day and Father’s Day until the day of. They don’t seem upset, but I want to make it up to them by converting their wedding videos from VHS to either digital, DVD, or Blu-Ray. What would be the best way to do so?"},
{"Title": "Getting a bit lost when it comes to good syncing/cloud storage options", "Author": "u/Creator13", "Content": "After using a laptop for the past six years and carrying it everywhere, I recently got a good desktop PC again. I've always played it super risky because all my data has never been properly backed up or duplicated. Now I want my files to be available between different (windows) computers. Ideally, every change would automatically get synced between both computers, through a cloud storage provider (that also stores the files for access from outside), as long as either computer is connected to the internet.\n  \n\n    Now, plenty of services offer this, in its most basic form. I get 1TB OneDrive though my parents' family plan and OneDrive is pretty nice. It integrates well enough into Windows. But there is one major limitation that makes it pretty much unsuitable for me: I don't want all my syncable data to be in one single folder. I want it spread out over different folders and even drives, because I run quite a few different drives with different purposes.\n  \n\n    Is there a service that basically offers a way to set custom endpoints for syncable folders? Say I have a cloud folder \n/Files\n, then I want a client that runs on any connected computer where I can set \n/Files\n to be synced to \nG:\\Files\n, or to \nC:\\Users\\some_user\\Documents\\CloudFiles\n on another computer?\n  \n\n    Ideally also affordable and reputable/secure of course, and for single individual users?"},
{"Title": "Android RClone app mounts remote drives with random seek support", "Author": "u/fourDnet", "Content": "Found this nifty tool recently:\nRSAF - An Android Storage Access Framework document provider for rclone\n\n\n\n    Based on rclone 1.67 (latest version). First app that I've seen for android that supports mounting arbitrary remote drives (google drive, WebDAV, SFTP) and supports streaming.\n  \n\n\nHad to manually add it to the battery optimization exclusion list on a OnePlus device (like in 3 different places, for background running, Optimize Battery Use etc.), or it would lose connection.\n\n\n\n    But after adding it to the battery exclusion list, I could reach over 280 megabits/s streaming 4K HDR video from a local linux machine!\n  \n\n    Basically added a config for WebDAV (or SFTP), added an alias to go to the specific folder, and opened that folder within the app. Was able to stream using VLC 4K HDR with very rare stutters via the local wifi."},
{"Title": "can anyone tell if this is molded or crimped molex to sata cable?", "Author": "u/KhanhEVB", "Content": "No content"},
{"Title": "What is the best way to go about cloning a 1 tb HDD with 48 bad sectors to an ssd?", "Author": "u/mudcakes2000", "Content": "I've installed aoemi backupper and ive seen there is an option to clone \"sector by sector\" however I have heard for large drives this can take hundred of hours. Will cloning the standard way work if I have some bad sectors? Or would this be detrimental? Im also not keen on doing it the sector by sector way as im worried my hard drive might fail during the long process. Does anyone have any experience with this ? Thanks"},
{"Title": "When are 30TB Seagate drives expected to become broadly a available?", "Author": "u/coffeenerd_", "Content": "Knowing that they've completed pilot tests a long time ago, are being deployed commercially, and getting mass produced...\n  \n\n    Wondering when would these 30TB Seagate drives become broadly available for us folks?\n  \n\n    Any have any real information or seeing any listings across any retailers / wholesalers?"},
{"Title": "How long for an SSD to do it's business after a long stint in cold storage?", "Author": "u/Captain_Starkiller", "Content": "I'm firing up a computer after it was offline for nearly two years. It's SSD is just a windows drive, the data storage drives are spinning rust. That said, I want to make sure the error protection has a chance to do its thing for the SSD, refill the charge traps so bit rot doesn't set in, ect. Does anyone have any idea how long I should let it run for, before turning it off again (for a month or two this time, not years) to make sure it does it's business?"},
{"Title": "files taking too much space in external hard drive?", "Author": "u/Tikas92", "Content": "Hello everyone. I have a question and I was wondering if anyone knows what's up with that. I recently transfered 3,53 TB worth of files from a 4TB Seagate to an 8TB Lacie but for some reason those files now take up 4,46 TB on the new drive. Why is that happening?"},
{"Title": "Samsung t7 PSSD android software", "Author": "u/digital_monk10010", "Content": "Hi Long time lurker first time poster\n  \n\n    My issue regards samsung portable ssd software for the portable t7 ssd. My samsung s22 is currently not supported as the app is designed for older android software. I would like to be able to access my password encrypted drive to read and write data directly from the phone Is there any workarounds?"},
{"Title": "Looking for an external HDD to backup my NAS - what drives do you recommend?", "Author": "u/kavakravata", "Content": "Hey!\n  \n\n    I have a NAS with 16TB of active storage using RAID. As a newbie, I didn’t even think about the possibility of my NAS drives failing with time, especially after reading horror stories with seagate ironwolf drives which I’m currently using.\n  \n\n    I hate SaaS and cloud, and would much prefer a local backup to my Synology NAS. What drives do you recommend? Been looking at the WD My Book 16TB or Easystore 18TB from Amazon, but I’m unsure. I don’t care about house fires / theft, so ignore that risk of backup solutions.\n  \n\n    Taking all ideas! Thank you 🥰"},
{"Title": "Hoarders with sensitive ears might want to skip Helium-filled HDDs", "Author": "u/andrebrait", "Content": "No content"},
{"Title": "Advice/Recommendation on a Personal Desktop Build with a focus on Data Storage that can also be used as a small homeserver for myself.", "Author": "u/curiousdoggo", "Content": "Goal:\n  \n\n    I know people typically separate their data storage/server/nas from their personal desktop so it can be left to do its designated tasks and so that it won't affect the performance of the desktop (if it has to serve a multitude of people or perform a lot of different tasks), but what if my server/nas needs are minimal and my primary focus is just a good personal desktop with a focus on datahoarding/data storage, some file sharing, running a few VMs, and possibly a few more server features? In this case, is it okay to just build a decently powerful modern personal desktop - killing 2 birds with 1 s tone, instead of building 2 computers, one for desktop (desperately need the upgrade now) and one specifically for a server/nas? Is this totally okay?\n  \n\n    I live by myself so aside from being a personal computer with data storage, it'll just be serving me alone at home. To be honest, at the moment, I pretty much just consume media on my desktop, so even nas/media server features like plex, jellyfins aren't even 100% necessary - though nice to have perhaps in the future.\n  \n\n\nSummary\n: Decently powerful personal desktop with a focus on datahoarding/data storage that can also perform some server side of things like running VMs, and other homelab things down the road.\n  \n\n\nOS\n: FreeBSD with ZFS + ECC Memory\n  \n\n\nCASE\n: thinking of a big case like Fractal Design Define 7 XL that is capable of holding 14-18 HDDs.\n  \n\n\nMOBO\n:\n  \n\n\nSSD\n: What's a good NVMe 2.0 ?(maybe 1TB)\n  \n\n\nCPU\n: amd or intel? what series/models would you guys recommend?\n  \n\n\nMEM\n: looking for ECC ram as the main focus will be data storage. but how much memory will I need for zfs (assuming I will fill up the whole case with 18 HDDs down the road)?\n  \n\n\nGPU\n: a gpu capable of driving maybe a LG DualUp 2560 x 2880 with a 34\" 1440p 3440×1440 ultrawide monitor. I will also be doing some photo editing with darktable, rawtherapee, etc. as well so a designated gpu that is good enough should be enough. (don't think there will be much gaming).\n  \n\n\nPSU\n: how big of a power supply? keep in mind the full capacity is 18 HDD, with dual monitor, etc.\n  \n\n\nCPU COOLER\n:\n  \n\n\nHDD\n: thinking of 18 or 20TB seagate exos (are they too loud to use in the bedroom in a personal desktop? should i go for ironwolf pro?)"},
{"Title": "New Build raid/filesystem recommendations", "Author": "u/NextRedditAccount0", "Content": "I have a new HL15 coming. I'm planning to use it for some docker for *arr, deluge, and as a NAS. I have a separate Plex server that will be accessing the files on the HL15. No plans of doing any VMs. I'm trying to figure out the best way to get good performance and some parity in case a drive fails. Yes I do have plenty of backups.\nMy current drives in my synology is 8x8TB, 1x 500GB SSD, 1x 1TB SSD in SHR2. I also have 3x 16TB drives coming.\n  \n\n    My original plan was to run unraid but I don't want to lose out on performance due to the 8x8TB are all 5400rpms.\nI'm open to running unraid or truenas or proxmox or etc. My end goal is to get as much speed as possible while being able to survive a drive failure. No future drive expansion is planned ATM but would be nice if the new solution could support it.\nAlso this will be on a 10gbps network.\n  \n\n    Thoughts?"},
{"Title": "I have nearly 30 TB on external hard drives I want to find a permanent solution to keep my data as i continue increase the amount", "Author": "u/romic007", "Content": "Like the title states i have nearly 30 TB on several external hard drives. The files vary from (videos, fILms, series, pictures, music, documents, etc.) i looking for a permanent solution to keep my data as it continues to grow.\n  \n\n    I am not very tech savy at all\n  \n\n    I have seen things about nas, Synology stuff but im not too familiar with that stuff.\n  \n\n    I have heard good things about icloud but im i bit worried since my files were LEGALLY downloaded. Im worried that they could look at my stuff.\n  \n\n    I use my external hard drives daily and would like this permanent solution to be accessible whenever and wherever i am.\n  \n\n    I use my external hard drives on. My laptop via usb port and do not have a pc.\n  \n\n    I am leaning towards icloud or something equivalent to that since i wouldn't have to use external hard drives as much as i currently am now.\n  \n\n    Im planning on using this as my main backup system with external hard drives as secondary but like i said i use these hard drives daily would icloud be the best solution for my situation?"},
{"Title": "5x3.5 tool-less drive bay prices", "Author": "u/Doodarazumas", "Content": "I'm putting together a nas and I saw several threads where people recommended these kind of 3x5.25 to 5x3.5 hard drive cages\n  \n\n\nhttps://www.amazon.com/dp/B00DWHLFMA/ref=cm_sw_r_cp_api_glt_fabc_ZJWWH4ZW3JXHXF89RMN3?_encoding=UTF8&th=1\n\n\n\n\nhttps://www.amazon.com/dp/B00DWHLFMA/ref=cm_sw_r_cp_api_glt_fabc_ZJWWH4ZW3JXHXF89RMN3?_encoding=UTF8&th=1\n\n\n\n    plus silverstone/rosewill/etc.\n  \n\n    Now most of these threads were from a few years back and since then the prices on all these things have tripled or quadrupled. Even no-name aliexpress ones I've found were about $150. Is there some secret method to finding or making something like that (5x 3.5 drives tool-less with a backplane in 3x5.25 bays) for a more reasonable $50-75 or am I just going to be a caveman with a screwdriver:\n  \n\n\nhttps://www.amazon.com/EMVANV-Stainless-5-25inch-Adapter-Bracket/dp/B0C1BQ36ML/ref=pd_ci_mcx_pspc_dp_d_2_i_1"},
{"Title": "Advice/Recommendation on a Personal Desktop Build with a focus on Data Storage that can also be used as a small homeserver for myself.", "Author": "u/zostj", "Content": "I know people typically separate their data storage/server/nas from their personal desktop so it can be left to do its designated tasks and so that it won't affect the performance of the desktop (if it has to serve a multitude of people or perform a lot of different tasks), but what if my server/nas needs are minimal and my primary focus is just a good personal desktop with a focus on datahoarding/data storage, some file sharing, running a few VMs, and possibly a few more server features? In this case, is it okay to just build a decently powerful modern personal desktop - killing 2 birds with 1 s tone, instead of building 2 computers, one for desktop (desperately need the upgrade now) and one specifically for a server/nas?  Is this totally okay?\n  \n\n    I live by myself so aside from being a personal computer with data storage, it'll just be serving me alone at home. To be honest, at the moment, I pretty much just consume media on my desktop, so even nas/media server features like plex, jellyfins aren't even 100% necessary - though nice to have perhaps in the future.\n  \n\n\nSummary\n: Decently powerful personal desktop with a focus on datahoarding/data storage that can also perform some server side of things like running VMs, and other homelab things down the road.\n  \n\n\nOS\n: FreeBSD with ZFS + ECC Memory\n  \n\n\nCASE\n:   thinking of a big case like Fractal Design Define 7 XL that is capable of holding 14-18 HDDs.\n  \n\n\nMOBO\n:\n  \n\n\nSSD\n: What's a good NVMe 2.0 ?(maybe 1TB)\n  \n\n\nCPU\n: amd or intel? what series/models would you guys recommend?\n  \n\n\nMEM\n: looking for ECC ram as the main focus will be data storage. but how much memory will I need for zfs (assuming I will fill up the whole case with 18 HDDs down the road)?\n  \n\n\nGPU\n: a gpu capable of driving maybe a LG DualUp 2560 x 2880 with a 34\" 1440p 3440×1440 ultrawide monitor. I will also be doing some photo editing with darktable, rawtherapee, etc. as well so a designated gpu that is good enough should be enough. (don't think there will be much gaming).\n  \n\n\nPSU\n: how big of a power supply? keep in mind the full capacity is 18 HDD, with dual monitor, etc.\n  \n\n\nCPU COOLER\n:\n  \n\n\nHDD\n: thinking of 18 or 20TB seagate exos (are they too loud to use in the bedroom in a personal desktop? should i go for ironwolf pro?)"},
{"Title": "For photos and videos backup, is it better to use a cloud-based storage service or buy an SSD drive?", "Author": "u/jesuisapprenant", "Content": "I got a subscription for Dropbox at around $12 per month, and I was wondering if it is worth it to just buy a 2TB SSD drive since overall the cost is much cheaper (a nice SSD with 500mb r&w is about $119 so that's 10 months of storage cost for Dropbox, so I break even at 10 months.\n  \n\n    The pros of Dropbox is that I can access it anywhere, even on my phone, and I don't have to worry about data loss or drive failure or my disk getting stolen or lost. I also won't have to carry that disk around.\n  \n\n    The pros of an external drive is that it's much cheaper and it pays for itself in 10 months. I can also transfer data in and out much faster. I also don't need internet to access my files.\n  \n\n    Which solution is better for my use case? TIA"},
{"Title": "Question about using wget to download images from Newgrounds", "Author": "u/Glen_Garrett_Gayhart", "Content": "I've got a lot of urls like this: \nhttps://www.newgrounds.com/art/view/alvinhew/annika\n where one or more images are displayed.\n  \n\n    I want to use wget to get the images on these pages that have links like this: \nhttps://art.ngfiles.com/images/49000/49087_alvinhew_annika.jpg?f1254528733\n but I'm not sure how I should configure wget to go from the first sort of url to target the second sort.\n  \n\n    I could just open all of the \nwww.newgrounds\n urls and copy the art.ngfiles urls, but that would defeat the purpose of automating it. I want to download a lot of these, and I've got a batch file that will go through them all. How should I instruct wget to look at urls of the first \nwww.newgrounds\n sort, and then download everything from urls of the second art.ngfiles sort?\n  \n\n    I don't mind if I get some extra files, like thumbnails and things, but I don't want wget spidering all over the website and potentially downloading things from pages \nother\n than the art.ngfiles links.\n  \n\n    `\n  \n\n    Thanks in advance for any help!"},
{"Title": "GM service manual archiving", "Author": "u/Betelgeuse28", "Content": "Has anyone managed to download the newer service manuals from ACDelco TDS site? I bought a 3 day access pass to the site but I've had zero luck so far. Ive tried wget, Offline Explorer, HTTrack, and Webcopy. I'm not really trying to save an 18k page manual by rightclicking and save to pdf."},
{"Title": "Any thoughts on using something lie LBRY protocol for mass decentralised data hoarding?", "Author": "u/MasterDefibrillator", "Content": "Something like it, or the LBRY protocol itself."},
{"Title": "Data Compression", "Author": "u/elgato123", "Content": "Noticed that a drive was filling up, saw it was mostly log files...49Gb of log files. Broke out the ol' 7-zip and in ultra mode, it compressed it down to 1.8Gb. Wow\n  \n\n    I am wondering if there is any better compression or if this is about as good as it will get? Either way, I'm very impressed"},
{"Title": "LSI 9650se-16ml rebuild questiom", "Author": "u/SirMeili", "Content": "I know this is an old card. I've been using it since I bought it new in 2008. I'm prepping to do a migration to trunas and a set of larger drives and an also 9305 card but until I can get some new drives I'm limping along with this old card.\n  \n\n    I currently have a RAID6 array of 9 4tb WD red drives. One degraded and it's been trying to rebuild. I'm currently running windows server 2016 essentials. I think something is causing the is to bsod while rebuilding the array. So I went into the cards bios to rebuild there.\n  \n\n    Does anyone know if the card will rebuild while I'm in the bios screen of the card? I would rather leave it there and let it rebuild.\n  \n\n    It could also be the drive is hosed and I need to buy a new one. Not sure why the drive went degraded except that we had a storm the other night and my UPSs battery apparently failed (less than 6 months old) and the server hard shutdown. The drives were unlikely to be writing anything as I don't currently write to that array. It's purely read operations.\n  \n\n    Any help would be greatly appreciated.\n  \n\n    *Btw I have backed up data to external drives, but I would still rather not lose the data as I could mount the array and make copying to the new array in trunas faster."},
{"Title": "MergerFS on top of ZFS pools with a single mirror vdev", "Author": "u/averageFOSSenjoyer", "Content": "Does a setup mentioned in the title make sense? Or are there better ways?\n  \n\n    For context:\n  \n\n    I've been running a single ZFS pool with multiple mirror vdevs, effectively raid10. The ability to expand the pool with vdevs has been great. However, I've found out that failure with a single vdev (both mirror in a vdev fails) means failure for the entire pool. I realized this is because ZFS pools stripes data by blocks.\n  \n\n    Recently I found out about MergerFS, which when writing, stripes data by files instead of blocks since it's effectively an arbitrator. External fragmentation shouldn't be an issue as I don't have insanely big files.\n  \n\n    I've seen people mentioning MergerFS with SnapRaid. Which I don't see a point to if I'm just going to mirror.\n  \n\n    I'm basically wondering if there is a better way to achieve what I want."},
{"Title": "Question re: drives in a RAID array I inherited from a relative", "Author": "u/RhetoricalAnswer-001", "Content": "Hope this is appropriate for the forum.\n  \n\n    I inherited a full height rackmount cabinet with 12 HDs. It looks like it belongs in a data center.\n  \n\n    I want to use the drives but my PC won't recognize them. Any tips on software that can \"see\" them, then wipe and reformat them?"},
{"Title": "What is your preferred way to archive YouTube videos?", "Author": "u/EfficiencyFine3560", "Content": "Do you just run yt-dlp on a channel and put each channel in its own folder? Do you have a more elaborate directory strcuture? Do you use archive scripts to save stuff like comments and description? Please let me know your system!"},
{"Title": "VHS to DVD/Digital", "Author": "u/Djinnimania", "Content": "For context, I dropped the ball recently by forgetting both Mother’s Day and Father’s Day until the day of. They don’t seem upset, but I want to make it up to them by converting their wedding videos from VHS to either digital, DVD, or Blu-Ray. What would be the best way to do so?"},
{"Title": "Getting a bit lost when it comes to good syncing/cloud storage options", "Author": "u/Creator13", "Content": "After using a laptop for the past six years and carrying it everywhere, I recently got a good desktop PC again. I've always played it super risky because all my data has never been properly backed up or duplicated. Now I want my files to be available between different (windows) computers. Ideally, every change would automatically get synced between both computers, through a cloud storage provider (that also stores the files for access from outside), as long as either computer is connected to the internet.\n  \n\n    Now, plenty of services offer this, in its most basic form. I get 1TB OneDrive though my parents' family plan and OneDrive is pretty nice. It integrates well enough into Windows. But there is one major limitation that makes it pretty much unsuitable for me: I don't want all my syncable data to be in one single folder. I want it spread out over different folders and even drives, because I run quite a few different drives with different purposes.\n  \n\n    Is there a service that basically offers a way to set custom endpoints for syncable folders? Say I have a cloud folder \n/Files\n, then I want a client that runs on any connected computer where I can set \n/Files\n to be synced to \nG:\\Files\n, or to \nC:\\Users\\some_user\\Documents\\CloudFiles\n on another computer?\n  \n\n    Ideally also affordable and reputable/secure of course, and for single individual users?"},
{"Title": "Android RClone app mounts remote drives with random seek support", "Author": "u/fourDnet", "Content": "Found this nifty tool recently:\nRSAF - An Android Storage Access Framework document provider for rclone\n\n\n\n    Based on rclone 1.67 (latest version). First app that I've seen for android that supports mounting arbitrary remote drives (google drive, WebDAV, SFTP) and supports streaming.\n  \n\n\nHad to manually add it to the battery optimization exclusion list on a OnePlus device (like in 3 different places, for background running, Optimize Battery Use etc.), or it would lose connection.\n\n\n\n    But after adding it to the battery exclusion list, I could reach over 280 megabits/s streaming 4K HDR video from a local linux machine!\n  \n\n    Basically added a config for WebDAV (or SFTP), added an alias to go to the specific folder, and opened that folder within the app. Was able to stream using VLC 4K HDR with very rare stutters via the local wifi."},
{"Title": "can anyone tell if this is molded or crimped molex to sata cable?", "Author": "u/KhanhEVB", "Content": "No content"},
{"Title": "What is the best way to go about cloning a 1 tb HDD with 48 bad sectors to an ssd?", "Author": "u/mudcakes2000", "Content": "I've installed aoemi backupper and ive seen there is an option to clone \"sector by sector\" however I have heard for large drives this can take hundred of hours. Will cloning the standard way work if I have some bad sectors? Or would this be detrimental? Im also not keen on doing it the sector by sector way as im worried my hard drive might fail during the long process. Does anyone have any experience with this ? Thanks"},
{"Title": "When are 30TB Seagate drives expected to become broadly a available?", "Author": "u/coffeenerd_", "Content": "Knowing that they've completed pilot tests a long time ago, are being deployed commercially, and getting mass produced...\n  \n\n    Wondering when would these 30TB Seagate drives become broadly available for us folks?\n  \n\n    Any have any real information or seeing any listings across any retailers / wholesalers?"},
{"Title": "How long for an SSD to do it's business after a long stint in cold storage?", "Author": "u/Captain_Starkiller", "Content": "I'm firing up a computer after it was offline for nearly two years. It's SSD is just a windows drive, the data storage drives are spinning rust. That said, I want to make sure the error protection has a chance to do its thing for the SSD, refill the charge traps so bit rot doesn't set in, ect. Does anyone have any idea how long I should let it run for, before turning it off again (for a month or two this time, not years) to make sure it does it's business?"},
{"Title": "files taking too much space in external hard drive?", "Author": "u/Tikas92", "Content": "Hello everyone. I have a question and I was wondering if anyone knows what's up with that. I recently transfered 3,53 TB worth of files from a 4TB Seagate to an 8TB Lacie but for some reason those files now take up 4,46 TB on the new drive. Why is that happening?"},
{"Title": "Samsung t7 PSSD android software", "Author": "u/digital_monk10010", "Content": "Hi Long time lurker first time poster\n  \n\n    My issue regards samsung portable ssd software for the portable t7 ssd. My samsung s22 is currently not supported as the app is designed for older android software. I would like to be able to access my password encrypted drive to read and write data directly from the phone Is there any workarounds?"},
{"Title": "Looking for an external HDD to backup my NAS - what drives do you recommend?", "Author": "u/kavakravata", "Content": "Hey!\n  \n\n    I have a NAS with 16TB of active storage using RAID. As a newbie, I didn’t even think about the possibility of my NAS drives failing with time, especially after reading horror stories with seagate ironwolf drives which I’m currently using.\n  \n\n    I hate SaaS and cloud, and would much prefer a local backup to my Synology NAS. What drives do you recommend? Been looking at the WD My Book 16TB or Easystore 18TB from Amazon, but I’m unsure. I don’t care about house fires / theft, so ignore that risk of backup solutions.\n  \n\n    Taking all ideas! Thank you 🥰"},
{"Title": "Hoarders with sensitive ears might want to skip Helium-filled HDDs", "Author": "u/andrebrait", "Content": "No content"},
{"Title": "Advice/Recommendation on a Personal Desktop Build with a focus on Data Storage that can also be used as a small homeserver for myself.", "Author": "u/curiousdoggo", "Content": "Goal:\n  \n\n    I know people typically separate their data storage/server/nas from their personal desktop so it can be left to do its designated tasks and so that it won't affect the performance of the desktop (if it has to serve a multitude of people or perform a lot of different tasks), but what if my server/nas needs are minimal and my primary focus is just a good personal desktop with a focus on datahoarding/data storage, some file sharing, running a few VMs, and possibly a few more server features? In this case, is it okay to just build a decently powerful modern personal desktop - killing 2 birds with 1 s tone, instead of building 2 computers, one for desktop (desperately need the upgrade now) and one specifically for a server/nas? Is this totally okay?\n  \n\n    I live by myself so aside from being a personal computer with data storage, it'll just be serving me alone at home. To be honest, at the moment, I pretty much just consume media on my desktop, so even nas/media server features like plex, jellyfins aren't even 100% necessary - though nice to have perhaps in the future.\n  \n\n\nSummary\n: Decently powerful personal desktop with a focus on datahoarding/data storage that can also perform some server side of things like running VMs, and other homelab things down the road.\n  \n\n\nOS\n: FreeBSD with ZFS + ECC Memory\n  \n\n\nCASE\n: thinking of a big case like Fractal Design Define 7 XL that is capable of holding 14-18 HDDs.\n  \n\n\nMOBO\n:\n  \n\n\nSSD\n: What's a good NVMe 2.0 ?(maybe 1TB)\n  \n\n\nCPU\n: amd or intel? what series/models would you guys recommend?\n  \n\n\nMEM\n: looking for ECC ram as the main focus will be data storage. but how much memory will I need for zfs (assuming I will fill up the whole case with 18 HDDs down the road)?\n  \n\n\nGPU\n: a gpu capable of driving maybe a LG DualUp 2560 x 2880 with a 34\" 1440p 3440×1440 ultrawide monitor. I will also be doing some photo editing with darktable, rawtherapee, etc. as well so a designated gpu that is good enough should be enough. (don't think there will be much gaming).\n  \n\n\nPSU\n: how big of a power supply? keep in mind the full capacity is 18 HDD, with dual monitor, etc.\n  \n\n\nCPU COOLER\n:\n  \n\n\nHDD\n: thinking of 18 or 20TB seagate exos (are they too loud to use in the bedroom in a personal desktop? should i go for ironwolf pro?)"},
{"Title": "New Build raid/filesystem recommendations", "Author": "u/NextRedditAccount0", "Content": "I have a new HL15 coming. I'm planning to use it for some docker for *arr, deluge, and as a NAS. I have a separate Plex server that will be accessing the files on the HL15. No plans of doing any VMs. I'm trying to figure out the best way to get good performance and some parity in case a drive fails. Yes I do have plenty of backups.\nMy current drives in my synology is 8x8TB, 1x 500GB SSD, 1x 1TB SSD in SHR2. I also have 3x 16TB drives coming.\n  \n\n    My original plan was to run unraid but I don't want to lose out on performance due to the 8x8TB are all 5400rpms.\nI'm open to running unraid or truenas or proxmox or etc. My end goal is to get as much speed as possible while being able to survive a drive failure. No future drive expansion is planned ATM but would be nice if the new solution could support it.\nAlso this will be on a 10gbps network.\n  \n\n    Thoughts?"},
{"Title": "I have nearly 30 TB on external hard drives I want to find a permanent solution to keep my data as i continue increase the amount", "Author": "u/romic007", "Content": "Like the title states i have nearly 30 TB on several external hard drives. The files vary from (videos, fILms, series, pictures, music, documents, etc.) i looking for a permanent solution to keep my data as it continues to grow.\n  \n\n    I am not very tech savy at all\n  \n\n    I have seen things about nas, Synology stuff but im not too familiar with that stuff.\n  \n\n    I have heard good things about icloud but im i bit worried since my files were LEGALLY downloaded. Im worried that they could look at my stuff.\n  \n\n    I use my external hard drives daily and would like this permanent solution to be accessible whenever and wherever i am.\n  \n\n    I use my external hard drives on. My laptop via usb port and do not have a pc.\n  \n\n    I am leaning towards icloud or something equivalent to that since i wouldn't have to use external hard drives as much as i currently am now.\n  \n\n    Im planning on using this as my main backup system with external hard drives as secondary but like i said i use these hard drives daily would icloud be the best solution for my situation?"},
{"Title": "5x3.5 tool-less drive bay prices", "Author": "u/Doodarazumas", "Content": "I'm putting together a nas and I saw several threads where people recommended these kind of 3x5.25 to 5x3.5 hard drive cages\n  \n\n\nhttps://www.amazon.com/dp/B00DWHLFMA/ref=cm_sw_r_cp_api_glt_fabc_ZJWWH4ZW3JXHXF89RMN3?_encoding=UTF8&th=1\n\n\n\n\nhttps://www.amazon.com/dp/B00DWHLFMA/ref=cm_sw_r_cp_api_glt_fabc_ZJWWH4ZW3JXHXF89RMN3?_encoding=UTF8&th=1\n\n\n\n    plus silverstone/rosewill/etc.\n  \n\n    Now most of these threads were from a few years back and since then the prices on all these things have tripled or quadrupled. Even no-name aliexpress ones I've found were about $150. Is there some secret method to finding or making something like that (5x 3.5 drives tool-less with a backplane in 3x5.25 bays) for a more reasonable $50-75 or am I just going to be a caveman with a screwdriver:\n  \n\n\nhttps://www.amazon.com/EMVANV-Stainless-5-25inch-Adapter-Bracket/dp/B0C1BQ36ML/ref=pd_ci_mcx_pspc_dp_d_2_i_1"},
{"Title": "Advice/Recommendation on a Personal Desktop Build with a focus on Data Storage that can also be used as a small homeserver for myself.", "Author": "u/zostj", "Content": "I know people typically separate their data storage/server/nas from their personal desktop so it can be left to do its designated tasks and so that it won't affect the performance of the desktop (if it has to serve a multitude of people or perform a lot of different tasks), but what if my server/nas needs are minimal and my primary focus is just a good personal desktop with a focus on datahoarding/data storage, some file sharing, running a few VMs, and possibly a few more server features? In this case, is it okay to just build a decently powerful modern personal desktop - killing 2 birds with 1 s tone, instead of building 2 computers, one for desktop (desperately need the upgrade now) and one specifically for a server/nas?  Is this totally okay?\n  \n\n    I live by myself so aside from being a personal computer with data storage, it'll just be serving me alone at home. To be honest, at the moment, I pretty much just consume media on my desktop, so even nas/media server features like plex, jellyfins aren't even 100% necessary - though nice to have perhaps in the future.\n  \n\n\nSummary\n: Decently powerful personal desktop with a focus on datahoarding/data storage that can also perform some server side of things like running VMs, and other homelab things down the road.\n  \n\n\nOS\n: FreeBSD with ZFS + ECC Memory\n  \n\n\nCASE\n:   thinking of a big case like Fractal Design Define 7 XL that is capable of holding 14-18 HDDs.\n  \n\n\nMOBO\n:\n  \n\n\nSSD\n: What's a good NVMe 2.0 ?(maybe 1TB)\n  \n\n\nCPU\n: amd or intel? what series/models would you guys recommend?\n  \n\n\nMEM\n: looking for ECC ram as the main focus will be data storage. but how much memory will I need for zfs (assuming I will fill up the whole case with 18 HDDs down the road)?\n  \n\n\nGPU\n: a gpu capable of driving maybe a LG DualUp 2560 x 2880 with a 34\" 1440p 3440×1440 ultrawide monitor. I will also be doing some photo editing with darktable, rawtherapee, etc. as well so a designated gpu that is good enough should be enough. (don't think there will be much gaming).\n  \n\n\nPSU\n: how big of a power supply? keep in mind the full capacity is 18 HDD, with dual monitor, etc.\n  \n\n\nCPU COOLER\n:\n  \n\n\nHDD\n: thinking of 18 or 20TB seagate exos (are they too loud to use in the bedroom in a personal desktop? should i go for ironwolf pro?)"},
{"Title": "For photos and videos backup, is it better to use a cloud-based storage service or buy an SSD drive?", "Author": "u/jesuisapprenant", "Content": "I got a subscription for Dropbox at around $12 per month, and I was wondering if it is worth it to just buy a 2TB SSD drive since overall the cost is much cheaper (a nice SSD with 500mb r&w is about $119 so that's 10 months of storage cost for Dropbox, so I break even at 10 months.\n  \n\n    The pros of Dropbox is that I can access it anywhere, even on my phone, and I don't have to worry about data loss or drive failure or my disk getting stolen or lost. I also won't have to carry that disk around.\n  \n\n    The pros of an external drive is that it's much cheaper and it pays for itself in 10 months. I can also transfer data in and out much faster. I also don't need internet to access my files.\n  \n\n    Which solution is better for my use case? TIA"},
{"Title": "Question about using wget to download images from Newgrounds", "Author": "u/Glen_Garrett_Gayhart", "Content": "I've got a lot of urls like this: \nhttps://www.newgrounds.com/art/view/alvinhew/annika\n where one or more images are displayed.\n  \n\n    I want to use wget to get the images on these pages that have links like this: \nhttps://art.ngfiles.com/images/49000/49087_alvinhew_annika.jpg?f1254528733\n but I'm not sure how I should configure wget to go from the first sort of url to target the second sort.\n  \n\n    I could just open all of the \nwww.newgrounds\n urls and copy the art.ngfiles urls, but that would defeat the purpose of automating it. I want to download a lot of these, and I've got a batch file that will go through them all. How should I instruct wget to look at urls of the first \nwww.newgrounds\n sort, and then download everything from urls of the second art.ngfiles sort?\n  \n\n    I don't mind if I get some extra files, like thumbnails and things, but I don't want wget spidering all over the website and potentially downloading things from pages \nother\n than the art.ngfiles links.\n  \n\n    `\n  \n\n    Thanks in advance for any help!"},
{"Title": "GM service manual archiving", "Author": "u/Betelgeuse28", "Content": "Has anyone managed to download the newer service manuals from ACDelco TDS site? I bought a 3 day access pass to the site but I've had zero luck so far. Ive tried wget, Offline Explorer, HTTrack, and Webcopy. I'm not really trying to save an 18k page manual by rightclicking and save to pdf."},
{"Title": "Any thoughts on using something lie LBRY protocol for mass decentralised data hoarding?", "Author": "u/MasterDefibrillator", "Content": "Something like it, or the LBRY protocol itself."},
{"Title": "Data Compression", "Author": "u/elgato123", "Content": "Noticed that a drive was filling up, saw it was mostly log files...49Gb of log files. Broke out the ol' 7-zip and in ultra mode, it compressed it down to 1.8Gb. Wow\n  \n\n    I am wondering if there is any better compression or if this is about as good as it will get? Either way, I'm very impressed"},
{"Title": "LSI 9650se-16ml rebuild questiom", "Author": "u/SirMeili", "Content": "I know this is an old card. I've been using it since I bought it new in 2008. I'm prepping to do a migration to trunas and a set of larger drives and an also 9305 card but until I can get some new drives I'm limping along with this old card.\n  \n\n    I currently have a RAID6 array of 9 4tb WD red drives. One degraded and it's been trying to rebuild. I'm currently running windows server 2016 essentials. I think something is causing the is to bsod while rebuilding the array. So I went into the cards bios to rebuild there.\n  \n\n    Does anyone know if the card will rebuild while I'm in the bios screen of the card? I would rather leave it there and let it rebuild.\n  \n\n    It could also be the drive is hosed and I need to buy a new one. Not sure why the drive went degraded except that we had a storm the other night and my UPSs battery apparently failed (less than 6 months old) and the server hard shutdown. The drives were unlikely to be writing anything as I don't currently write to that array. It's purely read operations.\n  \n\n    Any help would be greatly appreciated.\n  \n\n    *Btw I have backed up data to external drives, but I would still rather not lose the data as I could mount the array and make copying to the new array in trunas faster."},
{"Title": "MergerFS on top of ZFS pools with a single mirror vdev", "Author": "u/averageFOSSenjoyer", "Content": "Does a setup mentioned in the title make sense? Or are there better ways?\n  \n\n    For context:\n  \n\n    I've been running a single ZFS pool with multiple mirror vdevs, effectively raid10. The ability to expand the pool with vdevs has been great. However, I've found out that failure with a single vdev (both mirror in a vdev fails) means failure for the entire pool. I realized this is because ZFS pools stripes data by blocks.\n  \n\n    Recently I found out about MergerFS, which when writing, stripes data by files instead of blocks since it's effectively an arbitrator. External fragmentation shouldn't be an issue as I don't have insanely big files.\n  \n\n    I've seen people mentioning MergerFS with SnapRaid. Which I don't see a point to if I'm just going to mirror.\n  \n\n    I'm basically wondering if there is a better way to achieve what I want."},
{"Title": "Question re: drives in a RAID array I inherited from a relative", "Author": "u/RhetoricalAnswer-001", "Content": "Hope this is appropriate for the forum.\n  \n\n    I inherited a full height rackmount cabinet with 12 HDs. It looks like it belongs in a data center.\n  \n\n    I want to use the drives but my PC won't recognize them. Any tips on software that can \"see\" them, then wipe and reformat them?"},
{"Title": "HD Tune Pro Question", "Author": "u/klaaaay", "Content": "Hello, I have installed the HD Tune Pro program to see how my disk was since in the Crystal Disk Info program it shows me 69% Good in green, the disk is approximately 2 and a half or 3 years old and I wanted to confirm the information, doing the Error Scan test I have noticed that there are rectangles that remain blank, should I be worried?\n  \nhttps://preview.redd.it/hd-tune-pro-question-v0-zycqm8oomt6d1.png"},
{"Title": "A simple way to save a lot of data?", "Author": "u/Jatm4", "Content": "Hi there, I've been having a serious storage problem for a few weeks now. I used to store the media generated by my projects on individual external HDD, but this is no longer an option for me. I found a storage unit on Amazon (WD Elements 18TB) that was exactly what I needed. The problem? I bought it and it came DOA, and after seeing some comments about that device, it seems they are very unreliable, so it's no longer an option. Now I don't know how to solve my problem. I just want a drive to store my backups and where I can access them when needed, not something that needs to be constantly connected, some simple, a NAS seems a bit excessive and I wouldn't want to use a cloud. What solution do you recommend me? Did I just have bad luck with the WD Elements? I live outside the USA, so I would need something that can be purchased and shipped internationally"},
{"Title": "SATA vs SAS", "Author": "u/uberkalden2", "Content": "Genuinely confused here.  Are any of the enterprise drives SATA, or are they all SAS? They all say SATA in the description, but the details will typically also say SAS.  I was going to get a Sabrent external enclosure, but I don't think they work with SAS drives.\n  \n\n    Maybe my understanding of SATA is wrong?"},
{"Title": "Download site with login?", "Author": "u/Cyan7988", "Content": "Hello, a website is about to shutdown and there are many links that are only accessible after logging in, when downloading website with httrack it only downloads the non logged in version of thr site which I can't see the download links, how to I make it download the logged in version of thr site? I have the password and username\n  \n\n    Using HTTRACK"},
{"Title": "Any ideas for how to acquire BluRays of foreign versions of films? (Specifically, Russian Cars 2 and Planes, and Chinese Zootopia.)", "Author": "u/CtrlAltSysRq", "Content": "Up front: I don't mind paying for it. I'm not asking for help doing piracy 101 or anything.\n  \n\n    Hi fellow hoarders. I'm not sure if this is the right place to post this, but I figure this is a good place to ask fellow hoarders about what they hoard. Feel free to lmk if you think there's a better place to post this.\n  \n\n    I'm trying to archive the different versions of Disney movies that have regional differences. For example, I have the different versions of Inside Out where Riley hates either broccoli (US) or green bell peppers (Japan).\n  \n\n    Most movies only have a few variations, but Cars 2 and Planes each has about 7 variations each where the design of a car or a plane changes depending on the region. I've gotten nearly all of them, and almost all the variations of all the other movies, except for three:\n  \n\n\n\n\n\n    Chinese Zootopia (secondary newscaster is a panda)\n  \n\n\n\n\n\n    Russian Cars 2 (Car is styled as the Russian flag)\n  \n\n\n\n\n\n    Russian Planes (the \"sexy\" girl plane is styled after the Russian flag)\n  \n\n\n\n\n\n    You can probably see why I'm having trouble with these. Disney+ isn't offered in those countries for geopolitical reasons.\n  \n\n    I've scoured the internet that is available to me looking for ways to source these either physically or digitally, but even my non-public sources are not very interested in this kind of thing. So I'm reduced to looking for physical Blu-ray's of them and that is going about as well as you might expect.\n  \n\n    So I'm wondering if anyone has ideas of ways I might be able to swing this. Thanks in advance!"},
{"Title": "Long term data storage options", "Author": "u/BroccoliSanchez", "Content": "I currently have a wd 14tb desktop harddrive for my digital backups of my home media. I know consumer drives have a decent shelf life but I was wondering if there is a particular brand or type of drive I should use to back up my main drive. I plan on keeping the backup drive in a fire and flood proof safe and only powering it up to do weekly updates of new files. External options are preferred for the simplicity"},
{"Title": "Rackmount case recs with >12 bays", "Author": "u/jtscribe52", "Content": "I’ve currently maxed out my tower and have been trying to figure out a rack mount replacement that won’t break the bank. A lot of older recs point to SuperMicro cases, but those have really jumped in price the past few years. I’ve seen some other post recommending Sliger,  but I don’t see anything with more than 10 bays,  even in a 4U.\n  \n\n    Not opposed to something from AliExpress, but curious what everyone is using of late. Thanks in advance!"},
{"Title": "Cold storage backups", "Author": "u/Vatican87", "Content": "What's the best way to backup important media (Photos / Videos), are cold storage options the best way? As in do they degrade much at all if they're only spinning up every few months to backup files?"},
{"Title": "ZFS write errors on 7200 RPM drives, fine with badblocks", "Author": "u/rhnet", "Content": "I have been struggling adding 7200 RPM refurbished SATA drives (WUH721414AL) to my existing ZFS pool. The drives have no issues with badblocks, and I have tested them on another system as well.\n  \n\n    When I try to add them to an existing zfs mirror, I run into lots of WRITE/CKSUM errors, and they will eventually fault. Here's the output only 10% into a resilver.\n  \n    NAME                       STATE     READ WRITE CKSUM\n    tank                  DEGRADED     0     0     0\n      mirror-0                 DEGRADED     0     0     0\n        disk2_crypt            ONLINE       0     0     0\n        disk16_crypt           ONLINE       0     4    93  (resilvering)\n\n    And in dmesg I get stuff like:\n  \n[Sat Jun 15 12:39:59 2024] zio pool=tank vdev=/dev/mapper/disk16_crypt error=5 type=2 offset=7423255224320 size=12288 flags=1808aa\n[Sat Jun 15 12:39:59 2024] zio pool=tank vdev=/dev/mapper/disk16_crypt error=5 type=2 offset=7423255212032 size=12288 flags=1808aa\n\n    I have these attached to an HBA and SAS expander, but I've also tried with the SATA ports on the motherboard directly.\n  \n\n    Setup:\n  \n\n\n\n\n\n    LSI SAS9340-8i ServeRAID M1215 12Gbps SAS (from artofserver)\n  \n\n\n\n\n\n    Adaptec 2283400-R AEC-82885T LENOVO 36Port 12Gb/s SAS Expander Card 82885T US\n  \n\n\n\n\n\n    10Gtek# 12G Internal Mini SAS HD SFF-8643 to SFF-8643 Cable, with Sideband, 100-Ohm, 0.5-m(1.6ft), 2 Pack\n  \n\n\n\n\n\n    3x AdcAudx 2Pack SFF-8643 to SATA: 1M SFF-8643 Mini-SAS to SATA-Cable SFF8643 to SATA Mini SAS HD to SATA Forward Breakout (3.3FT)\n  \n\n\n\n\n\n    Lots of working fine 5200 RPM data drives: WD101EMAZ-11, WDC WD140EDFZ-11, WDC WD140EDGZ-11, WD80EMAZ-00W, ...\n  \n\n\n\n\n\n    Several 7200 RPM drives from Serverparts and goharddrive, all WUH721414AL.\n  \n\n    I run them with luks (cryptsetup luksFormat -c aes-xts-plain64 -s 512 -h sha256) and in zfs mirror."},
{"Title": "How do i rip a copy protected DVD?", "Author": "u/Icy-Composer9021", "Content": "I have some DVDs i wanna rip onto my computer and put on my ipod, specifically some simpsons and avp if it matters. Also region code is 2 or PAL on the simpsons."},
{"Title": "Megaraid 9271-8i Dying - How do I replace it without data loss?", "Author": "u/Barja_Bardagi", "Content": "(Cross-posting a couple places to hopefully find help)  I've got a DIY NAS that I built a number of years ago based on a Megaraid 9271-8icc. There's 8x HDD RAID-50 array on it, and a 6x SSD RAID-6 array. Well, last Sunday, the card started dying. The machine's boot drives are NOT on the raid controller, and every few reboots, the card works for a while and then craps out. So, I bought a new (used) card from eBay.\n  \n\n    Now, storage is NOT my forte. I know enough to be dangerous to myself. How do I go about replacing the failing card without losing all my data? Will the new card see data on the drives and realize \"Oh, this is part of an array\"? Do I need to try to recover some settings from the old card? Could someone explain this to me like I'm an end user? :P"},
{"Title": "Can you rename files based on metadata within the file?", "Author": "u/Elarionus", "Content": "I take photos with three different devices at work for different purposes, a Pixel, a Samsung, and an iPhone. They all name their files differently. This isn't an issue when they're all in Google Photos, but that's never their permanent home. They all add different pieces and parts to the file names. I know I could run them through a renamer to remove or add certain parts, but I was wondering if there's a software out there that lets me just dump thousands of photos into it and have it spit out filenames based on the metadata of when they were taken. YYYY-MM-DD_HH-MM-SS (Year, Month, Day, Hours, Minutes, Seconds).\n  \n\n    It would help us out a lot as we would be able to filter images in file explorer much more quickly."},
{"Title": "NEW to RAID and need help with a DIY 4 Bay", "Author": "u/FreasFrames", "Content": "I am new to the whole RAID landscape. I have been looking at the Thunderbay 4 to set up as a RAID 5 with 4x16TB HDD.\n  \n\n    the question I have is what is the most cost effective way of building one? or is it a smart idea to go with the OWC built 4x16TB so its just plug and play?\n  \n\n    Would like some help with what sites to source drives and enclosures from if OWC is not my end result\n  \n\n    Currently on a 2017 iMac Retina with 64MB DDR4 using a 3.4 GHz Quad-Core Intel i5. Running Ventura 13.6.6"},
{"Title": "Instaloader hits login wall with VPN", "Author": "u/patagonianlamb", "Content": "A few weeks back, I managed to scrape a good amount of data from Instagram using a VPN and Instaloader without even logging in. It was great! But now, whenever I try to access Instagram through a VPN, it just takes me straight to the login page. Instaloader can't bypass the login wall either. Is this the end of accessing Instagram media without logging in via a VPN?"},
{"Title": "First machine at 15 YO", "Author": "u/modestt_rat", "Content": "No content"},
{"Title": "Would you not use a certified refurbished 20tb drive for parity?", "Author": "u/NotAnADC", "Content": "Asking specifically if I should only use a drive like that for expansion and not parity, cause maybe parity sees more action. Running in unraid. I know a lot of people like and trust serverpartdeals"},
{"Title": "Backup Client From NAS", "Author": "u/FancyRectangle", "Content": "I've been using Arq 7 for quite some time at this point, and have had a Windows 2019 VM running exclusively to mount RO shares from my main NAS and backup to a couple endpoint.\n  \n\n    This has been on a physically separate box (security), but have been considering moving this VM to just be on the NAS itself and backing up from there.\n  \n\n    Does anyone else backup straight from NAS to a remote endpoint? I have a separate local NAS that pulls snapshots, but looking into some potential consolidation for a VM that needs to remain on consistently."},
{"Title": "Which CDs are legit and best for burning?", "Author": "u/Successful_Hope8909", "Content": "No content"},
{"Title": "Refurbished NAS Hard Drives… Ye or Ne?", "Author": "u/maximumkush", "Content": "Starting my first NAS to fuel my addiction. I’m starting off with RAID 5 with 3 12tb hard drives. I found some decent priced refurbished ones. Asking the pros for their honest opinion"},
{"Title": "Scribd Bypass Downloader", "Author": "u/Alive_Use_6822", "Content": "https://scribd.vdownloaders.com/\n\n\n\n    Needed to download a pdf, tried several other websites and found this one to work from another reddit user.\nJust thought ill put it out there."},
{"Title": "Samsung 8tb qvo ssd reliability", "Author": "u/ChillCaptain", "Content": "I bought the 8tb Samsung qvo ssd for a gaming/Roms drive.\n  \n\n    I know performance is meh and tbw is not great. But I don’t expect to write a lot to the drive. Copy my Roms and games once and switch out the games every so often.\n  \n\n    I’m mainly concerned with reliability. Id imagine it would be better than a spinning hard drive. Any opinions on reliability?"},
{"Title": "Can I put a 12-to-16 pin adapter inside a USB enclosure?", "Author": "u/biocoder86", "Content": "I have an old SSD drive I want to recover data from and maybe use as a portable drive going forward...\n  \n\n    Specifically I want to use this old 12 + 16 pin from an old MacBook Air (A1465), with a 12 + 16 to NVMe M key adapter.\n  \n\n\nhttps://amzn.eu/d/1gMJdGQ\n\n\n\n    Then I want to put those inside a NVMe M key to USB enclosure.\n  \n\n\nhttps://amzn.eu/d/9ifm71g\n\n\n\n    But the fourth image you scroll to of the adapter says that it cannot work in a USB enclosure, only plugged directly into the motherboard. Then in one of the user questions they seem to say the opposite with no explanation. That so long as it is 12 + 16 on one end and M key on the other it will work.\n  \n\n    So... will it work? If not, is this universally true or can I get a different adapter?"},
{"Title": "Would you return this dented 16TB hard drive?", "Author": "u/P10tr3kkk", "Content": "No content"},
{"Title": "Is there info on failure rate of SSD vs spinning HD", "Author": "u/SlothChunks", "Content": "Hi everybody, I am trying to decide whether to buy a larger capacity drive to replace my two old Samsung SSDs that are 1TB and 500gb.\n  \n\n    When I looked at Amazon I saw that there are many options of new models if standard spinning drives for much less.\n  \n\n    As far as I know from reading over the years spinning drives are more likely to fail than the spinning disk drives.  But I haven’t ever actually seen the test data to see just how likely or unlikely they are to break compared to SSD.\n  \n\n    If this drive is going to be used only at home and not carried anywhere, does anyone have any idea just how much more likely it is to fail than an SSD?\n  \n\n    Bonus: question, are WesternDigital SSDs any better or worse than Samsung? Or are there any established brands are are absolutely better to avoid?"},
{"Title": "Using Seagate ST1000DM003 1TB HDD as External Drive with USB 3.0 Enclosure", "Author": "u/Strict-Fan-6302", "Content": "Hello everyone,\n  \n\n    I'm looking to expand my storage, so I checked on eBay and found a cheap option: an \nAPPLE SEAGATE ST1000DM003 - 1TB HDD 3.5\" FUSION DRIVE - 655-1724H - 1ER162-045\n ($16). I want to use it as an external HDD, so I found two enclosures on AliExpress that look identical, but there's a small price difference of $5:\n  \n\n\n\n\n\n\nSATA to USB 3.0 Adapter Cable for 3.5/2.5 Inch SSD HDD SATA III Hard Drive Disk Converter Support UASP with 12V Power Adapter\n\n\n\n\n\n\n\n\nSATA to USB 3.0 Adapter Cable for 3.5/2.5 Inch SSD HDD SATA III Hard Drive Disk Converter Support UASP with 12V Power Adapter\n\n\n\n\n\n\n\n    I'm planning to use this with a Windows machine, not a Mac. Is that okay? Also, I want to make sure the enclosure/converter is compatible with the HDD.\n  \n\n    I'm pretty new to this, so forgive me if I said anything dumb. I'm also broke AF, so I'm trying to find the most affordable solution.\n  \n\n    Any advice or suggestions would be greatly appreciated! Thanks in advance for your help."},
{"Title": "HD Tune Pro Question", "Author": "u/klaaaay", "Content": "Hello, I have installed the HD Tune Pro program to see how my disk was since in the Crystal Disk Info program it shows me 69% Good in green, the disk is approximately 2 and a half or 3 years old and I wanted to confirm the information, doing the Error Scan test I have noticed that there are rectangles that remain blank, should I be worried?\n  \nhttps://preview.redd.it/hd-tune-pro-question-v0-zycqm8oomt6d1.png"},
{"Title": "A simple way to save a lot of data?", "Author": "u/Jatm4", "Content": "Hi there, I've been having a serious storage problem for a few weeks now. I used to store the media generated by my projects on individual external HDD, but this is no longer an option for me. I found a storage unit on Amazon (WD Elements 18TB) that was exactly what I needed. The problem? I bought it and it came DOA, and after seeing some comments about that device, it seems they are very unreliable, so it's no longer an option. Now I don't know how to solve my problem. I just want a drive to store my backups and where I can access them when needed, not something that needs to be constantly connected, some simple, a NAS seems a bit excessive and I wouldn't want to use a cloud. What solution do you recommend me? Did I just have bad luck with the WD Elements? I live outside the USA, so I would need something that can be purchased and shipped internationally"},
{"Title": "SATA vs SAS", "Author": "u/uberkalden2", "Content": "Genuinely confused here.  Are any of the enterprise drives SATA, or are they all SAS? They all say SATA in the description, but the details will typically also say SAS.  I was going to get a Sabrent external enclosure, but I don't think they work with SAS drives.\n  \n\n    Maybe my understanding of SATA is wrong?"},
{"Title": "Download site with login?", "Author": "u/Cyan7988", "Content": "Hello, a website is about to shutdown and there are many links that are only accessible after logging in, when downloading website with httrack it only downloads the non logged in version of thr site which I can't see the download links, how to I make it download the logged in version of thr site? I have the password and username\n  \n\n    Using HTTRACK"},
{"Title": "Any ideas for how to acquire BluRays of foreign versions of films? (Specifically, Russian Cars 2 and Planes, and Chinese Zootopia.)", "Author": "u/CtrlAltSysRq", "Content": "Up front: I don't mind paying for it. I'm not asking for help doing piracy 101 or anything.\n  \n\n    Hi fellow hoarders. I'm not sure if this is the right place to post this, but I figure this is a good place to ask fellow hoarders about what they hoard. Feel free to lmk if you think there's a better place to post this.\n  \n\n    I'm trying to archive the different versions of Disney movies that have regional differences. For example, I have the different versions of Inside Out where Riley hates either broccoli (US) or green bell peppers (Japan).\n  \n\n    Most movies only have a few variations, but Cars 2 and Planes each has about 7 variations each where the design of a car or a plane changes depending on the region. I've gotten nearly all of them, and almost all the variations of all the other movies, except for three:\n  \n\n\n\n\n\n    Chinese Zootopia (secondary newscaster is a panda)\n  \n\n\n\n\n\n    Russian Cars 2 (Car is styled as the Russian flag)\n  \n\n\n\n\n\n    Russian Planes (the \"sexy\" girl plane is styled after the Russian flag)\n  \n\n\n\n\n\n    You can probably see why I'm having trouble with these. Disney+ isn't offered in those countries for geopolitical reasons.\n  \n\n    I've scoured the internet that is available to me looking for ways to source these either physically or digitally, but even my non-public sources are not very interested in this kind of thing. So I'm reduced to looking for physical Blu-ray's of them and that is going about as well as you might expect.\n  \n\n    So I'm wondering if anyone has ideas of ways I might be able to swing this. Thanks in advance!"},
{"Title": "Long term data storage options", "Author": "u/BroccoliSanchez", "Content": "I currently have a wd 14tb desktop harddrive for my digital backups of my home media. I know consumer drives have a decent shelf life but I was wondering if there is a particular brand or type of drive I should use to back up my main drive. I plan on keeping the backup drive in a fire and flood proof safe and only powering it up to do weekly updates of new files. External options are preferred for the simplicity"},
{"Title": "Rackmount case recs with >12 bays", "Author": "u/jtscribe52", "Content": "I’ve currently maxed out my tower and have been trying to figure out a rack mount replacement that won’t break the bank. A lot of older recs point to SuperMicro cases, but those have really jumped in price the past few years. I’ve seen some other post recommending Sliger,  but I don’t see anything with more than 10 bays,  even in a 4U.\n  \n\n    Not opposed to something from AliExpress, but curious what everyone is using of late. Thanks in advance!"},
{"Title": "Cold storage backups", "Author": "u/Vatican87", "Content": "What's the best way to backup important media (Photos / Videos), are cold storage options the best way? As in do they degrade much at all if they're only spinning up every few months to backup files?"},
{"Title": "ZFS write errors on 7200 RPM drives, fine with badblocks", "Author": "u/rhnet", "Content": "I have been struggling adding 7200 RPM refurbished SATA drives (WUH721414AL) to my existing ZFS pool. The drives have no issues with badblocks, and I have tested them on another system as well.\n  \n\n    When I try to add them to an existing zfs mirror, I run into lots of WRITE/CKSUM errors, and they will eventually fault. Here's the output only 10% into a resilver.\n  \n    NAME                       STATE     READ WRITE CKSUM\n    tank                  DEGRADED     0     0     0\n      mirror-0                 DEGRADED     0     0     0\n        disk2_crypt            ONLINE       0     0     0\n        disk16_crypt           ONLINE       0     4    93  (resilvering)\n\n    And in dmesg I get stuff like:\n  \n[Sat Jun 15 12:39:59 2024] zio pool=tank vdev=/dev/mapper/disk16_crypt error=5 type=2 offset=7423255224320 size=12288 flags=1808aa\n[Sat Jun 15 12:39:59 2024] zio pool=tank vdev=/dev/mapper/disk16_crypt error=5 type=2 offset=7423255212032 size=12288 flags=1808aa\n\n    I have these attached to an HBA and SAS expander, but I've also tried with the SATA ports on the motherboard directly.\n  \n\n    Setup:\n  \n\n\n\n\n\n    LSI SAS9340-8i ServeRAID M1215 12Gbps SAS (from artofserver)\n  \n\n\n\n\n\n    Adaptec 2283400-R AEC-82885T LENOVO 36Port 12Gb/s SAS Expander Card 82885T US\n  \n\n\n\n\n\n    10Gtek# 12G Internal Mini SAS HD SFF-8643 to SFF-8643 Cable, with Sideband, 100-Ohm, 0.5-m(1.6ft), 2 Pack\n  \n\n\n\n\n\n    3x AdcAudx 2Pack SFF-8643 to SATA: 1M SFF-8643 Mini-SAS to SATA-Cable SFF8643 to SATA Mini SAS HD to SATA Forward Breakout (3.3FT)\n  \n\n\n\n\n\n    Lots of working fine 5200 RPM data drives: WD101EMAZ-11, WDC WD140EDFZ-11, WDC WD140EDGZ-11, WD80EMAZ-00W, ...\n  \n\n\n\n\n\n    Several 7200 RPM drives from Serverparts and goharddrive, all WUH721414AL.\n  \n\n    I run them with luks (cryptsetup luksFormat -c aes-xts-plain64 -s 512 -h sha256) and in zfs mirror."},
{"Title": "How do i rip a copy protected DVD?", "Author": "u/Icy-Composer9021", "Content": "I have some DVDs i wanna rip onto my computer and put on my ipod, specifically some simpsons and avp if it matters. Also region code is 2 or PAL on the simpsons."},
{"Title": "Megaraid 9271-8i Dying - How do I replace it without data loss?", "Author": "u/Barja_Bardagi", "Content": "(Cross-posting a couple places to hopefully find help)  I've got a DIY NAS that I built a number of years ago based on a Megaraid 9271-8icc. There's 8x HDD RAID-50 array on it, and a 6x SSD RAID-6 array. Well, last Sunday, the card started dying. The machine's boot drives are NOT on the raid controller, and every few reboots, the card works for a while and then craps out. So, I bought a new (used) card from eBay.\n  \n\n    Now, storage is NOT my forte. I know enough to be dangerous to myself. How do I go about replacing the failing card without losing all my data? Will the new card see data on the drives and realize \"Oh, this is part of an array\"? Do I need to try to recover some settings from the old card? Could someone explain this to me like I'm an end user? :P"},
{"Title": "Can you rename files based on metadata within the file?", "Author": "u/Elarionus", "Content": "I take photos with three different devices at work for different purposes, a Pixel, a Samsung, and an iPhone. They all name their files differently. This isn't an issue when they're all in Google Photos, but that's never their permanent home. They all add different pieces and parts to the file names. I know I could run them through a renamer to remove or add certain parts, but I was wondering if there's a software out there that lets me just dump thousands of photos into it and have it spit out filenames based on the metadata of when they were taken. YYYY-MM-DD_HH-MM-SS (Year, Month, Day, Hours, Minutes, Seconds).\n  \n\n    It would help us out a lot as we would be able to filter images in file explorer much more quickly."},
{"Title": "NEW to RAID and need help with a DIY 4 Bay", "Author": "u/FreasFrames", "Content": "I am new to the whole RAID landscape. I have been looking at the Thunderbay 4 to set up as a RAID 5 with 4x16TB HDD.\n  \n\n    the question I have is what is the most cost effective way of building one? or is it a smart idea to go with the OWC built 4x16TB so its just plug and play?\n  \n\n    Would like some help with what sites to source drives and enclosures from if OWC is not my end result\n  \n\n    Currently on a 2017 iMac Retina with 64MB DDR4 using a 3.4 GHz Quad-Core Intel i5. Running Ventura 13.6.6"},
{"Title": "Instaloader hits login wall with VPN", "Author": "u/patagonianlamb", "Content": "A few weeks back, I managed to scrape a good amount of data from Instagram using a VPN and Instaloader without even logging in. It was great! But now, whenever I try to access Instagram through a VPN, it just takes me straight to the login page. Instaloader can't bypass the login wall either. Is this the end of accessing Instagram media without logging in via a VPN?"},
{"Title": "First machine at 15 YO", "Author": "u/modestt_rat", "Content": "No content"},
{"Title": "Would you not use a certified refurbished 20tb drive for parity?", "Author": "u/NotAnADC", "Content": "Asking specifically if I should only use a drive like that for expansion and not parity, cause maybe parity sees more action. Running in unraid. I know a lot of people like and trust serverpartdeals"},
{"Title": "Backup Client From NAS", "Author": "u/FancyRectangle", "Content": "I've been using Arq 7 for quite some time at this point, and have had a Windows 2019 VM running exclusively to mount RO shares from my main NAS and backup to a couple endpoint.\n  \n\n    This has been on a physically separate box (security), but have been considering moving this VM to just be on the NAS itself and backing up from there.\n  \n\n    Does anyone else backup straight from NAS to a remote endpoint? I have a separate local NAS that pulls snapshots, but looking into some potential consolidation for a VM that needs to remain on consistently."},
{"Title": "Which CDs are legit and best for burning?", "Author": "u/Successful_Hope8909", "Content": "No content"},
{"Title": "Refurbished NAS Hard Drives… Ye or Ne?", "Author": "u/maximumkush", "Content": "Starting my first NAS to fuel my addiction. I’m starting off with RAID 5 with 3 12tb hard drives. I found some decent priced refurbished ones. Asking the pros for their honest opinion"},
{"Title": "Scribd Bypass Downloader", "Author": "u/Alive_Use_6822", "Content": "https://scribd.vdownloaders.com/\n\n\n\n    Needed to download a pdf, tried several other websites and found this one to work from another reddit user.\nJust thought ill put it out there."},
{"Title": "Samsung 8tb qvo ssd reliability", "Author": "u/ChillCaptain", "Content": "I bought the 8tb Samsung qvo ssd for a gaming/Roms drive.\n  \n\n    I know performance is meh and tbw is not great. But I don’t expect to write a lot to the drive. Copy my Roms and games once and switch out the games every so often.\n  \n\n    I’m mainly concerned with reliability. Id imagine it would be better than a spinning hard drive. Any opinions on reliability?"},
{"Title": "Can I put a 12-to-16 pin adapter inside a USB enclosure?", "Author": "u/biocoder86", "Content": "I have an old SSD drive I want to recover data from and maybe use as a portable drive going forward...\n  \n\n    Specifically I want to use this old 12 + 16 pin from an old MacBook Air (A1465), with a 12 + 16 to NVMe M key adapter.\n  \n\n\nhttps://amzn.eu/d/1gMJdGQ\n\n\n\n    Then I want to put those inside a NVMe M key to USB enclosure.\n  \n\n\nhttps://amzn.eu/d/9ifm71g\n\n\n\n    But the fourth image you scroll to of the adapter says that it cannot work in a USB enclosure, only plugged directly into the motherboard. Then in one of the user questions they seem to say the opposite with no explanation. That so long as it is 12 + 16 on one end and M key on the other it will work.\n  \n\n    So... will it work? If not, is this universally true or can I get a different adapter?"},
{"Title": "Would you return this dented 16TB hard drive?", "Author": "u/P10tr3kkk", "Content": "No content"},
{"Title": "Is there info on failure rate of SSD vs spinning HD", "Author": "u/SlothChunks", "Content": "Hi everybody, I am trying to decide whether to buy a larger capacity drive to replace my two old Samsung SSDs that are 1TB and 500gb.\n  \n\n    When I looked at Amazon I saw that there are many options of new models if standard spinning drives for much less.\n  \n\n    As far as I know from reading over the years spinning drives are more likely to fail than the spinning disk drives.  But I haven’t ever actually seen the test data to see just how likely or unlikely they are to break compared to SSD.\n  \n\n    If this drive is going to be used only at home and not carried anywhere, does anyone have any idea just how much more likely it is to fail than an SSD?\n  \n\n    Bonus: question, are WesternDigital SSDs any better or worse than Samsung? Or are there any established brands are are absolutely better to avoid?"},
{"Title": "Using Seagate ST1000DM003 1TB HDD as External Drive with USB 3.0 Enclosure", "Author": "u/Strict-Fan-6302", "Content": "Hello everyone,\n  \n\n    I'm looking to expand my storage, so I checked on eBay and found a cheap option: an \nAPPLE SEAGATE ST1000DM003 - 1TB HDD 3.5\" FUSION DRIVE - 655-1724H - 1ER162-045\n ($16). I want to use it as an external HDD, so I found two enclosures on AliExpress that look identical, but there's a small price difference of $5:\n  \n\n\n\n\n\n\nSATA to USB 3.0 Adapter Cable for 3.5/2.5 Inch SSD HDD SATA III Hard Drive Disk Converter Support UASP with 12V Power Adapter\n\n\n\n\n\n\n\n\nSATA to USB 3.0 Adapter Cable for 3.5/2.5 Inch SSD HDD SATA III Hard Drive Disk Converter Support UASP with 12V Power Adapter\n\n\n\n\n\n\n\n    I'm planning to use this with a Windows machine, not a Mac. Is that okay? Also, I want to make sure the enclosure/converter is compatible with the HDD.\n  \n\n    I'm pretty new to this, so forgive me if I said anything dumb. I'm also broke AF, so I'm trying to find the most affordable solution.\n  \n\n    Any advice or suggestions would be greatly appreciated! Thanks in advance for your help."},
{"Title": "Amazing piece of software: Podcast Bulk Downloader", "Author": "u/didyousayboop", "Content": "Podcast Bulk Downloader is a Windows program (written by \nu/cnovel\n) that allows you to batch download episodes of a podcast simply by copy/pasting in a link to the RSS feed.\n  \n\n    There is an option to automatically append the release dates of the episodes as a prefix to the file names.\n  \n\n    Download it on GitHub \nhere\n."},
{"Title": "Something about sorting media that is really bugging me", "Author": "u/kyne_ahnung", "Content": "This is one of those questions where I don't know if I'm doing it wrong or so many other people are, but I can't work out why it's so hard to find a way to go through a big directory of videos or images in a gallery/viewer manually and easily say this one should go in folder A, that one in B, this one in D, that one in A; without having to - for each file - close the gallery (memorizing the filename), find it in the current directory among thousands of others, also find the destination and open that in another window, copy/move/drag the file to the destination.\n  \n\n    What I'm looking for:\n  \n\n\n\n\n\n    A video and image gallery\n  \n\n\n\n\n\n    Some kind of sidebar with shortcuts to favourited/saved paths\n  \n\n\n\n\n\n    The ability to easily move the image or video that I am currently viewing to one of these shortcuts either via drag or clicking move>move to>shortcut to folder A\n  \n\n\n\n\n\n    Am I crazy/stupid or is it unneccessarily hard to do this task in an ergonomic way? I have all my photos and videos sent and received on my phone over the years to sort through... deleting is no problem, finding duplicates is easy but how do people actually do the organizing? Any methods, software suggestions welcome.\n  \n\n     \n  \n\n    Edit: or another plausible method is being able to easily apply a tag to each file from the viewer, so you watch a video and can quickly click on or type a tag.."},
{"Title": "I upsized from a Fractal Design Node 804 into a Meshify 2 XL!", "Author": "u/shockguard", "Content": "No content"},
{"Title": "my friend doesn't understand... help me understand why", "Author": "u/npcwaifu", "Content": "So this really close friend of mine has been bugging me for a while, sayin i need to \"clean-up my drive\" and that I'm a hoarder.\n  \n\n    I know I am but i feel their takes are too extreme, always sayin i need to delete everything off my drive, like i was cleaning a room.\n  \n\n    I don't understand this thought process, as if drives weren't meant to store information? My computer has only one drive and for a while we were sharing it, wich makes sense to clean-up since the pc will run better, but like i said they are always takin it to the extreme: Delete all my old pictures, old project files, sample libraries. Why do you need those? Do you even use those files? They say\n  \n\n    I was talking to my girlfriend about this wondering about this mentality.\n  \n\n    Maybe it's an age thing, i said, since she understands me but me and her are both older than my friend. Maybe it's the cloud storage mentality of this last decade, having all your memories and information stored in a corporations server, social media etc. A local storage paradigm is not as common it seems.\n  \n\n    I'm an artist and my girlfriend is too so we are really attuned to the idea of personal archiving. She said, maybe its because your friend isn't really in tune with the act of creation in this time of their life. I found that kinda sad. Maybe it's an age thing again i thought, meaning when you are younger you are not as interested in preserving memories/information. I know it was like that for me.\n  \n\n    Help me understand."},
{"Title": "Which SATA Ssd should I buy in 2024?", "Author": "u/eliosferre3", "Content": "Hi! I need it to be a sata ssd, I recently bought a Crucial MX500 which failed while I was installing Windows and wasn't able to detect again. Now I'm thinking on a 1TB Samsung 870 Evo, but reading some posts in this subreddit apparently it has a high failure rate as well? I thought Samsung would be reliable but I don't know what to expect or buy anymore."},
{"Title": "almost entirely geoblocked youtube videos?", "Author": "u/koalahugthekoala", "Content": "hi! so i have some important videos that are related to my special interest but have been geoblocked outside kosovo, somaliland, and northern cyprus. i know they still exist so what tool would i use to get them?\n  \n\n    i have no idea how github or anything works so that kinda rules out youtubedl unless someone did it for me. they are not on the wayback machine.\n  \n\n    here's the links if this helps you! \nhttps://youtube.com/watch?v=b7TYi0FwR1M\n \nhttps://youtube.com/watch?v=xmKYxwXox5g\n \nhttps://youtube.com/watch?v=AJr9VOCe1yY\n \nhttps://youtube.com/watch?v=FMLjygFXB7w\n \nhttps://youtube.com/watch?v=ZhLJyHxRuu8\n \nhttps://youtube.com/watch?v=mHU6dS07cZQ\n \nhttps://youtube.com/watch?v=Z6S5klRoI_c\n \nhttps://youtube.com/watch?v=AVeE9NMfAxE\n thank u for any help!"},
{"Title": "Recommended temporary external drives?", "Author": "u/DisasterSpinach", "Content": "I might not be asking in the right place because my goal isn't to set up something that is highly systematic or robust at this time.\n  \n\n    The place I'm renting has serious roof issues and a bunch of my stuff was water damaged. I'm trying to salvage what I can to some portable drives and get the most important belongings out as soon as I can.\n  \n\n    In the past I remember Easystores/WD Elements being popular here, but apparently they have different drives inside now or high failure rates or something?\n  \n\n    And then I was just going to go with whatever Costco carried, but at this time that's only the doomed Sandisk SSDs.\n  \n\n    Anyone have any recommendations? Doesn't have to be perfect, just reasonably priced.\n  \n\n    Just looking to buy two drives for about $300-500 total. I guess HDDs preferred if they are decently reliable and not SMR.\n  \n\n    EDIT: OK externals are all apparently crap? \nhttps://www.reddit.com/r/DataHoarder/comments/146hb9k/information_about_cmr_to_smr_manufacturer/\n\n\n\n    Maybe I'll just roll the dice on those Sandisk SSDs.."},
{"Title": "Quick question about IDM", "Author": "u/redskies1991", "Content": "Can i save my download location to an external drive (external ssd) ? Does it work.. coz i want to lessen the \"rebuilding\" time when i download large file sizes.."},
{"Title": "How to Download a Video off of Europeana?", "Author": "u/thxdley", "Content": "Sorry, i dunno if this belongs here but i dont know where else to put it. I'm pretty sure Europeana embeds the videos or something (i have no clue how any of it works) but when i try downloading the video it gives me a \"raw.html\"  which my computer wont download. Is it impossible to get my hands on this? I dont want to screen record it because of background noise/low quality/lag. Below is the link to the video im trying to download on Europeana.\n  \n\n\nhttps://www.europeana.eu/item/2051918/data_euscreenXL_EUS_0BCE32473CEBA87D2DB36A87B5511130"},
{"Title": "Personal NAS OS: Debian/Ubuntu vs TrueNAS or Rockstor", "Author": "u/PuzzleHeadPistion", "Content": "I have a personal NAS built on a i5-4690 with 16Gb RAM, which I use for archived work files (music, photos and videos), backups from my computers and as Plex Server. Services like ownCloud or something that would allow me to share files via url (like a personal WeTransfer) would be extremely useful. Maybe a system with ZFS would be good.\n  \n\n    I'm trying to decide whether to build from scratch on a full OS (Debian, Ubuntu or even Windows 2022?) vs something like TrueNAS or Rockstor. I haven't used Linux in almost 10y, but I used to use Arch.\n  \n\n    Not sure if it's relevant, but I also own an Asustor Drivestor 2 Lite and a ZenWifi XT9 router with a drive attached, use WireGuard VPN, etc."},
{"Title": "Equipment recommendations", "Author": "u/Broke_Bearded_Guy", "Content": "I was looking at buying a storage drawer preferably a 4U 60bay. I've seen some of the newer HGST units available but I've seen some posts about requiring proprietary drives I didn't know if anyone could make a recommendation my only real requirement is 120v compatible"},
{"Title": "just wondering if others with IDM also have this problem", "Author": "u/Street_Mine_1969", "Content": "for the last 3 days my IDM pop up download bar does not show on youtube and youtube only. other other video site is still okay and can download without problem. anyone else with IDM have this problem with youtube?"},
{"Title": "Internet Archive Forced to Remove 500,000 books Due to Copyright Lawsuit", "Author": "u/Run_the_Line", "Content": "No content"},
{"Title": "how do you batch select on czkawka?", "Author": "u/randomusername11222", "Content": "there is this select windows\n  \nhttps://preview.redd.it/how-do-you-batch-select-on-czkawka-v0-u0bmvpoaim6d1.png\n\n    But I cant like multiselect the files that I want manually?"},
{"Title": "Has anyone else ever experienced this? 20TB Exos white label results in my ssd activity spiking to 100% and boot issues", "Author": "u/good4y0u", "Content": "I recently purchased a 20TB Exos white label drive from eBay, which was advertised as a Seagate refurbished drive. The serial numbers do trace back to Seagate, but I'm experiencing some unusual issues with it. Has anyone else encountered this?\n  \n\n    Here's what's happening when I test it with my Windows machine:\n  \n\n\n\n\n\n    With the machine powered off, I plug in the drive, but the machine doesn't boot.\n  \n\n\n\n\n\n    With the machine powered off, I boot to BIOS, and the disk is found. However, after rebooting, the machine doesn't boot.\n  \n\n\n\n\n\n    If I unplug the drive after step 2, the machine boots normally.\n  \n\n\n\n\n\n    If I plug the drive back in at the login screen, the machine freezes.\n  \n\n\n\n\n\n    If I log in first and then plug the drive in, I can see the task manager showing max activity on my main OS SSD before the machine freezes. Unplugging the drive at this point unfreezes the machine.\n  \n\n\n\n\n\n    I've bought a number of drives this way before and never had a serious issue. Any insights or suggestions would be greatly appreciated. In the meantime I am reaching out to the seller. The other drive I got seems to work fine."},
{"Title": "Does anyone know the IBM TS3500 Tape Library (IBM 3592 JC/JY)?", "Author": "u/_c0der", "Content": "Hi all,\n  \n\n    does anyone know the IBM TS3500 Tape Library with the corresponding IBM 3592 JC/JY type drives and tapes?\n  \n\n    I can have a full rack for free - where is the catch? Is it worth it?\n  \n\n    Power and space isn't an issue.\n  \n\n    Pictures: \nhttps://imgur.com/a/mjwmvI6"},
{"Title": "YouTube seems to be blocking accounts that are used with yt-dlp (by passing cookies)", "Author": "u/BowzasaurusRex", "Content": "No content"},
{"Title": "[HDD] 14TB Refreshed WD Ultrastar Hard Drive w/ 5 Year Warranty - $99.99 (NewEgg)", "Author": "u/Axodique", "Content": "No content"},
{"Title": "G-technology 6tb fair used price? Reliability for Family Backup?", "Author": "u/myfacenotmyaccount", "Content": "Some guy near me has a couple of these for $90 each, I was thinking to buy a couple to back up all my families data and pictures, wondering if it was a good idea?\n  \n\n\nhttps://www.amazon.com/G-Technology-Thunderbolt-High-Performance-Solution-0G04023/dp/B00QJJ5362?th=1"},
{"Title": "I have a bunch of hard drives laying around that I want to access at once instead of swapping around SATA-USB cables. Does a DAS fit my use case?", "Author": "u/Stock-Belt-8470", "Content": "I'm awfully \"casual\" about hoarding data so I don't have any sort of fancy setup at home. I just have a laptop and a box full of labelled 2.5 HDDs I've collected and swap around whenever I need to access them, but have noted the existence of NAS, DAS, and servers. I don't have too much of a budget to blow, so I was looking into some options such as \"racks\" (which I've learned definitely need a server or some tower for me to invest in) or DIY options for making something similar by myself which I'm not confident about. For example, I was confused for a while and thought bays were something you could connect just a power cord and USB for, but actually need to be connected as a network or hardware component.\n  \n\n    I've looked into a DAS and they seem to be closer to what I want but I still wonder if any of this is all overkill for my use. I don't currently hold anything important on my drives at the moment and really use them to organize games and archives with the important stuff being backed up elsewhere. I just have a few USB enclosures, so the idea of having a box to set down and connect whenever I want to swap around data sounds nice, but given this isn't something I would leave plugged in all the time (I'm not at my computer often), I don't know if there are some caveats and considerations I'm missing out on. It's especially the case that I don't know if I need future-proofing as all of my drives are 2.5 and I don't see myself buying a 3.5 large-size drive anytime soon (in which I do have a separate 3.5 reader for a 300gb drive I rarely use).\n  \n\n    So is the option there for me to get something I could easily plug-and-play into a device by USB? Or is it a pipe dream and something I should consider when I have a static setup like with a tower? I see all sorts of things from searching eBay and Amazon when it comes to enclosures but I'd like some more insight from you knowledgeable folks."},
{"Title": "how to download videos from just for fans?", "Author": "u/m300n", "Content": "hi, i was wondering if anyone here knows how to save videos from just for fans?"},
{"Title": "Regarding Uloz.to", "Author": "u/HakimOne", "Content": "Hi,\n  \n\n    Any thoughts on \nhttps://ulozto.net\n ? Their plans look too good to be true. 10 TB for 6 EURO, 50 TB for only 15 EURO. Rclone recently added \nUloz.to\n support."},
{"Title": "Shucking an old WD My Book?", "Author": "u/EdiblePwncakes", "Content": "I have this really old WD MyBook that I'm trying to backup the data off of. However the drive doesn't seem to spin at all even though the enclosure is powered on. It's a very old model, so much so that I can't quite find much info on it through a search online - its model is WD5000P302.\n  \n\n    I want to shuck it in hopes of preserving the data - however I've heard that these old WD MyBooks have some sort of drive encryption that might prevent this? Does anyone have any experience with this? The drive must be at least 10 years old if I were to guess.\n  \n\n    Or if the drive doesn't spin at all then might it be completely dead? Thanks for any advice.\n  \nhttps://preview.redd.it/shucking-an-old-wd-my-book-v0-hyto1szn9l6d1.jpg\nhttps://preview.redd.it/shucking-an-old-wd-my-book-v0-sr1olvho9l6d1.jpg"},
{"Title": "I finally migrated off my old Drobo! What's the bottom line wit SoftRaid? Do I need to pay for the premium license?", "Author": "u/Splitsurround", "Content": "So against ALL odds I did get all my data safely off a dying Drobo, onto a High Point 4 bay enclosure with four 16Tb drives. I made it Raid 5 using Softeraid's trial, and so far, so good.\n  \n\n    I'm trying to wrap my head around paying for the SoftRaid premium or not: I've read all the FAQs and as far as I can tell, the only things I can't do without premium is create new raids and use their monitoring feature.\n  \n\n    I understand about the new volume thing but...if I \ndon't\n upgrade to premium, since I won't be able to use their monitoring, how will I know when a disk is dying or is dead?"},
{"Title": "Data management approach", "Author": "u/nlj1978", "Content": "Narrowing down my approach and looking for some additional guidance. Complete novice to home server operation.  After discussion in another thread, I've decided to not go with Windows OS on the server and instead run a Linux based OS so some sort.\n  \n\n    My hardware is a i5-9500 with 8gb or ram. In terms of storage I have a 256gb m2 NVME, 2x 10tb HDD and a 256g 2.5\" SSD if it is useful in some way. This leaves me with 2 sata3 ports(1 if I use the 2.5\" SSD) and 1 m2 slot available for further expansion of storage.\n  \n\n    Initial intended uses are to run JellyFin media server, Home Assistant and an image management app for pics, all local.\n  \n\n    I would like full redundancy via raid1, this is where I'm a bit uncertain on approach.\n  \n\n    I assume I'll run the OS and any apps on the NVME, not the HDD. Since i have the additional NVME slot available is there benefit to adding a second NVME drive for cache or even a mirror of the OS and apps?\n  \n\n    Should I be looking to manage my raid with an application of some sort or in the Debian OS itself?\n  \n\n    If the raid is setup in Debian, how does that affect future expansion? Do i have to add pairs of drives or could I for example just add a 18tb random drive?\n  \n\n    If for example a year from now I add 2 additional drives, at that time would there be a better solution than raid1?\n  \n\n    Thanks for your time."},
{"Title": "Amazing piece of software: Podcast Bulk Downloader", "Author": "u/didyousayboop", "Content": "Podcast Bulk Downloader is a Windows program (written by \nu/cnovel\n) that allows you to batch download episodes of a podcast simply by copy/pasting in a link to the RSS feed.\n  \n\n    There is an option to automatically append the release dates of the episodes as a prefix to the file names.\n  \n\n    Download it on GitHub \nhere\n."},
{"Title": "Something about sorting media that is really bugging me", "Author": "u/kyne_ahnung", "Content": "This is one of those questions where I don't know if I'm doing it wrong or so many other people are, but I can't work out why it's so hard to find a way to go through a big directory of videos or images in a gallery/viewer manually and easily say this one should go in folder A, that one in B, this one in D, that one in A; without having to - for each file - close the gallery (memorizing the filename), find it in the current directory among thousands of others, also find the destination and open that in another window, copy/move/drag the file to the destination.\n  \n\n    What I'm looking for:\n  \n\n\n\n\n\n    A video and image gallery\n  \n\n\n\n\n\n    Some kind of sidebar with shortcuts to favourited/saved paths\n  \n\n\n\n\n\n    The ability to easily move the image or video that I am currently viewing to one of these shortcuts either via drag or clicking move>move to>shortcut to folder A\n  \n\n\n\n\n\n    Am I crazy/stupid or is it unneccessarily hard to do this task in an ergonomic way? I have all my photos and videos sent and received on my phone over the years to sort through... deleting is no problem, finding duplicates is easy but how do people actually do the organizing? Any methods, software suggestions welcome.\n  \n\n     \n  \n\n    Edit: or another plausible method is being able to easily apply a tag to each file from the viewer, so you watch a video and can quickly click on or type a tag.."},
{"Title": "I upsized from a Fractal Design Node 804 into a Meshify 2 XL!", "Author": "u/shockguard", "Content": "No content"},
{"Title": "my friend doesn't understand... help me understand why", "Author": "u/npcwaifu", "Content": "So this really close friend of mine has been bugging me for a while, sayin i need to \"clean-up my drive\" and that I'm a hoarder.\n  \n\n    I know I am but i feel their takes are too extreme, always sayin i need to delete everything off my drive, like i was cleaning a room.\n  \n\n    I don't understand this thought process, as if drives weren't meant to store information? My computer has only one drive and for a while we were sharing it, wich makes sense to clean-up since the pc will run better, but like i said they are always takin it to the extreme: Delete all my old pictures, old project files, sample libraries. Why do you need those? Do you even use those files? They say\n  \n\n    I was talking to my girlfriend about this wondering about this mentality.\n  \n\n    Maybe it's an age thing, i said, since she understands me but me and her are both older than my friend. Maybe it's the cloud storage mentality of this last decade, having all your memories and information stored in a corporations server, social media etc. A local storage paradigm is not as common it seems.\n  \n\n    I'm an artist and my girlfriend is too so we are really attuned to the idea of personal archiving. She said, maybe its because your friend isn't really in tune with the act of creation in this time of their life. I found that kinda sad. Maybe it's an age thing again i thought, meaning when you are younger you are not as interested in preserving memories/information. I know it was like that for me.\n  \n\n    Help me understand."},
{"Title": "Which SATA Ssd should I buy in 2024?", "Author": "u/eliosferre3", "Content": "Hi! I need it to be a sata ssd, I recently bought a Crucial MX500 which failed while I was installing Windows and wasn't able to detect again. Now I'm thinking on a 1TB Samsung 870 Evo, but reading some posts in this subreddit apparently it has a high failure rate as well? I thought Samsung would be reliable but I don't know what to expect or buy anymore."},
{"Title": "almost entirely geoblocked youtube videos?", "Author": "u/koalahugthekoala", "Content": "hi! so i have some important videos that are related to my special interest but have been geoblocked outside kosovo, somaliland, and northern cyprus. i know they still exist so what tool would i use to get them?\n  \n\n    i have no idea how github or anything works so that kinda rules out youtubedl unless someone did it for me. they are not on the wayback machine.\n  \n\n    here's the links if this helps you! \nhttps://youtube.com/watch?v=b7TYi0FwR1M\n \nhttps://youtube.com/watch?v=xmKYxwXox5g\n \nhttps://youtube.com/watch?v=AJr9VOCe1yY\n \nhttps://youtube.com/watch?v=FMLjygFXB7w\n \nhttps://youtube.com/watch?v=ZhLJyHxRuu8\n \nhttps://youtube.com/watch?v=mHU6dS07cZQ\n \nhttps://youtube.com/watch?v=Z6S5klRoI_c\n \nhttps://youtube.com/watch?v=AVeE9NMfAxE\n thank u for any help!"},
{"Title": "Recommended temporary external drives?", "Author": "u/DisasterSpinach", "Content": "I might not be asking in the right place because my goal isn't to set up something that is highly systematic or robust at this time.\n  \n\n    The place I'm renting has serious roof issues and a bunch of my stuff was water damaged. I'm trying to salvage what I can to some portable drives and get the most important belongings out as soon as I can.\n  \n\n    In the past I remember Easystores/WD Elements being popular here, but apparently they have different drives inside now or high failure rates or something?\n  \n\n    And then I was just going to go with whatever Costco carried, but at this time that's only the doomed Sandisk SSDs.\n  \n\n    Anyone have any recommendations? Doesn't have to be perfect, just reasonably priced.\n  \n\n    Just looking to buy two drives for about $300-500 total. I guess HDDs preferred if they are decently reliable and not SMR.\n  \n\n    EDIT: OK externals are all apparently crap? \nhttps://www.reddit.com/r/DataHoarder/comments/146hb9k/information_about_cmr_to_smr_manufacturer/\n\n\n\n    Maybe I'll just roll the dice on those Sandisk SSDs.."},
{"Title": "Quick question about IDM", "Author": "u/redskies1991", "Content": "Can i save my download location to an external drive (external ssd) ? Does it work.. coz i want to lessen the \"rebuilding\" time when i download large file sizes.."},
{"Title": "How to Download a Video off of Europeana?", "Author": "u/thxdley", "Content": "Sorry, i dunno if this belongs here but i dont know where else to put it. I'm pretty sure Europeana embeds the videos or something (i have no clue how any of it works) but when i try downloading the video it gives me a \"raw.html\"  which my computer wont download. Is it impossible to get my hands on this? I dont want to screen record it because of background noise/low quality/lag. Below is the link to the video im trying to download on Europeana.\n  \n\n\nhttps://www.europeana.eu/item/2051918/data_euscreenXL_EUS_0BCE32473CEBA87D2DB36A87B5511130"},
{"Title": "Personal NAS OS: Debian/Ubuntu vs TrueNAS or Rockstor", "Author": "u/PuzzleHeadPistion", "Content": "I have a personal NAS built on a i5-4690 with 16Gb RAM, which I use for archived work files (music, photos and videos), backups from my computers and as Plex Server. Services like ownCloud or something that would allow me to share files via url (like a personal WeTransfer) would be extremely useful. Maybe a system with ZFS would be good.\n  \n\n    I'm trying to decide whether to build from scratch on a full OS (Debian, Ubuntu or even Windows 2022?) vs something like TrueNAS or Rockstor. I haven't used Linux in almost 10y, but I used to use Arch.\n  \n\n    Not sure if it's relevant, but I also own an Asustor Drivestor 2 Lite and a ZenWifi XT9 router with a drive attached, use WireGuard VPN, etc."},
{"Title": "Equipment recommendations", "Author": "u/Broke_Bearded_Guy", "Content": "I was looking at buying a storage drawer preferably a 4U 60bay. I've seen some of the newer HGST units available but I've seen some posts about requiring proprietary drives I didn't know if anyone could make a recommendation my only real requirement is 120v compatible"},
{"Title": "just wondering if others with IDM also have this problem", "Author": "u/Street_Mine_1969", "Content": "for the last 3 days my IDM pop up download bar does not show on youtube and youtube only. other other video site is still okay and can download without problem. anyone else with IDM have this problem with youtube?"},
{"Title": "Internet Archive Forced to Remove 500,000 books Due to Copyright Lawsuit", "Author": "u/Run_the_Line", "Content": "No content"},
{"Title": "how do you batch select on czkawka?", "Author": "u/randomusername11222", "Content": "there is this select windows\n  \nhttps://preview.redd.it/how-do-you-batch-select-on-czkawka-v0-u0bmvpoaim6d1.png\n\n    But I cant like multiselect the files that I want manually?"},
{"Title": "Has anyone else ever experienced this? 20TB Exos white label results in my ssd activity spiking to 100% and boot issues", "Author": "u/good4y0u", "Content": "I recently purchased a 20TB Exos white label drive from eBay, which was advertised as a Seagate refurbished drive. The serial numbers do trace back to Seagate, but I'm experiencing some unusual issues with it. Has anyone else encountered this?\n  \n\n    Here's what's happening when I test it with my Windows machine:\n  \n\n\n\n\n\n    With the machine powered off, I plug in the drive, but the machine doesn't boot.\n  \n\n\n\n\n\n    With the machine powered off, I boot to BIOS, and the disk is found. However, after rebooting, the machine doesn't boot.\n  \n\n\n\n\n\n    If I unplug the drive after step 2, the machine boots normally.\n  \n\n\n\n\n\n    If I plug the drive back in at the login screen, the machine freezes.\n  \n\n\n\n\n\n    If I log in first and then plug the drive in, I can see the task manager showing max activity on my main OS SSD before the machine freezes. Unplugging the drive at this point unfreezes the machine.\n  \n\n\n\n\n\n    I've bought a number of drives this way before and never had a serious issue. Any insights or suggestions would be greatly appreciated. In the meantime I am reaching out to the seller. The other drive I got seems to work fine."},
{"Title": "Does anyone know the IBM TS3500 Tape Library (IBM 3592 JC/JY)?", "Author": "u/_c0der", "Content": "Hi all,\n  \n\n    does anyone know the IBM TS3500 Tape Library with the corresponding IBM 3592 JC/JY type drives and tapes?\n  \n\n    I can have a full rack for free - where is the catch? Is it worth it?\n  \n\n    Power and space isn't an issue.\n  \n\n    Pictures: \nhttps://imgur.com/a/mjwmvI6"},
{"Title": "YouTube seems to be blocking accounts that are used with yt-dlp (by passing cookies)", "Author": "u/BowzasaurusRex", "Content": "No content"},
{"Title": "[HDD] 14TB Refreshed WD Ultrastar Hard Drive w/ 5 Year Warranty - $99.99 (NewEgg)", "Author": "u/Axodique", "Content": "No content"},
{"Title": "G-technology 6tb fair used price? Reliability for Family Backup?", "Author": "u/myfacenotmyaccount", "Content": "Some guy near me has a couple of these for $90 each, I was thinking to buy a couple to back up all my families data and pictures, wondering if it was a good idea?\n  \n\n\nhttps://www.amazon.com/G-Technology-Thunderbolt-High-Performance-Solution-0G04023/dp/B00QJJ5362?th=1"},
{"Title": "I have a bunch of hard drives laying around that I want to access at once instead of swapping around SATA-USB cables. Does a DAS fit my use case?", "Author": "u/Stock-Belt-8470", "Content": "I'm awfully \"casual\" about hoarding data so I don't have any sort of fancy setup at home. I just have a laptop and a box full of labelled 2.5 HDDs I've collected and swap around whenever I need to access them, but have noted the existence of NAS, DAS, and servers. I don't have too much of a budget to blow, so I was looking into some options such as \"racks\" (which I've learned definitely need a server or some tower for me to invest in) or DIY options for making something similar by myself which I'm not confident about. For example, I was confused for a while and thought bays were something you could connect just a power cord and USB for, but actually need to be connected as a network or hardware component.\n  \n\n    I've looked into a DAS and they seem to be closer to what I want but I still wonder if any of this is all overkill for my use. I don't currently hold anything important on my drives at the moment and really use them to organize games and archives with the important stuff being backed up elsewhere. I just have a few USB enclosures, so the idea of having a box to set down and connect whenever I want to swap around data sounds nice, but given this isn't something I would leave plugged in all the time (I'm not at my computer often), I don't know if there are some caveats and considerations I'm missing out on. It's especially the case that I don't know if I need future-proofing as all of my drives are 2.5 and I don't see myself buying a 3.5 large-size drive anytime soon (in which I do have a separate 3.5 reader for a 300gb drive I rarely use).\n  \n\n    So is the option there for me to get something I could easily plug-and-play into a device by USB? Or is it a pipe dream and something I should consider when I have a static setup like with a tower? I see all sorts of things from searching eBay and Amazon when it comes to enclosures but I'd like some more insight from you knowledgeable folks."},
{"Title": "how to download videos from just for fans?", "Author": "u/m300n", "Content": "hi, i was wondering if anyone here knows how to save videos from just for fans?"},
{"Title": "Regarding Uloz.to", "Author": "u/HakimOne", "Content": "Hi,\n  \n\n    Any thoughts on \nhttps://ulozto.net\n ? Their plans look too good to be true. 10 TB for 6 EURO, 50 TB for only 15 EURO. Rclone recently added \nUloz.to\n support."},
{"Title": "Shucking an old WD My Book?", "Author": "u/EdiblePwncakes", "Content": "I have this really old WD MyBook that I'm trying to backup the data off of. However the drive doesn't seem to spin at all even though the enclosure is powered on. It's a very old model, so much so that I can't quite find much info on it through a search online - its model is WD5000P302.\n  \n\n    I want to shuck it in hopes of preserving the data - however I've heard that these old WD MyBooks have some sort of drive encryption that might prevent this? Does anyone have any experience with this? The drive must be at least 10 years old if I were to guess.\n  \n\n    Or if the drive doesn't spin at all then might it be completely dead? Thanks for any advice.\n  \nhttps://preview.redd.it/shucking-an-old-wd-my-book-v0-hyto1szn9l6d1.jpg\nhttps://preview.redd.it/shucking-an-old-wd-my-book-v0-sr1olvho9l6d1.jpg"},
{"Title": "I finally migrated off my old Drobo! What's the bottom line wit SoftRaid? Do I need to pay for the premium license?", "Author": "u/Splitsurround", "Content": "So against ALL odds I did get all my data safely off a dying Drobo, onto a High Point 4 bay enclosure with four 16Tb drives. I made it Raid 5 using Softeraid's trial, and so far, so good.\n  \n\n    I'm trying to wrap my head around paying for the SoftRaid premium or not: I've read all the FAQs and as far as I can tell, the only things I can't do without premium is create new raids and use their monitoring feature.\n  \n\n    I understand about the new volume thing but...if I \ndon't\n upgrade to premium, since I won't be able to use their monitoring, how will I know when a disk is dying or is dead?"},
{"Title": "Data management approach", "Author": "u/nlj1978", "Content": "Narrowing down my approach and looking for some additional guidance. Complete novice to home server operation.  After discussion in another thread, I've decided to not go with Windows OS on the server and instead run a Linux based OS so some sort.\n  \n\n    My hardware is a i5-9500 with 8gb or ram. In terms of storage I have a 256gb m2 NVME, 2x 10tb HDD and a 256g 2.5\" SSD if it is useful in some way. This leaves me with 2 sata3 ports(1 if I use the 2.5\" SSD) and 1 m2 slot available for further expansion of storage.\n  \n\n    Initial intended uses are to run JellyFin media server, Home Assistant and an image management app for pics, all local.\n  \n\n    I would like full redundancy via raid1, this is where I'm a bit uncertain on approach.\n  \n\n    I assume I'll run the OS and any apps on the NVME, not the HDD. Since i have the additional NVME slot available is there benefit to adding a second NVME drive for cache or even a mirror of the OS and apps?\n  \n\n    Should I be looking to manage my raid with an application of some sort or in the Debian OS itself?\n  \n\n    If the raid is setup in Debian, how does that affect future expansion? Do i have to add pairs of drives or could I for example just add a 18tb random drive?\n  \n\n    If for example a year from now I add 2 additional drives, at that time would there be a better solution than raid1?\n  \n\n    Thanks for your time."},
{"Title": "I know iCloud is not considered a backup but..", "Author": "u/askinghawking", "Content": "I know iCloud is more considered as a sync service but do you think I can use it as a backup how I do it?\n  \n\n    I have a Mac that is only a backup tool. Means that I get all photos and documents to the Mac + iCloud there from my iphone - with a different iCloud account. So it couldn‘t happen that I delete a picture from my phone and is deleted everywhere.\n  \n\n    Would you consider it a cloud backup or would you use something else in addition? (Or course, it is also all backup up on a ssd to follow 3-2-1)"},
{"Title": "How can I archive a webpage with functioning buttons in a legally usable way? On Archive.org and Archive.is, the buttons lose their functionality, and the content I need to capture is not available via a separate URL.", "Author": "u/tajsta", "Content": "Hi all,\n  \n\n    I need to capture a webpage (\nhttps://denkly.de/angebot/fuzu/registrierung/\n) in a way that when you click on the button \"Paket wählen & weiter\", it actually shows you the content on the second step of the page. The second step is not a separate URL, so I need to find an archival website that doesn't break this functionality. So far I have tested archive.org, archive.is and conifer.rhizome.org, but all of them break this functionality. Only Google webcache doesn't break the site (\nhttps://webcache.googleusercontent.com/search?q=cache:https://denkly.de/angebot/fuzu/registrierung/\n), but obviously it's not an archival site and may be overwritten in the future.\n  \n\n    Since the reason for archiving is to safeguard a friend of mine for a potential legal dispute, I don't think saving it offline is enough, since an offline archive may be manipulated.\n  \n\n    Does anyone know of an archival site that is able to capture the second step of this page?\n  \n\n    Thanks!"},
{"Title": "Couple question to get started", "Author": "u/EvenRD", "Content": "Hello, i tried checking in the wiki or in FAQs but i couldn't find anything of use. I am considering starting hoarding files on physical drives since my online cloud is full and i don't want to pay a monthly fee. A couple questions:\n  \n\n\n\n\n\n    Should i? I need space to save personal files, photos and videos. Right now i think i could have all my storage done with 1TB, but for the sake of futereproofing and redundancy i think i should aim for 4TB. I still don't know if its convenient or should i just suck it up and pay online cloud services\n  \n\n\n\n\n\n    Do i need a NAS? I do all my work from my main computer so what i am basically thinking is just to add a RAID 5 HDD to my existing setup and call it a day, is there some reason i should NOT do?\n  \n\n\n\n\n\n    Since HDD tend to get noisy i'd like to shut them off when they are not needed, this way i can save energy as well"},
{"Title": "Twitter extension to download videos inside the page", "Author": "u/findthatgayporn", "Content": "Anyone knows a good one? I have two installed but have to open a new tab for each video I want to download; I need a extension to click and start downloading"},
{"Title": "How often should I update/refresh my cold storage?", "Author": "u/largePenisLover", "Content": "For cold/\"off-site\" storage of backups I use few HDD's. Backups go on them and then I store them nice and safe in a brick shed as an off-site kinda thing. They contain full backups. Disk is wiped and then a fresh backup goes on. I do this a few times a year. Not a real schedule to it.\n  \n\n    I fear bitrot.\nHow often should I refresh them to manage the chance of bitrot happening?\nWould it even help? I mean yes I wrote new data but the metal still aged."},
{"Title": "Fractal Define 7 XL: How many 3.5 HDDs with 1 or 2 5.25\"?", "Author": "u/BigNutritiousGoat", "Content": "Pretty much as per the title :) I want to put a CD drive and possibly a tape drive inside the case, if I take one or two 5.25\" slots how many 3.5\" HDDs can I accommodate? I'm assuming you lose 2 or 3 HDD slots?"},
{"Title": "Sending large files online solution?", "Author": "u/backflipbadboy", "Content": "I found the website \nhttps://tempfile.me\n who are claiming privacy + encryption when uploading large files online up to 10GB per file has anyone used such a service?"},
{"Title": "what are your predictions of IA lawsuit and is there any website archiving the archive?", "Author": "u/legz2006", "Content": "saw vid more muta(someordinarygames) about the lawsuit, something ive been keeping up with adn was wondering, will all that data just vanish?"},
{"Title": "New HDD test sequence", "Author": "u/sobo5o", "Content": "Got another 5TB external Seagate Expansion HDD and want to optimize my routine. The drive is originally in exFAT with some warranty content on it. I have Windows 10, so not using badblocks, but have HD Sentinel. My order is this:\n  \n\n    Minimum:\n  \n\n\n\n\n\n\nShort\n Long self-test (which will do an initial READ)\n  \n\n\n\n\n\n    Surface WRITE+Read with default 0's\n  \n\n\n\n\n\n    Quick format (to NTFS for use)\n  \n\n\n\n\n\n    Extensive:\n  \n\n\n\n\n\n    Short self-test\n  \n\n\n\n\n\n    Quick format (to NTFS, solely for the next step)\n  \n\n\n\n\n\n    Filling disk with large files (\nusing TeraCopy verify+test\n using H2TestW)\n  \n\n\n\n\n\n    Surface READ test\n  \n\n\n\n\n\n    Surface WRITE+Read with default 0's\n  \n\n\n\n\n\n    Surface WRITE+Read with 1's (\n0xFF)\n\n\n\n\n\n\n\n    Surface WRITE+Read back with 0's\n  \n\n\n\n\n\n    Quick format (to NTFS)\n  \n\n\n\n\n\n    Alternatively, badblocks instead of steps 5-7, or full u/\nEchoGecko795\n routine below in the comments.\n  \n\n    Thanks to everyone, all questions answered!\n  \n\n    Some notes:\n  \n\n\n\n\n\n\nExtended self-test\n can be skipped, as it just \nshort self-test\n + \nREAD test\n sequence \nwithin\n the drive, just less informative than the \nSurface read test\n as doesn't consider connectivity performance\n  \n\n\n\n\n\n\nFull format\n in Windows isn't needed, as it's the same as \nSurface READ + WRITE\n (with 0's) tests, maybe more limited, and \nquick format\n is enough just to change the filesystem\n  \n\n\n\n\n\n    Different surface write+read patterns emulate the 4-pass badblocks test\n  \n\n\n\n\n\n    A few things I wanted to clarify:\n  \n\n\n\n\n\n    how redundant is filling the drive with files, considering further WRITE+Read surface test? Does it only serve as another WRITE pass, just with different data?\n  \n\n\n\n\n\n    do I really need the \nRead test\n before the \nWRITE+Read test\n, or is the latter enough? (i.e. can a READ \nbefore\n WRITE indicate something that a READ \nafter\n WRITE won't?). My idea was to see the initial READ after the drive is filled with files, then overwriting it with 0's and reading again\n  \n\n\n\n\n\n    how important is changing the pattern/flipping 0's to 1's?\n  \n\n\n\n\n\n    should I flip 1's to 0's back again? Can the 1's pattern remain, following a quick format prior to using the drive?\n  \n\n\n\n\n\n    And finally, is the more time-consuming 3-4 pass procedure really worth it, and not an overkill?"},
{"Title": "PlutoTV - Downloading episodes from live channel (ondemand not available)", "Author": "u/pstNN", "Content": "Hi all,\n  \n\n    I've been waiting for this show to be released online for ages and it just released this week, however, there doesn't seem to be any plans to make it on demand, which means I cant use StreamFab.\n  \n\n    Does anyone know of a way to download episodes without the ads/commercials from a live stream on PlutoTV france?\n  \n\n    This is the link. If there is a paid software for it, i have no problem buying it.\n  \n\n\nhttps://pluto.tv/fr/live-tv/662a622b5e2370000800f392\n\n\n\n    Thanks!"},
{"Title": "Does suddenly unplugging the data connection to an externally powered drive carry a risk of corruption?", "Author": "u/SinkLeakOnFleek", "Content": "Hey y’all! Since summer is here now, I’m looking to upgrade my home setup. I already have a NAS at home, but I’m searching for a convenient way to expand my local storage for large games and the like while at home. I’m specifically looking at Thunderbolt docks such as this one that have built-in SATA or M.2 slots like this one:\n  \n\n\nhttps://a.co/d/e0Or2B6\n\n\n\n    My question is, since this enclosed drive would be receiving power from the dock (I might be totally misunderstanding here, sorry if that’s the case!), would it carry the same risk of data corruption if suddenly unplugged?\n  \n\n    A few Google searches couldn’t uncover this information, so I was hoping someone here might have expertise or experience with the matter.\n  \n\n    Thanks!"},
{"Title": "Recommendations for changing my 40 drive setup", "Author": "u/Professional_Lychee9", "Content": "I currently have a 45bay supermicro SAS2 JBOD enclosure with 40x 16TB Exos X16 enterprise drives in it. I would like to upgrade to SAS3. I have 2 options:\n  \n\n\n\n\n\n    Keep all drives together and use a single server to connect to it\n  \n\n\n\n\n\n    Split the drives into 2-4 enclosures and connect them each to a server\n  \n\n\n\n\n\n    I have a kubernetes cluster with 3x R630s and 1x R730. and looking to use Rook/Ceph to surface these drives to Minio. IT is currently connected to the R730 via an LSI SAS3 16e card.\n  \n\n    what enclosures might you recommend? I was looking at the D60 but cant tell if it will take SATA drives. I also cant seem to find smaller enclosures (12-15 bays) that dont also need CPU/Mobo/RAM. just want a JBOD enclosure"},
{"Title": "Is there a way to sync between devices using a usb cable?", "Author": "u/vrtqlwlpl", "Content": "Currently there is a programme called Syncthing which enables the wireless syncing of files between devices. It does not store data on the servers - rather, two devices have to be online at the same time for data to be synced. It's been a while so I don't remember the mechanisms through which it operates\n  \n\n    There are a couple of downsides. First being that wireless syncing is slow, second being that errors are more common with wireless syncing (from my experiences).\n  \n\n    Imagine a folder and imagine that every day I make a few changes to the files within it. I need the ability to sync all the changes within the folder for 2 devices. If I do not sync them, I would have to comb the entire folder for every change and apply them one by one OR delete the folder and paste the updated folder from my PC. It is around 50GB so it would take a while to paste\n  \n\n    I'd probably sync twice a week"},
{"Title": "Moving large files online?", "Author": "u/ParticularTreacle446", "Content": "I need to send a large number of files over the internet without the need of buying hardware. i came accross this website has anyone used it? if so please share your thoughts. \ntempfile.me"},
{"Title": "RAID 5 controller for Win 11 Workstation", "Author": "u/Heinrich_v_Schimmer", "Content": "As a photographer, I generate more than a TByte of data per month and therefore have a RAID 5 on my work system. The controller used for this RAID runs into problems with the energy saving modes of Windows; when the system wakes up from sleep mode, the drive is no longer visible in Explorer until a complete reboot.\n  \n\n    Does anyone know of a RAID 5 controller that can cope with the energy saving modes of Windows 11?\n  \n\n    PS: Software (OS) RAIDs are not an option."},
{"Title": "Best way to transfer data from one external ssd to another external ssd?", "Author": "u/alucvrdofficial", "Content": "Not sure if this is the right subreddit to post in, but as the title states, I purchased another external ssd, and I want to upload all of the data on my current ssd to this new one. Does anybody have suggestions for how to go about this? Can I just plug em both in and drag the folders over?\n  \n\n    Also, if this isn't the right place to ask, does anyone have suggestions on where to look?"},
{"Title": "Quiet HL15 Build help", "Author": "u/NextRedditAccount0", "Content": "I'm planning to pick up an HL15 to replace my Synology DS2415+.\nMy current DS2415+ is not the quietest thing in the world but the noise is manageable considering its a few feet away from my desk and bed. I'm also running 8x8TB shucked WD easystore drives in there.\n  \n\n    My plan is to pickup the HL15 and move all the drives over AND purchase some new larger drives since my pool is roughly 70% full and i'm planning to fill it up some more.\n  \n\n    Some questions.\nHow loud is the HL15? I'm planning on picking up the HL15 with the Noctua fans option.\nAny recommendations for quiet or quietish 12tb+ drives? I'm going to grab them from \nserverpartdeals.com\nI saw some videos with PWL drives and that thumping would drive me crazy. I hope the HL15 has some form of noise damping if PWL drives are my only option.\n  \n\n    Would love some feedback before I hit the buy button on this one."},
{"Title": "Using a homelab as a cache server for my cloud storage?", "Author": "u/sqenixs", "Content": "I'm looking to set up a homelab pc where it will have about 10TB of storage.  I also have a backblaze B2 bucket I will use for cloud storage.  I would like to use the homelab PC as a sort of cache drive where when I am at home I can use it, and when I am away I can connect to my backblaze b2 bucket directly from my laptop.  For example, I could open a word doc, make a few changes, and it would sync automatically to my cloud and NAS.  However the cloud would have more storage so I envision a scenario where my laptop would run out of space so I would keep some files \"cloud only\" and they would be on the NAS when at home or in the backblaze cloud when away.  However, some files I might want to only keep in the cloud and not on my laptop or NAS.  Is this possible?"},
{"Title": "Im looking for the best way to store my hentai collections preferbely cloud and external hard drive as backup. whats the best cloud service that can be used and external ssd. I want to start with 2TB for now as my collection is only 500gb and more to come in few days.", "Author": "u/RealComposer5655", "Content": "as title says"},
{"Title": "The Internet Archive solution and a creative way to compress large text files", "Author": "u/mazemadman12346", "Content": "As many of us are aware the internet archive is under legal flak for sharing books during covid to the dismay of book publishers\n  \n\n    This makes me wonder. What if they never actually shared any media or websites, and instead gave a series of links to \nlibraryofbabel.info\n (or similar website modified to generate random html code) which would conatain either the direct text or the source code of the designated media?\n  \n\n    By doing this they would be able to circumvent copyright laws as anything they share would be the product of randomly generated code and they would simply be telling you where to find it as opposed to sharing the image\n  \n\n    secondly, what if we made a website like this but for compression? Instead of needing 400mb of compressed files you could have a 2mb text file that links you to the necessary pages\n  \n\n    TLDR instead of compressing the entire bee movie script you would only need to compress a text folder containing 1-10 of \"\nhttps://libraryofbabel.info/bookmark.cgi?bee_movie_script_random\n)\" and write a program to decrypt them"},
{"Title": "looking for something similar to Qsync", "Author": "u/niloproject", "Content": "Hi everyone, I could use some help. I've put together a NAS for my business and I was wondering if there were any alternatives to Qnap Qsync that would work with Truenas. (I also asked this in the truenas server but figured it would hurt to ask here too). The functionality in specific that I'm looking for is the ability to create users that can then establish a two way sync with the server, but similar to with Qsync, there would ideally be a smart sync that would only download what users actually need locally and not anything that isn't necessary to their work so they're not having to deal with terabytes of storage being synced.  They could then work directly on the mounted drive from their machines and anything they create will be synced to everyone and they won't have to worry about manually downloading/duplicating files on the server.\n  \n\n    When building this I didn't realize how hard it would be to find a tool for this, and everything I've found just isn't very useful. Syncthing is not helpful, its not smart and would require everyone mirror 20tb of files (unless im misunderstanding what it does.) SMB sharing technically works but is too slow for people to work off of for our purposes as our files have huge datarates (multilayer EXR sequences, 1gb a frame kind of stuff).  I'm also experimenting with Google Workspace to see if that works any better for this but I'd figure I'd ask for help before I go down that road.\n  \n\n    If any of you have any experience with this or could maybe point me to a client-side software that can manage client side downloads from the server in a smart way like Qsync that would be amazing."},
{"Title": "Need recommendations for USB3 or eSata external drive to connect to router for FTP server.", "Author": "u/mufasis", "Content": "What’s going on data hoarders. I’m looking for a network drive I can connect to my router, USB3 or eSata. Will be used to store stuff on my home network as well as serve files by FTP, mostly music files and projects I need to share.\n  \n\n    Also what would be better USB3 or eSata?\n  \n\n    Looking for speed and reliability, thanks!"},
{"Title": "Donating space", "Author": "u/noideawhatimdoing444", "Content": "I'm not at the place where I can donate space on my server but eventually I will be. I'd like to give support to pages like Wikipedia or any other project I feel aligns with my values. Is that something thats even feasible?"},
{"Title": "Any hardware Raid 4-bay enclosures out there that ARE \"power disable\" compatible?", "Author": "u/09Klr650", "Content": "Perhaps my search-fu is lacking but all the small 4-bay hardware raid enclosures I find specifically state they are not Power Disable compatible. Before I go the whole \"kapton tape in pin 3\" route is there a manufacturer/model out there that is capable? Without costing an arm, leg and earlobe preferably.  This will be my first such setup and I want to KISS for the moment. Figure that (4) 12TB Reman HGST would be a good start. At Raid 5 that's approx 36TB. Or approximately 4x all my current motley collection of externals combined. Thanks."},
{"Title": "Increasing the redundancy/error-correction of a partition?", "Author": "u/metal_wires", "Content": "I have a 2TB external HDD, and I have created a 256GB partition which is an encrypted VeraCrypt volume. I was thinking, that since I have more than 1.5TB space leftover, is it possible to use some of that remaining space to add parity data or error correction for this VeraCrypt partition, to protect against bit rot?\n  \n\n    I have tried searching all over the Internet for a tool that would let me create a \"error correction partition\" which stores ECC for the VeraCrypt partition, but I cannot find it. At most, I can find references to RAID 5, but I don't have multiple drives, just this one."},
{"Title": "I know iCloud is not considered a backup but..", "Author": "u/askinghawking", "Content": "I know iCloud is more considered as a sync service but do you think I can use it as a backup how I do it?\n  \n\n    I have a Mac that is only a backup tool. Means that I get all photos and documents to the Mac + iCloud there from my iphone - with a different iCloud account. So it couldn‘t happen that I delete a picture from my phone and is deleted everywhere.\n  \n\n    Would you consider it a cloud backup or would you use something else in addition? (Or course, it is also all backup up on a ssd to follow 3-2-1)"},
{"Title": "How can I archive a webpage with functioning buttons in a legally usable way? On Archive.org and Archive.is, the buttons lose their functionality, and the content I need to capture is not available via a separate URL.", "Author": "u/tajsta", "Content": "Hi all,\n  \n\n    I need to capture a webpage (\nhttps://denkly.de/angebot/fuzu/registrierung/\n) in a way that when you click on the button \"Paket wählen & weiter\", it actually shows you the content on the second step of the page. The second step is not a separate URL, so I need to find an archival website that doesn't break this functionality. So far I have tested archive.org, archive.is and conifer.rhizome.org, but all of them break this functionality. Only Google webcache doesn't break the site (\nhttps://webcache.googleusercontent.com/search?q=cache:https://denkly.de/angebot/fuzu/registrierung/\n), but obviously it's not an archival site and may be overwritten in the future.\n  \n\n    Since the reason for archiving is to safeguard a friend of mine for a potential legal dispute, I don't think saving it offline is enough, since an offline archive may be manipulated.\n  \n\n    Does anyone know of an archival site that is able to capture the second step of this page?\n  \n\n    Thanks!"},
{"Title": "Couple question to get started", "Author": "u/EvenRD", "Content": "Hello, i tried checking in the wiki or in FAQs but i couldn't find anything of use. I am considering starting hoarding files on physical drives since my online cloud is full and i don't want to pay a monthly fee. A couple questions:\n  \n\n\n\n\n\n    Should i? I need space to save personal files, photos and videos. Right now i think i could have all my storage done with 1TB, but for the sake of futereproofing and redundancy i think i should aim for 4TB. I still don't know if its convenient or should i just suck it up and pay online cloud services\n  \n\n\n\n\n\n    Do i need a NAS? I do all my work from my main computer so what i am basically thinking is just to add a RAID 5 HDD to my existing setup and call it a day, is there some reason i should NOT do?\n  \n\n\n\n\n\n    Since HDD tend to get noisy i'd like to shut them off when they are not needed, this way i can save energy as well"},
{"Title": "Twitter extension to download videos inside the page", "Author": "u/findthatgayporn", "Content": "Anyone knows a good one? I have two installed but have to open a new tab for each video I want to download; I need a extension to click and start downloading"},
{"Title": "How often should I update/refresh my cold storage?", "Author": "u/largePenisLover", "Content": "For cold/\"off-site\" storage of backups I use few HDD's. Backups go on them and then I store them nice and safe in a brick shed as an off-site kinda thing. They contain full backups. Disk is wiped and then a fresh backup goes on. I do this a few times a year. Not a real schedule to it.\n  \n\n    I fear bitrot.\nHow often should I refresh them to manage the chance of bitrot happening?\nWould it even help? I mean yes I wrote new data but the metal still aged."},
{"Title": "Fractal Define 7 XL: How many 3.5 HDDs with 1 or 2 5.25\"?", "Author": "u/BigNutritiousGoat", "Content": "Pretty much as per the title :) I want to put a CD drive and possibly a tape drive inside the case, if I take one or two 5.25\" slots how many 3.5\" HDDs can I accommodate? I'm assuming you lose 2 or 3 HDD slots?"},
{"Title": "Sending large files online solution?", "Author": "u/backflipbadboy", "Content": "I found the website \nhttps://tempfile.me\n who are claiming privacy + encryption when uploading large files online up to 10GB per file has anyone used such a service?"},
{"Title": "what are your predictions of IA lawsuit and is there any website archiving the archive?", "Author": "u/legz2006", "Content": "saw vid more muta(someordinarygames) about the lawsuit, something ive been keeping up with adn was wondering, will all that data just vanish?"},
{"Title": "New HDD test sequence", "Author": "u/sobo5o", "Content": "Got another 5TB external Seagate Expansion HDD and want to optimize my routine. The drive is originally in exFAT with some warranty content on it. I have Windows 10, so not using badblocks, but have HD Sentinel. My order is this:\n  \n\n    Minimum:\n  \n\n\n\n\n\n\nShort\n Long self-test (which will do an initial READ)\n  \n\n\n\n\n\n    Surface WRITE+Read with default 0's\n  \n\n\n\n\n\n    Quick format (to NTFS for use)\n  \n\n\n\n\n\n    Extensive:\n  \n\n\n\n\n\n    Short self-test\n  \n\n\n\n\n\n    Quick format (to NTFS, solely for the next step)\n  \n\n\n\n\n\n    Filling disk with large files (\nusing TeraCopy verify+test\n using H2TestW)\n  \n\n\n\n\n\n    Surface READ test\n  \n\n\n\n\n\n    Surface WRITE+Read with default 0's\n  \n\n\n\n\n\n    Surface WRITE+Read with 1's (\n0xFF)\n\n\n\n\n\n\n\n    Surface WRITE+Read back with 0's\n  \n\n\n\n\n\n    Quick format (to NTFS)\n  \n\n\n\n\n\n    Alternatively, badblocks instead of steps 5-7, or full u/\nEchoGecko795\n routine below in the comments.\n  \n\n    Thanks to everyone, all questions answered!\n  \n\n    Some notes:\n  \n\n\n\n\n\n\nExtended self-test\n can be skipped, as it just \nshort self-test\n + \nREAD test\n sequence \nwithin\n the drive, just less informative than the \nSurface read test\n as doesn't consider connectivity performance\n  \n\n\n\n\n\n\nFull format\n in Windows isn't needed, as it's the same as \nSurface READ + WRITE\n (with 0's) tests, maybe more limited, and \nquick format\n is enough just to change the filesystem\n  \n\n\n\n\n\n    Different surface write+read patterns emulate the 4-pass badblocks test\n  \n\n\n\n\n\n    A few things I wanted to clarify:\n  \n\n\n\n\n\n    how redundant is filling the drive with files, considering further WRITE+Read surface test? Does it only serve as another WRITE pass, just with different data?\n  \n\n\n\n\n\n    do I really need the \nRead test\n before the \nWRITE+Read test\n, or is the latter enough? (i.e. can a READ \nbefore\n WRITE indicate something that a READ \nafter\n WRITE won't?). My idea was to see the initial READ after the drive is filled with files, then overwriting it with 0's and reading again\n  \n\n\n\n\n\n    how important is changing the pattern/flipping 0's to 1's?\n  \n\n\n\n\n\n    should I flip 1's to 0's back again? Can the 1's pattern remain, following a quick format prior to using the drive?\n  \n\n\n\n\n\n    And finally, is the more time-consuming 3-4 pass procedure really worth it, and not an overkill?"},
{"Title": "PlutoTV - Downloading episodes from live channel (ondemand not available)", "Author": "u/pstNN", "Content": "Hi all,\n  \n\n    I've been waiting for this show to be released online for ages and it just released this week, however, there doesn't seem to be any plans to make it on demand, which means I cant use StreamFab.\n  \n\n    Does anyone know of a way to download episodes without the ads/commercials from a live stream on PlutoTV france?\n  \n\n    This is the link. If there is a paid software for it, i have no problem buying it.\n  \n\n\nhttps://pluto.tv/fr/live-tv/662a622b5e2370000800f392\n\n\n\n    Thanks!"},
{"Title": "Does suddenly unplugging the data connection to an externally powered drive carry a risk of corruption?", "Author": "u/SinkLeakOnFleek", "Content": "Hey y’all! Since summer is here now, I’m looking to upgrade my home setup. I already have a NAS at home, but I’m searching for a convenient way to expand my local storage for large games and the like while at home. I’m specifically looking at Thunderbolt docks such as this one that have built-in SATA or M.2 slots like this one:\n  \n\n\nhttps://a.co/d/e0Or2B6\n\n\n\n    My question is, since this enclosed drive would be receiving power from the dock (I might be totally misunderstanding here, sorry if that’s the case!), would it carry the same risk of data corruption if suddenly unplugged?\n  \n\n    A few Google searches couldn’t uncover this information, so I was hoping someone here might have expertise or experience with the matter.\n  \n\n    Thanks!"},
{"Title": "Recommendations for changing my 40 drive setup", "Author": "u/Professional_Lychee9", "Content": "I currently have a 45bay supermicro SAS2 JBOD enclosure with 40x 16TB Exos X16 enterprise drives in it. I would like to upgrade to SAS3. I have 2 options:\n  \n\n\n\n\n\n    Keep all drives together and use a single server to connect to it\n  \n\n\n\n\n\n    Split the drives into 2-4 enclosures and connect them each to a server\n  \n\n\n\n\n\n    I have a kubernetes cluster with 3x R630s and 1x R730. and looking to use Rook/Ceph to surface these drives to Minio. IT is currently connected to the R730 via an LSI SAS3 16e card.\n  \n\n    what enclosures might you recommend? I was looking at the D60 but cant tell if it will take SATA drives. I also cant seem to find smaller enclosures (12-15 bays) that dont also need CPU/Mobo/RAM. just want a JBOD enclosure"},
{"Title": "Is there a way to sync between devices using a usb cable?", "Author": "u/vrtqlwlpl", "Content": "Currently there is a programme called Syncthing which enables the wireless syncing of files between devices. It does not store data on the servers - rather, two devices have to be online at the same time for data to be synced. It's been a while so I don't remember the mechanisms through which it operates\n  \n\n    There are a couple of downsides. First being that wireless syncing is slow, second being that errors are more common with wireless syncing (from my experiences).\n  \n\n    Imagine a folder and imagine that every day I make a few changes to the files within it. I need the ability to sync all the changes within the folder for 2 devices. If I do not sync them, I would have to comb the entire folder for every change and apply them one by one OR delete the folder and paste the updated folder from my PC. It is around 50GB so it would take a while to paste\n  \n\n    I'd probably sync twice a week"},
{"Title": "Moving large files online?", "Author": "u/ParticularTreacle446", "Content": "I need to send a large number of files over the internet without the need of buying hardware. i came accross this website has anyone used it? if so please share your thoughts. \ntempfile.me"},
{"Title": "RAID 5 controller for Win 11 Workstation", "Author": "u/Heinrich_v_Schimmer", "Content": "As a photographer, I generate more than a TByte of data per month and therefore have a RAID 5 on my work system. The controller used for this RAID runs into problems with the energy saving modes of Windows; when the system wakes up from sleep mode, the drive is no longer visible in Explorer until a complete reboot.\n  \n\n    Does anyone know of a RAID 5 controller that can cope with the energy saving modes of Windows 11?\n  \n\n    PS: Software (OS) RAIDs are not an option."},
{"Title": "Best way to transfer data from one external ssd to another external ssd?", "Author": "u/alucvrdofficial", "Content": "Not sure if this is the right subreddit to post in, but as the title states, I purchased another external ssd, and I want to upload all of the data on my current ssd to this new one. Does anybody have suggestions for how to go about this? Can I just plug em both in and drag the folders over?\n  \n\n    Also, if this isn't the right place to ask, does anyone have suggestions on where to look?"},
{"Title": "Quiet HL15 Build help", "Author": "u/NextRedditAccount0", "Content": "I'm planning to pick up an HL15 to replace my Synology DS2415+.\nMy current DS2415+ is not the quietest thing in the world but the noise is manageable considering its a few feet away from my desk and bed. I'm also running 8x8TB shucked WD easystore drives in there.\n  \n\n    My plan is to pickup the HL15 and move all the drives over AND purchase some new larger drives since my pool is roughly 70% full and i'm planning to fill it up some more.\n  \n\n    Some questions.\nHow loud is the HL15? I'm planning on picking up the HL15 with the Noctua fans option.\nAny recommendations for quiet or quietish 12tb+ drives? I'm going to grab them from \nserverpartdeals.com\nI saw some videos with PWL drives and that thumping would drive me crazy. I hope the HL15 has some form of noise damping if PWL drives are my only option.\n  \n\n    Would love some feedback before I hit the buy button on this one."},
{"Title": "Using a homelab as a cache server for my cloud storage?", "Author": "u/sqenixs", "Content": "I'm looking to set up a homelab pc where it will have about 10TB of storage.  I also have a backblaze B2 bucket I will use for cloud storage.  I would like to use the homelab PC as a sort of cache drive where when I am at home I can use it, and when I am away I can connect to my backblaze b2 bucket directly from my laptop.  For example, I could open a word doc, make a few changes, and it would sync automatically to my cloud and NAS.  However the cloud would have more storage so I envision a scenario where my laptop would run out of space so I would keep some files \"cloud only\" and they would be on the NAS when at home or in the backblaze cloud when away.  However, some files I might want to only keep in the cloud and not on my laptop or NAS.  Is this possible?"},
{"Title": "Im looking for the best way to store my hentai collections preferbely cloud and external hard drive as backup. whats the best cloud service that can be used and external ssd. I want to start with 2TB for now as my collection is only 500gb and more to come in few days.", "Author": "u/RealComposer5655", "Content": "as title says"},
{"Title": "The Internet Archive solution and a creative way to compress large text files", "Author": "u/mazemadman12346", "Content": "As many of us are aware the internet archive is under legal flak for sharing books during covid to the dismay of book publishers\n  \n\n    This makes me wonder. What if they never actually shared any media or websites, and instead gave a series of links to \nlibraryofbabel.info\n (or similar website modified to generate random html code) which would conatain either the direct text or the source code of the designated media?\n  \n\n    By doing this they would be able to circumvent copyright laws as anything they share would be the product of randomly generated code and they would simply be telling you where to find it as opposed to sharing the image\n  \n\n    secondly, what if we made a website like this but for compression? Instead of needing 400mb of compressed files you could have a 2mb text file that links you to the necessary pages\n  \n\n    TLDR instead of compressing the entire bee movie script you would only need to compress a text folder containing 1-10 of \"\nhttps://libraryofbabel.info/bookmark.cgi?bee_movie_script_random\n)\" and write a program to decrypt them"},
{"Title": "looking for something similar to Qsync", "Author": "u/niloproject", "Content": "Hi everyone, I could use some help. I've put together a NAS for my business and I was wondering if there were any alternatives to Qnap Qsync that would work with Truenas. (I also asked this in the truenas server but figured it would hurt to ask here too). The functionality in specific that I'm looking for is the ability to create users that can then establish a two way sync with the server, but similar to with Qsync, there would ideally be a smart sync that would only download what users actually need locally and not anything that isn't necessary to their work so they're not having to deal with terabytes of storage being synced.  They could then work directly on the mounted drive from their machines and anything they create will be synced to everyone and they won't have to worry about manually downloading/duplicating files on the server.\n  \n\n    When building this I didn't realize how hard it would be to find a tool for this, and everything I've found just isn't very useful. Syncthing is not helpful, its not smart and would require everyone mirror 20tb of files (unless im misunderstanding what it does.) SMB sharing technically works but is too slow for people to work off of for our purposes as our files have huge datarates (multilayer EXR sequences, 1gb a frame kind of stuff).  I'm also experimenting with Google Workspace to see if that works any better for this but I'd figure I'd ask for help before I go down that road.\n  \n\n    If any of you have any experience with this or could maybe point me to a client-side software that can manage client side downloads from the server in a smart way like Qsync that would be amazing."},
{"Title": "Need recommendations for USB3 or eSata external drive to connect to router for FTP server.", "Author": "u/mufasis", "Content": "What’s going on data hoarders. I’m looking for a network drive I can connect to my router, USB3 or eSata. Will be used to store stuff on my home network as well as serve files by FTP, mostly music files and projects I need to share.\n  \n\n    Also what would be better USB3 or eSata?\n  \n\n    Looking for speed and reliability, thanks!"},
{"Title": "Donating space", "Author": "u/noideawhatimdoing444", "Content": "I'm not at the place where I can donate space on my server but eventually I will be. I'd like to give support to pages like Wikipedia or any other project I feel aligns with my values. Is that something thats even feasible?"},
{"Title": "Any hardware Raid 4-bay enclosures out there that ARE \"power disable\" compatible?", "Author": "u/09Klr650", "Content": "Perhaps my search-fu is lacking but all the small 4-bay hardware raid enclosures I find specifically state they are not Power Disable compatible. Before I go the whole \"kapton tape in pin 3\" route is there a manufacturer/model out there that is capable? Without costing an arm, leg and earlobe preferably.  This will be my first such setup and I want to KISS for the moment. Figure that (4) 12TB Reman HGST would be a good start. At Raid 5 that's approx 36TB. Or approximately 4x all my current motley collection of externals combined. Thanks."},
{"Title": "Increasing the redundancy/error-correction of a partition?", "Author": "u/metal_wires", "Content": "I have a 2TB external HDD, and I have created a 256GB partition which is an encrypted VeraCrypt volume. I was thinking, that since I have more than 1.5TB space leftover, is it possible to use some of that remaining space to add parity data or error correction for this VeraCrypt partition, to protect against bit rot?\n  \n\n    I have tried searching all over the Internet for a tool that would let me create a \"error correction partition\" which stores ECC for the VeraCrypt partition, but I cannot find it. At most, I can find references to RAID 5, but I don't have multiple drives, just this one."},
{"Title": "External Hard Drive for High Humidity Conditions", "Author": "u/BrEichen", "Content": "I'm gonna be living in a peat swamp forest in Borneo for a year and am looking to bring a hard drive to store movies, TV, and photos on as I will not have reliable internet access. Where I'll be the humidity is so high clothes and technology are stored in plastic bins w/ silica packets when not in use. I was wondering if anyone could recommend an external hard drive that could hold up to these conditions (if such a thing even exists). Sorry if this is a dumb or already answered question, pretty new to this stuff. Thanks!"},
{"Title": "I bought a sas controller LSI 9240-8i SAS SATA RAID Controller Card drives", "Author": "u/Unusual-Ingenuity831", "Content": "I need help installing it i bought this to use my sas hard drive but i have plugged it in and everything and it still wont work so i need help"},
{"Title": "Samsung SSD cache sizes for 1TB", "Author": "u/madurbad", "Content": "Looking to buy a Samsung SSD. I only have the money for 1TB, but I'm not sure which model to get given the prices (I can only afford 1TB). Obviously I want performance to be the best, but that largely comes down to cache size between the Samsung T7, T7 shield, and T9. Unfortunately, I can't take advantage of USB 3.2x2.\n  \n\n    My question is: what are the cache sizes for each of these SSDs with their 1TB models (I heard cache sizes differ with storage capacity)?\n  \n\n    If theyre all the same, I'm looking to save money and just buy the T7.\n  \n\n    Thanks"},
{"Title": "How to download the video content from Microsoft Lean On-demand training?", "Author": "u/HardLearner01", "Content": "How to download the video content of this site?\n  \n\n\nDP-100 Design a machine learning solution (1 of 6) | Microsoft Learn"},
{"Title": "Upgrading and future-proofing my Plex Media server & library setup, looking for advice", "Author": "u/Reasonable_Jelly9435", "Content": "TL;DR - Nearing storage cap on my current external HDD. Want to upgrade storage and reasonably future-proof as best as possible. Considering changing my setup from PC (Plex Media Server) + external HDD (media storage), to a mini PC (Plex) + DAS. Could use advice.\n\n\n\n    Hi, I've done some research on upgrading my current Plex / general media storage setup and I've come up with a plan that looks something like the below. Please share any constructive criticisms, tips, things I might have overlooked, etc. I want to do this right the first time around.\n  \n\n    Use case: 1-2 simultaneous 1080p streams, most clients will be able to directly play my mostly HEVC (h.265) content without needing to transcode. Not all, though, so transcoding option is nice. I have Plex Pass so HW transcoding is also an option.\n  \n\n    My current setup:\n  \n\n\n\n\n\n    PC \n[Plex Media Server]\n\n\n\n\n\n\n\n    External Hard drive (12TB) [\n~10TB personal media\n]\n  \n\n\n\n\n\n\n\n\n\n    What I'm thinking of moving to:\n  \n\n\n\n\n\n    Mini PC (\nBeelink Mini S12\n) \n[Plex Media Server]\n\n\n\n\n\n\n\n    DAS (\n4-bay QNAP\n)\n  \n\n\n\n\n\n    3.5 12TB HDD (shuck my current drive) [\n~10TB personal media\n]\n  \n\n\n\n\n\n    3.5 12TB HDD (buy a new one) [\nRAID backup?\n]\n  \n\n\n\n\n\n    empty (add a 12TB in future for more storage?)\n  \n\n\n\n\n\n    empty (add a 12TB in future for more storage?)\n  \n\n\n\n\n\n\n\n\n\n    If this looks good, I have a bonus question: How do I safely move my content on my current 12TB external hard drive to the DAS? Is it as simple as shucking the drive and installing in the DAS? I've also read that setting up RAID will wipe the drives; will it be necessary to buy a third 12TB drive before moving my media?\n  \n\n    Thanks in advance!"},
{"Title": "NVMe SSD based storage computer", "Author": "u/aes100", "Content": "If you were to build a storage computer based on NVMe SSDs, how would you do it? Nor datarate, nor storage space is priority. Just sheer number of NVMe SSDs... and you hate cables.\n  \n\n    Build#1: AMD Threadripper with PCIe to M.2 adapter cards. Because I think that is the only motherboard that has more than one or two PCIe slots. But Threadripper is overkill expensive for just storage and not worth it. I didn't do research on Intel side.\n  \n\n    Build#2: Get a server motherboard with lots of SATA ports and lots of SATA to M.2 adapters. Put the NVMe's in, and connect them to SATA ports. But you don't like cables.\n  \n\n    Build#3: Get a LattePanda Mu based on Intel N100 which they advertise a NAS carrier but I don't know if it exists yet or not. Or get a FriendlyELEC CM3588 based on Rockchip. You are free of cables, but are you gonna regret accessing the data on there because it is slow? Or is it actually fast enough to, I don't know, watch a video from it?\n  \n\n    What do you think about the above builds? What downs and ups do you think they have? How would you do it? Why?"},
{"Title": "Can storage have a maximum amount of storage space?", "Author": "u/Card_Boxy", "Content": "Sorry if this question was worded weirdly, but I am looking to buy a new hard drive for my pre-built Lenovo IdeaCentre Gaming 5 17IAB7. I noticed that, according to the specs on the Product Specifications Reference it could only fit 2 3.5\" HDDs with a maximum of 2 TB, and 1 M.2 SSD with a max of 1 TB.\n  \n\n    What would happen if I were to buy and install a HDD / SSD larger than the reported maximum on the specifications sheet?\n  \n\n    Here's the actual pages I was looking at.\n  \n\n\nhttps://psref.lenovo.com/Detail/IdeaCentre/IdeaCentre_Gaming_5_17IAB7?M=90T00003US\n\n\n\n\nhttps://psref.lenovo.com/Product/IdeaCentre/IdeaCentre_Gaming_5_17IAB7\n\n\n\n    Thanks in advance for your times."},
{"Title": "Macrium Reflect backup to NVMe drive in USB-C enclosure is very slow? Normal copying to same drive is fast...", "Author": "u/ozzuneoj", "Content": "Relevant Specs:\n  \n\n    Windows 10 22H2\n  \n\n    Ryzen 7 5800X3D\n  \n\n    Gigabyte X570 Aorus Elite\n  \n\n    64GB DDR4-3600\n  \n\n    Soldigm P44 Pro 2TB NVMe Gen4\n  \n\n    Macrium Reflect Free 8\n  \n\n    To keep things simple, I'm just going to focus on making a macrium image of my system partitions (C: and a couple without letters; about 100GB of data total) as a backup . I have been doing this for years but lately I've been trying to streamline and speed up the process.\n  \n\n    I have a SATA dock installed inside my system (straight SATA, no USB), and when I slot in my old 1TB Crucial MX500 drive, I can run the macrium backup in about 6 minutes.\n  \n\n    I have lots of spare NVMe drives, so I got one of these Orico 10Gbps USB 3.2 NVMe enclosures (\nhttps://www.amazon.com/ORICO-NVMe-Thunderbolt-Compatible-SSDs-PWM2-BK/dp/B0BJ23JTXX\n) several months ago and it has worked fine for transferring files. However, when I run the same macrium backup as before to this NVMe drive it seems to hang for a second, then shows an estimate of 6 minutes, then within a few seconds the transfer rate drops from 1+gbps to under 100mbps and the estimated time shoots up to 55 minutes.\n  \n\n    You would think that the symptoms point to a crappy USB enclosure or a problem with the drive... but when I copy the same image file directly from the SATA drive to the NVMe drive manually in Windows the transfer rate is pegged at over 550MB\\sec (megabytes) and it is done in just over a minute.\n  \n\n    Is there something I can adjust in Macrium or elsewhere that would fix this seeming incompatibility with this NVMe USB enclosure? I'd love to use it (to free up my old 1TB MX500) but having to wait nearly 10 times as long for backups is unacceptable.\n  \n\n    Thank you for any help you can offer."},
{"Title": "Modular NAS build", "Author": "u/Mother_Occasion_8076", "Content": "No content"},
{"Title": "Extension cable to disable Power Disable Feature on HDD?", "Author": "u/feedmememes", "Content": "I just purchased this HDD of Amazon: \nhttps://www.amazon.com/gp/product/B08T3PBV57/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&th=1\n\n\n\n    However it did not come with the power extension cable mentioned in the product description. I have purchased this drive before and it would not work without that cable, so it is necessary for me to get one for the HDD to work. My question is what would I search for the get the correct part? Would any sata-to-sata power extension work or would it need to have some special spec? I've read a 4-pin Molex to SATA connector might be the solution, but I would like to confirm before purchasing because I am dumb!! Something like this for example:\nhttps://www.amazon.com/Cable-Matters-3-Pack-Molex-Power/dp/B00STNUB04/ref=sr_1_2?crid=B3ZGL1OM3IR1&dib=eyJ2IjoiMSJ9.f9jru-Gy4n_1s6sxvx6tecrDs0kKyQc_KXFNnctPSyGpgk3wiTyXQRVjv8latROCZFMth35JZj6AzNa09K_WespKmumHEQjA1Qn9tuzw8MBtUCX9qyoxPfAfS1R9c3JLDgIR1NHveuutkNGIKTrnouyP5DBd2e2yp3U9bkzTz5b_jPWn4NWf9pusLWEVS3OvqcRsb74HYfa7bE5vtR5EWmod_f3B-fJJnotQO7qTLbE.4mkQvoblx472TPQkw3pPm3UzP8ULyibyZTNH-zpyBg4&dib_tag=se&keywords=Sata-to-sata+power+adapter+cable&qid=1718302912&sprefix=sata-to-sata+power+adapter+cable+%2Caps%2C84&sr=8-2\n\n\n\n    Or if there are any other solutions that would be helpful too.\n  \n\n    Sorry for noob question and thank you in advanced for any help!"},
{"Title": "How do you go about pruning your hoard?", "Author": "u/Clive1792", "Content": "Personally I feel snowed under with what I've got. There's countless files on my PC scattered everywhere. Documents, pictures (probably in the 100,000s), audio files, video files. It's most certainly not organised at all, it's scattered all over the hard drives on this PC in various folders & folders of folders.\n  \n\n    But to make it better I had no real backup plan. I'd just drag & drop and then not really remember what I'd backed up and what I hadn't so then I'd buy a new hard drive & make another copy because the last drive was fairly full.\n  \n\n    I now have a number of drives that surely have many multiples of various single files.\n  \n\n    My end goal is I would like some organisation rather than random files & folders scattered here there & everywhere. I'd like to get rid of the multiple duplicate files & also delete files I no longer want/need.\n  \n\n    Have any of you attacked this kind of task? Any tips or do you really just do it file-by-file? Which to be honest with what I've got & the fact I only have limited time outside of work, this is going to take me many months if not 12months plus .... and that's if I get stuck in & stay focused doing it day in day out."},
{"Title": "Need help with magazine scanning - resolution vs size", "Author": "u/MyBallsSmellFruity", "Content": "So I'm scanning magazines at 300 dpi.  Any less, and the images look kind of cruddy.  Of course, the image size is pretty large, so I'm having to batch convert them to manually make the image height 1200 (width is auto calculated).\n  \n\n    Is this pretty much the only way to get both decent quality and an acceptable image size?  The actual filesize difference in the PDFs is pretty noticeable - and significant when doing hundreds of magazines.\n  \n\n    Or is there an easier way that I just haven't stumbled across?"},
{"Title": "I'm 98% of the way there — help me across the finish line! (Syncing help)", "Author": "u/740990929974739", "Content": "MY FRIENDS!\n\n\n\n    I'm finally doing it. Bought a 12 TB External HDD + Backblaze (Computer Backup, not B2) so I can back up my scattered external drives to the big HDD and have that backup automatically to Backblaze.\n  \n\n    That should allow me, I hope, to finally delete files from my computer's SSD as well as my 3 other external SSDs that are all clogged up with old photos and videos. (I'm a photographer + videographer + audio engineer so I produce a lot of files — I'm \nout\n of working space and it's ruining my life!)\n  \n\n    My issue:\n  \n\n    I backed up 2/3 external SSDs to the big HDD about a month ago, but since then, new files have been added. I want to add only the new files to the HDD, without having to re-copy the entire folder, since I suspect that would also mess with Backblaze's file detection.\n  \n\n\nI think this means I need a file syncing and/or deduplication program.\n\n\n\n    I've seen FreeFileSync as a recommended service. Is this what I need?\n  \n\n    Thanks so much for your help!"},
{"Title": "First TrueNAS SCALE build - I'd like to begin doing weekly snapshots of Wikipedia. Any tips?", "Author": "u/saltyspicehead", "Content": "6 x 12TB Drives, Raidz2, NVMe L2ARC + SLOG etc etc etc roughly 45 TB to work with.\n  \n\n    I'd like to start by creating a weekly Wikipedia backup job to track change history. I'm familiar enough about storage tech to know that this should be possible without consuming a new ~120GB of storage every week, since only the delta will actually consume any disk space. However, I'm not familiar enough with non-enterprise solutions for this task. I see a few tools in the wiki but I'm not sure which one is best suited for this situation.\n  \n\n    Any solutions or guides you can recommend? I'd prefer not to enable dedup on my primary pool, but if that's the best option then I'll likely just create a secondary pool for this specific task."},
{"Title": "Message Board Posts", "Author": "u/Expensive_Elk_3618", "Content": "I am trying to figure out how to download all of the message board posts in a certain category along with all of the responses.  I can get the first level done but not every level with responses.  I've tried HTTrack without success.  Years ago I used to do this sort of thing and it wasn't all that hard to figure out but I am older and everything is a little stricter. :-) So, I would need the easiest tool.  Thanks for any advice you can offer.   Here is one of the sites.  \nhttps://www.genealogy.com/forum/surnames/topics/reed/"},
{"Title": "The.tnk.loft Instagram profile is about to be deleted - best way to archive everything?", "Author": "u/studioviper", "Content": "As the title says, the fantastic and amazing the.tnk.loft Instagram account is about to be deleted. A lot of really great and inspiring content will be lost forever. Is there an easy way to back everything up? Thanks!"},
{"Title": "Why is fluid RAID not more widely adopted by NAS makers?", "Author": "u/digitalanalog0524", "Content": "Synology and Terramaster both allow for fluid RAID setups (SHR and TRAID). I understand there is no black magic here and both are just using clever partitioning and a mix of RAID types. How come QNAP and Asustor do not offer these out of the box? I struggle to understand how Terramaster could out-innovate those two companies."},
{"Title": "Weird Method to Check Legitimacy of Drives", "Author": "u/miko-zee", "Content": "So I recommended a seller to my brother who is highly regarded as providing mostly legitimate drives. The problem is they seem to be of varying quality almost like shucking a drive. Sometimes they're totally new, sometimes unused old stock and sometimes manufacturer refurbished.\n  \n\n    My brother got a years old stock that had zero on power hours.\n  \n\n    However, a review of the seller suggested the following methodology. They were reviewing a 12TB Exos\n  \n\n    \"According to my tests, this drive is legit. I was able to:\n  \n\n\n\n\n\n    Verify the serial number at the Seagate website-  - - -    - Format the drive into 11 partitions.\n  \n\n\n\n\n\n    Put files into the first and last 2 partitions and was able to read back the files.\n  \n\n\n\n\n\n    Note that the drive has 11,175.98 GB of actual free space. The missing 825 GB may have been allocated to the file mapping table.\"\n  \n\n    Why do you need to partition it n-1 TB times then write data on the first and last partition? Is this even sound? I think they suggested it because it's quicker and more painless than stress testing the whole drive for a legitimacy test.\n  \n\n    EDIT. I want to clarify I know the scam of declaring high capacities using a smaller capacity medium. Also most of these drives usually have valid warranties just in a different region when checked via the their respective manufacturers website even the refurbished ones."},
{"Title": "Transport 3.5\" HDD with tray weekly in small casing - can't re-use packaging forever", "Author": "u/No-Balance-8038", "Content": "I want basically a similar small case that allows for a 3.5\" with tray which is 17cm long, but as small and portable! I will get a bigger antistatic bag still. The issue is that cardboard will wear down.\nI looked into Pelican cases and they are just too big to fit in my backpack!\n  \n\n    I already have 8 of \nhttps://www.amazon.de/gp/product/B01JOCHO80/\n but they do not have enough space for a 3.5\" with tray on ( ~ 170mm)\n  \n\n    Dimensions are:\n  \n\n\n\n\n\n    7cm height\n  \n\n\n\n\n\n    20cm length\n  \n\n\n\n\n\n    13cm width\n  \n\n\n\n\nhttps://preview.redd.it/transport-3-5-hdd-with-tray-weekly-in-small-casing-cant-re-v0-pfl9kd0ytc6d1.png\nhttps://preview.redd.it/transport-3-5-hdd-with-tray-weekly-in-small-casing-cant-re-v0-uifnnwg2uc6d1.png"},
{"Title": "How to upgrade windows PC using with storage spaces, 6 hdds", "Author": "u/OC2k16", "Content": "Hello,\n  \n\n    I currently run a PC with win 10, older hardware. I have 6 3TB hdds, set up using storage spaces, two-way mirror, so 9TB total. They are all connected via sata.\n  \n\n    I want to upgrade to a different PC, and transfer the data to newer hard drives.\n  \n\n    Will it be as simple as: disconnecting some drives, connecting new ones, transfering the files to new hdds, and connecting new hdds to new PC? Or will windows get angry with that?\n  \n\n    I am going from win 10 to win 11 if that matters.\n  \n\n    Perhaps I should just transfer the files to the single drives, put those in the new PC, then add their backups and do the storage spaces then?\n  \n\n    Any advice would be appreciated!"},
{"Title": "Best cooled NVME enclosure", "Author": "u/JaL3J", "Content": "Suggestions for best cooled USB-C - NVME M.2 enclosure?\nLooking for:\n  \n\n\n\n\n\n\n\n\n\n\n\n    Single or dual NVME M.2 full length enclosure\n  \n\n\n\n\n\n\n\n\n\n    2. Cooling fan in housing and good heat transfer\n  \n\n\n\n\n\n    3. Low cost, 20-50usd, not 150+.\n  \n\n\n\n\n\n    4. USB-C 3.2 gen2 controller (10Gb/s or more).\n  \n\n\n\n\n\n    5. Preferrably a minimalistic design\n  \n\n\n\n\n\n    I've seen a couple of products on amazon etc., but usually too large and nothing with dual stick. Low profile housing is optimal.\n  \n\n    What would you suggest?"},
{"Title": "Need help setting up pool", "Author": "u/Kriznick", "Content": "Hey, so new baby data hoarder here, built a pool using Windows Storage Spaces and 12hdds and 4ssds I had laying around. It's working fine so far, but I can't help but wondering if my performance and pool efficency is suffering.\n  \n\n    So I've got:\n  \n\n    1tb ssd x4\n  \n\n    4tb hdd x1 // 3tb hdd x2 // 1tb hdd x1 // .75tb hdd x4 // .64tb hdd x1 // .5tb hdd x3\n  \n\n    Totaling 4tb ssd and 16.4tb hdd. HOWEVER, I'm only getting 6tb of storage I THINK.\n  \n\n    I'm set to parity, which I thought was supposed to be more efficient for the storage, but it doesn't math out.... I've heard about this SHR-2 thing, but I have no idea about using NAS or whatever. Storage Spaces was nice because it was pretty push-pull click-click. Is there another simple setup program that's more efficient? I'm getting 1.7mb/s write speed, and thought it should have been faster since it's writing to multiple disk spaces simultaneously rather than just 1 drive...\n  \n\n    Am I just dumb and should just stick with what I have?\n  \n\n    I've tried researching it, but I can't make heads or tails of it.\n  \n\n    Thanks yall"},
{"Title": "10 year old Cold storage 4TB HGST drive 4 weak sectors 1200 bad sectors? User error ? Expert advice needed 🫠", "Author": "u/Positive_Minds", "Content": "This 4TB drive and also my 10 year old 2TB HGST drive. have popped up bad and weak sectors , they haven’t been switched on in 10 years ..\n  \n\n    So was this basically my fault for not powering them up every and using disk fresh etc or is it just a case of age related demagnetisation or mechanical failure ? I just don’t get as most of my 10 year old western digital drives or seagate have been fine when tested after 10 years\n  \n\n    I’m seriously thinking of doing yearly refreshes of my drives from now on .. My other question is can the weak sectors be reallocated or removed ?\n  \n\n    I read this on super user , is this true ?\n  \n\n    In order to keep the data signal from fading, you need to re-write the data. This is often known as “hard disk maintenance”, and should be done 3 or 4 times a year. While it does not prevent data from being corrupted or deleted, it can go a long way towards ensuring that the magnetic signal does not fade away completely. The way it works is to read every sector of the drive, and then re-write the data found there, provided the drive reported no errors. If this is done on a regular basis, the magnetic signal of every part of the drive will be refreshed long before the signal fades or becomes ambiguous. This technique also gives the drive controller the opportunity to decide whether to retire any sectors that are becoming too unreliable, before any important data is lost.\n  \n\n    Magnetic Field Breakdown\n  \n\n    Most sources state that permanent magnets lose their magnetic field strength at a rate of 1% per year. Assuming this is valid, after ~69 years, we can assume that half of the sectors in a hard drive would be corrupted (since they all lost half of their strength by this time). Obviously, this is quite a long time, but this risk is easily mitigated - simply re-write the data to the drive. How frequently you need to do this depends on the following two issues (I also go over this in my conclusion).\n  \n\n    To periodically refresh the data on the drive, simply transfer it to another location, and re-writing it back to the drive. That way, the magnetic domains in the physical disk surface will be renewed with their original strength (because you just re-wrote the files back to the disk). If you're concerned about filesystem corruption, you can also format the disk before transferring the data back.\n  \n\n    You can also help to avoid this issue by archiving your data with recovery data and error correction when you put the data onto the drive. Many archive formats support the inclusion of data recovery algorithms, so even if you have a few corrupted sectors, you can still re-build the lost data.\n  \n\n    Depending on the priority of the data you've stored, you may want to refresh the hard disk more often. If it is essential data, I would recommend no less then 2 years at maximum. If you can withstand some chance of minor data loss (e.g. a few corrupted sectors here and there), go with 5 years. It doesn't take long to copy the data off the drive, and copy it back.\n  \n\n    One thing not considered is the servo tracks and markings. These are written one time at the factory and never again (on modern disks). No amount of re-writes by the user or so-called low-level formatting freshens these. Once they fade, they fade!\n  \n\n    It's different with the first stepper motor disks of the 80's. They don't have servo tracks and a low-level format writes ALL of the bits - fresh."},
{"Title": "How unlimited is Flickr Pro?", "Author": "u/jammsession", "Content": "A friend of mine is a photographer. He currently uses the good old \"put all photos onto one external HDD and labeling them\" method for storing his files.\n  \n\n    He now got to a point where he is scared of loosing data and asked about Flickr.\n  \n\n    So I was wondering if anyone else here has around 10TB of photos on Flickr Pro. Is it really unlimited? Price seems almost too good to be true."},
{"Title": "Help on selecting file system / software raid solution", "Author": "u/Altruistic-Coyote731", "Content": "Hi, I know this issue has been discussed to death but pleas bear with me!\n  \n\n    I am running a server for backups, metabase (BI Tool) and some other apps. I have 4 x 4 tb ssd drives. Right now I use Minio for data management as it was the easiest to setup but I have 2 issues with it:\n  \n\n\n\n\n\n    Memory usage: I have only 16gb available and Minio uses most of it during large syncs.\n  \n\n\n\n\n\n    For most of my use cases I need the fs directly eg. samba or nfs, databases, etc. You can mount  S3 buckets as drives but that just feels redundant.\n  \n\n\n\n\n\n    I researched the topic a bit and came up with 3 potential options described below that meet my requirements.\n  \n\n\nI would greatly appreciate feedback form the community on:\n\n\n\n\n\n\n\n    What is the memory usage like?\n  \n\n\n\n\n\n    Ease of setup?\n  \n\n\n\n\n\n    Ease of recovery in case of disk failure? (note that I have never had to deal with raid recovery before so total noob!)\n  \n\n\n\n\n\n    Anything i missed out from the pros/cons table below\n  \n\n\n\n\n\n\n\n\n\n\n\n            Options\n          \n\n            Option 1: mdadm RAID10 + xfs\n          \n\n\nOption 2: mdadm RAID10 + btrfs\n\n\n\n\nOptions 3: btrfs RAID10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n              Pros\n            \n\n              mdadm and xfs are stable solutions; good performance;\n            \n\n              snapshots\n            \n\n              snapshots; native RAID; healing;\n            \n\n\n\n\n\n              Cons\n            \n\n              missing features such as snapshots\n            \n\n              ???\n            \n\n              reliability of btrfs RAID\n            \n\n\n\n\n\n\n\n    I didn't include ZFS because, to my understanding, it's RAM intensive and has a seep learning curve.\n  \n\n    I am open to other solutions if they make more sense as well! :)"},
{"Title": "External Hard Drive for High Humidity Conditions", "Author": "u/BrEichen", "Content": "I'm gonna be living in a peat swamp forest in Borneo for a year and am looking to bring a hard drive to store movies, TV, and photos on as I will not have reliable internet access. Where I'll be the humidity is so high clothes and technology are stored in plastic bins w/ silica packets when not in use. I was wondering if anyone could recommend an external hard drive that could hold up to these conditions (if such a thing even exists). Sorry if this is a dumb or already answered question, pretty new to this stuff. Thanks!"},
{"Title": "I bought a sas controller LSI 9240-8i SAS SATA RAID Controller Card drives", "Author": "u/Unusual-Ingenuity831", "Content": "I need help installing it i bought this to use my sas hard drive but i have plugged it in and everything and it still wont work so i need help"},
{"Title": "Samsung SSD cache sizes for 1TB", "Author": "u/madurbad", "Content": "Looking to buy a Samsung SSD. I only have the money for 1TB, but I'm not sure which model to get given the prices (I can only afford 1TB). Obviously I want performance to be the best, but that largely comes down to cache size between the Samsung T7, T7 shield, and T9. Unfortunately, I can't take advantage of USB 3.2x2.\n  \n\n    My question is: what are the cache sizes for each of these SSDs with their 1TB models (I heard cache sizes differ with storage capacity)?\n  \n\n    If theyre all the same, I'm looking to save money and just buy the T7.\n  \n\n    Thanks"},
{"Title": "How to download the video content from Microsoft Lean On-demand training?", "Author": "u/HardLearner01", "Content": "How to download the video content of this site?\n  \n\n\nDP-100 Design a machine learning solution (1 of 6) | Microsoft Learn"},
{"Title": "Upgrading and future-proofing my Plex Media server & library setup, looking for advice", "Author": "u/Reasonable_Jelly9435", "Content": "TL;DR - Nearing storage cap on my current external HDD. Want to upgrade storage and reasonably future-proof as best as possible. Considering changing my setup from PC (Plex Media Server) + external HDD (media storage), to a mini PC (Plex) + DAS. Could use advice.\n\n\n\n    Hi, I've done some research on upgrading my current Plex / general media storage setup and I've come up with a plan that looks something like the below. Please share any constructive criticisms, tips, things I might have overlooked, etc. I want to do this right the first time around.\n  \n\n    Use case: 1-2 simultaneous 1080p streams, most clients will be able to directly play my mostly HEVC (h.265) content without needing to transcode. Not all, though, so transcoding option is nice. I have Plex Pass so HW transcoding is also an option.\n  \n\n    My current setup:\n  \n\n\n\n\n\n    PC \n[Plex Media Server]\n\n\n\n\n\n\n\n    External Hard drive (12TB) [\n~10TB personal media\n]\n  \n\n\n\n\n\n\n\n\n\n    What I'm thinking of moving to:\n  \n\n\n\n\n\n    Mini PC (\nBeelink Mini S12\n) \n[Plex Media Server]\n\n\n\n\n\n\n\n    DAS (\n4-bay QNAP\n)\n  \n\n\n\n\n\n    3.5 12TB HDD (shuck my current drive) [\n~10TB personal media\n]\n  \n\n\n\n\n\n    3.5 12TB HDD (buy a new one) [\nRAID backup?\n]\n  \n\n\n\n\n\n    empty (add a 12TB in future for more storage?)\n  \n\n\n\n\n\n    empty (add a 12TB in future for more storage?)\n  \n\n\n\n\n\n\n\n\n\n    If this looks good, I have a bonus question: How do I safely move my content on my current 12TB external hard drive to the DAS? Is it as simple as shucking the drive and installing in the DAS? I've also read that setting up RAID will wipe the drives; will it be necessary to buy a third 12TB drive before moving my media?\n  \n\n    Thanks in advance!"},
{"Title": "NVMe SSD based storage computer", "Author": "u/aes100", "Content": "If you were to build a storage computer based on NVMe SSDs, how would you do it? Nor datarate, nor storage space is priority. Just sheer number of NVMe SSDs... and you hate cables.\n  \n\n    Build#1: AMD Threadripper with PCIe to M.2 adapter cards. Because I think that is the only motherboard that has more than one or two PCIe slots. But Threadripper is overkill expensive for just storage and not worth it. I didn't do research on Intel side.\n  \n\n    Build#2: Get a server motherboard with lots of SATA ports and lots of SATA to M.2 adapters. Put the NVMe's in, and connect them to SATA ports. But you don't like cables.\n  \n\n    Build#3: Get a LattePanda Mu based on Intel N100 which they advertise a NAS carrier but I don't know if it exists yet or not. Or get a FriendlyELEC CM3588 based on Rockchip. You are free of cables, but are you gonna regret accessing the data on there because it is slow? Or is it actually fast enough to, I don't know, watch a video from it?\n  \n\n    What do you think about the above builds? What downs and ups do you think they have? How would you do it? Why?"},
{"Title": "Can storage have a maximum amount of storage space?", "Author": "u/Card_Boxy", "Content": "Sorry if this question was worded weirdly, but I am looking to buy a new hard drive for my pre-built Lenovo IdeaCentre Gaming 5 17IAB7. I noticed that, according to the specs on the Product Specifications Reference it could only fit 2 3.5\" HDDs with a maximum of 2 TB, and 1 M.2 SSD with a max of 1 TB.\n  \n\n    What would happen if I were to buy and install a HDD / SSD larger than the reported maximum on the specifications sheet?\n  \n\n    Here's the actual pages I was looking at.\n  \n\n\nhttps://psref.lenovo.com/Detail/IdeaCentre/IdeaCentre_Gaming_5_17IAB7?M=90T00003US\n\n\n\n\nhttps://psref.lenovo.com/Product/IdeaCentre/IdeaCentre_Gaming_5_17IAB7\n\n\n\n    Thanks in advance for your times."},
{"Title": "Macrium Reflect backup to NVMe drive in USB-C enclosure is very slow? Normal copying to same drive is fast...", "Author": "u/ozzuneoj", "Content": "Relevant Specs:\n  \n\n    Windows 10 22H2\n  \n\n    Ryzen 7 5800X3D\n  \n\n    Gigabyte X570 Aorus Elite\n  \n\n    64GB DDR4-3600\n  \n\n    Soldigm P44 Pro 2TB NVMe Gen4\n  \n\n    Macrium Reflect Free 8\n  \n\n    To keep things simple, I'm just going to focus on making a macrium image of my system partitions (C: and a couple without letters; about 100GB of data total) as a backup . I have been doing this for years but lately I've been trying to streamline and speed up the process.\n  \n\n    I have a SATA dock installed inside my system (straight SATA, no USB), and when I slot in my old 1TB Crucial MX500 drive, I can run the macrium backup in about 6 minutes.\n  \n\n    I have lots of spare NVMe drives, so I got one of these Orico 10Gbps USB 3.2 NVMe enclosures (\nhttps://www.amazon.com/ORICO-NVMe-Thunderbolt-Compatible-SSDs-PWM2-BK/dp/B0BJ23JTXX\n) several months ago and it has worked fine for transferring files. However, when I run the same macrium backup as before to this NVMe drive it seems to hang for a second, then shows an estimate of 6 minutes, then within a few seconds the transfer rate drops from 1+gbps to under 100mbps and the estimated time shoots up to 55 minutes.\n  \n\n    You would think that the symptoms point to a crappy USB enclosure or a problem with the drive... but when I copy the same image file directly from the SATA drive to the NVMe drive manually in Windows the transfer rate is pegged at over 550MB\\sec (megabytes) and it is done in just over a minute.\n  \n\n    Is there something I can adjust in Macrium or elsewhere that would fix this seeming incompatibility with this NVMe USB enclosure? I'd love to use it (to free up my old 1TB MX500) but having to wait nearly 10 times as long for backups is unacceptable.\n  \n\n    Thank you for any help you can offer."},
{"Title": "Modular NAS build", "Author": "u/Mother_Occasion_8076", "Content": "No content"},
{"Title": "Extension cable to disable Power Disable Feature on HDD?", "Author": "u/feedmememes", "Content": "I just purchased this HDD of Amazon: \nhttps://www.amazon.com/gp/product/B08T3PBV57/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&th=1\n\n\n\n    However it did not come with the power extension cable mentioned in the product description. I have purchased this drive before and it would not work without that cable, so it is necessary for me to get one for the HDD to work. My question is what would I search for the get the correct part? Would any sata-to-sata power extension work or would it need to have some special spec? I've read a 4-pin Molex to SATA connector might be the solution, but I would like to confirm before purchasing because I am dumb!! Something like this for example:\nhttps://www.amazon.com/Cable-Matters-3-Pack-Molex-Power/dp/B00STNUB04/ref=sr_1_2?crid=B3ZGL1OM3IR1&dib=eyJ2IjoiMSJ9.f9jru-Gy4n_1s6sxvx6tecrDs0kKyQc_KXFNnctPSyGpgk3wiTyXQRVjv8latROCZFMth35JZj6AzNa09K_WespKmumHEQjA1Qn9tuzw8MBtUCX9qyoxPfAfS1R9c3JLDgIR1NHveuutkNGIKTrnouyP5DBd2e2yp3U9bkzTz5b_jPWn4NWf9pusLWEVS3OvqcRsb74HYfa7bE5vtR5EWmod_f3B-fJJnotQO7qTLbE.4mkQvoblx472TPQkw3pPm3UzP8ULyibyZTNH-zpyBg4&dib_tag=se&keywords=Sata-to-sata+power+adapter+cable&qid=1718302912&sprefix=sata-to-sata+power+adapter+cable+%2Caps%2C84&sr=8-2\n\n\n\n    Or if there are any other solutions that would be helpful too.\n  \n\n    Sorry for noob question and thank you in advanced for any help!"},
{"Title": "How do you go about pruning your hoard?", "Author": "u/Clive1792", "Content": "Personally I feel snowed under with what I've got. There's countless files on my PC scattered everywhere. Documents, pictures (probably in the 100,000s), audio files, video files. It's most certainly not organised at all, it's scattered all over the hard drives on this PC in various folders & folders of folders.\n  \n\n    But to make it better I had no real backup plan. I'd just drag & drop and then not really remember what I'd backed up and what I hadn't so then I'd buy a new hard drive & make another copy because the last drive was fairly full.\n  \n\n    I now have a number of drives that surely have many multiples of various single files.\n  \n\n    My end goal is I would like some organisation rather than random files & folders scattered here there & everywhere. I'd like to get rid of the multiple duplicate files & also delete files I no longer want/need.\n  \n\n    Have any of you attacked this kind of task? Any tips or do you really just do it file-by-file? Which to be honest with what I've got & the fact I only have limited time outside of work, this is going to take me many months if not 12months plus .... and that's if I get stuck in & stay focused doing it day in day out."},
{"Title": "Need help with magazine scanning - resolution vs size", "Author": "u/MyBallsSmellFruity", "Content": "So I'm scanning magazines at 300 dpi.  Any less, and the images look kind of cruddy.  Of course, the image size is pretty large, so I'm having to batch convert them to manually make the image height 1200 (width is auto calculated).\n  \n\n    Is this pretty much the only way to get both decent quality and an acceptable image size?  The actual filesize difference in the PDFs is pretty noticeable - and significant when doing hundreds of magazines.\n  \n\n    Or is there an easier way that I just haven't stumbled across?"},
{"Title": "I'm 98% of the way there — help me across the finish line! (Syncing help)", "Author": "u/740990929974739", "Content": "MY FRIENDS!\n\n\n\n    I'm finally doing it. Bought a 12 TB External HDD + Backblaze (Computer Backup, not B2) so I can back up my scattered external drives to the big HDD and have that backup automatically to Backblaze.\n  \n\n    That should allow me, I hope, to finally delete files from my computer's SSD as well as my 3 other external SSDs that are all clogged up with old photos and videos. (I'm a photographer + videographer + audio engineer so I produce a lot of files — I'm \nout\n of working space and it's ruining my life!)\n  \n\n    My issue:\n  \n\n    I backed up 2/3 external SSDs to the big HDD about a month ago, but since then, new files have been added. I want to add only the new files to the HDD, without having to re-copy the entire folder, since I suspect that would also mess with Backblaze's file detection.\n  \n\n\nI think this means I need a file syncing and/or deduplication program.\n\n\n\n    I've seen FreeFileSync as a recommended service. Is this what I need?\n  \n\n    Thanks so much for your help!"},
{"Title": "First TrueNAS SCALE build - I'd like to begin doing weekly snapshots of Wikipedia. Any tips?", "Author": "u/saltyspicehead", "Content": "6 x 12TB Drives, Raidz2, NVMe L2ARC + SLOG etc etc etc roughly 45 TB to work with.\n  \n\n    I'd like to start by creating a weekly Wikipedia backup job to track change history. I'm familiar enough about storage tech to know that this should be possible without consuming a new ~120GB of storage every week, since only the delta will actually consume any disk space. However, I'm not familiar enough with non-enterprise solutions for this task. I see a few tools in the wiki but I'm not sure which one is best suited for this situation.\n  \n\n    Any solutions or guides you can recommend? I'd prefer not to enable dedup on my primary pool, but if that's the best option then I'll likely just create a secondary pool for this specific task."},
{"Title": "Message Board Posts", "Author": "u/Expensive_Elk_3618", "Content": "I am trying to figure out how to download all of the message board posts in a certain category along with all of the responses.  I can get the first level done but not every level with responses.  I've tried HTTrack without success.  Years ago I used to do this sort of thing and it wasn't all that hard to figure out but I am older and everything is a little stricter. :-) So, I would need the easiest tool.  Thanks for any advice you can offer.   Here is one of the sites.  \nhttps://www.genealogy.com/forum/surnames/topics/reed/"},
{"Title": "The.tnk.loft Instagram profile is about to be deleted - best way to archive everything?", "Author": "u/studioviper", "Content": "As the title says, the fantastic and amazing the.tnk.loft Instagram account is about to be deleted. A lot of really great and inspiring content will be lost forever. Is there an easy way to back everything up? Thanks!"},
{"Title": "Why is fluid RAID not more widely adopted by NAS makers?", "Author": "u/digitalanalog0524", "Content": "Synology and Terramaster both allow for fluid RAID setups (SHR and TRAID). I understand there is no black magic here and both are just using clever partitioning and a mix of RAID types. How come QNAP and Asustor do not offer these out of the box? I struggle to understand how Terramaster could out-innovate those two companies."},
{"Title": "Weird Method to Check Legitimacy of Drives", "Author": "u/miko-zee", "Content": "So I recommended a seller to my brother who is highly regarded as providing mostly legitimate drives. The problem is they seem to be of varying quality almost like shucking a drive. Sometimes they're totally new, sometimes unused old stock and sometimes manufacturer refurbished.\n  \n\n    My brother got a years old stock that had zero on power hours.\n  \n\n    However, a review of the seller suggested the following methodology. They were reviewing a 12TB Exos\n  \n\n    \"According to my tests, this drive is legit. I was able to:\n  \n\n\n\n\n\n    Verify the serial number at the Seagate website-  - - -    - Format the drive into 11 partitions.\n  \n\n\n\n\n\n    Put files into the first and last 2 partitions and was able to read back the files.\n  \n\n\n\n\n\n    Note that the drive has 11,175.98 GB of actual free space. The missing 825 GB may have been allocated to the file mapping table.\"\n  \n\n    Why do you need to partition it n-1 TB times then write data on the first and last partition? Is this even sound? I think they suggested it because it's quicker and more painless than stress testing the whole drive for a legitimacy test.\n  \n\n    EDIT. I want to clarify I know the scam of declaring high capacities using a smaller capacity medium. Also most of these drives usually have valid warranties just in a different region when checked via the their respective manufacturers website even the refurbished ones."},
{"Title": "Transport 3.5\" HDD with tray weekly in small casing - can't re-use packaging forever", "Author": "u/No-Balance-8038", "Content": "I want basically a similar small case that allows for a 3.5\" with tray which is 17cm long, but as small and portable! I will get a bigger antistatic bag still. The issue is that cardboard will wear down.\nI looked into Pelican cases and they are just too big to fit in my backpack!\n  \n\n    I already have 8 of \nhttps://www.amazon.de/gp/product/B01JOCHO80/\n but they do not have enough space for a 3.5\" with tray on ( ~ 170mm)\n  \n\n    Dimensions are:\n  \n\n\n\n\n\n    7cm height\n  \n\n\n\n\n\n    20cm length\n  \n\n\n\n\n\n    13cm width\n  \n\n\n\n\nhttps://preview.redd.it/transport-3-5-hdd-with-tray-weekly-in-small-casing-cant-re-v0-pfl9kd0ytc6d1.png\nhttps://preview.redd.it/transport-3-5-hdd-with-tray-weekly-in-small-casing-cant-re-v0-uifnnwg2uc6d1.png"},
{"Title": "How to upgrade windows PC using with storage spaces, 6 hdds", "Author": "u/OC2k16", "Content": "Hello,\n  \n\n    I currently run a PC with win 10, older hardware. I have 6 3TB hdds, set up using storage spaces, two-way mirror, so 9TB total. They are all connected via sata.\n  \n\n    I want to upgrade to a different PC, and transfer the data to newer hard drives.\n  \n\n    Will it be as simple as: disconnecting some drives, connecting new ones, transfering the files to new hdds, and connecting new hdds to new PC? Or will windows get angry with that?\n  \n\n    I am going from win 10 to win 11 if that matters.\n  \n\n    Perhaps I should just transfer the files to the single drives, put those in the new PC, then add their backups and do the storage spaces then?\n  \n\n    Any advice would be appreciated!"},
{"Title": "Best cooled NVME enclosure", "Author": "u/JaL3J", "Content": "Suggestions for best cooled USB-C - NVME M.2 enclosure?\nLooking for:\n  \n\n\n\n\n\n\n\n\n\n\n\n    Single or dual NVME M.2 full length enclosure\n  \n\n\n\n\n\n\n\n\n\n    2. Cooling fan in housing and good heat transfer\n  \n\n\n\n\n\n    3. Low cost, 20-50usd, not 150+.\n  \n\n\n\n\n\n    4. USB-C 3.2 gen2 controller (10Gb/s or more).\n  \n\n\n\n\n\n    5. Preferrably a minimalistic design\n  \n\n\n\n\n\n    I've seen a couple of products on amazon etc., but usually too large and nothing with dual stick. Low profile housing is optimal.\n  \n\n    What would you suggest?"},
{"Title": "Need help setting up pool", "Author": "u/Kriznick", "Content": "Hey, so new baby data hoarder here, built a pool using Windows Storage Spaces and 12hdds and 4ssds I had laying around. It's working fine so far, but I can't help but wondering if my performance and pool efficency is suffering.\n  \n\n    So I've got:\n  \n\n    1tb ssd x4\n  \n\n    4tb hdd x1 // 3tb hdd x2 // 1tb hdd x1 // .75tb hdd x4 // .64tb hdd x1 // .5tb hdd x3\n  \n\n    Totaling 4tb ssd and 16.4tb hdd. HOWEVER, I'm only getting 6tb of storage I THINK.\n  \n\n    I'm set to parity, which I thought was supposed to be more efficient for the storage, but it doesn't math out.... I've heard about this SHR-2 thing, but I have no idea about using NAS or whatever. Storage Spaces was nice because it was pretty push-pull click-click. Is there another simple setup program that's more efficient? I'm getting 1.7mb/s write speed, and thought it should have been faster since it's writing to multiple disk spaces simultaneously rather than just 1 drive...\n  \n\n    Am I just dumb and should just stick with what I have?\n  \n\n    I've tried researching it, but I can't make heads or tails of it.\n  \n\n    Thanks yall"},
{"Title": "10 year old Cold storage 4TB HGST drive 4 weak sectors 1200 bad sectors? User error ? Expert advice needed 🫠", "Author": "u/Positive_Minds", "Content": "This 4TB drive and also my 10 year old 2TB HGST drive. have popped up bad and weak sectors , they haven’t been switched on in 10 years ..\n  \n\n    So was this basically my fault for not powering them up every and using disk fresh etc or is it just a case of age related demagnetisation or mechanical failure ? I just don’t get as most of my 10 year old western digital drives or seagate have been fine when tested after 10 years\n  \n\n    I’m seriously thinking of doing yearly refreshes of my drives from now on .. My other question is can the weak sectors be reallocated or removed ?\n  \n\n    I read this on super user , is this true ?\n  \n\n    In order to keep the data signal from fading, you need to re-write the data. This is often known as “hard disk maintenance”, and should be done 3 or 4 times a year. While it does not prevent data from being corrupted or deleted, it can go a long way towards ensuring that the magnetic signal does not fade away completely. The way it works is to read every sector of the drive, and then re-write the data found there, provided the drive reported no errors. If this is done on a regular basis, the magnetic signal of every part of the drive will be refreshed long before the signal fades or becomes ambiguous. This technique also gives the drive controller the opportunity to decide whether to retire any sectors that are becoming too unreliable, before any important data is lost.\n  \n\n    Magnetic Field Breakdown\n  \n\n    Most sources state that permanent magnets lose their magnetic field strength at a rate of 1% per year. Assuming this is valid, after ~69 years, we can assume that half of the sectors in a hard drive would be corrupted (since they all lost half of their strength by this time). Obviously, this is quite a long time, but this risk is easily mitigated - simply re-write the data to the drive. How frequently you need to do this depends on the following two issues (I also go over this in my conclusion).\n  \n\n    To periodically refresh the data on the drive, simply transfer it to another location, and re-writing it back to the drive. That way, the magnetic domains in the physical disk surface will be renewed with their original strength (because you just re-wrote the files back to the disk). If you're concerned about filesystem corruption, you can also format the disk before transferring the data back.\n  \n\n    You can also help to avoid this issue by archiving your data with recovery data and error correction when you put the data onto the drive. Many archive formats support the inclusion of data recovery algorithms, so even if you have a few corrupted sectors, you can still re-build the lost data.\n  \n\n    Depending on the priority of the data you've stored, you may want to refresh the hard disk more often. If it is essential data, I would recommend no less then 2 years at maximum. If you can withstand some chance of minor data loss (e.g. a few corrupted sectors here and there), go with 5 years. It doesn't take long to copy the data off the drive, and copy it back.\n  \n\n    One thing not considered is the servo tracks and markings. These are written one time at the factory and never again (on modern disks). No amount of re-writes by the user or so-called low-level formatting freshens these. Once they fade, they fade!\n  \n\n    It's different with the first stepper motor disks of the 80's. They don't have servo tracks and a low-level format writes ALL of the bits - fresh."},
{"Title": "How unlimited is Flickr Pro?", "Author": "u/jammsession", "Content": "A friend of mine is a photographer. He currently uses the good old \"put all photos onto one external HDD and labeling them\" method for storing his files.\n  \n\n    He now got to a point where he is scared of loosing data and asked about Flickr.\n  \n\n    So I was wondering if anyone else here has around 10TB of photos on Flickr Pro. Is it really unlimited? Price seems almost too good to be true."},
{"Title": "Help on selecting file system / software raid solution", "Author": "u/Altruistic-Coyote731", "Content": "Hi, I know this issue has been discussed to death but pleas bear with me!\n  \n\n    I am running a server for backups, metabase (BI Tool) and some other apps. I have 4 x 4 tb ssd drives. Right now I use Minio for data management as it was the easiest to setup but I have 2 issues with it:\n  \n\n\n\n\n\n    Memory usage: I have only 16gb available and Minio uses most of it during large syncs.\n  \n\n\n\n\n\n    For most of my use cases I need the fs directly eg. samba or nfs, databases, etc. You can mount  S3 buckets as drives but that just feels redundant.\n  \n\n\n\n\n\n    I researched the topic a bit and came up with 3 potential options described below that meet my requirements.\n  \n\n\nI would greatly appreciate feedback form the community on:\n\n\n\n\n\n\n\n    What is the memory usage like?\n  \n\n\n\n\n\n    Ease of setup?\n  \n\n\n\n\n\n    Ease of recovery in case of disk failure? (note that I have never had to deal with raid recovery before so total noob!)\n  \n\n\n\n\n\n    Anything i missed out from the pros/cons table below\n  \n\n\n\n\n\n\n\n\n\n\n\n            Options\n          \n\n            Option 1: mdadm RAID10 + xfs\n          \n\n\nOption 2: mdadm RAID10 + btrfs\n\n\n\n\nOptions 3: btrfs RAID10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n              Pros\n            \n\n              mdadm and xfs are stable solutions; good performance;\n            \n\n              snapshots\n            \n\n              snapshots; native RAID; healing;\n            \n\n\n\n\n\n              Cons\n            \n\n              missing features such as snapshots\n            \n\n              ???\n            \n\n              reliability of btrfs RAID\n            \n\n\n\n\n\n\n\n    I didn't include ZFS because, to my understanding, it's RAM intensive and has a seep learning curve.\n  \n\n    I am open to other solutions if they make more sense as well! :)"},
{"Title": "Two 2TB external HDDs or one 4TB external HDD?", "Author": "u/Fonti_Sgasao", "Content": "Hey there, I need an external HDD just to store data, I would buy a 4TB HDD (probably Toshiba Canvio, never had a problem with it) but I heard that it's more likely to suffer data loss than a 2TB HDD, is it true?"},
{"Title": "Rsync Ran With Read Only Destination", "Author": "u/klnadler", "Content": "Hi all, I was transfering some data from my Unraid to an external drive mounted as an unassigned drive. I had to tweak the command a little to work with the permissions due to the drive being ExFat. After the transfer I realized the drive was set to read only through the Unassigned Disk settings, but the files transferred? How and why?\n  \n\n    Command used:\n  \nrsync -avPh --no-owner --no-group --no-perms"},
{"Title": "What drives do you recommend?", "Author": "u/Endeavour1988", "Content": "I currently have 3x 6TB Western Digital Golds for my media server.  2x Host content and one for spare (backups).\n  \n\n    * I do back up externally/offsite\n  \n\n    I've always had a bad history with Seagate but some of my external drives have been solid which are Seagate so I'm open minded.  Can anyone recommend from experience what brands to go for?  The Golds are 7 year old now so I would like to look at replacing 2x with 12TB and possibly the third with something larger like 16TB.  Which should hopefully see me through another 6 years."},
{"Title": "Youtube channel downloader and sync for 1000s of videos?", "Author": "u/No_Doubt8973", "Content": "Hi first of all, I am on windows but I can install linux on a virtual machine.\n  \n\n    I have about 50 channels I am downloading videos from manually and it's so tiring I stopped for a year. I started again and found a lot of channels deleted videos or the channel is closed. And some of the channels have since uploaded thousands of videos.\n  \n\n    I used to manually go on youtube on my pc and grab the links but it stops loading after 1000 videos or it overloaded the chrome and crash. Would a channel downloader be able to download thousands of videos from one channel?\n  \n\n    How does the leading youtube downloaders know which videos were has been downloaded so that it doesn't download it again?\n  \n\n    Which program allows me to select preferred codec for a specific resolution?\n  \n\n    If it is possible I want to avoid av1 codec because my tablet can't play it unless it's 8k because youtube uses only av1 on 8k resolution, I would play it on my pc when I upgrade my video card black friday."},
{"Title": "Dreams and Aspirations", "Author": "u/thenazgul80", "Content": "Do I have this right? I want to build a nas to store my digital library and stream it to my and my family's devices. Currently relying on 5 external 2.5\" drives and windows media share. However I can't outright purchase something like a Synology nas due to cost. I have my old PC collecting dust. Amd fx 4100 Radeon 7700hd and 8 gb of ddr3 ram. Here is the plan. Undevolt the fx4100 to the lowest it can go. Diy mod my Asus Vento a8 PC case for cooling and dust prevention. Buy a 16-20 TB drive and start the nas. Once I can afford a second drive i plan on using them in raid 1. Once a 3rd drive is added I want to use them in raid 5. Over all I want to end up with 40-60tb of useable storage with some redundancy and keep the external 2.5\" drives for backups. From what I can gather, truenas won't let me just add drives later on down the line. Is unRAID my only option if I want to start with the bare minimum and expand later on as I can afford more drives?"},
{"Title": "Need help with converting and compressing old VOB files", "Author": "u/martian_doggo", "Content": "So i have a bunch of old vob files, and i want to convert them to mkv or mp4 or something. I admit i don't have much experience in video manipulation but this is turning out to be exceptionally hard.\n  \n\n    I have around 5 movies which have 5 vob files each. The movies are around 4 hours long but around 12gb in size for barely 704x570p so i would love to concatinate and compress them.\n  \n\n    Now here's the problem, none of the video editor software is picking up the subtitles, not handbrake, not even ffmpeg but mpv somehow plays with the subtitles, though it takes mpv 10ish seconds to load the subtitles (weird ik).\n  \n\n    Now if i join 5 of the files to make 1 complete movie using ffmpeg, the subtitles stop loading.\n  \n\n    I have no idea what to do :(\n  \n\n    thanks"},
{"Title": "Backing up MacBook and multiple SSDs to single HDD", "Author": "u/cloudfortynine", "Content": "Hi everyone,\n  \n\n    I could use some guidance as I'm unsure what the simplest and low maintenance solution is for me. I'm looking to purchase an external HDD to backup the following:\n  \n\n\n\n\n\n    Macbook\n  \n\n\n\n\n\n    1TB SSD with my travel photos to be edited\n  \n\n\n\n\n\n    1TB SSD with my partners travel photos to be edited\n  \n\n\n\n\n\n    2TB SSD with music libraries for music production (Kontakt, Omnisphere etc)\n  \n\n\n\n\n\n    At first I was thinking of buying a 8TB external HDD and just backing everything up via Time Machine by having it all plugged in at once. However people online had also mentioned CCC and I'm unsure how that works? I was also hoping to back this all up to a portable HDD but it seems that 8TB HDDs can only be plugged in is that true? I'm not interested in NAS etc. as this is too complicated and expensive for me.\n  \n\n    As a sidetone I'm also planning on backing up to BackBlaze as well.\n  \n\n    Thanks in advance for any pointers!"},
{"Title": "Need help figuring how do archive part of a soon-to-die site", "Author": "u/Mode7GFX", "Content": "I posted this on stack overflow and they called me stupid (I am) and locked the question when someone was in the middle of actually helping me so I'm asking here because it's probably a more welcoming community for this sort of thing.\n  \n\n\nhttps://prcm.jp/list/akb48%20%E3%83%97%E3%83%AA\n\n\n\n    So this (formerly) huge Japanese image sharing site is shutting down in 2 weeks and my sister's begging me to archive at least some of it. I was trying to find a python script to automate it, cuz it will take me forever going one by one on tens of thousands of images, but I can't seem to find one that can archive this sort of website. It only goes by pages of 9 and the thumbnail images are shrunk down a ton so you have to click on the image twice to open the full size. Luckily it seems like every thumbnail image shares a name with the source image, but with an added suffix of the preview size, so I imagine it would be possible to have the script delete the underscore and re-add the .jpeg extension. As for going through pages, I'm not so sure on, but if I can input a list of URLs and just batch copy the original URL adding every page number (I know how to do this without a script), I could just use that.\n  \n\n    I was only going to download AKB48 related images, because most of these images aren't available anywhere else online, and soon won't be anywhere period. They're all old and thus fairly small, so I'm not too worried about it taking a long time to download.\n  \n\n    If anyone can direct me to a script that can do this or has some other mass image downloading method you're aware of, please let me know. Thanks!"},
{"Title": "ATA security doesn't play well with WD USB-SATA bridge devices", "Author": "u/Visual-East8300", "Content": "A couple of years ago, I bricked a 10TB WD easystore by issuing \"hdparm --security-set-pass\" on the USB drive, un-bricked it by plugging the HDD to another USB adapter then \"hdparm --security-disable\". Today, I bricked a 4TB WD easystore (2.5 inch), out of luck this time because inside the enclosure it's an USB on-board WD Blue drive.\n  \n\n    Both are using ASMedia ASM1151W.\n  \n\n    Does anyone have ideas how to recover from this? Or it's not worth the time trying to fix?"},
{"Title": "Looking for an alternative to dban to wipe an old computer with SSD", "Author": "u/ilovecokeslurpees", "Content": "I have an old computer (turned it off 2.5 years ago but it was a mid-spec PC built in 2016 I bought second hand in 2017). I can barely boot it these days. I want to wipe the 1 TB SSD before throwing the whole PC into the trash or recycle or whatever. Most parts are unsalvageable. I used to use dban way back when but it appears to not have been updated in almost a decade. The PC is running Windows 10, but I would like a simple solution bootable from a USB to ensure complete data erasure. I tried ABAN but it couldn't detect anything. Any suggestions?"},
{"Title": "Building up my personal media server, and I have additional questions about sourcing storage", "Author": "u/TheXypris", "Content": "So I asked \nr/Plex\n a few days ago and got some really great advice\n  \n\n    One of which was to send me here\n  \n\n    So along side what I was told there I had more questions\n  \n\n    How is shucking more affordable than just buying the regular drive? And how do I actually find those deals\n  \n\n    Are Seagate drives really that bad?\n  \n\n    What is the general consensus on buying drives second hand off eBay or through a liquidation auction? Bad idea or risky at best?\n  \n\n    I'm assuming Facebook marketplace/Craigslist should be avoided, but is there any merit in looking there? Like if I find a second hand external I could shuck?\n  \n\n    How important are RPMs sata type and all that other non capacity info? What's good and what's bad? Tradeoffs?\n  \n\n    How long will a healthy high capacity drive realistically last? People keep saying raid is mandatory and act like drives fail because you look at them funny. I can't afford a raid array right now and anything I'm putting on it would be easily required if time consuming.\n  \n\n    Are there price monitoring sites I can use to keep an eye out for deals or sales?\n  \n\n    And where is the best place to get sata and power cables for the drives?"},
{"Title": "Attempting to digitize some Beta tapes, but getting this rainbow banding through the picture.", "Author": "u/hmhsbritannic12", "Content": "No content"},
{"Title": "Anyone know of a device that can easily back-up data portably off a memory card onto an SSD?", "Author": "u/Ok-Cartographer1745", "Content": "I bought a Wolverine 80gb like 15 years ago. You plug in a memory card (not specifically Sony Memory Stick. I mean like Compact Flash, SD Card, and so on), press a button, and it copies your card to a folder on the hard drive.\n  \n\n    But that think is old and low capacity and I probably can't upgrade the hard drive due to the form factor and firmware likely only allowing 80gb drives.\n  \n\n    Anyway, anyone know of a similar device that is more modern?  I want it to:\n  \n\n\n\n\n\n    be portable and battery powered (nothing huge and nothing that needs to be plugged in to work)\n  \n\n\n\n\n\n    have a large SSD (500 GB or more)\n  \n\n\n\n\n\n    be self sustained (I don't want to have to plug it into a PC nor Bluetooth it to my phone)\n  \n\n\n\n\n\n    accept at least SD cards (more slots would be nice, but not necessary)\n  \n\n\n\n\n\n    I mainly want to do it to easily hoard pictures off my camera, especially if I need to quickly empty out my more expensive fast cards\n  \n\n    Also, a link to show what I already have. I'm not the one selling it and I don't recommend buying it because it's so outdated and slow (and the battery probably doesn't work considering how old it is).  So don't consider this advertising.\n  \n\n\nhttps://www.ebay.com/itm/125748798949?_trkparms=amclksrc%3DITM%26aid%3D1110006%26algo%3DHOMESPLICE.SIM%26ao%3D1%26asc%3D266917%2C266785%26meid%3D0caf8ebbb6584b81a8ed70c03fd786fd%26pid%3D101875%26rk%3D1%26rkt%3D5%26sd%3D285760155205%26itm%3D125748798949%26pmt%3D1%26noa%3D1%26pg%3D2332490%26algv%3DSimplAMLv11WebTrimmedV3MskuWithLambda85KnnRecallV1V2V4ItemNrtInQueryAndCassiniVisualRankerAndBertRecallWithVMEV3CPCAutoWithCassiniEmbRecall%26brand%3DWolverine&_trksid=p2332490.c101875.m1851"},
{"Title": "Software to recover data from a formatted and written disk?", "Author": "u/lsgz3", "Content": "The disk has been formatted twice and written with New stuff. Is there any chance of recovering old files?"},
{"Title": "is this samsung 512 gb micro sd fake?", "Author": "u/UlisesDeveloper", "Content": "No content"},
{"Title": "BTRFS file sync over the internet through Tailscale, or traditional backups using Kopia or Restic?", "Author": "u/1000Zebras", "Content": "Hi,\n  \n\n    I've got a couple of drives running off of a couple of instances of Debian, one of which is at my house, and the other is at my brother's house. They're 14tb drives, currently containing ~4.7TB of data.\n  \n\n    I'd like to, ideally I think, keep the two drives/filesystems in sync over the internet, probably through Tailscale so no public exposure necessary. At the very least I'd like to have a solid, relatively up to date backup of all of the data that lives on the drive at my brother's house, backing up that of the one at house.\n  \n\n    What are my best options for doing so, and, if it were you, how would you go about setting things up?\n  \n\n    I'm thinking maybe btrfs snapshots over ssh using btrbkup (both drives are formatted using btrfs) is probably me best bet, but I've never used snapshots and not sure how easy it would be configure in this case. This would, of course, depend on the drives both being btrfs formatted, which I suppose okay, although I was also thinking maybe it's smarter to have just regular backups that are filesystem agnostic.\n  \n\n    My favorite straight backup tool these days is Kopia, so if I were to go the second route I'd probably be looking at using that, although I'm not opposed to going restic. The only problem with that is that I think Kopia can only backup to either an S3-compatible bucket (so maybe run minio on secondary sysem?), or through webDAV which I'd have to figure out how to configure on the machine at my brother's house, or to the local filesystem, in which case I could maybe mount the remote disk on the local machine at my place using sshfs, but that may introduce weirdness, or just be a bit too unstable.\n  \n\n    What would you do in a situation like mine? Do you have any experience in setting something like this scenario up and what potential pitfalls would you anticipate?\n  \n\n    Thank you for reading the somewhat lengthy post,\n  \n\n    I look forward to any insights.\n  \n\n    Kind Regards,\n  \n\n    LS"},
{"Title": "Buying drives from eBay?", "Author": "u/Seventeen-Oncelers", "Content": "I was considering buying a 10tb HDD on eBay and was wondering if this is considered a good place to buy? It's certified eBay refurbished, 30 day returns etc. Just curious on you guy's thoughts on buying hard drives on eBay."},
{"Title": "Cost Efficient Storage Revamp", "Author": "u/iLOLZU", "Content": "I'm want to get into archival with all the shenanigans with the Internet Archive and game preservation. I'm in need of a storage upgrade anyways. I have a Lian Li O11 with the 2x 3.5\" drive cage unpopulated and 2x 2.5\" HDDs (2.5TB total) installed, was thinking of getting a pair of 3.5\" HDDs & a pair of SATA SSDs. Considering 8TB Seagate Firecuda + 2TB Samsung 870s. I know higher capacity 3.5\" HDDs exist, but heard that buying a single high capacity drive is not worth while in terms of cost and data loss."},
{"Title": "Can my old (possibly infected?) digital camera’s SD card and/or photos transfer a virus to my iPhone via an adapter?", "Author": "u/knOn0", "Content": "Hello! (I’ve asked this already but wanted to widen the net of insight before I proceed)\n  \n\n    I have an old digital camera from 2009-2011. I recently bought a new charger for it, turned it on, and it works perfectly! When I first turned it on, I was able to see tons of old pictures that I’d forgotten about; now, I can see my old photos but any new photo that I try to view has the “File Error” message. I did buy an SD card adapter to put my photos from the SD card to my iPhone, and now I’m seeing a “content unavailable: files could not be opened due to an unknown error.” (The iPhone is an 11, IOS 17).\n  \n\n    Does my SD card have a virus? Do the photos on them have a virus? Should I get a brand new adapter and SD card?\n  \n\n    TYIA"},
{"Title": "document scanner with local file upload", "Author": "u/tillybowman", "Content": "i‘m looking for a compact document scanner that can upload images immediately to some local file sevice like ftp, sftp, smb or something.\n  \n\n    i don’t want dropbox or other cloud services involved.\n  \n\n    any recommendation here?"},
{"Title": "A New Idea for Data Storage: Combining Piezoelectric Materials and 3D NAND", "Author": "u/Mysterious_Crazy9606", "Content": "Hey everyone,\n  \n\n    I’ve been thinking about a new way to revolutionize data storage by combining piezoelectric materials with 3D NAND technology. Here’s the gist of my idea:\n  \n\n    The Concept\n  \n•\tHigh-Speed Piezoelectric Module: Use piezoelectric crystals that can oscillate at frequencies in the gigahertz range as an ultra-fast data buffer. This could potentially give us read and write speeds way beyond what we have with current tech.\n•\tMain 3D NAND Storage: Use 3D NAND for the main long-term storage. We all know it’s reliable and has a high capacity.\n\n    How It Would Work\n  \n1.\tWriting Data: Incoming data would first go to the piezoelectric module at super high speeds.\n2.\tTransferring Data: The data would then be transferred to the main 3D NAND storage for long-term keeping.\n3.\tReading Data: For reads, the system would first check the piezoelectric buffer for quick access. If the data isn’t there, it would pull from the 3D NAND storage.\n\n    Benefits\n  \n•\tSpeed: This setup could drastically reduce latency and boost read/write speeds.\n•\tEnergy Efficiency: Piezoelectric materials might be more energy-efficient for rapid operations.\n•\tNew Storage Architecture: Combining the speed of piezoelectrics with the capacity of 3D NAND could create a super-efficient storage solution.\n\n    Challenges\n  \n•\tTech Integration: Making sure the piezoelectric and 3D NAND components work seamlessly together.\n•\tCost: High-quality piezoelectric materials and the complexity of this setup might be pricey.\n•\tDurability and Reliability: The materials need to handle high-frequency oscillations over long periods without wearing out.\n\n    Potential Impact\n  \n\n    If we can make this work, it could be a game-changer for data centers, mobile devices, and industrial applications that need ultra-fast response times.\n  \n\n    What do you all think? Could this actually work?"},
{"Title": "help with a complicated wget string : how do -A and -R args stack, and is there any means of boolean filtering ?", "Author": "u/ImaginaryCheetah", "Content": "good afternoon,\n  \n\n    i'm not particularly familiar with \nwget\n so i'm asking the experts for assistance...\n  \n\n    my current string of \nwget -A \"*(USA)*zip\" -R -m -p -E -k -K -np -nd -w 2 https://target\n works fine to pull all files with \"(USA)\" included in the name, but i'd like to understand if i can get more complicated.\n  \n\n    does the \n-R\n arg work in conjunction with \n-A\n or would it override ?\n  \n\n    for example, \nwget -A \"*(USA)*zip\" -R \"*(Demo)*\" [etc]\n would this return all files with \"(USA)\" in the title unless it also had \"(Demo)\" in the file name ?\n  \n\n    is there any way of passing a boolean criteria through wget ? \"get files with (Europe) in the title if same file with (USA) in the title doesn't exist\" kind of thing ?\n  \n\n    i expect that might require grabbing a list of files with \nlftp\n and processing it instead of having \nwget\n do that kind of logic."},
{"Title": "Help needed with my western digital elements hdd", "Author": "u/Tiredcardinal", "Content": "I have a 4 year old WD elements 1.5tb hdd It was working completely fine until the starting of this year but all of a sudden it started giving buggy video outputs and I couldn't run games on it anymore So recently I decided to format it , only for it to be faulty a day later now I can copy any data to hdd normally but I cannot transfer anything for it Any suggestions or troubleshoots are welcome and appreciated"},
{"Title": "Which is more safe, a partitioned SSD (OS/Data) or two separate SSDs (one for OS, one for Data)", "Author": "u/cs_legend_93", "Content": "Hello all\n  \n\n    I'm trying to settle a debate with a other redditor.\n  \n\n    Assume both of these scenarios are basic setups without drive pools or raid.\n  \n\n    The redditor suggests and recommends that using a single SSD with a partition for the OS and Data drive is more safe than using dual drives.\n  \n\n    I believe using a partitioned SSD will both double your chances of drive failure due to writes and reads, and it will make it a pain in the ass to restore the backup.\n  \n\n    I suggested using two separate SSDs, and the redditor said that this indeed doubles the chances of drive failure due to two drives. I disagreed and said that it halves it due to the decreased reads and writes. I also suggested that dual drives will make it easier to restore a backup drive if one fails.\n  \n\n    Which scenario is better?\n  \n\n    In both scenerios there are backups, like a mirrored drive using Acronis disk imager or something like that. But it's still not a drive pool or RAID\n  \n\n    Here is the debate: \nhttps://www.reddit.com/r/buildapc/s/ArnZMYuQSD"},
{"Title": "Are any HDD manufacturer RMAs not predatory?", "Author": "u/Vile-The-Terrible", "Content": "I bought a NAS less than two years ago from B&H that had Seagate Ironwolf Pro 16tbs in it. One of the drives started to fail so I began the RMA process with Seagate. They charged to have expedited delivery but it took them two weeks to process my order before shipping it. They then send me a nonfunctional drive. I now have to go through the process of RMAing the RMA drive, and the kicker? I have to pay the return shipping on the drive that failed and the broken drive they sent me.\n  \n\n    So as the title asks, are there any other companies I should be spending my dollars with going forward?\n  \n\n    Edit: In case it wasn’t clear. I understand that it is standard practice to pay for return shipping on the drive you’re using the warranty for. The problem is paying shipping again to return the faulty drive they sent me."},
{"Title": "Two 2TB external HDDs or one 4TB external HDD?", "Author": "u/Fonti_Sgasao", "Content": "Hey there, I need an external HDD just to store data, I would buy a 4TB HDD (probably Toshiba Canvio, never had a problem with it) but I heard that it's more likely to suffer data loss than a 2TB HDD, is it true?"},
{"Title": "Rsync Ran With Read Only Destination", "Author": "u/klnadler", "Content": "Hi all, I was transfering some data from my Unraid to an external drive mounted as an unassigned drive. I had to tweak the command a little to work with the permissions due to the drive being ExFat. After the transfer I realized the drive was set to read only through the Unassigned Disk settings, but the files transferred? How and why?\n  \n\n    Command used:\n  \nrsync -avPh --no-owner --no-group --no-perms"},
{"Title": "What drives do you recommend?", "Author": "u/Endeavour1988", "Content": "I currently have 3x 6TB Western Digital Golds for my media server.  2x Host content and one for spare (backups).\n  \n\n    * I do back up externally/offsite\n  \n\n    I've always had a bad history with Seagate but some of my external drives have been solid which are Seagate so I'm open minded.  Can anyone recommend from experience what brands to go for?  The Golds are 7 year old now so I would like to look at replacing 2x with 12TB and possibly the third with something larger like 16TB.  Which should hopefully see me through another 6 years."},
{"Title": "Youtube channel downloader and sync for 1000s of videos?", "Author": "u/No_Doubt8973", "Content": "Hi first of all, I am on windows but I can install linux on a virtual machine.\n  \n\n    I have about 50 channels I am downloading videos from manually and it's so tiring I stopped for a year. I started again and found a lot of channels deleted videos or the channel is closed. And some of the channels have since uploaded thousands of videos.\n  \n\n    I used to manually go on youtube on my pc and grab the links but it stops loading after 1000 videos or it overloaded the chrome and crash. Would a channel downloader be able to download thousands of videos from one channel?\n  \n\n    How does the leading youtube downloaders know which videos were has been downloaded so that it doesn't download it again?\n  \n\n    Which program allows me to select preferred codec for a specific resolution?\n  \n\n    If it is possible I want to avoid av1 codec because my tablet can't play it unless it's 8k because youtube uses only av1 on 8k resolution, I would play it on my pc when I upgrade my video card black friday."},
{"Title": "Dreams and Aspirations", "Author": "u/thenazgul80", "Content": "Do I have this right? I want to build a nas to store my digital library and stream it to my and my family's devices. Currently relying on 5 external 2.5\" drives and windows media share. However I can't outright purchase something like a Synology nas due to cost. I have my old PC collecting dust. Amd fx 4100 Radeon 7700hd and 8 gb of ddr3 ram. Here is the plan. Undevolt the fx4100 to the lowest it can go. Diy mod my Asus Vento a8 PC case for cooling and dust prevention. Buy a 16-20 TB drive and start the nas. Once I can afford a second drive i plan on using them in raid 1. Once a 3rd drive is added I want to use them in raid 5. Over all I want to end up with 40-60tb of useable storage with some redundancy and keep the external 2.5\" drives for backups. From what I can gather, truenas won't let me just add drives later on down the line. Is unRAID my only option if I want to start with the bare minimum and expand later on as I can afford more drives?"},
{"Title": "Need help with converting and compressing old VOB files", "Author": "u/martian_doggo", "Content": "So i have a bunch of old vob files, and i want to convert them to mkv or mp4 or something. I admit i don't have much experience in video manipulation but this is turning out to be exceptionally hard.\n  \n\n    I have around 5 movies which have 5 vob files each. The movies are around 4 hours long but around 12gb in size for barely 704x570p so i would love to concatinate and compress them.\n  \n\n    Now here's the problem, none of the video editor software is picking up the subtitles, not handbrake, not even ffmpeg but mpv somehow plays with the subtitles, though it takes mpv 10ish seconds to load the subtitles (weird ik).\n  \n\n    Now if i join 5 of the files to make 1 complete movie using ffmpeg, the subtitles stop loading.\n  \n\n    I have no idea what to do :(\n  \n\n    thanks"},
{"Title": "Backing up MacBook and multiple SSDs to single HDD", "Author": "u/cloudfortynine", "Content": "Hi everyone,\n  \n\n    I could use some guidance as I'm unsure what the simplest and low maintenance solution is for me. I'm looking to purchase an external HDD to backup the following:\n  \n\n\n\n\n\n    Macbook\n  \n\n\n\n\n\n    1TB SSD with my travel photos to be edited\n  \n\n\n\n\n\n    1TB SSD with my partners travel photos to be edited\n  \n\n\n\n\n\n    2TB SSD with music libraries for music production (Kontakt, Omnisphere etc)\n  \n\n\n\n\n\n    At first I was thinking of buying a 8TB external HDD and just backing everything up via Time Machine by having it all plugged in at once. However people online had also mentioned CCC and I'm unsure how that works? I was also hoping to back this all up to a portable HDD but it seems that 8TB HDDs can only be plugged in is that true? I'm not interested in NAS etc. as this is too complicated and expensive for me.\n  \n\n    As a sidetone I'm also planning on backing up to BackBlaze as well.\n  \n\n    Thanks in advance for any pointers!"},
{"Title": "Need help figuring how do archive part of a soon-to-die site", "Author": "u/Mode7GFX", "Content": "I posted this on stack overflow and they called me stupid (I am) and locked the question when someone was in the middle of actually helping me so I'm asking here because it's probably a more welcoming community for this sort of thing.\n  \n\n\nhttps://prcm.jp/list/akb48%20%E3%83%97%E3%83%AA\n\n\n\n    So this (formerly) huge Japanese image sharing site is shutting down in 2 weeks and my sister's begging me to archive at least some of it. I was trying to find a python script to automate it, cuz it will take me forever going one by one on tens of thousands of images, but I can't seem to find one that can archive this sort of website. It only goes by pages of 9 and the thumbnail images are shrunk down a ton so you have to click on the image twice to open the full size. Luckily it seems like every thumbnail image shares a name with the source image, but with an added suffix of the preview size, so I imagine it would be possible to have the script delete the underscore and re-add the .jpeg extension. As for going through pages, I'm not so sure on, but if I can input a list of URLs and just batch copy the original URL adding every page number (I know how to do this without a script), I could just use that.\n  \n\n    I was only going to download AKB48 related images, because most of these images aren't available anywhere else online, and soon won't be anywhere period. They're all old and thus fairly small, so I'm not too worried about it taking a long time to download.\n  \n\n    If anyone can direct me to a script that can do this or has some other mass image downloading method you're aware of, please let me know. Thanks!"},
{"Title": "ATA security doesn't play well with WD USB-SATA bridge devices", "Author": "u/Visual-East8300", "Content": "A couple of years ago, I bricked a 10TB WD easystore by issuing \"hdparm --security-set-pass\" on the USB drive, un-bricked it by plugging the HDD to another USB adapter then \"hdparm --security-disable\". Today, I bricked a 4TB WD easystore (2.5 inch), out of luck this time because inside the enclosure it's an USB on-board WD Blue drive.\n  \n\n    Both are using ASMedia ASM1151W.\n  \n\n    Does anyone have ideas how to recover from this? Or it's not worth the time trying to fix?"},
{"Title": "Looking for an alternative to dban to wipe an old computer with SSD", "Author": "u/ilovecokeslurpees", "Content": "I have an old computer (turned it off 2.5 years ago but it was a mid-spec PC built in 2016 I bought second hand in 2017). I can barely boot it these days. I want to wipe the 1 TB SSD before throwing the whole PC into the trash or recycle or whatever. Most parts are unsalvageable. I used to use dban way back when but it appears to not have been updated in almost a decade. The PC is running Windows 10, but I would like a simple solution bootable from a USB to ensure complete data erasure. I tried ABAN but it couldn't detect anything. Any suggestions?"},
{"Title": "Building up my personal media server, and I have additional questions about sourcing storage", "Author": "u/TheXypris", "Content": "So I asked \nr/Plex\n a few days ago and got some really great advice\n  \n\n    One of which was to send me here\n  \n\n    So along side what I was told there I had more questions\n  \n\n    How is shucking more affordable than just buying the regular drive? And how do I actually find those deals\n  \n\n    Are Seagate drives really that bad?\n  \n\n    What is the general consensus on buying drives second hand off eBay or through a liquidation auction? Bad idea or risky at best?\n  \n\n    I'm assuming Facebook marketplace/Craigslist should be avoided, but is there any merit in looking there? Like if I find a second hand external I could shuck?\n  \n\n    How important are RPMs sata type and all that other non capacity info? What's good and what's bad? Tradeoffs?\n  \n\n    How long will a healthy high capacity drive realistically last? People keep saying raid is mandatory and act like drives fail because you look at them funny. I can't afford a raid array right now and anything I'm putting on it would be easily required if time consuming.\n  \n\n    Are there price monitoring sites I can use to keep an eye out for deals or sales?\n  \n\n    And where is the best place to get sata and power cables for the drives?"},
{"Title": "Attempting to digitize some Beta tapes, but getting this rainbow banding through the picture.", "Author": "u/hmhsbritannic12", "Content": "No content"},
{"Title": "Anyone know of a device that can easily back-up data portably off a memory card onto an SSD?", "Author": "u/Ok-Cartographer1745", "Content": "I bought a Wolverine 80gb like 15 years ago. You plug in a memory card (not specifically Sony Memory Stick. I mean like Compact Flash, SD Card, and so on), press a button, and it copies your card to a folder on the hard drive.\n  \n\n    But that think is old and low capacity and I probably can't upgrade the hard drive due to the form factor and firmware likely only allowing 80gb drives.\n  \n\n    Anyway, anyone know of a similar device that is more modern?  I want it to:\n  \n\n\n\n\n\n    be portable and battery powered (nothing huge and nothing that needs to be plugged in to work)\n  \n\n\n\n\n\n    have a large SSD (500 GB or more)\n  \n\n\n\n\n\n    be self sustained (I don't want to have to plug it into a PC nor Bluetooth it to my phone)\n  \n\n\n\n\n\n    accept at least SD cards (more slots would be nice, but not necessary)\n  \n\n\n\n\n\n    I mainly want to do it to easily hoard pictures off my camera, especially if I need to quickly empty out my more expensive fast cards\n  \n\n    Also, a link to show what I already have. I'm not the one selling it and I don't recommend buying it because it's so outdated and slow (and the battery probably doesn't work considering how old it is).  So don't consider this advertising.\n  \n\n\nhttps://www.ebay.com/itm/125748798949?_trkparms=amclksrc%3DITM%26aid%3D1110006%26algo%3DHOMESPLICE.SIM%26ao%3D1%26asc%3D266917%2C266785%26meid%3D0caf8ebbb6584b81a8ed70c03fd786fd%26pid%3D101875%26rk%3D1%26rkt%3D5%26sd%3D285760155205%26itm%3D125748798949%26pmt%3D1%26noa%3D1%26pg%3D2332490%26algv%3DSimplAMLv11WebTrimmedV3MskuWithLambda85KnnRecallV1V2V4ItemNrtInQueryAndCassiniVisualRankerAndBertRecallWithVMEV3CPCAutoWithCassiniEmbRecall%26brand%3DWolverine&_trksid=p2332490.c101875.m1851"},
{"Title": "Software to recover data from a formatted and written disk?", "Author": "u/lsgz3", "Content": "The disk has been formatted twice and written with New stuff. Is there any chance of recovering old files?"},
{"Title": "is this samsung 512 gb micro sd fake?", "Author": "u/UlisesDeveloper", "Content": "No content"},
{"Title": "BTRFS file sync over the internet through Tailscale, or traditional backups using Kopia or Restic?", "Author": "u/1000Zebras", "Content": "Hi,\n  \n\n    I've got a couple of drives running off of a couple of instances of Debian, one of which is at my house, and the other is at my brother's house. They're 14tb drives, currently containing ~4.7TB of data.\n  \n\n    I'd like to, ideally I think, keep the two drives/filesystems in sync over the internet, probably through Tailscale so no public exposure necessary. At the very least I'd like to have a solid, relatively up to date backup of all of the data that lives on the drive at my brother's house, backing up that of the one at house.\n  \n\n    What are my best options for doing so, and, if it were you, how would you go about setting things up?\n  \n\n    I'm thinking maybe btrfs snapshots over ssh using btrbkup (both drives are formatted using btrfs) is probably me best bet, but I've never used snapshots and not sure how easy it would be configure in this case. This would, of course, depend on the drives both being btrfs formatted, which I suppose okay, although I was also thinking maybe it's smarter to have just regular backups that are filesystem agnostic.\n  \n\n    My favorite straight backup tool these days is Kopia, so if I were to go the second route I'd probably be looking at using that, although I'm not opposed to going restic. The only problem with that is that I think Kopia can only backup to either an S3-compatible bucket (so maybe run minio on secondary sysem?), or through webDAV which I'd have to figure out how to configure on the machine at my brother's house, or to the local filesystem, in which case I could maybe mount the remote disk on the local machine at my place using sshfs, but that may introduce weirdness, or just be a bit too unstable.\n  \n\n    What would you do in a situation like mine? Do you have any experience in setting something like this scenario up and what potential pitfalls would you anticipate?\n  \n\n    Thank you for reading the somewhat lengthy post,\n  \n\n    I look forward to any insights.\n  \n\n    Kind Regards,\n  \n\n    LS"},
{"Title": "Buying drives from eBay?", "Author": "u/Seventeen-Oncelers", "Content": "I was considering buying a 10tb HDD on eBay and was wondering if this is considered a good place to buy? It's certified eBay refurbished, 30 day returns etc. Just curious on you guy's thoughts on buying hard drives on eBay."},
{"Title": "Cost Efficient Storage Revamp", "Author": "u/iLOLZU", "Content": "I'm want to get into archival with all the shenanigans with the Internet Archive and game preservation. I'm in need of a storage upgrade anyways. I have a Lian Li O11 with the 2x 3.5\" drive cage unpopulated and 2x 2.5\" HDDs (2.5TB total) installed, was thinking of getting a pair of 3.5\" HDDs & a pair of SATA SSDs. Considering 8TB Seagate Firecuda + 2TB Samsung 870s. I know higher capacity 3.5\" HDDs exist, but heard that buying a single high capacity drive is not worth while in terms of cost and data loss."},
{"Title": "Can my old (possibly infected?) digital camera’s SD card and/or photos transfer a virus to my iPhone via an adapter?", "Author": "u/knOn0", "Content": "Hello! (I’ve asked this already but wanted to widen the net of insight before I proceed)\n  \n\n    I have an old digital camera from 2009-2011. I recently bought a new charger for it, turned it on, and it works perfectly! When I first turned it on, I was able to see tons of old pictures that I’d forgotten about; now, I can see my old photos but any new photo that I try to view has the “File Error” message. I did buy an SD card adapter to put my photos from the SD card to my iPhone, and now I’m seeing a “content unavailable: files could not be opened due to an unknown error.” (The iPhone is an 11, IOS 17).\n  \n\n    Does my SD card have a virus? Do the photos on them have a virus? Should I get a brand new adapter and SD card?\n  \n\n    TYIA"},
{"Title": "document scanner with local file upload", "Author": "u/tillybowman", "Content": "i‘m looking for a compact document scanner that can upload images immediately to some local file sevice like ftp, sftp, smb or something.\n  \n\n    i don’t want dropbox or other cloud services involved.\n  \n\n    any recommendation here?"},
{"Title": "A New Idea for Data Storage: Combining Piezoelectric Materials and 3D NAND", "Author": "u/Mysterious_Crazy9606", "Content": "Hey everyone,\n  \n\n    I’ve been thinking about a new way to revolutionize data storage by combining piezoelectric materials with 3D NAND technology. Here’s the gist of my idea:\n  \n\n    The Concept\n  \n•\tHigh-Speed Piezoelectric Module: Use piezoelectric crystals that can oscillate at frequencies in the gigahertz range as an ultra-fast data buffer. This could potentially give us read and write speeds way beyond what we have with current tech.\n•\tMain 3D NAND Storage: Use 3D NAND for the main long-term storage. We all know it’s reliable and has a high capacity.\n\n    How It Would Work\n  \n1.\tWriting Data: Incoming data would first go to the piezoelectric module at super high speeds.\n2.\tTransferring Data: The data would then be transferred to the main 3D NAND storage for long-term keeping.\n3.\tReading Data: For reads, the system would first check the piezoelectric buffer for quick access. If the data isn’t there, it would pull from the 3D NAND storage.\n\n    Benefits\n  \n•\tSpeed: This setup could drastically reduce latency and boost read/write speeds.\n•\tEnergy Efficiency: Piezoelectric materials might be more energy-efficient for rapid operations.\n•\tNew Storage Architecture: Combining the speed of piezoelectrics with the capacity of 3D NAND could create a super-efficient storage solution.\n\n    Challenges\n  \n•\tTech Integration: Making sure the piezoelectric and 3D NAND components work seamlessly together.\n•\tCost: High-quality piezoelectric materials and the complexity of this setup might be pricey.\n•\tDurability and Reliability: The materials need to handle high-frequency oscillations over long periods without wearing out.\n\n    Potential Impact\n  \n\n    If we can make this work, it could be a game-changer for data centers, mobile devices, and industrial applications that need ultra-fast response times.\n  \n\n    What do you all think? Could this actually work?"},
{"Title": "help with a complicated wget string : how do -A and -R args stack, and is there any means of boolean filtering ?", "Author": "u/ImaginaryCheetah", "Content": "good afternoon,\n  \n\n    i'm not particularly familiar with \nwget\n so i'm asking the experts for assistance...\n  \n\n    my current string of \nwget -A \"*(USA)*zip\" -R -m -p -E -k -K -np -nd -w 2 https://target\n works fine to pull all files with \"(USA)\" included in the name, but i'd like to understand if i can get more complicated.\n  \n\n    does the \n-R\n arg work in conjunction with \n-A\n or would it override ?\n  \n\n    for example, \nwget -A \"*(USA)*zip\" -R \"*(Demo)*\" [etc]\n would this return all files with \"(USA)\" in the title unless it also had \"(Demo)\" in the file name ?\n  \n\n    is there any way of passing a boolean criteria through wget ? \"get files with (Europe) in the title if same file with (USA) in the title doesn't exist\" kind of thing ?\n  \n\n    i expect that might require grabbing a list of files with \nlftp\n and processing it instead of having \nwget\n do that kind of logic."},
{"Title": "Help needed with my western digital elements hdd", "Author": "u/Tiredcardinal", "Content": "I have a 4 year old WD elements 1.5tb hdd It was working completely fine until the starting of this year but all of a sudden it started giving buggy video outputs and I couldn't run games on it anymore So recently I decided to format it , only for it to be faulty a day later now I can copy any data to hdd normally but I cannot transfer anything for it Any suggestions or troubleshoots are welcome and appreciated"},
{"Title": "Which is more safe, a partitioned SSD (OS/Data) or two separate SSDs (one for OS, one for Data)", "Author": "u/cs_legend_93", "Content": "Hello all\n  \n\n    I'm trying to settle a debate with a other redditor.\n  \n\n    Assume both of these scenarios are basic setups without drive pools or raid.\n  \n\n    The redditor suggests and recommends that using a single SSD with a partition for the OS and Data drive is more safe than using dual drives.\n  \n\n    I believe using a partitioned SSD will both double your chances of drive failure due to writes and reads, and it will make it a pain in the ass to restore the backup.\n  \n\n    I suggested using two separate SSDs, and the redditor said that this indeed doubles the chances of drive failure due to two drives. I disagreed and said that it halves it due to the decreased reads and writes. I also suggested that dual drives will make it easier to restore a backup drive if one fails.\n  \n\n    Which scenario is better?\n  \n\n    In both scenerios there are backups, like a mirrored drive using Acronis disk imager or something like that. But it's still not a drive pool or RAID\n  \n\n    Here is the debate: \nhttps://www.reddit.com/r/buildapc/s/ArnZMYuQSD"},
{"Title": "Are any HDD manufacturer RMAs not predatory?", "Author": "u/Vile-The-Terrible", "Content": "I bought a NAS less than two years ago from B&H that had Seagate Ironwolf Pro 16tbs in it. One of the drives started to fail so I began the RMA process with Seagate. They charged to have expedited delivery but it took them two weeks to process my order before shipping it. They then send me a nonfunctional drive. I now have to go through the process of RMAing the RMA drive, and the kicker? I have to pay the return shipping on the drive that failed and the broken drive they sent me.\n  \n\n    So as the title asks, are there any other companies I should be spending my dollars with going forward?\n  \n\n    Edit: In case it wasn’t clear. I understand that it is standard practice to pay for return shipping on the drive you’re using the warranty for. The problem is paying shipping again to return the faulty drive they sent me."},
{"Title": "What my boss has collecting dust (brand new)", "Author": "u/ResponsibilityIll888", "Content": "No content"},
{"Title": "Issues with LSI 9300-16i wiping partition tables", "Author": "u/Electronic-Papaya", "Content": "I'm trying to free up some PCIe slots in my system so I'm switching from 2 x LSI 2008 to a single 16 port LSI 9300-16i.  I'm running Linux and using mdadm to run 3 arrays.\n  \n\n    Before I attached any of my drives with data and arrays configured, I installed the card with no drives attached and update the firmware to \n16.00.12.00\n, and made sure it was in IT mode.  As a test I then connected one of my arrays to the controller and booted the system.  After booting up, the drives were detected fine (4 x 2TB) but the array was gone.  It appears that the metadata was erased, mdadm didn't recognize any drive as being part of an array.\n  \n\n    I was able to recover the data and the array by following the steps here:  \nhttps://raid.wiki.kernel.org/index.php/Recovering_a_damaged_RAID\n\n\n\n    However, if I reboot again the same thing happens, the metadata is lost and mdadm does not recognize that the drives are part of an array.   I do not have this issue with the older LSI controllers.\n  \n\n    Any idea what's going on here?  When I created the array I used the entre drive, so I did not create a Linux RAID partition on each drive.  The array is configured using /dev/sda to /dev/sdd, and not /dev/sda1 to /dev/sdd1.  Not sure that has anything to do with it.\n  \n\n    Edit:  Seems to be an issue with the controller and GPT partition tables.  As a test, I created an array with a couple 120gb SSD's I had laying around.  I created the array with the whole drive, rebooted, and after a reboot the array was still present.  I realized my other drives are configured as GPT.  So I wiped the SSDs, switched them to GPT and again created the array.  This time after a reboot the array was gone, mdadm does not recognize the drives as being part of an array.  Not sure how to fix this."},
{"Title": "Official Giveaway: June 2024 Seagate IronWolf Pro 16TB Hard Drive Giveaway", "Author": "u/Seagate_Surfer", "Content": "Hi \nr/DataHoarder\n crowd! We love your sub and would like to rev up another giveaway with the permission of the mod team.\n  \n\n    The prize is: one 16TB IronWolf Pro Hard Disk Drive\n  \n\n\nHow to enter:\n\n\n\n\nJust reply to this post once with a top-level comment response on the following topic:\n\n\n\n\nWhat kind of loyalty program matters to you for a company? Is drive capacity, price point, excellent customer service, etc. the highest priority for you? Please include the phrases RunWithIronWolf and Seagate in your comment.\n\n\n\n    Selection process/rules\n  \n\n    One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until June 27, 2024 at 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.\n  \n\n    Geographic restrictions:\n  \n\n    Our policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don’t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions (e.g. the obvious shipping restrictions to Russia and Belarus currently)\n  \n\n    US\n  \n\n    Canada (will require a basic skills-based question if winner is chosen by law)\n  \n\n    Brazil\n  \n\n    South America\n  \n\n    United Kingdom\n  \n\n    Germany\n  \n\n    France\n  \n\n    Iberia\n  \n\n    Australia\n  \n\n    New Zealand\n  \n\n    Korea\n  \n\n    India\n  \n\n    Malaysia\n  \n\n    Singapore\n  \n\n    China"},
{"Title": "Is a dual bay HDD docking station right for me?", "Author": "u/Vanillinn", "Content": "Hello! I only have my toe dipped in data hoarding but I've been meaning to buy the orico 6228US3 dual bay non cloning docking station.\n  \n\n    Here is my use case:\n  \n\n\n\n\n\n    Use my extra 3.5\" 500GB HDD for my modded wii u (to be formatted for the wii u) it will be where my games are installed while running the console\n  \n\n\n\n\n\n    back up photos, videos, school files, and game ROMs I have on future storage expansions (1-4TB at a time)\n  \n\n\n\n\n\n    have two drives connected to my pc at the same time\n  \n\n\n\n\n\n    on a very tight budget as a student\n  \n\n\n\n\n\n    In the future, I would like to build my own NAS if I get into bigger data hoarding and archiving. It's something I want to do but do not have the budget for right now. I have a lot of files currently but 1 or 2 more extra drives would be enough. If I could, I'd like to own two copies of my files.\n  \n\n    I have read some posts here on the subreddit raising issues on cooling, partitions, and corrupted drives. On cooling, would it still be an issue for a dual bay? I don't exactly understand the formatting problem of the partitions so I'd like to ask about that too. On corrupted drives, I'll always wait for the disk to stop spinning before ejection and also not move it as much as possible.\n  \n\n    Is a dual bay docking station a good low cost entry into data hoarding or is there an alternative more appropriate for my use case?"},
{"Title": "Is there a software that batch reverse search images and download the best version of it?", "Author": "u/BulgyBoy123", "Content": "Hi guys,\nI'm looking for a software that is able to batch reverse search some images.\nI downloaded all of my pinterest boards, but some of the files are really tiny. I wouldn't mind being able to download bigger versions of said files without having to spend weeks doing that manually."},
{"Title": "YouTube is testing server-side ad injection into video streams (per SponsorBlock Twitter)", "Author": "u/ThePixelHunter", "Content": "No content"},
{"Title": "Easy and reliable storage for students?", "Author": "u/DetImplicitteSubjekt", "Content": "I'm a frequent internet user looking for an easy and reliable way to store my data. I write many personal notes daily, and I have a large number of photos (20k) on my Iphone. Additionally, I have over 700GB of various files, documents, and old system images.\n  \n\n    I currently use icloud for my images. My files are either stored locally on my old Windows or in icloud drive on my Mac.\n  \n\n    I own a Portable SSD, but i rarely use it. (still use 1,5 out of 2TB tho)\n  \n\n    What storage solution would you recommend for my needs?\n  \n\n    I've thought about something like this:\n  \n\n\n\n\n\n    Create a new Google account and purchase Google Drive storage.\n  \n\n\n\n\n\n    Upload all photos and icloud stuff to Google Drive, in a folder named \"iCloud\" for iCloud files and photos.\n  \n\n\n\n\n\n    Simultaneously, upload all files to the Portable SSD.\n  \n\n\n\n\n\n    Additionally, invest in a secondary SSD.\n  \n\n\n\n\n\n    Monthly backup the main SSD to the secondary SSD.\n  \n\n\n\n\n\n    Maintain a monthly routine of cleaning up iPhone photos, then upload them to both the Portable SSD and Google Drive.\n  \n\n\n\n\n\n    What do you think? Will it be enough? Is it too much? Let me hear your thoughts. And please go easy on me😉"},
{"Title": "Price Point", "Author": "u/Crafty_Future4829", "Content": "I apologize in advanced as I know there are a lot related posts to buying refurbished/used hard drives for non critical data.  On eBay,  it seems you can get 16tb exos drives for around 160.00 or 10 per tb.  They say refurbished with zero hours and the reseller (goharddrives) offers a 5 year warranty.\n  \n\n    Where do these hard drives from?  Do they really have zero hours as opposed to having smart data wiped?  Is this a good deal?\n  \n\n    I read another post being able to get used drives for around 5 dollars per tb.\n  \n\n    What is your sweet spot and reliable ebay sellers you would buy from?\n  \n\n    Thanks"},
{"Title": "Came across a Reddit Archive project (Pushshift alternative)", "Author": "u/marinluv", "Content": "Came across this \npost\n yesterday. That user and \nu/RaiderBDev\n are archiving Reddit data. The data is around 3-4Tb roughly from what I have seen.\n  \n\n    The GitHub Repo to archive and access the data: \nHere\n\n\n\n    To download and search Subreddit and user data manually: \nHere\n\n\n\n    Post on \nr/pushshift\n for the 2.5TB dump: \nHere"},
{"Title": "How much would it cost me to have and maintain a 1 TB database?", "Author": "u/AtwoodEnterprise", "Content": "I have an SEO SaaS and I store a lot of data for keywords and backlinks.\n  \n\n    My database is about 50gb and I’m currently paying about $80/mo for my webhosting VPS and up to 75gb of database storage.\n  \n\n    Currently, I use a lot of API’s to pull SEO data down because it’s such a hassle to store that much data, but over the next year I want to try and up my game a bit.\n  \n\n    So I’m gonna try and start off by increasing my keyword, and my backlink data to around 1 TB total if possible. The majority of the data is gonna be due to the backlink data of course.\n  \n\n    Would anyone have any estimates for how much something like this might cost? Or what factors I should consider/ask when obtaining pricing?"},
{"Title": "Hulkshare Hacks?", "Author": "u/mamba_regime19", "Content": "Is there an easy way to download larger songs/mp3's from Hulkshare?\n\n\n\n    Found some old shows no longer available anywhere else that I wouldn't mind having but the files stop playing after like 10 mins so my downloaders stop as well.\n  \n\n    Is there anything like YoutubetoMp3 or SoundcloudtoMp3 that works?\n  \n\n    Saw some older posts from 11years ago....not sure if anybody has figured it out since then.\n  \n\n    Thanks!"},
{"Title": "Lsi hba 9207-8i", "Author": "u/Crystal_Jayhawk", "Content": "No content"},
{"Title": "SATA only 50 to 500 mating cycles - what do you use for backup?", "Author": "u/No-Balance-8038", "Content": "I've got currently 5 backup 3.5\" HDD disks which are planned to be stored offsite. And backup is earliest weekly. But the real issue is that according to the SATA specification, after 50 times replugging the disk, both the Server slot for 3.5\" or the HDD itself can fail!\n  \n\n    What do I do? Put the disks in a USB enclosure and never remove it again?\nBut what about keeping the HDD running in proper temperature? My current usb cases do not have fans, and USB is not as reliable. I know turning off UASP helps for that, but I am still kind of disappointed that I am not meant to regularly take backups from SATA disks.\n  \n\n    I know theres also eSATA, but  I am not sure which combination of that would be reliable! I could basically instead have a PCIe eSATA card and eSATA cases.\nI even found two suitable cases \nhttps://www.turtlecase.eu/5-hdd/40-35-hard-drive-hdd-5-capacity-long-slots-waterproof-hd-5-turtle-case.html\n or \nhttps://www.feldherr.com/feldherr-esd-schaumstoff-set-euro-box-mit-16-faecher-fuer-3-5-zoll-festplatten/a-61567\n\n\n\n    What do you guys do recommend?"},
{"Title": "Verifying disk/data integrity before backup?", "Author": "u/Unnombrepls", "Content": "Hi guys,\n  \n\n    So I backup my important things from other drives in a 8 TB drive each 15 days. Recently, I have been worrying that a disk might fail; but not catastrophically, still being able to copy and open most files, while displaying normal SMART values. That could make me substitute a totally healthy backup with corrupted files without knowing. Thus, I have resolved to do disk checks before updating my backups.\n  \n\n    I was wondering if you guys know any software that checks the disks with more depth than just SMART and that can do it in around 3-4 hours. It doesn't need to create a super extensive report; but to identify any problem so I can run a deeper analysis later to pinpoint or solve the exact issue (I would also be grateful if you can recommend me any program for this)."},
{"Title": "Best way to contact Seagate for warranty?", "Author": "u/green314159", "Content": "*** Update - I got in contact with Seagate and they wanted me to send them the drive and pay for the shipping costs when sending it in to them. They will cover the shipping costs for the return trip. Does this seem like standard procedure? It's my first time needing to RMA during the warranty period. I live in the USA.\n  \n\n    Original post: A Seagate Barracuda 8TB drive with warranty expiration date sometime in 2025 has failed the other day. What is the best way to get in contact with technical support and get the warranty and replacement going? Sorry if this is the wrong place on Reddit to ask"},
{"Title": "Where to find US Trademark Data", "Author": "u/Acrobatic_Stay_9221", "Content": "Hi, I'm looking for granular US trademark data that includes the name of the company that filed the trademark (I'm trying to view summary statistics on trademark filed by company in the US).\n  \n\n    I've tried: \nhttps://tmsearch.uspto.gov/search/search-resultsbut\n but can't find out how to get the aggregate data out of this.\n  \n\n    I've been told that this data should be publicly available, but am stumped on where to find it.\n  \n\n    Has anyone \"hoarded\" a data set that would have this data? Alternatively, does anyone know how to scrape data from this lookup above?"},
{"Title": "Samsung 970 evo plus M2 ssd boot drive not recognizing any more. Now what?", "Author": "u/tobyisthecoolest", "Content": "I’ve been using this drive for about 1.5years and today got the boot drive not detected error. I opened bios, but the only shows up sometimes.\n  \n\n    I have a m2 to usb adapter, but the drive isn’t showing up on my other computers, so I can’t seem to copy the data off it easily.\n  \n\n    I’ve found posts with other ppl having problems with the EVO plus drives.\n  \n\n    What should I do now?\n  \n\n    If I buy a replacement boot drive how do I get windows onto it? My back ups aren’t perfect, so is there data recovery possible?\n  \n\n    Thanks"},
{"Title": "Any good suggestions for hardware to transfer analogue camcorder footage to a computer?", "Author": "u/Zazabar11", "Content": "My camcorder has av out and I have cables going from the camcorder to a framemister, which converts the signal to digital and uses an HDMI cable to transfer the signal to an elgato hd 60s, which ends with a USB C cable going to my computer for capture. It's a bit, but it has worked for older VHS tapes pretty well. I'm also using the basic capture software which comes with the elgato software.\n  \n\n    While trying to get footage from my camcorder, I noticed the audio and video footage stops getting captured on my PC when the tracking gets real messy, even if only for a couple seconds, and it ruins lots of the tape.\n  \n\n    Any suggestions for a capturing device which can handle any sort of tracking that may be required by the tapes?\n  \n\n    To note, I'm using a Sony CCD-TRV57, which uses VHS-C tapes (they're a compact form of regular VHS tapes)."},
{"Title": "winhttrack problem with cloning a single landing page. Any solutions?", "Author": "u/SolidShowerr", "Content": "I want to clone a landing page, I do everything right and download the files, but when I try to go to the index, it just opens the \"Loading screen\" from that page but not the page, it stays stuck on \"Loading\". Do you have a solution? Thank you\n  \nhttps://preview.redd.it/winhttrack-problem-with-cloning-a-single-landing-page-any-v0-9ywe6e7ja26d1.jpg"},
{"Title": "How to download Twitch vod?", "Author": "u/RainBowSwift71532", "Content": "I've been trying to download a twitch vod but have had no luck in doing so. If I want to download say a YouTube video. Search download YouTube video and a bunch of site pop up. Click on one copy and paste the YouTube link. Pick resolution and click download mad easy. But for some reason it's harder for a twitch vod. I have yet to find a site that will allow me to download a twitch vod. I'm trying to download a streamers recent twitch vod.\n  \n\n    I've tried a Twitch downloader for windows and it didn't work. It wouldn't download the video. So does anyone know a good site to download twitch vods? Please let me know!!"},
{"Title": "Internet Download Manager stopped detecting YouTube MKV format videos to download", "Author": "u/TheHighImperial", "Content": "Just today I discovered that it detects them if the video is embedded on a forum but not showing for the same video directly at YouTubes page. Ive updated the browser, IDM extension and even software. I also tried it on a different computer... same problem."},
{"Title": "Do I need to reformat my drives?", "Author": "u/Sinnagangsta", "Content": "My Plex server storage is running off a WD MyCloud EX4. When I first started my server I only had 1 4TB drive, but I quickly outgrew that. The drive mode is set as JBOD “one drive”. I have another 4TB drive that I want to put in my NAS, but when I go in to change the RAID mode, I get warnings saying that all data will be lost. I know my only RAID options are 0 and 1. I believe I can also use JBOD as well with two drives? I’m not worried about redundancy as I can easily redownload content but would not like to have my drives erased just to add another drive. What would be the best way to move forward?"},
{"Title": "How much damage have I caused from leaving a HDD in the sun?", "Author": "u/JerichoBlows", "Content": "I ordered a refurbished 12TB Seagate Enterprise HDD and it was delivered today while I wasn't home. It was over +100°F (+38°C) degrees today and the sun was beaming directly on the mailbox for 4 hours before I got to it. I suspected the box could have easily been 130°F (55°C) or possibly much hotter having been in the direct sunlight for so long. I immediately put the entire box in the refrigerator. After about 5 minutes in the fridge, I decided to measure the temp using a digital BBQ thermometer. It measured at 104°F (40°C) but this was likely not accurate because I was using a thermometer that is meant to be shoved inside of meat and the box had already been in the fridge for 5 mins.\n  \n\n    How much damage could have been caused from it sitting in the direct +100°F (+38°C) degree sunlight for just over 4 hours? Thanks!"},
{"Title": "Vimms Lair, the largest collections of ROMs, is being taken down.", "Author": "u/snowysysadmin59", "Content": "Corporate greed at it again. Anyone got a backup? 🥺"},
{"Title": "Huge Collection", "Author": "u/CoreDreamStudiosLLC", "Content": "Good evening, hope all is well. I lost my dad on Saturday and was going through some things to get bills paid/cancelled, etc. He had over 430 media discs at his apartment which I've taken back to me.\n  \n\n    Most are DVD-R, about 20 are DVD, and the rest are DVD+RW and Divx.\n  \n\n    Is it worth ripping each one of the DVD-R's at minimum? Some are very rare and streaming sites probably won't even half this collection."},
{"Title": "What my boss has collecting dust (brand new)", "Author": "u/ResponsibilityIll888", "Content": "No content"},
{"Title": "Issues with LSI 9300-16i wiping partition tables", "Author": "u/Electronic-Papaya", "Content": "I'm trying to free up some PCIe slots in my system so I'm switching from 2 x LSI 2008 to a single 16 port LSI 9300-16i.  I'm running Linux and using mdadm to run 3 arrays.\n  \n\n    Before I attached any of my drives with data and arrays configured, I installed the card with no drives attached and update the firmware to \n16.00.12.00\n, and made sure it was in IT mode.  As a test I then connected one of my arrays to the controller and booted the system.  After booting up, the drives were detected fine (4 x 2TB) but the array was gone.  It appears that the metadata was erased, mdadm didn't recognize any drive as being part of an array.\n  \n\n    I was able to recover the data and the array by following the steps here:  \nhttps://raid.wiki.kernel.org/index.php/Recovering_a_damaged_RAID\n\n\n\n    However, if I reboot again the same thing happens, the metadata is lost and mdadm does not recognize that the drives are part of an array.   I do not have this issue with the older LSI controllers.\n  \n\n    Any idea what's going on here?  When I created the array I used the entre drive, so I did not create a Linux RAID partition on each drive.  The array is configured using /dev/sda to /dev/sdd, and not /dev/sda1 to /dev/sdd1.  Not sure that has anything to do with it.\n  \n\n    Edit:  Seems to be an issue with the controller and GPT partition tables.  As a test, I created an array with a couple 120gb SSD's I had laying around.  I created the array with the whole drive, rebooted, and after a reboot the array was still present.  I realized my other drives are configured as GPT.  So I wiped the SSDs, switched them to GPT and again created the array.  This time after a reboot the array was gone, mdadm does not recognize the drives as being part of an array.  Not sure how to fix this."},
{"Title": "Official Giveaway: June 2024 Seagate IronWolf Pro 16TB Hard Drive Giveaway", "Author": "u/Seagate_Surfer", "Content": "Hi \nr/DataHoarder\n crowd! We love your sub and would like to rev up another giveaway with the permission of the mod team.\n  \n\n    The prize is: one 16TB IronWolf Pro Hard Disk Drive\n  \n\n\nHow to enter:\n\n\n\n\nJust reply to this post once with a top-level comment response on the following topic:\n\n\n\n\nWhat kind of loyalty program matters to you for a company? Is drive capacity, price point, excellent customer service, etc. the highest priority for you? Please include the phrases RunWithIronWolf and Seagate in your comment.\n\n\n\n    Selection process/rules\n  \n\n    One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until June 27, 2024 at 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.\n  \n\n    Geographic restrictions:\n  \n\n    Our policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don’t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions (e.g. the obvious shipping restrictions to Russia and Belarus currently)\n  \n\n    US\n  \n\n    Canada (will require a basic skills-based question if winner is chosen by law)\n  \n\n    Brazil\n  \n\n    South America\n  \n\n    United Kingdom\n  \n\n    Germany\n  \n\n    France\n  \n\n    Iberia\n  \n\n    Australia\n  \n\n    New Zealand\n  \n\n    Korea\n  \n\n    India\n  \n\n    Malaysia\n  \n\n    Singapore\n  \n\n    China"},
{"Title": "Is a dual bay HDD docking station right for me?", "Author": "u/Vanillinn", "Content": "Hello! I only have my toe dipped in data hoarding but I've been meaning to buy the orico 6228US3 dual bay non cloning docking station.\n  \n\n    Here is my use case:\n  \n\n\n\n\n\n    Use my extra 3.5\" 500GB HDD for my modded wii u (to be formatted for the wii u) it will be where my games are installed while running the console\n  \n\n\n\n\n\n    back up photos, videos, school files, and game ROMs I have on future storage expansions (1-4TB at a time)\n  \n\n\n\n\n\n    have two drives connected to my pc at the same time\n  \n\n\n\n\n\n    on a very tight budget as a student\n  \n\n\n\n\n\n    In the future, I would like to build my own NAS if I get into bigger data hoarding and archiving. It's something I want to do but do not have the budget for right now. I have a lot of files currently but 1 or 2 more extra drives would be enough. If I could, I'd like to own two copies of my files.\n  \n\n    I have read some posts here on the subreddit raising issues on cooling, partitions, and corrupted drives. On cooling, would it still be an issue for a dual bay? I don't exactly understand the formatting problem of the partitions so I'd like to ask about that too. On corrupted drives, I'll always wait for the disk to stop spinning before ejection and also not move it as much as possible.\n  \n\n    Is a dual bay docking station a good low cost entry into data hoarding or is there an alternative more appropriate for my use case?"},
{"Title": "Is there a software that batch reverse search images and download the best version of it?", "Author": "u/BulgyBoy123", "Content": "Hi guys,\nI'm looking for a software that is able to batch reverse search some images.\nI downloaded all of my pinterest boards, but some of the files are really tiny. I wouldn't mind being able to download bigger versions of said files without having to spend weeks doing that manually."},
{"Title": "YouTube is testing server-side ad injection into video streams (per SponsorBlock Twitter)", "Author": "u/ThePixelHunter", "Content": "No content"},
{"Title": "Easy and reliable storage for students?", "Author": "u/DetImplicitteSubjekt", "Content": "I'm a frequent internet user looking for an easy and reliable way to store my data. I write many personal notes daily, and I have a large number of photos (20k) on my Iphone. Additionally, I have over 700GB of various files, documents, and old system images.\n  \n\n    I currently use icloud for my images. My files are either stored locally on my old Windows or in icloud drive on my Mac.\n  \n\n    I own a Portable SSD, but i rarely use it. (still use 1,5 out of 2TB tho)\n  \n\n    What storage solution would you recommend for my needs?\n  \n\n    I've thought about something like this:\n  \n\n\n\n\n\n    Create a new Google account and purchase Google Drive storage.\n  \n\n\n\n\n\n    Upload all photos and icloud stuff to Google Drive, in a folder named \"iCloud\" for iCloud files and photos.\n  \n\n\n\n\n\n    Simultaneously, upload all files to the Portable SSD.\n  \n\n\n\n\n\n    Additionally, invest in a secondary SSD.\n  \n\n\n\n\n\n    Monthly backup the main SSD to the secondary SSD.\n  \n\n\n\n\n\n    Maintain a monthly routine of cleaning up iPhone photos, then upload them to both the Portable SSD and Google Drive.\n  \n\n\n\n\n\n    What do you think? Will it be enough? Is it too much? Let me hear your thoughts. And please go easy on me😉"},
{"Title": "Price Point", "Author": "u/Crafty_Future4829", "Content": "I apologize in advanced as I know there are a lot related posts to buying refurbished/used hard drives for non critical data.  On eBay,  it seems you can get 16tb exos drives for around 160.00 or 10 per tb.  They say refurbished with zero hours and the reseller (goharddrives) offers a 5 year warranty.\n  \n\n    Where do these hard drives from?  Do they really have zero hours as opposed to having smart data wiped?  Is this a good deal?\n  \n\n    I read another post being able to get used drives for around 5 dollars per tb.\n  \n\n    What is your sweet spot and reliable ebay sellers you would buy from?\n  \n\n    Thanks"},
{"Title": "Came across a Reddit Archive project (Pushshift alternative)", "Author": "u/marinluv", "Content": "Came across this \npost\n yesterday. That user and \nu/RaiderBDev\n are archiving Reddit data. The data is around 3-4Tb roughly from what I have seen.\n  \n\n    The GitHub Repo to archive and access the data: \nHere\n\n\n\n    To download and search Subreddit and user data manually: \nHere\n\n\n\n    Post on \nr/pushshift\n for the 2.5TB dump: \nHere"},
{"Title": "How much would it cost me to have and maintain a 1 TB database?", "Author": "u/AtwoodEnterprise", "Content": "I have an SEO SaaS and I store a lot of data for keywords and backlinks.\n  \n\n    My database is about 50gb and I’m currently paying about $80/mo for my webhosting VPS and up to 75gb of database storage.\n  \n\n    Currently, I use a lot of API’s to pull SEO data down because it’s such a hassle to store that much data, but over the next year I want to try and up my game a bit.\n  \n\n    So I’m gonna try and start off by increasing my keyword, and my backlink data to around 1 TB total if possible. The majority of the data is gonna be due to the backlink data of course.\n  \n\n    Would anyone have any estimates for how much something like this might cost? Or what factors I should consider/ask when obtaining pricing?"},
{"Title": "Hulkshare Hacks?", "Author": "u/mamba_regime19", "Content": "Is there an easy way to download larger songs/mp3's from Hulkshare?\n\n\n\n    Found some old shows no longer available anywhere else that I wouldn't mind having but the files stop playing after like 10 mins so my downloaders stop as well.\n  \n\n    Is there anything like YoutubetoMp3 or SoundcloudtoMp3 that works?\n  \n\n    Saw some older posts from 11years ago....not sure if anybody has figured it out since then.\n  \n\n    Thanks!"},
{"Title": "Lsi hba 9207-8i", "Author": "u/Crystal_Jayhawk", "Content": "No content"},
{"Title": "SATA only 50 to 500 mating cycles - what do you use for backup?", "Author": "u/No-Balance-8038", "Content": "I've got currently 5 backup 3.5\" HDD disks which are planned to be stored offsite. And backup is earliest weekly. But the real issue is that according to the SATA specification, after 50 times replugging the disk, both the Server slot for 3.5\" or the HDD itself can fail!\n  \n\n    What do I do? Put the disks in a USB enclosure and never remove it again?\nBut what about keeping the HDD running in proper temperature? My current usb cases do not have fans, and USB is not as reliable. I know turning off UASP helps for that, but I am still kind of disappointed that I am not meant to regularly take backups from SATA disks.\n  \n\n    I know theres also eSATA, but  I am not sure which combination of that would be reliable! I could basically instead have a PCIe eSATA card and eSATA cases.\nI even found two suitable cases \nhttps://www.turtlecase.eu/5-hdd/40-35-hard-drive-hdd-5-capacity-long-slots-waterproof-hd-5-turtle-case.html\n or \nhttps://www.feldherr.com/feldherr-esd-schaumstoff-set-euro-box-mit-16-faecher-fuer-3-5-zoll-festplatten/a-61567\n\n\n\n    What do you guys do recommend?"},
{"Title": "Verifying disk/data integrity before backup?", "Author": "u/Unnombrepls", "Content": "Hi guys,\n  \n\n    So I backup my important things from other drives in a 8 TB drive each 15 days. Recently, I have been worrying that a disk might fail; but not catastrophically, still being able to copy and open most files, while displaying normal SMART values. That could make me substitute a totally healthy backup with corrupted files without knowing. Thus, I have resolved to do disk checks before updating my backups.\n  \n\n    I was wondering if you guys know any software that checks the disks with more depth than just SMART and that can do it in around 3-4 hours. It doesn't need to create a super extensive report; but to identify any problem so I can run a deeper analysis later to pinpoint or solve the exact issue (I would also be grateful if you can recommend me any program for this)."},
{"Title": "Best way to contact Seagate for warranty?", "Author": "u/green314159", "Content": "*** Update - I got in contact with Seagate and they wanted me to send them the drive and pay for the shipping costs when sending it in to them. They will cover the shipping costs for the return trip. Does this seem like standard procedure? It's my first time needing to RMA during the warranty period. I live in the USA.\n  \n\n    Original post: A Seagate Barracuda 8TB drive with warranty expiration date sometime in 2025 has failed the other day. What is the best way to get in contact with technical support and get the warranty and replacement going? Sorry if this is the wrong place on Reddit to ask"},
{"Title": "Where to find US Trademark Data", "Author": "u/Acrobatic_Stay_9221", "Content": "Hi, I'm looking for granular US trademark data that includes the name of the company that filed the trademark (I'm trying to view summary statistics on trademark filed by company in the US).\n  \n\n    I've tried: \nhttps://tmsearch.uspto.gov/search/search-resultsbut\n but can't find out how to get the aggregate data out of this.\n  \n\n    I've been told that this data should be publicly available, but am stumped on where to find it.\n  \n\n    Has anyone \"hoarded\" a data set that would have this data? Alternatively, does anyone know how to scrape data from this lookup above?"},
{"Title": "Samsung 970 evo plus M2 ssd boot drive not recognizing any more. Now what?", "Author": "u/tobyisthecoolest", "Content": "I’ve been using this drive for about 1.5years and today got the boot drive not detected error. I opened bios, but the only shows up sometimes.\n  \n\n    I have a m2 to usb adapter, but the drive isn’t showing up on my other computers, so I can’t seem to copy the data off it easily.\n  \n\n    I’ve found posts with other ppl having problems with the EVO plus drives.\n  \n\n    What should I do now?\n  \n\n    If I buy a replacement boot drive how do I get windows onto it? My back ups aren’t perfect, so is there data recovery possible?\n  \n\n    Thanks"},
{"Title": "Any good suggestions for hardware to transfer analogue camcorder footage to a computer?", "Author": "u/Zazabar11", "Content": "My camcorder has av out and I have cables going from the camcorder to a framemister, which converts the signal to digital and uses an HDMI cable to transfer the signal to an elgato hd 60s, which ends with a USB C cable going to my computer for capture. It's a bit, but it has worked for older VHS tapes pretty well. I'm also using the basic capture software which comes with the elgato software.\n  \n\n    While trying to get footage from my camcorder, I noticed the audio and video footage stops getting captured on my PC when the tracking gets real messy, even if only for a couple seconds, and it ruins lots of the tape.\n  \n\n    Any suggestions for a capturing device which can handle any sort of tracking that may be required by the tapes?\n  \n\n    To note, I'm using a Sony CCD-TRV57, which uses VHS-C tapes (they're a compact form of regular VHS tapes)."},
{"Title": "winhttrack problem with cloning a single landing page. Any solutions?", "Author": "u/SolidShowerr", "Content": "I want to clone a landing page, I do everything right and download the files, but when I try to go to the index, it just opens the \"Loading screen\" from that page but not the page, it stays stuck on \"Loading\". Do you have a solution? Thank you\n  \nhttps://preview.redd.it/winhttrack-problem-with-cloning-a-single-landing-page-any-v0-9ywe6e7ja26d1.jpg"},
{"Title": "How to download Twitch vod?", "Author": "u/RainBowSwift71532", "Content": "I've been trying to download a twitch vod but have had no luck in doing so. If I want to download say a YouTube video. Search download YouTube video and a bunch of site pop up. Click on one copy and paste the YouTube link. Pick resolution and click download mad easy. But for some reason it's harder for a twitch vod. I have yet to find a site that will allow me to download a twitch vod. I'm trying to download a streamers recent twitch vod.\n  \n\n    I've tried a Twitch downloader for windows and it didn't work. It wouldn't download the video. So does anyone know a good site to download twitch vods? Please let me know!!"},
{"Title": "Internet Download Manager stopped detecting YouTube MKV format videos to download", "Author": "u/TheHighImperial", "Content": "Just today I discovered that it detects them if the video is embedded on a forum but not showing for the same video directly at YouTubes page. Ive updated the browser, IDM extension and even software. I also tried it on a different computer... same problem."},
{"Title": "Do I need to reformat my drives?", "Author": "u/Sinnagangsta", "Content": "My Plex server storage is running off a WD MyCloud EX4. When I first started my server I only had 1 4TB drive, but I quickly outgrew that. The drive mode is set as JBOD “one drive”. I have another 4TB drive that I want to put in my NAS, but when I go in to change the RAID mode, I get warnings saying that all data will be lost. I know my only RAID options are 0 and 1. I believe I can also use JBOD as well with two drives? I’m not worried about redundancy as I can easily redownload content but would not like to have my drives erased just to add another drive. What would be the best way to move forward?"},
{"Title": "How much damage have I caused from leaving a HDD in the sun?", "Author": "u/JerichoBlows", "Content": "I ordered a refurbished 12TB Seagate Enterprise HDD and it was delivered today while I wasn't home. It was over +100°F (+38°C) degrees today and the sun was beaming directly on the mailbox for 4 hours before I got to it. I suspected the box could have easily been 130°F (55°C) or possibly much hotter having been in the direct sunlight for so long. I immediately put the entire box in the refrigerator. After about 5 minutes in the fridge, I decided to measure the temp using a digital BBQ thermometer. It measured at 104°F (40°C) but this was likely not accurate because I was using a thermometer that is meant to be shoved inside of meat and the box had already been in the fridge for 5 mins.\n  \n\n    How much damage could have been caused from it sitting in the direct +100°F (+38°C) degree sunlight for just over 4 hours? Thanks!"},
{"Title": "Vimms Lair, the largest collections of ROMs, is being taken down.", "Author": "u/snowysysadmin59", "Content": "Corporate greed at it again. Anyone got a backup? 🥺"},
{"Title": "Huge Collection", "Author": "u/CoreDreamStudiosLLC", "Content": "Good evening, hope all is well. I lost my dad on Saturday and was going through some things to get bills paid/cancelled, etc. He had over 430 media discs at his apartment which I've taken back to me.\n  \n\n    Most are DVD-R, about 20 are DVD, and the rest are DVD+RW and Divx.\n  \n\n    Is it worth ripping each one of the DVD-R's at minimum? Some are very rare and streaming sites probably won't even half this collection."},
{"Title": "3D printed 8-Bay DAS with Supermicro backplane, trays, PSUs and external SAS-8088 connectors", "Author": "u/kschaffner", "Content": "https://imgur.com/a/YcbODga\n\n\n\n\nhttps://makerworld.com/en/models/491457\n\n\n\n    I've been working hard on this project for the past couple months in my spare time trying to make a product that I couldn't really find on the market. I had some extra PSUs and fans and supermicro trays so I figured why not design around that. I've probably put no less than 40+ hours into design, print, redesign, print, try fitment etc. Not the most experience with Fusion360 or CAD in general. The front LEDs do light up during activity :). I've been thinking of expanding this into a mATX or Mini-ITX supported case as well.\n  \n\n    I know this is also pretty much on the heals of shaztech_info but I think we have enough differences between us and I was kinda shocked to see someone else coming out with a similar idea around the same time lol. Let me know what you fellas and fellettes think!\n  \n\n    From Makerworld:\n  \n\n    I was unable to find a product that met my specifications of 8 hot-swap bays, a SAS backplane and external SAS connectors for easy connectivity, so I decided to design and build my own 8-bay Direct Attached Storage (DAS). This DAS features a Supermicro SAS833TQ backplane with Gen 5.5 hot-swap 3.5\" trays. It is powered by either a 200W PWS-203-1H (as-shown) or a 350W PWS-351-1H (or similar units of the same dimensions: PWS-351-1H 100 x 40 x 220mm, PWS-203-1H 76 x 40.3 x 192mm) power supply. Additionally, it includes an external SAS SFF-8088 to SFF-8087 adapter to cut down on internal wires.\n  \n\n    I printed this on my X1C and have realized that making it available for smaller print beds should also be done instead of 1 large single print.\n  \n\n    The body is 255 W x 190 H x 245mm D, it is printed as a single print, no supports needed. The body at 10% infill, 2 walls with gyroid infill .20mm layer height with a 0.4mm nozzle. This print requires NO supports to print. The print of the body will use approximately 984.5g of filament if no painting is done of the logo or numbers, and 982.6g if painted of a single color. This print took roughly 20 hours to print. I realize this might also be a turn off being a large print but I wasn't wanting to have to glue or screw it together if I could help it. If you are wanting this, let me know and I can work it into a new version. There are 2 version of the back plate for the different sizes of PSUs mentioned.\n  \n\n    Here is the list of parts used for this build:\n  \n\n\n\n\n\n\n\n            Part\n          \n\n            Price\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              Supermicro Gen 5.5 3.5\" trays (MCP-220-00075-0B) x8\n            \n\n              ~$50 for 8 on eBay\n            \n\n\n\n\n\n              Supermicro SAS833TQ 8-bay SAS backplane\n            \n\n              ~$35 on eBay\n            \n\n\n\n\n\n              SFF-8087 to SATA breakout cable x2\n            \n\n              ~$16\n            \n\n\n\n\n\n              SFF-8088 to SFF-8087 adapter\n            \n\n              ~$30\n            \n\n\n\n\n\n              Supermicro 1U PSU of dimensions 100 x 40 x 220mm or 76 x 40.3 x 192mm (As seen PWS-203-1H)\n            \n\n              ~32$ on eBay, also designed screw hole for PWS-351-1H ~$30 on eBay\n            \n\n\n\n\n\n              Molex Y-cable\n            \n\n              ~$6\n            \n\n\n\n\n\n              120mm of your choice x2 (Noctua NF-P12 shown)\n            \n\n              ~$16 ea.\n            \n\n\n\n\n\n              ATX power jumper cable w/ switch\n            \n\n              ~$11\n            \n\n\n\n\n\n              This required a tool to remove the pins from the connector to feed it through the hole\n            \n\n              ~$17, you don't have to get one like this, but I wanted the other pin extractors for future projects.)\n            \n\n\n\n\n\n\n\n    Grand Total of parts: $210, could save $32 with some random 120mm fans as long as they can pull through all the trays.\n  \n\n    For hardware needed:\n  \n\n\n\n\n\n\n\n            Part\n          \n\n            qty\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              M3x4x5 Heatset inserts\n            \n\n              7\n            \n\n\n\n\n\n              M4x6x6 Heatset inserts\n            \n\n              6\n            \n\n\n\n\n\n              M3x6 socket head screw\n            \n\n              3\n            \n\n\n\n\n\n              M3x12 socket head screw\n            \n\n              4\n            \n\n\n\n\n\n              M4x8 socket head screw\n            \n\n              6\n            \n\n\n\n\n\n\n\n    Some optional parts that might be desired:\n  \n\n    120mm wire fan grills ~$8\n  \n\n    Some rubber feet for the bottom"},
{"Title": "Is there a way to backup recorded classes on a private google drive file?", "Author": "u/simonbleu", "Content": "So, basically the classes im taking are recorded for review, and uploaded to google drive. I can see them but not download them, and  it would be very very laborious to record the screen so my question is if there is a way to download them anyway. I couldnt with the browser inspector\n  \n\n    I do understand that the policy of the institute is not to download the classes becuase of risk of misuse, but my intentions are merely about doing a backup of the classes for future reference. The classes *will* be deleted afterwards, and is not like I will have access to other otnes im not in.\n  \n\n    Not sure if this is the right place to ask but one can be hopeful I guess. Thanks in advance!"},
{"Title": "YouTube is A/B testing requiring login for video playback", "Author": "u/ThePixelHunter", "Content": "No content"},
{"Title": "Ways to summarize rsync logs? Too verbose so I never read them", "Author": "u/Ninj_Pizz_ha", "Content": "There's too much output from my rsync such that I end up not reading what was added/deleted. I think part of the issue is that \nit's logging stupid stuff like if a file timestamp got changed.\n\n\n\n    Really, I'd like a summary at the top that shows like \"x number of files from folder y were deleted/added.\" I'm using the \n-aih\n flags.\n  \n\n    Apologies for the somewhat vague question."},
{"Title": "Simple web scraping Chrome extension side project", "Author": "u/Fair_Perspective_761", "Content": "I made a free Chrome extension that scrapes all plain text from the active webpage and download's it as a plain text .txt file. It works great on articles, blogs, online forums (Reddit), wiki's, and more. It has a filter option that filters out smaller text elements and keeps large elements.\n  \n\n    I made this extension as a tool to 'pre-process' large websites before analyzing them with ChatGPT. Cmd + A, Cmd + C, and Cmd + V wasn't cutting it for me, and ChatGPT 4o can process almost 100x more words when fed a plain text .txt file.\n  \n\n    Any feedback would be great. I don't track data and everything runs native in the users browser.\n  \n\n    My extension: \nWeb.txt"},
{"Title": "My home backup method is bad. I need help re-thinking it.", "Author": "u/Zach83", "Content": "I don't know a lot about networking, storage, and proper backing up. I'm a 3d artist and do some coding on the side so I don't get scared by technical manuals or learning new tech, but proper sys adminning is not my strength.\nI just did some reading on things like windows backup and mirroring and now I think I need to update/change/modernize how I backup my stuff.\nApparently the things I am relying on are NOT reliable at all.\nSo I dove in and now I can't see the forest for the trees anymore. I need help thinking this out.\n  \n\n\nMy current setup\nI have a work/gaming pc with 2 2TB drives and a synology 1 disk(2TB) NAS device.\nThe windows PC contains important data, the NAS serves media to a media pc(that needs no backing up) and some tablets\n  \n\n    To back these up I have a windows based \"NAS\" with 2 mirrored volumes, F and G. 2 4TB volumes (so 4 disks, 4TB each, 2 used for each mirorred volume)\nOn the Work PC there are three folders that I manually backup to G while working. Daily backups sort off.\nEvery week I run a Bat file with a few robocopy commands on the windows \"NAS\". The BAT maps the work PC's drives and the synology NAS drive and then does a copy with options like /mir and /purge. Essentially an incremental backup of the NAS and work PC drives to the windows \"NAS\".\n  \n\n    A few times a year a I run a second bat script. It copies everything to external devices that I store in my shed. Best offsite backup available to me.\n  \n\n\nmy questions\nHow to mirror?\nApparently windows mirrored volumes can not be relied on? I use it to protect against disk failure and apparently there are situations where the still working disk will NOT be read by another windows pc. Kinda defeats the point.\nI want such protection on the windows \"NAS\", an automatic and fast mirror copy.\nI want to be able to put any disk of the mirror pair in any other windows pc and have it appear like a normal disk, so it should be NTFS.\nWhat should I do? There are so many options and I have no idea what is reliable.\n  \n\n\nHow to backup without Robocopy (in a file system that windows can read like ntfs, and without puting files into a proprietary binary blob)?\nI'm told I shouldn't use Robocopy for incremental backups because it's too easy to fuck up, and should power cut out while copying I could be fucked.\nGoogling I went, searching for a way with the following requirements:\n  \n\n\n\n\n\n    I want to backup the synology nas and the 2 disks on the work pc weekly, to the windows \"NAS\".\n  \n\n\n\n\n\n    I only want to copy changed or new files and I want to remove files that no longer exist in the original source.\n  \n\n\n\n\n\n    The backup should not go into a binary blob, I want loose files.\n  \n\n\n\n\n\n    No need for file versions/history.\n  \n\n\n\n\n\n    Timestamps(date modifed/created) are important to me.\n  \n\n\n\n\n\n    And I found nothing. I probably don't even know the right terms to search for.\nHow should I do this backup?\n  \n\n    Ideally this should not involve signing up for a service or managed via a web interface hosted by some company. I want to keep everything in home and away from the internet.\nFree would be nice too."},
{"Title": "Is the video conversion offered by VIDBOX (was Honestech) a reliable product also, how would I go about digitizing old VHS/VCR videos?", "Author": "u/Duck_Dur", "Content": "Hello All,\n  \n\n    Is the video conservation service offered by VIDBOX (previously Honestech) a reliable product and how would you go about digitizing old VHS/VCR videos and if you were to recommend another brand, what would it be?\n  \n\n    EDIT: Fixed grammer"},
{"Title": "Any optical media ratings / testers out there checking media surfacing recently? Ridata Valor bd-r 10x brand?", "Author": "u/Gbxx69", "Content": "I lost track of the definitive site(s) for reviewing optical media or at least blu-ray discs / brands / sub brands.. can anyone send a link to who's doing the due diligence on media these days?\n  \n\n    I've seen Ridata Valor 10x bd-r discs which seem to be sold cheaper than PlexDisc or even the 6x RiData bd-r's... so what gives.. why is it somewhat cheaper?!? Were these sitting in a warehouse somewhere since before 2020 or something??!?\n  \n\n    I am looking to use the media as backup of videos, software and occasionally important data (of which I would make multiple backups over time)."},
{"Title": "Chown Errors Running Rsnyc Going from Unraid to Unassigned Device", "Author": "u/klnadler", "Content": "Hi everyone, I'm syncing some files from my unraid to an external drive and I'm having issues with permissions, I did run newperms on the unraid side but I think this is a destination problem. The files seem to be transferring but not with the correct permissions\n  \nCommand: rsync -avPh\n05/2019-05-01/DSC00001(1)-2.ARW\n         32.77K   0%  248.06kB/s    0:01:40  rsync: [receiver] chown \"destination/2019/05/2019-05-01/.DSC00001(1)-1.ARW.sDzkxQ\" failed: Operation not permitted (1)\n         24.85M 100%   92.20MB/s    0:00:00 (xfr#2, ir-chk=1498/1516)\n05/2019-05-01/DSC00001(1)-positive-1.tif\n         32.77K   0%  118.96kB/s    0:07:37  rsync: [receiver] chown \"destination/05/2019-05-01/.DSC00001(1)-2.ARW.Q8mP3g\" failed: Operation not permitted (1)\n         54.49M 100%   99.36MB/s    0:00:00 (xfr#3, ir-chk=1497/1516)"},
{"Title": "M2 Pro/M3 Pro w/ 990 Pro NVMe + 40 Gb/s external", "Author": "u/Direct-Button1358", "Content": "Hi all,\n  \n\n    Systems: Mac Mini M2 Pro, MBP M3 Pro\n  \n\n    Thank you for your time. I am trying to put together an external drive using the Samsung 990 PRO NVMe with an external enclosure rated at 40 Gb/s like the ugreen or acasis.\n  \n\n    I do have a few questions:\n  \n\n\n\n\n\n    What external enclosure would work best for use with my M2 Pro and M3 Pro, I mostly do research and will be using it as an extended mobile storage solution .\n  \n\n\n\n\n\n    Is this overkill for my usage? Keep in mind, the difference in price between this SSD and others that write at half the speed is maybe $50 .  I am using my University start up funds for the purchase.\n  \n\n\n\n\n\n    Additionally: I am interested in eventually setting up NAS using this SSD paired with something like a Yottamaster enclosure.\n  \n\n    Thanks!"},
{"Title": "VirtualDub won't record audio from capture card but sound works fine outside of recording", "Author": "u/Throwaway173638o", "Content": "I'm trying to capture video and audio from my JVC HR-S7100U through a GV-USB2 capture card device.  I am using S-Video as source with composite as my audio sources.  I set the audio source to the device.\n  \n\n    When I try to capture video, the audio doesn't get recorded.  But when I'm not recording under Overview mode, the volume is playing fine.  Preview mode doesn't work for audio too.\n  \n\n    I also don't have any issues recording video and audio from OBS.  However I want to stick with Virtualdub for the best quality.\n  \n\n    I don't know what I can really do to fix this?"},
{"Title": "Download from Google Sites Embedded Image Pages", "Author": "u/kylemj89", "Content": "I am trying to download batch urls and renaming each image in sequence order.\n  \n\n    The images are saves with unique urls from google sites and fails to download after multiple saves using python BeautifulSoup and request\n  \n\n    Wget runs into the same\n  \n\n    HTTrack fails to download the webpages as dispayed (haven't yet got as far as renaming sequence\n  \n\n    Bulk Image downloader doesn't have the ability to rename or save in folders from \nhttps://tigerlovefish.com/\n\n\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/472-1st-january-14th-january-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/474-29th-january-11th-february-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1996/467-23rdoctober-5th-november-1996\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/478-26th-march-8th-april-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/480-23rd-april-6th-may-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/482-21st-may-3rd-june-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/484-18th-june-1st-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/486-17th-july-29th-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/490-10th-september-23rd-september-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/492-8th-october-21st-october-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/494-5th-november-18th-november-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/496-3rd-december-17th-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/tour-programme-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/477-12th-march-25th-march-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/479-9th-april-22nd-april-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/481-7th-may-20th-may-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/483-4th-june-17th-june-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/485-2nd-july-16th-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/487-30th-july-12th-august-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/489-27th-august-9th-september-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/491-24th-september-7th-october-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/493-22nd-october-4th-november-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/495-19th-november-2nd-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/497-17th-december-31st-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/498-1st-january-13th-january-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/500-28th-january-10th-february-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/502-25th-february-10th-march-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/504-25th-march-7th-april-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/506-22nd-april-5th-may-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/508-20th-may-2nd-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/510-17th-june-30th-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/512-15th-july-28th-july-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/514-12th-august-25th-august-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/516-9th-september-22nd-september-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/518-7th-october-20th-october-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/520-4th-november-17th-november-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/522-2nd-december-15th-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/524-30th-december-1998-12th-january-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/499-14th-january-27th-january-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/501-11th-february-24th-february-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/503-11th-march-24th-march-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/505-8th-april-21st-april-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/507-6th-may-19th-may-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/509-3rd-june-16th-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/511-1st-july-14th-july-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/513-29th-july-11th-august-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/515-26th-august-8th-september-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/517-23rd-september-6th-october-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/519-21st-october-3rd-november-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/521-18th-november-1st-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/523-16th-december-29th-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/tour-programme-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/525-13th-january-26th-january-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/527-10th-february-23rd-february-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/529-10th-march-23rd-march-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/531-7th-april-20th-april-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/533-5th-may-18th-may-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/535-2nd-june-15th-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/537-30th-june-13th-july-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/539-28th-july-10th-august-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/541-25th-august-7th-september-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/543-22nd-september-5th-october-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/545-20th-october-2nd-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/547-17th-november-30th-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/549-15th-december-28th-december-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/poll-winners-party-and-tour-programme-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/526-27th-january-9th-february-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/528-24th-february-9th-march-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/530-24th-march-6th-april-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/532-21st-april-4th-may-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/534-19th-may-1st-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/536-16th-june-29th-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/538-14th-july-27th-july-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/540-11th-august-24th-august-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/542-8th-september-21st-september-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/544-6th-october-19th-october-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/546-3rd-november-16th-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/548-1st-december-14th-december-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/550-29thdecember-1989-11th-january-2000\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/poll-winners-party-and-tour-programme-1999\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/551-12thjanuary-25thjanuary-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/553-9th-february-22nd-february-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/555-8th-march-21st-march-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/557-5th-april-18th-april-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/559-3rd-may-16th-may-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/561-31stmay-13thjune-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/563-28thjune-11thjuly-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/565-26th-july-8th-august-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/567-23rd-august-5th-september-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/569-20th-september-3rd-october-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/571-18thoctober-31stoctober2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/573-15thnovember-28thnovember-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/575-13thdecember-9th-january-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/tour-programme-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/552-26th-january-8th-february-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/554-23rd-february-8th-march-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/556-22nd-march-4th-april-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/558-19th-april-2nd-may-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/560-17thmay-30thmay2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/562-14thjune-27thjune-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/564-12thjuly-25thjuly-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/566-9th-august-22nd-august-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/568-6th-september-19th-september-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/570-4th-october-17thoctober-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/572-1st-november-14th-november-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/574-29th-november-12th-december-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/576-free-with-issue-575\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/577-10thjanuary-23rdjanuary-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/579-7th-february-20th-february-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/581-7th-march-20th-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/583-4th-april-17th-april-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/585-2nd-may-15th-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/587-30th-may-12th-june-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/589-27thjune-10thjuly-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/591-25th-july-7th-august-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/593-22nd-august-4th-september-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/595-19th-september-2nd-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/597-17th-october-30th-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/599-14th-november-27th-november-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/601-19th-december-2001-8th-january-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/smash-hits-brits-special-1st-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/578-24thjanuary-6thfebruary-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/580-21st-february-6th-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/582-21st-march-3rd-april-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/584-18th-april-1st-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/586-16th-may-29th-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/588-13thjune-26thjune-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/590-11thjuly-24thjuly-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/592-8th-august-21st-august-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/594-5th-september-18th-september-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/596-3rd-october-16th-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/598-31st-october-13th-november-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/600-28th-november-18th-december-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/602-19th-december-2001-8th-january-2002-free-with-issue-601\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/603-9th-january-22nd-january-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/605-6th-february-19th-february-2002\nhttps://sites.google.com/view/smash-hits-remembered-01/home/2002/607-6th-march-19th-march-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/609-3rd-april-16th-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/611-1st-may-14th-may-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/613-29th-may-11th-june-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/615-26th-june-9th-july-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/617-24th-july-6th-august-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/619-23rd-august-3rd-september-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/621-18th-september-1st-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/623-16th-october-29th-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/625-13th-november-26th-november-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/627-18th-december-2002-7th-january-2003\nhttps://sites.google.com/view/smash-hits-remembered-01/home/2002/604-23rd-january-5th-february-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/606-20th-february-5th-march-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/608-20th-march-2nd-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/610-17th-april-30th-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/612-15th-may-28th-may-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/614-12th-june-25th-june-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/616-10th-july-23rd-july-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/618-7th-august-20th-august-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/620-4th-september-17th-september-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/622-2nd-october-15th-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/624-30th-october-12th-november-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/626-27th-november-17th-december-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/sneak-preview-magazine\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/636-30th-april-13th-may-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/638-28th-may-10th-june-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/642-23rd-july-5th-august-2003\nhttps://sites.google.com/view/smashhitsremembered01/home/2003/summer-quiz-book\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/635-16th-april-29th-april-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2004/659-5th-march-18th-march-2004\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2004/659-5th-march-18th-march-2004"},
{"Title": "Media storage guide for a highschooler", "Author": "u/MintedMince", "Content": "Hi! So I am a highschooler from a third world country and recently I have been struggling to keep all of my data intact. I have been juggling around 1 or 2 spare hard-drives and google accounts to somehow store family photos and other important media with as many backups as I can make. The thing is, I can't really afford a lot to invest into some more high-end, and I really do not want to loose my (had a few close calls, though my backups saved me). So any advice on improving the situation or do most people hang around doing the same thing? Would love to hear from yall :)"},
{"Title": "Advice/guidance needed for a first time NAS builder", "Author": "u/de4thr4sher", "Content": "Hello everyone! I've been lurking around here for quite some time and all I'll say is that I've been inspired by your posts so much that I've decided to dive into the realm of building my first NAS and be a data hoarder myself. But I'll need your help with that as I've been very confused with a lot of things and obviously, I don't want to screw everything up.\n  \n\n    So, first things first. My intention with the setup is purely just hoarding data on a separate machine other than my main PC while i keep everything safe and secure as much as possible. I don't need it to be accessible from anywhere or anything like that, just locally from my main PC. Like an enormous external HDD to put it simply. I don't need crazy speeds either as I won't be using it for work or anything similar. It's main use will be storing and playing my audio/video files from there and ofc, store a lot of other files and having backups of my main system and other devices.\n  \n\n    I'll be starting with the hardware I already own and the ones I plan on buying (suggestions are welcome ofc)\n  \n\n    *Already owned hardware*\n  \n\n    Option 1 for mobo/CPU/RAM would be my old setup:\n  \n\n    A Z390-E paired with a 9700k (8C/8T) and 32GB (DDR4-3000) of RAM\n  \n\n    Option 2 would be a setup I got recently for free:\n  \n\n    An Asus ROG Maximus VII paired with a 4790k (4C/8T) and 16GB (DDR3-1600).\n  \n\n    A 700W Coolermaster PSU that I also got with the free setup, an old spare Kingston SSDNow V300 240GB and if I manage to finally build this NAS, I'll be getting rid of a 4TB WD drive and an 8TB Ironwolf drive.\n  \n\n    Will I have to use the 9700k setup in this case or even the 4790k will be enough?\n  \n\n    *Hardware I plan on buying*\n  \n\n    The goal for now is to get 4 drives so I can have 2 of them for redundancy and add another 4 next year and hopefully I won't have a storage issue for a long time.\n  \n\n    I've locked my eyes on Exos X16 14TB and on X18 16TB drives and a Define 7 XL R2 case for this whole setup as all these are in a fairly good price right now where I'm from. Seagate lists these drives as CMR so I guess shouldn't be concerned...? Later on I know I'll also have to get a Pci-e to 4x sata or something like that.\n  \n\n    That's about it as far as hardware goes. Let's dive into software now, shall we?\n  \n\n    The most confusing part for me and where I need your advice the most. What should I go for?\n  \n\n    I see a lot of people recommending unRAID for basic setups like this. I got very confused when I was trying to decide between that or TrueNAS and eventually I gave it up and decided to ask the experts here. What would you do? Is it worth spending extra for an unRAID licence?\n  \n\n    I know this post is stupid for 99.8% of you but it's obviously not my field of expertise and I'm trying to not spend anywhere else right now, except mainly for HDDs and a case.\n  \n\n    Suggestions AND roasts are welcome! :) Thanks in advance!"},
{"Title": "Rosewill hot swap bay source/alternative?", "Author": "u/thecaramelbandit", "Content": "I've got a rosewill 4U case with one of their 4x3.5 hot swap enclosures. I want to add a second but they seem to be out of stock everywhere.\n  \n\n    Anyone have a source for one, or know of an alternative that will also fit?"},
{"Title": "4x5.25\" to 7x3.5\" adapter?", "Author": "u/Adam1394", "Content": "Hello, I look for aforementioned adapter for my Define XL R2 case."},
{"Title": "\"Vimm's Lair\" receives notice to remove tons of games.", "Author": "u/blackletum", "Content": "No content"},
{"Title": "\"Best\" 3.5\" 8Tb HDD Brand?", "Author": "u/Large_Medium_8984", "Content": "This question pops up all the time on here but I only see specific use cases when others ask and nothing really close to what my situation is. I'm looking to bring together all of mine and my families ancient Hard drives, laptop backups, flash drives, externals, family photo scans and videos all onto a few backup HDDs. Just over a Million files @ under 6TB that I'd like to put into an 8Tb HDD (or 2). Photos, Videos, Text Docs, and whatever else might be in there. These drives will not be used for gaming at all, so no need to worry about being rough on the drive with pulling all the time, as I see a lot of people looking for gaming AND storage when asking this. Just something to have peace of mind that nothing could go wrong in a reasonable amount of time with them. I've read good and bad things about both Seagate Barracuda and Western Digital Blue. Are there other 3.5\"s I should also look in to? I'm not expecting these drives to live dormant 5-10 years, but it would be nice. I'd like to read any and all personal experiences users have had over the years."},
{"Title": "Raid controller advices", "Author": "u/Surax98", "Content": "Hello guys, I am looking for a raid controller to be used over USB 3.2 10Gbps (I know, it's far from being advisable but that's the only thing I can do right now, since my server is a laptop) and I have to choose between the following:\n  \n\n\n\n\n\n    IBM M5015 (PCIe 2.0 x8, SAS 6Gbps, 512MB cache DDR2 800MHz) for 20€ and located in my city\n  \n\n\n\n\n\n    LSI 9271 (PCIe 3.0 x8, SAS 6Gbps, 1GB cache DDR3 idk-how-many MHz) for 33€ shipped from China.\n  \n\n\n\n\n\n    Now, since I am over USB 10Gbps, I am limited in both scenarios, but I'd like to know if that faster and more cache of the 9271 will actually make a difference for a domestic usage. To help you better understand my use cases, I will list them:\n  \n\n\n\n\n\n    Plex and Jellyfin media server\n  \n\n\n\n\n\n    IMMICH for photo synching\n  \n\n\n\n\n\n    Nextcloud for everything else\n  \n\n\n\n\n\n    These are the main I/O bound containers I am running on my server. What do you think? Any other suggestions for a raid controller, instead (which costs less than 40€)?"},
{"Title": "Question related to the voiceover feature (headphone symbol) in internet archive", "Author": "u/69PepperoniPickles69", "Content": "Do you know if there's a way to upload my own files so that listen to them instead of reading? Or does it have to include actually uploading books and them getting approved, scripted and so on? And if so do you guys know any alternative website where we can upload large texts for listening with decent quality?"},
{"Title": "How best to migrate to new hardware?", "Author": "u/SlayterDevAgain", "Content": "I'm about to build a new NAS. With my current NAS I just kind of threw drives at it as I aquired them (2x 2TB in RAID 1, a 4TB and a 6TB drive in pools by themselves, and 5 6TB drives in an external enclosure in RAID 5).\n  \n\n    In the new build I have 3 10TB drives I'll be adding. I don't necessarily need to keep all the drives from the old build (I at least want the 5x 6TB drives but not externally) but what would be the best way to migrate the data to the new build? Any advice is appreciated.\n  \n\n    Further info: Current build is FreeNAS and I'll probably keep with that or TrueNAS."},
{"Title": "Historical data hoarders at the library of Alexandria lost untolds amount of work and knowledge after the library was burned. Sumerian texts survived 4000+ years due to being written on clay tablets. Is there any efforts to transcribe some of our knowledge into more permanent media?", "Author": "u/rrybwyb", "Content": "I mostly hoard books. Its amazing how many I can fit onto just a small 10 tb hard drive. But if that gets wet, dropped, or someone holds a magnet to it, I've lost millions of hours of research and knowledge from 10's of thousands of authors.\n  \n\n    Even looking at the history of the dead sea scrolls, Whatever idiots were in charge of transporting those did an awful job. They were taken from the dry desert to a place where they could get humid and rot.\n  \n\n    Are there any organizations out there that have transcribed some of our more important items into stone or clay? I've been looking more into Sumerian history and the reason we have many of these items still is because they were carved into clay - and clay can last a pretty long time.\n  \n\n    Its kind of short sighted of humans to think we're immune to a giant asteroid or nuclear winter. In that situation, What would humans 5,000 years in the future after a major catastrophe be able to look back on and decipher about the 2000s?\n  \n\n    Edit: also I can't believe I forgot about plastic. That supposedly forever product that never breaks down. Does anyone know if it is really as permanent as something like ceramic? I've seen it become quite brittle and disintegrate when left out in the sun for even 6-12 months"},
{"Title": "When to consider pre-emptive replacement of drives?", "Author": "u/MagicPracticalFlame", "Content": "I've got a small NAS with 4 x 6tb Drives in. The drives have just ticked over the 40,000 (grim dark) power-on time. Given that all the drives where purchased and installed at the same time, I'm worried about one crapping out and causing a domino effect when I get the replacement in to rebuild the array.\n  \n\n    The drives are Seagate ST6000VN0033 drives, health status shows as good on all counts. Just wondering when you guys start to consider replacement or migration to a new NAS (which is what I'd probably do)."},
{"Title": "Any good Kemono/coomer bulk downloaders?", "Author": "u/TravDeMan", "Content": "I've been looking for a while and im struggling to find any"},
{"Title": "Live sync of data drive over the internet or simple backup. Lsyncd, DRDB or Kopia backup", "Author": "u/1000Zebras", "Content": "Hi, \n  \n\n    I'm curious what you guys would implement in this situation in order to, above all, simply maintain at the very least one solid, off-site backup of all of my data files and also, in the event of something happening to my main data drive on-site, reduce downtime as much as possible. \n  \n\n    Here is my current setup as is relevant to the question at hand: \n  \n\n\n\n\n\n    OrangePi 5 Plus running dietpi (so pretty much just debian) as my main server on-site\n  \n\n\n\n\n\n    One eMMC boot drive on the OrangePi containing the OS and all of my docker-compose files, as well as the OS itself\n  \n\n\n\n\n\n    Recently acquired 14TB external USB drive that houses purely my data for all of my docker containers (and then some outside of those, as well, but not much)\n  \n\n\n\n\n\n    OrangePi is running Tailscale\n  \n\n\n\n\n\n    A second RPi that lives at my brother's house also running Tailscale (so any connection between the two will more than likely be running over the interwebs, but through Tailscale) and with a second 14tb drive identical to the other connected to it, ready for data storage \n  \n\n\n\n\n\n    What I'm wondering is what may be the best strategy for maintaining a backup of the main data drive on the secondary drive, ideally in a mirrored fashion such that were the main drive to fail, I'd simply be able to plug in the secondary drive to the OrangePi, mount it at the same mountpoint as primary would have been, and I'd be back up and running nearly immediately (once the drive was physically moved between locations, of course). \n  \n\n    It's worth noting that, at present, I am dealing with nearly 4.5TB of data on main data drive (also currently backed up to the cloud via Kopia and iDrive E2)\n  \n\n    I've been considering: \n  \n\n\n\n\n\n    Trying out lsyncd or DRDB in order to literally have the drives mirror each other in as near realtime as the connection will allow. I have not used either of these tools yet, however, so I'm not familiar with exactly how they work behind the scene. And also, I realize that it is a lot of data to keep in sync over an internet connection, especially at file or block-level granularity as I believe those tools are designed for. In \"normal\" usage, I am not necessarily adding or changing all that much data on a day to day basis, but were I to make any major shifts in organization, or simply to add a lot more data into the mix suddenly, I'm wondering if the tools would be able to keep up\n  \n\n\n\n\n\n    Running an rsync job over ssh at a specified interval (say, maybe, a couple of times a day) in order to keep the two up date. I would of course again run into the same problem that would arise with the first option were I to make any drastic changes, but theoretically I'd eventually always have a 1 to 1 sync/backup between the two drives\n  \n\n\n\n\n\n    Simply running some sort of backup program from the main Orangepi data drive to the RPi's data drive, again at whatever specified interval (say, maybe, daily). I'd probably have to run some sort of webDAV server on the secondary RPi in order to facilitate backups between the two were I to use Kopia. Or, I suppose I could even run the data drive on RPi on a minio instance and have Kopia backup via the S3 protocol, but this seems perhaps like a little bit of overkill, and it wouldn't necessarily be the sort of 1 to 1 sync I'm shooting for as Kopia would organize the backup data in a fashion that it understands. This would be acceptable, though, as again at the end of the day the most important thing is to have all of the data itself stored safely in both locations, one way or another. \n  \n\n\n\n\n\n    How would you guys go about keeping things in sync between the two data drives? Or, should I just eschew that idea given the limitations of the bandwidth/connection between the two and go for straight backups using Kopia, or some othe rbackup system? \n  \n\n    Please, if you have any thoughts on how you'd architect this scenario, I'd very much appreciate any and perspectives/insights. \n  \n\n    Hopefully that all makes sense. If you need anything clarified, by all means speak up and I'll do my best to address. \n  \n\n    Thank you so very much for your time, expertise, and patience with my rambling question. I look forward to hearing how people weigh in. \n  \n\n    Kind Regards,\n  \n\n    LS"},
{"Title": "3D printed 8-Bay DAS with Supermicro backplane, trays, PSUs and external SAS-8088 connectors", "Author": "u/kschaffner", "Content": "https://imgur.com/a/YcbODga\n\n\n\n\nhttps://makerworld.com/en/models/491457\n\n\n\n    I've been working hard on this project for the past couple months in my spare time trying to make a product that I couldn't really find on the market. I had some extra PSUs and fans and supermicro trays so I figured why not design around that. I've probably put no less than 40+ hours into design, print, redesign, print, try fitment etc. Not the most experience with Fusion360 or CAD in general. The front LEDs do light up during activity :). I've been thinking of expanding this into a mATX or Mini-ITX supported case as well.\n  \n\n    I know this is also pretty much on the heals of shaztech_info but I think we have enough differences between us and I was kinda shocked to see someone else coming out with a similar idea around the same time lol. Let me know what you fellas and fellettes think!\n  \n\n    From Makerworld:\n  \n\n    I was unable to find a product that met my specifications of 8 hot-swap bays, a SAS backplane and external SAS connectors for easy connectivity, so I decided to design and build my own 8-bay Direct Attached Storage (DAS). This DAS features a Supermicro SAS833TQ backplane with Gen 5.5 hot-swap 3.5\" trays. It is powered by either a 200W PWS-203-1H (as-shown) or a 350W PWS-351-1H (or similar units of the same dimensions: PWS-351-1H 100 x 40 x 220mm, PWS-203-1H 76 x 40.3 x 192mm) power supply. Additionally, it includes an external SAS SFF-8088 to SFF-8087 adapter to cut down on internal wires.\n  \n\n    I printed this on my X1C and have realized that making it available for smaller print beds should also be done instead of 1 large single print.\n  \n\n    The body is 255 W x 190 H x 245mm D, it is printed as a single print, no supports needed. The body at 10% infill, 2 walls with gyroid infill .20mm layer height with a 0.4mm nozzle. This print requires NO supports to print. The print of the body will use approximately 984.5g of filament if no painting is done of the logo or numbers, and 982.6g if painted of a single color. This print took roughly 20 hours to print. I realize this might also be a turn off being a large print but I wasn't wanting to have to glue or screw it together if I could help it. If you are wanting this, let me know and I can work it into a new version. There are 2 version of the back plate for the different sizes of PSUs mentioned.\n  \n\n    Here is the list of parts used for this build:\n  \n\n\n\n\n\n\n\n            Part\n          \n\n            Price\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              Supermicro Gen 5.5 3.5\" trays (MCP-220-00075-0B) x8\n            \n\n              ~$50 for 8 on eBay\n            \n\n\n\n\n\n              Supermicro SAS833TQ 8-bay SAS backplane\n            \n\n              ~$35 on eBay\n            \n\n\n\n\n\n              SFF-8087 to SATA breakout cable x2\n            \n\n              ~$16\n            \n\n\n\n\n\n              SFF-8088 to SFF-8087 adapter\n            \n\n              ~$30\n            \n\n\n\n\n\n              Supermicro 1U PSU of dimensions 100 x 40 x 220mm or 76 x 40.3 x 192mm (As seen PWS-203-1H)\n            \n\n              ~32$ on eBay, also designed screw hole for PWS-351-1H ~$30 on eBay\n            \n\n\n\n\n\n              Molex Y-cable\n            \n\n              ~$6\n            \n\n\n\n\n\n              120mm of your choice x2 (Noctua NF-P12 shown)\n            \n\n              ~$16 ea.\n            \n\n\n\n\n\n              ATX power jumper cable w/ switch\n            \n\n              ~$11\n            \n\n\n\n\n\n              This required a tool to remove the pins from the connector to feed it through the hole\n            \n\n              ~$17, you don't have to get one like this, but I wanted the other pin extractors for future projects.)\n            \n\n\n\n\n\n\n\n    Grand Total of parts: $210, could save $32 with some random 120mm fans as long as they can pull through all the trays.\n  \n\n    For hardware needed:\n  \n\n\n\n\n\n\n\n            Part\n          \n\n            qty\n          \n\n\n\n\n\n\n\n\n\n\n\n\n\n              M3x4x5 Heatset inserts\n            \n\n              7\n            \n\n\n\n\n\n              M4x6x6 Heatset inserts\n            \n\n              6\n            \n\n\n\n\n\n              M3x6 socket head screw\n            \n\n              3\n            \n\n\n\n\n\n              M3x12 socket head screw\n            \n\n              4\n            \n\n\n\n\n\n              M4x8 socket head screw\n            \n\n              6\n            \n\n\n\n\n\n\n\n    Some optional parts that might be desired:\n  \n\n    120mm wire fan grills ~$8\n  \n\n    Some rubber feet for the bottom"},
{"Title": "Is there a way to backup recorded classes on a private google drive file?", "Author": "u/simonbleu", "Content": "So, basically the classes im taking are recorded for review, and uploaded to google drive. I can see them but not download them, and  it would be very very laborious to record the screen so my question is if there is a way to download them anyway. I couldnt with the browser inspector\n  \n\n    I do understand that the policy of the institute is not to download the classes becuase of risk of misuse, but my intentions are merely about doing a backup of the classes for future reference. The classes *will* be deleted afterwards, and is not like I will have access to other otnes im not in.\n  \n\n    Not sure if this is the right place to ask but one can be hopeful I guess. Thanks in advance!"},
{"Title": "YouTube is A/B testing requiring login for video playback", "Author": "u/ThePixelHunter", "Content": "No content"},
{"Title": "Ways to summarize rsync logs? Too verbose so I never read them", "Author": "u/Ninj_Pizz_ha", "Content": "There's too much output from my rsync such that I end up not reading what was added/deleted. I think part of the issue is that \nit's logging stupid stuff like if a file timestamp got changed.\n\n\n\n    Really, I'd like a summary at the top that shows like \"x number of files from folder y were deleted/added.\" I'm using the \n-aih\n flags.\n  \n\n    Apologies for the somewhat vague question."},
{"Title": "Simple web scraping Chrome extension side project", "Author": "u/Fair_Perspective_761", "Content": "I made a free Chrome extension that scrapes all plain text from the active webpage and download's it as a plain text .txt file. It works great on articles, blogs, online forums (Reddit), wiki's, and more. It has a filter option that filters out smaller text elements and keeps large elements.\n  \n\n    I made this extension as a tool to 'pre-process' large websites before analyzing them with ChatGPT. Cmd + A, Cmd + C, and Cmd + V wasn't cutting it for me, and ChatGPT 4o can process almost 100x more words when fed a plain text .txt file.\n  \n\n    Any feedback would be great. I don't track data and everything runs native in the users browser.\n  \n\n    My extension: \nWeb.txt"},
{"Title": "My home backup method is bad. I need help re-thinking it.", "Author": "u/Zach83", "Content": "I don't know a lot about networking, storage, and proper backing up. I'm a 3d artist and do some coding on the side so I don't get scared by technical manuals or learning new tech, but proper sys adminning is not my strength.\nI just did some reading on things like windows backup and mirroring and now I think I need to update/change/modernize how I backup my stuff.\nApparently the things I am relying on are NOT reliable at all.\nSo I dove in and now I can't see the forest for the trees anymore. I need help thinking this out.\n  \n\n\nMy current setup\nI have a work/gaming pc with 2 2TB drives and a synology 1 disk(2TB) NAS device.\nThe windows PC contains important data, the NAS serves media to a media pc(that needs no backing up) and some tablets\n  \n\n    To back these up I have a windows based \"NAS\" with 2 mirrored volumes, F and G. 2 4TB volumes (so 4 disks, 4TB each, 2 used for each mirorred volume)\nOn the Work PC there are three folders that I manually backup to G while working. Daily backups sort off.\nEvery week I run a Bat file with a few robocopy commands on the windows \"NAS\". The BAT maps the work PC's drives and the synology NAS drive and then does a copy with options like /mir and /purge. Essentially an incremental backup of the NAS and work PC drives to the windows \"NAS\".\n  \n\n    A few times a year a I run a second bat script. It copies everything to external devices that I store in my shed. Best offsite backup available to me.\n  \n\n\nmy questions\nHow to mirror?\nApparently windows mirrored volumes can not be relied on? I use it to protect against disk failure and apparently there are situations where the still working disk will NOT be read by another windows pc. Kinda defeats the point.\nI want such protection on the windows \"NAS\", an automatic and fast mirror copy.\nI want to be able to put any disk of the mirror pair in any other windows pc and have it appear like a normal disk, so it should be NTFS.\nWhat should I do? There are so many options and I have no idea what is reliable.\n  \n\n\nHow to backup without Robocopy (in a file system that windows can read like ntfs, and without puting files into a proprietary binary blob)?\nI'm told I shouldn't use Robocopy for incremental backups because it's too easy to fuck up, and should power cut out while copying I could be fucked.\nGoogling I went, searching for a way with the following requirements:\n  \n\n\n\n\n\n    I want to backup the synology nas and the 2 disks on the work pc weekly, to the windows \"NAS\".\n  \n\n\n\n\n\n    I only want to copy changed or new files and I want to remove files that no longer exist in the original source.\n  \n\n\n\n\n\n    The backup should not go into a binary blob, I want loose files.\n  \n\n\n\n\n\n    No need for file versions/history.\n  \n\n\n\n\n\n    Timestamps(date modifed/created) are important to me.\n  \n\n\n\n\n\n    And I found nothing. I probably don't even know the right terms to search for.\nHow should I do this backup?\n  \n\n    Ideally this should not involve signing up for a service or managed via a web interface hosted by some company. I want to keep everything in home and away from the internet.\nFree would be nice too."},
{"Title": "Is the video conversion offered by VIDBOX (was Honestech) a reliable product also, how would I go about digitizing old VHS/VCR videos?", "Author": "u/Duck_Dur", "Content": "Hello All,\n  \n\n    Is the video conservation service offered by VIDBOX (previously Honestech) a reliable product and how would you go about digitizing old VHS/VCR videos and if you were to recommend another brand, what would it be?\n  \n\n    EDIT: Fixed grammer"},
{"Title": "Any optical media ratings / testers out there checking media surfacing recently? Ridata Valor bd-r 10x brand?", "Author": "u/Gbxx69", "Content": "I lost track of the definitive site(s) for reviewing optical media or at least blu-ray discs / brands / sub brands.. can anyone send a link to who's doing the due diligence on media these days?\n  \n\n    I've seen Ridata Valor 10x bd-r discs which seem to be sold cheaper than PlexDisc or even the 6x RiData bd-r's... so what gives.. why is it somewhat cheaper?!? Were these sitting in a warehouse somewhere since before 2020 or something??!?\n  \n\n    I am looking to use the media as backup of videos, software and occasionally important data (of which I would make multiple backups over time)."},
{"Title": "Chown Errors Running Rsnyc Going from Unraid to Unassigned Device", "Author": "u/klnadler", "Content": "Hi everyone, I'm syncing some files from my unraid to an external drive and I'm having issues with permissions, I did run newperms on the unraid side but I think this is a destination problem. The files seem to be transferring but not with the correct permissions\n  \nCommand: rsync -avPh\n05/2019-05-01/DSC00001(1)-2.ARW\n         32.77K   0%  248.06kB/s    0:01:40  rsync: [receiver] chown \"destination/2019/05/2019-05-01/.DSC00001(1)-1.ARW.sDzkxQ\" failed: Operation not permitted (1)\n         24.85M 100%   92.20MB/s    0:00:00 (xfr#2, ir-chk=1498/1516)\n05/2019-05-01/DSC00001(1)-positive-1.tif\n         32.77K   0%  118.96kB/s    0:07:37  rsync: [receiver] chown \"destination/05/2019-05-01/.DSC00001(1)-2.ARW.Q8mP3g\" failed: Operation not permitted (1)\n         54.49M 100%   99.36MB/s    0:00:00 (xfr#3, ir-chk=1497/1516)"},
{"Title": "M2 Pro/M3 Pro w/ 990 Pro NVMe + 40 Gb/s external", "Author": "u/Direct-Button1358", "Content": "Hi all,\n  \n\n    Systems: Mac Mini M2 Pro, MBP M3 Pro\n  \n\n    Thank you for your time. I am trying to put together an external drive using the Samsung 990 PRO NVMe with an external enclosure rated at 40 Gb/s like the ugreen or acasis.\n  \n\n    I do have a few questions:\n  \n\n\n\n\n\n    What external enclosure would work best for use with my M2 Pro and M3 Pro, I mostly do research and will be using it as an extended mobile storage solution .\n  \n\n\n\n\n\n    Is this overkill for my usage? Keep in mind, the difference in price between this SSD and others that write at half the speed is maybe $50 .  I am using my University start up funds for the purchase.\n  \n\n\n\n\n\n    Additionally: I am interested in eventually setting up NAS using this SSD paired with something like a Yottamaster enclosure.\n  \n\n    Thanks!"},
{"Title": "VirtualDub won't record audio from capture card but sound works fine outside of recording", "Author": "u/Throwaway173638o", "Content": "I'm trying to capture video and audio from my JVC HR-S7100U through a GV-USB2 capture card device.  I am using S-Video as source with composite as my audio sources.  I set the audio source to the device.\n  \n\n    When I try to capture video, the audio doesn't get recorded.  But when I'm not recording under Overview mode, the volume is playing fine.  Preview mode doesn't work for audio too.\n  \n\n    I also don't have any issues recording video and audio from OBS.  However I want to stick with Virtualdub for the best quality.\n  \n\n    I don't know what I can really do to fix this?"},
{"Title": "Download from Google Sites Embedded Image Pages", "Author": "u/kylemj89", "Content": "I am trying to download batch urls and renaming each image in sequence order.\n  \n\n    The images are saves with unique urls from google sites and fails to download after multiple saves using python BeautifulSoup and request\n  \n\n    Wget runs into the same\n  \n\n    HTTrack fails to download the webpages as dispayed (haven't yet got as far as renaming sequence\n  \n\n    Bulk Image downloader doesn't have the ability to rename or save in folders from \nhttps://tigerlovefish.com/\n\n\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/472-1st-january-14th-january-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/474-29th-january-11th-february-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1996/467-23rdoctober-5th-november-1996\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/478-26th-march-8th-april-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/480-23rd-april-6th-may-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/482-21st-may-3rd-june-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/484-18th-june-1st-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/486-17th-july-29th-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/490-10th-september-23rd-september-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/492-8th-october-21st-october-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/494-5th-november-18th-november-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/496-3rd-december-17th-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/tour-programme-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/477-12th-march-25th-march-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/479-9th-april-22nd-april-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/481-7th-may-20th-may-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/483-4th-june-17th-june-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/485-2nd-july-16th-july-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/487-30th-july-12th-august-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/489-27th-august-9th-september-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/491-24th-september-7th-october-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/493-22nd-october-4th-november-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/495-19th-november-2nd-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1997/497-17th-december-31st-december-1997\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/498-1st-january-13th-january-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/500-28th-january-10th-february-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/502-25th-february-10th-march-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/504-25th-march-7th-april-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/506-22nd-april-5th-may-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/508-20th-may-2nd-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/510-17th-june-30th-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/512-15th-july-28th-july-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/514-12th-august-25th-august-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/516-9th-september-22nd-september-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/518-7th-october-20th-october-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/520-4th-november-17th-november-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/522-2nd-december-15th-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/524-30th-december-1998-12th-january-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/499-14th-january-27th-january-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/501-11th-february-24th-february-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/503-11th-march-24th-march-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/505-8th-april-21st-april-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/507-6th-may-19th-may-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/509-3rd-june-16th-june-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/511-1st-july-14th-july-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/513-29th-july-11th-august-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/515-26th-august-8th-september-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/517-23rd-september-6th-october-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/519-21st-october-3rd-november-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/521-18th-november-1st-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/523-16th-december-29th-december-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1998/tour-programme-1998\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/525-13th-january-26th-january-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/527-10th-february-23rd-february-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/529-10th-march-23rd-march-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/531-7th-april-20th-april-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/533-5th-may-18th-may-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/535-2nd-june-15th-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/537-30th-june-13th-july-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/539-28th-july-10th-august-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/541-25th-august-7th-september-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/543-22nd-september-5th-october-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/545-20th-october-2nd-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/547-17th-november-30th-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/549-15th-december-28th-december-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/poll-winners-party-and-tour-programme-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/526-27th-january-9th-february-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/528-24th-february-9th-march-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/530-24th-march-6th-april-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/532-21st-april-4th-may-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/534-19th-may-1st-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/536-16th-june-29th-june-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/538-14th-july-27th-july-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/540-11th-august-24th-august-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/542-8th-september-21st-september-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/544-6th-october-19th-october-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/546-3rd-november-16th-november-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/548-1st-december-14th-december-1999\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/550-29thdecember-1989-11th-january-2000\nhttps://sites.google.com/view/smashhitsremembered1995-1999/home/1999/poll-winners-party-and-tour-programme-1999\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/551-12thjanuary-25thjanuary-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/553-9th-february-22nd-february-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/555-8th-march-21st-march-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/557-5th-april-18th-april-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/559-3rd-may-16th-may-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/561-31stmay-13thjune-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/563-28thjune-11thjuly-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/565-26th-july-8th-august-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/567-23rd-august-5th-september-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/569-20th-september-3rd-october-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/571-18thoctober-31stoctober2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/573-15thnovember-28thnovember-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/575-13thdecember-9th-january-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/tour-programme-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/552-26th-january-8th-february-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/554-23rd-february-8th-march-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/556-22nd-march-4th-april-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/558-19th-april-2nd-may-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/560-17thmay-30thmay2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/562-14thjune-27thjune-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/564-12thjuly-25thjuly-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/566-9th-august-22nd-august-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/568-6th-september-19th-september-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/570-4th-october-17thoctober-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/572-1st-november-14th-november-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/574-29th-november-12th-december-2000\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2000/576-free-with-issue-575\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/577-10thjanuary-23rdjanuary-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/579-7th-february-20th-february-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/581-7th-march-20th-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/583-4th-april-17th-april-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/585-2nd-may-15th-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/587-30th-may-12th-june-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/589-27thjune-10thjuly-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/591-25th-july-7th-august-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/593-22nd-august-4th-september-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/595-19th-september-2nd-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/597-17th-october-30th-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/599-14th-november-27th-november-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/601-19th-december-2001-8th-january-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/smash-hits-brits-special-1st-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/578-24thjanuary-6thfebruary-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/580-21st-february-6th-march-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/582-21st-march-3rd-april-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/584-18th-april-1st-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/586-16th-may-29th-may-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/588-13thjune-26thjune-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/590-11thjuly-24thjuly-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/592-8th-august-21st-august-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/594-5th-september-18th-september-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/596-3rd-october-16th-october-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/598-31st-october-13th-november-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/600-28th-november-18th-december-2001\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2001/602-19th-december-2001-8th-january-2002-free-with-issue-601\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/603-9th-january-22nd-january-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/605-6th-february-19th-february-2002\nhttps://sites.google.com/view/smash-hits-remembered-01/home/2002/607-6th-march-19th-march-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/609-3rd-april-16th-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/611-1st-may-14th-may-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/613-29th-may-11th-june-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/615-26th-june-9th-july-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/617-24th-july-6th-august-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/619-23rd-august-3rd-september-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/621-18th-september-1st-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/623-16th-october-29th-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/625-13th-november-26th-november-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/627-18th-december-2002-7th-january-2003\nhttps://sites.google.com/view/smash-hits-remembered-01/home/2002/604-23rd-january-5th-february-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/606-20th-february-5th-march-2002\nhttps://sites.google.com/view/smashhitsremembered01/home/2002/608-20th-march-2nd-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/610-17th-april-30th-april-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/612-15th-may-28th-may-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/614-12th-june-25th-june-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/616-10th-july-23rd-july-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/618-7th-august-20th-august-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/620-4th-september-17th-september-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/622-2nd-october-15th-october-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/624-30th-october-12th-november-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/626-27th-november-17th-december-2002\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2002/sneak-preview-magazine\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/636-30th-april-13th-may-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/638-28th-may-10th-june-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/642-23rd-july-5th-august-2003\nhttps://sites.google.com/view/smashhitsremembered01/home/2003/summer-quiz-book\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2003/635-16th-april-29th-april-2003\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2004/659-5th-march-18th-march-2004\nhttps://sites.google.com/view/smashhitsremebered2000s/home/2004/659-5th-march-18th-march-2004"},
{"Title": "Media storage guide for a highschooler", "Author": "u/MintedMince", "Content": "Hi! So I am a highschooler from a third world country and recently I have been struggling to keep all of my data intact. I have been juggling around 1 or 2 spare hard-drives and google accounts to somehow store family photos and other important media with as many backups as I can make. The thing is, I can't really afford a lot to invest into some more high-end, and I really do not want to loose my (had a few close calls, though my backups saved me). So any advice on improving the situation or do most people hang around doing the same thing? Would love to hear from yall :)"},
{"Title": "Advice/guidance needed for a first time NAS builder", "Author": "u/de4thr4sher", "Content": "Hello everyone! I've been lurking around here for quite some time and all I'll say is that I've been inspired by your posts so much that I've decided to dive into the realm of building my first NAS and be a data hoarder myself. But I'll need your help with that as I've been very confused with a lot of things and obviously, I don't want to screw everything up.\n  \n\n    So, first things first. My intention with the setup is purely just hoarding data on a separate machine other than my main PC while i keep everything safe and secure as much as possible. I don't need it to be accessible from anywhere or anything like that, just locally from my main PC. Like an enormous external HDD to put it simply. I don't need crazy speeds either as I won't be using it for work or anything similar. It's main use will be storing and playing my audio/video files from there and ofc, store a lot of other files and having backups of my main system and other devices.\n  \n\n    I'll be starting with the hardware I already own and the ones I plan on buying (suggestions are welcome ofc)\n  \n\n    *Already owned hardware*\n  \n\n    Option 1 for mobo/CPU/RAM would be my old setup:\n  \n\n    A Z390-E paired with a 9700k (8C/8T) and 32GB (DDR4-3000) of RAM\n  \n\n    Option 2 would be a setup I got recently for free:\n  \n\n    An Asus ROG Maximus VII paired with a 4790k (4C/8T) and 16GB (DDR3-1600).\n  \n\n    A 700W Coolermaster PSU that I also got with the free setup, an old spare Kingston SSDNow V300 240GB and if I manage to finally build this NAS, I'll be getting rid of a 4TB WD drive and an 8TB Ironwolf drive.\n  \n\n    Will I have to use the 9700k setup in this case or even the 4790k will be enough?\n  \n\n    *Hardware I plan on buying*\n  \n\n    The goal for now is to get 4 drives so I can have 2 of them for redundancy and add another 4 next year and hopefully I won't have a storage issue for a long time.\n  \n\n    I've locked my eyes on Exos X16 14TB and on X18 16TB drives and a Define 7 XL R2 case for this whole setup as all these are in a fairly good price right now where I'm from. Seagate lists these drives as CMR so I guess shouldn't be concerned...? Later on I know I'll also have to get a Pci-e to 4x sata or something like that.\n  \n\n    That's about it as far as hardware goes. Let's dive into software now, shall we?\n  \n\n    The most confusing part for me and where I need your advice the most. What should I go for?\n  \n\n    I see a lot of people recommending unRAID for basic setups like this. I got very confused when I was trying to decide between that or TrueNAS and eventually I gave it up and decided to ask the experts here. What would you do? Is it worth spending extra for an unRAID licence?\n  \n\n    I know this post is stupid for 99.8% of you but it's obviously not my field of expertise and I'm trying to not spend anywhere else right now, except mainly for HDDs and a case.\n  \n\n    Suggestions AND roasts are welcome! :) Thanks in advance!"},
{"Title": "Rosewill hot swap bay source/alternative?", "Author": "u/thecaramelbandit", "Content": "I've got a rosewill 4U case with one of their 4x3.5 hot swap enclosures. I want to add a second but they seem to be out of stock everywhere.\n  \n\n    Anyone have a source for one, or know of an alternative that will also fit?"},
{"Title": "4x5.25\" to 7x3.5\" adapter?", "Author": "u/Adam1394", "Content": "Hello, I look for aforementioned adapter for my Define XL R2 case."},
{"Title": "\"Vimm's Lair\" receives notice to remove tons of games.", "Author": "u/blackletum", "Content": "No content"},
{"Title": "\"Best\" 3.5\" 8Tb HDD Brand?", "Author": "u/Large_Medium_8984", "Content": "This question pops up all the time on here but I only see specific use cases when others ask and nothing really close to what my situation is. I'm looking to bring together all of mine and my families ancient Hard drives, laptop backups, flash drives, externals, family photo scans and videos all onto a few backup HDDs. Just over a Million files @ under 6TB that I'd like to put into an 8Tb HDD (or 2). Photos, Videos, Text Docs, and whatever else might be in there. These drives will not be used for gaming at all, so no need to worry about being rough on the drive with pulling all the time, as I see a lot of people looking for gaming AND storage when asking this. Just something to have peace of mind that nothing could go wrong in a reasonable amount of time with them. I've read good and bad things about both Seagate Barracuda and Western Digital Blue. Are there other 3.5\"s I should also look in to? I'm not expecting these drives to live dormant 5-10 years, but it would be nice. I'd like to read any and all personal experiences users have had over the years."},
{"Title": "Raid controller advices", "Author": "u/Surax98", "Content": "Hello guys, I am looking for a raid controller to be used over USB 3.2 10Gbps (I know, it's far from being advisable but that's the only thing I can do right now, since my server is a laptop) and I have to choose between the following:\n  \n\n\n\n\n\n    IBM M5015 (PCIe 2.0 x8, SAS 6Gbps, 512MB cache DDR2 800MHz) for 20€ and located in my city\n  \n\n\n\n\n\n    LSI 9271 (PCIe 3.0 x8, SAS 6Gbps, 1GB cache DDR3 idk-how-many MHz) for 33€ shipped from China.\n  \n\n\n\n\n\n    Now, since I am over USB 10Gbps, I am limited in both scenarios, but I'd like to know if that faster and more cache of the 9271 will actually make a difference for a domestic usage. To help you better understand my use cases, I will list them:\n  \n\n\n\n\n\n    Plex and Jellyfin media server\n  \n\n\n\n\n\n    IMMICH for photo synching\n  \n\n\n\n\n\n    Nextcloud for everything else\n  \n\n\n\n\n\n    These are the main I/O bound containers I am running on my server. What do you think? Any other suggestions for a raid controller, instead (which costs less than 40€)?"},
{"Title": "Question related to the voiceover feature (headphone symbol) in internet archive", "Author": "u/69PepperoniPickles69", "Content": "Do you know if there's a way to upload my own files so that listen to them instead of reading? Or does it have to include actually uploading books and them getting approved, scripted and so on? And if so do you guys know any alternative website where we can upload large texts for listening with decent quality?"},
{"Title": "How best to migrate to new hardware?", "Author": "u/SlayterDevAgain", "Content": "I'm about to build a new NAS. With my current NAS I just kind of threw drives at it as I aquired them (2x 2TB in RAID 1, a 4TB and a 6TB drive in pools by themselves, and 5 6TB drives in an external enclosure in RAID 5).\n  \n\n    In the new build I have 3 10TB drives I'll be adding. I don't necessarily need to keep all the drives from the old build (I at least want the 5x 6TB drives but not externally) but what would be the best way to migrate the data to the new build? Any advice is appreciated.\n  \n\n    Further info: Current build is FreeNAS and I'll probably keep with that or TrueNAS."},
{"Title": "Historical data hoarders at the library of Alexandria lost untolds amount of work and knowledge after the library was burned. Sumerian texts survived 4000+ years due to being written on clay tablets. Is there any efforts to transcribe some of our knowledge into more permanent media?", "Author": "u/rrybwyb", "Content": "I mostly hoard books. Its amazing how many I can fit onto just a small 10 tb hard drive. But if that gets wet, dropped, or someone holds a magnet to it, I've lost millions of hours of research and knowledge from 10's of thousands of authors.\n  \n\n    Even looking at the history of the dead sea scrolls, Whatever idiots were in charge of transporting those did an awful job. They were taken from the dry desert to a place where they could get humid and rot.\n  \n\n    Are there any organizations out there that have transcribed some of our more important items into stone or clay? I've been looking more into Sumerian history and the reason we have many of these items still is because they were carved into clay - and clay can last a pretty long time.\n  \n\n    Its kind of short sighted of humans to think we're immune to a giant asteroid or nuclear winter. In that situation, What would humans 5,000 years in the future after a major catastrophe be able to look back on and decipher about the 2000s?\n  \n\n    Edit: also I can't believe I forgot about plastic. That supposedly forever product that never breaks down. Does anyone know if it is really as permanent as something like ceramic? I've seen it become quite brittle and disintegrate when left out in the sun for even 6-12 months"},
{"Title": "When to consider pre-emptive replacement of drives?", "Author": "u/MagicPracticalFlame", "Content": "I've got a small NAS with 4 x 6tb Drives in. The drives have just ticked over the 40,000 (grim dark) power-on time. Given that all the drives where purchased and installed at the same time, I'm worried about one crapping out and causing a domino effect when I get the replacement in to rebuild the array.\n  \n\n    The drives are Seagate ST6000VN0033 drives, health status shows as good on all counts. Just wondering when you guys start to consider replacement or migration to a new NAS (which is what I'd probably do)."},
{"Title": "Any good Kemono/coomer bulk downloaders?", "Author": "u/TravDeMan", "Content": "I've been looking for a while and im struggling to find any"},
{"Title": "Live sync of data drive over the internet or simple backup. Lsyncd, DRDB or Kopia backup", "Author": "u/1000Zebras", "Content": "Hi, \n  \n\n    I'm curious what you guys would implement in this situation in order to, above all, simply maintain at the very least one solid, off-site backup of all of my data files and also, in the event of something happening to my main data drive on-site, reduce downtime as much as possible. \n  \n\n    Here is my current setup as is relevant to the question at hand: \n  \n\n\n\n\n\n    OrangePi 5 Plus running dietpi (so pretty much just debian) as my main server on-site\n  \n\n\n\n\n\n    One eMMC boot drive on the OrangePi containing the OS and all of my docker-compose files, as well as the OS itself\n  \n\n\n\n\n\n    Recently acquired 14TB external USB drive that houses purely my data for all of my docker containers (and then some outside of those, as well, but not much)\n  \n\n\n\n\n\n    OrangePi is running Tailscale\n  \n\n\n\n\n\n    A second RPi that lives at my brother's house also running Tailscale (so any connection between the two will more than likely be running over the interwebs, but through Tailscale) and with a second 14tb drive identical to the other connected to it, ready for data storage \n  \n\n\n\n\n\n    What I'm wondering is what may be the best strategy for maintaining a backup of the main data drive on the secondary drive, ideally in a mirrored fashion such that were the main drive to fail, I'd simply be able to plug in the secondary drive to the OrangePi, mount it at the same mountpoint as primary would have been, and I'd be back up and running nearly immediately (once the drive was physically moved between locations, of course). \n  \n\n    It's worth noting that, at present, I am dealing with nearly 4.5TB of data on main data drive (also currently backed up to the cloud via Kopia and iDrive E2)\n  \n\n    I've been considering: \n  \n\n\n\n\n\n    Trying out lsyncd or DRDB in order to literally have the drives mirror each other in as near realtime as the connection will allow. I have not used either of these tools yet, however, so I'm not familiar with exactly how they work behind the scene. And also, I realize that it is a lot of data to keep in sync over an internet connection, especially at file or block-level granularity as I believe those tools are designed for. In \"normal\" usage, I am not necessarily adding or changing all that much data on a day to day basis, but were I to make any major shifts in organization, or simply to add a lot more data into the mix suddenly, I'm wondering if the tools would be able to keep up\n  \n\n\n\n\n\n    Running an rsync job over ssh at a specified interval (say, maybe, a couple of times a day) in order to keep the two up date. I would of course again run into the same problem that would arise with the first option were I to make any drastic changes, but theoretically I'd eventually always have a 1 to 1 sync/backup between the two drives\n  \n\n\n\n\n\n    Simply running some sort of backup program from the main Orangepi data drive to the RPi's data drive, again at whatever specified interval (say, maybe, daily). I'd probably have to run some sort of webDAV server on the secondary RPi in order to facilitate backups between the two were I to use Kopia. Or, I suppose I could even run the data drive on RPi on a minio instance and have Kopia backup via the S3 protocol, but this seems perhaps like a little bit of overkill, and it wouldn't necessarily be the sort of 1 to 1 sync I'm shooting for as Kopia would organize the backup data in a fashion that it understands. This would be acceptable, though, as again at the end of the day the most important thing is to have all of the data itself stored safely in both locations, one way or another. \n  \n\n\n\n\n\n    How would you guys go about keeping things in sync between the two data drives? Or, should I just eschew that idea given the limitations of the bandwidth/connection between the two and go for straight backups using Kopia, or some othe rbackup system? \n  \n\n    Please, if you have any thoughts on how you'd architect this scenario, I'd very much appreciate any and perspectives/insights. \n  \n\n    Hopefully that all makes sense. If you need anything clarified, by all means speak up and I'll do my best to address. \n  \n\n    Thank you so very much for your time, expertise, and patience with my rambling question. I look forward to hearing how people weigh in. \n  \n\n    Kind Regards,\n  \n\n    LS"},
{"Title": "NAS vs just in PC", "Author": "u/EnigmatheEgg", "Content": "Hi all!\n  \n\n    I have started to trust the internet less and less and have decided to save as much as I can in my own drives at home. I managed to find a Fractal design R5 with all drive sleds still there and thought it would make a great NAS Chassi. But now I'm wondering, do I need a NAS or can I just move my PC components there and just have a PC with 30+TB of space? All of the other people on the network don't have much data to store and would rather I help them anyway to save things. What other reasons would there be to have my data storage in a seperate chassi?"},
{"Title": "How to save entire Google site (which I don't own) for offline viewing?", "Author": "u/redrockerou812", "Content": "I tried HTTrack and Cyotek Webcopy and they don't copy the menu bar, and it just launches a broken site.\n  \n\n    Specifically looking to copy this site \nSouthCarleton (google.com)\n with all links and files.\n  \n\n    If anyone can help me out with this I'd appreciate it."},
{"Title": "Backing up Google calendar", "Author": "u/c05d", "Content": "Hi,\n  \n\n    I’ve been using Google calendar for close to 20 years now. It’s started to bother me that my entire life is in Google’s hands and Id like to back this up & transfer to another service like Outlook\n  \n\n    what’s the best way to do this? I want everything including tasks etc to transfer\n  \n\n    thanks"},
{"Title": "How much free space should I leave on my 1TB HDD with a btrfs file system ?", "Author": "u/Yukinoooo", "Content": "Is it dangerous to leave 80GB on my 1TB HDD (only files without OS) ? I'm using GNU/Linux + KDE"},
{"Title": "[YoYotta] How can I change destination folder in LTO Tape", "Author": "u/ddd102", "Content": "https://preview.redd.it/yoyotta-how-can-i-change-destination-folder-in-lto-tape-v0-6t4uhiti1w5d1.png\n\n    Hi, there.\n  \n\n    I'm very newbie on YoYotta.\nToday, I do my first copy job. 3.5 inch HDD to LTO 8 Tape by YoYotta.\nBut, I wonder how can I change destination folder trees. This software create just same folder trees from the source folders. I don't want that way. I want to create different folder trees on LTO Tapes which I'll do back up my data.\n  \n\n    Anyone knows how can do that?\nAnd is there any LTO or YoYotta user community? even though subreddit.\nI need more information. Official website of YoYotta, already I checked, but I need to story from real users.\n  \n\n    Thanks!"},
{"Title": "How to organize 10+ years of computer and phone backups? ~3TB", "Author": "u/PrivateAd990", "Content": "I'm looking for strategies, tools / software and tips to make my long journey of organizing these backups easier. Main questions at the bottom for a TLDR.\n  \n\n    About the content:\n  \n\n\n\n\n\n    ~3tb total, 15 laptop backups, 12 phone backups\n  \n\n\n\n\n\n    there will be overlap / duplicates in content between backups\n  \n\n\n\n\n\n    backups contain folders I manually dragged onto the portable drive. I never plan to do a full restore of a backup.\n  \n\n\n\n\n\n    backups may contain photos, videos, downloads, photo editing files, code and projects I wrote, a lot of junk I'd like to scrap\n  \n\n\n\n\n\n    Hardware:\n  \n\n\n\n\n\n    A recent MacBook Pro\n  \n\n\n\n\n\n    empty Samsung T9 4TB SSD, ~2000MB/s\n  \n\n\n\n\n\n    WD 2.5\" passport HDD 5TB, ~110MB/s\n  \n\n\n\n\n\n    A second HDD with a copy of the above for redundancy\n  \n\n\n\n\n\n    Plan:\n  \n\n\n\n\n\n    first bring everything on the HDD to the SSD since the SSD is way faster\n  \n\n\n\n\n\n    sort through everything. I need help with this part\n  \n\n\n\n\n\n    move the organized backup back to the HDD since SSD's aren't suitable for cold storage\n  \n\n\n\n\n\n    implement a plan for the 3 2 1 backup method\n  \n\n\n\n\n\n    Questions:\n  \n\n\n\n\n\n    software or tools to sort, organize, de-dupe, delete through everything on the drive. Free or paid\n  \n\n\n\n\n\n    tips for how to search through everything instead of going folder by folder? I'm guessing software can help here.\n  \n\n\n\n\n\n    output folder structure suggestions? Should I just flatten all backups to one? Let's say, all photos I took with my phone from all the backups to one folder? Or is that a bad idea"},
{"Title": "How often does the pCloud discount $890 10TB lifetime come around? I need to move my GSuite data soon to a new place.", "Author": "u/n4n4n4n4n", "Content": "(I will be using cryptomator to mask the data)"},
{"Title": "Would it be possible to recover previously-deleted photos from a 1998 digital camera?", "Author": "u/Throwaway173638o", "Content": "I was curious in recovering any previously-deleted and current photos off a vintage camera.  The catch is that it doesn't have an SD card and that taking any additional photos after its filled starts to delete them.\n  \n\n    It does use a 3.5 mm cord with some kind of port for vintage computers. I have no problem getting a 3.5 mm to USB cord.\n  \n\n    Is there a similar process with data recovery for SD cards and hard drives that I can do with recovering data from the camera?  Would I also need some drivers for this camera to detect too?\n  \n\n    For context, the digital camera is a Mattel Barbie Digital Camera from 1998."},
{"Title": "WD MyPassport Ultra vs WD Black [6TB]", "Author": "u/Previous_Day4842", "Content": "Is one of these drives better than the other? It seems on here some people mention the WD black being total rubish. I really like these drives for the aesthetic, but have never owned one. I have owned the MyPassport models for years and years and have never had an issue. Are they equal and i'm safe to get the WD Black for aesthetics? Or would it be wiser to get the MyPassport Ultra, with the metal build and USB-C Connection?\n  \n\n    I would be using this drive for time machine backups. Aesthetics are rather important to me, so it is a bummer that the MyPassport ultra does not come in black."},
{"Title": "Python script to help identify hot swapped drives", "Author": "u/radialmonster", "Content": "No content"},
{"Title": "Starting my self owned drive journey", "Author": "u/tessereis", "Content": "I'm moving from various cloud drives to local backups. I really would like some suggestion from this sub.\n  \n\n    I've 2 backups.\n  \n\n\n\n\n\n    SSD 1TB - formatted to exFat. I've heard bad things about this fs but I really need this drive to be cross compatible and plug and play. This seemed to be the only sane choice.\n  \n\n\n\n\n\n    HDD 2TB - formatted to ext4/zfs. Haven't decided on this yet, will probably go with zfs because it auto recovers and doesn't need to run something like fsck. Increased size for versioning.\n  \n\n\n\n\n\n    I'm planning to keep my SSD portable (on a trip etc) and whenever I'm at home, connect it to a system (rasp pi or a regular PC) with photoprism or librephotos installed. HDD is going to be the cold storage.\n  \n\n    I tried to follow the 3-2-1 rule but can't afford to get another drive just yet. Although, I'm thinking to get S3 Glacier for that offsite storage."},
{"Title": "SFTP/FTP/Local File Move", "Author": "u/Dking2204", "Content": "Coming from MacOS using Transit to Windows, I would like to move a large number of personal files from the Mac drives to the new Windows machine. What software is recommended? I keep seeing that Filezilla needs to be more secure, and I'm unsure about others. I appreciate any help you can provide."},
{"Title": "Anyone have luck with any of the high-speed 4x6 photo scanners with feed trays? I’ve tried 3 now and none seem good so far.", "Author": "u/Hour-Process6382", "Content": "I have 8000 photos to digitize. I've tried and returned 3 Epson FastFoto 680Ws because they all scratched the print photos, but scan at 600dpi was acceptable color and quality. But scratching the originals is non-starter. Plustek ePhoto 2300 is too slow with its single-feed, quality was ok. Now I'm on a Canon RS40 because my local photolab uses them for bulk scanning but the output is terrible with crushed blacks and super saturated reds - they even gave me info on their setup.\n  \n\n    I see a new product: Visioneer High-Speed Color Photo and Document Scanner PH70. I guess I'll try that one. Anyone have any experience with it? It's too new to find reviews.\n  \n\n    There's also the ScanSnap iX1600, but haven't researched it yet.\n  \n\n    Anyone successfully setup the Canon RS40 with quality output or have any other recommendations for a hi-speed photo scanner? About to give up!\n  \n\n    (I know flatbed is best, but not feasible for so many photos)."},
{"Title": "Offline served and auto-updating Wikipedia instance", "Author": "u/BarthoAz", "Content": "Hello!\n  \n\n    I was wondering if there was some tool out there that could:\n  \n\n\n\n\n\n    download the entire Wikipedia database (w/ images and in maybe 2~3 languages)\n  \n\n\n\n\n\n    keep it synced/updated\n  \n\n\n\n\n\n    being able to serve it statically through a self-hosted website\n  \n\n\n\n\n\n    bonus: keeping all of the data in files easily readable by humans, even without any tool\n  \n\n\n\n\n\n    Quite a wishlist, but I want to know if something like this (or similar) already exists before trying to do it myself!"},
{"Title": "Multipath aggregation aware file copy software?", "Author": "u/pally_nid", "Content": "I barely know how to ask this question...\n  \n\n    Would anyone know of a file copying software that can handle a source/destination like a NAS with multiple 1gb network interfaces.\nMaybe its best if I describe the effect I am looking for.\n  \n\n    Start a copy job, reach the avg-peak of 100MB/s and then the software becomes aware of this and then continues to enumerate folders as subtasks and starts these folders on the other IP addresses available from the NAS.\n  \n\n    So, if the NAS had 2 gb/s NICs, both would be saturated at 100MB/s, rather than only one granting higher thorough-put.\n  \n\n    Thank you for reading."},
{"Title": "What is the best free(non trial) software for converting a dvd to mp4 (ideally with subtitles)?", "Author": "u/Immediate-Risk-7569", "Content": "Every software I found is a trial with either a time limit or an ugly watermark."},
{"Title": "Photo deduplication on Mac", "Author": "u/ChumboChili", "Content": "Hello all -\n  \n\n    I have a significant volume of photo dupes to work through, but I am a bit particular as to how I want to proceed through them, and so I wanted to ask about those with experience with deduplication apps.\n  \n\n    I want to create a master set of photos, organized by year and device.  Accordingly, in a serial fashion, I want to use a folder as a reference source, compare its contents to a second folder, and in the second folder I would like to be able to:\n  \n\n    --easily see the non-duplicate photos;\n  \n\n    --also be able to see the duplicate photos, and delete them.\n  \n\n    I would also like to be able to identify and delete duplicates WITHIN a folder and its subfolders, although I understand that functionality is pretty standard.\n  \n\n    One final question, is whether this can also be performed for video files.\n  \n\n    Any recommendations to achieve this workflow would be most appreciated.  Thanks all."},
{"Title": "using gallery-dl for downloading sub. only content in deviantart", "Author": "u/South-Order2046", "Content": "I want to download a gallery of a creator that I have been subscribed to. I first tried download them with using \"WFDownloaderApp\" but it only downloaded the public images and gave me an error while trying to download the private images (subscribers only). Then, I tried my chances with gallery-dl. First, I had tried without adding any .conf file, but it gave me \"API responded with 429 Too Many Requests.\" error.  It doesn't work with any amounts of delay. Next, I added the .conf file, put my own client_id and client_secret values into that file. But it still give me the same error. How can I solve this problem? Thank you all for your answers."},
{"Title": "Uploading files to a shared folder consumes my storage space?", "Author": "u/IseeYouLater", "Content": "Hello,\n  \n\n    as mentioned in the headline I am slightly confused.\n  \n\n    A friend shared a google drive folder with me to upload our vacation pics - I created a Subfolder in his shared folder and now when I upload my pics to the subfolder that I created, the files count against my storage limit. Which is bad cuz I am already very close to max.\n  \n\n    Is this intended? Everywhere on the net it says subfolders should count against the parent folder's storage limit.\n  \n\n    What am I missing here?"},
{"Title": "FLAC Server + Player that handles Ratings well, last played?", "Author": "u/th_teacher", "Content": "I believe nothing works well with \"standard\" tags, only stored in the database?\n  \n\n    I do not need multi-user handling.\n  \n\n    But I do want to be able to periodically export from the database and store the ratings in the FLAC tags for playlist creation\n  \n\n    hoping other servers/players will at least use them read-only\n  \n\n    Last played would be nice too, is played - count a thing?"},
{"Title": "How to backup an entire website from a few days ago?", "Author": "u/TheGoodSir1", "Content": "Since vimm.net got in trouble with Nintendo I can't get new games for my GBC (I have a flash cart) and I was wondering if it would be possible to back up the entirety of vimm.net to archive.org   or a personal file/files, I know you can save individual webpages but since in some sections of the website there is near 20,000 pages, it would take forever. Are there any ways too?"},
{"Title": "What Podcasts to Hoard?", "Author": "u/4bstractals", "Content": "So, I just discovered \nPodcastBulkDownloader\n thanks to a recent \nthread\n, and it's got we wondering...\n  \n\n    If I am going to start assembling a podcast hoard, what are the criteria that I might use to decide what gets included? Obviously, podcasts I \nlike\n would be the primary metric -- but I can download all of those in a couple of hours, and I have a \nlot\n more space.\n  \n\n    So... what about podcasts at risk of going behind a paywall? Podcasts of significant cultural importance? How does one best serve as a casual archivist for such a massive amount of data?"},
{"Title": "Hard Drive Formatting from Windows to Mac  Catch-22 Situation", "Author": "u/djensenteeken", "Content": "Hey everyone, so i have a situation i need help with.\n  \n\n    I recently switched over from my HP Omen laptop to a new MacBook Pro. Not knowing about the data formatting situation, I backed up all my data from my old laptop onto my Seagate Expansion Portable Drive 2TB. When using my MacBook, I noticed I couldn't upload files to this harddrive because the file formatting was different.\n  \n\n    I found on the internet that to switch the external harddrive from NTFS to APFS I can use Disk Utility to reformat the device. For this to happen however i have to backup the files that I have on my external harddrive, because to reformat it the harddrive has to be erased.\n  \n\n    The thing is, if i back-up the files to my old HP Omen, I can't reupload the files back to my external hard drive because it has been reformatted to APFS, and the files are NTFS. I also can't back-up the files to my new MacBook, because the size of my files is way to big for the internal storage of my Macbook!\n  \n\n    Is the only option for this really just to buy another external harddrive coded to APFS, or keep my files on my hard drive on my old dusty laptop that barely functions? This feels like a catch-22 situation to me.\n  \n\n    Sorry if this question has a) been answered already or b) is not relevant to this subreddit. Any help is appreciated!"},
{"Title": "Macrium Reflect Home Does Not Send Me Installation Code", "Author": "u/Skywatchmartin", "Content": "While installing Macrium Reflect Home I click Send Code However in the mail they send there is no code.\n  \n\n    The Mail is Just Users Manual.\n  \n\n    How can I Install Macrium Reflect Home?"},
{"Title": "How do you archive emails?", "Author": "u/Commercial_Union_296", "Content": "How were you able to save your emails from many years back?"},
{"Title": "NAS vs just in PC", "Author": "u/EnigmatheEgg", "Content": "Hi all!\n  \n\n    I have started to trust the internet less and less and have decided to save as much as I can in my own drives at home. I managed to find a Fractal design R5 with all drive sleds still there and thought it would make a great NAS Chassi. But now I'm wondering, do I need a NAS or can I just move my PC components there and just have a PC with 30+TB of space? All of the other people on the network don't have much data to store and would rather I help them anyway to save things. What other reasons would there be to have my data storage in a seperate chassi?"},
{"Title": "How to save entire Google site (which I don't own) for offline viewing?", "Author": "u/redrockerou812", "Content": "I tried HTTrack and Cyotek Webcopy and they don't copy the menu bar, and it just launches a broken site.\n  \n\n    Specifically looking to copy this site \nSouthCarleton (google.com)\n with all links and files.\n  \n\n    If anyone can help me out with this I'd appreciate it."},
{"Title": "Backing up Google calendar", "Author": "u/c05d", "Content": "Hi,\n  \n\n    I’ve been using Google calendar for close to 20 years now. It’s started to bother me that my entire life is in Google’s hands and Id like to back this up & transfer to another service like Outlook\n  \n\n    what’s the best way to do this? I want everything including tasks etc to transfer\n  \n\n    thanks"},
{"Title": "How much free space should I leave on my 1TB HDD with a btrfs file system ?", "Author": "u/Yukinoooo", "Content": "Is it dangerous to leave 80GB on my 1TB HDD (only files without OS) ? I'm using GNU/Linux + KDE"},
{"Title": "[YoYotta] How can I change destination folder in LTO Tape", "Author": "u/ddd102", "Content": "https://preview.redd.it/yoyotta-how-can-i-change-destination-folder-in-lto-tape-v0-6t4uhiti1w5d1.png\n\n    Hi, there.\n  \n\n    I'm very newbie on YoYotta.\nToday, I do my first copy job. 3.5 inch HDD to LTO 8 Tape by YoYotta.\nBut, I wonder how can I change destination folder trees. This software create just same folder trees from the source folders. I don't want that way. I want to create different folder trees on LTO Tapes which I'll do back up my data.\n  \n\n    Anyone knows how can do that?\nAnd is there any LTO or YoYotta user community? even though subreddit.\nI need more information. Official website of YoYotta, already I checked, but I need to story from real users.\n  \n\n    Thanks!"},
{"Title": "How to organize 10+ years of computer and phone backups? ~3TB", "Author": "u/PrivateAd990", "Content": "I'm looking for strategies, tools / software and tips to make my long journey of organizing these backups easier. Main questions at the bottom for a TLDR.\n  \n\n    About the content:\n  \n\n\n\n\n\n    ~3tb total, 15 laptop backups, 12 phone backups\n  \n\n\n\n\n\n    there will be overlap / duplicates in content between backups\n  \n\n\n\n\n\n    backups contain folders I manually dragged onto the portable drive. I never plan to do a full restore of a backup.\n  \n\n\n\n\n\n    backups may contain photos, videos, downloads, photo editing files, code and projects I wrote, a lot of junk I'd like to scrap\n  \n\n\n\n\n\n    Hardware:\n  \n\n\n\n\n\n    A recent MacBook Pro\n  \n\n\n\n\n\n    empty Samsung T9 4TB SSD, ~2000MB/s\n  \n\n\n\n\n\n    WD 2.5\" passport HDD 5TB, ~110MB/s\n  \n\n\n\n\n\n    A second HDD with a copy of the above for redundancy\n  \n\n\n\n\n\n    Plan:\n  \n\n\n\n\n\n    first bring everything on the HDD to the SSD since the SSD is way faster\n  \n\n\n\n\n\n    sort through everything. I need help with this part\n  \n\n\n\n\n\n    move the organized backup back to the HDD since SSD's aren't suitable for cold storage\n  \n\n\n\n\n\n    implement a plan for the 3 2 1 backup method\n  \n\n\n\n\n\n    Questions:\n  \n\n\n\n\n\n    software or tools to sort, organize, de-dupe, delete through everything on the drive. Free or paid\n  \n\n\n\n\n\n    tips for how to search through everything instead of going folder by folder? I'm guessing software can help here.\n  \n\n\n\n\n\n    output folder structure suggestions? Should I just flatten all backups to one? Let's say, all photos I took with my phone from all the backups to one folder? Or is that a bad idea"},
{"Title": "How often does the pCloud discount $890 10TB lifetime come around? I need to move my GSuite data soon to a new place.", "Author": "u/n4n4n4n4n", "Content": "(I will be using cryptomator to mask the data)"},
{"Title": "Would it be possible to recover previously-deleted photos from a 1998 digital camera?", "Author": "u/Throwaway173638o", "Content": "I was curious in recovering any previously-deleted and current photos off a vintage camera.  The catch is that it doesn't have an SD card and that taking any additional photos after its filled starts to delete them.\n  \n\n    It does use a 3.5 mm cord with some kind of port for vintage computers. I have no problem getting a 3.5 mm to USB cord.\n  \n\n    Is there a similar process with data recovery for SD cards and hard drives that I can do with recovering data from the camera?  Would I also need some drivers for this camera to detect too?\n  \n\n    For context, the digital camera is a Mattel Barbie Digital Camera from 1998."},
{"Title": "WD MyPassport Ultra vs WD Black [6TB]", "Author": "u/Previous_Day4842", "Content": "Is one of these drives better than the other? It seems on here some people mention the WD black being total rubish. I really like these drives for the aesthetic, but have never owned one. I have owned the MyPassport models for years and years and have never had an issue. Are they equal and i'm safe to get the WD Black for aesthetics? Or would it be wiser to get the MyPassport Ultra, with the metal build and USB-C Connection?\n  \n\n    I would be using this drive for time machine backups. Aesthetics are rather important to me, so it is a bummer that the MyPassport ultra does not come in black."},
{"Title": "Python script to help identify hot swapped drives", "Author": "u/radialmonster", "Content": "No content"},
{"Title": "Starting my self owned drive journey", "Author": "u/tessereis", "Content": "I'm moving from various cloud drives to local backups. I really would like some suggestion from this sub.\n  \n\n    I've 2 backups.\n  \n\n\n\n\n\n    SSD 1TB - formatted to exFat. I've heard bad things about this fs but I really need this drive to be cross compatible and plug and play. This seemed to be the only sane choice.\n  \n\n\n\n\n\n    HDD 2TB - formatted to ext4/zfs. Haven't decided on this yet, will probably go with zfs because it auto recovers and doesn't need to run something like fsck. Increased size for versioning.\n  \n\n\n\n\n\n    I'm planning to keep my SSD portable (on a trip etc) and whenever I'm at home, connect it to a system (rasp pi or a regular PC) with photoprism or librephotos installed. HDD is going to be the cold storage.\n  \n\n    I tried to follow the 3-2-1 rule but can't afford to get another drive just yet. Although, I'm thinking to get S3 Glacier for that offsite storage."},
{"Title": "SFTP/FTP/Local File Move", "Author": "u/Dking2204", "Content": "Coming from MacOS using Transit to Windows, I would like to move a large number of personal files from the Mac drives to the new Windows machine. What software is recommended? I keep seeing that Filezilla needs to be more secure, and I'm unsure about others. I appreciate any help you can provide."},
{"Title": "Anyone have luck with any of the high-speed 4x6 photo scanners with feed trays? I’ve tried 3 now and none seem good so far.", "Author": "u/Hour-Process6382", "Content": "I have 8000 photos to digitize. I've tried and returned 3 Epson FastFoto 680Ws because they all scratched the print photos, but scan at 600dpi was acceptable color and quality. But scratching the originals is non-starter. Plustek ePhoto 2300 is too slow with its single-feed, quality was ok. Now I'm on a Canon RS40 because my local photolab uses them for bulk scanning but the output is terrible with crushed blacks and super saturated reds - they even gave me info on their setup.\n  \n\n    I see a new product: Visioneer High-Speed Color Photo and Document Scanner PH70. I guess I'll try that one. Anyone have any experience with it? It's too new to find reviews.\n  \n\n    There's also the ScanSnap iX1600, but haven't researched it yet.\n  \n\n    Anyone successfully setup the Canon RS40 with quality output or have any other recommendations for a hi-speed photo scanner? About to give up!\n  \n\n    (I know flatbed is best, but not feasible for so many photos)."},
{"Title": "Offline served and auto-updating Wikipedia instance", "Author": "u/BarthoAz", "Content": "Hello!\n  \n\n    I was wondering if there was some tool out there that could:\n  \n\n\n\n\n\n    download the entire Wikipedia database (w/ images and in maybe 2~3 languages)\n  \n\n\n\n\n\n    keep it synced/updated\n  \n\n\n\n\n\n    being able to serve it statically through a self-hosted website\n  \n\n\n\n\n\n    bonus: keeping all of the data in files easily readable by humans, even without any tool\n  \n\n\n\n\n\n    Quite a wishlist, but I want to know if something like this (or similar) already exists before trying to do it myself!"},
{"Title": "Multipath aggregation aware file copy software?", "Author": "u/pally_nid", "Content": "I barely know how to ask this question...\n  \n\n    Would anyone know of a file copying software that can handle a source/destination like a NAS with multiple 1gb network interfaces.\nMaybe its best if I describe the effect I am looking for.\n  \n\n    Start a copy job, reach the avg-peak of 100MB/s and then the software becomes aware of this and then continues to enumerate folders as subtasks and starts these folders on the other IP addresses available from the NAS.\n  \n\n    So, if the NAS had 2 gb/s NICs, both would be saturated at 100MB/s, rather than only one granting higher thorough-put.\n  \n\n    Thank you for reading."},
{"Title": "What is the best free(non trial) software for converting a dvd to mp4 (ideally with subtitles)?", "Author": "u/Immediate-Risk-7569", "Content": "Every software I found is a trial with either a time limit or an ugly watermark."},
{"Title": "Photo deduplication on Mac", "Author": "u/ChumboChili", "Content": "Hello all -\n  \n\n    I have a significant volume of photo dupes to work through, but I am a bit particular as to how I want to proceed through them, and so I wanted to ask about those with experience with deduplication apps.\n  \n\n    I want to create a master set of photos, organized by year and device.  Accordingly, in a serial fashion, I want to use a folder as a reference source, compare its contents to a second folder, and in the second folder I would like to be able to:\n  \n\n    --easily see the non-duplicate photos;\n  \n\n    --also be able to see the duplicate photos, and delete them.\n  \n\n    I would also like to be able to identify and delete duplicates WITHIN a folder and its subfolders, although I understand that functionality is pretty standard.\n  \n\n    One final question, is whether this can also be performed for video files.\n  \n\n    Any recommendations to achieve this workflow would be most appreciated.  Thanks all."},
{"Title": "using gallery-dl for downloading sub. only content in deviantart", "Author": "u/South-Order2046", "Content": "I want to download a gallery of a creator that I have been subscribed to. I first tried download them with using \"WFDownloaderApp\" but it only downloaded the public images and gave me an error while trying to download the private images (subscribers only). Then, I tried my chances with gallery-dl. First, I had tried without adding any .conf file, but it gave me \"API responded with 429 Too Many Requests.\" error.  It doesn't work with any amounts of delay. Next, I added the .conf file, put my own client_id and client_secret values into that file. But it still give me the same error. How can I solve this problem? Thank you all for your answers."},
{"Title": "Uploading files to a shared folder consumes my storage space?", "Author": "u/IseeYouLater", "Content": "Hello,\n  \n\n    as mentioned in the headline I am slightly confused.\n  \n\n    A friend shared a google drive folder with me to upload our vacation pics - I created a Subfolder in his shared folder and now when I upload my pics to the subfolder that I created, the files count against my storage limit. Which is bad cuz I am already very close to max.\n  \n\n    Is this intended? Everywhere on the net it says subfolders should count against the parent folder's storage limit.\n  \n\n    What am I missing here?"},
{"Title": "FLAC Server + Player that handles Ratings well, last played?", "Author": "u/th_teacher", "Content": "I believe nothing works well with \"standard\" tags, only stored in the database?\n  \n\n    I do not need multi-user handling.\n  \n\n    But I do want to be able to periodically export from the database and store the ratings in the FLAC tags for playlist creation\n  \n\n    hoping other servers/players will at least use them read-only\n  \n\n    Last played would be nice too, is played - count a thing?"},
{"Title": "How to backup an entire website from a few days ago?", "Author": "u/TheGoodSir1", "Content": "Since vimm.net got in trouble with Nintendo I can't get new games for my GBC (I have a flash cart) and I was wondering if it would be possible to back up the entirety of vimm.net to archive.org   or a personal file/files, I know you can save individual webpages but since in some sections of the website there is near 20,000 pages, it would take forever. Are there any ways too?"},
{"Title": "What Podcasts to Hoard?", "Author": "u/4bstractals", "Content": "So, I just discovered \nPodcastBulkDownloader\n thanks to a recent \nthread\n, and it's got we wondering...\n  \n\n    If I am going to start assembling a podcast hoard, what are the criteria that I might use to decide what gets included? Obviously, podcasts I \nlike\n would be the primary metric -- but I can download all of those in a couple of hours, and I have a \nlot\n more space.\n  \n\n    So... what about podcasts at risk of going behind a paywall? Podcasts of significant cultural importance? How does one best serve as a casual archivist for such a massive amount of data?"},
{"Title": "Hard Drive Formatting from Windows to Mac  Catch-22 Situation", "Author": "u/djensenteeken", "Content": "Hey everyone, so i have a situation i need help with.\n  \n\n    I recently switched over from my HP Omen laptop to a new MacBook Pro. Not knowing about the data formatting situation, I backed up all my data from my old laptop onto my Seagate Expansion Portable Drive 2TB. When using my MacBook, I noticed I couldn't upload files to this harddrive because the file formatting was different.\n  \n\n    I found on the internet that to switch the external harddrive from NTFS to APFS I can use Disk Utility to reformat the device. For this to happen however i have to backup the files that I have on my external harddrive, because to reformat it the harddrive has to be erased.\n  \n\n    The thing is, if i back-up the files to my old HP Omen, I can't reupload the files back to my external hard drive because it has been reformatted to APFS, and the files are NTFS. I also can't back-up the files to my new MacBook, because the size of my files is way to big for the internal storage of my Macbook!\n  \n\n    Is the only option for this really just to buy another external harddrive coded to APFS, or keep my files on my hard drive on my old dusty laptop that barely functions? This feels like a catch-22 situation to me.\n  \n\n    Sorry if this question has a) been answered already or b) is not relevant to this subreddit. Any help is appreciated!"},
{"Title": "Macrium Reflect Home Does Not Send Me Installation Code", "Author": "u/Skywatchmartin", "Content": "While installing Macrium Reflect Home I click Send Code However in the mail they send there is no code.\n  \n\n    The Mail is Just Users Manual.\n  \n\n    How can I Install Macrium Reflect Home?"},
{"Title": "How do you archive emails?", "Author": "u/Commercial_Union_296", "Content": "How were you able to save your emails from many years back?"},
{"Title": "How do I download a certain video from the wayback machine?", "Author": "u/wiicrafttech", "Content": "This is the link I'm using\n  \n\n\nhttps://web.archive.org/web/20230520032047/https://www.youtube.com/watch?v=Oy2c6Mt9KwY#"},
{"Title": "Does anyone know how to look into .rpk files? (Related to EA games)", "Author": "u/EUOS_the_cat", "Content": "Let me know if this isn't the right sub for this, and if it isn't, point me in the right direction please.\n  \n\n    I'm on a mission to extract models from old Littlest Pet Shop games (PC, Wii), and unfortunately they were made by EA. Me and another person have looked into it, and the models are stored in the .big format. These have ways to be opened, however they lead to the .rpk files that have no information that either of us could find on how to get into. The only info about them I see is that they're used as skins for RadLight, which obviously isn't what these files are.\n  \n\n    If anyone knows a way to get into these files, I'd be very thankful."},
{"Title": "CGSociety - Site Rip", "Author": "u/valdearg", "Content": "Completely forgot about this from \nhttps://old.reddit.com/r/DataHoarder/comments/18tlukv/cgsociety_is_closing_up_soon_decades_of_valuable/\n\n\n\n\nhttps://archive.org/details/cgsocietyarchive\n\n\n\n    It's about 300GB+\n  \n\n    Images has JSON files with their metadata alongside it.\n  \n\n    Torrent needs to be regenerated I think, not sure if there's a way to do that."},
{"Title": "Best software to automatically catalog / search your data", "Author": "u/ripperdoc", "Content": "New to this subreddit. For long believed in manual cataloguing but I’m starting to feel I don’t have time for that. What’s the go to software for automatically cataloguing data, from documents to websites to media?"},
{"Title": "AWS deep freeze pricing", "Author": "u/KingRollos", "Content": "I'm thinking of moving most of my backup to Amazon's deep freeze service. I'm sure it's made complicated deliberately.\n  \n\n    I'm thinking of adding it in bits. Will this cost me more? Do I need to gather it all together and then transfer in 1 go?"},
{"Title": "NAS nvme build options", "Author": "u/AHappyGaijin", "Content": "Hello, i am currently building my first NAS using a Topton N100 board.\n  \n\n    Im currently deciding on which nvme to use as a system drive - currently leaning for a WD Blue SN580 2Tb. My question is if one should get 2 of the same drive to mirror the operating System?\n  \n\n    Using 2 nvme drives would limit the pcie expansion possibility of the board because the second nvme slot shares lanes with the nvme slot. Though currently i have no plans to use a pcie expansion card."},
{"Title": "Are Kingston and Corsair SSDs still reliable?", "Author": "u/SoftAlexandra3", "Content": "Hi there! First time on the sub. Planning on upgrading my laptop to 4TB M.2 SSD and I'm looking at possible brand options. I know Samsung and Crucial are very good options, but at the same time I wanna know if Kingston and Corsair are also good options in today's market for long term storage and speed.\n  \n\n    Context: I'm moving from a 1TB WD SATA HDD and 128GB TOSHIBA M.2 SSD combo that came with my laptop, and they've been slowly failing with disk 100 usage when I have plenty of space. I'm also planning to move all my family memories from an assortment of thumbdrives and majority of Google Cloud storage to a partition I'll make after I upgrade. I'm also on a relative budget of max around €320 / $330\n  \n\n    I hope fellow data hoarders will help a newbie like me with this, as I also don't have the money for a 990/980 PRO atm, and the laptop will be a storage driver after I upgrade to a tower in the future years."},
{"Title": "NVMe SSD enclosure vs Portable external SSD?", "Author": "u/ProFalseIdol", "Content": "I am looking for at least 1TB to store videos and pictures. Travel a lot, so it has to be as convenient and compact as a Flash thumb drive. I saw plenty of recommendations of using NVMe + enclosure for portable consumer storage.\n  \n\n    Then I saw the SSK Portable options (while looking for their enclosure).. Also the Crucial X6..\n  \n\n\nhttps://www.amazon.com/SSK-Portable-External-MacBook-Laptops/dp/B0CL94LX9W?ref_=ast_sto_dp&th=1\n\n\n\n\nWhat are the pros and cons?\n For 87 USD, you have a ready to use USB C or A portable solution. Got a new laptop with USB 4 and USB-C 3.2 Gen 2 ports (I assume I can get that sweet 2000 MB/s read/write)..\n  \n\n    Versus an M.2 NVMe + enclosure that I probably will never upgrade and will be permanently external as if I bought a Thumb drive..\n  \n\n    TIA!"},
{"Title": "Best Way To Dump/Mirror 16'000 mp3 (Podcast) Files?", "Author": "u/Redditarianist", "Content": "As the title states. I'm looking to upload around 16 thousand podcasted files to the Internet Archive & am looking for the best way.\n  \n\n    Is there an RSS ingest system at all?"},
{"Title": "Looking for a cloud backup service", "Author": "u/aradbe", "Content": "Hey all,\n  \n\n    so pretty simple, im looking for a cloud service where can i backup some of my important files so ill have them in case i lose them.\n  \n\n    i dont know much about this kinda stuff amd im looking for something simple and reliable, i was interested to see if thers a service where i can start off with purchasing a sub for a set amount of storage and if i want more later i can add a few dollars and expand the storage. like maybe start out with 100gb and expand it to 200gb if i need it later.\n  \n\n    If there nothing like then i would just like a recommendation for a good reliable backup service that will do the job.\n  \n\n    Thanks for any replies !"},
{"Title": "NOAA Coast Survey is shutting down the Raster Navigational Chart Tile Service (RNC) and other related services", "Author": "u/TheHornedGod", "Content": "I stumbled across this while doing some research and noticed there are no threads here about it. I'm late to the party on this but I thought if there are some people already on the case then maybe users from this subreddit might be interested in finding them to help with backups and hosting.\n  \n\n    The NOAA is shutting down some of their online and printed services and they are removing that data from their websites. This project actually began in 2021 and is set to be completed in 2025.\n  \n\n\nSo what is the RNC?\n\n\n\n\n\n    NOAA's RNC Tile Service (WMTS)\n  \n\n\n\n\n\n    The NOAA RNC Tile Service provides standardized nautical chart tilesets for the public, eliminating the need for application developers to regularly undergo the cumbersome process of transforming NOAA BSB files into tilesets. It provides geo-referenced charts compatible with the Web Map Tile Specifications (WMTS) and Tile Map Service Specification (TMS). All tilesets are published on a weekly basis.\n  \n\n\n\n    Original website (already deleted?): \nhttps://tileservice.charts.noaa.gov\n\n\n\n    Their annoucement:\n  \n\n\n\n    NOAA will shut down its Raster Navigational Chart (RNC) Tile Service and the online RNC Viewer on October 1, 2021. The NOAA Seamless Raster Navigational Chart Services will be shut down on January 1, 2022. This is part of a larger NOAA program to end production and maintenance of all NOAA traditional paper and raster nautical charts that was announced in the Federal Register in November 2019.\n  \n\n\n\n\n\n    Cancellation of traditional NOAA paper nautical charts and associated raster nautical chart products, such as BookletCharts™ and Raster Navigational Charts (RNC) will occur over the next four years and be completed by January 2025. More information about this overarching program to “sunset” traditional  nautical chart products is available on the “\nFarewell to Traditional Nautical Charts\n” web page.\n  \n\n\n\n    -- \nsource\n\n\n\n\nWhy help with this project?\n\n\n\n    The abandoned nautical tilesets and paper charts have been replaced with GIS offerings for modern equipment, however these older documents were a failsafe for smaller vessels and operations. They may not have the technical know how to backup and retrieve this data otherwise."},
{"Title": "Sort backup raid 1", "Author": "u/sweetestpeach94", "Content": "Hi, I hope I can get some help. I have a Lacie 2big thunderbolt 2 set as Raid 1. I’ve just completed the backup of almost 6TB of data (mainly pics), however half of it are just the mirror copies. Now I would move the original half on another disk, the problem is that the backup isn’t like sort out in different folders, it’s just every file and its copy back to back in sequence all together (file A, file A-2 , file B, file B-2, file C, file C - 2 etc.). So here is my question, how I select just one half of the files to move it in the new disk without their duplicate?"},
{"Title": "Suitcase for 3.5\" disks with screwed on HotSwap", "Author": "u/No-Balance-8038", "Content": "Need a way to protect my backup disks that are meant to be stored offsite.\nI already got cases, but they are too small to account for a 3.5\" HDD plus the mount for SilverStone Technology RM43-320-RS.\n  \n\n    What would you guys recommend? I live in Germany. From Amazon would be cool.\nI already have 3.5\" Protection cases but they are not long enough!\nThe HDDs are 17cm long with it."},
{"Title": "are SSK USB flash drives safe?", "Author": "u/retrorays", "Content": "I read how USB drives can run malware to act as a USB keyboard and then compromise your system. I see the SSK drives are from China. Do we know if they are safe?"},
{"Title": "Video upscaling 480p to 1080 ffmpeg", "Author": "u/1michaelbrown", "Content": "The title pretty much explains what I’m asking. I want to know if it’s worth it since most dvds only provide 480p. Would it be worth it upscaling it to 1080p. With FFmpeg.\n  \n\n    I plan on buying 100” screen and projector. If that matters\n  \n\n    What I am using to encode with. I can use either.\n  \n\n    Mac mini M1 Or Dell power edge r620 with Debian vm With two cpus with a total of 40 cores.\n  \n\n    I plan on using FFmpeg via command line. (Some inside thoughts I want to make a script that will kind of automate this process. Checking if upscaling is needed or not)\n  \n\n    I am new here I hope this post is the right place."},
{"Title": "For Those That Archive YouTube Videos From Your Favorite Channels, Do You Archive Your Videos in the Highest Possible Quality or Do You Limit The Quality of Your Downloads to Save Storage Space?", "Author": "u/Ripcitytoker", "Content": "I personally always save videos in the highest quality possible, regardless of how much storage it takes u. Does anyone else do this or do you download videos in lower quality (like 1080p instead of 4k) in order to use up less storage space?"},
{"Title": "Downloading PDF file from offline website", "Author": "u/Puzzleheaded-King295", "Content": "I have a URL of a said website that ends in .pdf. The issue is that the whole website is down, and does not seem it will be up back. With the URL alone, would one be able to download the PDF? (Non-archived)\n  \n\n    iOS/MacOS"},
{"Title": "Alternatives to Epson V600", "Author": "u/ass-master-blaster", "Content": "The V600 is discontinued in my country (past prices are around $650) and the V850 is too expensive ($1600). Are there any alternatives around the same price and quality for a newer model scanner? I've looked at the FastFoto and don't like the quality of the photos and am happy to spend the time with a flatbed scanner."},
{"Title": "Software for finding all files with identical names on a drive", "Author": "u/MisterPenishead", "Content": "I have a hard drive with thousands of files spread across different folders and some of the files have the same name in spite of them having different content. Is there a software I can use to find all files with identical names so that I can rename them?"},
{"Title": "Offsite backup for 20TB Linux data and capped Internet connection?", "Author": "u/Supertanker13", "Content": "I have a poor Internet connection, a Linux NAS, a secondary/backup Linux NAS, a handful of Windows PCs with Veeam Agent, a few Linux PCs, a gigabit local network, a piss-poor and data-capped Internet connection, and a bunch of hard drives. I need help figuring out the 2-1 part of my 3-2-1 plan.\n  \n\n    Most of my data is on the primary NAS, about 20TB worth. A stupid amount of it is large raw photos from vacations--let's say 8TB. The rest is a packrat assortment of All The Things going back to the early 00s and most of it is personal large data like video game development environments, art assets, etc that I consider irreplaceable. Storage is two 2x12TB mirrors.\n  \n\n    I also have up to 1TB of data per Windows PC. The important folders get backed up to the NAS via Veeam Agent, so I have a handful of several-hundred-GB files per PC there.\n  \n\n    My Linux PCs are mostly covered by BackupPC, which is very crusty these days and I may end up switching to something else. That's another topic for another day. It's not very much data. But it also also stores on the NAS.\n  \n\n    The NAS itself is replicated via zfs send to a local secondary NAS. The primary NAS has mirrored zdevs but the secondary NAS has single drive zdevs, so two separate 12TB drives.\n  \n\n    So my data sources and primary backups are:\n  \n\n\n\n\n\n    Windows PCs -> NAS -> backup NAS (via zfs replication of Veeam directory)\n  \n\n\n\n\n\n    Linux PCs -> NAS -> backup NAS (via zfs replication of backuppc dir)\n  \n\n\n\n\n\n    NAS -> secondary NAS (via zfs replication)\n  \n\n\n\n\n\n    You're probably noticing the glaring hole in my setup: off-site replication for the NAS. What would you do for your offsite backup? There are a dizzying array of options for slapping data on some 12TB externals. Encryption seems like a good idea in case of theft (lots of receipts, financial documents, etc). But do I layer it on top of something like LUKS? zfs native encryption? Do those play well with big external drives?\n  \n\n    I was using zfs replication for awhile to an external drive, but this would be my \"my house and neighborhood burned down\" recovery plan, which makes me worry about starting from nothing: is a backup that I can't access with a surviving Windows laptop (easiest thing to get my hands on) worth anything? What's the Windows-compatible field look like?\n  \n\n    My biggest two worries are: being able to start over from nothing after a natural disaster (#1) and stolen drives (#2).\n  \n\n    As a side note, the Veeam files are huge and are a non-trivial amount of time to transfer during a backup...I wish Veeam Agent (standalone) could hit multiple backup targets on a rotation...\n  \n\n    Thanks for reading"},
{"Title": "Good Databasing software for digital media (movies in particular)?", "Author": "u/sbourwest", "Content": "My Dad has a pretty extensive collection of movies (close to 6,000), and his only real method for cataloguing is a private streaming platform (Emby), but he's interested in creating a database for all of his content, but doesn't want to have to populate the whole thing himself, he'd rather be able to just type in the media and have it pull from online databases like IMDB or the like.\n  \n\n    He would prefer PC software, no mobile apps or online-only (have to register an account) platforms, browser-based is fine though.\n  \n\n    I've tried doing a bit of looking myself but most personal film cataloguing software is focused on physical media (DVDs, Blu-Rays, etc.) and not a digital collection."},
{"Title": "Looking for some critiquing of my plan.", "Author": "u/OnenonlyAl", "Content": "Thanks for taking the time to read and comment. I'm looking to backup a zpool of media. I had tried to setup a truenas for the data but I didn't love the UI and I have what I need on Ubuntu with docker. My plan is to destroy a zpool of the truenas made of 4x10tb raidz1 and move that pool into the primary server (add a pcie with more sata ports) then use zpool attach to mirror my current 4x8tb raidz1 (mnt) to the newly recreated zpool of the 4x10tb from the old truenas server (named mntbackup). So zpool attach mnt to mntbackup. Sounds like this automatically starts mirroring.\n  \n\n    I know this isn't ideal without being an off-site backup but I'm not the most literate at actually managing this and want something easy. Would I be able to just plug in backup, then unplug the backup pool and cold storage? I don't need perfect redundancy. Would I be able to plug the mntbackup raidz1 back in sometime in the future and the missing new data automatically sync or would I need scripts of rysnc or zfs send receive to add new data?\n  \n\n    Thanks for any insight and help!"},
{"Title": "Sorting tens of thousands of recovered video files by presence of audio?", "Author": "u/CyberpunkLover", "Content": "I've been collecting music video clips for about 15 years now, and collected something like 85k clips.\nI've been putting everything on hard drives, then after filling them up, moving everything to larger drive.\nThe last drive I've used was some Western Digital Blue 8TB drive, and last week it filled up, so I purchased a new 20TB drive and was about to copy everything into it, but before I could do that, the WD drive failed.\n  \n\n    I've used few file restoration programs, and managed to salvage about 80% of everything that was on the drive, but the problem is, like 70% of what I've restored is either corrupted, or doesn't have audio. And all the files were put into ~75 different folders, with around 900 or so files each.\nI'd like to sort out the files with audio and without, in order to save the good ones and get rid of the bad ones.\nAll files were renamed to random letters and numbers by recovery software, so the corrupted and muted files are basically completely useless to me, since I can't even use the file names to find out what files those are.\n  \n\n    All the files are either .mp4, .mkv, .avi, .mov or .wmv.\n  \n\n    Sorting through tens of thousands of files would take me months, and I just don't have the time or patience to do that. I've had the idea of importing files into video editing soft like Premiere and look at the generated waveform to find out good files,  but there's quite a lot of files with codecs unsupported by Premiere, like VP09 and such, so vast majority of files, even with audio present show up as flat lines on Premiere waveform, thus this method is completely useless to me. Like, importing a folder of restored files only generates maybe 20-30 waveforms, the rest are flat lines, and so manual sorting is still required.\n  \n\n    Anyone know of any software that can scan thousands of files and either mark or separate them by presence of audio, or have some other solution?"},
{"Title": "Help getting a 3D model from web model viewer, is it possible?", "Author": "u/ConsistentYou4832", "Content": "I have seen this question asked many times in this subreddit, and this time was my time. I have been scrolling and testing every way I found here but I haven't been able to succeed.\n  \n\n    Could you guys help me on this one I need the model to create a custom body kit for \nthis car"},
{"Title": "How far does your email archive go back to?", "Author": "u/Commercial_Union_296", "Content": "My sent email archive goes back to 2013."},
{"Title": "How do I download a certain video from the wayback machine?", "Author": "u/wiicrafttech", "Content": "This is the link I'm using\n  \n\n\nhttps://web.archive.org/web/20230520032047/https://www.youtube.com/watch?v=Oy2c6Mt9KwY#"},
{"Title": "Does anyone know how to look into .rpk files? (Related to EA games)", "Author": "u/EUOS_the_cat", "Content": "Let me know if this isn't the right sub for this, and if it isn't, point me in the right direction please.\n  \n\n    I'm on a mission to extract models from old Littlest Pet Shop games (PC, Wii), and unfortunately they were made by EA. Me and another person have looked into it, and the models are stored in the .big format. These have ways to be opened, however they lead to the .rpk files that have no information that either of us could find on how to get into. The only info about them I see is that they're used as skins for RadLight, which obviously isn't what these files are.\n  \n\n    If anyone knows a way to get into these files, I'd be very thankful."},
{"Title": "CGSociety - Site Rip", "Author": "u/valdearg", "Content": "Completely forgot about this from \nhttps://old.reddit.com/r/DataHoarder/comments/18tlukv/cgsociety_is_closing_up_soon_decades_of_valuable/\n\n\n\n\nhttps://archive.org/details/cgsocietyarchive\n\n\n\n    It's about 300GB+\n  \n\n    Images has JSON files with their metadata alongside it.\n  \n\n    Torrent needs to be regenerated I think, not sure if there's a way to do that."},
{"Title": "Best software to automatically catalog / search your data", "Author": "u/ripperdoc", "Content": "New to this subreddit. For long believed in manual cataloguing but I’m starting to feel I don’t have time for that. What’s the go to software for automatically cataloguing data, from documents to websites to media?"},
{"Title": "AWS deep freeze pricing", "Author": "u/KingRollos", "Content": "I'm thinking of moving most of my backup to Amazon's deep freeze service. I'm sure it's made complicated deliberately.\n  \n\n    I'm thinking of adding it in bits. Will this cost me more? Do I need to gather it all together and then transfer in 1 go?"},
{"Title": "NAS nvme build options", "Author": "u/AHappyGaijin", "Content": "Hello, i am currently building my first NAS using a Topton N100 board.\n  \n\n    Im currently deciding on which nvme to use as a system drive - currently leaning for a WD Blue SN580 2Tb. My question is if one should get 2 of the same drive to mirror the operating System?\n  \n\n    Using 2 nvme drives would limit the pcie expansion possibility of the board because the second nvme slot shares lanes with the nvme slot. Though currently i have no plans to use a pcie expansion card."},
{"Title": "Are Kingston and Corsair SSDs still reliable?", "Author": "u/SoftAlexandra3", "Content": "Hi there! First time on the sub. Planning on upgrading my laptop to 4TB M.2 SSD and I'm looking at possible brand options. I know Samsung and Crucial are very good options, but at the same time I wanna know if Kingston and Corsair are also good options in today's market for long term storage and speed.\n  \n\n    Context: I'm moving from a 1TB WD SATA HDD and 128GB TOSHIBA M.2 SSD combo that came with my laptop, and they've been slowly failing with disk 100 usage when I have plenty of space. I'm also planning to move all my family memories from an assortment of thumbdrives and majority of Google Cloud storage to a partition I'll make after I upgrade. I'm also on a relative budget of max around €320 / $330\n  \n\n    I hope fellow data hoarders will help a newbie like me with this, as I also don't have the money for a 990/980 PRO atm, and the laptop will be a storage driver after I upgrade to a tower in the future years."},
{"Title": "NVMe SSD enclosure vs Portable external SSD?", "Author": "u/ProFalseIdol", "Content": "I am looking for at least 1TB to store videos and pictures. Travel a lot, so it has to be as convenient and compact as a Flash thumb drive. I saw plenty of recommendations of using NVMe + enclosure for portable consumer storage.\n  \n\n    Then I saw the SSK Portable options (while looking for their enclosure).. Also the Crucial X6..\n  \n\n\nhttps://www.amazon.com/SSK-Portable-External-MacBook-Laptops/dp/B0CL94LX9W?ref_=ast_sto_dp&th=1\n\n\n\n\nWhat are the pros and cons?\n For 87 USD, you have a ready to use USB C or A portable solution. Got a new laptop with USB 4 and USB-C 3.2 Gen 2 ports (I assume I can get that sweet 2000 MB/s read/write)..\n  \n\n    Versus an M.2 NVMe + enclosure that I probably will never upgrade and will be permanently external as if I bought a Thumb drive..\n  \n\n    TIA!"},
{"Title": "Best Way To Dump/Mirror 16'000 mp3 (Podcast) Files?", "Author": "u/Redditarianist", "Content": "As the title states. I'm looking to upload around 16 thousand podcasted files to the Internet Archive & am looking for the best way.\n  \n\n    Is there an RSS ingest system at all?"},
{"Title": "Looking for a cloud backup service", "Author": "u/aradbe", "Content": "Hey all,\n  \n\n    so pretty simple, im looking for a cloud service where can i backup some of my important files so ill have them in case i lose them.\n  \n\n    i dont know much about this kinda stuff amd im looking for something simple and reliable, i was interested to see if thers a service where i can start off with purchasing a sub for a set amount of storage and if i want more later i can add a few dollars and expand the storage. like maybe start out with 100gb and expand it to 200gb if i need it later.\n  \n\n    If there nothing like then i would just like a recommendation for a good reliable backup service that will do the job.\n  \n\n    Thanks for any replies !"},
{"Title": "NOAA Coast Survey is shutting down the Raster Navigational Chart Tile Service (RNC) and other related services", "Author": "u/TheHornedGod", "Content": "I stumbled across this while doing some research and noticed there are no threads here about it. I'm late to the party on this but I thought if there are some people already on the case then maybe users from this subreddit might be interested in finding them to help with backups and hosting.\n  \n\n    The NOAA is shutting down some of their online and printed services and they are removing that data from their websites. This project actually began in 2021 and is set to be completed in 2025.\n  \n\n\nSo what is the RNC?\n\n\n\n\n\n    NOAA's RNC Tile Service (WMTS)\n  \n\n\n\n\n\n    The NOAA RNC Tile Service provides standardized nautical chart tilesets for the public, eliminating the need for application developers to regularly undergo the cumbersome process of transforming NOAA BSB files into tilesets. It provides geo-referenced charts compatible with the Web Map Tile Specifications (WMTS) and Tile Map Service Specification (TMS). All tilesets are published on a weekly basis.\n  \n\n\n\n    Original website (already deleted?): \nhttps://tileservice.charts.noaa.gov\n\n\n\n    Their annoucement:\n  \n\n\n\n    NOAA will shut down its Raster Navigational Chart (RNC) Tile Service and the online RNC Viewer on October 1, 2021. The NOAA Seamless Raster Navigational Chart Services will be shut down on January 1, 2022. This is part of a larger NOAA program to end production and maintenance of all NOAA traditional paper and raster nautical charts that was announced in the Federal Register in November 2019.\n  \n\n\n\n\n\n    Cancellation of traditional NOAA paper nautical charts and associated raster nautical chart products, such as BookletCharts™ and Raster Navigational Charts (RNC) will occur over the next four years and be completed by January 2025. More information about this overarching program to “sunset” traditional  nautical chart products is available on the “\nFarewell to Traditional Nautical Charts\n” web page.\n  \n\n\n\n    -- \nsource\n\n\n\n\nWhy help with this project?\n\n\n\n    The abandoned nautical tilesets and paper charts have been replaced with GIS offerings for modern equipment, however these older documents were a failsafe for smaller vessels and operations. They may not have the technical know how to backup and retrieve this data otherwise."},
{"Title": "Sort backup raid 1", "Author": "u/sweetestpeach94", "Content": "Hi, I hope I can get some help. I have a Lacie 2big thunderbolt 2 set as Raid 1. I’ve just completed the backup of almost 6TB of data (mainly pics), however half of it are just the mirror copies. Now I would move the original half on another disk, the problem is that the backup isn’t like sort out in different folders, it’s just every file and its copy back to back in sequence all together (file A, file A-2 , file B, file B-2, file C, file C - 2 etc.). So here is my question, how I select just one half of the files to move it in the new disk without their duplicate?"},
{"Title": "Suitcase for 3.5\" disks with screwed on HotSwap", "Author": "u/No-Balance-8038", "Content": "Need a way to protect my backup disks that are meant to be stored offsite.\nI already got cases, but they are too small to account for a 3.5\" HDD plus the mount for SilverStone Technology RM43-320-RS.\n  \n\n    What would you guys recommend? I live in Germany. From Amazon would be cool.\nI already have 3.5\" Protection cases but they are not long enough!\nThe HDDs are 17cm long with it."},
{"Title": "are SSK USB flash drives safe?", "Author": "u/retrorays", "Content": "I read how USB drives can run malware to act as a USB keyboard and then compromise your system. I see the SSK drives are from China. Do we know if they are safe?"},
{"Title": "Video upscaling 480p to 1080 ffmpeg", "Author": "u/1michaelbrown", "Content": "The title pretty much explains what I’m asking. I want to know if it’s worth it since most dvds only provide 480p. Would it be worth it upscaling it to 1080p. With FFmpeg.\n  \n\n    I plan on buying 100” screen and projector. If that matters\n  \n\n    What I am using to encode with. I can use either.\n  \n\n    Mac mini M1 Or Dell power edge r620 with Debian vm With two cpus with a total of 40 cores.\n  \n\n    I plan on using FFmpeg via command line. (Some inside thoughts I want to make a script that will kind of automate this process. Checking if upscaling is needed or not)\n  \n\n    I am new here I hope this post is the right place."},
{"Title": "For Those That Archive YouTube Videos From Your Favorite Channels, Do You Archive Your Videos in the Highest Possible Quality or Do You Limit The Quality of Your Downloads to Save Storage Space?", "Author": "u/Ripcitytoker", "Content": "I personally always save videos in the highest quality possible, regardless of how much storage it takes u. Does anyone else do this or do you download videos in lower quality (like 1080p instead of 4k) in order to use up less storage space?"},
{"Title": "Downloading PDF file from offline website", "Author": "u/Puzzleheaded-King295", "Content": "I have a URL of a said website that ends in .pdf. The issue is that the whole website is down, and does not seem it will be up back. With the URL alone, would one be able to download the PDF? (Non-archived)\n  \n\n    iOS/MacOS"},
{"Title": "Alternatives to Epson V600", "Author": "u/ass-master-blaster", "Content": "The V600 is discontinued in my country (past prices are around $650) and the V850 is too expensive ($1600). Are there any alternatives around the same price and quality for a newer model scanner? I've looked at the FastFoto and don't like the quality of the photos and am happy to spend the time with a flatbed scanner."},
{"Title": "Software for finding all files with identical names on a drive", "Author": "u/MisterPenishead", "Content": "I have a hard drive with thousands of files spread across different folders and some of the files have the same name in spite of them having different content. Is there a software I can use to find all files with identical names so that I can rename them?"},
{"Title": "Offsite backup for 20TB Linux data and capped Internet connection?", "Author": "u/Supertanker13", "Content": "I have a poor Internet connection, a Linux NAS, a secondary/backup Linux NAS, a handful of Windows PCs with Veeam Agent, a few Linux PCs, a gigabit local network, a piss-poor and data-capped Internet connection, and a bunch of hard drives. I need help figuring out the 2-1 part of my 3-2-1 plan.\n  \n\n    Most of my data is on the primary NAS, about 20TB worth. A stupid amount of it is large raw photos from vacations--let's say 8TB. The rest is a packrat assortment of All The Things going back to the early 00s and most of it is personal large data like video game development environments, art assets, etc that I consider irreplaceable. Storage is two 2x12TB mirrors.\n  \n\n    I also have up to 1TB of data per Windows PC. The important folders get backed up to the NAS via Veeam Agent, so I have a handful of several-hundred-GB files per PC there.\n  \n\n    My Linux PCs are mostly covered by BackupPC, which is very crusty these days and I may end up switching to something else. That's another topic for another day. It's not very much data. But it also also stores on the NAS.\n  \n\n    The NAS itself is replicated via zfs send to a local secondary NAS. The primary NAS has mirrored zdevs but the secondary NAS has single drive zdevs, so two separate 12TB drives.\n  \n\n    So my data sources and primary backups are:\n  \n\n\n\n\n\n    Windows PCs -> NAS -> backup NAS (via zfs replication of Veeam directory)\n  \n\n\n\n\n\n    Linux PCs -> NAS -> backup NAS (via zfs replication of backuppc dir)\n  \n\n\n\n\n\n    NAS -> secondary NAS (via zfs replication)\n  \n\n\n\n\n\n    You're probably noticing the glaring hole in my setup: off-site replication for the NAS. What would you do for your offsite backup? There are a dizzying array of options for slapping data on some 12TB externals. Encryption seems like a good idea in case of theft (lots of receipts, financial documents, etc). But do I layer it on top of something like LUKS? zfs native encryption? Do those play well with big external drives?\n  \n\n    I was using zfs replication for awhile to an external drive, but this would be my \"my house and neighborhood burned down\" recovery plan, which makes me worry about starting from nothing: is a backup that I can't access with a surviving Windows laptop (easiest thing to get my hands on) worth anything? What's the Windows-compatible field look like?\n  \n\n    My biggest two worries are: being able to start over from nothing after a natural disaster (#1) and stolen drives (#2).\n  \n\n    As a side note, the Veeam files are huge and are a non-trivial amount of time to transfer during a backup...I wish Veeam Agent (standalone) could hit multiple backup targets on a rotation...\n  \n\n    Thanks for reading"},
{"Title": "Good Databasing software for digital media (movies in particular)?", "Author": "u/sbourwest", "Content": "My Dad has a pretty extensive collection of movies (close to 6,000), and his only real method for cataloguing is a private streaming platform (Emby), but he's interested in creating a database for all of his content, but doesn't want to have to populate the whole thing himself, he'd rather be able to just type in the media and have it pull from online databases like IMDB or the like.\n  \n\n    He would prefer PC software, no mobile apps or online-only (have to register an account) platforms, browser-based is fine though.\n  \n\n    I've tried doing a bit of looking myself but most personal film cataloguing software is focused on physical media (DVDs, Blu-Rays, etc.) and not a digital collection."},
{"Title": "Looking for some critiquing of my plan.", "Author": "u/OnenonlyAl", "Content": "Thanks for taking the time to read and comment. I'm looking to backup a zpool of media. I had tried to setup a truenas for the data but I didn't love the UI and I have what I need on Ubuntu with docker. My plan is to destroy a zpool of the truenas made of 4x10tb raidz1 and move that pool into the primary server (add a pcie with more sata ports) then use zpool attach to mirror my current 4x8tb raidz1 (mnt) to the newly recreated zpool of the 4x10tb from the old truenas server (named mntbackup). So zpool attach mnt to mntbackup. Sounds like this automatically starts mirroring.\n  \n\n    I know this isn't ideal without being an off-site backup but I'm not the most literate at actually managing this and want something easy. Would I be able to just plug in backup, then unplug the backup pool and cold storage? I don't need perfect redundancy. Would I be able to plug the mntbackup raidz1 back in sometime in the future and the missing new data automatically sync or would I need scripts of rysnc or zfs send receive to add new data?\n  \n\n    Thanks for any insight and help!"},
{"Title": "Sorting tens of thousands of recovered video files by presence of audio?", "Author": "u/CyberpunkLover", "Content": "I've been collecting music video clips for about 15 years now, and collected something like 85k clips.\nI've been putting everything on hard drives, then after filling them up, moving everything to larger drive.\nThe last drive I've used was some Western Digital Blue 8TB drive, and last week it filled up, so I purchased a new 20TB drive and was about to copy everything into it, but before I could do that, the WD drive failed.\n  \n\n    I've used few file restoration programs, and managed to salvage about 80% of everything that was on the drive, but the problem is, like 70% of what I've restored is either corrupted, or doesn't have audio. And all the files were put into ~75 different folders, with around 900 or so files each.\nI'd like to sort out the files with audio and without, in order to save the good ones and get rid of the bad ones.\nAll files were renamed to random letters and numbers by recovery software, so the corrupted and muted files are basically completely useless to me, since I can't even use the file names to find out what files those are.\n  \n\n    All the files are either .mp4, .mkv, .avi, .mov or .wmv.\n  \n\n    Sorting through tens of thousands of files would take me months, and I just don't have the time or patience to do that. I've had the idea of importing files into video editing soft like Premiere and look at the generated waveform to find out good files,  but there's quite a lot of files with codecs unsupported by Premiere, like VP09 and such, so vast majority of files, even with audio present show up as flat lines on Premiere waveform, thus this method is completely useless to me. Like, importing a folder of restored files only generates maybe 20-30 waveforms, the rest are flat lines, and so manual sorting is still required.\n  \n\n    Anyone know of any software that can scan thousands of files and either mark or separate them by presence of audio, or have some other solution?"},
{"Title": "Help getting a 3D model from web model viewer, is it possible?", "Author": "u/ConsistentYou4832", "Content": "I have seen this question asked many times in this subreddit, and this time was my time. I have been scrolling and testing every way I found here but I haven't been able to succeed.\n  \n\n    Could you guys help me on this one I need the model to create a custom body kit for \nthis car"},
{"Title": "How far does your email archive go back to?", "Author": "u/Commercial_Union_296", "Content": "My sent email archive goes back to 2013."},
{"Title": "Adding 2.5 HDD for secondary storage for pc - looking for advice please", "Author": "u/92jwm92", "Content": "No content"},
{"Title": "Im looking to transfer highest quality from Hi-Fi camera for 8mm Tapes.  Which is better: Mini-USB or FireWire?", "Author": "u/Throwaway173638o", "Content": "I have a Sony Hi-Fi camera for 8mm videos that has a FireWire, Mini USB, A/V, and S-video ports.  I want to get the highest quality as possible.  I narrowed down to FireWire or Mini USB transfer for better quality. Which of the two is better overall or are they the same?\n  \n\n    Edit: For context, the camera is a Sony DCR-TRV730 and the tapes are Sony Hi8 MP 8mm Video Cassette.  Cassette also lists it as Digital8 with \"60\" while the Hi8 is listed as \"120\""},
{"Title": "Download Twitter video and tweet", "Author": "u/Ilikegirlandwoman", "Content": "I am looking for a way to download a Twitter video, but also the associated tweet. Like a screenshot but the video plays as well if that's possible."},
{"Title": "Future Data Hoarder!", "Author": "u/allweretakenornot", "Content": "Hello! I long time lurker finally looking to break into data hoarding. My mom is looking to back up around a terabyte of photos and I was considering getting her a storage bay likely in RAID 1 to protect her data. Is there any recommended system? I was looking on Amazon and saw this 5 bay orico enclosure. Are these systems good? Should I try and find a cloud solution for her?\n  \n\n    PS: I read the rules and saw that they recommended tech support. If this post is not in the nature of the subreddit please let me know! Happy hoarding!"},
{"Title": "Does tubeup delete video file after upload?", "Author": "u/elgato123", "Content": "Once tubeup downloads a youtube video and uploads it to \narchive.org\n, does it then delete the file locally? I can see a hard drive getting full fast if not."},
{"Title": "How can I download my entire Google Drive?", "Author": "u/BlackJackT", "Content": "I want to download all the files on Google Drive, zip them and re-upload, and maybe organize a little. What would be the simplest way to perform this?"},
{"Title": "Any Software Recommendations for Folder Sync that Works on Top of Existing OS?", "Author": "u/avattz", "Content": "I almost had a data loss scare yesterday with a Windows machine, luckily I managed to restore it, but this has lead to figuring out a file sync system for my machines in case one has an issue with the boot drive or hardware failure. I currently have a small RAID 1 file server running Samba and while I manually copy files from my computers to this server, I wanted to see if there was software that could automated this.\n  \n\n    The goal is for this software to automatically copy a new completed file placed in the documents folder to a  network drive that is available on the same computer. Literally \"copy this file over there when it exists\". I looked into FreeFileSync and Syncthing but these appear to sync directly to a server instead to a local folder.\n  \n\n    One additional thing I an looking for is two-way syncing. This way, I can make a \"universal\" document folders where all my computers will have the same content, and update them if they are missing anything. This could count as additional backup since I would have the same files over many computers.\n  \n\n    Does anyone have recommendations for a software solution?\n  \n\n    Preferably:\n  \n\n\n\n\n\n    Open source\n  \n\n\n\n\n\n    \"Live\" syncing (runs when new or changed file detected instead of scheduled syncing)\n  \n\n\n\n\n\n    Flexible / Plenty of Options / Configurable\n  \n\n\n\n\n\n    Uses native Windows file commands\n  \n\n\n\n\n\n    Doesn't hurt, but works on Linux (I have \"better\" options for my Linux machines though)\n  \n\n\n\n\n\n    I appreciate any recommendations!\n  \n\n    Edit: I remember SyncToy which would be perfect, if anyone knows of an open source version of SyncToy, then that would be what I am looking for!"},
{"Title": "UPS APC BX1200MI-MS a good choice with no fans?", "Author": "u/maguillo", "Content": "Hello , I am about to buy the APC BX1200MI-MS with 1200VA and 650W (for the price) to back my nas , but the thing is it does not have fans to cool the device like other models , so I dont know if is or not necessary as I dont want the place smell burnt plastic , or how it disipates the heat? Thanks\n  \nhttps://preview.redd.it/ups-apc-bx1200mi-ms-a-good-choice-with-no-fans-v0-xbq80a528l5d1.png\nhttps://preview.redd.it/ups-apc-bx1200mi-ms-a-good-choice-with-no-fans-v0-s5alvwq38l5d1.png"},
{"Title": "Looking For Help Regarding My Leftover Google Drive Issue", "Author": "u/Hibiki_Kenzaki", "Content": "Hi Everyone,\n  \n\n    Hope this post finds you well.\n  \n\n    I just received the following notification from Google Drive that my Google Drive Workspace Enterprise Standard will soon be suspended and all my data will be deleted.\n  \nThe Notice From Google\n\n    To explain my situation, basically like a lot of us on this subreddit, I signed up for Google Drive several years ago by paying $20 a month with only one user and been enjoying the unlimited space until July 2023 when I was hit with a notice claiming my unlimited space is coming to an end.\n  \n\n    Reading the information of this subreddit around a year ago, I thought I have 2 years until the data will be deleted so I did not take any action to transfer my data but simply kept paying the $20 (now $27) every month with my account being in read-only mode until last month when I got hit with this notice as shown in the screenshot. This has made me very nervous and I have started to transfer all my data locally last month.\n  \n\n    Overall, I have around 200 TB of data (the dominant majority of them are Japanese TV programs I have recorded from my TV) and I intend to keep all of them as I have been hoarding these for over a decade and many of them are precious, meaning they are not even available for purchase in commercial settings, i.e., there is no way to get original recording of those TV programs from several years ago or a decade ago even if you offer to pay someone, there is simply no one who is selling, not even the TV stations.\n  \n\n    I already purchased 30 Seagate 8TB HDDs so there is no issue with the local storage problem for me. However, the issue is that after all 200 TB is 200 TB, and there is no way for me to download 200 TB in one month. Currently, I am using my company's Ethernet to download those data but as we all know HDD's written speed is limited to 60 megabytes per second, the physical limit means I could transfer at maximum 5 TB per day even if my Ethernet speed exceeds 60 megabytes per second. Based on my real test, I can currently pull around 3 to 4 TB per day from my Google Drive account. However, this is not gonna be enough as my account will be suspended on June 22, 2024. Before then, I could at most pull around 75 to 80 TB from my Google Drive account.\n  \n\n    Therefore, I am here trying to seek fellow datahoarders' wisdom here. Personally I have come up with the following solutions, could anyone help me assess how viable they are, or if better, is there any possibility that someone knows an even better solution than any of the ones I came up with on my own?\n  \n\n\nSolution 1:\n\n\n\n    Contact Google Workspace support and ask for extension of suspension. I am wondering whether it is possible to simply contact Google Workspace support and ask for mercy so that I could just delay the suspension of my account for 2 months. As you know, I can pull around 3 TB of data per day so that so long as I have around 60-70 days, I would be able to download all of my data from my Google Drive. Is this a viable solution? Would Google be flexible enough to agree to this with me only continuing to pay $27 per month?\n  \n\n    Additionally, I found it impossible to directly contact Google with regard to this. When I click the help button in the Admin Console as shown below, I am always directed to a chatbot but am unable to talk to a real human being. Does anyone know how I could directly reach out to a Google personnel and ask for extension?\n  \nAdmin Console\n\n\nSolution 2:\n\n\n\n    Simply adding more users on a temporary basis. I heard some rumors saying that when you have 5 users (currently I only have one) in your Google Workspace, you are kind of treated differently. While I know there is no way that by having 5 users I would be granted 200 TB space, all I need is to stop the imminent deletion of my data. If adding to 5 users can grant me some status and put a stop to the suspension, I could just afford to pay 5-user fee for 2 more months and transfer all my data locally and then I could just cancel them altogether and say goodbye to Google. Does anyone know whether this approach would work? As the notice from Google claimed that \"If you take no action your account will be suspended.\", I am wondering whether adding to 5 users would count as \"some action\" and at least stop the imminent deletion of all my data on June 22, 2024...\n  \n\n    Thank you very much for your help, I really appreicate it.\n  \n\n    Best,\n  \n\n    Hibiki"},
{"Title": "Planning on storing txt, xlsx, and MKV files. It seems like Flash-Drives/Micro SD's aren't reliable, what is a good alternative?", "Author": "u/Sasutaschi", "Content": "So far I've mostly stored Data on the aforementioned methods, but browsing this Sub, it seems like a SSD + Enclosure would be the best way to go.\n  \n\n    This Enclosure was recommended.\n  \n\n\nhttps://www.amazon.com/ineo-Aluminum-External-Enclosure-C2594-NVME/dp/B07MZQF1H6\n\n\n\n    For a SSD, I was thinking about the Samsung EVO 980.\n  \n\n    Are there better alternatives?\n  \n\n    Finally, would it be possible to watch MKV files, if plugged into a TV/PS4 from the enclosure? Will there be a delay?\n  \n\n    Thx. for the advice and have a nice day."},
{"Title": "Which type of external backup drives/systems should I get and use?", "Author": "u/BrinkleyPT", "Content": "Hi.\n  \n\n    I'm building a new PC with 1TB SSD nVME.\n  \n\n    What should I get for backup that's reliable?\n  \n\n    And if I get something how often should I replace the drive to ensure I don't lose data?\n  \n\n    Still trying to figure out what's the best method of image and file backup and what to buy and use, but also replace and when to replace it in order to avoid losing data.\n  \n\n    Thanks 👍"},
{"Title": "Need some help sanity checking my UnRAID 'Reamalgamation' project, specifically Disk Shelves", "Author": "u/AshleyUncia", "Content": "So here's the situation; I currently live with my spouse in a one bedroom apartment built in 1922.  For this reason there are some real issues with the loads on the electrical circuits between my network storage, gaming PC, HTPCs and so on.  Plus just 'physical space' and noise limitations.\n  \n\n    As such, when my 16 drive UnRAID server ran out of drive slots, the only solution was to build a second server which is in the Livingroom, in a 4U Rosewill case, sitting discretely in an Ikea Lack table with caster wheels.  The main server has a Ryzen 9 3950X and does all the dockers and stuff.  The secondary server has an Intel E5 2697v2 and sits there eating electricity for the sake of letting me run 12 more drives.\n  \n\n    But we're moving!  Three floors!  Gonna run ethernet in all the walls.  There will be a finished basement area for 'the gaming goodness' and I can finally set up network and storage in a real rack, on the unfinished side of the basement, with it's own 15amp circuit and where no one will care how much noise anything in there makes.  That means I an get disk shelf and make all of this way less stupid!\n  \n\n    The main plan is to retire the server inside the 4U rack case, then transplant the main tower server into that 4U rack case and expand it's drive capacity with a disk shelf.  So here's where I have questions:\n  \n\n    Firstly, things like the NetApp DS4246 and related seem to be what I'm looking at.  All my drives are SATA, to these disk shelves support SATA out of the box, is additional hardware required for SATA drives, or do I need to look for something alternate/specific?\n  \n\n    Secondly, these shelves offer up to four PSUs for redundancy, but how many are needed at minimum assuming 'up time' is not a major concern?  Also what kind of power consumption should I see beyond the drives it's powering?  I should def see an advantage over a whole 11 year old Xeon running, right?\n  \n\n    Thirdly, for the 'host server' to access this kind of disk shelf, I should only require something like an LSI 9201-16E and a quartet of 8088 to SFF-8088 cables, right?  From there on, the host device should just have an LSI controller which see's up to 24 drives on it, and it's all happy and 'just works'?"},
{"Title": "Is it worth archiving random pages aimlessly?", "Author": "u/peliciego", "Content": "Hi folks. I wonder if it is worth using the \"wayback machine\" and \"archive.ph\" addons for archiving random websites when you are navigating across the internet.\n  \n\n    Sometimes I focus on old websites (*index.html or other dork commands). Other times, it is local news in my surroundings. And from time to time, websites in minority languages. I don't save locally in large quantities. Do you think this strategy is worth it?\n  \n\n    Sometimes it is like planting a forest. You may never see the results in 100 years."},
{"Title": "Does anyone have a used harddrive to give for free?", "Author": "u/Alexander_Alexis", "Content": "Hello, i need to put emergently  my phone photos to my pc but my pc is full(200gb ssd) And i dont have moneys or a place near to buy a hard drive, does anyone have a very used hard drive? i need one only for the photos so not running games or big stuff like that"},
{"Title": "SAS Expander with SATA power?", "Author": "u/emanknugsaeman", "Content": ""},
{"Title": "Question about Macrium's compression", "Author": "u/Revolutionary_Cod672", "Content": "Hi all,\n  \n\n    I've got a 12TB home server and I'm trying to use Macrium Reflect to run backups. In an effort to cut costs, I'm trying to backup onto smaller external HDs. I've got one media library that's about 6TB that I'm trying to put onto a drive that's got an actual capacity of 4.5TB, I'm trying to rely on compression to make that work.\n  \n\n    The issue is that I've tried with both medium and high compression but the backup always fails due to insufficient space. Does the compression happen after the backup takes place? Or am I doing something wrong?\n  \n\n    Wasn't sure if I needed to have 6TB of space available initially, then it does some compression afterwards.\n  \n\n    Thanks in advance."},
{"Title": "Questions about File Integrity when and after transferring files", "Author": "u/gpspam", "Content": "Hello everyone, I'm a bit new to true data hoarding and I had made what is probably considered rookie mistakes.\n  \n\n    Some backstory: I had an unfortunate ssd failure which cost me about $1000 to recover the files. After some research I've decided to set up a NAS w/ RAID1 (and other back up methods). Now I have some questions to help me transition/transfer/migration from my old external hdd setup to my NAS solution.\n  \n\n    My first question mainly revolves around keeping file integrity when transferring files. What programs are best at doing this? I've done some research and I've currently chosen TeraCopy. It looks pretty good; other posts have suggested stuff like Robocopy but I couldn't find/get it to work (maybe it's command line stuff that, though I admittedly didn't look too hard since I don't trust inbuilt windows stuff that much). How good is TeraCopy and its file integrity verification?\n  \n\n    My second question is about checking files for corruption, mainly videos. This one is a bit of a shot in the dark, a hail mary hope of mine that I can fix this headache inducing rookie mistake of mine. Long story short, I had to reinitialize my NAS due to changing its setup. When doing this, I copied data I had on the NAS to a ext HDD (no verification done, I now know it was a stupid rookie mistake) totaling approx 3.5 TB of data, mainly video files (probably around 1k hours). Now I found at least 1 of them has a bit of corruption, where about 20 seconds got messed up. Is there a way or program that can find these kind of problems with files? I'm guessing probably not, but if there are potential solutions I'd love to find them. Otherwise, I guess those errors/problems will just exist and years later I'll find out and lament that if I knew years ago I could have replaced those files but not when I do.\n  \n\n    Thanks for your help and I'll reply if I have any follow up questions."},
{"Title": "What's your guys system for archiving entire youtube channels look like?", "Author": "u/glowcialist", "Content": "I tried TubeArchivist, and it worked great for maybe 500 vids, but now seems to be completely blocked, I'm assuming that any script utilizing yt-dlp would face similar issues?\n  \n\n    4k tube seemed to work alright for individual playlists at first, but now seems to be consistently throttled to like 50 kb/s.\n  \n\n    Any ideas?\n  \n\n    Edit: Please forgive the missing apostrophe in the title. I won't do it again."},
{"Title": "Transcode Settings and Workflows for Archiving Video Game Clips", "Author": "u/HalluxTheGreat", "Content": "Looking for advice on how to compress some of the gameplay videos I make in some video games. I typically record in 3440 x 1440 30fps with a bitrate of 10000-15000 kbps. And at the end of the day or week I use handbrake to cut the size to about half. A lot of my clips arent for posting to streams but to just compare my early gameplay with myself later on to see how I changed with 0 hours in a game vs 100 or even 1000, or to just capture the moment when playing with friends.\n  \n\n    Does anyone have any workflows in capturing their own gameplay and storing it? Naming schemes, settings, scripts, etc...\n  \n\n    I've been looking at alternatives such as Shutter encoder as well."},
{"Title": "irc.hackint.org", "Author": "u/GuillermoBotonio", "Content": "Anyone know why I would suddenly not be able to access irc.hackint.org? I was able to go on there for about 3 days then its not loading. The guy I talked to from the page says the server is loading for him. I can get on Hackint.org ok but not the IRC."},
{"Title": "TrackTalk.net, one of the biggest athletics forums of its time, on the verge of shutting down - Looking for a way to back it up.", "Author": "u/xd-Drewski13", "Content": "I'm somewhat of a fan of track and field fan and this was one of my favorite sites to go on back in the day. It seems that the owner is unsure if he can keep it up and is running out of time/energy to maintain it. I was wondering if there would be a simple way to back it up.\n  \n\n    It contains thousands of threads about information that would mostly be lost to time if it were to disappear.\n  \n\n    I have a fairly large server for movies and shows but don't have to experience scraping and hoarding data like this. Any ideas? I know this site is a certain type of forum template, but I don't know which one it is or the best way to go about this."},
{"Title": "Recovering webms and other video file formats (using R-Linux, or a recommended alternative)", "Author": "u/burning_torch", "Content": "I formatted a drive full of videos by accident on my Ubuntu 22.04 computer. Stupid me. It was a full format, not a quick format, but I stopped it only a second or two after it had started. I ran testdisk to check the damages and try to recover the files; it didn't really work all too well. I tried to run photorec, but the software is unusable - my input was randomized and would constantly change if it even accepted input at all; this wasn't a mapping issue, as the right arrow key would act as arrow up, enter, arrow down, or any other random input at any given time. Either way, I eventually found and ran R-Studio's R-Linux, which seemed to work fine, if a little unintuitive. I ran the software and seemingly recovered a lot of files; among others, I recovered a lot of mp4 files. This was expected, as the drive was filled almost exclusively with videos. However, R-Linux does not have built in capabilities to recover webms or other video file formats like qt, and I know there were a great deal of those files on the drive. Does anyone know of any good ways to recover those files as well?\n  \n\n    I know R-Linux has the ability to add custom file types by building an xml file for that type. I wouldn't know where to begin on getting the information for such a file, but does anyone have one that would work for the not included video file types (webm, qt, etc.)? Or does anyone know of a software that has the ability to recover those files?"},
{"Title": "Does anyone use serverpartdeal drives as their main drives in a nas?", "Author": "u/DGU_kibb", "Content": "I'm planning my next NAS. Definitely going for an array of larger capacity drives. I bought new drives for my last build, but im going to have to buy several 12tb drives for my next one.\n  \n\n    I know if you have backups then it doesn't really matter (and I do have backups) but I'm curious, i know serverpartdeals is reputable around here, but are people using these in their main nas? Or are you using them purely as backups/cold storage or for unimportant data at the most?"},
{"Title": "My favorite hard drive tracker + when will 30+ TB drives hit retail?", "Author": "u/chuckremes", "Content": "I will share some information and then ask a question too.\n  \n\n    I like this site for tracking hard drive prices. Last September I bought a bunch of 16 TB drives for $10.6 per terabyte and then I saw the price go as low as $9.40. For the 16+ TB sizes it's now been hovering at around $14/TB for months. Very concerning.\n  \n\n\nhttps://diskprices.com/?locale=us&condition=new&disk_types=external_hdd,internal_hdd,external_ssd,internal_ssd\n\n\n\n    So when can we expect to see those 30+ TB drives hit retail? The older articles I read all indicated 2024Q1 but we're about to exit 2024Q2 and I still haven't seen any. What's the latest buzz?"},
{"Title": "Anyway to grab the name of a mega folder in the terminal? Megatools doesnt preserve the folder name", "Author": "u/NotAnADC", "Content": "Thank you for any help! Been trying to download mega files but hate that I can't save the folder names"},
{"Title": "Adding 2.5 HDD for secondary storage for pc - looking for advice please", "Author": "u/92jwm92", "Content": "No content"},
{"Title": "Im looking to transfer highest quality from Hi-Fi camera for 8mm Tapes.  Which is better: Mini-USB or FireWire?", "Author": "u/Throwaway173638o", "Content": "I have a Sony Hi-Fi camera for 8mm videos that has a FireWire, Mini USB, A/V, and S-video ports.  I want to get the highest quality as possible.  I narrowed down to FireWire or Mini USB transfer for better quality. Which of the two is better overall or are they the same?\n  \n\n    Edit: For context, the camera is a Sony DCR-TRV730 and the tapes are Sony Hi8 MP 8mm Video Cassette.  Cassette also lists it as Digital8 with \"60\" while the Hi8 is listed as \"120\""},
{"Title": "Download Twitter video and tweet", "Author": "u/Ilikegirlandwoman", "Content": "I am looking for a way to download a Twitter video, but also the associated tweet. Like a screenshot but the video plays as well if that's possible."},
{"Title": "Future Data Hoarder!", "Author": "u/allweretakenornot", "Content": "Hello! I long time lurker finally looking to break into data hoarding. My mom is looking to back up around a terabyte of photos and I was considering getting her a storage bay likely in RAID 1 to protect her data. Is there any recommended system? I was looking on Amazon and saw this 5 bay orico enclosure. Are these systems good? Should I try and find a cloud solution for her?\n  \n\n    PS: I read the rules and saw that they recommended tech support. If this post is not in the nature of the subreddit please let me know! Happy hoarding!"},
{"Title": "Does tubeup delete video file after upload?", "Author": "u/elgato123", "Content": "Once tubeup downloads a youtube video and uploads it to \narchive.org\n, does it then delete the file locally? I can see a hard drive getting full fast if not."},
{"Title": "How can I download my entire Google Drive?", "Author": "u/BlackJackT", "Content": "I want to download all the files on Google Drive, zip them and re-upload, and maybe organize a little. What would be the simplest way to perform this?"},
{"Title": "Any Software Recommendations for Folder Sync that Works on Top of Existing OS?", "Author": "u/avattz", "Content": "I almost had a data loss scare yesterday with a Windows machine, luckily I managed to restore it, but this has lead to figuring out a file sync system for my machines in case one has an issue with the boot drive or hardware failure. I currently have a small RAID 1 file server running Samba and while I manually copy files from my computers to this server, I wanted to see if there was software that could automated this.\n  \n\n    The goal is for this software to automatically copy a new completed file placed in the documents folder to a  network drive that is available on the same computer. Literally \"copy this file over there when it exists\". I looked into FreeFileSync and Syncthing but these appear to sync directly to a server instead to a local folder.\n  \n\n    One additional thing I an looking for is two-way syncing. This way, I can make a \"universal\" document folders where all my computers will have the same content, and update them if they are missing anything. This could count as additional backup since I would have the same files over many computers.\n  \n\n    Does anyone have recommendations for a software solution?\n  \n\n    Preferably:\n  \n\n\n\n\n\n    Open source\n  \n\n\n\n\n\n    \"Live\" syncing (runs when new or changed file detected instead of scheduled syncing)\n  \n\n\n\n\n\n    Flexible / Plenty of Options / Configurable\n  \n\n\n\n\n\n    Uses native Windows file commands\n  \n\n\n\n\n\n    Doesn't hurt, but works on Linux (I have \"better\" options for my Linux machines though)\n  \n\n\n\n\n\n    I appreciate any recommendations!\n  \n\n    Edit: I remember SyncToy which would be perfect, if anyone knows of an open source version of SyncToy, then that would be what I am looking for!"},
{"Title": "UPS APC BX1200MI-MS a good choice with no fans?", "Author": "u/maguillo", "Content": "Hello , I am about to buy the APC BX1200MI-MS with 1200VA and 650W (for the price) to back my nas , but the thing is it does not have fans to cool the device like other models , so I dont know if is or not necessary as I dont want the place smell burnt plastic , or how it disipates the heat? Thanks\n  \nhttps://preview.redd.it/ups-apc-bx1200mi-ms-a-good-choice-with-no-fans-v0-xbq80a528l5d1.png\nhttps://preview.redd.it/ups-apc-bx1200mi-ms-a-good-choice-with-no-fans-v0-s5alvwq38l5d1.png"},
{"Title": "Looking For Help Regarding My Leftover Google Drive Issue", "Author": "u/Hibiki_Kenzaki", "Content": "Hi Everyone,\n  \n\n    Hope this post finds you well.\n  \n\n    I just received the following notification from Google Drive that my Google Drive Workspace Enterprise Standard will soon be suspended and all my data will be deleted.\n  \nThe Notice From Google\n\n    To explain my situation, basically like a lot of us on this subreddit, I signed up for Google Drive several years ago by paying $20 a month with only one user and been enjoying the unlimited space until July 2023 when I was hit with a notice claiming my unlimited space is coming to an end.\n  \n\n    Reading the information of this subreddit around a year ago, I thought I have 2 years until the data will be deleted so I did not take any action to transfer my data but simply kept paying the $20 (now $27) every month with my account being in read-only mode until last month when I got hit with this notice as shown in the screenshot. This has made me very nervous and I have started to transfer all my data locally last month.\n  \n\n    Overall, I have around 200 TB of data (the dominant majority of them are Japanese TV programs I have recorded from my TV) and I intend to keep all of them as I have been hoarding these for over a decade and many of them are precious, meaning they are not even available for purchase in commercial settings, i.e., there is no way to get original recording of those TV programs from several years ago or a decade ago even if you offer to pay someone, there is simply no one who is selling, not even the TV stations.\n  \n\n    I already purchased 30 Seagate 8TB HDDs so there is no issue with the local storage problem for me. However, the issue is that after all 200 TB is 200 TB, and there is no way for me to download 200 TB in one month. Currently, I am using my company's Ethernet to download those data but as we all know HDD's written speed is limited to 60 megabytes per second, the physical limit means I could transfer at maximum 5 TB per day even if my Ethernet speed exceeds 60 megabytes per second. Based on my real test, I can currently pull around 3 to 4 TB per day from my Google Drive account. However, this is not gonna be enough as my account will be suspended on June 22, 2024. Before then, I could at most pull around 75 to 80 TB from my Google Drive account.\n  \n\n    Therefore, I am here trying to seek fellow datahoarders' wisdom here. Personally I have come up with the following solutions, could anyone help me assess how viable they are, or if better, is there any possibility that someone knows an even better solution than any of the ones I came up with on my own?\n  \n\n\nSolution 1:\n\n\n\n    Contact Google Workspace support and ask for extension of suspension. I am wondering whether it is possible to simply contact Google Workspace support and ask for mercy so that I could just delay the suspension of my account for 2 months. As you know, I can pull around 3 TB of data per day so that so long as I have around 60-70 days, I would be able to download all of my data from my Google Drive. Is this a viable solution? Would Google be flexible enough to agree to this with me only continuing to pay $27 per month?\n  \n\n    Additionally, I found it impossible to directly contact Google with regard to this. When I click the help button in the Admin Console as shown below, I am always directed to a chatbot but am unable to talk to a real human being. Does anyone know how I could directly reach out to a Google personnel and ask for extension?\n  \nAdmin Console\n\n\nSolution 2:\n\n\n\n    Simply adding more users on a temporary basis. I heard some rumors saying that when you have 5 users (currently I only have one) in your Google Workspace, you are kind of treated differently. While I know there is no way that by having 5 users I would be granted 200 TB space, all I need is to stop the imminent deletion of my data. If adding to 5 users can grant me some status and put a stop to the suspension, I could just afford to pay 5-user fee for 2 more months and transfer all my data locally and then I could just cancel them altogether and say goodbye to Google. Does anyone know whether this approach would work? As the notice from Google claimed that \"If you take no action your account will be suspended.\", I am wondering whether adding to 5 users would count as \"some action\" and at least stop the imminent deletion of all my data on June 22, 2024...\n  \n\n    Thank you very much for your help, I really appreicate it.\n  \n\n    Best,\n  \n\n    Hibiki"},
{"Title": "Planning on storing txt, xlsx, and MKV files. It seems like Flash-Drives/Micro SD's aren't reliable, what is a good alternative?", "Author": "u/Sasutaschi", "Content": "So far I've mostly stored Data on the aforementioned methods, but browsing this Sub, it seems like a SSD + Enclosure would be the best way to go.\n  \n\n    This Enclosure was recommended.\n  \n\n\nhttps://www.amazon.com/ineo-Aluminum-External-Enclosure-C2594-NVME/dp/B07MZQF1H6\n\n\n\n    For a SSD, I was thinking about the Samsung EVO 980.\n  \n\n    Are there better alternatives?\n  \n\n    Finally, would it be possible to watch MKV files, if plugged into a TV/PS4 from the enclosure? Will there be a delay?\n  \n\n    Thx. for the advice and have a nice day."},
{"Title": "Which type of external backup drives/systems should I get and use?", "Author": "u/BrinkleyPT", "Content": "Hi.\n  \n\n    I'm building a new PC with 1TB SSD nVME.\n  \n\n    What should I get for backup that's reliable?\n  \n\n    And if I get something how often should I replace the drive to ensure I don't lose data?\n  \n\n    Still trying to figure out what's the best method of image and file backup and what to buy and use, but also replace and when to replace it in order to avoid losing data.\n  \n\n    Thanks 👍"},
{"Title": "Need some help sanity checking my UnRAID 'Reamalgamation' project, specifically Disk Shelves", "Author": "u/AshleyUncia", "Content": "So here's the situation; I currently live with my spouse in a one bedroom apartment built in 1922.  For this reason there are some real issues with the loads on the electrical circuits between my network storage, gaming PC, HTPCs and so on.  Plus just 'physical space' and noise limitations.\n  \n\n    As such, when my 16 drive UnRAID server ran out of drive slots, the only solution was to build a second server which is in the Livingroom, in a 4U Rosewill case, sitting discretely in an Ikea Lack table with caster wheels.  The main server has a Ryzen 9 3950X and does all the dockers and stuff.  The secondary server has an Intel E5 2697v2 and sits there eating electricity for the sake of letting me run 12 more drives.\n  \n\n    But we're moving!  Three floors!  Gonna run ethernet in all the walls.  There will be a finished basement area for 'the gaming goodness' and I can finally set up network and storage in a real rack, on the unfinished side of the basement, with it's own 15amp circuit and where no one will care how much noise anything in there makes.  That means I an get disk shelf and make all of this way less stupid!\n  \n\n    The main plan is to retire the server inside the 4U rack case, then transplant the main tower server into that 4U rack case and expand it's drive capacity with a disk shelf.  So here's where I have questions:\n  \n\n    Firstly, things like the NetApp DS4246 and related seem to be what I'm looking at.  All my drives are SATA, to these disk shelves support SATA out of the box, is additional hardware required for SATA drives, or do I need to look for something alternate/specific?\n  \n\n    Secondly, these shelves offer up to four PSUs for redundancy, but how many are needed at minimum assuming 'up time' is not a major concern?  Also what kind of power consumption should I see beyond the drives it's powering?  I should def see an advantage over a whole 11 year old Xeon running, right?\n  \n\n    Thirdly, for the 'host server' to access this kind of disk shelf, I should only require something like an LSI 9201-16E and a quartet of 8088 to SFF-8088 cables, right?  From there on, the host device should just have an LSI controller which see's up to 24 drives on it, and it's all happy and 'just works'?"},
{"Title": "Is it worth archiving random pages aimlessly?", "Author": "u/peliciego", "Content": "Hi folks. I wonder if it is worth using the \"wayback machine\" and \"archive.ph\" addons for archiving random websites when you are navigating across the internet.\n  \n\n    Sometimes I focus on old websites (*index.html or other dork commands). Other times, it is local news in my surroundings. And from time to time, websites in minority languages. I don't save locally in large quantities. Do you think this strategy is worth it?\n  \n\n    Sometimes it is like planting a forest. You may never see the results in 100 years."},
{"Title": "Does anyone have a used harddrive to give for free?", "Author": "u/Alexander_Alexis", "Content": "Hello, i need to put emergently  my phone photos to my pc but my pc is full(200gb ssd) And i dont have moneys or a place near to buy a hard drive, does anyone have a very used hard drive? i need one only for the photos so not running games or big stuff like that"},
{"Title": "SAS Expander with SATA power?", "Author": "u/emanknugsaeman", "Content": ""},
{"Title": "Question about Macrium's compression", "Author": "u/Revolutionary_Cod672", "Content": "Hi all,\n  \n\n    I've got a 12TB home server and I'm trying to use Macrium Reflect to run backups. In an effort to cut costs, I'm trying to backup onto smaller external HDs. I've got one media library that's about 6TB that I'm trying to put onto a drive that's got an actual capacity of 4.5TB, I'm trying to rely on compression to make that work.\n  \n\n    The issue is that I've tried with both medium and high compression but the backup always fails due to insufficient space. Does the compression happen after the backup takes place? Or am I doing something wrong?\n  \n\n    Wasn't sure if I needed to have 6TB of space available initially, then it does some compression afterwards.\n  \n\n    Thanks in advance."},
{"Title": "Questions about File Integrity when and after transferring files", "Author": "u/gpspam", "Content": "Hello everyone, I'm a bit new to true data hoarding and I had made what is probably considered rookie mistakes.\n  \n\n    Some backstory: I had an unfortunate ssd failure which cost me about $1000 to recover the files. After some research I've decided to set up a NAS w/ RAID1 (and other back up methods). Now I have some questions to help me transition/transfer/migration from my old external hdd setup to my NAS solution.\n  \n\n    My first question mainly revolves around keeping file integrity when transferring files. What programs are best at doing this? I've done some research and I've currently chosen TeraCopy. It looks pretty good; other posts have suggested stuff like Robocopy but I couldn't find/get it to work (maybe it's command line stuff that, though I admittedly didn't look too hard since I don't trust inbuilt windows stuff that much). How good is TeraCopy and its file integrity verification?\n  \n\n    My second question is about checking files for corruption, mainly videos. This one is a bit of a shot in the dark, a hail mary hope of mine that I can fix this headache inducing rookie mistake of mine. Long story short, I had to reinitialize my NAS due to changing its setup. When doing this, I copied data I had on the NAS to a ext HDD (no verification done, I now know it was a stupid rookie mistake) totaling approx 3.5 TB of data, mainly video files (probably around 1k hours). Now I found at least 1 of them has a bit of corruption, where about 20 seconds got messed up. Is there a way or program that can find these kind of problems with files? I'm guessing probably not, but if there are potential solutions I'd love to find them. Otherwise, I guess those errors/problems will just exist and years later I'll find out and lament that if I knew years ago I could have replaced those files but not when I do.\n  \n\n    Thanks for your help and I'll reply if I have any follow up questions."},
{"Title": "What's your guys system for archiving entire youtube channels look like?", "Author": "u/glowcialist", "Content": "I tried TubeArchivist, and it worked great for maybe 500 vids, but now seems to be completely blocked, I'm assuming that any script utilizing yt-dlp would face similar issues?\n  \n\n    4k tube seemed to work alright for individual playlists at first, but now seems to be consistently throttled to like 50 kb/s.\n  \n\n    Any ideas?\n  \n\n    Edit: Please forgive the missing apostrophe in the title. I won't do it again."},
{"Title": "Transcode Settings and Workflows for Archiving Video Game Clips", "Author": "u/HalluxTheGreat", "Content": "Looking for advice on how to compress some of the gameplay videos I make in some video games. I typically record in 3440 x 1440 30fps with a bitrate of 10000-15000 kbps. And at the end of the day or week I use handbrake to cut the size to about half. A lot of my clips arent for posting to streams but to just compare my early gameplay with myself later on to see how I changed with 0 hours in a game vs 100 or even 1000, or to just capture the moment when playing with friends.\n  \n\n    Does anyone have any workflows in capturing their own gameplay and storing it? Naming schemes, settings, scripts, etc...\n  \n\n    I've been looking at alternatives such as Shutter encoder as well."},
{"Title": "irc.hackint.org", "Author": "u/GuillermoBotonio", "Content": "Anyone know why I would suddenly not be able to access irc.hackint.org? I was able to go on there for about 3 days then its not loading. The guy I talked to from the page says the server is loading for him. I can get on Hackint.org ok but not the IRC."},
{"Title": "TrackTalk.net, one of the biggest athletics forums of its time, on the verge of shutting down - Looking for a way to back it up.", "Author": "u/xd-Drewski13", "Content": "I'm somewhat of a fan of track and field fan and this was one of my favorite sites to go on back in the day. It seems that the owner is unsure if he can keep it up and is running out of time/energy to maintain it. I was wondering if there would be a simple way to back it up.\n  \n\n    It contains thousands of threads about information that would mostly be lost to time if it were to disappear.\n  \n\n    I have a fairly large server for movies and shows but don't have to experience scraping and hoarding data like this. Any ideas? I know this site is a certain type of forum template, but I don't know which one it is or the best way to go about this."},
{"Title": "Recovering webms and other video file formats (using R-Linux, or a recommended alternative)", "Author": "u/burning_torch", "Content": "I formatted a drive full of videos by accident on my Ubuntu 22.04 computer. Stupid me. It was a full format, not a quick format, but I stopped it only a second or two after it had started. I ran testdisk to check the damages and try to recover the files; it didn't really work all too well. I tried to run photorec, but the software is unusable - my input was randomized and would constantly change if it even accepted input at all; this wasn't a mapping issue, as the right arrow key would act as arrow up, enter, arrow down, or any other random input at any given time. Either way, I eventually found and ran R-Studio's R-Linux, which seemed to work fine, if a little unintuitive. I ran the software and seemingly recovered a lot of files; among others, I recovered a lot of mp4 files. This was expected, as the drive was filled almost exclusively with videos. However, R-Linux does not have built in capabilities to recover webms or other video file formats like qt, and I know there were a great deal of those files on the drive. Does anyone know of any good ways to recover those files as well?\n  \n\n    I know R-Linux has the ability to add custom file types by building an xml file for that type. I wouldn't know where to begin on getting the information for such a file, but does anyone have one that would work for the not included video file types (webm, qt, etc.)? Or does anyone know of a software that has the ability to recover those files?"},
{"Title": "Does anyone use serverpartdeal drives as their main drives in a nas?", "Author": "u/DGU_kibb", "Content": "I'm planning my next NAS. Definitely going for an array of larger capacity drives. I bought new drives for my last build, but im going to have to buy several 12tb drives for my next one.\n  \n\n    I know if you have backups then it doesn't really matter (and I do have backups) but I'm curious, i know serverpartdeals is reputable around here, but are people using these in their main nas? Or are you using them purely as backups/cold storage or for unimportant data at the most?"},
{"Title": "My favorite hard drive tracker + when will 30+ TB drives hit retail?", "Author": "u/chuckremes", "Content": "I will share some information and then ask a question too.\n  \n\n    I like this site for tracking hard drive prices. Last September I bought a bunch of 16 TB drives for $10.6 per terabyte and then I saw the price go as low as $9.40. For the 16+ TB sizes it's now been hovering at around $14/TB for months. Very concerning.\n  \n\n\nhttps://diskprices.com/?locale=us&condition=new&disk_types=external_hdd,internal_hdd,external_ssd,internal_ssd\n\n\n\n    So when can we expect to see those 30+ TB drives hit retail? The older articles I read all indicated 2024Q1 but we're about to exit 2024Q2 and I still haven't seen any. What's the latest buzz?"},
{"Title": "Anyway to grab the name of a mega folder in the terminal? Megatools doesnt preserve the folder name", "Author": "u/NotAnADC", "Content": "Thank you for any help! Been trying to download mega files but hate that I can't save the folder names"},
{"Title": "Is it good practice to leave free space on Optical Disks?", "Author": "u/finbarrgalloway", "Content": "I know for hard disk storage they often tell you to leave 1/3 to 1/4 free to not stress the drive, but does this hold true for a DVD? Or can I fill them up to my hearts content?"},
{"Title": "Where to buy the cheapest reliable Renewed 16+ TB Hard drives for NAS?", "Author": "u/Charbax", "Content": "Hi! Recently by searching on Amazon US \nhttps://www.amazon.com/s?k=renewed+16TB\n I discovered that there's a whole world of \nrenewed hard drives\n sold at perhaps around half of the price of new per same amount of TB!! Woah! 16TB starts at $139!\n  \n\n    I used to buy so many external (I have a bunch of 8TBs) Seagate (probably all are \nshingled magnetic recording\n based?) USB3 hard drives, but these renewed Enterprise hard drives seem so much better performing, way cheaper than even cheapest USB3 externals, and I would hope all decently usable to build a future NAS I am envisioning.. !!\n  \n\n    Here are some places that sell these renewed hard drives as I have found:\n  \n\n\nhttps://serverpartdeals.com/\n (they seem to have 2-year warranty WD Ultrastar and etc) with $40 worldwide shipping (free 2-day shipping in the USA)\n  \n\n\nhttps://www.goharddrive.com/category-s/293.htm\n (under this renewed HDD brand \"MaxDigitalData\" which can also be found on Amazon US)\n  \n\n    Some Ebay sellers such as these:\n  \n\n\nhttps://www.ebay.com/str/eastdigital\n out of Hong Kong with free shipping worldwide or $20 expedited worldwide shipping\n  \n\n\nhttps://www.ebay.com/str/goharddrivewholesaleandretail\n (perhaps they have more or different drives on their ebay than on their website?)\n  \n\n\nhttps://www.ebay.com/str/dbskyusa88\n\n\n\n    Which of these or other sellers have you tried and can you recommend? As many of them seem to say they provide 2-year, 3-year even 5-year \"Warranty from the Reseller\", one might want to buy from a reseller that seems to have many reviews and a longer history to hopefully still be around if one or other of these hard drives stop working within the 2, 3 or 5-year warranty..\n  \n\n    Although it might sound scary to buy a hard drive that might have already run 26 thousand hours or more (if it has already run for 3 years or so constantly in these data centers), coming out of a cloud storage provider who for one reason or other needs to sell or to replace their storage drives periodically, I would think:\n  \n\n\n\n\n\n    That these renewed hard drives might have actually been tested way more than new hard drives, and since the resellers test them before selling them, it means they're probably still fine, so who knows, they might have a better chance of lasting a further many years compared with buying a new hard drive off the market? Especially since my future NAS or just USB enclosure backup usage would be much less heavy in usage compared with the usage they've had in the datacenters until being sold for renewed.\n  \n\n\n\n\n\n    I go to check Backblaze's Hard drive tests \nhttps://www.backblaze.com/cloud-storage/resources/hard-drive-test-data\n and I simply try to order those same exact hard drive model numbers that have the best reliability according to Backblaze!\n  \n\n\n\n\n\n    Hard drive manufacturers (WD Ultrastar?) advertise something like 2.5 million hours of usage before an expected failure, so if they've run for about 25'000 hours in some datacenters for 3 years constantly somewhere, that's only 1% of the advertised lifetime?\n  \n\n\n\n\n\n    Once I get my 5-bay or 6-bay or 8-bay NAS up and running (still I don't know which one I will aim for, I am looking through second hand markets periodically), I would think, it shouldn't be a problem just swapping out any failed hard drive if that happens eventually (if still within warranty or after warranty expired), and considering Renewed hard drives are sold at half the price of new! If I eventually have 10% of my renewed hard drives fail (sooner than new hard drives fail, which I am unsure if one should expect), it might still be 2x cheaper per TB than buying all these hard drives as new!"},
{"Title": "Starting data hording journey", "Author": "u/nlj1978", "Content": "After the help I got here on ripping my cd collection I'm jumping in the deep end. I'm putting together a media server. Have a HP z1 G5 tower workstation with i5-9500 on the way but still have decisions to make in terms of hardware and software.\n  \n\n    I'm finding mixed data on ECC ram support. Apparently the motherboards come in a couple variations. Once I confirm I believe I believe ECC is a better choice for this application. Still need to verify but I believe the board supports either 64 or 128gig.  That said how much ram should I use?\n  \n\n    Mobo has 2 m2 slots and 4 sata ports. Computer comes with a 256g nvme. I've read a little about using m2 Intel Optane drives for improved server performance. Anyone have any experience or input on this?\n  \n\n    Drives I'm still pondering.\n  \n\n    On the software side I am leaning towards TrueNas and  Jellyfin. Both seem relatively user friendly to someone with limited server knowledge. Thoughts?"},
{"Title": "New to Data hoarding", "Author": "u/Rio-Chevalier", "Content": "So I'm currently trying to back up my old DVD and blue ray collection digitally,  (and admittedly I'm not the most tech savvy.  I got a blue-ray writer and a MKV writer, now I want  to figure out how to  mount that digitally  into something more user friendly. Suggestions?"},
{"Title": "Merging folders and files", "Author": "u/cl326", "Content": "I have a Windows 11 system with many folders, sub-folders, and files. I want to keep only one copy of each file based on its MD5 hash, including its filename and extension. In the end I want just one folder with all the unique files. Is there any easy way to do this? If not a specific app, I'm willing to write an app or script in Python, Ruby, or PowerShell. Any thoughts or suggestions?"},
{"Title": "WD Ultrastar DC SN655 7.68 Tb for 196€ (211$) at a French retailer", "Author": "u/Nayko93", "Content": "I just found this deal, a 7.68TB NAS SSD for 196€, that's 0.02 cents per GB !I was thinking it could interest a few people here\n  \n\n\nhttps://fr.shopping.rakuten.com/offer/buy/11626286226/disque-dur-interne-7-68to-wd-ultrastar-dc-sn655-2-5-u-3-pcie-4-0-nvme-wus5ea176esp7e3.html\n\n\n\n    I'm not even sure it's real but it look like it, seller have a good reputation and the website is legitMaybe it's a price error, I don't know, but I've seen other posts talking about huge deal on those SSD so it seem this kind of deal is not impossible\n  \n\n    I tried to place a order to see if they ship outside of France and unfortunately they don't, so you either need to be in France, or use a friend or package forwarding service\n  \n\n    I'm almost tempted to buy 2 myself, since I'm looking to make my first home NASThat's a lot of money but for this much storage it would be dumb to pass it... but I know nothing of those SSD or NAS SSD in general, They need a PCI adapter to plug on a normal MB and I think I've read somewhere they heat up a lot ?I would be more comfortable dealing with normal sata or m.2 SSD... but such a deal.. I'm really tempted\n  \n\n\n\n    Update : It was legit, the seller confirmed my order and the price\n  \n\n    Unfortunately I had to cancel my order, because I can't find any U.3 pci card that can hold more than 1 SSD, and I need 3 off them, but I don't have 3 PCI left in my NAS"},
{"Title": "Is this a good deal listed in my local facebook marketplace “Dell poweredge r710 md1220 READ”", "Author": "u/makzero", "Content": "No content"},
{"Title": "Need to rename thousands of files that were named with a bad template", "Author": "u/NighthawkE3", "Content": "Okay this is a potentially weird one, I’ll do my best\n  \n\n    Very quick summery: I have about 5000 files that must be renamed from:\n  \n\n\n\n    To Simply\n  \n\n\n\n    I have about 5000 of these incorrectly named files, and they can't be used in the current format. I have both Windows and Linux operating systems at my disposal, any help would be massively appreciated"},
{"Title": "Are there any risks of using a USB Switch with a power supply on my PC and my DAS ?", "Author": "u/Yukinoooo", "Content": "My goal is to use my DAS on my PC and my media player (like a kind of Nvidia Shield, not Android or IOS, just the KODI interface under GNU/Linux) safely. I'm wondering if it's a good idea to use the two ports (PC and my media player) of a usb switch + a power supply and one port for my DAS ? If not, which solution should I use ?"},
{"Title": "Is there a way to get full news broadcasts from archive.org or anywhere else?", "Author": "u/Ok-Nobody8834", "Content": "I'm doing something for school, but \narchive.org\n only seem to have parts of full news broadcasts, but I'm wondering if there's a way to get full broadcasts from them?\n  \n\n    here is an example of how they're chopped up:\n  \n\n\nhttps://archive.org/details/CNN_20100826_230000_John_King_USA/start/0/end/60\n\n\n\n    Better quality video would be nice too.  Any help is appreciated!"},
{"Title": "RAID card no longer working, gives firmware error on POST", "Author": "u/Cyber_Akuma", "Content": "I have a LSI 9260-8i, this was actually reflashed from the original IRM ServeRAID M5014 it arrived as. It has since also been upgraded to the latest firmware from LSI/Broadcom, which is 12.15.0-0239 (also the card at boot identifies as BIOS version \"3.30.02.2 (Build June 17, 2014)\"). I am just simply using it in my Windows 10 system, not as part of a server or NAS.\n  \n\n    This card had been disconnected from my system for about 6-12 months, as well as it's drives, I recently reconnected everything in a new system. I have four HDDs in a RAID5, but had recently acquired the license key to enable RAID6 and had installed a 5th HDD in preparation for that. I had a few errors at first, but many things in the system were at first giving me errors so I didn't think much of it as I had performed several upgrades and changes at once.\n  \n\n    I eventually got everything booting properly and then opened up the RAID Windows management software (Version 17.05.02.01 at the time) and it seemed to be going ok. It was performing a Patrol Read on all of my drives and was recharging the battery (Though it claimed the battery was bad, but it was new, so I figured it needed to do a recharge cycle and re-learn to see it as good again). It said the Patrol Read was only going to take 10 minutes but I knew it was going to take hours. Halfway in, at about the 3-4 hour mark, the software completely stopped responding. I restarted it, and now the card was showing that absolutely nothing was installed to it.\n  \n\n    I performed a reboot and now I kept getting an error message during the card's initialization during post:\n  \n\n\n\n    LSI MegaRAID SAS-MFI BIOS Version 3.30.02.2 (Build June 17, 2014) Copyright(c) 2014 LSI Corporation Host Adapter Bus 5 Dev 0:\n  \n\n\n\n\n\n    F/W is in Fault State MFI Register State 0xF0010002\n  \n\n\n\n\n\n    Adapter at Baseport is not responding\n  \n\n\n\n\n\n    No MegaRAID Adapter Installed\n  \n\n\n\n    The card then could be seen as installed, but the drives were not showing up, and the management software could not even tell a card was installed anymore. I tried updating to the latest management software (17.05.06.00) in case it might at least see there is a card installed, with that being it's own can of worms of expecting me to manually install OpenJDK and set the environment paths myself, it also just gets stuck loading the application.\n  \n\n    I tried MegaCLI, StorCLI, and MegaSCU (I admit I am not too familiar with managing this card through a CLI) but -v and -AdpAllInfo -aALL but they all returned nothing. I tried disconnecting the drives in case one had somehow become so fault during storage that it was crashing it, and no difference. I tried the only other PCI socket in my motherboard and it would not even boot then, guess that socket isn't even working with everything else installed in my system.\n  \n\n    I have no idea what to do now. The card refuses to work, claiming it's suffering some kind of firmware fault on POST, none of the software seems to even detect the presence of the card at all despite it physically showing up in Device Manager (although with an \"An I/O adapter hardware error has occurred.\" error) and HWiNFO, and I am not aware of any way I can attempt a force-reflash of the firmware in case it's a software issue (although I somehow doubt it) or of what else to try.\n  \n\n    And yes, I have a backup of my data."},
{"Title": "Ibms first commercially available 5mb ramac's disk storage 1956", "Author": "u/noideawhatimdoing444", "Content": "No content"},
{"Title": "Twitter is silently deleting some suspended accounts which has not been logged in for some time.", "Author": "u/cyberanakinvader", "Content": "I think I've made a disturbing discovery regarding Twitter where they have silently deleted some suspended accounts which has not been logged in for some time, including some of mine.\n  \n\n    Has anyone else encountered this issue recently?"},
{"Title": "Silverstone shows off CS383 at Computex", "Author": "u/Odrel", "Content": "GamersNexus is looking at the Silverstone CS383\n at Computex. The video is super quick but some highlights include:\n  \n\n\n\n\n\n    Up to 12x3,5\" drives\n  \n\n\n\n\n\n    Option to add a second power supply by removing a HDD cage (-4 HDDs)\n  \n\n\n\n\n\n    5,25\" bay at the top\n  \n\n\n\n\n\n    Support for large motherboards and GPUs\n  \n\n\n\n\n\n    Targeting $400 in Q3"},
{"Title": "How does position affect hdd life span?", "Author": "u/d3crypti0n", "Content": "Hello everybody,\n  \n\n    I found a cheap server chassis for my rack I wanted to buy but the thing that bothers me is the positing of the drives, they are mounted vertically.\n  \n\n    This brings me to my question - does the position affect the hdd lifespan? Do drives that stand life longer / shorter then the ones who are mounted horizontally due to gravity (because of the rotating platters) ?\nIf yes, how big of difference does it make?"},
{"Title": "WD MyCloud Home once again screws me over", "Author": "u/techek", "Content": "My MyCloud Home has been updated to version 4.23.0 from December 4th 2023. I now know not become all excited and such, because almost every update since my purchase, has introduced one or more downgrades. Why remains unanswered.\n  \n\n    This time is no exception although the information about version 4.23.0 starts of with \"We constantly evaluate the customer experience ... wish to improve ... bring new and exciting features\" and so on.\n  \n\n    In reality it's a load of b......t, because this time they remove support for backing up videos and photos from Facebook. Previous update removed feature for editing photos in the app, before that remote backup with ElephantDrive disappeared, less connectivity and so on.\n  \n\n    The list of downgrades is impressive! And I feel used. Thanks for nothing, Western Digital!\n  \n\n    I cannot recommend their products for anyone anymore - those days are definitely over now."},
{"Title": "No media on window help.", "Author": "u/MisakaMisakaS100", "Content": "No content"},
{"Title": "Is it worth buying a WD Ultrastar on e-bay and use it with an external HDD enclosure?", "Author": "u/Lion_Blue357", "Content": "Hi everyone,\n  \n\n    I saw a few WD Ultrastar HDD on e-bay, the price looks good compared to other new drives I bought on Amazon some time ago.\n  \n\n    The HDDs I'm referring to are these:\n  \n\n\nhttps://www.ebay.it/itm/116156982107\n\n\n\n\nhttps://www.ebay.it/itm/355675152726\n\n\n\n\nhttps://www.ebay.it/itm/115946008531\n\n\n\n\nhttps://www.ebay.it/itm/354913714861\n\n\n\n    I would like to use the drive with an external enclosure.\n  \n\n    The first question i would like to ask you is: based on your experience, what is the catch with these drives sold on e-bay? Is there something I should be careful about?\n  \n\n    The other question is about the enclosure: I have read that some enclosures format the drive in such a way that makes it impossibile to access the drive without the enclosure. Can you suggest me an enclosured that is reliable and would allow me to use the drive even without the enclosure itself?\n  \n\n    Thank you so much"},
{"Title": "Newbie needing help", "Author": "u/Lochness_al", "Content": "I have 5 portable SSD and HDD plugged into my computer making my desk a mess I was wonding what would be a good external bay and HDD to buy. I want to run it with some kind of redundancy  (raid 1 most likely) It has my audio books, photos, and movies on it that I access through jelly fin I have thought about a nas before but I'm not that good with computers and just run jelly fin off my main PC."},
{"Title": "DAS Box - Can it be restarted remotely after a blackout?", "Author": "u/jfromeo", "Content": "I am in the search of a USB-C DAS to upgrade my 3,5\" HDD hoarding, as I do not have the space to accommodate a rack solution at the moment.\n  \n\n    I have found the MB-X10U31 from Fantec, which ticks all the features (10 bays, hot-swap, USB-C, etc). Quite similiar to the Mediasonic, IcyBox and Sabrent ones.\n  \n\n\nhttps://fantecshop.de/p/fantec-mb-x10u31\n\n\nhttps://preview.redd.it/das-box-can-it-be-restarted-remotely-after-a-blackout-v0-npzcdqysbb5d1.jpg\n\n    But I have one feature I depend on, and I cannot deduce how it will behave, and the brand has not answered me either.\n  \n\n    I need to find out \nif the box can somehow be restarted remotely after a blackout\n, as I live 1.000km away from the server and there is no one to operate it. I have an UPS which can hold around 15 minutes, but sometimes the blackout are longer and I have a routine via NUT to power off all the devices if power is not restored within that period of time. I can WoL the main machine, but I do not know how could I power up the DAS box.\n  \n\n    Thanks in advance."},
{"Title": "External Hard Drives", "Author": "u/Cravendale3", "Content": "Can someone explain why curry’s sells a 1tb external hard drive for £143 and then some random online shop sells 128tb for £130? How can there but such a tb difference but price is practically the same, I’m having such a difficult time trying to pick the right drive because there’s so much variety in price and tb storage, all I want is around 2tbs for a decent price, confused 🤔"},
{"Title": "Online NAS custom builders?", "Author": "u/Creepy_Finish1497", "Content": "Are there any online retailers that build NAS' for consumers?"},
{"Title": "Scanning magazines without cutting", "Author": "u/empireerotica", "Content": "Hi all, I’m sure this has been asked in here before, but is there any way to scan magazines without cutting them? I’ve acquired quite a substantial collection of vintage Playboy/Playgirl and vintage gay erotic and culture magazines. I would really love to digitize them but would hate to destroy them in the process, especially with some of them being 75+ years old. Thanks!"},
{"Title": "Need Help Setting Up Android and iPhone Backup Over WiFi to Windows PC", "Author": "u/BrokenScorp", "Content": "Hey everyone,\n  \n\n    I’m looking for some advice on setting up a reliable photo backup solution for my Android and iPhone over WiFi to my Windows PC. Currently, I’m using Resilio Sync, but it doesn’t seem to work well with iOS.\n  \n\n    Does anyone have any recommendations for tools or software that can handle this more effectively? Ideally, I’d like something that can manage both platforms seamlessly and ensure my data is safely backed up to my PC.\n  \n\n    Thanks in advance for your suggestions!"},
{"Title": "Need Honest Advice", "Author": "u/Substantial-Big8229", "Content": "For context, I left my gaming PC in a storage unit in a desert environment for nearly 2-3 years without ventilation, I'm concerned about potential data corruption or loss, especially regarding the SSD.\n  \n\n    I haven't powered it on, cleaned it, or updated its firmware during this time. What are the realistic chances of data corruption or loss, and how feasible is data recovery at this stage?\n  \n\n    (NOTE: Its consumer grade TLC SSD if that makes a difference.)"},
{"Title": "Is it good practice to leave free space on Optical Disks?", "Author": "u/finbarrgalloway", "Content": "I know for hard disk storage they often tell you to leave 1/3 to 1/4 free to not stress the drive, but does this hold true for a DVD? Or can I fill them up to my hearts content?"},
{"Title": "Where to buy the cheapest reliable Renewed 16+ TB Hard drives for NAS?", "Author": "u/Charbax", "Content": "Hi! Recently by searching on Amazon US \nhttps://www.amazon.com/s?k=renewed+16TB\n I discovered that there's a whole world of \nrenewed hard drives\n sold at perhaps around half of the price of new per same amount of TB!! Woah! 16TB starts at $139!\n  \n\n    I used to buy so many external (I have a bunch of 8TBs) Seagate (probably all are \nshingled magnetic recording\n based?) USB3 hard drives, but these renewed Enterprise hard drives seem so much better performing, way cheaper than even cheapest USB3 externals, and I would hope all decently usable to build a future NAS I am envisioning.. !!\n  \n\n    Here are some places that sell these renewed hard drives as I have found:\n  \n\n\nhttps://serverpartdeals.com/\n (they seem to have 2-year warranty WD Ultrastar and etc) with $40 worldwide shipping (free 2-day shipping in the USA)\n  \n\n\nhttps://www.goharddrive.com/category-s/293.htm\n (under this renewed HDD brand \"MaxDigitalData\" which can also be found on Amazon US)\n  \n\n    Some Ebay sellers such as these:\n  \n\n\nhttps://www.ebay.com/str/eastdigital\n out of Hong Kong with free shipping worldwide or $20 expedited worldwide shipping\n  \n\n\nhttps://www.ebay.com/str/goharddrivewholesaleandretail\n (perhaps they have more or different drives on their ebay than on their website?)\n  \n\n\nhttps://www.ebay.com/str/dbskyusa88\n\n\n\n    Which of these or other sellers have you tried and can you recommend? As many of them seem to say they provide 2-year, 3-year even 5-year \"Warranty from the Reseller\", one might want to buy from a reseller that seems to have many reviews and a longer history to hopefully still be around if one or other of these hard drives stop working within the 2, 3 or 5-year warranty..\n  \n\n    Although it might sound scary to buy a hard drive that might have already run 26 thousand hours or more (if it has already run for 3 years or so constantly in these data centers), coming out of a cloud storage provider who for one reason or other needs to sell or to replace their storage drives periodically, I would think:\n  \n\n\n\n\n\n    That these renewed hard drives might have actually been tested way more than new hard drives, and since the resellers test them before selling them, it means they're probably still fine, so who knows, they might have a better chance of lasting a further many years compared with buying a new hard drive off the market? Especially since my future NAS or just USB enclosure backup usage would be much less heavy in usage compared with the usage they've had in the datacenters until being sold for renewed.\n  \n\n\n\n\n\n    I go to check Backblaze's Hard drive tests \nhttps://www.backblaze.com/cloud-storage/resources/hard-drive-test-data\n and I simply try to order those same exact hard drive model numbers that have the best reliability according to Backblaze!\n  \n\n\n\n\n\n    Hard drive manufacturers (WD Ultrastar?) advertise something like 2.5 million hours of usage before an expected failure, so if they've run for about 25'000 hours in some datacenters for 3 years constantly somewhere, that's only 1% of the advertised lifetime?\n  \n\n\n\n\n\n    Once I get my 5-bay or 6-bay or 8-bay NAS up and running (still I don't know which one I will aim for, I am looking through second hand markets periodically), I would think, it shouldn't be a problem just swapping out any failed hard drive if that happens eventually (if still within warranty or after warranty expired), and considering Renewed hard drives are sold at half the price of new! If I eventually have 10% of my renewed hard drives fail (sooner than new hard drives fail, which I am unsure if one should expect), it might still be 2x cheaper per TB than buying all these hard drives as new!"},
{"Title": "Starting data hording journey", "Author": "u/nlj1978", "Content": "After the help I got here on ripping my cd collection I'm jumping in the deep end. I'm putting together a media server. Have a HP z1 G5 tower workstation with i5-9500 on the way but still have decisions to make in terms of hardware and software.\n  \n\n    I'm finding mixed data on ECC ram support. Apparently the motherboards come in a couple variations. Once I confirm I believe I believe ECC is a better choice for this application. Still need to verify but I believe the board supports either 64 or 128gig.  That said how much ram should I use?\n  \n\n    Mobo has 2 m2 slots and 4 sata ports. Computer comes with a 256g nvme. I've read a little about using m2 Intel Optane drives for improved server performance. Anyone have any experience or input on this?\n  \n\n    Drives I'm still pondering.\n  \n\n    On the software side I am leaning towards TrueNas and  Jellyfin. Both seem relatively user friendly to someone with limited server knowledge. Thoughts?"},
{"Title": "New to Data hoarding", "Author": "u/Rio-Chevalier", "Content": "So I'm currently trying to back up my old DVD and blue ray collection digitally,  (and admittedly I'm not the most tech savvy.  I got a blue-ray writer and a MKV writer, now I want  to figure out how to  mount that digitally  into something more user friendly. Suggestions?"},
{"Title": "Merging folders and files", "Author": "u/cl326", "Content": "I have a Windows 11 system with many folders, sub-folders, and files. I want to keep only one copy of each file based on its MD5 hash, including its filename and extension. In the end I want just one folder with all the unique files. Is there any easy way to do this? If not a specific app, I'm willing to write an app or script in Python, Ruby, or PowerShell. Any thoughts or suggestions?"},
{"Title": "WD Ultrastar DC SN655 7.68 Tb for 196€ (211$) at a French retailer", "Author": "u/Nayko93", "Content": "I just found this deal, a 7.68TB NAS SSD for 196€, that's 0.02 cents per GB !I was thinking it could interest a few people here\n  \n\n\nhttps://fr.shopping.rakuten.com/offer/buy/11626286226/disque-dur-interne-7-68to-wd-ultrastar-dc-sn655-2-5-u-3-pcie-4-0-nvme-wus5ea176esp7e3.html\n\n\n\n    I'm not even sure it's real but it look like it, seller have a good reputation and the website is legitMaybe it's a price error, I don't know, but I've seen other posts talking about huge deal on those SSD so it seem this kind of deal is not impossible\n  \n\n    I tried to place a order to see if they ship outside of France and unfortunately they don't, so you either need to be in France, or use a friend or package forwarding service\n  \n\n    I'm almost tempted to buy 2 myself, since I'm looking to make my first home NASThat's a lot of money but for this much storage it would be dumb to pass it... but I know nothing of those SSD or NAS SSD in general, They need a PCI adapter to plug on a normal MB and I think I've read somewhere they heat up a lot ?I would be more comfortable dealing with normal sata or m.2 SSD... but such a deal.. I'm really tempted\n  \n\n\n\n    Update : It was legit, the seller confirmed my order and the price\n  \n\n    Unfortunately I had to cancel my order, because I can't find any U.3 pci card that can hold more than 1 SSD, and I need 3 off them, but I don't have 3 PCI left in my NAS"},
{"Title": "Is this a good deal listed in my local facebook marketplace “Dell poweredge r710 md1220 READ”", "Author": "u/makzero", "Content": "No content"},
{"Title": "Need to rename thousands of files that were named with a bad template", "Author": "u/NighthawkE3", "Content": "Okay this is a potentially weird one, I’ll do my best\n  \n\n    Very quick summery: I have about 5000 files that must be renamed from:\n  \n\n\n\n    To Simply\n  \n\n\n\n    I have about 5000 of these incorrectly named files, and they can't be used in the current format. I have both Windows and Linux operating systems at my disposal, any help would be massively appreciated"},
{"Title": "Are there any risks of using a USB Switch with a power supply on my PC and my DAS ?", "Author": "u/Yukinoooo", "Content": "My goal is to use my DAS on my PC and my media player (like a kind of Nvidia Shield, not Android or IOS, just the KODI interface under GNU/Linux) safely. I'm wondering if it's a good idea to use the two ports (PC and my media player) of a usb switch + a power supply and one port for my DAS ? If not, which solution should I use ?"},
{"Title": "Is there a way to get full news broadcasts from archive.org or anywhere else?", "Author": "u/Ok-Nobody8834", "Content": "I'm doing something for school, but \narchive.org\n only seem to have parts of full news broadcasts, but I'm wondering if there's a way to get full broadcasts from them?\n  \n\n    here is an example of how they're chopped up:\n  \n\n\nhttps://archive.org/details/CNN_20100826_230000_John_King_USA/start/0/end/60\n\n\n\n    Better quality video would be nice too.  Any help is appreciated!"},
{"Title": "RAID card no longer working, gives firmware error on POST", "Author": "u/Cyber_Akuma", "Content": "I have a LSI 9260-8i, this was actually reflashed from the original IRM ServeRAID M5014 it arrived as. It has since also been upgraded to the latest firmware from LSI/Broadcom, which is 12.15.0-0239 (also the card at boot identifies as BIOS version \"3.30.02.2 (Build June 17, 2014)\"). I am just simply using it in my Windows 10 system, not as part of a server or NAS.\n  \n\n    This card had been disconnected from my system for about 6-12 months, as well as it's drives, I recently reconnected everything in a new system. I have four HDDs in a RAID5, but had recently acquired the license key to enable RAID6 and had installed a 5th HDD in preparation for that. I had a few errors at first, but many things in the system were at first giving me errors so I didn't think much of it as I had performed several upgrades and changes at once.\n  \n\n    I eventually got everything booting properly and then opened up the RAID Windows management software (Version 17.05.02.01 at the time) and it seemed to be going ok. It was performing a Patrol Read on all of my drives and was recharging the battery (Though it claimed the battery was bad, but it was new, so I figured it needed to do a recharge cycle and re-learn to see it as good again). It said the Patrol Read was only going to take 10 minutes but I knew it was going to take hours. Halfway in, at about the 3-4 hour mark, the software completely stopped responding. I restarted it, and now the card was showing that absolutely nothing was installed to it.\n  \n\n    I performed a reboot and now I kept getting an error message during the card's initialization during post:\n  \n\n\n\n    LSI MegaRAID SAS-MFI BIOS Version 3.30.02.2 (Build June 17, 2014) Copyright(c) 2014 LSI Corporation Host Adapter Bus 5 Dev 0:\n  \n\n\n\n\n\n    F/W is in Fault State MFI Register State 0xF0010002\n  \n\n\n\n\n\n    Adapter at Baseport is not responding\n  \n\n\n\n\n\n    No MegaRAID Adapter Installed\n  \n\n\n\n    The card then could be seen as installed, but the drives were not showing up, and the management software could not even tell a card was installed anymore. I tried updating to the latest management software (17.05.06.00) in case it might at least see there is a card installed, with that being it's own can of worms of expecting me to manually install OpenJDK and set the environment paths myself, it also just gets stuck loading the application.\n  \n\n    I tried MegaCLI, StorCLI, and MegaSCU (I admit I am not too familiar with managing this card through a CLI) but -v and -AdpAllInfo -aALL but they all returned nothing. I tried disconnecting the drives in case one had somehow become so fault during storage that it was crashing it, and no difference. I tried the only other PCI socket in my motherboard and it would not even boot then, guess that socket isn't even working with everything else installed in my system.\n  \n\n    I have no idea what to do now. The card refuses to work, claiming it's suffering some kind of firmware fault on POST, none of the software seems to even detect the presence of the card at all despite it physically showing up in Device Manager (although with an \"An I/O adapter hardware error has occurred.\" error) and HWiNFO, and I am not aware of any way I can attempt a force-reflash of the firmware in case it's a software issue (although I somehow doubt it) or of what else to try.\n  \n\n    And yes, I have a backup of my data."},
{"Title": "Ibms first commercially available 5mb ramac's disk storage 1956", "Author": "u/noideawhatimdoing444", "Content": "No content"},
{"Title": "Twitter is silently deleting some suspended accounts which has not been logged in for some time.", "Author": "u/cyberanakinvader", "Content": "I think I've made a disturbing discovery regarding Twitter where they have silently deleted some suspended accounts which has not been logged in for some time, including some of mine.\n  \n\n    Has anyone else encountered this issue recently?"},
{"Title": "Silverstone shows off CS383 at Computex", "Author": "u/Odrel", "Content": "GamersNexus is looking at the Silverstone CS383\n at Computex. The video is super quick but some highlights include:\n  \n\n\n\n\n\n    Up to 12x3,5\" drives\n  \n\n\n\n\n\n    Option to add a second power supply by removing a HDD cage (-4 HDDs)\n  \n\n\n\n\n\n    5,25\" bay at the top\n  \n\n\n\n\n\n    Support for large motherboards and GPUs\n  \n\n\n\n\n\n    Targeting $400 in Q3"},
{"Title": "How does position affect hdd life span?", "Author": "u/d3crypti0n", "Content": "Hello everybody,\n  \n\n    I found a cheap server chassis for my rack I wanted to buy but the thing that bothers me is the positing of the drives, they are mounted vertically.\n  \n\n    This brings me to my question - does the position affect the hdd lifespan? Do drives that stand life longer / shorter then the ones who are mounted horizontally due to gravity (because of the rotating platters) ?\nIf yes, how big of difference does it make?"},
{"Title": "WD MyCloud Home once again screws me over", "Author": "u/techek", "Content": "My MyCloud Home has been updated to version 4.23.0 from December 4th 2023. I now know not become all excited and such, because almost every update since my purchase, has introduced one or more downgrades. Why remains unanswered.\n  \n\n    This time is no exception although the information about version 4.23.0 starts of with \"We constantly evaluate the customer experience ... wish to improve ... bring new and exciting features\" and so on.\n  \n\n    In reality it's a load of b......t, because this time they remove support for backing up videos and photos from Facebook. Previous update removed feature for editing photos in the app, before that remote backup with ElephantDrive disappeared, less connectivity and so on.\n  \n\n    The list of downgrades is impressive! And I feel used. Thanks for nothing, Western Digital!\n  \n\n    I cannot recommend their products for anyone anymore - those days are definitely over now."},
{"Title": "No media on window help.", "Author": "u/MisakaMisakaS100", "Content": "No content"},
{"Title": "Is it worth buying a WD Ultrastar on e-bay and use it with an external HDD enclosure?", "Author": "u/Lion_Blue357", "Content": "Hi everyone,\n  \n\n    I saw a few WD Ultrastar HDD on e-bay, the price looks good compared to other new drives I bought on Amazon some time ago.\n  \n\n    The HDDs I'm referring to are these:\n  \n\n\nhttps://www.ebay.it/itm/116156982107\n\n\n\n\nhttps://www.ebay.it/itm/355675152726\n\n\n\n\nhttps://www.ebay.it/itm/115946008531\n\n\n\n\nhttps://www.ebay.it/itm/354913714861\n\n\n\n    I would like to use the drive with an external enclosure.\n  \n\n    The first question i would like to ask you is: based on your experience, what is the catch with these drives sold on e-bay? Is there something I should be careful about?\n  \n\n    The other question is about the enclosure: I have read that some enclosures format the drive in such a way that makes it impossibile to access the drive without the enclosure. Can you suggest me an enclosured that is reliable and would allow me to use the drive even without the enclosure itself?\n  \n\n    Thank you so much"},
{"Title": "Newbie needing help", "Author": "u/Lochness_al", "Content": "I have 5 portable SSD and HDD plugged into my computer making my desk a mess I was wonding what would be a good external bay and HDD to buy. I want to run it with some kind of redundancy  (raid 1 most likely) It has my audio books, photos, and movies on it that I access through jelly fin I have thought about a nas before but I'm not that good with computers and just run jelly fin off my main PC."},
{"Title": "DAS Box - Can it be restarted remotely after a blackout?", "Author": "u/jfromeo", "Content": "I am in the search of a USB-C DAS to upgrade my 3,5\" HDD hoarding, as I do not have the space to accommodate a rack solution at the moment.\n  \n\n    I have found the MB-X10U31 from Fantec, which ticks all the features (10 bays, hot-swap, USB-C, etc). Quite similiar to the Mediasonic, IcyBox and Sabrent ones.\n  \n\n\nhttps://fantecshop.de/p/fantec-mb-x10u31\n\n\nhttps://preview.redd.it/das-box-can-it-be-restarted-remotely-after-a-blackout-v0-npzcdqysbb5d1.jpg\n\n    But I have one feature I depend on, and I cannot deduce how it will behave, and the brand has not answered me either.\n  \n\n    I need to find out \nif the box can somehow be restarted remotely after a blackout\n, as I live 1.000km away from the server and there is no one to operate it. I have an UPS which can hold around 15 minutes, but sometimes the blackout are longer and I have a routine via NUT to power off all the devices if power is not restored within that period of time. I can WoL the main machine, but I do not know how could I power up the DAS box.\n  \n\n    Thanks in advance."},
{"Title": "External Hard Drives", "Author": "u/Cravendale3", "Content": "Can someone explain why curry’s sells a 1tb external hard drive for £143 and then some random online shop sells 128tb for £130? How can there but such a tb difference but price is practically the same, I’m having such a difficult time trying to pick the right drive because there’s so much variety in price and tb storage, all I want is around 2tbs for a decent price, confused 🤔"},
{"Title": "Online NAS custom builders?", "Author": "u/Creepy_Finish1497", "Content": "Are there any online retailers that build NAS' for consumers?"},
{"Title": "Scanning magazines without cutting", "Author": "u/empireerotica", "Content": "Hi all, I’m sure this has been asked in here before, but is there any way to scan magazines without cutting them? I’ve acquired quite a substantial collection of vintage Playboy/Playgirl and vintage gay erotic and culture magazines. I would really love to digitize them but would hate to destroy them in the process, especially with some of them being 75+ years old. Thanks!"},
{"Title": "Need Help Setting Up Android and iPhone Backup Over WiFi to Windows PC", "Author": "u/BrokenScorp", "Content": "Hey everyone,\n  \n\n    I’m looking for some advice on setting up a reliable photo backup solution for my Android and iPhone over WiFi to my Windows PC. Currently, I’m using Resilio Sync, but it doesn’t seem to work well with iOS.\n  \n\n    Does anyone have any recommendations for tools or software that can handle this more effectively? Ideally, I’d like something that can manage both platforms seamlessly and ensure my data is safely backed up to my PC.\n  \n\n    Thanks in advance for your suggestions!"},
{"Title": "Need Honest Advice", "Author": "u/Substantial-Big8229", "Content": "For context, I left my gaming PC in a storage unit in a desert environment for nearly 2-3 years without ventilation, I'm concerned about potential data corruption or loss, especially regarding the SSD.\n  \n\n    I haven't powered it on, cleaned it, or updated its firmware during this time. What are the realistic chances of data corruption or loss, and how feasible is data recovery at this stage?\n  \n\n    (NOTE: Its consumer grade TLC SSD if that makes a difference.)"},
{"Title": "Is it good practice to leave free space on Optical Disks?", "Author": "u/finbarrgalloway", "Content": "I know for hard disk storage they often tell you to leave 1/3 to 1/4 free to not stress the drive, but does this hold true for a DVD? Or can I fill them up to my hearts content?"},
{"Title": "Where to buy the cheapest reliable Renewed 16+ TB Hard drives for NAS?", "Author": "u/Charbax", "Content": "Hi! Recently by searching on Amazon US \nhttps://www.amazon.com/s?k=renewed+16TB\n I discovered that there's a whole world of \nrenewed hard drives\n sold at perhaps around half of the price of new per same amount of TB!! Woah! 16TB starts at $139!\n  \n\n    I used to buy so many external (I have a bunch of 8TBs) Seagate (probably all are \nshingled magnetic recording\n based?) USB3 hard drives, but these renewed Enterprise hard drives seem so much better performing, way cheaper than even cheapest USB3 externals, and I would hope all decently usable to build a future NAS I am envisioning.. !!\n  \n\n    Here are some places that sell these renewed hard drives as I have found:\n  \n\n\nhttps://serverpartdeals.com/\n (they seem to have 2-year warranty WD Ultrastar and etc) with $40 worldwide shipping (free 2-day shipping in the USA)\n  \n\n\nhttps://www.goharddrive.com/category-s/293.htm\n (under this renewed HDD brand \"MaxDigitalData\" which can also be found on Amazon US)\n  \n\n    Some Ebay sellers such as these:\n  \n\n\nhttps://www.ebay.com/str/eastdigital\n out of Hong Kong with free shipping worldwide or $20 expedited worldwide shipping\n  \n\n\nhttps://www.ebay.com/str/goharddrivewholesaleandretail\n (perhaps they have more or different drives on their ebay than on their website?)\n  \n\n\nhttps://www.ebay.com/str/dbskyusa88\n\n\n\n    Which of these or other sellers have you tried and can you recommend? As many of them seem to say they provide 2-year, 3-year even 5-year \"Warranty from the Reseller\", one might want to buy from a reseller that seems to have many reviews and a longer history to hopefully still be around if one or other of these hard drives stop working within the 2, 3 or 5-year warranty..\n  \n\n    Although it might sound scary to buy a hard drive that might have already run 26 thousand hours or more (if it has already run for 3 years or so constantly in these data centers), coming out of a cloud storage provider who for one reason or other needs to sell or to replace their storage drives periodically, I would think:\n  \n\n\n\n\n\n    That these renewed hard drives might have actually been tested way more than new hard drives, and since the resellers test them before selling them, it means they're probably still fine, so who knows, they might have a better chance of lasting a further many years compared with buying a new hard drive off the market? Especially since my future NAS or just USB enclosure backup usage would be much less heavy in usage compared with the usage they've had in the datacenters until being sold for renewed.\n  \n\n\n\n\n\n    I go to check Backblaze's Hard drive tests \nhttps://www.backblaze.com/cloud-storage/resources/hard-drive-test-data\n and I simply try to order those same exact hard drive model numbers that have the best reliability according to Backblaze!\n  \n\n\n\n\n\n    Hard drive manufacturers (WD Ultrastar?) advertise something like 2.5 million hours of usage before an expected failure, so if they've run for about 25'000 hours in some datacenters for 3 years constantly somewhere, that's only 1% of the advertised lifetime?\n  \n\n\n\n\n\n    Once I get my 5-bay or 6-bay or 8-bay NAS up and running (still I don't know which one I will aim for, I am looking through second hand markets periodically), I would think, it shouldn't be a problem just swapping out any failed hard drive if that happens eventually (if still within warranty or after warranty expired), and considering Renewed hard drives are sold at half the price of new! If I eventually have 10% of my renewed hard drives fail (sooner than new hard drives fail, which I am unsure if one should expect), it might still be 2x cheaper per TB than buying all these hard drives as new!"},
{"Title": "Starting data hording journey", "Author": "u/nlj1978", "Content": "After the help I got here on ripping my cd collection I'm jumping in the deep end. I'm putting together a media server. Have a HP z1 G5 tower workstation with i5-9500 on the way but still have decisions to make in terms of hardware and software.\n  \n\n    I'm finding mixed data on ECC ram support. Apparently the motherboards come in a couple variations. Once I confirm I believe I believe ECC is a better choice for this application. Still need to verify but I believe the board supports either 64 or 128gig.  That said how much ram should I use?\n  \n\n    Mobo has 2 m2 slots and 4 sata ports. Computer comes with a 256g nvme. I've read a little about using m2 Intel Optane drives for improved server performance. Anyone have any experience or input on this?\n  \n\n    Drives I'm still pondering.\n  \n\n    On the software side I am leaning towards TrueNas and  Jellyfin. Both seem relatively user friendly to someone with limited server knowledge. Thoughts?"},
{"Title": "New to Data hoarding", "Author": "u/Rio-Chevalier", "Content": "So I'm currently trying to back up my old DVD and blue ray collection digitally,  (and admittedly I'm not the most tech savvy.  I got a blue-ray writer and a MKV writer, now I want  to figure out how to  mount that digitally  into something more user friendly. Suggestions?"},
{"Title": "Merging folders and files", "Author": "u/cl326", "Content": "I have a Windows 11 system with many folders, sub-folders, and files. I want to keep only one copy of each file based on its MD5 hash, including its filename and extension. In the end I want just one folder with all the unique files. Is there any easy way to do this? If not a specific app, I'm willing to write an app or script in Python, Ruby, or PowerShell. Any thoughts or suggestions?"},
{"Title": "WD Ultrastar DC SN655 7.68 Tb for 196€ (211$) at a French retailer", "Author": "u/Nayko93", "Content": "I just found this deal, a 7.68TB NAS SSD for 196€, that's 0.02 cents per GB !I was thinking it could interest a few people here\n  \n\n\nhttps://fr.shopping.rakuten.com/offer/buy/11626286226/disque-dur-interne-7-68to-wd-ultrastar-dc-sn655-2-5-u-3-pcie-4-0-nvme-wus5ea176esp7e3.html\n\n\n\n    I'm not even sure it's real but it look like it, seller have a good reputation and the website is legitMaybe it's a price error, I don't know, but I've seen other posts talking about huge deal on those SSD so it seem this kind of deal is not impossible\n  \n\n    I tried to place a order to see if they ship outside of France and unfortunately they don't, so you either need to be in France, or use a friend or package forwarding service\n  \n\n    I'm almost tempted to buy 2 myself, since I'm looking to make my first home NASThat's a lot of money but for this much storage it would be dumb to pass it... but I know nothing of those SSD or NAS SSD in general, They need a PCI adapter to plug on a normal MB and I think I've read somewhere they heat up a lot ?I would be more comfortable dealing with normal sata or m.2 SSD... but such a deal.. I'm really tempted\n  \n\n\n\n    Update : It was legit, the seller confirmed my order and the price\n  \n\n    Unfortunately I had to cancel my order, because I can't find any U.3 pci card that can hold more than 1 SSD, and I need 3 off them, but I don't have 3 PCI left in my NAS"},
{"Title": "Is this a good deal listed in my local facebook marketplace “Dell poweredge r710 md1220 READ”", "Author": "u/makzero", "Content": "No content"},
{"Title": "Need to rename thousands of files that were named with a bad template", "Author": "u/NighthawkE3", "Content": "Okay this is a potentially weird one, I’ll do my best\n  \n\n    Very quick summery: I have about 5000 files that must be renamed from:\n  \n\n\n\n    To Simply\n  \n\n\n\n    I have about 5000 of these incorrectly named files, and they can't be used in the current format. I have both Windows and Linux operating systems at my disposal, any help would be massively appreciated"},
{"Title": "Are there any risks of using a USB Switch with a power supply on my PC and my DAS ?", "Author": "u/Yukinoooo", "Content": "My goal is to use my DAS on my PC and my media player (like a kind of Nvidia Shield, not Android or IOS, just the KODI interface under GNU/Linux) safely. I'm wondering if it's a good idea to use the two ports (PC and my media player) of a usb switch + a power supply and one port for my DAS ? If not, which solution should I use ?"},
{"Title": "Is there a way to get full news broadcasts from archive.org or anywhere else?", "Author": "u/Ok-Nobody8834", "Content": "I'm doing something for school, but \narchive.org\n only seem to have parts of full news broadcasts, but I'm wondering if there's a way to get full broadcasts from them?\n  \n\n    here is an example of how they're chopped up:\n  \n\n\nhttps://archive.org/details/CNN_20100826_230000_John_King_USA/start/0/end/60\n\n\n\n    Better quality video would be nice too.  Any help is appreciated!"},
{"Title": "RAID card no longer working, gives firmware error on POST", "Author": "u/Cyber_Akuma", "Content": "I have a LSI 9260-8i, this was actually reflashed from the original IRM ServeRAID M5014 it arrived as. It has since also been upgraded to the latest firmware from LSI/Broadcom, which is 12.15.0-0239 (also the card at boot identifies as BIOS version \"3.30.02.2 (Build June 17, 2014)\"). I am just simply using it in my Windows 10 system, not as part of a server or NAS.\n  \n\n    This card had been disconnected from my system for about 6-12 months, as well as it's drives, I recently reconnected everything in a new system. I have four HDDs in a RAID5, but had recently acquired the license key to enable RAID6 and had installed a 5th HDD in preparation for that. I had a few errors at first, but many things in the system were at first giving me errors so I didn't think much of it as I had performed several upgrades and changes at once.\n  \n\n    I eventually got everything booting properly and then opened up the RAID Windows management software (Version 17.05.02.01 at the time) and it seemed to be going ok. It was performing a Patrol Read on all of my drives and was recharging the battery (Though it claimed the battery was bad, but it was new, so I figured it needed to do a recharge cycle and re-learn to see it as good again). It said the Patrol Read was only going to take 10 minutes but I knew it was going to take hours. Halfway in, at about the 3-4 hour mark, the software completely stopped responding. I restarted it, and now the card was showing that absolutely nothing was installed to it.\n  \n\n    I performed a reboot and now I kept getting an error message during the card's initialization during post:\n  \n\n\n\n    LSI MegaRAID SAS-MFI BIOS Version 3.30.02.2 (Build June 17, 2014) Copyright(c) 2014 LSI Corporation Host Adapter Bus 5 Dev 0:\n  \n\n\n\n\n\n    F/W is in Fault State MFI Register State 0xF0010002\n  \n\n\n\n\n\n    Adapter at Baseport is not responding\n  \n\n\n\n\n\n    No MegaRAID Adapter Installed\n  \n\n\n\n    The card then could be seen as installed, but the drives were not showing up, and the management software could not even tell a card was installed anymore. I tried updating to the latest management software (17.05.06.00) in case it might at least see there is a card installed, with that being it's own can of worms of expecting me to manually install OpenJDK and set the environment paths myself, it also just gets stuck loading the application.\n  \n\n    I tried MegaCLI, StorCLI, and MegaSCU (I admit I am not too familiar with managing this card through a CLI) but -v and -AdpAllInfo -aALL but they all returned nothing. I tried disconnecting the drives in case one had somehow become so fault during storage that it was crashing it, and no difference. I tried the only other PCI socket in my motherboard and it would not even boot then, guess that socket isn't even working with everything else installed in my system.\n  \n\n    I have no idea what to do now. The card refuses to work, claiming it's suffering some kind of firmware fault on POST, none of the software seems to even detect the presence of the card at all despite it physically showing up in Device Manager (although with an \"An I/O adapter hardware error has occurred.\" error) and HWiNFO, and I am not aware of any way I can attempt a force-reflash of the firmware in case it's a software issue (although I somehow doubt it) or of what else to try.\n  \n\n    And yes, I have a backup of my data."},
{"Title": "Ibms first commercially available 5mb ramac's disk storage 1956", "Author": "u/noideawhatimdoing444", "Content": "No content"},
{"Title": "Twitter is silently deleting some suspended accounts which has not been logged in for some time.", "Author": "u/cyberanakinvader", "Content": "I think I've made a disturbing discovery regarding Twitter where they have silently deleted some suspended accounts which has not been logged in for some time, including some of mine.\n  \n\n    Has anyone else encountered this issue recently?"},
{"Title": "Silverstone shows off CS383 at Computex", "Author": "u/Odrel", "Content": "GamersNexus is looking at the Silverstone CS383\n at Computex. The video is super quick but some highlights include:\n  \n\n\n\n\n\n    Up to 12x3,5\" drives\n  \n\n\n\n\n\n    Option to add a second power supply by removing a HDD cage (-4 HDDs)\n  \n\n\n\n\n\n    5,25\" bay at the top\n  \n\n\n\n\n\n    Support for large motherboards and GPUs\n  \n\n\n\n\n\n    Targeting $400 in Q3"},
{"Title": "How does position affect hdd life span?", "Author": "u/d3crypti0n", "Content": "Hello everybody,\n  \n\n    I found a cheap server chassis for my rack I wanted to buy but the thing that bothers me is the positing of the drives, they are mounted vertically.\n  \n\n    This brings me to my question - does the position affect the hdd lifespan? Do drives that stand life longer / shorter then the ones who are mounted horizontally due to gravity (because of the rotating platters) ?\nIf yes, how big of difference does it make?"},
{"Title": "WD MyCloud Home once again screws me over", "Author": "u/techek", "Content": "My MyCloud Home has been updated to version 4.23.0 from December 4th 2023. I now know not become all excited and such, because almost every update since my purchase, has introduced one or more downgrades. Why remains unanswered.\n  \n\n    This time is no exception although the information about version 4.23.0 starts of with \"We constantly evaluate the customer experience ... wish to improve ... bring new and exciting features\" and so on.\n  \n\n    In reality it's a load of b......t, because this time they remove support for backing up videos and photos from Facebook. Previous update removed feature for editing photos in the app, before that remote backup with ElephantDrive disappeared, less connectivity and so on.\n  \n\n    The list of downgrades is impressive! And I feel used. Thanks for nothing, Western Digital!\n  \n\n    I cannot recommend their products for anyone anymore - those days are definitely over now."},
{"Title": "No media on window help.", "Author": "u/MisakaMisakaS100", "Content": "No content"},
{"Title": "Is it worth buying a WD Ultrastar on e-bay and use it with an external HDD enclosure?", "Author": "u/Lion_Blue357", "Content": "Hi everyone,\n  \n\n    I saw a few WD Ultrastar HDD on e-bay, the price looks good compared to other new drives I bought on Amazon some time ago.\n  \n\n    The HDDs I'm referring to are these:\n  \n\n\nhttps://www.ebay.it/itm/116156982107\n\n\n\n\nhttps://www.ebay.it/itm/355675152726\n\n\n\n\nhttps://www.ebay.it/itm/115946008531\n\n\n\n\nhttps://www.ebay.it/itm/354913714861\n\n\n\n    I would like to use the drive with an external enclosure.\n  \n\n    The first question i would like to ask you is: based on your experience, what is the catch with these drives sold on e-bay? Is there something I should be careful about?\n  \n\n    The other question is about the enclosure: I have read that some enclosures format the drive in such a way that makes it impossibile to access the drive without the enclosure. Can you suggest me an enclosured that is reliable and would allow me to use the drive even without the enclosure itself?\n  \n\n    Thank you so much"},
{"Title": "Newbie needing help", "Author": "u/Lochness_al", "Content": "I have 5 portable SSD and HDD plugged into my computer making my desk a mess I was wonding what would be a good external bay and HDD to buy. I want to run it with some kind of redundancy  (raid 1 most likely) It has my audio books, photos, and movies on it that I access through jelly fin I have thought about a nas before but I'm not that good with computers and just run jelly fin off my main PC."},
{"Title": "DAS Box - Can it be restarted remotely after a blackout?", "Author": "u/jfromeo", "Content": "I am in the search of a USB-C DAS to upgrade my 3,5\" HDD hoarding, as I do not have the space to accommodate a rack solution at the moment.\n  \n\n    I have found the MB-X10U31 from Fantec, which ticks all the features (10 bays, hot-swap, USB-C, etc). Quite similiar to the Mediasonic, IcyBox and Sabrent ones.\n  \n\n\nhttps://fantecshop.de/p/fantec-mb-x10u31\n\n\nhttps://preview.redd.it/das-box-can-it-be-restarted-remotely-after-a-blackout-v0-npzcdqysbb5d1.jpg\n\n    But I have one feature I depend on, and I cannot deduce how it will behave, and the brand has not answered me either.\n  \n\n    I need to find out \nif the box can somehow be restarted remotely after a blackout\n, as I live 1.000km away from the server and there is no one to operate it. I have an UPS which can hold around 15 minutes, but sometimes the blackout are longer and I have a routine via NUT to power off all the devices if power is not restored within that period of time. I can WoL the main machine, but I do not know how could I power up the DAS box.\n  \n\n    Thanks in advance."},
{"Title": "External Hard Drives", "Author": "u/Cravendale3", "Content": "Can someone explain why curry’s sells a 1tb external hard drive for £143 and then some random online shop sells 128tb for £130? How can there but such a tb difference but price is practically the same, I’m having such a difficult time trying to pick the right drive because there’s so much variety in price and tb storage, all I want is around 2tbs for a decent price, confused 🤔"},
{"Title": "Online NAS custom builders?", "Author": "u/Creepy_Finish1497", "Content": "Are there any online retailers that build NAS' for consumers?"},
{"Title": "Scanning magazines without cutting", "Author": "u/empireerotica", "Content": "Hi all, I’m sure this has been asked in here before, but is there any way to scan magazines without cutting them? I’ve acquired quite a substantial collection of vintage Playboy/Playgirl and vintage gay erotic and culture magazines. I would really love to digitize them but would hate to destroy them in the process, especially with some of them being 75+ years old. Thanks!"},
{"Title": "Need Help Setting Up Android and iPhone Backup Over WiFi to Windows PC", "Author": "u/BrokenScorp", "Content": "Hey everyone,\n  \n\n    I’m looking for some advice on setting up a reliable photo backup solution for my Android and iPhone over WiFi to my Windows PC. Currently, I’m using Resilio Sync, but it doesn’t seem to work well with iOS.\n  \n\n    Does anyone have any recommendations for tools or software that can handle this more effectively? Ideally, I’d like something that can manage both platforms seamlessly and ensure my data is safely backed up to my PC.\n  \n\n    Thanks in advance for your suggestions!"},
{"Title": "Need Honest Advice", "Author": "u/Substantial-Big8229", "Content": "For context, I left my gaming PC in a storage unit in a desert environment for nearly 2-3 years without ventilation, I'm concerned about potential data corruption or loss, especially regarding the SSD.\n  \n\n    I haven't powered it on, cleaned it, or updated its firmware during this time. What are the realistic chances of data corruption or loss, and how feasible is data recovery at this stage?\n  \n\n    (NOTE: Its consumer grade TLC SSD if that makes a difference.)"},
{"Title": "Portable (no-install) backup software for Windows?", "Author": "u/nefarious_bumpps", "Content": "I'm looking for a portable backup utility for Windows 10/11 desktops/laptops that can run from a USB drive without installation and perform disk image and full volume/partition backups and restores quickly to a USB external hdd/ssd.\n  \n\n    Free or reasonably-priced (under $150) commercial license.\n  \n\n    Any suggestions?"},
{"Title": "I'm running low on space in my custom built tower, what internal HDD's would you recommend?", "Author": "u/AVoraciousLatias", "Content": "Hi there, I have a 1 tb HDD and a 1 tb SDD. I'm looking to upgrade my HDD so I can store more games and programs on it, I'm looking for possibly a 4 tb or bigger so I won't have to worry about it any time soon. Do you have any suggestions for reliable HDDs that will last for a while? I'm looking for an internal that can be hooked up to the motherboard."},
{"Title": "Teracopy Cut/Paste", "Author": "u/rickydumpling", "Content": "Does anyone know how Teracopy handles cutting and pasting? I interrupted it while moving multiple folders with verify enabled and I can’t find one of the original folders. Just wondering if this means that Teracopy finished pasting, verified, then deleted the original folder or something else."},
{"Title": "Big off-line database for recipes?", "Author": "u/CamT86", "Content": "I'm about to start compiling some recipes for offline use(ideally in a way that'll be easy to view on a tablet, either in its memory or from a home server) and i was wondering if maybe there was already something similar thats already been set up, that i could work from rather than start from scratch. I dont really have any bright ideas on how to do this.\n  \n\n    In 2 weeks i'll need to go to a remote cabin with really poor internet connection(old style satellite shared between 8 households, thats barely better than 56k... not the elon musk new stuff) and cook for a few families that are also staying out there for summer. I'm sure this time I could literally just bring a cookbook and maybe a few printouts for what i need, but id like to set something up for future use as well.\nThey already have a small server set up with i think Kodi or plex that gets dragged back to civilization every few months for updates, so i figure i could just add whatever database file/system to that, to also be accessible to the person doing the cooking."},
{"Title": "Easy store external hard drive not mounting", "Author": "u/JessSerrano", "Content": "Hello! I have an Apple MacBook and I have the 2TB EasyStore external hard drive.\n  \n\n    I plug it in and sometimes it mounts, sometimes it doesn’t. I have another external hard drive (Seagate) that mounts with no issues. I changed cords too and my EasyStore isn’t mounting. Sometimes it does, though, which is odd. The light always turns on when I plug the cord into my Mac. Any suggestions on how to fix this? Thank you!"},
{"Title": "I just need a a quiet always on network disk without all the usual NAS apps/features.", "Author": "u/largePenisLover", "Content": "The only thing missing from my setup is a simple NAS like 4tb volume that I can split into two partitions or shares, running on a very quiet always on device.\nI've been looking at NAS solutions for this but these do wayyyy to much feature wise and often have a weird walled gardenish approaches to things.\nLike this device that looks perfect, synology BeeDrive, apparently needs to be controlled VIA a synology run web service and has undeletable folders related to photo and video apps. Less idiot proof devices don't have this nonsense but are weird about backing them up.\nIt all feels very bloatwary to a home-NAS newbie\n  \n\n    I JUST need a dumb networked file box WITHOUT all the apps and features QNAP and Synolgoy bring to the table.\nI need it to be JUST a network share that I can access from any device on my home network using the file browsers on those devices.\nNo video managers, DSM's, BSM's, photo managers, or any of the usual stuff. Just files, in a file browser, that I can doubleclick to open.\nJut a dumb, \nquiet\n, reliable, file box.\n  \n\n    I want to be able to backup this dumb file box by mapping it to a drive letter on the backup pc and then run my backup script.\nNo bullshit with installing third party synology/qnap/whatever software, I just want to integrate it in my existing backup solutions and ignore what vendors want me to do.\n  \n\n    Does anyone know if such a dumb file box is available as an off the shelf product?"},
{"Title": "Looking for good a good place to buy NAS HDD in Australia", "Author": "u/NZ_I3east", "Content": "Looking for some suggestions on an online retail other than Amazon in Australia.\n  \n\n    I have been eyeing out Seagate 16TB in Amazon but based on the comments I believe they are recertified. I personally don't really mind recertified stuff since the price is decent and I do have backups. I was just wondering if there are other online shops I could be looking that has better deals than Amazon in general."},
{"Title": "Powered down some HSGT workhorses today for not quite the last time - SMART stats are insane.", "Author": "u/platformterrestial", "Content": "We powered down an old storage server today and I took a few drives home partially to re-use and partially to check the SMART data.\n  \n\n    94568 power on hours, 23 spin ups. Still cranking away happily.\n  \nhttps://preview.redd.it/powered-down-some-hsgt-workhorses-today-for-not-quite-the-v0-8hl946jqa85d1.png"},
{"Title": "when your hdd order is delayed for the 3rd time you really learn what files are important to you", "Author": "u/d1ckpunch68", "Content": "No content"},
{"Title": "Does Google Cloud have a migration tool from Google Workplace? (Shared Drive --> GCS Archive)", "Author": "u/mcrsquared", "Content": "I'm finally trying to do something about my Google Workspace archive, and I'm getting caught in a doom spiral between Google Cloud and Google Workplace support.\n  \n\n    I have about 100TB and growing on Shared Drives within Google Workspace (legacy Google Apps / Unlimited / etc.). I want to move it to Google Cloud Storage...according to my calculations, Archive storage will be about 50% cheaper. This is redundancy to my NAS and local backups.\n  \n\n    Is there a migration tool to move within Google Cloud (from Workspace to Cloud Storage)? The support flow so far has just activated my Cloud 90-day trial.\n  \n\n    I used Syncovery back in the day to get everything uploaded to Drive, but it now looks blocked when I try to sign in with my Google Cloud account. And, of course, moving within Google Cloud would be a lot faster and simpler than downloading and re-uploading.\n  \n\n    Thanks, cheers."},
{"Title": "Jumper pins on exos x18 14tb", "Author": "u/ctles", "Content": "Figured i might try here in that probably lots of people would have the 14tb exos here:\nWhat's the 4 jumper pins next to the SATA data for, see image below. I've looked through the main document i could find and asked a rep in seagate chat but he could only provide me what jumper pins may be for and his doc said the drive didn't have any jumper pins. But clearly they're there:\n  \n\n\nhttps://www.kitguru.net/wp-content/uploads/2018/11/Seagate-Exos-X14-14TB-Hard-Drive-Review-on-KitGuru-SATA-Connectors.png"},
{"Title": "Recommended storage configurations for basic self hosted media and cloud storage replacement.", "Author": "u/robdupre", "Content": "Hi All,\n  \n\n    Hopefully a simple question for the experts!\n  \n\n    I have a Lenovo M600 on a 1GB home network (could be upgraded to be fair...), its running home assistant, Plex, the arr suit for downloading media and I would like to replace dropbox/google drive and ICloud with nextCloud or similar.\n  \n\n    Currently, given the small form factor, I have a 2TB SSD (already 75% full) and a 500GB M.2, running the OS. Currently there is no backup (at the moment this is not super terrible, nothing is that important... yet!).\n  \n\n    I would like to increase this storage and add backup. I am not super worried about 3-2-1 coverage, but definitely a nightly backup of everything would be good especially when we move away from the cloud storage suppliers for our photos etc.\n  \n\n    So what is the best option:\n  \n\n\n\n\n\n    Replace SSD with a 4TB (£225), add a 6TB (£120) external USB drive and manage nightly backups. This is cheapest, but least long lasting the 2TB filled up fast and I expect even going to 4TB will not be enough longer term.\n  \n\n\n\n\n\n    Get a 2 bay USB3 external caddy (£50-150???) and add 2 x 8TB drives (£270). Use this as both primary media storage and secondary backup (assume this is not advised? Whats the view of applications like plex running over USB storage...?).\n  \n\n\n\n\n\n    Just go with a NAS, in which case id go with a 4 bay something £??? open to suggestions here, 2x8TB £270, in which case it feels the M600 is mostly redundant, i expect this is also the most expensive option.\n  \n\n\n\n\n\n    better cheaper and all round wonderful thing I have not thought of?\n  \n\n\n\n\n\n    Be great to have some thoughts."},
{"Title": "Still not over the fact after close to 20 years Apple/iTunes/Apple TV lowers their movie trailer encode rate not just for new encodes/trailers but all prexisting encodes/trailers too", "Author": "u/ekos_640", "Content": "You can still download trailers from Apple though it's just a step or two more now - but they went from 9mbps on their movie trailer encodes since 2005-2006 until about 2022 when they redid everything on their backend and killed the old iTunes movie trailers site and moved it to Apple TV down to 6mbps\n  \n\n    Guess they wanted to start saving on storage/bandwith costs over the cost of the old files\n  \n\n    This wasn't just for new trailers from then on, but all preexisting trailers too :(\n  \n\n    Already have some 'older' movies I added to Plex I could have grabbed better trailers for then but didn't know I wanted the movies yet or changed my mind since I initially saw them :(\n  \n\n    We used to live in an age of opulence :("},
{"Title": "Fast write speed small capacity USB Flash Drive", "Author": "u/Eidbanger", "Content": "Searching for a small capacity (due to expecting lower price) flash drive which has fast write speeds. I found a \n$32 Kingston DataTraveler Max 256 GB\n with up to 900 MB/s write but curious to hear if there's anything from 500 MB/s write for cheaper (~$10-20)?\nI'll be using this for creating bootable ISO images."},
{"Title": "Looking for photo library app with selective sync", "Author": "u/Anubis2k", "Content": "Hey,\n  \n\n    I'm searching for a photo library app that handles use cases where your smartphone has not enough capacity for all your photos/videos but you still want to have all of them accessible.\n  \n\n    Essentially:\n  \n\n\n\n\n\n    Performant enough to replace the phone's gallery app in day-to-day use\n  \n\n\n\n\n\n    Syncing ability (either self-hosted or Cloud-based), including some kind of selective sync, e.g. to keep enough images local to fill a certain amount of space, but automatically remove old ones locally if you take new ones\n  \n\n\n\n\n\n    Sync albums\n  \n\n\n\n\n\n    Offline support (at least for those that are synced locally)\n  \n\n\n\n\n\n    Support of Android, Windows, and Mac OS X (or Web-based for non-mobile)\n  \n\n\n\n\n\n    Does anyone know of an app that supports all of that? I tested out 15+ apps, but none came close except Mylio Photos. Unfortunately, Mylio turned out to be incredibly unreliable, thus not an option for one's most cherished memories.\n  \n\n    I would appreciate any and all recommendations. Thanks!"},
{"Title": "40Gb/s fiber in Finland is o so tempting for Torrents and Usenet...", "Author": "u/Rugta", "Content": "No content"},
{"Title": "Is there any news about Redfox AnyDVD being taken down?", "Author": "u/brandonyoung", "Content": "I use AnyDVD  as an easy way to make backup iso images of my DVDs and blurays.  I just noticed their forums now come up with an error page, and their main website  domain name no longer resolves to a site. \nhttp://www.redfox.bz/\n\n\n\n    Has their been any news of them going out of business or being taken down?  I tried Google search, but I haven't found anything.\n  \n\n    As an alternative, I can use makemkv to copy the folders, or just the video files. but it isn't the same.   I find backing up to iso image files easier for me to manage and organize my backups.  I tried using imgburn to copy the files to  an iso.  But VLC wouldn't play it.  Maybe I messed up somewhere in the settings  when creating the iso image from the backed up files?"},
{"Title": "Lib-gen question", "Author": "u/Hungry-Sentence-6722", "Content": "I’ve seen the direct download page for lib-gen sci-mag articles. I would like to understand how to convert all those files to the correct file name and extension. Libgen desktop is having issues with sourcing from mirrors.  I also don’t see the point in one by one files.. any advice? The metadata must be in the sql file but many pdf’s are just a few pages of a large book, I want to merge them all automatically."},
{"Title": "I don't trust raid 5", "Author": "u/obalobadik", "Content": "I have a 4-bay Asustor nas and 4x3TB HDD's. As for now I do not require more than 3TB raw storage and run the nas in raid 1 with only two drives.\n  \n\n    When I eventually want to increase my storage, I am sceptical to convert my volume to raid 5. Seeing the struggles involved with recovering data from an raid 5 array, I can't trust it as an option. I am more comfortable running two 2x3TB raid 1 array, since then I know that the data is formatted such that I can fetch it without rebuilding.  Even asustor themselves does not have a method of recovering the data from an raid 5 array. I have been using snapraid before, and that is has been feeling more safe, as  when a drive has failed, only the data on that drive has potentially been lost.\n  \n\n    Am I paranoid and recovering from raid 5 data loss not that troublesome? can you recover data from a single drive that is from a raid 5 array?"},
{"Title": "Just started VHS digitizing. Any tips for cable management?", "Author": "u/Applewoood", "Content": "No content"},
{"Title": "Decades since I was a teenager but sometimes 'You just don't understand me, Dad!' still applies.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Building a DIY JBOD", "Author": "u/OverlyBurntToast", "Content": "I have a bunch of old hard drives, and was wondering the best approach to putting them in some sort of DIY enclosure.\nMy first thought was to just buy a bunch of the super cheap SATA to USB converters and plug that into a USB hub (speed is a low priority), but that wont be able to power the 3.5 inch drives I have.\nI was wondering if I could power the hard drives using a spare PC PSU I have, and then connect the hard drives via some sort of SATA DATA to USB or something.\nDoes anyone have any ideas or hints, I would appreciate it greatly, as I am not too experienced in this field."},
{"Title": "Mid tower case vs 4U chassis for DIY NAS?", "Author": "u/Neurrone", "Content": "Hi,\n  \n\n    I'm currently looking to upgrade from an O11 air mini that only holds 4 drives because I realized it would be nice to have more drive slots and inadequate airflow causing some drives to run hot (ambient 28 C, idle 45, 51 under load). I made the mistake of choosing a case that only has as many drives that I had, so wanted to do it right this time. Use case is TrueNas with some apps, running on Ryzen 5700G to optimize for idle power consumption.\n  \n\n    I don't yet have a rack, but will be getting one when I move. Hence, I shortlisted some 4U rackmounts to place vertically first on a shelf:\n  \n\n\n\n\n\n\nLogic case sc-4316\n: US$350, 16 drives\n  \n\n\n\n\n\n\nSliger CX4712 \n: US$399, 12 drives. I'm leaning towards this\n  \n\n\n\n\n\n    These 4u cases aren't available for me locally - so estimated shipping to get either of those is an extra US$200, though I'm trying to find out if I can reduce that somehow.\n  \n\n    On the other hand,, a tower like the Fractal Meshify 2 (US$150) is much cheaper, and available to me locally, so I don't have to pay much for shipping. I could get 3 of these with the money needed to get the 4U.\n  \n\n    In this situation, are there enough advantages of those 4U cases to justify the extra expense? If I get a rack, I think I could place the Meshify 2 on its side on a shelf so that it only takes 6U.\n  \n\n    I'm new to rackmounted chassis, so these are the pros and cons I'm weighing, let me know if I missed anything.\n  \n\n    Pros:\n  \n\n\n\n\n\n    Support for redundant PSUs, hot swappable fans and drives for less uptime in case of a failure\n  \n\n\n\n\n\n    Support for larger motherboards: I currently have an ATX, not sure how useful support for larger form factors would be if I upgrade to lower end server boards\n  \n\n\n\n\n\n    Designed for rack mounting, smaller footprint\n  \n\n\n\n\n\n    Cons:\n  \n\n\n\n\n\n    Expensive\n  \n\n\n\n\n\n    Requires fan swaps for silence\n  \n\n\n\n\n\n    Higher drive temperatures? I assume drive temps would be worse compared to e.g, the meshify\n  \n\n\n\n\n\n    Won't fit my 160 mm cooler\n  \n\n\n\n\n\n    Thanks for reading!"},
{"Title": "What is the best software for testing a drives reads and writes until failure (RAID 5 with Windows)", "Author": "u/Appropriate_Face8497", "Content": "I have a RAID 5 configuration on a windows system and I would like to see how many reads and writes it will take for me to kill one of the drives in the configuration. Everywhere I look people are talking about smartctl conveyance test, badblocks, and SMART. But these seem to be Linux utilities and I need to test on windows. Also it is not clear that these are designed to test the drive till failure.\n  \n\n    I would be able to use the eventviewer logs to compare drive failure time stamp with the corresponding timestamp of the testing software. For which I would assume the testing software logs the total number of reads and writes at a certain timestamp."},
{"Title": "Recommendations for optimal Backplane and HBA Card for High-Speed Cloud Storage Server", "Author": "u/One-Definition-not", "Content": "Hello Dear,\n  \n\n    I have a server with a 24-bay 3.5\" SAS2 expansion (\nBPN-SAS2-846EL\n) backplane, which seems to be malfunctioning. I am looking to replace it, as I am running cloud storage where speed is critical. I want a backplane without expansion capability, and I plan to use 24TB WD Red Pro hard drives.\n  \n\n    My question is: what backplane and HBA card would be the best option for me? I was considering the \nBPN-SAS-846A\n, but I couldn't find much information about its speed.\n  \n\n    Here are the server details:\n  \n\n\n\n\n\n    Chassis: \nSupermicro 846\n, 24-bay 3.5\"\n  \n\n\n\n\n\n    Motherboard: \nSupermicro X11DPI-NT,\n dual socket 3467\n  \n\n\n\n\n\n    CPUs: 2x Xeon Gold 6148\n  \n\n\n\n\n\n    RAM: 12x Samsung 32GB DDR4 2666 MHz ECC REG (M393A4K40CB2-CTD RDIMM)\n  \n\n\n\n\n\n    Expansion Card: ASUS Hyper M.2 X16\n  \n\n\n\n\n\n    NVMe SSDs: 8x WD Red SN700 NVMe SSD 4TB\n  \n\n\n\n\n\n    Hard Drives: 24x 24TB WD Red Pro\n  \n\n\n\n\n\n    I appreciate any recommendations or insights you can provide.\n  \n\n    Thank you!"},
{"Title": "Portable (no-install) backup software for Windows?", "Author": "u/nefarious_bumpps", "Content": "I'm looking for a portable backup utility for Windows 10/11 desktops/laptops that can run from a USB drive without installation and perform disk image and full volume/partition backups and restores quickly to a USB external hdd/ssd.\n  \n\n    Free or reasonably-priced (under $150) commercial license.\n  \n\n    Any suggestions?"},
{"Title": "I'm running low on space in my custom built tower, what internal HDD's would you recommend?", "Author": "u/AVoraciousLatias", "Content": "Hi there, I have a 1 tb HDD and a 1 tb SDD. I'm looking to upgrade my HDD so I can store more games and programs on it, I'm looking for possibly a 4 tb or bigger so I won't have to worry about it any time soon. Do you have any suggestions for reliable HDDs that will last for a while? I'm looking for an internal that can be hooked up to the motherboard."},
{"Title": "Teracopy Cut/Paste", "Author": "u/rickydumpling", "Content": "Does anyone know how Teracopy handles cutting and pasting? I interrupted it while moving multiple folders with verify enabled and I can’t find one of the original folders. Just wondering if this means that Teracopy finished pasting, verified, then deleted the original folder or something else."},
{"Title": "Big off-line database for recipes?", "Author": "u/CamT86", "Content": "I'm about to start compiling some recipes for offline use(ideally in a way that'll be easy to view on a tablet, either in its memory or from a home server) and i was wondering if maybe there was already something similar thats already been set up, that i could work from rather than start from scratch. I dont really have any bright ideas on how to do this.\n  \n\n    In 2 weeks i'll need to go to a remote cabin with really poor internet connection(old style satellite shared between 8 households, thats barely better than 56k... not the elon musk new stuff) and cook for a few families that are also staying out there for summer. I'm sure this time I could literally just bring a cookbook and maybe a few printouts for what i need, but id like to set something up for future use as well.\nThey already have a small server set up with i think Kodi or plex that gets dragged back to civilization every few months for updates, so i figure i could just add whatever database file/system to that, to also be accessible to the person doing the cooking."},
{"Title": "Easy store external hard drive not mounting", "Author": "u/JessSerrano", "Content": "Hello! I have an Apple MacBook and I have the 2TB EasyStore external hard drive.\n  \n\n    I plug it in and sometimes it mounts, sometimes it doesn’t. I have another external hard drive (Seagate) that mounts with no issues. I changed cords too and my EasyStore isn’t mounting. Sometimes it does, though, which is odd. The light always turns on when I plug the cord into my Mac. Any suggestions on how to fix this? Thank you!"},
{"Title": "I just need a a quiet always on network disk without all the usual NAS apps/features.", "Author": "u/largePenisLover", "Content": "The only thing missing from my setup is a simple NAS like 4tb volume that I can split into two partitions or shares, running on a very quiet always on device.\nI've been looking at NAS solutions for this but these do wayyyy to much feature wise and often have a weird walled gardenish approaches to things.\nLike this device that looks perfect, synology BeeDrive, apparently needs to be controlled VIA a synology run web service and has undeletable folders related to photo and video apps. Less idiot proof devices don't have this nonsense but are weird about backing them up.\nIt all feels very bloatwary to a home-NAS newbie\n  \n\n    I JUST need a dumb networked file box WITHOUT all the apps and features QNAP and Synolgoy bring to the table.\nI need it to be JUST a network share that I can access from any device on my home network using the file browsers on those devices.\nNo video managers, DSM's, BSM's, photo managers, or any of the usual stuff. Just files, in a file browser, that I can doubleclick to open.\nJut a dumb, \nquiet\n, reliable, file box.\n  \n\n    I want to be able to backup this dumb file box by mapping it to a drive letter on the backup pc and then run my backup script.\nNo bullshit with installing third party synology/qnap/whatever software, I just want to integrate it in my existing backup solutions and ignore what vendors want me to do.\n  \n\n    Does anyone know if such a dumb file box is available as an off the shelf product?"},
{"Title": "Looking for good a good place to buy NAS HDD in Australia", "Author": "u/NZ_I3east", "Content": "Looking for some suggestions on an online retail other than Amazon in Australia.\n  \n\n    I have been eyeing out Seagate 16TB in Amazon but based on the comments I believe they are recertified. I personally don't really mind recertified stuff since the price is decent and I do have backups. I was just wondering if there are other online shops I could be looking that has better deals than Amazon in general."},
{"Title": "Powered down some HSGT workhorses today for not quite the last time - SMART stats are insane.", "Author": "u/platformterrestial", "Content": "We powered down an old storage server today and I took a few drives home partially to re-use and partially to check the SMART data.\n  \n\n    94568 power on hours, 23 spin ups. Still cranking away happily.\n  \nhttps://preview.redd.it/powered-down-some-hsgt-workhorses-today-for-not-quite-the-v0-8hl946jqa85d1.png"},
{"Title": "when your hdd order is delayed for the 3rd time you really learn what files are important to you", "Author": "u/d1ckpunch68", "Content": "No content"},
{"Title": "Does Google Cloud have a migration tool from Google Workplace? (Shared Drive --> GCS Archive)", "Author": "u/mcrsquared", "Content": "I'm finally trying to do something about my Google Workspace archive, and I'm getting caught in a doom spiral between Google Cloud and Google Workplace support.\n  \n\n    I have about 100TB and growing on Shared Drives within Google Workspace (legacy Google Apps / Unlimited / etc.). I want to move it to Google Cloud Storage...according to my calculations, Archive storage will be about 50% cheaper. This is redundancy to my NAS and local backups.\n  \n\n    Is there a migration tool to move within Google Cloud (from Workspace to Cloud Storage)? The support flow so far has just activated my Cloud 90-day trial.\n  \n\n    I used Syncovery back in the day to get everything uploaded to Drive, but it now looks blocked when I try to sign in with my Google Cloud account. And, of course, moving within Google Cloud would be a lot faster and simpler than downloading and re-uploading.\n  \n\n    Thanks, cheers."},
{"Title": "Jumper pins on exos x18 14tb", "Author": "u/ctles", "Content": "Figured i might try here in that probably lots of people would have the 14tb exos here:\nWhat's the 4 jumper pins next to the SATA data for, see image below. I've looked through the main document i could find and asked a rep in seagate chat but he could only provide me what jumper pins may be for and his doc said the drive didn't have any jumper pins. But clearly they're there:\n  \n\n\nhttps://www.kitguru.net/wp-content/uploads/2018/11/Seagate-Exos-X14-14TB-Hard-Drive-Review-on-KitGuru-SATA-Connectors.png"},
{"Title": "Recommended storage configurations for basic self hosted media and cloud storage replacement.", "Author": "u/robdupre", "Content": "Hi All,\n  \n\n    Hopefully a simple question for the experts!\n  \n\n    I have a Lenovo M600 on a 1GB home network (could be upgraded to be fair...), its running home assistant, Plex, the arr suit for downloading media and I would like to replace dropbox/google drive and ICloud with nextCloud or similar.\n  \n\n    Currently, given the small form factor, I have a 2TB SSD (already 75% full) and a 500GB M.2, running the OS. Currently there is no backup (at the moment this is not super terrible, nothing is that important... yet!).\n  \n\n    I would like to increase this storage and add backup. I am not super worried about 3-2-1 coverage, but definitely a nightly backup of everything would be good especially when we move away from the cloud storage suppliers for our photos etc.\n  \n\n    So what is the best option:\n  \n\n\n\n\n\n    Replace SSD with a 4TB (£225), add a 6TB (£120) external USB drive and manage nightly backups. This is cheapest, but least long lasting the 2TB filled up fast and I expect even going to 4TB will not be enough longer term.\n  \n\n\n\n\n\n    Get a 2 bay USB3 external caddy (£50-150???) and add 2 x 8TB drives (£270). Use this as both primary media storage and secondary backup (assume this is not advised? Whats the view of applications like plex running over USB storage...?).\n  \n\n\n\n\n\n    Just go with a NAS, in which case id go with a 4 bay something £??? open to suggestions here, 2x8TB £270, in which case it feels the M600 is mostly redundant, i expect this is also the most expensive option.\n  \n\n\n\n\n\n    better cheaper and all round wonderful thing I have not thought of?\n  \n\n\n\n\n\n    Be great to have some thoughts."},
{"Title": "Still not over the fact after close to 20 years Apple/iTunes/Apple TV lowers their movie trailer encode rate not just for new encodes/trailers but all prexisting encodes/trailers too", "Author": "u/ekos_640", "Content": "You can still download trailers from Apple though it's just a step or two more now - but they went from 9mbps on their movie trailer encodes since 2005-2006 until about 2022 when they redid everything on their backend and killed the old iTunes movie trailers site and moved it to Apple TV down to 6mbps\n  \n\n    Guess they wanted to start saving on storage/bandwith costs over the cost of the old files\n  \n\n    This wasn't just for new trailers from then on, but all preexisting trailers too :(\n  \n\n    Already have some 'older' movies I added to Plex I could have grabbed better trailers for then but didn't know I wanted the movies yet or changed my mind since I initially saw them :(\n  \n\n    We used to live in an age of opulence :("},
{"Title": "Fast write speed small capacity USB Flash Drive", "Author": "u/Eidbanger", "Content": "Searching for a small capacity (due to expecting lower price) flash drive which has fast write speeds. I found a \n$32 Kingston DataTraveler Max 256 GB\n with up to 900 MB/s write but curious to hear if there's anything from 500 MB/s write for cheaper (~$10-20)?\nI'll be using this for creating bootable ISO images."},
{"Title": "Looking for photo library app with selective sync", "Author": "u/Anubis2k", "Content": "Hey,\n  \n\n    I'm searching for a photo library app that handles use cases where your smartphone has not enough capacity for all your photos/videos but you still want to have all of them accessible.\n  \n\n    Essentially:\n  \n\n\n\n\n\n    Performant enough to replace the phone's gallery app in day-to-day use\n  \n\n\n\n\n\n    Syncing ability (either self-hosted or Cloud-based), including some kind of selective sync, e.g. to keep enough images local to fill a certain amount of space, but automatically remove old ones locally if you take new ones\n  \n\n\n\n\n\n    Sync albums\n  \n\n\n\n\n\n    Offline support (at least for those that are synced locally)\n  \n\n\n\n\n\n    Support of Android, Windows, and Mac OS X (or Web-based for non-mobile)\n  \n\n\n\n\n\n    Does anyone know of an app that supports all of that? I tested out 15+ apps, but none came close except Mylio Photos. Unfortunately, Mylio turned out to be incredibly unreliable, thus not an option for one's most cherished memories.\n  \n\n    I would appreciate any and all recommendations. Thanks!"},
{"Title": "40Gb/s fiber in Finland is o so tempting for Torrents and Usenet...", "Author": "u/Rugta", "Content": "No content"},
{"Title": "Is there any news about Redfox AnyDVD being taken down?", "Author": "u/brandonyoung", "Content": "I use AnyDVD  as an easy way to make backup iso images of my DVDs and blurays.  I just noticed their forums now come up with an error page, and their main website  domain name no longer resolves to a site. \nhttp://www.redfox.bz/\n\n\n\n    Has their been any news of them going out of business or being taken down?  I tried Google search, but I haven't found anything.\n  \n\n    As an alternative, I can use makemkv to copy the folders, or just the video files. but it isn't the same.   I find backing up to iso image files easier for me to manage and organize my backups.  I tried using imgburn to copy the files to  an iso.  But VLC wouldn't play it.  Maybe I messed up somewhere in the settings  when creating the iso image from the backed up files?"},
{"Title": "Lib-gen question", "Author": "u/Hungry-Sentence-6722", "Content": "I’ve seen the direct download page for lib-gen sci-mag articles. I would like to understand how to convert all those files to the correct file name and extension. Libgen desktop is having issues with sourcing from mirrors.  I also don’t see the point in one by one files.. any advice? The metadata must be in the sql file but many pdf’s are just a few pages of a large book, I want to merge them all automatically."},
{"Title": "I don't trust raid 5", "Author": "u/obalobadik", "Content": "I have a 4-bay Asustor nas and 4x3TB HDD's. As for now I do not require more than 3TB raw storage and run the nas in raid 1 with only two drives.\n  \n\n    When I eventually want to increase my storage, I am sceptical to convert my volume to raid 5. Seeing the struggles involved with recovering data from an raid 5 array, I can't trust it as an option. I am more comfortable running two 2x3TB raid 1 array, since then I know that the data is formatted such that I can fetch it without rebuilding.  Even asustor themselves does not have a method of recovering the data from an raid 5 array. I have been using snapraid before, and that is has been feeling more safe, as  when a drive has failed, only the data on that drive has potentially been lost.\n  \n\n    Am I paranoid and recovering from raid 5 data loss not that troublesome? can you recover data from a single drive that is from a raid 5 array?"},
{"Title": "Just started VHS digitizing. Any tips for cable management?", "Author": "u/Applewoood", "Content": "No content"},
{"Title": "Decades since I was a teenager but sometimes 'You just don't understand me, Dad!' still applies.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Building a DIY JBOD", "Author": "u/OverlyBurntToast", "Content": "I have a bunch of old hard drives, and was wondering the best approach to putting them in some sort of DIY enclosure.\nMy first thought was to just buy a bunch of the super cheap SATA to USB converters and plug that into a USB hub (speed is a low priority), but that wont be able to power the 3.5 inch drives I have.\nI was wondering if I could power the hard drives using a spare PC PSU I have, and then connect the hard drives via some sort of SATA DATA to USB or something.\nDoes anyone have any ideas or hints, I would appreciate it greatly, as I am not too experienced in this field."},
{"Title": "Mid tower case vs 4U chassis for DIY NAS?", "Author": "u/Neurrone", "Content": "Hi,\n  \n\n    I'm currently looking to upgrade from an O11 air mini that only holds 4 drives because I realized it would be nice to have more drive slots and inadequate airflow causing some drives to run hot (ambient 28 C, idle 45, 51 under load). I made the mistake of choosing a case that only has as many drives that I had, so wanted to do it right this time. Use case is TrueNas with some apps, running on Ryzen 5700G to optimize for idle power consumption.\n  \n\n    I don't yet have a rack, but will be getting one when I move. Hence, I shortlisted some 4U rackmounts to place vertically first on a shelf:\n  \n\n\n\n\n\n\nLogic case sc-4316\n: US$350, 16 drives\n  \n\n\n\n\n\n\nSliger CX4712 \n: US$399, 12 drives. I'm leaning towards this\n  \n\n\n\n\n\n    These 4u cases aren't available for me locally - so estimated shipping to get either of those is an extra US$200, though I'm trying to find out if I can reduce that somehow.\n  \n\n    On the other hand,, a tower like the Fractal Meshify 2 (US$150) is much cheaper, and available to me locally, so I don't have to pay much for shipping. I could get 3 of these with the money needed to get the 4U.\n  \n\n    In this situation, are there enough advantages of those 4U cases to justify the extra expense? If I get a rack, I think I could place the Meshify 2 on its side on a shelf so that it only takes 6U.\n  \n\n    I'm new to rackmounted chassis, so these are the pros and cons I'm weighing, let me know if I missed anything.\n  \n\n    Pros:\n  \n\n\n\n\n\n    Support for redundant PSUs, hot swappable fans and drives for less uptime in case of a failure\n  \n\n\n\n\n\n    Support for larger motherboards: I currently have an ATX, not sure how useful support for larger form factors would be if I upgrade to lower end server boards\n  \n\n\n\n\n\n    Designed for rack mounting, smaller footprint\n  \n\n\n\n\n\n    Cons:\n  \n\n\n\n\n\n    Expensive\n  \n\n\n\n\n\n    Requires fan swaps for silence\n  \n\n\n\n\n\n    Higher drive temperatures? I assume drive temps would be worse compared to e.g, the meshify\n  \n\n\n\n\n\n    Won't fit my 160 mm cooler\n  \n\n\n\n\n\n    Thanks for reading!"},
{"Title": "What is the best software for testing a drives reads and writes until failure (RAID 5 with Windows)", "Author": "u/Appropriate_Face8497", "Content": "I have a RAID 5 configuration on a windows system and I would like to see how many reads and writes it will take for me to kill one of the drives in the configuration. Everywhere I look people are talking about smartctl conveyance test, badblocks, and SMART. But these seem to be Linux utilities and I need to test on windows. Also it is not clear that these are designed to test the drive till failure.\n  \n\n    I would be able to use the eventviewer logs to compare drive failure time stamp with the corresponding timestamp of the testing software. For which I would assume the testing software logs the total number of reads and writes at a certain timestamp."},
{"Title": "Recommendations for optimal Backplane and HBA Card for High-Speed Cloud Storage Server", "Author": "u/One-Definition-not", "Content": "Hello Dear,\n  \n\n    I have a server with a 24-bay 3.5\" SAS2 expansion (\nBPN-SAS2-846EL\n) backplane, which seems to be malfunctioning. I am looking to replace it, as I am running cloud storage where speed is critical. I want a backplane without expansion capability, and I plan to use 24TB WD Red Pro hard drives.\n  \n\n    My question is: what backplane and HBA card would be the best option for me? I was considering the \nBPN-SAS-846A\n, but I couldn't find much information about its speed.\n  \n\n    Here are the server details:\n  \n\n\n\n\n\n    Chassis: \nSupermicro 846\n, 24-bay 3.5\"\n  \n\n\n\n\n\n    Motherboard: \nSupermicro X11DPI-NT,\n dual socket 3467\n  \n\n\n\n\n\n    CPUs: 2x Xeon Gold 6148\n  \n\n\n\n\n\n    RAM: 12x Samsung 32GB DDR4 2666 MHz ECC REG (M393A4K40CB2-CTD RDIMM)\n  \n\n\n\n\n\n    Expansion Card: ASUS Hyper M.2 X16\n  \n\n\n\n\n\n    NVMe SSDs: 8x WD Red SN700 NVMe SSD 4TB\n  \n\n\n\n\n\n    Hard Drives: 24x 24TB WD Red Pro\n  \n\n\n\n\n\n    I appreciate any recommendations or insights you can provide.\n  \n\n    Thank you!"},
{"Title": "Complete noob needs some guidance on NAS purchase and setup.", "Author": "u/Wdowiak", "Content": "Hey,\n  \n\n    To preamble, I am complete noob when it comes to storage/NAS and don't know anything. Anything in here is stuff I gathered up from reading some posts.\n  \n\n    My current storage setup is almost non existant. Most important things are simply \"backed up\" multiple times manually on each random drive I have on a couple of PCs, with some data on OneDrive and GDrive.\n  \n\n    So long story short, I need a main NAS mainly for a redundancy QOL (better late than never):\n  \n\n\n\n\n\n    Single place where I can upload all my data, as currently it's heavily scattered and duplicated.\n  \n\n\n\n\n\n    I want the data to be synced to other endpoints automatically for backup:\n  \n\n\n\n\n\n    NAS in another location as additional backup, not used for anything else. Probably simple two bay 2x16TB - and probably RAID 1. Don't have one yet, will most likely setup once I get this one going.\n  \n\n\n\n\n\n    16TB drive on my second PC, as another backup\n  \n\n\n\n\n\n    Locally encrypting files before cloud syncing. Only important files, so about ~1-2TB. Probably OneDrive, since I already have some space there and potentially one other in the future, like blackbaze. (heard about rclone, not sure if this is good or there are better alternatives).\n  \n\n\n\n\n\n    Two seperate external 8TB drives for important data and p4/git only, with manual syncing once a month or two, alterneting between the drives (just a failsafe in case of corrupted data being synced to other endpoints)\n  \n\n\n\n\n\n\n\n\n\n    Local Perforce / Git servers ~2TB (later on, I'll be making seperate server for that, so it's just for a year, maybe two).\n  \n\n\n\n\n\n    The Data:\n  \n\n\n\n\n\n    Most important files ~1-2TB (mostly personal photos/videos/docs). These files will be rarely accessed. Once I get them all sorted into a single location, I was thinking of burning them on BD-R disks.\n  \n\n\n\n\n\n    Other files to sync - ~3TB\n  \n\n\n\n\n\n    Random stuff that I don't care for loosing, few TBs, no syncing to other endpoints.\n  \n\n\n\n\n\n\n\n\n\n    Files will be uploaded to the NAS manually (e.g. when dumping photos from my phone).\n  \n\n    My main need is redundancy and potentially ensuring I don't sync corrupted files to other endpoints (so some kind of checksums when uploading stuff to the NAS and prevent syncing corrupted ones). Warning when corrupted files are detected would be great.\n  \n\n    I don't need much speed in day to day operations (not sure if it's needed by the NAS itself in case of drive failure). Other than P4/Git, all data will be accessed very rarely (maybe a couple times a year).\n  \n\n    My current idea was to get DS1522+ with either 8TB or 16TB drives and go with RAID 6, unless there better setups for redundency and my specific needs, as I don't know anything.\n  \n\n    Drives, these are currently my main ideas, unless you can recommend better ones:\n  \n\n\n\n\n\n    16TB WUH721816ALE6L4\n  \n\n\n\n\n\n    8TB WD8003FFBX or 16TB WD161KFGX\n  \n\n\n\n\n\n    So, my initial questions:\n  \n\n\n\n\n\n    Do you have any guidence for hardware (nas/drives), software (syncing/checksums), storage setup (raid 6 or something else?) and workflows on how should I go on about this setup?\n  \n\n\n\n\n\n    Do I go with synology or build myself? I can build PCs, but perosnally would like something that I have a less chance of screwing up.\n  \n\n\n\n\n\n    What to use for syncing into other endpoints and how can I ensure I am not syncing corrupted data?\n  \n\n\n\n\n\n    Do I need UPS for the NAS during normal operations (e.g. idling or simply copying) to prevent potential corruptions?\n  \n\n\n\n\n\n    How do I periodically check if all the files all alright (no corruptions or anything) from their initial state?\n  \n\n\n\n\n\n    Other tips?\n  \n\n\n\n\n\n    Thanks!"},
{"Title": "IT BEGINS!", "Author": "u/pele4096", "Content": "No content"},
{"Title": "Jonsbo announces the N5 case", "Author": "u/Ben4425", "Content": "Nascompares just posted a description of the new \nJonsbo N5 case\n. It's a \nbeast\n with space for up to \n12\n 3.5\" drives and motherboard support for mITX, mATX, ATX, and E-ATX all with full-height PCIe cards."},
{"Title": "Another Hardware / Software / Raid / Sync Recommendation for Windows File Server", "Author": "u/westopants", "Content": "What I already have to work with\n  \n\n    Windows 11 Pro File Server. Modern hardware.\n  \n\n    2x 22tb ironwolf pro , + ext 22 wd + carbonite.\n  \n\n    Currently on this setup there is a 22tb data drive, with 1 internal incremental backup and 1 ext inc bkp. The thought of downtime restoring the data drive is my biggest concern. Reliability and Ease of use are top priorities. This is for a business with 5-10 users accessing the data. SMART or similar remote management capabilities are also important.\n  \n\n    ...... Traditionally have worked mostly with 1-4tb systems. Back in the day would use 2 drives in Allway-Sync ,, and even further back some Hardware raid cards.\n  \n\n    I've read Hardware raid is somewhat dead, but still in use. I would be ok with a card, but it would need to be brand new card. I like the idea of those used enterprise cards, but new is much more ideal and require low cost.\n  \n\n    Windows storage spaces sounds decent. Some articles mention it is not as reliable.\n  \n\n    I'm not going linux at this time\n  \n\n    I havn't yet looked into drivepool or snap raid or know what they really do\n  \n\n    I'm ready the smear campaign...."},
{"Title": "Buy used HD ?", "Author": "u/True-Entrepreneur851", "Content": "I am in China and some sellers here propose good price for used WD NAS drives like 20 000 hours. Sorry for silly question if sounds like this but would you recommend ?"},
{"Title": "How to crawl/grab 3mf/stil files from makerworld-com?", "Author": "u/Ok_Conversation2527", "Content": "During some free time i am going through interesting projects and mark them for me...\n  \n\n    then once  a month i review them and decide finally if i want to print them out.\nBut more and more of my \"likings\"/saved for later projects on \nmakerworld.com\n are being marked as offline after some time and i cannot even see which it was (having single option to remove from list without knowing what i am removing :S).\n  \n\n    Long story, short: i started to download projects \"almost\" immediately after liking and having by that a small archive. Trying to automate that, i am struggling a bit:\nLogin of \"google\"-auth-mechanism i tackled already. what i am facing right now is that neither via curl nor via \"HTTrack\" nor \"Offline Explorer\" i am able to get the download(s).\nLooking at the button it is a script which generates a one-time token for the actual file. and by that i am not aware how to grab that :S\n  \n\n    Any ideas/hints how to achieve that?\nI also played around with \"web scraper(io)\", but with no success."},
{"Title": "Help! I erased one of four RAID volumes set up with Disk Utilities", "Author": "u/peterinjapan", "Content": "Hi, I'm having an issue with a RAID with a volume I accidentally erased. My Yottamaster RAID started becoming unstable and was beeping all the time, so after giving up on it, I bought a Logitech enclosure and put the drives in, creating a RAID 5 volume with SoftRaid 8.\n  \n\n    After I got everything set up, of my disks disappeared from the new RAID, and as I was verifying the other three, another one gave me issues. So I decided to format the \"new\" disks and try again. I seem to have had one of the volumes in my old (backup) RAID selected, and erased it.\n  \n\n    The backup RAID was, I think, set up as two striped RAID volumes, which were then striped together to create a raid of that. This might not be the best way to do a RAID, but there was no option other than striped or mirrored disks, and at the time SoftRaid was not working with Apple Silicon at all.\n  \n\n    I have bought a large external disk to serve as a working disk to hopefully save my data. Can anyone suggest what will happen when I use the Restore option in Disk Utilities? If I can save the files and hopefully the folder structure, that will be good.  If there are any other tools besides Disk Utility I should be exploring, please let me know.\n  \n\n    Sending the disks to a data service isn't an option as I'm in rural Japan."},
{"Title": "Still trying to get the hand of Virtual Dub for transcribing my tapes", "Author": "u/KWalthersArt", "Content": "I am posting this so I can get answers while I sleep, I hope I'm not breaking any rules about redundent or stupid questions.\n  \n\n    So the problems I have are.\n  \n\n    Langrith compression seems to follow a high instance of dropped frames\n  \n\n    if I record to long audio and video goes out of sync.\n  \n\n    I don't know how to import my files into davinci for recompression in better lossless codec.\n  \n\n    I don't know how to install a better codec in VDub\n  \n\n    Some tapes have a whine sound on them.\n  \n\n    Set up.\n  \n\n    Gaming PC Intel Core i7\n  \n\n    Diamond VC500 usb card in a high level USB slot.\n  \n\n    Internal Hard drive then to external.\n  \n\n    Zenith XBR716 DVD-R VCR for play back.\n  \n\n    Most tapes are at SLP speed, I was a stupid teenager."},
{"Title": "Repairing drives…", "Author": "u/TwoRight9509", "Content": "A decade ago you’d send a broken drive to a place in California to get a repair / copy.\n  \n\n    How do we handle that now? Is there a best company to sent to?"},
{"Title": "How can I extract ColorNote notes?", "Author": "u/BlackJackT", "Content": "I have thousands... They are already backed up to Google Drive, but not as plain text as I'd like but rather through the app (whatever protocol that uses). I want to back them up as a CSV or XLSX but I'm not sure how that can be done.\n  \n\n    In addition to my request for help with a solution, here is something pretty concerning: I actually reached out to the company asking how I can do this, and take a look at their response: \nhttps://ibb.co/D9xBhXR\n Can they gain access to my notes by me just providing my account (i.e. email address)?"},
{"Title": "Retrieving Photos From iPhoto Library In Time Machine Backup", "Author": "u/Akura_Awesome", "Content": "I have about a decade’s worth of Time Machine back ups across a dozen external drives, all with disparate photo libraries on them.\n  \n\n    Is there any sure fire way to pull these libraries out with metadata to throw on my NAS?\n  \n\n    I’ve tried to pull them in before but I get notifications about version and key mismatches, not to mention they can be a pain to locate.\n  \n\n    Any ideas are appreciated!"},
{"Title": "2 part question.", "Author": "u/GrayManTech", "Content": "Hi.\n  \n\n    I have a bunch of DVDs that I want to convert to mp4 or whatever. I know I need a DVD player of some sort and software. I've seen here there are a couple of dvd players that don't need to be modified to use for this, but the posts I found were pretty old, have the available drives changed and if so which ones work out of the box?\n  \n\n    2nd part, storage. Is it possible to setup a Nas or something to use wifi so everyone in my house can access it? My router has a USB port but from what I understand it's disabled by xfinity. Basically I'm looking for something that can hold both 2.5 and 3.5 hdd since I already have both."},
{"Title": "Best Way to Convert Podcasts on Spotify?", "Author": "u/ShyGuyGaming76", "Content": "I listen to a lot of audio dramas, and with about two exceptions (The Magnus Archives and Kakos Industries) most of them are \nonly\n on Spotify, so I'm not really able to archive them conveniently. What I'm doing right now is just screen recording them and converting it to an audio file. However, this is \nungodly\n slow.\n  \n\n    Any better ways?"},
{"Title": "11 years ago I built a computer", "Author": "u/BinaryPatrickDev", "Content": "No content"},
{"Title": "Does this Buffalo Linksys NAS  have encryption?", "Author": "u/zemaacu001", "Content": "Help me data pros. I am have Link Station Buffalo NAS. LS220D0402B. Does this encrypt data inside? I don't know anything about NAS.\n  \n\n    I googled and found a post saying linksys doesn't support encryption, but TeraStation device does, but it seemed like an old post and I wasn't sure if it included my model.\n  \n\n    I didn't start using it yet since I don't think it encrypts data. If someone physically steals device, I think the data in device is vulnerable. Am I correct in thinking this? Is there anything I can do to encrypt it or would I have to buy a NAS that automatically encrypts the data?"},
{"Title": "Document Scanning Services", "Author": "u/JL4575", "Content": "I’m looking to scan a small collection of magazines, more than I want to manage manually. Each is stapled through the middle, not bound, and I would really like to not destroy the collection in getting them scanned. Can anyone recommend mail order services they’ve used?"},
{"Title": "G-RAID - Use built in HW RAID, Disk Utility RAID or something else?", "Author": "u/SuperChooch", "Content": "I have an older G-RAID device that is not supported by WD, attached to a Mac mini.    It is currently running G-RAID's hardware RAID at RAID 0 and I want to redeploy it for another purpose and make it RAID 1.  It is not mission critical and I'll be backing it up to another local location and to the cloud so if it craps out, it won't be the end of the world.  Should I continue to use G-RAID's RAID, should I use the Mac's Disk Utility RAID assistant or should I use something else?"},
{"Title": "CrcCheckCopy Software - Error reading the file. A random CRC will be given, to create an error when verifying.", "Author": "u/mrnngbgs", "Content": "Hello, I am in the middle of backing up my 18TB drive. I am not copying the files just yet. A few moments ago I finished creating a CRC hash checksum file using the CrcCheckCopy software and I am now running the verification in the background. Out of ~48,000 files, about 800 of them couldn't have been read and an error message was delivered for each one of them:\n  \n\n\nError reading the [FILENAME]. A random CRC will be given, to create an error when verifying.\n\n\n\n    I checked and I can manually open those files without any issues. Anyone more experienced with the software knows whether it is something I should worry about? CrystalDiskInfo says that my drive is OK."},
{"Title": "Photo and video sorting and recovering", "Author": "u/ravage007", "Content": "So I am a hoarder I've had several cell phones I have reimaged my computer countless times I have three to five hard drives with backups of my computer and all its files before I reformatted them I am looking for a program that can go through all my files and find my photos videos And compile them all into one area as well as helping me sort out duplicates for the best quality version a bonus would be nice if it could scan through my Google Drive photo bucket Amazon photo And maybe Facebook to find all my photos and videos so I can have one copy instead of 500 with an exponential amount\n  \n\n\nPlease note\n that I have a reading and writing disorder and have to use a speech to text program to type this out and ask for help I am sorry that there's not punctuations and that some sentences have wrong words  please ask questions I will elaborate but please just don't make fun I get that a lot in these forms\n  \n\n    ps I have tried Cisdem Duplicate Finder But it doesn't find the ones that I only have one copy of"},
{"Title": "How hard is it to switch between RAID configurations?", "Author": "u/Austinitered", "Content": "I have a CM3588 Nas with 4 x 4TB M.2 SSDs I'm trying to setup and I'm stuck between the RAID configurations. It sounds like RAID-5 isn't the best since they SSDs are over 3TB; haven't fully confirmed this, just something I've read (LTT used it on this setup though). RAID-Z sounds like the best option so far, but only allows for 1 drive failure and I don't really see me utilizing >8TB anytime in the near future. Because of this, I'm wondering if I should start with RAID-10, and adjust/recreate the configuration to RAID-6 and then/or RAID-Z later on?\n  \n\n    Just started looking into RAID configurations, so this is all new to me. I'm guessing the biggest hurdle is migrating the data to temporary disks if I need to switch to a different configuration?\n  \n\n    Edit: Using Open Media Vault"},
{"Title": "How to download video from mediasite.com", "Author": "u/pavoganso", "Content": "Hi,\n  \n\n    I can't figure out how to download video. It doesn't seem to have a m3u8 stream."},
{"Title": "Do you trust your backup enough to not use parity?", "Author": "u/19wolf", "Content": "If downtime isn't an issue, is there a reason to \"waste\"  space if you have a valid 3-2-1 backup? I'm using unraid so if a drive dies it's not like I need to restore my whole pool. How does everyone else feel about this?"},
{"Title": "Reddit saves", "Author": "u/gavinkamp", "Content": "Anyway to transfer Reddit saves to flash drive off a iPhone?"},
{"Title": "Needing Help Managing Duplicates", "Author": "u/klnadler", "Content": "Hi everyone, I'm on a long journey consolidating years of external drives to an Unraid server. I've been having a hard time managing duplicates, I am using Czkawka which is great at finding the duplicates but I'm having trouble with selecting the correct file to remove. I'll provide a screenshot of an example, after searching for duplicates I chose to select the newer file to delete and most of the files with -1 in the name are the newer file and it's from using exiftool to pool the files together. In the screenshot the one selected isn't the newer file according to any of the tags.\n  \n\n\nPhoto\n\n\n\n    Another issue I'm having is finding thumbnails that were accidentally sorted into the folders along the way. Some of the thumbnails are of the whole image and others are of faces from iPhotos face detection feature. Any guidance is appreciated TIA!"},
{"Title": "Need a solution for a one off project", "Author": "u/Safe_Table_9715", "Content": "I have a client that gave me about 10 devices with roughly 10 TB of data across all of them.  The goal is to get this into 1 device (I initially thought a Large external drive,) remove duplicate data across the devices (that should reduce it to about 5-6 TB) then give back that device to the client and they can then upload that data to their ICloud.\n  \n\n    I was looking for external drive recommendations but the impression I get from this sub and some other places is that an external USB drive will certainly destroy the data and shoot my dog in the process. A proper NAS is not an option as this needs to be extremely simple and require no support once I deliver the device.\n  \n\n    For this specific use case, am I fine going with the external drive?  Should I get a 2 bay external drive and duplicate the data for safety?  I really thought this would be straightforward but now I'm intimidated."},
{"Title": "Complete noob needs some guidance on NAS purchase and setup.", "Author": "u/Wdowiak", "Content": "Hey,\n  \n\n    To preamble, I am complete noob when it comes to storage/NAS and don't know anything. Anything in here is stuff I gathered up from reading some posts.\n  \n\n    My current storage setup is almost non existant. Most important things are simply \"backed up\" multiple times manually on each random drive I have on a couple of PCs, with some data on OneDrive and GDrive.\n  \n\n    So long story short, I need a main NAS mainly for a redundancy QOL (better late than never):\n  \n\n\n\n\n\n    Single place where I can upload all my data, as currently it's heavily scattered and duplicated.\n  \n\n\n\n\n\n    I want the data to be synced to other endpoints automatically for backup:\n  \n\n\n\n\n\n    NAS in another location as additional backup, not used for anything else. Probably simple two bay 2x16TB - and probably RAID 1. Don't have one yet, will most likely setup once I get this one going.\n  \n\n\n\n\n\n    16TB drive on my second PC, as another backup\n  \n\n\n\n\n\n    Locally encrypting files before cloud syncing. Only important files, so about ~1-2TB. Probably OneDrive, since I already have some space there and potentially one other in the future, like blackbaze. (heard about rclone, not sure if this is good or there are better alternatives).\n  \n\n\n\n\n\n    Two seperate external 8TB drives for important data and p4/git only, with manual syncing once a month or two, alterneting between the drives (just a failsafe in case of corrupted data being synced to other endpoints)\n  \n\n\n\n\n\n\n\n\n\n    Local Perforce / Git servers ~2TB (later on, I'll be making seperate server for that, so it's just for a year, maybe two).\n  \n\n\n\n\n\n    The Data:\n  \n\n\n\n\n\n    Most important files ~1-2TB (mostly personal photos/videos/docs). These files will be rarely accessed. Once I get them all sorted into a single location, I was thinking of burning them on BD-R disks.\n  \n\n\n\n\n\n    Other files to sync - ~3TB\n  \n\n\n\n\n\n    Random stuff that I don't care for loosing, few TBs, no syncing to other endpoints.\n  \n\n\n\n\n\n\n\n\n\n    Files will be uploaded to the NAS manually (e.g. when dumping photos from my phone).\n  \n\n    My main need is redundancy and potentially ensuring I don't sync corrupted files to other endpoints (so some kind of checksums when uploading stuff to the NAS and prevent syncing corrupted ones). Warning when corrupted files are detected would be great.\n  \n\n    I don't need much speed in day to day operations (not sure if it's needed by the NAS itself in case of drive failure). Other than P4/Git, all data will be accessed very rarely (maybe a couple times a year).\n  \n\n    My current idea was to get DS1522+ with either 8TB or 16TB drives and go with RAID 6, unless there better setups for redundency and my specific needs, as I don't know anything.\n  \n\n    Drives, these are currently my main ideas, unless you can recommend better ones:\n  \n\n\n\n\n\n    16TB WUH721816ALE6L4\n  \n\n\n\n\n\n    8TB WD8003FFBX or 16TB WD161KFGX\n  \n\n\n\n\n\n    So, my initial questions:\n  \n\n\n\n\n\n    Do you have any guidence for hardware (nas/drives), software (syncing/checksums), storage setup (raid 6 or something else?) and workflows on how should I go on about this setup?\n  \n\n\n\n\n\n    Do I go with synology or build myself? I can build PCs, but perosnally would like something that I have a less chance of screwing up.\n  \n\n\n\n\n\n    What to use for syncing into other endpoints and how can I ensure I am not syncing corrupted data?\n  \n\n\n\n\n\n    Do I need UPS for the NAS during normal operations (e.g. idling or simply copying) to prevent potential corruptions?\n  \n\n\n\n\n\n    How do I periodically check if all the files all alright (no corruptions or anything) from their initial state?\n  \n\n\n\n\n\n    Other tips?\n  \n\n\n\n\n\n    Thanks!"},
{"Title": "IT BEGINS!", "Author": "u/pele4096", "Content": "No content"},
{"Title": "Jonsbo announces the N5 case", "Author": "u/Ben4425", "Content": "Nascompares just posted a description of the new \nJonsbo N5 case\n. It's a \nbeast\n with space for up to \n12\n 3.5\" drives and motherboard support for mITX, mATX, ATX, and E-ATX all with full-height PCIe cards."},
{"Title": "Another Hardware / Software / Raid / Sync Recommendation for Windows File Server", "Author": "u/westopants", "Content": "What I already have to work with\n  \n\n    Windows 11 Pro File Server. Modern hardware.\n  \n\n    2x 22tb ironwolf pro , + ext 22 wd + carbonite.\n  \n\n    Currently on this setup there is a 22tb data drive, with 1 internal incremental backup and 1 ext inc bkp. The thought of downtime restoring the data drive is my biggest concern. Reliability and Ease of use are top priorities. This is for a business with 5-10 users accessing the data. SMART or similar remote management capabilities are also important.\n  \n\n    ...... Traditionally have worked mostly with 1-4tb systems. Back in the day would use 2 drives in Allway-Sync ,, and even further back some Hardware raid cards.\n  \n\n    I've read Hardware raid is somewhat dead, but still in use. I would be ok with a card, but it would need to be brand new card. I like the idea of those used enterprise cards, but new is much more ideal and require low cost.\n  \n\n    Windows storage spaces sounds decent. Some articles mention it is not as reliable.\n  \n\n    I'm not going linux at this time\n  \n\n    I havn't yet looked into drivepool or snap raid or know what they really do\n  \n\n    I'm ready the smear campaign...."},
{"Title": "Buy used HD ?", "Author": "u/True-Entrepreneur851", "Content": "I am in China and some sellers here propose good price for used WD NAS drives like 20 000 hours. Sorry for silly question if sounds like this but would you recommend ?"},
{"Title": "How to crawl/grab 3mf/stil files from makerworld-com?", "Author": "u/Ok_Conversation2527", "Content": "During some free time i am going through interesting projects and mark them for me...\n  \n\n    then once  a month i review them and decide finally if i want to print them out.\nBut more and more of my \"likings\"/saved for later projects on \nmakerworld.com\n are being marked as offline after some time and i cannot even see which it was (having single option to remove from list without knowing what i am removing :S).\n  \n\n    Long story, short: i started to download projects \"almost\" immediately after liking and having by that a small archive. Trying to automate that, i am struggling a bit:\nLogin of \"google\"-auth-mechanism i tackled already. what i am facing right now is that neither via curl nor via \"HTTrack\" nor \"Offline Explorer\" i am able to get the download(s).\nLooking at the button it is a script which generates a one-time token for the actual file. and by that i am not aware how to grab that :S\n  \n\n    Any ideas/hints how to achieve that?\nI also played around with \"web scraper(io)\", but with no success."},
{"Title": "Help! I erased one of four RAID volumes set up with Disk Utilities", "Author": "u/peterinjapan", "Content": "Hi, I'm having an issue with a RAID with a volume I accidentally erased. My Yottamaster RAID started becoming unstable and was beeping all the time, so after giving up on it, I bought a Logitech enclosure and put the drives in, creating a RAID 5 volume with SoftRaid 8.\n  \n\n    After I got everything set up, of my disks disappeared from the new RAID, and as I was verifying the other three, another one gave me issues. So I decided to format the \"new\" disks and try again. I seem to have had one of the volumes in my old (backup) RAID selected, and erased it.\n  \n\n    The backup RAID was, I think, set up as two striped RAID volumes, which were then striped together to create a raid of that. This might not be the best way to do a RAID, but there was no option other than striped or mirrored disks, and at the time SoftRaid was not working with Apple Silicon at all.\n  \n\n    I have bought a large external disk to serve as a working disk to hopefully save my data. Can anyone suggest what will happen when I use the Restore option in Disk Utilities? If I can save the files and hopefully the folder structure, that will be good.  If there are any other tools besides Disk Utility I should be exploring, please let me know.\n  \n\n    Sending the disks to a data service isn't an option as I'm in rural Japan."},
{"Title": "Still trying to get the hand of Virtual Dub for transcribing my tapes", "Author": "u/KWalthersArt", "Content": "I am posting this so I can get answers while I sleep, I hope I'm not breaking any rules about redundent or stupid questions.\n  \n\n    So the problems I have are.\n  \n\n    Langrith compression seems to follow a high instance of dropped frames\n  \n\n    if I record to long audio and video goes out of sync.\n  \n\n    I don't know how to import my files into davinci for recompression in better lossless codec.\n  \n\n    I don't know how to install a better codec in VDub\n  \n\n    Some tapes have a whine sound on them.\n  \n\n    Set up.\n  \n\n    Gaming PC Intel Core i7\n  \n\n    Diamond VC500 usb card in a high level USB slot.\n  \n\n    Internal Hard drive then to external.\n  \n\n    Zenith XBR716 DVD-R VCR for play back.\n  \n\n    Most tapes are at SLP speed, I was a stupid teenager."},
{"Title": "Repairing drives…", "Author": "u/TwoRight9509", "Content": "A decade ago you’d send a broken drive to a place in California to get a repair / copy.\n  \n\n    How do we handle that now? Is there a best company to sent to?"},
{"Title": "How can I extract ColorNote notes?", "Author": "u/BlackJackT", "Content": "I have thousands... They are already backed up to Google Drive, but not as plain text as I'd like but rather through the app (whatever protocol that uses). I want to back them up as a CSV or XLSX but I'm not sure how that can be done.\n  \n\n    In addition to my request for help with a solution, here is something pretty concerning: I actually reached out to the company asking how I can do this, and take a look at their response: \nhttps://ibb.co/D9xBhXR\n Can they gain access to my notes by me just providing my account (i.e. email address)?"},
{"Title": "Retrieving Photos From iPhoto Library In Time Machine Backup", "Author": "u/Akura_Awesome", "Content": "I have about a decade’s worth of Time Machine back ups across a dozen external drives, all with disparate photo libraries on them.\n  \n\n    Is there any sure fire way to pull these libraries out with metadata to throw on my NAS?\n  \n\n    I’ve tried to pull them in before but I get notifications about version and key mismatches, not to mention they can be a pain to locate.\n  \n\n    Any ideas are appreciated!"},
{"Title": "2 part question.", "Author": "u/GrayManTech", "Content": "Hi.\n  \n\n    I have a bunch of DVDs that I want to convert to mp4 or whatever. I know I need a DVD player of some sort and software. I've seen here there are a couple of dvd players that don't need to be modified to use for this, but the posts I found were pretty old, have the available drives changed and if so which ones work out of the box?\n  \n\n    2nd part, storage. Is it possible to setup a Nas or something to use wifi so everyone in my house can access it? My router has a USB port but from what I understand it's disabled by xfinity. Basically I'm looking for something that can hold both 2.5 and 3.5 hdd since I already have both."},
{"Title": "Best Way to Convert Podcasts on Spotify?", "Author": "u/ShyGuyGaming76", "Content": "I listen to a lot of audio dramas, and with about two exceptions (The Magnus Archives and Kakos Industries) most of them are \nonly\n on Spotify, so I'm not really able to archive them conveniently. What I'm doing right now is just screen recording them and converting it to an audio file. However, this is \nungodly\n slow.\n  \n\n    Any better ways?"},
{"Title": "11 years ago I built a computer", "Author": "u/BinaryPatrickDev", "Content": "No content"},
{"Title": "Does this Buffalo Linksys NAS  have encryption?", "Author": "u/zemaacu001", "Content": "Help me data pros. I am have Link Station Buffalo NAS. LS220D0402B. Does this encrypt data inside? I don't know anything about NAS.\n  \n\n    I googled and found a post saying linksys doesn't support encryption, but TeraStation device does, but it seemed like an old post and I wasn't sure if it included my model.\n  \n\n    I didn't start using it yet since I don't think it encrypts data. If someone physically steals device, I think the data in device is vulnerable. Am I correct in thinking this? Is there anything I can do to encrypt it or would I have to buy a NAS that automatically encrypts the data?"},
{"Title": "Document Scanning Services", "Author": "u/JL4575", "Content": "I’m looking to scan a small collection of magazines, more than I want to manage manually. Each is stapled through the middle, not bound, and I would really like to not destroy the collection in getting them scanned. Can anyone recommend mail order services they’ve used?"},
{"Title": "G-RAID - Use built in HW RAID, Disk Utility RAID or something else?", "Author": "u/SuperChooch", "Content": "I have an older G-RAID device that is not supported by WD, attached to a Mac mini.    It is currently running G-RAID's hardware RAID at RAID 0 and I want to redeploy it for another purpose and make it RAID 1.  It is not mission critical and I'll be backing it up to another local location and to the cloud so if it craps out, it won't be the end of the world.  Should I continue to use G-RAID's RAID, should I use the Mac's Disk Utility RAID assistant or should I use something else?"},
{"Title": "CrcCheckCopy Software - Error reading the file. A random CRC will be given, to create an error when verifying.", "Author": "u/mrnngbgs", "Content": "Hello, I am in the middle of backing up my 18TB drive. I am not copying the files just yet. A few moments ago I finished creating a CRC hash checksum file using the CrcCheckCopy software and I am now running the verification in the background. Out of ~48,000 files, about 800 of them couldn't have been read and an error message was delivered for each one of them:\n  \n\n\nError reading the [FILENAME]. A random CRC will be given, to create an error when verifying.\n\n\n\n    I checked and I can manually open those files without any issues. Anyone more experienced with the software knows whether it is something I should worry about? CrystalDiskInfo says that my drive is OK."},
{"Title": "Photo and video sorting and recovering", "Author": "u/ravage007", "Content": "So I am a hoarder I've had several cell phones I have reimaged my computer countless times I have three to five hard drives with backups of my computer and all its files before I reformatted them I am looking for a program that can go through all my files and find my photos videos And compile them all into one area as well as helping me sort out duplicates for the best quality version a bonus would be nice if it could scan through my Google Drive photo bucket Amazon photo And maybe Facebook to find all my photos and videos so I can have one copy instead of 500 with an exponential amount\n  \n\n\nPlease note\n that I have a reading and writing disorder and have to use a speech to text program to type this out and ask for help I am sorry that there's not punctuations and that some sentences have wrong words  please ask questions I will elaborate but please just don't make fun I get that a lot in these forms\n  \n\n    ps I have tried Cisdem Duplicate Finder But it doesn't find the ones that I only have one copy of"},
{"Title": "How hard is it to switch between RAID configurations?", "Author": "u/Austinitered", "Content": "I have a CM3588 Nas with 4 x 4TB M.2 SSDs I'm trying to setup and I'm stuck between the RAID configurations. It sounds like RAID-5 isn't the best since they SSDs are over 3TB; haven't fully confirmed this, just something I've read (LTT used it on this setup though). RAID-Z sounds like the best option so far, but only allows for 1 drive failure and I don't really see me utilizing >8TB anytime in the near future. Because of this, I'm wondering if I should start with RAID-10, and adjust/recreate the configuration to RAID-6 and then/or RAID-Z later on?\n  \n\n    Just started looking into RAID configurations, so this is all new to me. I'm guessing the biggest hurdle is migrating the data to temporary disks if I need to switch to a different configuration?\n  \n\n    Edit: Using Open Media Vault"},
{"Title": "How to download video from mediasite.com", "Author": "u/pavoganso", "Content": "Hi,\n  \n\n    I can't figure out how to download video. It doesn't seem to have a m3u8 stream."},
{"Title": "Do you trust your backup enough to not use parity?", "Author": "u/19wolf", "Content": "If downtime isn't an issue, is there a reason to \"waste\"  space if you have a valid 3-2-1 backup? I'm using unraid so if a drive dies it's not like I need to restore my whole pool. How does everyone else feel about this?"},
{"Title": "Reddit saves", "Author": "u/gavinkamp", "Content": "Anyway to transfer Reddit saves to flash drive off a iPhone?"},
{"Title": "Needing Help Managing Duplicates", "Author": "u/klnadler", "Content": "Hi everyone, I'm on a long journey consolidating years of external drives to an Unraid server. I've been having a hard time managing duplicates, I am using Czkawka which is great at finding the duplicates but I'm having trouble with selecting the correct file to remove. I'll provide a screenshot of an example, after searching for duplicates I chose to select the newer file to delete and most of the files with -1 in the name are the newer file and it's from using exiftool to pool the files together. In the screenshot the one selected isn't the newer file according to any of the tags.\n  \n\n\nPhoto\n\n\n\n    Another issue I'm having is finding thumbnails that were accidentally sorted into the folders along the way. Some of the thumbnails are of the whole image and others are of faces from iPhotos face detection feature. Any guidance is appreciated TIA!"},
{"Title": "Need a solution for a one off project", "Author": "u/Safe_Table_9715", "Content": "I have a client that gave me about 10 devices with roughly 10 TB of data across all of them.  The goal is to get this into 1 device (I initially thought a Large external drive,) remove duplicate data across the devices (that should reduce it to about 5-6 TB) then give back that device to the client and they can then upload that data to their ICloud.\n  \n\n    I was looking for external drive recommendations but the impression I get from this sub and some other places is that an external USB drive will certainly destroy the data and shoot my dog in the process. A proper NAS is not an option as this needs to be extremely simple and require no support once I deliver the device.\n  \n\n    For this specific use case, am I fine going with the external drive?  Should I get a 2 bay external drive and duplicate the data for safety?  I really thought this would be straightforward but now I'm intimidated."},
{"Title": "Complete noob needs some guidance on NAS purchase and setup.", "Author": "u/Wdowiak", "Content": "Hey,\n  \n\n    To preamble, I am complete noob when it comes to storage/NAS and don't know anything. Anything in here is stuff I gathered up from reading some posts.\n  \n\n    My current storage setup is almost non existant. Most important things are simply \"backed up\" multiple times manually on each random drive I have on a couple of PCs, with some data on OneDrive and GDrive.\n  \n\n    So long story short, I need a main NAS mainly for a redundancy QOL (better late than never):\n  \n\n\n\n\n\n    Single place where I can upload all my data, as currently it's heavily scattered and duplicated.\n  \n\n\n\n\n\n    I want the data to be synced to other endpoints automatically for backup:\n  \n\n\n\n\n\n    NAS in another location as additional backup, not used for anything else. Probably simple two bay 2x16TB - and probably RAID 1. Don't have one yet, will most likely setup once I get this one going.\n  \n\n\n\n\n\n    16TB drive on my second PC, as another backup\n  \n\n\n\n\n\n    Locally encrypting files before cloud syncing. Only important files, so about ~1-2TB. Probably OneDrive, since I already have some space there and potentially one other in the future, like blackbaze. (heard about rclone, not sure if this is good or there are better alternatives).\n  \n\n\n\n\n\n    Two seperate external 8TB drives for important data and p4/git only, with manual syncing once a month or two, alterneting between the drives (just a failsafe in case of corrupted data being synced to other endpoints)\n  \n\n\n\n\n\n\n\n\n\n    Local Perforce / Git servers ~2TB (later on, I'll be making seperate server for that, so it's just for a year, maybe two).\n  \n\n\n\n\n\n    The Data:\n  \n\n\n\n\n\n    Most important files ~1-2TB (mostly personal photos/videos/docs). These files will be rarely accessed. Once I get them all sorted into a single location, I was thinking of burning them on BD-R disks.\n  \n\n\n\n\n\n    Other files to sync - ~3TB\n  \n\n\n\n\n\n    Random stuff that I don't care for loosing, few TBs, no syncing to other endpoints.\n  \n\n\n\n\n\n\n\n\n\n    Files will be uploaded to the NAS manually (e.g. when dumping photos from my phone).\n  \n\n    My main need is redundancy and potentially ensuring I don't sync corrupted files to other endpoints (so some kind of checksums when uploading stuff to the NAS and prevent syncing corrupted ones). Warning when corrupted files are detected would be great.\n  \n\n    I don't need much speed in day to day operations (not sure if it's needed by the NAS itself in case of drive failure). Other than P4/Git, all data will be accessed very rarely (maybe a couple times a year).\n  \n\n    My current idea was to get DS1522+ with either 8TB or 16TB drives and go with RAID 6, unless there better setups for redundency and my specific needs, as I don't know anything.\n  \n\n    Drives, these are currently my main ideas, unless you can recommend better ones:\n  \n\n\n\n\n\n    16TB WUH721816ALE6L4\n  \n\n\n\n\n\n    8TB WD8003FFBX or 16TB WD161KFGX\n  \n\n\n\n\n\n    So, my initial questions:\n  \n\n\n\n\n\n    Do you have any guidence for hardware (nas/drives), software (syncing/checksums), storage setup (raid 6 or something else?) and workflows on how should I go on about this setup?\n  \n\n\n\n\n\n    Do I go with synology or build myself? I can build PCs, but perosnally would like something that I have a less chance of screwing up.\n  \n\n\n\n\n\n    What to use for syncing into other endpoints and how can I ensure I am not syncing corrupted data?\n  \n\n\n\n\n\n    Do I need UPS for the NAS during normal operations (e.g. idling or simply copying) to prevent potential corruptions?\n  \n\n\n\n\n\n    How do I periodically check if all the files all alright (no corruptions or anything) from their initial state?\n  \n\n\n\n\n\n    Other tips?\n  \n\n\n\n\n\n    Thanks!"},
{"Title": "IT BEGINS!", "Author": "u/pele4096", "Content": "No content"},
{"Title": "Jonsbo announces the N5 case", "Author": "u/Ben4425", "Content": "Nascompares just posted a description of the new \nJonsbo N5 case\n. It's a \nbeast\n with space for up to \n12\n 3.5\" drives and motherboard support for mITX, mATX, ATX, and E-ATX all with full-height PCIe cards."},
{"Title": "Another Hardware / Software / Raid / Sync Recommendation for Windows File Server", "Author": "u/westopants", "Content": "What I already have to work with\n  \n\n    Windows 11 Pro File Server. Modern hardware.\n  \n\n    2x 22tb ironwolf pro , + ext 22 wd + carbonite.\n  \n\n    Currently on this setup there is a 22tb data drive, with 1 internal incremental backup and 1 ext inc bkp. The thought of downtime restoring the data drive is my biggest concern. Reliability and Ease of use are top priorities. This is for a business with 5-10 users accessing the data. SMART or similar remote management capabilities are also important.\n  \n\n    ...... Traditionally have worked mostly with 1-4tb systems. Back in the day would use 2 drives in Allway-Sync ,, and even further back some Hardware raid cards.\n  \n\n    I've read Hardware raid is somewhat dead, but still in use. I would be ok with a card, but it would need to be brand new card. I like the idea of those used enterprise cards, but new is much more ideal and require low cost.\n  \n\n    Windows storage spaces sounds decent. Some articles mention it is not as reliable.\n  \n\n    I'm not going linux at this time\n  \n\n    I havn't yet looked into drivepool or snap raid or know what they really do\n  \n\n    I'm ready the smear campaign...."},
{"Title": "Buy used HD ?", "Author": "u/True-Entrepreneur851", "Content": "I am in China and some sellers here propose good price for used WD NAS drives like 20 000 hours. Sorry for silly question if sounds like this but would you recommend ?"},
{"Title": "How to crawl/grab 3mf/stil files from makerworld-com?", "Author": "u/Ok_Conversation2527", "Content": "During some free time i am going through interesting projects and mark them for me...\n  \n\n    then once  a month i review them and decide finally if i want to print them out.\nBut more and more of my \"likings\"/saved for later projects on \nmakerworld.com\n are being marked as offline after some time and i cannot even see which it was (having single option to remove from list without knowing what i am removing :S).\n  \n\n    Long story, short: i started to download projects \"almost\" immediately after liking and having by that a small archive. Trying to automate that, i am struggling a bit:\nLogin of \"google\"-auth-mechanism i tackled already. what i am facing right now is that neither via curl nor via \"HTTrack\" nor \"Offline Explorer\" i am able to get the download(s).\nLooking at the button it is a script which generates a one-time token for the actual file. and by that i am not aware how to grab that :S\n  \n\n    Any ideas/hints how to achieve that?\nI also played around with \"web scraper(io)\", but with no success."},
{"Title": "Help! I erased one of four RAID volumes set up with Disk Utilities", "Author": "u/peterinjapan", "Content": "Hi, I'm having an issue with a RAID with a volume I accidentally erased. My Yottamaster RAID started becoming unstable and was beeping all the time, so after giving up on it, I bought a Logitech enclosure and put the drives in, creating a RAID 5 volume with SoftRaid 8.\n  \n\n    After I got everything set up, of my disks disappeared from the new RAID, and as I was verifying the other three, another one gave me issues. So I decided to format the \"new\" disks and try again. I seem to have had one of the volumes in my old (backup) RAID selected, and erased it.\n  \n\n    The backup RAID was, I think, set up as two striped RAID volumes, which were then striped together to create a raid of that. This might not be the best way to do a RAID, but there was no option other than striped or mirrored disks, and at the time SoftRaid was not working with Apple Silicon at all.\n  \n\n    I have bought a large external disk to serve as a working disk to hopefully save my data. Can anyone suggest what will happen when I use the Restore option in Disk Utilities? If I can save the files and hopefully the folder structure, that will be good.  If there are any other tools besides Disk Utility I should be exploring, please let me know.\n  \n\n    Sending the disks to a data service isn't an option as I'm in rural Japan."},
{"Title": "Still trying to get the hand of Virtual Dub for transcribing my tapes", "Author": "u/KWalthersArt", "Content": "I am posting this so I can get answers while I sleep, I hope I'm not breaking any rules about redundent or stupid questions.\n  \n\n    So the problems I have are.\n  \n\n    Langrith compression seems to follow a high instance of dropped frames\n  \n\n    if I record to long audio and video goes out of sync.\n  \n\n    I don't know how to import my files into davinci for recompression in better lossless codec.\n  \n\n    I don't know how to install a better codec in VDub\n  \n\n    Some tapes have a whine sound on them.\n  \n\n    Set up.\n  \n\n    Gaming PC Intel Core i7\n  \n\n    Diamond VC500 usb card in a high level USB slot.\n  \n\n    Internal Hard drive then to external.\n  \n\n    Zenith XBR716 DVD-R VCR for play back.\n  \n\n    Most tapes are at SLP speed, I was a stupid teenager."},
{"Title": "Repairing drives…", "Author": "u/TwoRight9509", "Content": "A decade ago you’d send a broken drive to a place in California to get a repair / copy.\n  \n\n    How do we handle that now? Is there a best company to sent to?"},
{"Title": "How can I extract ColorNote notes?", "Author": "u/BlackJackT", "Content": "I have thousands... They are already backed up to Google Drive, but not as plain text as I'd like but rather through the app (whatever protocol that uses). I want to back them up as a CSV or XLSX but I'm not sure how that can be done.\n  \n\n    In addition to my request for help with a solution, here is something pretty concerning: I actually reached out to the company asking how I can do this, and take a look at their response: \nhttps://ibb.co/D9xBhXR\n Can they gain access to my notes by me just providing my account (i.e. email address)?"},
{"Title": "Retrieving Photos From iPhoto Library In Time Machine Backup", "Author": "u/Akura_Awesome", "Content": "I have about a decade’s worth of Time Machine back ups across a dozen external drives, all with disparate photo libraries on them.\n  \n\n    Is there any sure fire way to pull these libraries out with metadata to throw on my NAS?\n  \n\n    I’ve tried to pull them in before but I get notifications about version and key mismatches, not to mention they can be a pain to locate.\n  \n\n    Any ideas are appreciated!"},
{"Title": "2 part question.", "Author": "u/GrayManTech", "Content": "Hi.\n  \n\n    I have a bunch of DVDs that I want to convert to mp4 or whatever. I know I need a DVD player of some sort and software. I've seen here there are a couple of dvd players that don't need to be modified to use for this, but the posts I found were pretty old, have the available drives changed and if so which ones work out of the box?\n  \n\n    2nd part, storage. Is it possible to setup a Nas or something to use wifi so everyone in my house can access it? My router has a USB port but from what I understand it's disabled by xfinity. Basically I'm looking for something that can hold both 2.5 and 3.5 hdd since I already have both."},
{"Title": "Best Way to Convert Podcasts on Spotify?", "Author": "u/ShyGuyGaming76", "Content": "I listen to a lot of audio dramas, and with about two exceptions (The Magnus Archives and Kakos Industries) most of them are \nonly\n on Spotify, so I'm not really able to archive them conveniently. What I'm doing right now is just screen recording them and converting it to an audio file. However, this is \nungodly\n slow.\n  \n\n    Any better ways?"},
{"Title": "11 years ago I built a computer", "Author": "u/BinaryPatrickDev", "Content": "No content"},
{"Title": "Does this Buffalo Linksys NAS  have encryption?", "Author": "u/zemaacu001", "Content": "Help me data pros. I am have Link Station Buffalo NAS. LS220D0402B. Does this encrypt data inside? I don't know anything about NAS.\n  \n\n    I googled and found a post saying linksys doesn't support encryption, but TeraStation device does, but it seemed like an old post and I wasn't sure if it included my model.\n  \n\n    I didn't start using it yet since I don't think it encrypts data. If someone physically steals device, I think the data in device is vulnerable. Am I correct in thinking this? Is there anything I can do to encrypt it or would I have to buy a NAS that automatically encrypts the data?"},
{"Title": "Document Scanning Services", "Author": "u/JL4575", "Content": "I’m looking to scan a small collection of magazines, more than I want to manage manually. Each is stapled through the middle, not bound, and I would really like to not destroy the collection in getting them scanned. Can anyone recommend mail order services they’ve used?"},
{"Title": "G-RAID - Use built in HW RAID, Disk Utility RAID or something else?", "Author": "u/SuperChooch", "Content": "I have an older G-RAID device that is not supported by WD, attached to a Mac mini.    It is currently running G-RAID's hardware RAID at RAID 0 and I want to redeploy it for another purpose and make it RAID 1.  It is not mission critical and I'll be backing it up to another local location and to the cloud so if it craps out, it won't be the end of the world.  Should I continue to use G-RAID's RAID, should I use the Mac's Disk Utility RAID assistant or should I use something else?"},
{"Title": "CrcCheckCopy Software - Error reading the file. A random CRC will be given, to create an error when verifying.", "Author": "u/mrnngbgs", "Content": "Hello, I am in the middle of backing up my 18TB drive. I am not copying the files just yet. A few moments ago I finished creating a CRC hash checksum file using the CrcCheckCopy software and I am now running the verification in the background. Out of ~48,000 files, about 800 of them couldn't have been read and an error message was delivered for each one of them:\n  \n\n\nError reading the [FILENAME]. A random CRC will be given, to create an error when verifying.\n\n\n\n    I checked and I can manually open those files without any issues. Anyone more experienced with the software knows whether it is something I should worry about? CrystalDiskInfo says that my drive is OK."},
{"Title": "Photo and video sorting and recovering", "Author": "u/ravage007", "Content": "So I am a hoarder I've had several cell phones I have reimaged my computer countless times I have three to five hard drives with backups of my computer and all its files before I reformatted them I am looking for a program that can go through all my files and find my photos videos And compile them all into one area as well as helping me sort out duplicates for the best quality version a bonus would be nice if it could scan through my Google Drive photo bucket Amazon photo And maybe Facebook to find all my photos and videos so I can have one copy instead of 500 with an exponential amount\n  \n\n\nPlease note\n that I have a reading and writing disorder and have to use a speech to text program to type this out and ask for help I am sorry that there's not punctuations and that some sentences have wrong words  please ask questions I will elaborate but please just don't make fun I get that a lot in these forms\n  \n\n    ps I have tried Cisdem Duplicate Finder But it doesn't find the ones that I only have one copy of"},
{"Title": "How hard is it to switch between RAID configurations?", "Author": "u/Austinitered", "Content": "I have a CM3588 Nas with 4 x 4TB M.2 SSDs I'm trying to setup and I'm stuck between the RAID configurations. It sounds like RAID-5 isn't the best since they SSDs are over 3TB; haven't fully confirmed this, just something I've read (LTT used it on this setup though). RAID-Z sounds like the best option so far, but only allows for 1 drive failure and I don't really see me utilizing >8TB anytime in the near future. Because of this, I'm wondering if I should start with RAID-10, and adjust/recreate the configuration to RAID-6 and then/or RAID-Z later on?\n  \n\n    Just started looking into RAID configurations, so this is all new to me. I'm guessing the biggest hurdle is migrating the data to temporary disks if I need to switch to a different configuration?\n  \n\n    Edit: Using Open Media Vault"},
{"Title": "How to download video from mediasite.com", "Author": "u/pavoganso", "Content": "Hi,\n  \n\n    I can't figure out how to download video. It doesn't seem to have a m3u8 stream."},
{"Title": "Do you trust your backup enough to not use parity?", "Author": "u/19wolf", "Content": "If downtime isn't an issue, is there a reason to \"waste\"  space if you have a valid 3-2-1 backup? I'm using unraid so if a drive dies it's not like I need to restore my whole pool. How does everyone else feel about this?"},
{"Title": "Reddit saves", "Author": "u/gavinkamp", "Content": "Anyway to transfer Reddit saves to flash drive off a iPhone?"},
{"Title": "Needing Help Managing Duplicates", "Author": "u/klnadler", "Content": "Hi everyone, I'm on a long journey consolidating years of external drives to an Unraid server. I've been having a hard time managing duplicates, I am using Czkawka which is great at finding the duplicates but I'm having trouble with selecting the correct file to remove. I'll provide a screenshot of an example, after searching for duplicates I chose to select the newer file to delete and most of the files with -1 in the name are the newer file and it's from using exiftool to pool the files together. In the screenshot the one selected isn't the newer file according to any of the tags.\n  \n\n\nPhoto\n\n\n\n    Another issue I'm having is finding thumbnails that were accidentally sorted into the folders along the way. Some of the thumbnails are of the whole image and others are of faces from iPhotos face detection feature. Any guidance is appreciated TIA!"},
{"Title": "Need a solution for a one off project", "Author": "u/Safe_Table_9715", "Content": "I have a client that gave me about 10 devices with roughly 10 TB of data across all of them.  The goal is to get this into 1 device (I initially thought a Large external drive,) remove duplicate data across the devices (that should reduce it to about 5-6 TB) then give back that device to the client and they can then upload that data to their ICloud.\n  \n\n    I was looking for external drive recommendations but the impression I get from this sub and some other places is that an external USB drive will certainly destroy the data and shoot my dog in the process. A proper NAS is not an option as this needs to be extremely simple and require no support once I deliver the device.\n  \n\n    For this specific use case, am I fine going with the external drive?  Should I get a 2 bay external drive and duplicate the data for safety?  I really thought this would be straightforward but now I'm intimidated."},
{"Title": "Storage Configuration for Home Server", "Author": "u/Temporary_Cod_468", "Content": "Hi guys,\n  \n\n    I have 1x 1TB SSD and 2x 8TB HDDs and am trying to achieve the following using Ubuntu Server:\n  \n\n    1TB SSD\n  \n\n\n\n\n\n    500GB allocated for OS + Docker services (Home Assistant, Nextcloud, etc)\n  \n\n\n\n\n\n    500GB allocated as an LVM dm-cache in writeback mode (read and write cache) for the HDDs\n  \n\n\n\n\n\n    2x 8TB HDDs\n  \n\n\n\n\n\n    Setup in software RAID1 (is RAID configured during installation same or equivalent to using mdadm?)\n  \n\n\n\n\n\n    How should I go about doing this?\n  \n\n    I have been referencing the \nRed Hat LVM Docs\n and this is what I have deduced:\n  \n\n\n\n\n\n    The 2x 8TB HDDs (Physical Volumes) will form a 16TB Volume Group which will be used as an 8TB Logical Volume in RAID1\n  \n\n\n\n\n\n    The 1x SSD (Physical Volume) will be its own Volume Group and will be split into 2 Logical Volumes (1 for OS, 1 for Cache)\n  \n\n\n\n\n\n    Am I using the terminology in the right way and is it even possible to use the same SSD for OS and caching?\n  \n\n    If so, these are the steps I plan to execute:\n  \n\n\n\n\n\n    Install OS on SSD\n  \n\n\n\n\n\n    Setup Software RAID1 on the 2 HDDs during OS install (which will take care of the creation of the VG and the LV)\n  \n\n\n\n\n\n    Partition SSD into 2 Logical Volumes\n  \n\n\n\n\n\n    Setup LVM dm-cache in writeback mode (following something like \nthis (slide 8)\n)\n  \n\n\n\n\n\n    Lastly, are there any advantages or disadvantages to using cachepool (cache data + metadata) over cachevol? If using cachepool, what ratio should I use for the cache data and metadata?\n  \n\n    Please let me know if what I am doing is possible and if anything is missing or if there are any holes in my plan!\n  \n\n    (Btw, I posted this on \nr/linuxadmin\n and \nr/linuxquestions\n also, but if anyone knows a more relevant subreddit to post on please lmk!)\n  \n\n    TIA"},
{"Title": "How to transfer saved content?", "Author": "u/gavinkamp", "Content": "Hello all. Need help transferring my saved Reddit gifs photos and videos to my San disk flash drive. I was hoping for some shortcut I can use so I can do it all from my iPhone and not have to put it in my photo app also. Any help works thank you."},
{"Title": "Which would be better for a small NAS, using a RPi 4?", "Author": "u/NaAlSiO6", "Content": "I'm currently looking at two external HDD/SSD enclosures and can't decide which one to go with.\n  \n\n\n\n\n\n    The \nADSA-ST SUPERSPEED USB DUAL HDD DOCK\n\n\n\n\n\n\n\n    The \nAsus TUF Gaming A1\n\n\n\n\n\n\n\n    The first one supports two SSDs/HDDs, but it's somewhat difficult to find reasonable priced (when compared to a same capacity M.2 drive) 2.5 inch SATA SSDs. Still, it's not impossible and it could give me a lot more room to expand in the future. However, I also wonder about the performance of the drives, as there will be no cooling\n  \n\n    The second one however only supports one NVME SSD. Which couples with the USB 3.2 Gen 2X1 interface would give me better speed and thermals, due to the metal construction."},
{"Title": "Should I buy a 1TB external SSD, or a Blu-ray burner + a 50-pack BD-R spindle + 50 jewel cases?", "Author": "u/TheresThisOtherThing", "Content": "Hello, I am new here and to data hoarding in general, so please give me the for-dummies version.\n  \n\n    I need to back up some data, a little less than 1TB. I have a couple copies in the cloud with different providers, and I'd like to make a physical copy that I can put in a box and store at a relative's house. I don't expect to update or modify this copy at all, ever, just copy the files in it to my laptop if the copies in the cloud \nand\n my laptop somehow all fail at the same time.\n  \n\n    I've been poking around on Amazon and it looks like at time of writing, a 1 TB external SSD or a combination of a Blu-ray burner, a 50-pack of BD-Rs, and 50 jewel cases, will each cost around $80. Which option is better for my case, and could you point me to better options? I'm on a budget, so maybe keep it below $100 if possible. Thanks!"},
{"Title": "[Noob] Using LTO5 for archival purposes, tips?", "Author": "u/mactep66", "Content": "I just got myself a FC LTO5 drive along with a few tapes (haven't arrived yet) for the purposes of archiving old data and freeing up my HDDs.\n  \n\n    What im looking for is a tool/tools that will keep a (hopefully) searchable index of all the files on all my tapes on my main SSD, one that would allow me to add/remove files from a tape at will and one for archiving large amounts of data as reliably and fast as possible.\n  \n\n    Ive head of Uranium backup, Veeam CE and my 5 should also be compatible with LTFS, but i haven't heard the best things about it, how good is it?"},
{"Title": "My new Factory Recertified 22TB Seagate hard drives", "Author": "u/dropswisdom", "Content": "Sorry, had to re-post due to my previous post lacking in details.\n  \n\n    So here: got the drives here: \nhttps://www.ebay.com.sg/itm/204806952151\n\n\n\n    It was slightly cheaper when I got it. But it's one of the cheapest options you can find anywhere even now. The next step is 24TB drives which are not sold factory recertified as of yet, so they would cost.. about 50% more than this. I was concerned that some of the disks will arrive damaged, but as you can see it comes very well packaged, and they all passed testing. I put them into a Xpenology home made NAS. which is basically a itx motherboard inside a NAS case (jonsbo N1). It works like a charm. with one disk redundancy, I got about 80TB of fast storage.\n  \n\n    They cleared the hours on it when they recertified, but not the rest I think. But all the disks passed testing and are not making any suspicious noises or giving any issues.\n  \nhttps://preview.redd.it/my-new-factory-recertified-22tb-seagate-hard-drives-v0-j8twcye0lx4d1.jpg\nSeagate 22TB Sata Hard Drives"},
{"Title": "LTO5 tape drive with usbc thunderbolt", "Author": "u/mc_louis", "Content": "Hi everyone. I'm in the middle of some home renovation, and I decided that I want to reduce the space occupied by my all my stuff.\n  \n\n    At the moment I have a whole tower pc with windows 11 that I use just to run my external sas hp lto5 drive, through \nTHIS\n an lsi9211, which is a pcie 2.0 x8 lanes, everything working perfectly fine.\n  \n\n    I would like to remove the tower pc, if only I can connect the tape drive to a generic usb to use it with just the laptop when I need. I found few adapters like \nthis\n and I pulled the trigger. But it's not working, as I understand because my hba card is a x8 lanes, but all this adapters looks like they're just x4 lanes. I tried just covering the contacts on the card that correspond to the 5,6,7,8 lanes, as seen somewhere, but it's not working.\n  \n\n    Does anybody ever worked something like this out? For what I understand, there are not pcie x8 adapters that are affordable... are there any hba card that are x4 lanes? I found something on ebay, like \nthis\n, somewhere in the description says x8, but pictures and specifics says x4. Would this card work with my drive or am I missing something else?\n  \n\n    Damn it would be a game changer for me a usbc tape drive..."},
{"Title": "Using an external drive to store photos question.", "Author": "u/shdujssnensisishs", "Content": "https://support.apple.com/guide/iphone/import-and-export-photos-and-videos-iph480caa1f3/ios\n\n\n\n    The link above is to apple’s website that shows u how to move photos to an external device. More specifically the “Export photos and videos to an external storage device” section.\n  \n\n    If I choose to do this, will my iPhone move the photos or just copy the photos and videos over and leave the originals on my phone?\n  \n\n    How would restoring the photos work? If I import it back, would the dates and location and everything still be there? Has anyone done this and can I get insight on this? Thank you!"},
{"Title": "What happens if the Google Drive account that transfers ownership is deleted?", "Author": "Unknown author", "Content": "Hypothetically, Peter transfers you a folder containing 5GB, which is still counted to his 15GB quota. You already have 15GB of your own data. What happens if his account is deleted? Will the files he created but you own ultimately be deleted too? If it's added to your quota, will you then have 20GB in your account and be asked to delete some or simply be restricted from creating more? Does the reason why his account was deleted (personal choice, inactivity, policy violation) affect the outcome and, if so, what difference does it make?"},
{"Title": "Is this Rot?", "Author": "u/MDCasino21", "Content": "No content"},
{"Title": "Best way to transcode entire library of videos on Google Drive preferably though Google cloud", "Author": "u/cewong2", "Content": "I’ve been searing around for a day and a half trying to find a way to transcode lots of videos I have stored in my Google drive. I haven’t been able to find anyone ever having a solution (lots of what I’ve found isn’t gets downloaded and reuploaded after transcoding). Hopefully this is posted in the right place otherwise please suggest a subReddit for me to post to.\n  \n\n    Lots of my videos are in x264 format and I want to transcode them into x265 as I read there’s possibly a saving of at least 20-30% but it’s nearly 60-70TB which would take probably a long time compared just using Google’s free cloud trial. Can anyone recommend me a guide or tool that I can use to get this done?"},
{"Title": "any way to download entire galleries of art like gallery-dl?", "Author": "u/dietgilroy", "Content": "i tried using that but it didn't work at all, so i might use wfdownloader for that. i am considering trying to archive art from deviantart."},
{"Title": "CD ripping for dummies", "Author": "u/nlj1978", "Content": "While spring cleaning I stumbled across a long forgotten CD collection. Rummaging through it nostalgia is kicking hard. So of course I'm going to have to rip it all so I can enjoy.\n  \n\n    Have ~200 CDs I've located to rip.  Also have a previous stash of ripped CDs on one of my home computers\n  \n\n    Googling a bit I'm reading about FLAC files being best to get the best rip and gather the music information. Exact Audio Copy along with a few others get mentioned alot for ripping.\n  \n\n    What's the most user friendly and effective ripping software for someone new to this? Doesn't have to be freeware, will pay for solid software.\n  \n\n    Is the FLAC file format relatively usable? For example I have a networked Onkyo receiver, would it be able to play those files from the network?"},
{"Title": "Can 3.5” external enclosure setup drive", "Author": "u/ChillCaptain", "Content": "https://www.amazon.com/SSK-External-Docking-Enclosure-Supports/dp/B08P1539VD/ref=asc_df_B08P1539VD/?hvadid=693495256271&hvpos=&hvnetw=g&hvrand=2570617204095985210&hvpone=&hvptwo=&hvqmt=&hvdev=m&hvdvcmdl=&hvlocint=&hvlocphy=9057119&hvtargid=pla-1626594922711&psc=1&mcid=086ce8faf4d5351490f73a899c982a27&gad_source=1\n\n\n\n    I’m looking to get this enclosure to help with backups.\n  \n\n    Can I insert a brand new drive and set up the drive in windows? Usually this is done in disk management where you select gpt vs mbr and select the drive letter. After setting it up can I take the drive and insert it internally through sata and use the drive?\n  \n\n    I’m wondering if the usb connection limits this?"},
{"Title": "Synology vs Ebay PC", "Author": "u/Suspicious_Dig_5684", "Content": "So I have a server; what I am looking for is something to put 2 18tb drives in and be a dedicated photo backup for both IPhone and Android. Would love a way to pull the pictures from ICloud and get them local as well. The wife has more pictures in the cloud then she has space on the phone and I don't have a easy way to pull those down.\n  \n\n    Is the ds223 worth it? Are there better options. Biggest concern is a simple way to backup the iPhone that doesn't require user input.\n  \n\n    We tired nextcloud works great on android but with iphone I have to constantly remind her to open the app before it would backup anything.\n  \n\n    Thanks for any help."},
{"Title": "Saw this and thought it belonged here.", "Author": "u/Mist17", "Content": "No content"},
{"Title": "Power Outage Froze my TrueNAS OS. How to Monitor Offsite TrueNAS Replication?", "Author": "u/Luz3r", "Content": "Hey everyone,\n  \n\n    I recently had a power outage at my backup location, and it seems to have messed with my TrueNAS box. It got stuck in a weird state, but thankfully a reboot fixed it. The problem is, I don't check my offsite server that often since it's a secondary location. This time, I only found out because I got an alert about my ZFS replication failing.\n  \n\n\nMy question is:\n How can I best check if my replication is actually working properly?\n  \n\n    I was thinking about setting up Uptime Kuma to monitor the offsite TrueNAS web interface. While this wouldn't necessarily tell me if replication is failing, it might catch issues like SSH being unresponsive. Ideally, I'd like to get Telegram alerts for any problems.\n  \n\n\nAnyone have any suggestions for a better or cool way to monitor my TrueNAS replication health?"},
{"Title": "Storage Configuration for Home Server", "Author": "u/Temporary_Cod_468", "Content": "Hi guys,\n  \n\n    I have 1x 1TB SSD and 2x 8TB HDDs and am trying to achieve the following using Ubuntu Server:\n  \n\n    1TB SSD\n  \n\n\n\n\n\n    500GB allocated for OS + Docker services (Home Assistant, Nextcloud, etc)\n  \n\n\n\n\n\n    500GB allocated as an LVM dm-cache in writeback mode (read and write cache) for the HDDs\n  \n\n\n\n\n\n    2x 8TB HDDs\n  \n\n\n\n\n\n    Setup in software RAID1 (is RAID configured during installation same or equivalent to using mdadm?)\n  \n\n\n\n\n\n    How should I go about doing this?\n  \n\n    I have been referencing the \nRed Hat LVM Docs\n and this is what I have deduced:\n  \n\n\n\n\n\n    The 2x 8TB HDDs (Physical Volumes) will form a 16TB Volume Group which will be used as an 8TB Logical Volume in RAID1\n  \n\n\n\n\n\n    The 1x SSD (Physical Volume) will be its own Volume Group and will be split into 2 Logical Volumes (1 for OS, 1 for Cache)\n  \n\n\n\n\n\n    Am I using the terminology in the right way and is it even possible to use the same SSD for OS and caching?\n  \n\n    If so, these are the steps I plan to execute:\n  \n\n\n\n\n\n    Install OS on SSD\n  \n\n\n\n\n\n    Setup Software RAID1 on the 2 HDDs during OS install (which will take care of the creation of the VG and the LV)\n  \n\n\n\n\n\n    Partition SSD into 2 Logical Volumes\n  \n\n\n\n\n\n    Setup LVM dm-cache in writeback mode (following something like \nthis (slide 8)\n)\n  \n\n\n\n\n\n    Lastly, are there any advantages or disadvantages to using cachepool (cache data + metadata) over cachevol? If using cachepool, what ratio should I use for the cache data and metadata?\n  \n\n    Please let me know if what I am doing is possible and if anything is missing or if there are any holes in my plan!\n  \n\n    (Btw, I posted this on \nr/linuxadmin\n and \nr/linuxquestions\n also, but if anyone knows a more relevant subreddit to post on please lmk!)\n  \n\n    TIA"},
{"Title": "How to transfer saved content?", "Author": "u/gavinkamp", "Content": "Hello all. Need help transferring my saved Reddit gifs photos and videos to my San disk flash drive. I was hoping for some shortcut I can use so I can do it all from my iPhone and not have to put it in my photo app also. Any help works thank you."},
{"Title": "Which would be better for a small NAS, using a RPi 4?", "Author": "u/NaAlSiO6", "Content": "I'm currently looking at two external HDD/SSD enclosures and can't decide which one to go with.\n  \n\n\n\n\n\n    The \nADSA-ST SUPERSPEED USB DUAL HDD DOCK\n\n\n\n\n\n\n\n    The \nAsus TUF Gaming A1\n\n\n\n\n\n\n\n    The first one supports two SSDs/HDDs, but it's somewhat difficult to find reasonable priced (when compared to a same capacity M.2 drive) 2.5 inch SATA SSDs. Still, it's not impossible and it could give me a lot more room to expand in the future. However, I also wonder about the performance of the drives, as there will be no cooling\n  \n\n    The second one however only supports one NVME SSD. Which couples with the USB 3.2 Gen 2X1 interface would give me better speed and thermals, due to the metal construction."},
{"Title": "Should I buy a 1TB external SSD, or a Blu-ray burner + a 50-pack BD-R spindle + 50 jewel cases?", "Author": "u/TheresThisOtherThing", "Content": "Hello, I am new here and to data hoarding in general, so please give me the for-dummies version.\n  \n\n    I need to back up some data, a little less than 1TB. I have a couple copies in the cloud with different providers, and I'd like to make a physical copy that I can put in a box and store at a relative's house. I don't expect to update or modify this copy at all, ever, just copy the files in it to my laptop if the copies in the cloud \nand\n my laptop somehow all fail at the same time.\n  \n\n    I've been poking around on Amazon and it looks like at time of writing, a 1 TB external SSD or a combination of a Blu-ray burner, a 50-pack of BD-Rs, and 50 jewel cases, will each cost around $80. Which option is better for my case, and could you point me to better options? I'm on a budget, so maybe keep it below $100 if possible. Thanks!"},
{"Title": "[Noob] Using LTO5 for archival purposes, tips?", "Author": "u/mactep66", "Content": "I just got myself a FC LTO5 drive along with a few tapes (haven't arrived yet) for the purposes of archiving old data and freeing up my HDDs.\n  \n\n    What im looking for is a tool/tools that will keep a (hopefully) searchable index of all the files on all my tapes on my main SSD, one that would allow me to add/remove files from a tape at will and one for archiving large amounts of data as reliably and fast as possible.\n  \n\n    Ive head of Uranium backup, Veeam CE and my 5 should also be compatible with LTFS, but i haven't heard the best things about it, how good is it?"},
{"Title": "My new Factory Recertified 22TB Seagate hard drives", "Author": "u/dropswisdom", "Content": "Sorry, had to re-post due to my previous post lacking in details.\n  \n\n    So here: got the drives here: \nhttps://www.ebay.com.sg/itm/204806952151\n\n\n\n    It was slightly cheaper when I got it. But it's one of the cheapest options you can find anywhere even now. The next step is 24TB drives which are not sold factory recertified as of yet, so they would cost.. about 50% more than this. I was concerned that some of the disks will arrive damaged, but as you can see it comes very well packaged, and they all passed testing. I put them into a Xpenology home made NAS. which is basically a itx motherboard inside a NAS case (jonsbo N1). It works like a charm. with one disk redundancy, I got about 80TB of fast storage.\n  \n\n    They cleared the hours on it when they recertified, but not the rest I think. But all the disks passed testing and are not making any suspicious noises or giving any issues.\n  \nhttps://preview.redd.it/my-new-factory-recertified-22tb-seagate-hard-drives-v0-j8twcye0lx4d1.jpg\nSeagate 22TB Sata Hard Drives"},
{"Title": "LTO5 tape drive with usbc thunderbolt", "Author": "u/mc_louis", "Content": "Hi everyone. I'm in the middle of some home renovation, and I decided that I want to reduce the space occupied by my all my stuff.\n  \n\n    At the moment I have a whole tower pc with windows 11 that I use just to run my external sas hp lto5 drive, through \nTHIS\n an lsi9211, which is a pcie 2.0 x8 lanes, everything working perfectly fine.\n  \n\n    I would like to remove the tower pc, if only I can connect the tape drive to a generic usb to use it with just the laptop when I need. I found few adapters like \nthis\n and I pulled the trigger. But it's not working, as I understand because my hba card is a x8 lanes, but all this adapters looks like they're just x4 lanes. I tried just covering the contacts on the card that correspond to the 5,6,7,8 lanes, as seen somewhere, but it's not working.\n  \n\n    Does anybody ever worked something like this out? For what I understand, there are not pcie x8 adapters that are affordable... are there any hba card that are x4 lanes? I found something on ebay, like \nthis\n, somewhere in the description says x8, but pictures and specifics says x4. Would this card work with my drive or am I missing something else?\n  \n\n    Damn it would be a game changer for me a usbc tape drive..."},
{"Title": "Using an external drive to store photos question.", "Author": "u/shdujssnensisishs", "Content": "https://support.apple.com/guide/iphone/import-and-export-photos-and-videos-iph480caa1f3/ios\n\n\n\n    The link above is to apple’s website that shows u how to move photos to an external device. More specifically the “Export photos and videos to an external storage device” section.\n  \n\n    If I choose to do this, will my iPhone move the photos or just copy the photos and videos over and leave the originals on my phone?\n  \n\n    How would restoring the photos work? If I import it back, would the dates and location and everything still be there? Has anyone done this and can I get insight on this? Thank you!"},
{"Title": "What happens if the Google Drive account that transfers ownership is deleted?", "Author": "Unknown author", "Content": "Hypothetically, Peter transfers you a folder containing 5GB, which is still counted to his 15GB quota. You already have 15GB of your own data. What happens if his account is deleted? Will the files he created but you own ultimately be deleted too? If it's added to your quota, will you then have 20GB in your account and be asked to delete some or simply be restricted from creating more? Does the reason why his account was deleted (personal choice, inactivity, policy violation) affect the outcome and, if so, what difference does it make?"},
{"Title": "Is this Rot?", "Author": "u/MDCasino21", "Content": "No content"},
{"Title": "Best way to transcode entire library of videos on Google Drive preferably though Google cloud", "Author": "u/cewong2", "Content": "I’ve been searing around for a day and a half trying to find a way to transcode lots of videos I have stored in my Google drive. I haven’t been able to find anyone ever having a solution (lots of what I’ve found isn’t gets downloaded and reuploaded after transcoding). Hopefully this is posted in the right place otherwise please suggest a subReddit for me to post to.\n  \n\n    Lots of my videos are in x264 format and I want to transcode them into x265 as I read there’s possibly a saving of at least 20-30% but it’s nearly 60-70TB which would take probably a long time compared just using Google’s free cloud trial. Can anyone recommend me a guide or tool that I can use to get this done?"},
{"Title": "any way to download entire galleries of art like gallery-dl?", "Author": "u/dietgilroy", "Content": "i tried using that but it didn't work at all, so i might use wfdownloader for that. i am considering trying to archive art from deviantart."},
{"Title": "CD ripping for dummies", "Author": "u/nlj1978", "Content": "While spring cleaning I stumbled across a long forgotten CD collection. Rummaging through it nostalgia is kicking hard. So of course I'm going to have to rip it all so I can enjoy.\n  \n\n    Have ~200 CDs I've located to rip.  Also have a previous stash of ripped CDs on one of my home computers\n  \n\n    Googling a bit I'm reading about FLAC files being best to get the best rip and gather the music information. Exact Audio Copy along with a few others get mentioned alot for ripping.\n  \n\n    What's the most user friendly and effective ripping software for someone new to this? Doesn't have to be freeware, will pay for solid software.\n  \n\n    Is the FLAC file format relatively usable? For example I have a networked Onkyo receiver, would it be able to play those files from the network?"},
{"Title": "Can 3.5” external enclosure setup drive", "Author": "u/ChillCaptain", "Content": "https://www.amazon.com/SSK-External-Docking-Enclosure-Supports/dp/B08P1539VD/ref=asc_df_B08P1539VD/?hvadid=693495256271&hvpos=&hvnetw=g&hvrand=2570617204095985210&hvpone=&hvptwo=&hvqmt=&hvdev=m&hvdvcmdl=&hvlocint=&hvlocphy=9057119&hvtargid=pla-1626594922711&psc=1&mcid=086ce8faf4d5351490f73a899c982a27&gad_source=1\n\n\n\n    I’m looking to get this enclosure to help with backups.\n  \n\n    Can I insert a brand new drive and set up the drive in windows? Usually this is done in disk management where you select gpt vs mbr and select the drive letter. After setting it up can I take the drive and insert it internally through sata and use the drive?\n  \n\n    I’m wondering if the usb connection limits this?"},
{"Title": "Synology vs Ebay PC", "Author": "u/Suspicious_Dig_5684", "Content": "So I have a server; what I am looking for is something to put 2 18tb drives in and be a dedicated photo backup for both IPhone and Android. Would love a way to pull the pictures from ICloud and get them local as well. The wife has more pictures in the cloud then she has space on the phone and I don't have a easy way to pull those down.\n  \n\n    Is the ds223 worth it? Are there better options. Biggest concern is a simple way to backup the iPhone that doesn't require user input.\n  \n\n    We tired nextcloud works great on android but with iphone I have to constantly remind her to open the app before it would backup anything.\n  \n\n    Thanks for any help."},
{"Title": "Saw this and thought it belonged here.", "Author": "u/Mist17", "Content": "No content"},
{"Title": "Power Outage Froze my TrueNAS OS. How to Monitor Offsite TrueNAS Replication?", "Author": "u/Luz3r", "Content": "Hey everyone,\n  \n\n    I recently had a power outage at my backup location, and it seems to have messed with my TrueNAS box. It got stuck in a weird state, but thankfully a reboot fixed it. The problem is, I don't check my offsite server that often since it's a secondary location. This time, I only found out because I got an alert about my ZFS replication failing.\n  \n\n\nMy question is:\n How can I best check if my replication is actually working properly?\n  \n\n    I was thinking about setting up Uptime Kuma to monitor the offsite TrueNAS web interface. While this wouldn't necessarily tell me if replication is failing, it might catch issues like SSH being unresponsive. Ideally, I'd like to get Telegram alerts for any problems.\n  \n\n\nAnyone have any suggestions for a better or cool way to monitor my TrueNAS replication health?"},
{"Title": "MEGATHREAD: Archiving the Capitol Hill Riots", "Author": "u/AdamLynch", "Content": "FINAL UPDATE as of January 31st 5:35PM EST:\n\n\n\n    Thank you to everyone who shared content. The content being submitted now from what I'm seeing is duplicates of older content. \nI will thus no longer be updating this archive.\n The \nMEGA will remain\n untouched, so use that as you please, but that will likely die one day as there is a bandwidth/transfer limit. I will be uploading the content to Internet Archive, as well as other sources, but until then the torrent magnet that I will be seeding for a little while is listed below - my bandwidth isn't the best so please do seed if you can:\n  \n\n    Magnet:\n  \nmagnet:?xt=urn:btih:c8fc9979cc35f7062cd8715aaaff4da475d2fadc&dn=Trump%20protest%20Jan%2006%202021&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2fpublic.popcorn-tracker.org%3a6969%2fannounce&tr=http%3a%2f%2f104.28.1.30%3a8080%2fannounce&tr=http%3a%2f%2f104.28.16.69%2fannounce&tr=http%3a%2f%2f107.150.14.110%3a6969%2fannounce&tr=http%3a%2f%2f109.121.134.121%3a1337%2fannounce&tr=http%3a%2f%2f114.55.113.60%3a6969%2fannounce&tr=http%3a%2f%2f125.227.35.196%3a6969%2fannounce&tr=http%3a%2f%2f128.199.70.66%3a5944%2fannounce&tr=http%3a%2f%2f157.7.202.64%3a8080%2fannounce&tr=http%3a%2f%2f158.69.146.212%3a7777%2fannounce&tr=http%3a%2f%2f173.254.204.71%3a1096%2fannounce&tr=http%3a%2f%2f178.175.143.27%2fannounce&tr=http%3a%2f%2f178.33.73.26%3a2710%2fannounce&tr=http%3a%2f%2f182.176.139.129%3a6969%2fannounce&tr=http%3a%2f%2f185.5.97.139%3a8089%2fannounce&tr=http%3a%2f%2f188.165.253.109%3a1337%2fannounce&tr=http%3a%2f%2f194.106.216.222%2fannounce&tr=http%3a%2f%2f195.123.209.37%3a1337%2fannounce&tr=http%3a%2f%2f210.244.71.25%3a6969%2fannounce&tr=http%3a%2f%2f210.244.71.26%3a6969%2fannounce&tr=http%3a%2f%2f213.159.215.198%3a6970%2fannounce&tr=http%3a%2f%2f213.163.67.56%3a1337%2fannounce&tr=http%3a%2f%2f37.19.5.139%3a6969%2fannounce&tr=http%3a%2f%2f37.19.5.155%3a6881%2fannounce&tr=http%3a%2f%2f46.4.109.148%3a6969%2fannounce&tr=http%3a%2f%2f5.79.249.77%3a6969%2fannounce&tr=http%3a%2f%2f5.79.83.193%3a2710%2fannounce&tr=http%3a%2f%2f51.254.244.161%3a6969%2fannounce&tr=http%3a%2f%2f59.36.96.77%3a6969%2fannounce&tr=http%3a%2f%2f74.82.52.209%3a6969%2fannounce&tr=http%3a%2f%2f80.246.243.18%3a6969%2fannounce&tr=http%3a%2f%2f81.200.2.231%2fannounce&tr=http%3a%2f%2f85.17.19.180%2fannounce&tr=http%3a%2f%2f87.248.186.252%3a8080%2fannounce&tr=http%3a%2f%2f87.253.152.137%2fannounce&tr=http%3a%2f%2f91.216.110.47%2fannounce&tr=http%3a%2f%2f91.217.91.21%3a3218%2fannounce&tr=http%3a%2f%2f91.218.230.81%3a6969%2fannounce&tr=http%3a%2f%2f93.92.64.5%2fannounce&tr=http%3a%2f%2fatrack.pow7.com%2fannounce&tr=http%3a%2f%2fbt.henbt.com%3a2710%2fannounce&tr=http%3a%2f%2fbt.pusacg.org%3a8080%2fannounce&tr=http%3a%2f%2fbt2.careland.com.cn%3a6969%2fannounce&tr=http%3a%2f%2fexplodie.org%3a6969%2fannounce&tr=http%3a%2f%2fmgtracker.org%3a2710%2fannounce&tr=http%3a%2f%2fmgtracker.org%3a6969%2fannounce&tr=http%3a%2f%2fopen.acgtracker.com%3a1096%2fannounce&tr=http%3a%2f%2fopen.lolicon.eu%3a7777%2fannounce&tr=http%3a%2f%2fopen.touki.ru%2fannounce.php&tr=http%3a%2f%2fp4p.arenabg.ch%3a1337%2fannounce&tr=http%3a%2f%2fp4p.arenabg.com%3a1337%2fannounce&tr=http%3a%2f%2fpow7.com%3a80%2fannounce&tr=http%3a%2f%2fretracker.gorcomnet.ru%2fannounce&tr=http%3a%2f%2fretracker.krs-ix.ru%2fannounce&tr=http%3a%2f%2fretracker.krs-ix.ru%3a80%2fannounce&tr=http%3a%2f%2fsecure.pow7.com%2fannounce&tr=http%3a%2f%2ft1.pow7.com%2fannounce&tr=http%3a%2f%2ft2.pow7.com%2fannounce&tr=http%3a%2f%2fthetracker.org%3a80%2fannounce&tr=http%3a%2f%2ftorrent.gresille.org%2fannounce&tr=http%3a%2f%2ftorrentsmd.com%3a8080%2fannounce&tr=http%3a%2f%2ftracker.aletorrenty.pl%3a2710%2fannounce&tr=http%3a%2f%2ftracker.baravik.org%3a6970%2fannounce&tr=http%3a%2f%2ftracker.bittor.pw%3a1337%2fannounce&tr=http%3a%2f%2ftracker.bittorrent.am%2fannounce&tr=http%3a%2f%2ftracker.calculate.ru%3a6969%2fannounce&tr=http%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=http%3a%2f%2ftracker.dutchtracking.com%2fannounce&tr=http%3a%2f%2ftracker.dutchtracking.com%3a80%2fannounce&tr=http%3a%2f%2ftracker.dutchtracking.nl%2fannounce&tr=http%3a%2f%2ftracker.dutchtracking.nl%3a80%2fannounce&tr=http%3a%2f%2ftracker.edoardocolombo.eu%3a6969%2fannounce&tr=http%3a%2f%2ftracker.ex.ua%2fannounce&tr=http%3a%2f%2ftracker.ex.ua%3a80%2fannounce&tr=http%3a%2f%2ftracker.filetracker.pl%3a8089%2fannounce&tr=http%3a%2f%2ftracker.flashtorrents.org%3a6969%2fannounce&tr=http%3a%2f%2ftracker.grepler.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.internetwarriors.net%3a1337%2fannounce&tr=http%3a%2f%2ftracker.kicks-ass.net%2fannounce&tr=http%3a%2f%2ftracker.kicks-ass.net%3a80%2fannounce&tr=http%3a%2f%2ftracker.kuroy.me%3a5944%2fannounce&tr=http%3a%2f%2ftracker.mg64.net%3a6881%2fannounce&tr=http%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=http%3a%2f%2ftracker.skyts.net%3a6969%2fannounce&tr=http%3a%2f%2ftracker.tfile.me%2fannounce&tr=http%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.tvunderground.org.ru%3a3218%2fannounce&tr=http%3a%2f%2ftracker.yoshi210.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker1.wasabii.com.tw%3a6969%2fannounce&tr=http%3a%2f%2ftracker2.itzmx.com%3a6961%2fannounce&tr=http%3a%2f%2ftracker2.wasabii.com.tw%3a6969%2fannounce&tr=http%3a%2f%2fwww.wareztorrent.com%2fannounce&tr=http%3a%2f%2fwww.wareztorrent.com%3a80%2fannounce&tr=https%3a%2f%2f104.28.17.69%2fannounce&tr=https%3a%2f%2fwww.wareztorrent.com%2fannounce&tr=udp%3a%2f%2f107.150.14.110%3a6969%2fannounce&tr=udp%3a%2f%2f109.121.134.121%3a1337%2fannounce&tr=udp%3a%2f%2f114.55.113.60%3a6969%2fannounce&tr=udp%3a%2f%2f128.199.70.66%3a5944%2fannounce&tr=udp%3a%2f%2f151.80.120.114%3a2710%2fannounce&tr=udp%3a%2f%2f168.235.67.63%3a6969%2fannounce&tr=udp%3a%2f%2f178.33.73.26%3a2710%2fannounce&tr=udp%3a%2f%2f182.176.139.129%3a6969%2fannounce&tr=udp%3a%2f%2f185.5.97.139%3a8089%2fannounce&tr=udp%3a%2f%2f185.86.149.205%3a1337%2fannounce&tr=udp%3a%2f%2f188.165.253.109%3a1337%2fannounce&tr=udp%3a%2f%2f191.101.229.236%3a1337%2fannounce&tr=udp%3a%2f%2f194.106.216.222%3a80%2fannounce&tr=udp%3a%2f%2f195.123.209.37%3a1337%2fannounce&tr=udp%3a%2f%2f195.123.209.40%3a80%2fannounce&tr=udp%3a%2f%2f208.67.16.113%3a8000%2fannounce&tr=udp%3a%2f%2f213.163.67.56%3a1337%2fannounce&tr=udp%3a%2f%2f37.19.5.155%3a2710%2fannounce&tr=udp%3a%2f%2f46.4.109.148%3a6969%2fannounce&tr=udp%3a%2f%2f5.79.249.77%3a6969%2fannounce&tr=udp%3a%2f%2f5.79.83.193%3a6969%2fannounce&tr=udp%3a%2f%2f51.254.244.161%3a6969%2fannounce&tr=udp%3a%2f%2f62.138.0.158%3a6969%2fannounce&tr=udp%3a%2f%2f62.212.85.66%3a2710%2fannounce&tr=udp%3a%2f%2f74.82.52.209%3a6969%2fannounce&tr=udp%3a%2f%2f85.17.19.180%3a80%2fannounce&tr=udp%3a%2f%2f89.234.156.205%3a80%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2710%2fannounce&tr=udp%3a%2f%2f9.rarbg.me%3a2780%2fannounce&tr=udp%3a%2f%2f9.rarbg.to%3a2730%2fannounce&tr=udp%3a%2f%2f91.218.230.81%3a6969%2fannounce&tr=udp%3a%2f%2f94.23.183.33%3a6969%2fannounce&tr=udp%3a%2f%2fbt.xxx-tracker.com%3a2710%2fannounce&tr=udp%3a%2f%2feddie4.nl%3a6969%2fannounce&tr=udp%3a%2f%2fexplodie.org%3a6969%2fannounce&tr=udp%3a%2f%2fmgtracker.org%3a2710%2fannounce&tr=udp%3a%2f%2fp4p.arenabg.com%3a1337%2fannounce&tr=udp%3a%2f%2fshadowshq.eddie4.nl%3a6969%2fannounce&tr=udp%3a%2f%2fshadowshq.yi.org%3a6969%2fannounce&tr=udp%3a%2f%2ftorrent.gresille.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.aletorrenty.pl%3a2710%2fannounce&tr=udp%3a%2f%2ftracker.bittor.pw%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.coppersurfer.tk%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.eddie4.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.ex.ua%3a80%2fannounce&tr=udp%3a%2f%2ftracker.filetracker.pl%3a8089%2fannounce&tr=udp%3a%2f%2ftracker.flashtorrents.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.grepler.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.ilibr.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.internetwarriors.net%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.kicks-ass.net%3a80%2fannounce&tr=udp%3a%2f%2ftracker.kuroy.me%3a5944%2fannounce&tr=udp%3a%2f%2ftracker.leechers-paradise.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.mg64.net%3a2710%2fannounce&tr=udp%3a%2f%2ftracker.mg64.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.piratepublic.com%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.sktorrent.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.skyts.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.yoshi210.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.indowebster.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker4.piratux.com%3a6969%2fannounce&tr=udp%3a%2f%2fzer0day.ch%3a1337%2fannounce&tr=udp%3a%2f%2fzer0day.to%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.cyberia.is%3a6969%2fannounce&tr=http%3a%2f%2fvps02.net.orel.ru%3a80%2fannounce&tr=https%3a%2f%2ftracker.nanoha.org%3a443%2fannounce&tr=http%3a%2f%2ftracker.files.fm%3a6969%2fannounce&tr=https%3a%2f%2ftracker.nitrix.me%3a443%2fannounce&tr=https%3a%2f%2ftracker.tamersunion.org%3a443%2fannounce&tr=udp%3a%2f%2faaa.army%3a8866%2fannounce&tr=https%3a%2f%2ftracker.imgoingto.icu%3a443%2fannounce&tr=udp%3a%2f%2fblokas.io%3a6969%2fannounce&tr=udp%3a%2f%2fdiscord.heihachi.pw%3a6969%2fannounce&tr=udp%3a%2f%2ffe.dealclub.de%3a6969%2fannounce&tr=udp%3a%2f%2fln.mtahost.co%3a6969%2fannounce&tr=udp%3a%2f%2fvibe.community%3a6969%2fannounce&tr=udp%3a%2f%2ftracker0.ufibox.com%3a6969%2fannounce&tr=udp%3a%2f%2fmail.realliferpg.de%3a6969%2fannounce&tr=udp%3a%2f%2fmovies.zsw.ca%3a6969%2fannounce&tr=udp%3a%2f%2fnagios.tks.sumy.ua%3a80%2fannounce&tr=udp%3a%2f%2f47.ip-51-68-199.eu%3a6969%2fannounce&tr=udp%3a%2f%2fcdn-1.gamecoast.org%3a6969%2fannounce&tr=udp%3a%2f%2faruacfilmes.com.br%3a6969%2fannounce&tr=udp%3a%2f%2fedu.uifr.ru%3a6969%2fannounce&tr=http%3a%2f%2frt.tace.ru%3a80%2fannounce&tr=udp%3a%2f%2fcode2chicken.nl%3a6969%2fannounce&tr=udp%3a%2f%2fus-tracker.publictracker.xyz%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.0x.tf%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftorrentclub.online%3a54123%2fannounce&tr=http%3a%2f%2f5rt.tace.ru%3a60889%2fannounce&tr=udp%3a%2f%2fapp.icon256.com%3a8000%2fannounce&tr=udp%3a%2f%2ftracker.sigterm.xyz%3a6969%2fannounce&tr=http%3a%2f%2ftracker.loadbt.com%3a6969%2fannounce&tr=http%3a%2f%2fipv4announce.sktorrent.eu%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2fwww.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2fexodus.desync.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.shkinev.me%3a6969%2fannounce&tr=udp%3a%2f%2fstorage.groupees.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.v6speed.org%3a6969%2fannounce&tr=udp%3a%2f%2fdaveking.com%3a6969%2fannounce&tr=https%3a%2f%2ftracker.lilithraws.cf%3a443%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2f3rt.tace.ru%3a60889%2fannounce&tr=udp%3a%2f%2fjohnrosen1.com%3a6969%2fannounce&tr=udp%3a%2f%2fretracker.lanta-net.ru%3a2710%2fannounce&tr=udp%3a%2f%2fopentor.org%3a2710%2fannounce&tr=udp%3a%2f%2ft2.leech.ie%3a1337%2fannounce&tr=https%3a%2f%2ftracker.foreverpirates.co%3a443%2fannounce&tr=http%3a%2f%2ftracker.vraphim.com%3a6969%2fannounce&tr=udp%3a%2f%2fopen.stealth.si%3a80%2fannounce&tr=udp%3a%2f%2ftracker.uw0.xyz%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.army%3a6969%2fannounce&tr=udp%3a%2f%2fmts.tvbit.co%3a6969%2fannounce&tr=https%3a%2f%2ftracker.coalition.space%3a443%2fannounce&tr=http%3a%2f%2ftracker-cdn.moeking.me%3a2095%2fannounce&tr=udp%3a%2f%2fline-net.ru%3a6969%2fannounce&tr=udp%3a%2f%2fperu.subventas.com%3a53%2fannounce&tr=udp%3a%2f%2fbt1.archive.org%3a6969%2fannounce&tr=udp%3a%2f%2fengplus.ru%3a6969%2fannounce&tr=udp%3a%2f%2fvalakas.rollo.dnsabr.com%3a2710%2fannounce&tr=udp%3a%2f%2fbt2.archive.org%3a6969%2fannounce&tr=udp%3a%2f%2fipv4.tracker.harry.lu%3a80%2fannounce&tr=udp%3a%2f%2ft1.leech.ie%3a1337%2fannounce&tr=http%3a%2f%2fbt.okmp3.ru%3a2710%2fannounce&tr=http%3a%2f%2fcloud.nyap2p.com%3a8080%2fannounce&tr=http%3a%2f%2ft.overflow.biz%3a6969%2fannounce&tr=udp%3a%2f%2ft3.leech.ie%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.bt4g.com%3a2095%2fannounce&tr=http%3a%2f%2ft.nyaatracker.com%3a80%2fannounce&tr=udp%3a%2f%2fudp-tracker.shittyurl.org%3a6969%2fannounce&tr=https%3a%2f%2f1337.abcvg.info%3a443%2fannounce&tr=https%3a%2f%2fw.wwwww.wtf%3a443%2fannounce&tr=udp%3a%2f%2fbt2.3kb.xyz%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.ds.is%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2fcdn-2.gamecoast.org%3a6969%2fannounce&tr=udp%3a%2f%2fretracker.netbynet.ru%3a2710%2fannounce&tr=udp%3a%2f%2fteamspeak.value-wolf.org%3a6969%2fannounce&tr=udp%3a%2f%2fcutiegirl.ru%3a6969%2fannounce&tr=http%3a%2f%2fh4.trakx.nibba.trade%3a80%2fannounce\n\n    Hash (for verification of authenticity etc):\n  \nc8fc9979cc35f7062cd8715aaaff4da475d2fadc\n\n    Size:\n  \n1,013.12GiB\nOriginal post below\n\n    Archiving videos before potential removal from various websites...\n  \n\n    Send or comment links of videos you need downloaded. Currently going through POV livestreams/replays.\n  \n\n\nNOTE:\n livestreams/POV are of the utmost importance. AKA Twitch/dlive/Facebook Live, etc. If you find any of these POV angles, please tag me directly in your comment, or PM me. These generally get taken down VERY fast by the livestream website.\n  \n\n\nUPDATE:\n\n\n\n    Thank you to everyone who shared links (and continue to do so). I am noticing that a lot of the content is now duplicates, or variations (crops, lower quality, etc) of the same content. So I have put all the content I have on MEGA. If I have replied to your comment then the content for sure is in this torrent.\n  \n\n    MEGA: \nhttps://mega.nz/folder/30MlkQib#RDOaGzmtFEHkxSYBaJSzVA\n (this is the prefered way of downloading)\n  \n\n    (This is sitting in at ~350GB as of Jan 10 3:00 PM EST. Still adding content)\n  \n\n\nUPDATE 2:\n Link should be working - MEGA contacted me and reinstated the account (and gave premium so I could upload more). \nI will be uploading more content that I find to the mega account.\n Still going through the comments, and the 900+ messages I have. Keep posting comments and I will upload them to the MEGA folder.\n  \n\n\nUPDATE 3:\n \n\"Bellingcat\"\n has created a really efficient way to submit media via a \nGoogle Spreadsheet.\n It's not connected to my archive, but I hope to have a merged final copy in the end.\n  \n\n\nUPDATE 4:\n\n\n\n    IF YOU WANT TO UPLOAD A FILE DIRECTLY TO ME: \nhttps://mega.nz/megadrop/fgve0WRa880\n (no account registration needed)\n  \n\n\nBACKUPS:\n\n\n\n    Recommended backup:\n  \n\n\nu/tweedge\n : \ntweedge commits to making sure this mirror does not fall behind 12h behind, though he'll do his best to keep it within 6h\n\n\n\n    Other backups based on the original MEGA from Jan 06 6:30PM - some might've updated, but no idea if/when; check each link, it should say. Or you can message the user:\n  \n\n    MAGNET from \nu/SneakyPieBrown\n as of Jan 08 2021 : magnet:?xt=urn:btih:fc33c9146c81660ee087dbda756746a978c7c104&dn=Trump%20protest%20Jan-08-2021&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a80\n  \n\n\nu/firstgrow\n  : \nhosting direct downloads as well\n\n\n\n\nu/nuzzles_u_uwu\n : \nIs hosting as well\n\n\n\n\nu/tweedge\n : \nmade a direct download link on s3\n\n\n\n\nu/kenkoda\n : \nposted a torrent.\n\n\n\n\nu/Deifer\n : \nLink\n\n\n\n\nu/benediktkr\n : \nhttps://mirrors.deadops.de/capitol2021\n and \nhttps://mirrors.deadops.de/capitol2021.zip\n\n\n\n\nSee a familiar face in the archive? \nhttps://tips.fbi.gov/digitalmedia/aad18481a3e8f02"},
{"Title": "Justin Roiland, co-creator of Rick and Morty, discovers that Dropbox uses content scanners through the deletion of all his data stored on their servers", "Author": "u/_G0D_M0DE_", "Content": "No content"},
{"Title": "yall might appreciate this", "Author": "u/ian9921", "Content": "No content"},
{"Title": "I just built a collapse-ready laptop. What are some must haves to put on it?", "Author": "u/evanMeaney", "Content": "No content"},
{"Title": "Rescue Mission for Sci-Hub and Open Science: We are the library.", "Author": "u/shrine", "Content": "EFF hears the call: \"It’s Time to Fight for Open Access\"\n\n\n\n\n\n\nEFF reports:\n \nActivists Mobilize to Fight Censorship and Save Open Science\n\n\n\n\n\n\n\n\n\"Continuing the long tradition of internet hacktivism ... redditors are mobilizing to create an uncensorable back-up of Sci-Hub\"\n\n\n\n\n\n\n\n    The EFF stands with Sci-Hub in the fight for Open Science, a fight for the human right to benefit and share in human scientific advancement. My wholehearted thanks for every seeder who takes part in this rescue mission, and every person who raises their voice in support of Sci-Hub's vision for Open Science.\n  \n\n\n\n\n\n\nRescue Mission Links\n\n\n\n\n\n\n\n\nQuick start to rescuing Sci-Hub\n: Download 1 random torrent (100GB) from the \nscimag index of torrents with fewer than 12 seeders\n, open the .torrent file using a BitTorrent client, then leave your client open to upload (seed) the articles to others. You're now part of an un-censorable library archive!\n  \n\n\n\n\n\n    Initial success update: The entire Sci-Hub collection has at least 3 seeders: \nLet's get it to 5. Let's get it to 7! Let’s get it to 10!\n Let’s get it to 12!\n  \n\n\n\n\n\n    Contribute to open source Sci-Hub projects: \nfreereadorg/awesome-libgen\n\n\n\n\n\n\n\n    Join \nr/scihub\n to stay up to date\n  \n\n\n\n\n\n\nNote: We have no affiliation with Sci-Hub\n\n\n\n\n\n\n\n    This effort is completely unaffiliated from Sci-Hub, no one is in touch with Sci-Hub, and I don't speak for Sci-Hub in any form. Always refer to \nsci-hub.do\n for the latest from Sci-Hub directly.\n  \n\n\n\n\n\n    This is a data preservation effort for just the articles, and does not help Sci-Hub directly.  Sci-Hub is not in any further imminent danger than it always has been, and is not at greater risk of being shut-down than before.\n  \n\n\n\n\nA Rescue Mission for Sci-Hub and Open Science\n\n    Elsevier and the USDOJ have declared war against Sci-Hub and open science. The era of Sci-Hub and Alexandra standing alone in this fight must end. We have to take a stand with her.\n  \n\n    On May 7th, Sci-Hub's Alexandra Elbakyan \nrevealed\n that the FBI has been wiretapping her accounts for over 2 years. This news comes after Twitter \nsilenced the official Sci_Hub\n twitter account because Indian academics were organizing on it against Elsevier.\n  \n\n    Sci-Hub itself is currently frozen and has not downloaded any new articles since December 2020. This rescue mission is focused on seeding the article collection in order to prepare for a potential Sci-Hub shutdown.\n  \n\n\nAlexandra Elbakyan\n of Sci-Hub, bookwarrior of \nLibrary Genesis\n, \nAaron Swartz\n, and countless unnamed others have fought to free science from the grips of for-profit publishers. Today, they do it working in hiding, alone, without acknowledgment, in fear of imprisonment, and even now wiretapped by the FBI. They sacrifice everything for one vision: Open Science.\n  \n\n    Why do they do it? They do it so that humble scholars on the other side of the planet can practice medicine, create science, fight for democracy, teach, and learn. People like Alexandra Elbakyan would give up their personal freedom for that one goal: to free knowledge. For that, Elsevier Corp (RELX, market cap: 50 billion) wants to silence her, wants to see her in prison, and wants to shut Sci-Hub down.\n  \n\n    It's time we sent Elsevier and the USDOJ a clearer message about the fate of Sci-Hub and open science: we are the library, we do not get silenced, we do not shut down our computers, and we are many.\n  \nRescue Mission for Sci-Hub\n\n    If you have been following the story, then you know that this is not our first rescue mission.\n  \n\n\n\n\n\n\nWe protected the Library Genesis book collection\n\n\n\n\n\n\n\n\nWe unlocked over 5,000 COVID-19 research articles\n\n\n\n\n\n\n\n\nWe successfully petitioned publishers to unlock their COVID-19 paywalls\n\n\n\n\n\n\n\n    bookwarrior, the \nfounder\n of Library Genesis, took his library \nonto the de-centralized and un-censorable IPFS web\n\n\n\n\n\n\n\n    Next? Make Sci-Hub un-censorable too.\n  \n\n\n\n\nRescue Target\n\n    A handful of Library Genesis seeders are currently seeding the Sci-Hub torrents. There are \n850 scihub torrents\n, each containing 100,000 scientific articles, to a total of 85 million scientific articles: 77TB. This is the complete Sci-Hub database. We need to protect this.\n  \nRescue Team\n\n\nWave 1:\n We need \n85 datahoarders\n to store and seed 1TB of articles each, 10 torrents in total. Download 10 random torrents from the \nscimag index of < 12 seeders\n, then load the torrents onto your client and seed for as long as you can. The articles are coded by DOI and in zip files.\n  \n\n\nWave 2:\n Reach out to \n10 good friends\n to ask them to grab just 1 random torrent (100GB). That's 850 seeders. We are now the library.\n  \n\n\nFinal Wave:\n Development for an open source Sci-Hub. \nfreereadorg/awesome-libgen\n is a collection of open source achievements based on the Sci-Hub and Library Genesis databases. Open source de-centralization of Sci-Hub is the ultimate goal here, and this begins with the data, but it is going to take years of developer sweat to carry these libraries into the future.\n  \n\n    Heartfelt thanks to the \nr/datahoarder\n and \nr/seedboxes\n communities, \nseedbox.io\n and \nNFOrce\n for your support for previous missions and your love for science."},
{"Title": "Data transfer to new Lustre storage overwhelms campus network", "Author": "u/e_spider", "Content": "No content"},
{"Title": "Whoops", "Author": "u/MidnightLink", "Content": "No content"},
{"Title": "A funny exchange", "Author": "Unknown author", "Content": "No content"},
{"Title": "One woman's quest to \"never delete anything\" allowed internet archivists to find long-lost Minecraft Alpha 1.1.1.", "Author": "u/BrikenEnglz", "Content": "No content"},
{"Title": "Amazon delivery driver with my new HD", "Author": "u/fancy_pantser", "Content": "No content"},
{"Title": "Apple sued for terminating account with $25,000 worth of apps and videos", "Author": "u/usernamechosen999", "Content": "No content"},
{"Title": "Some of the drives used to store the data to to compile the first picture ever of a black hole.", "Author": "u/the_best_moshe", "Content": "No content"},
{"Title": "Archivists Are Preserving Capitol Hill Riot Livestreams Before They’re Deleted", "Author": "u/fairyrocker91", "Content": "No content"},
{"Title": "Twitter to purge accounts that have had no activity at all for several years", "Author": "u/NXGZ", "Content": "No content"},
{"Title": "I can dream", "Author": "u/gammajayy", "Content": "No content"},
{"Title": "This is your regular reminder that Comcast is still a dumpster fire: Comcast to impose home internet data cap of 1.2TB in more than a dozen US states next year", "Author": "u/Snoot_Boopins", "Content": "No content"},
{"Title": "\"If you visit CERN in Geneva, you can buy 1 Terabyte of Large Hadron Collider data from the souvenir shop\"... there goes my kid's college funds", "Author": "Unknown author", "Content": "No content"},
{"Title": "yahoo answers is shutting down", "Author": "u/Fazlul101", "Content": "No content"},
{"Title": "internet archive is being sued", "Author": "u/sersoniko", "Content": "No content"},
{"Title": "Forklift accident", "Author": "u/Enkelie", "Content": "No content"},
{"Title": "Michigan couple must pay son $30,441 for throwing out porn collection", "Author": "u/benjacob", "Content": "No content"},
{"Title": "TIL the Library of Congress has a 2.129 petabyte (and growing) archive of internet culture", "Author": "u/WhitefangdDS", "Content": "No content"},
{"Title": "100Mbps uploads and downloads should be US broadband standard, senators say", "Author": "u/Unlanded", "Content": "No content"},
{"Title": "Art imitates life", "Author": "Unknown author", "Content": "No content"},
{"Title": "Remember this?", "Author": "u/YosoyPabloIscobar", "Content": "No content"},
{"Title": "Well now you know", "Author": "u/emmmmceeee", "Content": "No content"},
{"Title": "Ever wondered what 2 Peta Bytes looks like?", "Author": "u/P_G_R_A", "Content": "No content"},
{"Title": "youtube-dl repo had been DMCA'd", "Author": "u/anakinfredo", "Content": "No content"},
{"Title": "MEGATHREAD: Archiving the Capitol Hill Riots", "Author": "u/AdamLynch", "Content": "FINAL UPDATE as of January 31st 5:35PM EST:\n\n\n\n    Thank you to everyone who shared content. The content being submitted now from what I'm seeing is duplicates of older content. \nI will thus no longer be updating this archive.\n The \nMEGA will remain\n untouched, so use that as you please, but that will likely die one day as there is a bandwidth/transfer limit. I will be uploading the content to Internet Archive, as well as other sources, but until then the torrent magnet that I will be seeding for a little while is listed below - my bandwidth isn't the best so please do seed if you can:\n  \n\n    Magnet:\n  \nmagnet:?xt=urn:btih:c8fc9979cc35f7062cd8715aaaff4da475d2fadc&dn=Trump%20protest%20Jan%2006%202021&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2fpublic.popcorn-tracker.org%3a6969%2fannounce&tr=http%3a%2f%2f104.28.1.30%3a8080%2fannounce&tr=http%3a%2f%2f104.28.16.69%2fannounce&tr=http%3a%2f%2f107.150.14.110%3a6969%2fannounce&tr=http%3a%2f%2f109.121.134.121%3a1337%2fannounce&tr=http%3a%2f%2f114.55.113.60%3a6969%2fannounce&tr=http%3a%2f%2f125.227.35.196%3a6969%2fannounce&tr=http%3a%2f%2f128.199.70.66%3a5944%2fannounce&tr=http%3a%2f%2f157.7.202.64%3a8080%2fannounce&tr=http%3a%2f%2f158.69.146.212%3a7777%2fannounce&tr=http%3a%2f%2f173.254.204.71%3a1096%2fannounce&tr=http%3a%2f%2f178.175.143.27%2fannounce&tr=http%3a%2f%2f178.33.73.26%3a2710%2fannounce&tr=http%3a%2f%2f182.176.139.129%3a6969%2fannounce&tr=http%3a%2f%2f185.5.97.139%3a8089%2fannounce&tr=http%3a%2f%2f188.165.253.109%3a1337%2fannounce&tr=http%3a%2f%2f194.106.216.222%2fannounce&tr=http%3a%2f%2f195.123.209.37%3a1337%2fannounce&tr=http%3a%2f%2f210.244.71.25%3a6969%2fannounce&tr=http%3a%2f%2f210.244.71.26%3a6969%2fannounce&tr=http%3a%2f%2f213.159.215.198%3a6970%2fannounce&tr=http%3a%2f%2f213.163.67.56%3a1337%2fannounce&tr=http%3a%2f%2f37.19.5.139%3a6969%2fannounce&tr=http%3a%2f%2f37.19.5.155%3a6881%2fannounce&tr=http%3a%2f%2f46.4.109.148%3a6969%2fannounce&tr=http%3a%2f%2f5.79.249.77%3a6969%2fannounce&tr=http%3a%2f%2f5.79.83.193%3a2710%2fannounce&tr=http%3a%2f%2f51.254.244.161%3a6969%2fannounce&tr=http%3a%2f%2f59.36.96.77%3a6969%2fannounce&tr=http%3a%2f%2f74.82.52.209%3a6969%2fannounce&tr=http%3a%2f%2f80.246.243.18%3a6969%2fannounce&tr=http%3a%2f%2f81.200.2.231%2fannounce&tr=http%3a%2f%2f85.17.19.180%2fannounce&tr=http%3a%2f%2f87.248.186.252%3a8080%2fannounce&tr=http%3a%2f%2f87.253.152.137%2fannounce&tr=http%3a%2f%2f91.216.110.47%2fannounce&tr=http%3a%2f%2f91.217.91.21%3a3218%2fannounce&tr=http%3a%2f%2f91.218.230.81%3a6969%2fannounce&tr=http%3a%2f%2f93.92.64.5%2fannounce&tr=http%3a%2f%2fatrack.pow7.com%2fannounce&tr=http%3a%2f%2fbt.henbt.com%3a2710%2fannounce&tr=http%3a%2f%2fbt.pusacg.org%3a8080%2fannounce&tr=http%3a%2f%2fbt2.careland.com.cn%3a6969%2fannounce&tr=http%3a%2f%2fexplodie.org%3a6969%2fannounce&tr=http%3a%2f%2fmgtracker.org%3a2710%2fannounce&tr=http%3a%2f%2fmgtracker.org%3a6969%2fannounce&tr=http%3a%2f%2fopen.acgtracker.com%3a1096%2fannounce&tr=http%3a%2f%2fopen.lolicon.eu%3a7777%2fannounce&tr=http%3a%2f%2fopen.touki.ru%2fannounce.php&tr=http%3a%2f%2fp4p.arenabg.ch%3a1337%2fannounce&tr=http%3a%2f%2fp4p.arenabg.com%3a1337%2fannounce&tr=http%3a%2f%2fpow7.com%3a80%2fannounce&tr=http%3a%2f%2fretracker.gorcomnet.ru%2fannounce&tr=http%3a%2f%2fretracker.krs-ix.ru%2fannounce&tr=http%3a%2f%2fretracker.krs-ix.ru%3a80%2fannounce&tr=http%3a%2f%2fsecure.pow7.com%2fannounce&tr=http%3a%2f%2ft1.pow7.com%2fannounce&tr=http%3a%2f%2ft2.pow7.com%2fannounce&tr=http%3a%2f%2fthetracker.org%3a80%2fannounce&tr=http%3a%2f%2ftorrent.gresille.org%2fannounce&tr=http%3a%2f%2ftorrentsmd.com%3a8080%2fannounce&tr=http%3a%2f%2ftracker.aletorrenty.pl%3a2710%2fannounce&tr=http%3a%2f%2ftracker.baravik.org%3a6970%2fannounce&tr=http%3a%2f%2ftracker.bittor.pw%3a1337%2fannounce&tr=http%3a%2f%2ftracker.bittorrent.am%2fannounce&tr=http%3a%2f%2ftracker.calculate.ru%3a6969%2fannounce&tr=http%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=http%3a%2f%2ftracker.dutchtracking.com%2fannounce&tr=http%3a%2f%2ftracker.dutchtracking.com%3a80%2fannounce&tr=http%3a%2f%2ftracker.dutchtracking.nl%2fannounce&tr=http%3a%2f%2ftracker.dutchtracking.nl%3a80%2fannounce&tr=http%3a%2f%2ftracker.edoardocolombo.eu%3a6969%2fannounce&tr=http%3a%2f%2ftracker.ex.ua%2fannounce&tr=http%3a%2f%2ftracker.ex.ua%3a80%2fannounce&tr=http%3a%2f%2ftracker.filetracker.pl%3a8089%2fannounce&tr=http%3a%2f%2ftracker.flashtorrents.org%3a6969%2fannounce&tr=http%3a%2f%2ftracker.grepler.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.internetwarriors.net%3a1337%2fannounce&tr=http%3a%2f%2ftracker.kicks-ass.net%2fannounce&tr=http%3a%2f%2ftracker.kicks-ass.net%3a80%2fannounce&tr=http%3a%2f%2ftracker.kuroy.me%3a5944%2fannounce&tr=http%3a%2f%2ftracker.mg64.net%3a6881%2fannounce&tr=http%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=http%3a%2f%2ftracker.skyts.net%3a6969%2fannounce&tr=http%3a%2f%2ftracker.tfile.me%2fannounce&tr=http%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.tvunderground.org.ru%3a3218%2fannounce&tr=http%3a%2f%2ftracker.yoshi210.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker1.wasabii.com.tw%3a6969%2fannounce&tr=http%3a%2f%2ftracker2.itzmx.com%3a6961%2fannounce&tr=http%3a%2f%2ftracker2.wasabii.com.tw%3a6969%2fannounce&tr=http%3a%2f%2fwww.wareztorrent.com%2fannounce&tr=http%3a%2f%2fwww.wareztorrent.com%3a80%2fannounce&tr=https%3a%2f%2f104.28.17.69%2fannounce&tr=https%3a%2f%2fwww.wareztorrent.com%2fannounce&tr=udp%3a%2f%2f107.150.14.110%3a6969%2fannounce&tr=udp%3a%2f%2f109.121.134.121%3a1337%2fannounce&tr=udp%3a%2f%2f114.55.113.60%3a6969%2fannounce&tr=udp%3a%2f%2f128.199.70.66%3a5944%2fannounce&tr=udp%3a%2f%2f151.80.120.114%3a2710%2fannounce&tr=udp%3a%2f%2f168.235.67.63%3a6969%2fannounce&tr=udp%3a%2f%2f178.33.73.26%3a2710%2fannounce&tr=udp%3a%2f%2f182.176.139.129%3a6969%2fannounce&tr=udp%3a%2f%2f185.5.97.139%3a8089%2fannounce&tr=udp%3a%2f%2f185.86.149.205%3a1337%2fannounce&tr=udp%3a%2f%2f188.165.253.109%3a1337%2fannounce&tr=udp%3a%2f%2f191.101.229.236%3a1337%2fannounce&tr=udp%3a%2f%2f194.106.216.222%3a80%2fannounce&tr=udp%3a%2f%2f195.123.209.37%3a1337%2fannounce&tr=udp%3a%2f%2f195.123.209.40%3a80%2fannounce&tr=udp%3a%2f%2f208.67.16.113%3a8000%2fannounce&tr=udp%3a%2f%2f213.163.67.56%3a1337%2fannounce&tr=udp%3a%2f%2f37.19.5.155%3a2710%2fannounce&tr=udp%3a%2f%2f46.4.109.148%3a6969%2fannounce&tr=udp%3a%2f%2f5.79.249.77%3a6969%2fannounce&tr=udp%3a%2f%2f5.79.83.193%3a6969%2fannounce&tr=udp%3a%2f%2f51.254.244.161%3a6969%2fannounce&tr=udp%3a%2f%2f62.138.0.158%3a6969%2fannounce&tr=udp%3a%2f%2f62.212.85.66%3a2710%2fannounce&tr=udp%3a%2f%2f74.82.52.209%3a6969%2fannounce&tr=udp%3a%2f%2f85.17.19.180%3a80%2fannounce&tr=udp%3a%2f%2f89.234.156.205%3a80%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2710%2fannounce&tr=udp%3a%2f%2f9.rarbg.me%3a2780%2fannounce&tr=udp%3a%2f%2f9.rarbg.to%3a2730%2fannounce&tr=udp%3a%2f%2f91.218.230.81%3a6969%2fannounce&tr=udp%3a%2f%2f94.23.183.33%3a6969%2fannounce&tr=udp%3a%2f%2fbt.xxx-tracker.com%3a2710%2fannounce&tr=udp%3a%2f%2feddie4.nl%3a6969%2fannounce&tr=udp%3a%2f%2fexplodie.org%3a6969%2fannounce&tr=udp%3a%2f%2fmgtracker.org%3a2710%2fannounce&tr=udp%3a%2f%2fp4p.arenabg.com%3a1337%2fannounce&tr=udp%3a%2f%2fshadowshq.eddie4.nl%3a6969%2fannounce&tr=udp%3a%2f%2fshadowshq.yi.org%3a6969%2fannounce&tr=udp%3a%2f%2ftorrent.gresille.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.aletorrenty.pl%3a2710%2fannounce&tr=udp%3a%2f%2ftracker.bittor.pw%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.coppersurfer.tk%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.eddie4.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.ex.ua%3a80%2fannounce&tr=udp%3a%2f%2ftracker.filetracker.pl%3a8089%2fannounce&tr=udp%3a%2f%2ftracker.flashtorrents.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.grepler.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.ilibr.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.internetwarriors.net%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.kicks-ass.net%3a80%2fannounce&tr=udp%3a%2f%2ftracker.kuroy.me%3a5944%2fannounce&tr=udp%3a%2f%2ftracker.leechers-paradise.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.mg64.net%3a2710%2fannounce&tr=udp%3a%2f%2ftracker.mg64.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.piratepublic.com%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.sktorrent.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.skyts.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.yoshi210.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.indowebster.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker4.piratux.com%3a6969%2fannounce&tr=udp%3a%2f%2fzer0day.ch%3a1337%2fannounce&tr=udp%3a%2f%2fzer0day.to%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.cyberia.is%3a6969%2fannounce&tr=http%3a%2f%2fvps02.net.orel.ru%3a80%2fannounce&tr=https%3a%2f%2ftracker.nanoha.org%3a443%2fannounce&tr=http%3a%2f%2ftracker.files.fm%3a6969%2fannounce&tr=https%3a%2f%2ftracker.nitrix.me%3a443%2fannounce&tr=https%3a%2f%2ftracker.tamersunion.org%3a443%2fannounce&tr=udp%3a%2f%2faaa.army%3a8866%2fannounce&tr=https%3a%2f%2ftracker.imgoingto.icu%3a443%2fannounce&tr=udp%3a%2f%2fblokas.io%3a6969%2fannounce&tr=udp%3a%2f%2fdiscord.heihachi.pw%3a6969%2fannounce&tr=udp%3a%2f%2ffe.dealclub.de%3a6969%2fannounce&tr=udp%3a%2f%2fln.mtahost.co%3a6969%2fannounce&tr=udp%3a%2f%2fvibe.community%3a6969%2fannounce&tr=udp%3a%2f%2ftracker0.ufibox.com%3a6969%2fannounce&tr=udp%3a%2f%2fmail.realliferpg.de%3a6969%2fannounce&tr=udp%3a%2f%2fmovies.zsw.ca%3a6969%2fannounce&tr=udp%3a%2f%2fnagios.tks.sumy.ua%3a80%2fannounce&tr=udp%3a%2f%2f47.ip-51-68-199.eu%3a6969%2fannounce&tr=udp%3a%2f%2fcdn-1.gamecoast.org%3a6969%2fannounce&tr=udp%3a%2f%2faruacfilmes.com.br%3a6969%2fannounce&tr=udp%3a%2f%2fedu.uifr.ru%3a6969%2fannounce&tr=http%3a%2f%2frt.tace.ru%3a80%2fannounce&tr=udp%3a%2f%2fcode2chicken.nl%3a6969%2fannounce&tr=udp%3a%2f%2fus-tracker.publictracker.xyz%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.0x.tf%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftorrentclub.online%3a54123%2fannounce&tr=http%3a%2f%2f5rt.tace.ru%3a60889%2fannounce&tr=udp%3a%2f%2fapp.icon256.com%3a8000%2fannounce&tr=udp%3a%2f%2ftracker.sigterm.xyz%3a6969%2fannounce&tr=http%3a%2f%2ftracker.loadbt.com%3a6969%2fannounce&tr=http%3a%2f%2fipv4announce.sktorrent.eu%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2fwww.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2fexodus.desync.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.shkinev.me%3a6969%2fannounce&tr=udp%3a%2f%2fstorage.groupees.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.v6speed.org%3a6969%2fannounce&tr=udp%3a%2f%2fdaveking.com%3a6969%2fannounce&tr=https%3a%2f%2ftracker.lilithraws.cf%3a443%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2f3rt.tace.ru%3a60889%2fannounce&tr=udp%3a%2f%2fjohnrosen1.com%3a6969%2fannounce&tr=udp%3a%2f%2fretracker.lanta-net.ru%3a2710%2fannounce&tr=udp%3a%2f%2fopentor.org%3a2710%2fannounce&tr=udp%3a%2f%2ft2.leech.ie%3a1337%2fannounce&tr=https%3a%2f%2ftracker.foreverpirates.co%3a443%2fannounce&tr=http%3a%2f%2ftracker.vraphim.com%3a6969%2fannounce&tr=udp%3a%2f%2fopen.stealth.si%3a80%2fannounce&tr=udp%3a%2f%2ftracker.uw0.xyz%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.army%3a6969%2fannounce&tr=udp%3a%2f%2fmts.tvbit.co%3a6969%2fannounce&tr=https%3a%2f%2ftracker.coalition.space%3a443%2fannounce&tr=http%3a%2f%2ftracker-cdn.moeking.me%3a2095%2fannounce&tr=udp%3a%2f%2fline-net.ru%3a6969%2fannounce&tr=udp%3a%2f%2fperu.subventas.com%3a53%2fannounce&tr=udp%3a%2f%2fbt1.archive.org%3a6969%2fannounce&tr=udp%3a%2f%2fengplus.ru%3a6969%2fannounce&tr=udp%3a%2f%2fvalakas.rollo.dnsabr.com%3a2710%2fannounce&tr=udp%3a%2f%2fbt2.archive.org%3a6969%2fannounce&tr=udp%3a%2f%2fipv4.tracker.harry.lu%3a80%2fannounce&tr=udp%3a%2f%2ft1.leech.ie%3a1337%2fannounce&tr=http%3a%2f%2fbt.okmp3.ru%3a2710%2fannounce&tr=http%3a%2f%2fcloud.nyap2p.com%3a8080%2fannounce&tr=http%3a%2f%2ft.overflow.biz%3a6969%2fannounce&tr=udp%3a%2f%2ft3.leech.ie%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.bt4g.com%3a2095%2fannounce&tr=http%3a%2f%2ft.nyaatracker.com%3a80%2fannounce&tr=udp%3a%2f%2fudp-tracker.shittyurl.org%3a6969%2fannounce&tr=https%3a%2f%2f1337.abcvg.info%3a443%2fannounce&tr=https%3a%2f%2fw.wwwww.wtf%3a443%2fannounce&tr=udp%3a%2f%2fbt2.3kb.xyz%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.ds.is%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2fcdn-2.gamecoast.org%3a6969%2fannounce&tr=udp%3a%2f%2fretracker.netbynet.ru%3a2710%2fannounce&tr=udp%3a%2f%2fteamspeak.value-wolf.org%3a6969%2fannounce&tr=udp%3a%2f%2fcutiegirl.ru%3a6969%2fannounce&tr=http%3a%2f%2fh4.trakx.nibba.trade%3a80%2fannounce\n\n    Hash (for verification of authenticity etc):\n  \nc8fc9979cc35f7062cd8715aaaff4da475d2fadc\n\n    Size:\n  \n1,013.12GiB\nOriginal post below\n\n    Archiving videos before potential removal from various websites...\n  \n\n    Send or comment links of videos you need downloaded. Currently going through POV livestreams/replays.\n  \n\n\nNOTE:\n livestreams/POV are of the utmost importance. AKA Twitch/dlive/Facebook Live, etc. If you find any of these POV angles, please tag me directly in your comment, or PM me. These generally get taken down VERY fast by the livestream website.\n  \n\n\nUPDATE:\n\n\n\n    Thank you to everyone who shared links (and continue to do so). I am noticing that a lot of the content is now duplicates, or variations (crops, lower quality, etc) of the same content. So I have put all the content I have on MEGA. If I have replied to your comment then the content for sure is in this torrent.\n  \n\n    MEGA: \nhttps://mega.nz/folder/30MlkQib#RDOaGzmtFEHkxSYBaJSzVA\n (this is the prefered way of downloading)\n  \n\n    (This is sitting in at ~350GB as of Jan 10 3:00 PM EST. Still adding content)\n  \n\n\nUPDATE 2:\n Link should be working - MEGA contacted me and reinstated the account (and gave premium so I could upload more). \nI will be uploading more content that I find to the mega account.\n Still going through the comments, and the 900+ messages I have. Keep posting comments and I will upload them to the MEGA folder.\n  \n\n\nUPDATE 3:\n \n\"Bellingcat\"\n has created a really efficient way to submit media via a \nGoogle Spreadsheet.\n It's not connected to my archive, but I hope to have a merged final copy in the end.\n  \n\n\nUPDATE 4:\n\n\n\n    IF YOU WANT TO UPLOAD A FILE DIRECTLY TO ME: \nhttps://mega.nz/megadrop/fgve0WRa880\n (no account registration needed)\n  \n\n\nBACKUPS:\n\n\n\n    Recommended backup:\n  \n\n\nu/tweedge\n : \ntweedge commits to making sure this mirror does not fall behind 12h behind, though he'll do his best to keep it within 6h\n\n\n\n    Other backups based on the original MEGA from Jan 06 6:30PM - some might've updated, but no idea if/when; check each link, it should say. Or you can message the user:\n  \n\n    MAGNET from \nu/SneakyPieBrown\n as of Jan 08 2021 : magnet:?xt=urn:btih:fc33c9146c81660ee087dbda756746a978c7c104&dn=Trump%20protest%20Jan-08-2021&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a80\n  \n\n\nu/firstgrow\n  : \nhosting direct downloads as well\n\n\n\n\nu/nuzzles_u_uwu\n : \nIs hosting as well\n\n\n\n\nu/tweedge\n : \nmade a direct download link on s3\n\n\n\n\nu/kenkoda\n : \nposted a torrent.\n\n\n\n\nu/Deifer\n : \nLink\n\n\n\n\nu/benediktkr\n : \nhttps://mirrors.deadops.de/capitol2021\n and \nhttps://mirrors.deadops.de/capitol2021.zip\n\n\n\n\nSee a familiar face in the archive? \nhttps://tips.fbi.gov/digitalmedia/aad18481a3e8f02"},
{"Title": "Justin Roiland, co-creator of Rick and Morty, discovers that Dropbox uses content scanners through the deletion of all his data stored on their servers", "Author": "u/_G0D_M0DE_", "Content": "No content"},
{"Title": "yall might appreciate this", "Author": "u/ian9921", "Content": "No content"},
{"Title": "I just built a collapse-ready laptop. What are some must haves to put on it?", "Author": "u/evanMeaney", "Content": "No content"},
{"Title": "Rescue Mission for Sci-Hub and Open Science: We are the library.", "Author": "u/shrine", "Content": "EFF hears the call: \"It’s Time to Fight for Open Access\"\n\n\n\n\n\n\nEFF reports:\n \nActivists Mobilize to Fight Censorship and Save Open Science\n\n\n\n\n\n\n\n\n\"Continuing the long tradition of internet hacktivism ... redditors are mobilizing to create an uncensorable back-up of Sci-Hub\"\n\n\n\n\n\n\n\n    The EFF stands with Sci-Hub in the fight for Open Science, a fight for the human right to benefit and share in human scientific advancement. My wholehearted thanks for every seeder who takes part in this rescue mission, and every person who raises their voice in support of Sci-Hub's vision for Open Science.\n  \n\n\n\n\n\n\nRescue Mission Links\n\n\n\n\n\n\n\n\nQuick start to rescuing Sci-Hub\n: Download 1 random torrent (100GB) from the \nscimag index of torrents with fewer than 12 seeders\n, open the .torrent file using a BitTorrent client, then leave your client open to upload (seed) the articles to others. You're now part of an un-censorable library archive!\n  \n\n\n\n\n\n    Initial success update: The entire Sci-Hub collection has at least 3 seeders: \nLet's get it to 5. Let's get it to 7! Let’s get it to 10!\n Let’s get it to 12!\n  \n\n\n\n\n\n    Contribute to open source Sci-Hub projects: \nfreereadorg/awesome-libgen\n\n\n\n\n\n\n\n    Join \nr/scihub\n to stay up to date\n  \n\n\n\n\n\n\nNote: We have no affiliation with Sci-Hub\n\n\n\n\n\n\n\n    This effort is completely unaffiliated from Sci-Hub, no one is in touch with Sci-Hub, and I don't speak for Sci-Hub in any form. Always refer to \nsci-hub.do\n for the latest from Sci-Hub directly.\n  \n\n\n\n\n\n    This is a data preservation effort for just the articles, and does not help Sci-Hub directly.  Sci-Hub is not in any further imminent danger than it always has been, and is not at greater risk of being shut-down than before.\n  \n\n\n\n\nA Rescue Mission for Sci-Hub and Open Science\n\n    Elsevier and the USDOJ have declared war against Sci-Hub and open science. The era of Sci-Hub and Alexandra standing alone in this fight must end. We have to take a stand with her.\n  \n\n    On May 7th, Sci-Hub's Alexandra Elbakyan \nrevealed\n that the FBI has been wiretapping her accounts for over 2 years. This news comes after Twitter \nsilenced the official Sci_Hub\n twitter account because Indian academics were organizing on it against Elsevier.\n  \n\n    Sci-Hub itself is currently frozen and has not downloaded any new articles since December 2020. This rescue mission is focused on seeding the article collection in order to prepare for a potential Sci-Hub shutdown.\n  \n\n\nAlexandra Elbakyan\n of Sci-Hub, bookwarrior of \nLibrary Genesis\n, \nAaron Swartz\n, and countless unnamed others have fought to free science from the grips of for-profit publishers. Today, they do it working in hiding, alone, without acknowledgment, in fear of imprisonment, and even now wiretapped by the FBI. They sacrifice everything for one vision: Open Science.\n  \n\n    Why do they do it? They do it so that humble scholars on the other side of the planet can practice medicine, create science, fight for democracy, teach, and learn. People like Alexandra Elbakyan would give up their personal freedom for that one goal: to free knowledge. For that, Elsevier Corp (RELX, market cap: 50 billion) wants to silence her, wants to see her in prison, and wants to shut Sci-Hub down.\n  \n\n    It's time we sent Elsevier and the USDOJ a clearer message about the fate of Sci-Hub and open science: we are the library, we do not get silenced, we do not shut down our computers, and we are many.\n  \nRescue Mission for Sci-Hub\n\n    If you have been following the story, then you know that this is not our first rescue mission.\n  \n\n\n\n\n\n\nWe protected the Library Genesis book collection\n\n\n\n\n\n\n\n\nWe unlocked over 5,000 COVID-19 research articles\n\n\n\n\n\n\n\n\nWe successfully petitioned publishers to unlock their COVID-19 paywalls\n\n\n\n\n\n\n\n    bookwarrior, the \nfounder\n of Library Genesis, took his library \nonto the de-centralized and un-censorable IPFS web\n\n\n\n\n\n\n\n    Next? Make Sci-Hub un-censorable too.\n  \n\n\n\n\nRescue Target\n\n    A handful of Library Genesis seeders are currently seeding the Sci-Hub torrents. There are \n850 scihub torrents\n, each containing 100,000 scientific articles, to a total of 85 million scientific articles: 77TB. This is the complete Sci-Hub database. We need to protect this.\n  \nRescue Team\n\n\nWave 1:\n We need \n85 datahoarders\n to store and seed 1TB of articles each, 10 torrents in total. Download 10 random torrents from the \nscimag index of < 12 seeders\n, then load the torrents onto your client and seed for as long as you can. The articles are coded by DOI and in zip files.\n  \n\n\nWave 2:\n Reach out to \n10 good friends\n to ask them to grab just 1 random torrent (100GB). That's 850 seeders. We are now the library.\n  \n\n\nFinal Wave:\n Development for an open source Sci-Hub. \nfreereadorg/awesome-libgen\n is a collection of open source achievements based on the Sci-Hub and Library Genesis databases. Open source de-centralization of Sci-Hub is the ultimate goal here, and this begins with the data, but it is going to take years of developer sweat to carry these libraries into the future.\n  \n\n    Heartfelt thanks to the \nr/datahoarder\n and \nr/seedboxes\n communities, \nseedbox.io\n and \nNFOrce\n for your support for previous missions and your love for science."},
{"Title": "Data transfer to new Lustre storage overwhelms campus network", "Author": "u/e_spider", "Content": "No content"},
{"Title": "Whoops", "Author": "u/MidnightLink", "Content": "No content"},
{"Title": "A funny exchange", "Author": "Unknown author", "Content": "No content"},
{"Title": "One woman's quest to \"never delete anything\" allowed internet archivists to find long-lost Minecraft Alpha 1.1.1.", "Author": "u/BrikenEnglz", "Content": "No content"},
{"Title": "Amazon delivery driver with my new HD", "Author": "u/fancy_pantser", "Content": "No content"},
{"Title": "Apple sued for terminating account with $25,000 worth of apps and videos", "Author": "u/usernamechosen999", "Content": "No content"},
{"Title": "Some of the drives used to store the data to to compile the first picture ever of a black hole.", "Author": "u/the_best_moshe", "Content": "No content"},
{"Title": "Archivists Are Preserving Capitol Hill Riot Livestreams Before They’re Deleted", "Author": "u/fairyrocker91", "Content": "No content"},
{"Title": "Twitter to purge accounts that have had no activity at all for several years", "Author": "u/NXGZ", "Content": "No content"},
{"Title": "I can dream", "Author": "u/gammajayy", "Content": "No content"},
{"Title": "This is your regular reminder that Comcast is still a dumpster fire: Comcast to impose home internet data cap of 1.2TB in more than a dozen US states next year", "Author": "u/Snoot_Boopins", "Content": "No content"},
{"Title": "\"If you visit CERN in Geneva, you can buy 1 Terabyte of Large Hadron Collider data from the souvenir shop\"... there goes my kid's college funds", "Author": "Unknown author", "Content": "No content"},
{"Title": "yahoo answers is shutting down", "Author": "u/Fazlul101", "Content": "No content"},
{"Title": "internet archive is being sued", "Author": "u/sersoniko", "Content": "No content"},
{"Title": "Forklift accident", "Author": "u/Enkelie", "Content": "No content"},
{"Title": "Michigan couple must pay son $30,441 for throwing out porn collection", "Author": "u/benjacob", "Content": "No content"},
{"Title": "TIL the Library of Congress has a 2.129 petabyte (and growing) archive of internet culture", "Author": "u/WhitefangdDS", "Content": "No content"},
{"Title": "100Mbps uploads and downloads should be US broadband standard, senators say", "Author": "u/Unlanded", "Content": "No content"},
{"Title": "Art imitates life", "Author": "Unknown author", "Content": "No content"},
{"Title": "Remember this?", "Author": "u/YosoyPabloIscobar", "Content": "No content"},
{"Title": "Well now you know", "Author": "u/emmmmceeee", "Content": "No content"},
{"Title": "Ever wondered what 2 Peta Bytes looks like?", "Author": "u/P_G_R_A", "Content": "No content"},
{"Title": "youtube-dl repo had been DMCA'd", "Author": "u/anakinfredo", "Content": "No content"},
{"Title": "Kids, you up?", "Author": "u/diamondsw", "Content": "No content"},
{"Title": "Problem has been solved, 87 TB Array! No more Panik", "Author": "u/cdeveringham", "Content": "No content"},
{"Title": "Thought you all might find this interesting", "Author": "u/erik530195", "Content": "No content"},
{"Title": "API Clusterfuck! ~ We're locked, read this.", "Author": "u/-Archivist", "Content": "See reopening post.....\n\n    Hi everyone, we'll keep this short, you already know what's going on.\n  \n\n    As you've almost certainly heard by now Reddit is locking down their API starting July 1st with the introduction of paid usage. These changes are what killed pushshift.io (full reddit archives and searchable api used by mods and many research/academic papers) and what will kill most (if not all) third-party reddit clients. This is obviously a detriment to everyone, and while Reddit will almost certainly go through with these changes regardless, thousands of subreddits are going to be participating in a 2-day (or longer) blackout. You can read more about the blackouts at \nr/ModCoord\n. At the very least, the planned blackout seems to have convinced Reddit to give free API access to accessibility clients. Hopefully it can change their minds further.\n  \n\n\nr/DataHoarder\n will be locked for an undetermined amount of time, see \nthis thread\n for reddit data archives, tools, etc. we will also be using this time to update our sidebar links and do some general maintenance in the hopes that this mess doesn't mean the end for us and the many communities that see this as a killing of the Reddit we have loved over the years.\n  \nNote; during this time no new posts can be made and all comments are black-holed.\n\n    ~ The Mod Team, ciao for now.\n  \n\n    Track the blackout here: \nhttps://reddark.untone.uk"},
{"Title": "The Coronavirus Papers unlocked: 5,352 scientific articles covering the coronavirus - fully searchable and free.", "Author": "u/shrine", "Content": "2020-04-15 update: the-eye.eu is temporarily down, but the de-centralized Interplanetary File System (IPFS) link remains up.\n  \n\n    Note, \npublishers have made most Coronavirus articles free\n as of March 6th 2020.\n  \n\n    Visit \nr/libgen\n and \nr/scihub\n to join the open science revolution.\n  \nAccess\n\n\n\n\n\n\nArticle listing / Links\n\n\n\n\n\n\n\n\nOpen Directory\n\n\n\n\n\n\n\n\nFull-text Search\n\n\n\n\n\n\n\n\nTorrent\n\n\n\n\n\n\n\n\nInterPlanetary File System\n\n\n\n\n\n\nInformation\n\n    In a \n2015 New York Times op-ed\n the chief medical officer of Liberia argued that the Ebola pandemic responsible for the loss of over 2,200 lives could have been prevented if not for a paywall blocking access to an article from 1982. Dividing the world’s scientists with a paywall in the middle of a global humanitarian crisis is an unacceptable and unforgivable act of criminal greed. In the developing world the price for a single article can amount to as much as half a week’s salary for a physician. A few days ago, I found an early-release coronavirus article with a $35.95 access fee for non-subscribers. The fury I felt brought tears to my eyes.\n  \n\n    Me and a few friends share that fury, so we gathered a collection of five-thousand scientific studies covering any article title containing “\ncoronav*\n” from 1968-2020. The scope of the papers spans not only the 7 human coronaviruses, but up to 40 other Coronaviridae family strains. The Ebola virus showed us that every study counts. We are on the first step towards compiling a complete open-access Coronaviridae research catalog for the world’s scientists, journalists, and virology experts to draw from to fight the virus and save lives.\n  \n\n    Our project is illegal, but it’s the right thing to do in this crisis. We refuse to put copyright before human lives. Sharing everything we know about the virus is essential, \nwhich is why international scientists are openly sharing their coronavirus findings in an unprecedented way\n. Developing-world scientists often work without article access due to complex and expensive contract agreements between publishers, universities, and hospitals, relying on overseas colleagues to help them hunt down PDF files. The virus is not going to wait for this, so we need to act with conviction, now.\n  \n\n    To their credit, publishers made a few dozen papers open-access in the last few days, which you can find over at \nElsevier’s Novel Coronavirus Information Center\n and \nWiley’s Coronavirus collection.\n While Wiley is slating to shut down their collection in April, our collection won’t be shutting down anytime soon. We’re going to keep growing to help our scientists out, and you can help us complete the catalog by identifying any papers we missed. All extant Coronaviridae research, accessible in seconds, by any scientist in the world. It’s the least we can do to help.\n  \nMethodology\n\n\nHow did we do it?\n\n\n\n    We scanned \nSci-Hub\n's 80 million title collection for the coronavirus, then we extracted the titles and Digital Object Identifiers (DOI) to an index, and exported the PDF files to upload them to The-Eye.eu’s full-text search repository.\n  \n\n\nHow can I help?\n\n\n\n    We always need developers. You can also help us identify new articles by \njoining our team spreadsheet here\n. Request access and you can begin adding new article titles to the list. You can also help share word of the collection with the scientific community by reaching out to journalists.\n  \n\n\nWho is helping us?\n\n\n\n    Our brave host is \nThe-Eye.eu\n, a “non-profit, community driven platform dedicated to the archiving and long-term preservation of any and all data,” making this project just one of the many public access preservation projects they stand behind. You can aid projects like this one by \ndonating toward their server bills.\n\n\n\n\nA thank you to Sci-Hub and Library Genesis.\n\n\n\n    Last year communities across reddit (including \nr/seedboxes\n and \nr/DataHoarder\n) came together in a mission to secure and preserve Sci-Hub and Library Genesis, collectively the two largest free and open non-profit library collections in the world: Sci-Hub’s 80-million scientific article database that made this project possible, and LibGen’s 2.5-million scientific-book collection. The libraries fulfill United Nations world development goals mandating the removal of restrictions on access to science, and they serve developing world doctors, academic researchers, and other experts in society with the knowledge they need to build a better world. Keeping these libraries open and thriving means saving lives, educating the world, and providing invaluable science to humanity’s global experts.\n  \n\n\nThank you\n to everyone involved in the project, \nThe-Eye.eu\n for their support, and to all the scientists around the world working on behalf of humanity today."},
{"Title": "Twitter will remove free access to the Twitter API from 9 Feb 2023. Probably a good time to archive notable accounts now.", "Author": "u/babelfishery", "Content": "No content"},
{"Title": "Imgur is updating their TOS on May 15, 2023: All NSFW content to be banned", "Author": "u/trd86", "Content": "No content"},
{"Title": "Thought you guys would appreciate this.", "Author": "Unknown author", "Content": "No content"},
{"Title": "The only Nintendo 64 and 64 Disk Drive Development Data Tapes known to exist are now resting happily in my collection, and happy to say 5/6 are dumped and preserved. I'm told the last one has no data on it, but I will be working to recheck and verify that. Data can be found at ultra64.ca", "Author": "u/Carl_Sammons", "Content": "No content"},
{"Title": "I've collected all the iFixit repair guides in PDF format - 38,893 files", "Author": "u/makeworld", "Content": "iFixit\n and their \nguides\n are a great source for learning how to repair and fix electronics. They offer all their guides in PDF format, which I thought might be easier for viewing and self-containment then HTML.\n  \n\n    I've downloaded all their guides as PDFs, and put them into a single torrent. I think this is information that is very valuable to have offline - for power outages, remote travel/backpacking, the end of the world, etc. I'm hoping this can join some of your collections, beside Wikipedia and first aid pamphlets.\n  \n\n    Magnet link:\n  \nmagnet:?xt=urn:btih:ed9889445d52d7882e844bd926e1b547a2c00781&dn=pdfs.zip&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969%2Fannounce&tr=udp%3A%2F%2Fp4p.arenabg.com%3A1337%2Fannounce\n\n\nTorrent file\n\n\n\n    The torrent is just a single ZIP file named \npdfs.zip\n, that contains all the guides. It is about 60 gigabytes in total. Each guide is named by the name of the guide, for easy searching. Duplicate names were fixed by adding numbers to the end, as in \nguide name [2].pdf\n and \nguide name [3].pdf\n. All filenames are Windows safe.\n  \n\n    Keep in mind that my upload speeds are slow, and it may take a bit for your computer to find mine. But I have always-on server that is seeding it, so it will download eventually.\n  \n\n    The contents of the torrent will also be up on the Internet Archive \nhere\n, they are downloading it now. If you want to replicate what I've done, or update the archive yourself (I will try and update it every so often), there are wget and python3 scripts and source files (like lists of urls) in that archive as well. Those files are not part of the torrent.\n  \n\n    If you have any questions, or plan on seeding, let me know below!\n  \n\n    EDIT: As I mentioned above, my upload speed is slow. The torrent will take a very long time initially, and there's not much I can do about that. Feel free to come back in a couple days when there will be more than just me with a full copy."},
{"Title": "YouTube-dl’s repository has been restored", "Author": "u/DisastrousRhubarb", "Content": "No content"},
{"Title": "Z-Library isn't really gone, but that maybe up to you.", "Author": "u/-Archivist", "Content": "UPDATE2\n\n\n\n    TorrentFreak is covering this continuing story as new details come to light.\n  \n\n\n\n\nhttps://torrentfreak.com/tag/zlibrary/\n\n\n\n\n\n\nUPDATE\n ~\n  \n\n\n\n\n\n\nZ-Library Aftermath Reveals The Feds Seized Dozens of Domain Names\n @ TorrentFreak\n  \n\n\n\n\n\n    We'd also like to address some of the comments here asking \n\"how do I extract a book from this data\"\n.  \nr/DataHoader\n isn't a piracy supporting subreddit, a guide on how to extract books from these archives was purposefully left out. These torrents are presented as a \npreservation only archive\n and are not meant to aid book piracy or add books to your curated collections.\n  \n\n    Once upon a time in this sub this explanation wouldn't have been necessary. The thread will be cleaned and comment locked.\n  \n\n\nOriginal Thread\n\n\n\n    Millions woke up to news today that Z-Library domains have been seized, cries that z-lib is gone were heard from red core to black sky!... but that's not really the case so here is what you, a humble datahoarder can do about it.\n  \n\n    In case you missed it a unique to z-lib (deduped against LibGen) backup was made and published by \nu/pilimi_anna\n a little over a \nmonth ago.\n While you did a \ngreat job\n with SciHub, there's still work be done to ensure the preservation of all written works and cultural heritage. So here is the 5,998,794 book 27.8TB z-lib archive for you to hold, hoard, preserve, seed and proliferate.\n  \n\n\n\n\n\n\nDatabase\n | \nMirror\n ~ (metadata, extensions)\n  \n\n\n\n\n\n\nTorrents\n | \nTOR Mirror\n\n\n\n\n\n\n\n\nRelated Reading\n\n\n\n\n\n\n\n\nU.S. Authorities Seize Z-Library Domain Names\n @ TorrentFreak\n  \n\n\n\n\n\n\nTikTok Blocks Z-Library Hashtag\n @ TorrentFreak\n  \n\n\n\n\n\n\nZLibrary domains have been seized\n @ HackerNews\n  \n\n\n\n\n\n\nISBNdb Dump – How many books are preserved forever?\n @ Annas-Blog\n  \n\n\n\n\n\n\nMission to preserve SciHub\n @ \nr/DataHoarder\n\n\n\n\n\n\n\n\nAlternative Libraries / Free eBook Hosts\n\n\n\n\n\n\n\n\nOpenLibrary\n\n\n\n\n\n\n\n\nLibrary Genesis\n | \nIPFS\n\n\n\n\n\n\n\n\nPDF Drive\n\n\n\n\n\n\n\n\nSci-Hub\n\n\n\n\n\n\n\n\nGutenberg\n\n\n\n\n\n\n\n\nObooko\n\n\n\n\n\n\n\n\nManyBooks\n\n\n\n\n\n\n\n\nFreeBookSpot\n\n\n\n\n\n\n\n\nThe Anarchist Library \n\n\n\n\n\n\n\n\nClosing\n\n\n\n    Support authors you love.. But abolish the strangle hold of DRM and licensing that kills ownership, seek to squash abuse of the DMCA, move to limit copyright terms and above all aim to ensure Alexandria doesn't burn twice.\n  \n\n\nUkraine Crisis ^Megathread\n \nwill\n \nreplace\n \nthis\n \nthread\n \nagain\n \nwithin\n \n7\n \ndays."},
{"Title": "The dream 🙏", "Author": "u/DragoniteChamp", "Content": "No content"},
{"Title": "Not just SATA . . .", "Author": "Unknown author", "Content": "No content"},
{"Title": "Anon loses 8 terabytes of data", "Author": "u/Epoxhy", "Content": "No content"},
{"Title": "Been watching everyone panic over HBO Max gutting it's library like a fish.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "In 1999 Amazon stored .5GB or “about 350 floppy disks” of data about its users every day", "Author": "u/the_best_moshe", "Content": "No content"},
{"Title": "I'm sorry Hasan. :(", "Author": "u/hobbseltoff", "Content": "No content"},
{"Title": "URGENT: Hong Kong Stand News to cease operations immediately after directors arrested this morning. Please help backup social media and website!", "Author": "u/TheIrishPanther", "Content": "No content"},
{"Title": "Two months ago, when I go a 16TB swapped for an 8TB from Amazon, and everyone told me I was getting catfished by someone pretending to be Seagate's head of global security? Here's the free 10TB Exos Seagate sent me direct from HQ 'for my trouble'. :P", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Youtube deleted a channel that made educational ethical hacking videos. Other Channels on the same topic face a risk of being taken down. Can you help and archive the channels that haven’t been deleted yet.", "Author": "u/latuziti", "Content": "The channel zSecurity was was deleted\n and it seem like other youtube channels that make ethical hacking content might face the same risk.\n  \n\n    If you can help please backup that following youtube channels.\n  \n\n\n\n\n\n    HackerSploit - \nhttps://www.youtube.com/channel/UC0ZTPkdxlAKf-V33tqXwi3Q/videos\n\n\n\n\n\n\n\n    Sam Bowne - \nhttps://www.youtube.com/user/sambowne/videos\n\n\n\n\n\n\n\n    LiveOverflow - \nhttps://www.youtube.com/channel/UClcE-kVhqyiHCcjYwcpfj9w/videos\n\n\n\n\n\n\n\n    Null Byte - \nhttps://www.youtube.com/channel/UCgTNupxATBfWmfehv21ym-g/videos\n\n\n\n\n\n\n\n    InsiderPhD - \nhttps://www.youtube.com/c/InsiderPhD/videos\n\n\n\n\n\n\n\n    Loi Liang Yang - \nhttps://www.youtube.com/channel/UC1szFCBUWXY3ESff8dJjjzw/videos\n\n\n\n\n\n\n\n    STÖK - \nhttps://www.youtube.com/c/STOKfredrik/videos\n\n\n\n\n\n\n\n    The Cyber Mentor - \nhttps://www.youtube.com/channel/UC0ArlFuFYMpEewyRBzdLHiw\n\n\n\n\n\n\n\n    Guided Hacking - \nhttps://www.youtube.com/user/L4DL4D2EUROPE/videos\n\n\n\n\n\n\n\n    Null - \nhttps://www.youtube.com/channel/UCZF93Qrt6yMAabRnlND4YsQ/videos\n\n\n\n\n\n\n\n    Cheat The Game - \nhttps://www.youtube.com/user/BloodFayte/videos\n\n\n\n\n\n\n\n    Stephen Chapman - \nhttps://www.youtube.com/user/seowhistleblower/videos\n\n\n\n\n\n\n\n    Cristi Vlad - \nhttps://www.youtube.com/user/cristivlad25/videos\n\n\n\n\n\n\n\n    DC CyberSec - \nhttps://www.youtube.com/channel/UC3sccPO4v8YqCTn8sezZGTw/videos\n\n\n\n\n\n\n\n    Joseph Delgadillo  - \nhttps://www.youtube.com/c/JosephDelgadillo/videos\n\n\n\n\n\n\n\n    Nahamsec - \nhttps://www.youtube.com/c/Nahamsec/videos\n\n\n\n\n\n\n\n    I.T Security Labs - \nhttps://www.youtube.com/c/ITSecurityLabs/videos\n\n\n\n\n\n\n\n    Red Team Village - \nhttps://www.youtube.com/c/RedTeamVillage/videos\n\n\n\n\n\n\n\n    People have recommended other youtube channels to archive. I'll add them here\n  \n\n\n\n\n\n    Deviant Ollam - \nhttps://www.youtube.com/user/DeviantOllam\n\n\n\n\n\n\n\n    LockpickingLawyer - \nhttps://www.youtube.com/channel/UCm9K6rby98W8JigLoZOh6FQ\n\n\n\n\n\n\n\n    BosnianBill - \nhttps://www.youtube.com/user/bosnianbill\n\n\n\n\n\n\n\n    13Cubed - \nhttps://www.youtube.com/c/13cubed/videos\n\n\n\n\n\n\n\n    Jose Barrientos - \nhttps://www.youtube.com/user/Greiko\n\n\n\n\n\n\n\n    Update 2:\n  \n\n\n\n\n\n    Cyberspatial - \nhttps://www.youtube.com/c/Cyberspatial/videos\n\n\n\n\n\n\n\n    Nahamsec - \nhttps://www.youtube.com/c/Nahamsec/videos\n\n\n\n\n\n\n\n    pwn.college - \nhttps://www.youtube.com/channel/UCBaWwFw7KmCN8YlfX4ERYKg/videos\n\n\n\n\n\n\n\n    Farah Hawa - \nhttps://www.youtube.com/c/FarahHawa/videos\n\n\n\n\n\n\n\n    Web Development Tutorials - \nhttps://www.youtube.com/c/yaworsk1/videos\n\n\n\n\n\n\n\n    OALabs - \nhttps://www.youtube.com/c/OALabs/videos\n\n\n\n\n\n\n\n    Hacksplained - \nhttps://www.youtube.com/c/Hacksplained/videos\n\n\n\n\n\n\n\n    Update 3: zecurity channel has been restored. It should be backedup just in case something like this happens again. \nhttps://www.youtube.com/zsecurity"},
{"Title": "Data hoarding is older than we thought! MAD Magazine 215 from 1980", "Author": "u/Hong-Hong-Hang-Hang", "Content": "No content"},
{"Title": "Hello, r/DataHoarder! We’re iFixit, and we just launched the world’s most comprehensive medical equipment repair database", "Author": "u/Craig_iFixit", "Content": "After my \nrecent comment\n on here blew up, I figured you all would get a kick out of this.\n  \n\n\nTL;DR:\n We scraped the internet for any and all medical equipment repair documentation we could find. We ended up with over 13,000 PDFs across 5,000 medical devices, all \nuploaded to iFixit.com and available for free\n to anyone and everyone.\n  \n\n    -----\n  \n\n    Hospitals are having trouble getting service information to fix medical equipment and manufacturers can’t keep pace with the growing demand for repair of critical hospital equipment. On top of that, biomedical technicians spend countless hours scouring the internet searching for crucial repair information. This is not a great way to run a health system.\n  \n\n    So we’ve been fixing that. Over the last two months, \nwe’ve pivoted half our company to build the world’s most comprehensive medical equipment service database\n. We just posted more than 13,000 PDFs from hundreds of manufacturers—online and available for free. You can find them in our \nMedical Device\n category.\n  \n\n    This has been an absolutely massive undertaking, and we were fortunate to have the help and support of over 200 librarians and archivists from across the country. Archivists from university and public libraries, research institutes, insurance and software companies, and of course biomedical technicians themselves, all donated their valuable time. Collectively, they’ve contributed thousands of hours organizing piles of documents into a navigable, searchable system.\n  \n\n    Some medical manufacturers, like \nMindray\n, allow biomeds to access their manuals freely. A few more released select documents after the outbreak of COVID-19. But for their day-to-day work, biomeds have long relied on a rag-tag set of web resources to get the job done. Among the most popular is \nFrank’s Hospital Workshop\n, a Tanzania-based site that hosts hundreds of medical device manuals—it’s the unofficial biomed bible.\n  \n\n    But we wanted to make it easier for anyone to find the right manual, especially in an emergency. Some of the documents in our collection were already available. \nOthers were not publicly posted until now\n. And it was important to us that this resource didn’t just duplicate existing resources, but improved accessibility in a meaningful way.\n  \n\n    To be very clear: \niFixit will not make any money off of this project\n. We are providing hosting and curation free of charge, and free of advertising, to the medical community.\n  \n\n    We welcome manufacturers to join us and contribute toward an up-to-date central repository for the biomedical community, as well as biomedical technicians around the world to join \niFixit’s repair community\n. No technician is an island, and we hope to facilitate an exchange of knowledge and troubleshooting. This medical repository is most useful if it’s collaboratively moderated by biomedical technicians, with our assistance."},
{"Title": "[Offtopic] Girlfriend took one look at the shell of a shucked EasyStore... “You need that?”", "Author": "u/DannyVFilms", "Content": "No content"},
{"Title": "Russianaircraft.net scrubs all military aircraft in a likely effort to prevent identification of downed Russian aircraft - If you ever needed a better justification for datahoarding, here it is.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Kids, you up?", "Author": "u/diamondsw", "Content": "No content"},
{"Title": "Problem has been solved, 87 TB Array! No more Panik", "Author": "u/cdeveringham", "Content": "No content"},
{"Title": "Thought you all might find this interesting", "Author": "u/erik530195", "Content": "No content"},
{"Title": "API Clusterfuck! ~ We're locked, read this.", "Author": "u/-Archivist", "Content": "See reopening post.....\n\n    Hi everyone, we'll keep this short, you already know what's going on.\n  \n\n    As you've almost certainly heard by now Reddit is locking down their API starting July 1st with the introduction of paid usage. These changes are what killed pushshift.io (full reddit archives and searchable api used by mods and many research/academic papers) and what will kill most (if not all) third-party reddit clients. This is obviously a detriment to everyone, and while Reddit will almost certainly go through with these changes regardless, thousands of subreddits are going to be participating in a 2-day (or longer) blackout. You can read more about the blackouts at \nr/ModCoord\n. At the very least, the planned blackout seems to have convinced Reddit to give free API access to accessibility clients. Hopefully it can change their minds further.\n  \n\n\nr/DataHoarder\n will be locked for an undetermined amount of time, see \nthis thread\n for reddit data archives, tools, etc. we will also be using this time to update our sidebar links and do some general maintenance in the hopes that this mess doesn't mean the end for us and the many communities that see this as a killing of the Reddit we have loved over the years.\n  \nNote; during this time no new posts can be made and all comments are black-holed.\n\n    ~ The Mod Team, ciao for now.\n  \n\n    Track the blackout here: \nhttps://reddark.untone.uk"},
{"Title": "The Coronavirus Papers unlocked: 5,352 scientific articles covering the coronavirus - fully searchable and free.", "Author": "u/shrine", "Content": "2020-04-15 update: the-eye.eu is temporarily down, but the de-centralized Interplanetary File System (IPFS) link remains up.\n  \n\n    Note, \npublishers have made most Coronavirus articles free\n as of March 6th 2020.\n  \n\n    Visit \nr/libgen\n and \nr/scihub\n to join the open science revolution.\n  \nAccess\n\n\n\n\n\n\nArticle listing / Links\n\n\n\n\n\n\n\n\nOpen Directory\n\n\n\n\n\n\n\n\nFull-text Search\n\n\n\n\n\n\n\n\nTorrent\n\n\n\n\n\n\n\n\nInterPlanetary File System\n\n\n\n\n\n\nInformation\n\n    In a \n2015 New York Times op-ed\n the chief medical officer of Liberia argued that the Ebola pandemic responsible for the loss of over 2,200 lives could have been prevented if not for a paywall blocking access to an article from 1982. Dividing the world’s scientists with a paywall in the middle of a global humanitarian crisis is an unacceptable and unforgivable act of criminal greed. In the developing world the price for a single article can amount to as much as half a week’s salary for a physician. A few days ago, I found an early-release coronavirus article with a $35.95 access fee for non-subscribers. The fury I felt brought tears to my eyes.\n  \n\n    Me and a few friends share that fury, so we gathered a collection of five-thousand scientific studies covering any article title containing “\ncoronav*\n” from 1968-2020. The scope of the papers spans not only the 7 human coronaviruses, but up to 40 other Coronaviridae family strains. The Ebola virus showed us that every study counts. We are on the first step towards compiling a complete open-access Coronaviridae research catalog for the world’s scientists, journalists, and virology experts to draw from to fight the virus and save lives.\n  \n\n    Our project is illegal, but it’s the right thing to do in this crisis. We refuse to put copyright before human lives. Sharing everything we know about the virus is essential, \nwhich is why international scientists are openly sharing their coronavirus findings in an unprecedented way\n. Developing-world scientists often work without article access due to complex and expensive contract agreements between publishers, universities, and hospitals, relying on overseas colleagues to help them hunt down PDF files. The virus is not going to wait for this, so we need to act with conviction, now.\n  \n\n    To their credit, publishers made a few dozen papers open-access in the last few days, which you can find over at \nElsevier’s Novel Coronavirus Information Center\n and \nWiley’s Coronavirus collection.\n While Wiley is slating to shut down their collection in April, our collection won’t be shutting down anytime soon. We’re going to keep growing to help our scientists out, and you can help us complete the catalog by identifying any papers we missed. All extant Coronaviridae research, accessible in seconds, by any scientist in the world. It’s the least we can do to help.\n  \nMethodology\n\n\nHow did we do it?\n\n\n\n    We scanned \nSci-Hub\n's 80 million title collection for the coronavirus, then we extracted the titles and Digital Object Identifiers (DOI) to an index, and exported the PDF files to upload them to The-Eye.eu’s full-text search repository.\n  \n\n\nHow can I help?\n\n\n\n    We always need developers. You can also help us identify new articles by \njoining our team spreadsheet here\n. Request access and you can begin adding new article titles to the list. You can also help share word of the collection with the scientific community by reaching out to journalists.\n  \n\n\nWho is helping us?\n\n\n\n    Our brave host is \nThe-Eye.eu\n, a “non-profit, community driven platform dedicated to the archiving and long-term preservation of any and all data,” making this project just one of the many public access preservation projects they stand behind. You can aid projects like this one by \ndonating toward their server bills.\n\n\n\n\nA thank you to Sci-Hub and Library Genesis.\n\n\n\n    Last year communities across reddit (including \nr/seedboxes\n and \nr/DataHoarder\n) came together in a mission to secure and preserve Sci-Hub and Library Genesis, collectively the two largest free and open non-profit library collections in the world: Sci-Hub’s 80-million scientific article database that made this project possible, and LibGen’s 2.5-million scientific-book collection. The libraries fulfill United Nations world development goals mandating the removal of restrictions on access to science, and they serve developing world doctors, academic researchers, and other experts in society with the knowledge they need to build a better world. Keeping these libraries open and thriving means saving lives, educating the world, and providing invaluable science to humanity’s global experts.\n  \n\n\nThank you\n to everyone involved in the project, \nThe-Eye.eu\n for their support, and to all the scientists around the world working on behalf of humanity today."},
{"Title": "Twitter will remove free access to the Twitter API from 9 Feb 2023. Probably a good time to archive notable accounts now.", "Author": "u/babelfishery", "Content": "No content"},
{"Title": "Imgur is updating their TOS on May 15, 2023: All NSFW content to be banned", "Author": "u/trd86", "Content": "No content"},
{"Title": "Thought you guys would appreciate this.", "Author": "Unknown author", "Content": "No content"},
{"Title": "The only Nintendo 64 and 64 Disk Drive Development Data Tapes known to exist are now resting happily in my collection, and happy to say 5/6 are dumped and preserved. I'm told the last one has no data on it, but I will be working to recheck and verify that. Data can be found at ultra64.ca", "Author": "u/Carl_Sammons", "Content": "No content"},
{"Title": "I've collected all the iFixit repair guides in PDF format - 38,893 files", "Author": "u/makeworld", "Content": "iFixit\n and their \nguides\n are a great source for learning how to repair and fix electronics. They offer all their guides in PDF format, which I thought might be easier for viewing and self-containment then HTML.\n  \n\n    I've downloaded all their guides as PDFs, and put them into a single torrent. I think this is information that is very valuable to have offline - for power outages, remote travel/backpacking, the end of the world, etc. I'm hoping this can join some of your collections, beside Wikipedia and first aid pamphlets.\n  \n\n    Magnet link:\n  \nmagnet:?xt=urn:btih:ed9889445d52d7882e844bd926e1b547a2c00781&dn=pdfs.zip&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969%2Fannounce&tr=udp%3A%2F%2Fp4p.arenabg.com%3A1337%2Fannounce\n\n\nTorrent file\n\n\n\n    The torrent is just a single ZIP file named \npdfs.zip\n, that contains all the guides. It is about 60 gigabytes in total. Each guide is named by the name of the guide, for easy searching. Duplicate names were fixed by adding numbers to the end, as in \nguide name [2].pdf\n and \nguide name [3].pdf\n. All filenames are Windows safe.\n  \n\n    Keep in mind that my upload speeds are slow, and it may take a bit for your computer to find mine. But I have always-on server that is seeding it, so it will download eventually.\n  \n\n    The contents of the torrent will also be up on the Internet Archive \nhere\n, they are downloading it now. If you want to replicate what I've done, or update the archive yourself (I will try and update it every so often), there are wget and python3 scripts and source files (like lists of urls) in that archive as well. Those files are not part of the torrent.\n  \n\n    If you have any questions, or plan on seeding, let me know below!\n  \n\n    EDIT: As I mentioned above, my upload speed is slow. The torrent will take a very long time initially, and there's not much I can do about that. Feel free to come back in a couple days when there will be more than just me with a full copy."},
{"Title": "YouTube-dl’s repository has been restored", "Author": "u/DisastrousRhubarb", "Content": "No content"},
{"Title": "Z-Library isn't really gone, but that maybe up to you.", "Author": "u/-Archivist", "Content": "UPDATE2\n\n\n\n    TorrentFreak is covering this continuing story as new details come to light.\n  \n\n\n\n\nhttps://torrentfreak.com/tag/zlibrary/\n\n\n\n\n\n\nUPDATE\n ~\n  \n\n\n\n\n\n\nZ-Library Aftermath Reveals The Feds Seized Dozens of Domain Names\n @ TorrentFreak\n  \n\n\n\n\n\n    We'd also like to address some of the comments here asking \n\"how do I extract a book from this data\"\n.  \nr/DataHoader\n isn't a piracy supporting subreddit, a guide on how to extract books from these archives was purposefully left out. These torrents are presented as a \npreservation only archive\n and are not meant to aid book piracy or add books to your curated collections.\n  \n\n    Once upon a time in this sub this explanation wouldn't have been necessary. The thread will be cleaned and comment locked.\n  \n\n\nOriginal Thread\n\n\n\n    Millions woke up to news today that Z-Library domains have been seized, cries that z-lib is gone were heard from red core to black sky!... but that's not really the case so here is what you, a humble datahoarder can do about it.\n  \n\n    In case you missed it a unique to z-lib (deduped against LibGen) backup was made and published by \nu/pilimi_anna\n a little over a \nmonth ago.\n While you did a \ngreat job\n with SciHub, there's still work be done to ensure the preservation of all written works and cultural heritage. So here is the 5,998,794 book 27.8TB z-lib archive for you to hold, hoard, preserve, seed and proliferate.\n  \n\n\n\n\n\n\nDatabase\n | \nMirror\n ~ (metadata, extensions)\n  \n\n\n\n\n\n\nTorrents\n | \nTOR Mirror\n\n\n\n\n\n\n\n\nRelated Reading\n\n\n\n\n\n\n\n\nU.S. Authorities Seize Z-Library Domain Names\n @ TorrentFreak\n  \n\n\n\n\n\n\nTikTok Blocks Z-Library Hashtag\n @ TorrentFreak\n  \n\n\n\n\n\n\nZLibrary domains have been seized\n @ HackerNews\n  \n\n\n\n\n\n\nISBNdb Dump – How many books are preserved forever?\n @ Annas-Blog\n  \n\n\n\n\n\n\nMission to preserve SciHub\n @ \nr/DataHoarder\n\n\n\n\n\n\n\n\nAlternative Libraries / Free eBook Hosts\n\n\n\n\n\n\n\n\nOpenLibrary\n\n\n\n\n\n\n\n\nLibrary Genesis\n | \nIPFS\n\n\n\n\n\n\n\n\nPDF Drive\n\n\n\n\n\n\n\n\nSci-Hub\n\n\n\n\n\n\n\n\nGutenberg\n\n\n\n\n\n\n\n\nObooko\n\n\n\n\n\n\n\n\nManyBooks\n\n\n\n\n\n\n\n\nFreeBookSpot\n\n\n\n\n\n\n\n\nThe Anarchist Library \n\n\n\n\n\n\n\n\nClosing\n\n\n\n    Support authors you love.. But abolish the strangle hold of DRM and licensing that kills ownership, seek to squash abuse of the DMCA, move to limit copyright terms and above all aim to ensure Alexandria doesn't burn twice.\n  \n\n\nUkraine Crisis ^Megathread\n \nwill\n \nreplace\n \nthis\n \nthread\n \nagain\n \nwithin\n \n7\n \ndays."},
{"Title": "The dream 🙏", "Author": "u/DragoniteChamp", "Content": "No content"},
{"Title": "Not just SATA . . .", "Author": "Unknown author", "Content": "No content"},
{"Title": "Anon loses 8 terabytes of data", "Author": "u/Epoxhy", "Content": "No content"},
{"Title": "Been watching everyone panic over HBO Max gutting it's library like a fish.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "In 1999 Amazon stored .5GB or “about 350 floppy disks” of data about its users every day", "Author": "u/the_best_moshe", "Content": "No content"},
{"Title": "I'm sorry Hasan. :(", "Author": "u/hobbseltoff", "Content": "No content"},
{"Title": "URGENT: Hong Kong Stand News to cease operations immediately after directors arrested this morning. Please help backup social media and website!", "Author": "u/TheIrishPanther", "Content": "No content"},
{"Title": "Two months ago, when I go a 16TB swapped for an 8TB from Amazon, and everyone told me I was getting catfished by someone pretending to be Seagate's head of global security? Here's the free 10TB Exos Seagate sent me direct from HQ 'for my trouble'. :P", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Youtube deleted a channel that made educational ethical hacking videos. Other Channels on the same topic face a risk of being taken down. Can you help and archive the channels that haven’t been deleted yet.", "Author": "u/latuziti", "Content": "The channel zSecurity was was deleted\n and it seem like other youtube channels that make ethical hacking content might face the same risk.\n  \n\n    If you can help please backup that following youtube channels.\n  \n\n\n\n\n\n    HackerSploit - \nhttps://www.youtube.com/channel/UC0ZTPkdxlAKf-V33tqXwi3Q/videos\n\n\n\n\n\n\n\n    Sam Bowne - \nhttps://www.youtube.com/user/sambowne/videos\n\n\n\n\n\n\n\n    LiveOverflow - \nhttps://www.youtube.com/channel/UClcE-kVhqyiHCcjYwcpfj9w/videos\n\n\n\n\n\n\n\n    Null Byte - \nhttps://www.youtube.com/channel/UCgTNupxATBfWmfehv21ym-g/videos\n\n\n\n\n\n\n\n    InsiderPhD - \nhttps://www.youtube.com/c/InsiderPhD/videos\n\n\n\n\n\n\n\n    Loi Liang Yang - \nhttps://www.youtube.com/channel/UC1szFCBUWXY3ESff8dJjjzw/videos\n\n\n\n\n\n\n\n    STÖK - \nhttps://www.youtube.com/c/STOKfredrik/videos\n\n\n\n\n\n\n\n    The Cyber Mentor - \nhttps://www.youtube.com/channel/UC0ArlFuFYMpEewyRBzdLHiw\n\n\n\n\n\n\n\n    Guided Hacking - \nhttps://www.youtube.com/user/L4DL4D2EUROPE/videos\n\n\n\n\n\n\n\n    Null - \nhttps://www.youtube.com/channel/UCZF93Qrt6yMAabRnlND4YsQ/videos\n\n\n\n\n\n\n\n    Cheat The Game - \nhttps://www.youtube.com/user/BloodFayte/videos\n\n\n\n\n\n\n\n    Stephen Chapman - \nhttps://www.youtube.com/user/seowhistleblower/videos\n\n\n\n\n\n\n\n    Cristi Vlad - \nhttps://www.youtube.com/user/cristivlad25/videos\n\n\n\n\n\n\n\n    DC CyberSec - \nhttps://www.youtube.com/channel/UC3sccPO4v8YqCTn8sezZGTw/videos\n\n\n\n\n\n\n\n    Joseph Delgadillo  - \nhttps://www.youtube.com/c/JosephDelgadillo/videos\n\n\n\n\n\n\n\n    Nahamsec - \nhttps://www.youtube.com/c/Nahamsec/videos\n\n\n\n\n\n\n\n    I.T Security Labs - \nhttps://www.youtube.com/c/ITSecurityLabs/videos\n\n\n\n\n\n\n\n    Red Team Village - \nhttps://www.youtube.com/c/RedTeamVillage/videos\n\n\n\n\n\n\n\n    People have recommended other youtube channels to archive. I'll add them here\n  \n\n\n\n\n\n    Deviant Ollam - \nhttps://www.youtube.com/user/DeviantOllam\n\n\n\n\n\n\n\n    LockpickingLawyer - \nhttps://www.youtube.com/channel/UCm9K6rby98W8JigLoZOh6FQ\n\n\n\n\n\n\n\n    BosnianBill - \nhttps://www.youtube.com/user/bosnianbill\n\n\n\n\n\n\n\n    13Cubed - \nhttps://www.youtube.com/c/13cubed/videos\n\n\n\n\n\n\n\n    Jose Barrientos - \nhttps://www.youtube.com/user/Greiko\n\n\n\n\n\n\n\n    Update 2:\n  \n\n\n\n\n\n    Cyberspatial - \nhttps://www.youtube.com/c/Cyberspatial/videos\n\n\n\n\n\n\n\n    Nahamsec - \nhttps://www.youtube.com/c/Nahamsec/videos\n\n\n\n\n\n\n\n    pwn.college - \nhttps://www.youtube.com/channel/UCBaWwFw7KmCN8YlfX4ERYKg/videos\n\n\n\n\n\n\n\n    Farah Hawa - \nhttps://www.youtube.com/c/FarahHawa/videos\n\n\n\n\n\n\n\n    Web Development Tutorials - \nhttps://www.youtube.com/c/yaworsk1/videos\n\n\n\n\n\n\n\n    OALabs - \nhttps://www.youtube.com/c/OALabs/videos\n\n\n\n\n\n\n\n    Hacksplained - \nhttps://www.youtube.com/c/Hacksplained/videos\n\n\n\n\n\n\n\n    Update 3: zecurity channel has been restored. It should be backedup just in case something like this happens again. \nhttps://www.youtube.com/zsecurity"},
{"Title": "Data hoarding is older than we thought! MAD Magazine 215 from 1980", "Author": "u/Hong-Hong-Hang-Hang", "Content": "No content"},
{"Title": "Hello, r/DataHoarder! We’re iFixit, and we just launched the world’s most comprehensive medical equipment repair database", "Author": "u/Craig_iFixit", "Content": "After my \nrecent comment\n on here blew up, I figured you all would get a kick out of this.\n  \n\n\nTL;DR:\n We scraped the internet for any and all medical equipment repair documentation we could find. We ended up with over 13,000 PDFs across 5,000 medical devices, all \nuploaded to iFixit.com and available for free\n to anyone and everyone.\n  \n\n    -----\n  \n\n    Hospitals are having trouble getting service information to fix medical equipment and manufacturers can’t keep pace with the growing demand for repair of critical hospital equipment. On top of that, biomedical technicians spend countless hours scouring the internet searching for crucial repair information. This is not a great way to run a health system.\n  \n\n    So we’ve been fixing that. Over the last two months, \nwe’ve pivoted half our company to build the world’s most comprehensive medical equipment service database\n. We just posted more than 13,000 PDFs from hundreds of manufacturers—online and available for free. You can find them in our \nMedical Device\n category.\n  \n\n    This has been an absolutely massive undertaking, and we were fortunate to have the help and support of over 200 librarians and archivists from across the country. Archivists from university and public libraries, research institutes, insurance and software companies, and of course biomedical technicians themselves, all donated their valuable time. Collectively, they’ve contributed thousands of hours organizing piles of documents into a navigable, searchable system.\n  \n\n    Some medical manufacturers, like \nMindray\n, allow biomeds to access their manuals freely. A few more released select documents after the outbreak of COVID-19. But for their day-to-day work, biomeds have long relied on a rag-tag set of web resources to get the job done. Among the most popular is \nFrank’s Hospital Workshop\n, a Tanzania-based site that hosts hundreds of medical device manuals—it’s the unofficial biomed bible.\n  \n\n    But we wanted to make it easier for anyone to find the right manual, especially in an emergency. Some of the documents in our collection were already available. \nOthers were not publicly posted until now\n. And it was important to us that this resource didn’t just duplicate existing resources, but improved accessibility in a meaningful way.\n  \n\n    To be very clear: \niFixit will not make any money off of this project\n. We are providing hosting and curation free of charge, and free of advertising, to the medical community.\n  \n\n    We welcome manufacturers to join us and contribute toward an up-to-date central repository for the biomedical community, as well as biomedical technicians around the world to join \niFixit’s repair community\n. No technician is an island, and we hope to facilitate an exchange of knowledge and troubleshooting. This medical repository is most useful if it’s collaboratively moderated by biomedical technicians, with our assistance."},
{"Title": "[Offtopic] Girlfriend took one look at the shell of a shucked EasyStore... “You need that?”", "Author": "u/DannyVFilms", "Content": "No content"},
{"Title": "Russianaircraft.net scrubs all military aircraft in a likely effort to prevent identification of downed Russian aircraft - If you ever needed a better justification for datahoarding, here it is.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Did you know that at the Internet Archive a light blinks on one of their servers every time you use their collections?", "Author": "u/storytracer", "Content": "No content"},
{"Title": "Zippyshare is shutting down", "Author": "u/giratina143", "Content": "No content"},
{"Title": "relatable to you guys?", "Author": "u/MysteriousK69420", "Content": "No content"},
{"Title": "Fujifilm refuses to pay ransomware demand, relies on backups", "Author": "u/razeus", "Content": "No content"},
{"Title": "ArchiveTeam has saved over 10.8 BILLION Reddit links so far. We need YOUR help running ArchiveTeam Warrior to archive subreddits before they're gone indefinitely after June 12th!", "Author": "u/BananaBus43", "Content": "ArchiveTeam has been archiving Reddit posts for a while now, but we are running out of time. \nSo far, we have archived 10.81 billion links, with 150 million to go\n.\n  \n\n    Recent news of the \nReddit API cost changes\n will force many of the top 3rd party Reddit apps to shut down. This will not only affect how people use Reddit, but it will also cause issues with many subreddit moderation bots which rely on the API to function. Many subreddits have agreed to shut down for 48 hours on June 12th, while others will be gone \nindefinitely\n unless this issue is resolved. We are archiving Reddit posts so that in the event that the API cost change is never addressed, we can still access posts from those closed subreddits.\n  \nHere is how you can help:\nChoose the \"host\" that matches your current PC, probably Windows or macOS\nDownload ArchiveTeam Warrior\n\n\n\n\n\n    In VirtualBox, click File > Import Appliance and open the file.\n  \n\n\n\n\n\n    Start the virtual machine. It will fetch the latest updates and will eventually tell you to start your web browser.\n  \n\n\n\n\n\n    Once you’ve started your warrior:\n  \n\n\n\n\n\n    Go to http://localhost:8001/ and check the Settings page.\n  \n\n\n\n\n\n    Choose a username — we’ll show your progress on the leaderboard.\n  \n\n\n\n\n\n    Go to the \"All projects\" tab and select ArchiveTeam’s Choice to let your warrior work on the most urgent project. (This will be Reddit).\n  \n\n\n\n\nAlternative Method: Docker\nDownload Docker on your \"host\" (Windows, macOS, Linux)\nFollow the instructions on the ArchiveTeam website to set up Docker\n\n    When setting up the project container, it will ask you to enter this command:\n  \n\n\ndocker run -d --name archiveteam --label=com.centurylinklabs.watchtower.enable=true --restart=unless-stopped [image address] --concurrent 1 [username]\n\n\n\n    Make sure to replace the [image address] with the Reddit project address (removing brackets): \natdr.meo.ws/archiveteam/reddit-grab\n\n\n\n    Also change the [username] to whatever you'd like, no need to register for anything.\n  \nMore information about running this project:\n\n\nInformation about setting up the project\n\n\n\n\nArchiveTeam Wiki page on the Reddit project\n\n\n\n\nArchiveTeam IRC Channel for the Reddit Project (#shreddit on hackint)\n\n\n\n    There are \na lot\n more items that are waiting to be queued into the tracker (approximately 758 million), so 150 million is not an accurate number. This is due to Redis limitations - the tracker is a Ruby and Redis monolith that serves multiple projects with around hundreds of millions of items. You can see all the Reddit items \nhere\n.\n  \n\n    The maximum concurrency that you can run is 10 per IP (this is stated in the IRC channel topic). 5 works better for datacenter IPs.\n  \nInformation about Docker errors:\n\n\nIf you are seeing RSYNC errors: If the error is about max connections (either -1 or 400), then this is normal. This is our (not amazingly intuitive) method of telling clients to try another target server (we have many of them). Just let it retry, it'll work eventually. If the error is not about max connections, please contact ArchiveTeam on IRC.\n\n\n\n\nIf you are seeing HOSTERRs, check your DNS. We use Quad9 for our containers.\n\n\n\n\nIf you need support or wish to discuss, contact ArchiveTeam on IRC\n\n\n\n    Information on what ArchiveTeam archives and how to access the data (from \nu/rewbycraft\n):\n  \n\n    We archive the posts and comments directly with this project. The things being linked to by the posts (and comments) are put in a queue that we'll process once we've got some more spare capacity. After a few days this stuff ends up in the Internet Archive's Wayback Machine. So, if you have an URL, you can put it in there and retrieve the post. (Note: We save the links without any query parameters and generally using permalinks, so if your URL has ?<and other stuff> at the end, remove that. And try to use permalinks if possible.) It takes a few days because there's a lot of processing logic going on behind the scenes.\n  \n\n    If you want to be sure something is archived and aren't sure we're covering it, feel free to talk to us on IRC. We're trying to archive literally everything.\n  \nIMPORTANT: Do NOT modify scripts or the Warrior client!\n\n    Edit 4: We’re over 12 billion links archived. Keep running the warrior/Docker during the blackout we still have a lot of posts left. Check \nthis website\n to see when a subreddit goes private.\n  \n\n    Edit 3: Added a more prominent link to the Reddit IRC channel. Added more info about Docker errors and the project data.\n  \n\n    Edit 2: If you want check how much you've contributed, go to \nthe project tracker website\n, press \"show all\" and type ctrl/cmd - F (find in page on mobile), and search your username. It should show you the number of items and the size of data that you've archived.\n  \n\n    Edit 1: Added more project info given by \nu/signalhunter\n."},
{"Title": "The 276TB monster under the bed", "Author": "u/spazatk", "Content": "No content"},
{"Title": "introducing hard drive fold", "Author": "u/Astavicious", "Content": "No content"},
{"Title": "I built a book scanner and scanned all the yearbooks at a school", "Author": "u/camwow13", "Content": "No content"},
{"Title": "Reject the \"EARN IT Act\" (s. 3398) which threatens free speech, encryption, privacy, and the nation's cybersecurity.", "Author": "u/peoplearemean78", "Content": "No content"},
{"Title": "Hackers leak 37GB of Microsoft's source code (Bing, Cortana and more)", "Author": "u/harrro", "Content": "No content"},
{"Title": "Due to the new Audacity Terms of Service, I present 31 versions of Audacity and Github source code for 18 versions", "Author": "u/coasterghost", "Content": "No content"},
{"Title": "\"Ever wonder what 200PB of tape looks like?\"", "Author": "u/equalunique", "Content": "No content"},
{"Title": "On the zeroth day of Christmas, my true love sent to me eight 8TB drives.", "Author": "u/YourMJK", "Content": "No content"},
{"Title": "Please stop posting photos of your hard drives.", "Author": "u/Nooco24", "Content": "Hey, quick reminder, posting pictures of a bunch of HDDs you just bought ISN'T interesting, it's boring and I'm tired of seeing them all, I'm tired of seeing \"Am I part of this now?\" or \"Am I doing this the right way?\" posts.\n  \n\n    It's not because you have 100TB free of storage on your server that you are a data hoarder, and there is no \"good way to do this\".\n  \n\n    Data hoarding isn't about just buying $3000 worth of hard drives just for posting them here. What's interesting is what you do with your storage.\n  \n\n    If you just have 1TB of storage but you do something freakin' cool with it, what you can share here is way more important than someone buying 30TB of storage and never post again here.\n  \n\n    Please, focus on what we love, the DATA, not the storage medium, please focus on projects, on archiving, on digital preservation.\n  \n\n    Thanks. Post \ninspired\n by \nu/Nooco24"},
{"Title": "Internet Archive justifies its vast 'copyright infringing' National Emergency Library of 1.4 million books by pointing out that libraries are closed", "Author": "u/Rincey_nz", "Content": "No content"},
{"Title": "My mother just passed away. She wrote extensively on this website. What can I do to archive everything she wrote?", "Author": "u/anthonyridad", "Content": "Hey guys, my mother just passed away a few days ago from heart surgery. I always knew that she used to write in this one website. She has around 1400 entries that I want to archive, on the off chance that the website goes down. What's the best way to save her articles and stuff? I want to get around to reading them one day.\n  \n\n    Here's a link to her stuff:\n  \n\n\nhttps://www.mylot.com/ridingbet/posts\n\n\n\n    I tried using archive.org, but it only saves the main URL.\n  \n\n    Thanks in advance. :)"},
{"Title": "Office Depot offered me a free charcoal grill with my hard drive purchase", "Author": "u/mrtramplefoot", "Content": "No content"},
{"Title": "Bounty: $1000USD (keeps updating). Help me find the whole videotape of Donald Trump on The Oprah Winfrey Show, 25th of April, 1988. Season 3, Episode 5 (60 min. episode). Saw it on Facebook back in 2015. Then, it vanished. I haven't found it after that. Help is greatly appreciated!", "Author": "u/trycoconutoil", "Content": "ACTUAL\n \nBOUNTY: $1310USD\nhttps://bountyhunters.world/\n\n\n\n\nTRANSCRIPTS:  $100USD\n\n\n\n\n\n\n\n    Must be copy of the original Journal Graphics transcript\n  \n\n\n\n\n\n\nI created a Discord for anyone interested:\n \nhttps://discord.gg/JD8Je3v\n\n\n\n\nSources that are relevant for the hunt:\n\n\n\n\n\n\n\n\nhttps://thetvdb.com/series/the-oprah-winfrey-show/allseasons/official\n (air date)\n  \n\n\n\n\n\n\n3 min. part from the original video\n\n\n\n\n\n\n\n\nhttps://www.reddit.com/r/politicalfactchecking/comments/4nt6iw/donald_trump_republicans_are_dumb_why_did_this/\n (Frustrated Redditors)\n  \n\n\n\n\n\n\nhttps://www.youtube.com/watch?v=AZtfSIgsH1o\n (some YouTube video that may not be important, but the comments on it are relevant)\n  \n\n\n\n\n\n\nhttp://www.oprah.com/own-oprahshow/what-donald-trump-told-oprah-about-his-presidential-hopes-video\n (an old link that might have shown the full episode in the past)\n  \n\n\n\n\n\n\ninteresting article\n (Interesting article on the disappearance of the video.)\n  \n\n\n\n\n\n\nAnother Reddit post by someone else asking for the same episode.\n\n\n\n\n\n\n\n\n A Reddit post about the missing episode, and what OP of this post thinks about it\n.\n  \n\n\n\n\n\n    Hopefully, any of you got it :)\n  \n\n    Post (over 1000 upvotes) \nhttps://www.reddit.com/r/DataHoarder/comments/j2xd4r/bounty_300usd_help_me_find_the_whole_videotape_of/\n (locked cause of some Redditors not following community guidelines, I respect that, hence why I made this sub.)\n  \n\n    I'll literally give the person who can find it and send it to me $1000USD (if you want). I'll give it through cryptocurrency, anonymous PayPal system, product(s), or other means if that is desired. There are several people from Reddit who help give more to raise the bounty. That's why it's updating.\n  \n\n\n\n\nNOTE!\n\n\n\n    Ignore the images and fact-checker sites. Those are red herrings and so points towards something different from the year 1998. I want the entire video from \nThe Oprah Winfrey Show, 25th of April, 1988, season 3, Episode 5, 60 minutes of the show.\n DM me here on Reddit or post it publically.\n  \n\n    And, the episode does not exist on The Oprah Winfrey Show: 20th Anniversary Collection.\n  \n\n\n\n\n\n    (\nhttps://www.amazon.com/dp/B000B91N3S/ref=nav_timeline_asin?_encoding=UTF8&psc=1\n).\n  \n\n\n\n\n\n    And also not here: \nhttp://www.oprah.com/own-oprahshow/what-donald-trump-told-oprah-about-his-presidential-hopes-video\n (I even requested a transcript)\n  \n\n\n\n\n\n\n\n\n**Since some ask. Why do I want it?**\n\n\n\n    I want it cause it's been suppressed on the internet, and various sites and people tell me what I saw and heard didn't happen, and it bothers me. Been bothering me for years. I want to prove them wrong by showing the people this episode. I do not have any political intentions; I want the truth.\n  \n\n\n3.10.20 UPDATE. More useful resources:\n\n\n\n\n\n\n\n    Identify who has the \nMarion Stokes collection\n and ask them.\n  \n\n\n\n\n\n    Try asking people at LostMediaWiki\n  \n\n\n\n\n\n    In LA and NY, there are TV libraries where I can request… NY Small town libraries?\n  \n\n\n\n\n\n    Reach out to the team responsible for producing the \nnew Oprah Winfrey podcast\n\n\n\n\n\n\n\n    I posted to \nLostemediaWIKI\n (might come valuable information there)\n  \n\n\n\n\n\n\nhttps://www.facebook.com/trumpvideogone\n (a page someone made on Facebook about finding this video, 2017) \nThis one is interesting.\n\n\n\n\n\n\n\n    Just going to leave this here: \nhttps://en.wikipedia.org/wiki/Streisand_effect\n\n\n\n\nGood luck.\n\n\n\n    Add: I see my posts are being either locked or removed on different subreddits. If you have any idea where to post that would help!\n  \n\n\nUPDATE:\n 9:35 PM (UTC) 10.10.20\n  \n\n\n\n\n\n    25th, April 1988 on the Oprah Winfrey Show.\n  \n\n\n\n\n\n\n\n\n\n    Production company WLS-TV.\n  \n\n\n\n\n\n    Harpo productions should have the transcripts, cause they bought the inventory of a prior transcript company.\n  \n\n\n\n\n\n\n\n\n\n    I made a comment here: \nhttps://www.tvtime.com/en/show/75010/episode/665033#\n\n\n\n\n\n\n\n    I contacted an archivist from OWN and he said they only give it to commerce and airing. They have it. I won't stop.\n  \n\n\n\n\n\n\n\n\n\n    If someone here wants to use it for broadcast or for commerce's sake. DM me and I can give you contact to the right person, who is responsible for this archive. I could not get it because they don't distribute for\"Personal viewing\".\n  \n\n\n\n\n\n\nI created a Discord for anyone interested:\n \nhttps://discord.gg/JD8Je3v"},
{"Title": "I can't wait to buy this on eBay for $100 in a few years", "Author": "u/smacksaw", "Content": "No content"},
{"Title": "This fits here.", "Author": "u/peaceman12824", "Content": "No content"},
{"Title": "2500 Dos Games", "Author": "u/dutchsingh", "Content": "No content"},
{"Title": "Remember when YouTube said security and hacking videos would/could be removed? This is why we hoard.", "Author": "u/-this-guy-fucks-", "Content": "No content"},
{"Title": "Wife's B'Day Present, She Knows Me So Well", "Author": "u/slider383", "Content": "No content"},
{"Title": "A major lawsuit against the nonprofit Internet Archive threatens the future of all libraries. Big publishers are suing to cut off libraries’ ownership and control of digital books, opening new paths for censorship. Oral arguments are on March 20.", "Author": "u/BananaBus43", "Content": "No content"},
{"Title": "$700 kitty butt warmer", "Author": "u/blueskyn01se", "Content": "No content"},
{"Title": "Did you know that at the Internet Archive a light blinks on one of their servers every time you use their collections?", "Author": "u/storytracer", "Content": "No content"},
{"Title": "Zippyshare is shutting down", "Author": "u/giratina143", "Content": "No content"},
{"Title": "relatable to you guys?", "Author": "u/MysteriousK69420", "Content": "No content"},
{"Title": "Fujifilm refuses to pay ransomware demand, relies on backups", "Author": "u/razeus", "Content": "No content"},
{"Title": "ArchiveTeam has saved over 10.8 BILLION Reddit links so far. We need YOUR help running ArchiveTeam Warrior to archive subreddits before they're gone indefinitely after June 12th!", "Author": "u/BananaBus43", "Content": "ArchiveTeam has been archiving Reddit posts for a while now, but we are running out of time. \nSo far, we have archived 10.81 billion links, with 150 million to go\n.\n  \n\n    Recent news of the \nReddit API cost changes\n will force many of the top 3rd party Reddit apps to shut down. This will not only affect how people use Reddit, but it will also cause issues with many subreddit moderation bots which rely on the API to function. Many subreddits have agreed to shut down for 48 hours on June 12th, while others will be gone \nindefinitely\n unless this issue is resolved. We are archiving Reddit posts so that in the event that the API cost change is never addressed, we can still access posts from those closed subreddits.\n  \nHere is how you can help:\nChoose the \"host\" that matches your current PC, probably Windows or macOS\nDownload ArchiveTeam Warrior\n\n\n\n\n\n    In VirtualBox, click File > Import Appliance and open the file.\n  \n\n\n\n\n\n    Start the virtual machine. It will fetch the latest updates and will eventually tell you to start your web browser.\n  \n\n\n\n\n\n    Once you’ve started your warrior:\n  \n\n\n\n\n\n    Go to http://localhost:8001/ and check the Settings page.\n  \n\n\n\n\n\n    Choose a username — we’ll show your progress on the leaderboard.\n  \n\n\n\n\n\n    Go to the \"All projects\" tab and select ArchiveTeam’s Choice to let your warrior work on the most urgent project. (This will be Reddit).\n  \n\n\n\n\nAlternative Method: Docker\nDownload Docker on your \"host\" (Windows, macOS, Linux)\nFollow the instructions on the ArchiveTeam website to set up Docker\n\n    When setting up the project container, it will ask you to enter this command:\n  \n\n\ndocker run -d --name archiveteam --label=com.centurylinklabs.watchtower.enable=true --restart=unless-stopped [image address] --concurrent 1 [username]\n\n\n\n    Make sure to replace the [image address] with the Reddit project address (removing brackets): \natdr.meo.ws/archiveteam/reddit-grab\n\n\n\n    Also change the [username] to whatever you'd like, no need to register for anything.\n  \nMore information about running this project:\n\n\nInformation about setting up the project\n\n\n\n\nArchiveTeam Wiki page on the Reddit project\n\n\n\n\nArchiveTeam IRC Channel for the Reddit Project (#shreddit on hackint)\n\n\n\n    There are \na lot\n more items that are waiting to be queued into the tracker (approximately 758 million), so 150 million is not an accurate number. This is due to Redis limitations - the tracker is a Ruby and Redis monolith that serves multiple projects with around hundreds of millions of items. You can see all the Reddit items \nhere\n.\n  \n\n    The maximum concurrency that you can run is 10 per IP (this is stated in the IRC channel topic). 5 works better for datacenter IPs.\n  \nInformation about Docker errors:\n\n\nIf you are seeing RSYNC errors: If the error is about max connections (either -1 or 400), then this is normal. This is our (not amazingly intuitive) method of telling clients to try another target server (we have many of them). Just let it retry, it'll work eventually. If the error is not about max connections, please contact ArchiveTeam on IRC.\n\n\n\n\nIf you are seeing HOSTERRs, check your DNS. We use Quad9 for our containers.\n\n\n\n\nIf you need support or wish to discuss, contact ArchiveTeam on IRC\n\n\n\n    Information on what ArchiveTeam archives and how to access the data (from \nu/rewbycraft\n):\n  \n\n    We archive the posts and comments directly with this project. The things being linked to by the posts (and comments) are put in a queue that we'll process once we've got some more spare capacity. After a few days this stuff ends up in the Internet Archive's Wayback Machine. So, if you have an URL, you can put it in there and retrieve the post. (Note: We save the links without any query parameters and generally using permalinks, so if your URL has ?<and other stuff> at the end, remove that. And try to use permalinks if possible.) It takes a few days because there's a lot of processing logic going on behind the scenes.\n  \n\n    If you want to be sure something is archived and aren't sure we're covering it, feel free to talk to us on IRC. We're trying to archive literally everything.\n  \nIMPORTANT: Do NOT modify scripts or the Warrior client!\n\n    Edit 4: We’re over 12 billion links archived. Keep running the warrior/Docker during the blackout we still have a lot of posts left. Check \nthis website\n to see when a subreddit goes private.\n  \n\n    Edit 3: Added a more prominent link to the Reddit IRC channel. Added more info about Docker errors and the project data.\n  \n\n    Edit 2: If you want check how much you've contributed, go to \nthe project tracker website\n, press \"show all\" and type ctrl/cmd - F (find in page on mobile), and search your username. It should show you the number of items and the size of data that you've archived.\n  \n\n    Edit 1: Added more project info given by \nu/signalhunter\n."},
{"Title": "The 276TB monster under the bed", "Author": "u/spazatk", "Content": "No content"},
{"Title": "introducing hard drive fold", "Author": "u/Astavicious", "Content": "No content"},
{"Title": "I built a book scanner and scanned all the yearbooks at a school", "Author": "u/camwow13", "Content": "No content"},
{"Title": "Reject the \"EARN IT Act\" (s. 3398) which threatens free speech, encryption, privacy, and the nation's cybersecurity.", "Author": "u/peoplearemean78", "Content": "No content"},
{"Title": "Hackers leak 37GB of Microsoft's source code (Bing, Cortana and more)", "Author": "u/harrro", "Content": "No content"},
{"Title": "Due to the new Audacity Terms of Service, I present 31 versions of Audacity and Github source code for 18 versions", "Author": "u/coasterghost", "Content": "No content"},
{"Title": "\"Ever wonder what 200PB of tape looks like?\"", "Author": "u/equalunique", "Content": "No content"},
{"Title": "On the zeroth day of Christmas, my true love sent to me eight 8TB drives.", "Author": "u/YourMJK", "Content": "No content"},
{"Title": "Please stop posting photos of your hard drives.", "Author": "u/Nooco24", "Content": "Hey, quick reminder, posting pictures of a bunch of HDDs you just bought ISN'T interesting, it's boring and I'm tired of seeing them all, I'm tired of seeing \"Am I part of this now?\" or \"Am I doing this the right way?\" posts.\n  \n\n    It's not because you have 100TB free of storage on your server that you are a data hoarder, and there is no \"good way to do this\".\n  \n\n    Data hoarding isn't about just buying $3000 worth of hard drives just for posting them here. What's interesting is what you do with your storage.\n  \n\n    If you just have 1TB of storage but you do something freakin' cool with it, what you can share here is way more important than someone buying 30TB of storage and never post again here.\n  \n\n    Please, focus on what we love, the DATA, not the storage medium, please focus on projects, on archiving, on digital preservation.\n  \n\n    Thanks. Post \ninspired\n by \nu/Nooco24"},
{"Title": "Internet Archive justifies its vast 'copyright infringing' National Emergency Library of 1.4 million books by pointing out that libraries are closed", "Author": "u/Rincey_nz", "Content": "No content"},
{"Title": "My mother just passed away. She wrote extensively on this website. What can I do to archive everything she wrote?", "Author": "u/anthonyridad", "Content": "Hey guys, my mother just passed away a few days ago from heart surgery. I always knew that she used to write in this one website. She has around 1400 entries that I want to archive, on the off chance that the website goes down. What's the best way to save her articles and stuff? I want to get around to reading them one day.\n  \n\n    Here's a link to her stuff:\n  \n\n\nhttps://www.mylot.com/ridingbet/posts\n\n\n\n    I tried using archive.org, but it only saves the main URL.\n  \n\n    Thanks in advance. :)"},
{"Title": "Office Depot offered me a free charcoal grill with my hard drive purchase", "Author": "u/mrtramplefoot", "Content": "No content"},
{"Title": "Bounty: $1000USD (keeps updating). Help me find the whole videotape of Donald Trump on The Oprah Winfrey Show, 25th of April, 1988. Season 3, Episode 5 (60 min. episode). Saw it on Facebook back in 2015. Then, it vanished. I haven't found it after that. Help is greatly appreciated!", "Author": "u/trycoconutoil", "Content": "ACTUAL\n \nBOUNTY: $1310USD\nhttps://bountyhunters.world/\n\n\n\n\nTRANSCRIPTS:  $100USD\n\n\n\n\n\n\n\n    Must be copy of the original Journal Graphics transcript\n  \n\n\n\n\n\n\nI created a Discord for anyone interested:\n \nhttps://discord.gg/JD8Je3v\n\n\n\n\nSources that are relevant for the hunt:\n\n\n\n\n\n\n\n\nhttps://thetvdb.com/series/the-oprah-winfrey-show/allseasons/official\n (air date)\n  \n\n\n\n\n\n\n3 min. part from the original video\n\n\n\n\n\n\n\n\nhttps://www.reddit.com/r/politicalfactchecking/comments/4nt6iw/donald_trump_republicans_are_dumb_why_did_this/\n (Frustrated Redditors)\n  \n\n\n\n\n\n\nhttps://www.youtube.com/watch?v=AZtfSIgsH1o\n (some YouTube video that may not be important, but the comments on it are relevant)\n  \n\n\n\n\n\n\nhttp://www.oprah.com/own-oprahshow/what-donald-trump-told-oprah-about-his-presidential-hopes-video\n (an old link that might have shown the full episode in the past)\n  \n\n\n\n\n\n\ninteresting article\n (Interesting article on the disappearance of the video.)\n  \n\n\n\n\n\n\nAnother Reddit post by someone else asking for the same episode.\n\n\n\n\n\n\n\n\n A Reddit post about the missing episode, and what OP of this post thinks about it\n.\n  \n\n\n\n\n\n    Hopefully, any of you got it :)\n  \n\n    Post (over 1000 upvotes) \nhttps://www.reddit.com/r/DataHoarder/comments/j2xd4r/bounty_300usd_help_me_find_the_whole_videotape_of/\n (locked cause of some Redditors not following community guidelines, I respect that, hence why I made this sub.)\n  \n\n    I'll literally give the person who can find it and send it to me $1000USD (if you want). I'll give it through cryptocurrency, anonymous PayPal system, product(s), or other means if that is desired. There are several people from Reddit who help give more to raise the bounty. That's why it's updating.\n  \n\n\n\n\nNOTE!\n\n\n\n    Ignore the images and fact-checker sites. Those are red herrings and so points towards something different from the year 1998. I want the entire video from \nThe Oprah Winfrey Show, 25th of April, 1988, season 3, Episode 5, 60 minutes of the show.\n DM me here on Reddit or post it publically.\n  \n\n    And, the episode does not exist on The Oprah Winfrey Show: 20th Anniversary Collection.\n  \n\n\n\n\n\n    (\nhttps://www.amazon.com/dp/B000B91N3S/ref=nav_timeline_asin?_encoding=UTF8&psc=1\n).\n  \n\n\n\n\n\n    And also not here: \nhttp://www.oprah.com/own-oprahshow/what-donald-trump-told-oprah-about-his-presidential-hopes-video\n (I even requested a transcript)\n  \n\n\n\n\n\n\n\n\n**Since some ask. Why do I want it?**\n\n\n\n    I want it cause it's been suppressed on the internet, and various sites and people tell me what I saw and heard didn't happen, and it bothers me. Been bothering me for years. I want to prove them wrong by showing the people this episode. I do not have any political intentions; I want the truth.\n  \n\n\n3.10.20 UPDATE. More useful resources:\n\n\n\n\n\n\n\n    Identify who has the \nMarion Stokes collection\n and ask them.\n  \n\n\n\n\n\n    Try asking people at LostMediaWiki\n  \n\n\n\n\n\n    In LA and NY, there are TV libraries where I can request… NY Small town libraries?\n  \n\n\n\n\n\n    Reach out to the team responsible for producing the \nnew Oprah Winfrey podcast\n\n\n\n\n\n\n\n    I posted to \nLostemediaWIKI\n (might come valuable information there)\n  \n\n\n\n\n\n\nhttps://www.facebook.com/trumpvideogone\n (a page someone made on Facebook about finding this video, 2017) \nThis one is interesting.\n\n\n\n\n\n\n\n    Just going to leave this here: \nhttps://en.wikipedia.org/wiki/Streisand_effect\n\n\n\n\nGood luck.\n\n\n\n    Add: I see my posts are being either locked or removed on different subreddits. If you have any idea where to post that would help!\n  \n\n\nUPDATE:\n 9:35 PM (UTC) 10.10.20\n  \n\n\n\n\n\n    25th, April 1988 on the Oprah Winfrey Show.\n  \n\n\n\n\n\n\n\n\n\n    Production company WLS-TV.\n  \n\n\n\n\n\n    Harpo productions should have the transcripts, cause they bought the inventory of a prior transcript company.\n  \n\n\n\n\n\n\n\n\n\n    I made a comment here: \nhttps://www.tvtime.com/en/show/75010/episode/665033#\n\n\n\n\n\n\n\n    I contacted an archivist from OWN and he said they only give it to commerce and airing. They have it. I won't stop.\n  \n\n\n\n\n\n\n\n\n\n    If someone here wants to use it for broadcast or for commerce's sake. DM me and I can give you contact to the right person, who is responsible for this archive. I could not get it because they don't distribute for\"Personal viewing\".\n  \n\n\n\n\n\n\nI created a Discord for anyone interested:\n \nhttps://discord.gg/JD8Je3v"},
{"Title": "I can't wait to buy this on eBay for $100 in a few years", "Author": "u/smacksaw", "Content": "No content"},
{"Title": "This fits here.", "Author": "u/peaceman12824", "Content": "No content"},
{"Title": "2500 Dos Games", "Author": "u/dutchsingh", "Content": "No content"},
{"Title": "Remember when YouTube said security and hacking videos would/could be removed? This is why we hoard.", "Author": "u/-this-guy-fucks-", "Content": "No content"},
{"Title": "Wife's B'Day Present, She Knows Me So Well", "Author": "u/slider383", "Content": "No content"},
{"Title": "A major lawsuit against the nonprofit Internet Archive threatens the future of all libraries. Big publishers are suing to cut off libraries’ ownership and control of digital books, opening new paths for censorship. Oral arguments are on March 20.", "Author": "u/BananaBus43", "Content": "No content"},
{"Title": "$700 kitty butt warmer", "Author": "u/blueskyn01se", "Content": "No content"},
{"Title": "Hey folks, here's the entire Computer Science curriculum organized in 1000 YouTube videos that you can just play and start learning. There are 40 courses in total, further organized in 4 academic years, each containing 2 semesters. I hope that everyone who wants to learn, will find this helpful.", "Author": "u/volunteervancouver", "Content": "No content"},
{"Title": "Hoarding =/= Preservation", "Author": "u/Lee__Jieun", "Content": "No content"},
{"Title": "We're gonna need another napster soon", "Author": "u/Scuczu2", "Content": "No content"},
{"Title": "HDD destruction day at work today", "Author": "u/AnxietyBytes", "Content": "No content"},
{"Title": "The Internet Archive is now preserving Flash animations and games", "Author": "u/retrac1324", "Content": "No content"},
{"Title": "The Ripinator restoration/build (15$ thrift store steal)", "Author": "u/Crossheart963", "Content": "No content"},
{"Title": "In 1886, the US Government Commissioned 7,500 Watercolor Paintings of Every Known Fruit in the World: Download Them in High Resolution", "Author": "u/fawkesdotbe", "Content": "No content"},
{"Title": "4TB marked down to $21 at Walmart.", "Author": "u/TheSkinnyD", "Content": "No content"},
{"Title": "Don't Let Reddit Kill 3rd Party Apps!", "Author": "u/MagicDalsi", "Content": "EDIT: Don't use this post any more: it's been crossposted so widely that it breaks Reddit when trying to open it! It's been locked. Further discussion (and crossposts) should go \nHERE.\n\n\nWhat's going on?\n\n    A recent Reddit policy change threatens to kill many beloved third-party mobile apps, making a great many quality-of-life features not seen in the official mobile app \npermanently inaccessible\n to users.\n  \n\n    On May 31, 2023, Reddit announced they were raising the price to make calls to their API from being free to a level that will kill every third party app on Reddit, from \nApollo\n to \nReddit is Fun\n to \nNarwhal\n to \nBaconReader\n.\n  \n\n    Even if you're not a mobile user and don't use any of those apps, this is a step toward killing other ways of customizing Reddit, such as Reddit Enhancement Suite or the use of the old.reddit.com desktop interface \n.\n  \n\n    This isn't only a problem on the user level: many subreddit moderators depend on tools only available outside the official app to keep their communities on-topic and spam-free.\n  \nWhat's the plan?\n\n    On June 12th, \nmany subreddits\n will be going dark to protest this policy. Some will return after 48 hours: others will go away \npermanently\n unless the issue is adequately addressed, since many moderators aren't able to put in the work they do with the poor tools available through the official app. This isn't something any of us do lightly: we do what we do because \nwe love Reddit\n, and we truly believe this change will make it impossible to keep doing what we love.\n  \n\n    The two-day blackout isn't the \ngoal\n, and it isn't the end. Should things reach the 14th with no sign of Reddit choosing to fix what they've broken, we'll use the community and buzz we've built between then and now as a tool for further action.\n  \n\n    What can \nyou\n do?\n  \n\n\n\n\n\n\nComplain.\n Message the mods of \nr/reddit\n.com, who are the admins of the site: message \nu/reddit\n: submit a \nsupport request\n: comment in relevant threads on \nr/reddit\n, such as \nthis one\n, leave a negative review on their official iOS or Android app- and sign your username in support to this post.\n  \n\n\n\n\n\n\nSpread the word.\n Rabble-rouse on related subreddits. Meme it up, make it spicy. Bitch about it to your cat. Suggest anyone you know who moderates a subreddit join us at our sister sub at \nr/ModCoord\n  - but please don't pester mods you \ndon't\n know by simply spamming their modmail.\n  \n\n\n\n\n\n\nBoycott \nand\n spread the word...to Reddit's competition!\n Stay off Reddit entirely on June 12th through the 13th- instead, take to your favorite \nnon\n-Reddit platform of choice and make some noise in support!\n  \n\n\n\n\n\n\nDon't be a jerk.\n As upsetting this may be, threats, profanity and vandalism will be worse than useless in getting people on our side. Please make every effort to be as restrained, polite, reasonable and law-abiding as possible. \nThis includes not harassing moderators of subreddits who have chosen not to take part\n: no one likes a missionary, a used-car salesman, or a flame warrior."},
{"Title": "Low Disk Space", "Author": "u/Flying-T", "Content": "No content"},
{"Title": "The Internet Archive lost their court case", "Author": "u/safels2", "Content": "kys \nu/spez"},
{"Title": "\"The Truth is Paywalled But the Lies Are Free\": Notes on why I hoard data", "Author": "u/gabefair", "Content": "I came across a beautifully written \narticle\n by Nathan J. Robinson about how quality work costs money to access and propaganda is freely given.\n  \n\n    The article makes some good points on why it is important for data to be more free, which I will summarize below:\n  \n\n\n\n\n\n\n\n\n\n\n\n    Nobody is allowed to build a giant free database of everything human beings have ever produced.\n  \n\n\n\n\n\n\n\n\n\n    2) Copyright law can be an intensive restriction on the freedom of speech and determines what information you can (and not) share with others.\n  \n\n\n\n\n\n    3) The concept of a public community library needs to evolve. As books, and other content move online, our communities have as well.\n  \n\n\n\n\n\n    4)  Human creativity and potential is phenomenally leashed when human knowledge is limited.\n  \n\n\n\n\n\n    5) Free and affordable libraries/sources of wisdom are dying.\n  \n\n\n\n\n\n    This got me thinking about why I care about hoarding data. Data is invaluable! A digital dark age is forming around us and we can do what we can to prevent it. A lot of people here will hoard data for personal reasons. I hoard data for others.\n  \n\n    The things the people in this subreddit hoard whether it be movies, Youtube, pictures, news articles, websites, all of it is culture. Its history.\n  \n\n    Even memes and social media are not crap. Even literal shit is valuable to a scatologist. Can you imagine if we were able to find the preserved excrement from a long extinct animal? What one sees as shit, is so much more to someone else who is trained and educated. Its data. The internet and social media around us is Art and Culture from our time. This is history for the future to use and learn.\n  \n\n    Things go viral for a reason. The information shared in the jokes and content are snapshots of the public's thinking and perspective on the world. Invaluable data for future scholars.\n  \n\n    Imagine we found a Viking warship and on it was a perfectly preserved book of jokes. Sure many at the time might have thought they were shit jokes made at the expense of others. But we would learn so much about their customs, society, and the evolution of human civilization if this book was preserved and found. And the book's contents were made available to the world.\n  \n\n    Also a lot of political content is shared on social media and comment sections as well. Our understanding of politics  will be carved up in units of memes, and shared on thousands of siloed paywalled platforms and mediums over time. And our role is to collect and consolidate them.\n  \n\n    This is but a small sliver of the documentation of how our world is changing around us. And we can do our part to save and make free to others as much of it as we can.\n  \n\n    P.S. Many reddit accounts unknowingly (like maybe yours) are being used by bots to vote for content. Please enable 2FA to stop this practice. \nInstructions\n\n\n\n    P.P.S. Summer of 2020 is time for contingency preparedness. There is no time to get started like the present. Buy your disks now to be prepared for when history needs you.\n  \n\n    P.P.P.S. Thank you all for the support and discussion so far. You are some good folks! A song that I enjoy due to it relating to the importance preserving history is \"Amnesia\" by Dead Can Dance. It has a line in the song that I find quite chilling, \"Can you really plan the future when you no longer have the past?\"\n  \n\n    P.P.P.P.S. Some people like to use the plural verb \"data are\" instead of the singular \"data is\" since data are used to refer to a collection. \"The fish are being collected\". I merely mention this as a factoid in celebration of this discussion receiving so much attention.\n  \n\n    P.P.P.P.P.S. Take a look at this \nlist of site-deaths\n to remind us of all the now dead sites that once existed.\n  \n\n    P.P.P.P.P.P.S For further motivation, consider how: \nFacebook is deleting evidence of war crimes"},
{"Title": "This meme speaks to me", "Author": "u/Fox_Uni_Charlie_Kilo", "Content": "No content"},
{"Title": "Absolutely unacceptable - Newegg shipped me drives like this", "Author": "u/redditor1101", "Content": "No content"},
{"Title": "Why throw away old ~60GB drives? Why not make something to commemorate their service?", "Author": "u/aforsberg", "Content": "No content"},
{"Title": "It’s because of youtube-dl that we have the audio recordings of Bitfinex executive admitting to bank fraud", "Author": "u/dharmatech", "Content": "No content"},
{"Title": "35+ years worth TV, 24/7. A true data hoarding legend", "Author": "u/orochimaru1999", "Content": "No content"},
{"Title": "It was a good electronics recycling day at work today.", "Author": "u/VertexBeatz", "Content": "No content"},
{"Title": "Tokyo Resident who's been filming scenes in Japan since 1990 has over 12,000 videos on youtube", "Author": "u/Ayit_Sevi", "Content": "So, I've found myself downloading a lot of historical footage and I stumbled upon this guy, \nLyle Hiroshi Saxon\n. The dude has been on youtube since 2007 and over the period of 14 years has uploaded \n12,967 videos\n. He's been a resident since 1984 and has footage dating from 1990-1993 and from 2008-present. It's by far the biggest channel I've ever downloaded.\n  \n\n    He even has a \nwebpage/blog\n Even if it looks like he hasn't updated it in a while.\n  \n\n    Thought it was interesting enough to share"},
{"Title": "Going to add some actual drives to it when I get the chance... Until then:", "Author": "Unknown author", "Content": "No content"},
{"Title": "At least 223 companies have manufactured hard disk drives. Most of that industry has vanished through bankruptcy or mergers and acquisitions. None of the first four entrants continue in the industry today.", "Author": "u/dabderax", "Content": "No content"},
{"Title": "A full house.", "Author": "u/ast3r3x", "Content": "No content"},
{"Title": "Only in San Francisco 🤣", "Author": "u/anxman", "Content": "No content"},
{"Title": "House Speaker deleted his podcast. Hoarders to the rescue", "Author": "u/harrro", "Content": "No content"},
{"Title": "Complete US PlayStation 2 manual collection posted to archive.org", "Author": "u/K1rkl4nd", "Content": "To celebrate the PlayStation 2's 22nd anniversary on Wednesday I have uploaded my complete US manual collection- personally scanned and edited to 4K resolution- to archive.org.  17GB of goodiness across 1795 titles plus an additional ~100 variants, art books, mini-guides, and comics.  The upload is done- it's \"processing\" now.  Be sure to download the original files, not anything archive.org generates (sometimes they recompress things poorly trying to OCR).\n  \n\n\nhttps://archive.org/details/kirklands-manual-labor-sony-playstation-2-usa-4k-version"},
{"Title": "Hey folks, here's the entire Computer Science curriculum organized in 1000 YouTube videos that you can just play and start learning. There are 40 courses in total, further organized in 4 academic years, each containing 2 semesters. I hope that everyone who wants to learn, will find this helpful.", "Author": "u/volunteervancouver", "Content": "No content"},
{"Title": "Hoarding =/= Preservation", "Author": "u/Lee__Jieun", "Content": "No content"},
{"Title": "We're gonna need another napster soon", "Author": "u/Scuczu2", "Content": "No content"},
{"Title": "HDD destruction day at work today", "Author": "u/AnxietyBytes", "Content": "No content"},
{"Title": "The Internet Archive is now preserving Flash animations and games", "Author": "u/retrac1324", "Content": "No content"},
{"Title": "The Ripinator restoration/build (15$ thrift store steal)", "Author": "u/Crossheart963", "Content": "No content"},
{"Title": "In 1886, the US Government Commissioned 7,500 Watercolor Paintings of Every Known Fruit in the World: Download Them in High Resolution", "Author": "u/fawkesdotbe", "Content": "No content"},
{"Title": "4TB marked down to $21 at Walmart.", "Author": "u/TheSkinnyD", "Content": "No content"},
{"Title": "Don't Let Reddit Kill 3rd Party Apps!", "Author": "u/MagicDalsi", "Content": "EDIT: Don't use this post any more: it's been crossposted so widely that it breaks Reddit when trying to open it! It's been locked. Further discussion (and crossposts) should go \nHERE.\n\n\nWhat's going on?\n\n    A recent Reddit policy change threatens to kill many beloved third-party mobile apps, making a great many quality-of-life features not seen in the official mobile app \npermanently inaccessible\n to users.\n  \n\n    On May 31, 2023, Reddit announced they were raising the price to make calls to their API from being free to a level that will kill every third party app on Reddit, from \nApollo\n to \nReddit is Fun\n to \nNarwhal\n to \nBaconReader\n.\n  \n\n    Even if you're not a mobile user and don't use any of those apps, this is a step toward killing other ways of customizing Reddit, such as Reddit Enhancement Suite or the use of the old.reddit.com desktop interface \n.\n  \n\n    This isn't only a problem on the user level: many subreddit moderators depend on tools only available outside the official app to keep their communities on-topic and spam-free.\n  \nWhat's the plan?\n\n    On June 12th, \nmany subreddits\n will be going dark to protest this policy. Some will return after 48 hours: others will go away \npermanently\n unless the issue is adequately addressed, since many moderators aren't able to put in the work they do with the poor tools available through the official app. This isn't something any of us do lightly: we do what we do because \nwe love Reddit\n, and we truly believe this change will make it impossible to keep doing what we love.\n  \n\n    The two-day blackout isn't the \ngoal\n, and it isn't the end. Should things reach the 14th with no sign of Reddit choosing to fix what they've broken, we'll use the community and buzz we've built between then and now as a tool for further action.\n  \n\n    What can \nyou\n do?\n  \n\n\n\n\n\n\nComplain.\n Message the mods of \nr/reddit\n.com, who are the admins of the site: message \nu/reddit\n: submit a \nsupport request\n: comment in relevant threads on \nr/reddit\n, such as \nthis one\n, leave a negative review on their official iOS or Android app- and sign your username in support to this post.\n  \n\n\n\n\n\n\nSpread the word.\n Rabble-rouse on related subreddits. Meme it up, make it spicy. Bitch about it to your cat. Suggest anyone you know who moderates a subreddit join us at our sister sub at \nr/ModCoord\n  - but please don't pester mods you \ndon't\n know by simply spamming their modmail.\n  \n\n\n\n\n\n\nBoycott \nand\n spread the word...to Reddit's competition!\n Stay off Reddit entirely on June 12th through the 13th- instead, take to your favorite \nnon\n-Reddit platform of choice and make some noise in support!\n  \n\n\n\n\n\n\nDon't be a jerk.\n As upsetting this may be, threats, profanity and vandalism will be worse than useless in getting people on our side. Please make every effort to be as restrained, polite, reasonable and law-abiding as possible. \nThis includes not harassing moderators of subreddits who have chosen not to take part\n: no one likes a missionary, a used-car salesman, or a flame warrior."},
{"Title": "Low Disk Space", "Author": "u/Flying-T", "Content": "No content"},
{"Title": "The Internet Archive lost their court case", "Author": "u/safels2", "Content": "kys \nu/spez"},
{"Title": "\"The Truth is Paywalled But the Lies Are Free\": Notes on why I hoard data", "Author": "u/gabefair", "Content": "I came across a beautifully written \narticle\n by Nathan J. Robinson about how quality work costs money to access and propaganda is freely given.\n  \n\n    The article makes some good points on why it is important for data to be more free, which I will summarize below:\n  \n\n\n\n\n\n\n\n\n\n\n\n    Nobody is allowed to build a giant free database of everything human beings have ever produced.\n  \n\n\n\n\n\n\n\n\n\n    2) Copyright law can be an intensive restriction on the freedom of speech and determines what information you can (and not) share with others.\n  \n\n\n\n\n\n    3) The concept of a public community library needs to evolve. As books, and other content move online, our communities have as well.\n  \n\n\n\n\n\n    4)  Human creativity and potential is phenomenally leashed when human knowledge is limited.\n  \n\n\n\n\n\n    5) Free and affordable libraries/sources of wisdom are dying.\n  \n\n\n\n\n\n    This got me thinking about why I care about hoarding data. Data is invaluable! A digital dark age is forming around us and we can do what we can to prevent it. A lot of people here will hoard data for personal reasons. I hoard data for others.\n  \n\n    The things the people in this subreddit hoard whether it be movies, Youtube, pictures, news articles, websites, all of it is culture. Its history.\n  \n\n    Even memes and social media are not crap. Even literal shit is valuable to a scatologist. Can you imagine if we were able to find the preserved excrement from a long extinct animal? What one sees as shit, is so much more to someone else who is trained and educated. Its data. The internet and social media around us is Art and Culture from our time. This is history for the future to use and learn.\n  \n\n    Things go viral for a reason. The information shared in the jokes and content are snapshots of the public's thinking and perspective on the world. Invaluable data for future scholars.\n  \n\n    Imagine we found a Viking warship and on it was a perfectly preserved book of jokes. Sure many at the time might have thought they were shit jokes made at the expense of others. But we would learn so much about their customs, society, and the evolution of human civilization if this book was preserved and found. And the book's contents were made available to the world.\n  \n\n    Also a lot of political content is shared on social media and comment sections as well. Our understanding of politics  will be carved up in units of memes, and shared on thousands of siloed paywalled platforms and mediums over time. And our role is to collect and consolidate them.\n  \n\n    This is but a small sliver of the documentation of how our world is changing around us. And we can do our part to save and make free to others as much of it as we can.\n  \n\n    P.S. Many reddit accounts unknowingly (like maybe yours) are being used by bots to vote for content. Please enable 2FA to stop this practice. \nInstructions\n\n\n\n    P.P.S. Summer of 2020 is time for contingency preparedness. There is no time to get started like the present. Buy your disks now to be prepared for when history needs you.\n  \n\n    P.P.P.S. Thank you all for the support and discussion so far. You are some good folks! A song that I enjoy due to it relating to the importance preserving history is \"Amnesia\" by Dead Can Dance. It has a line in the song that I find quite chilling, \"Can you really plan the future when you no longer have the past?\"\n  \n\n    P.P.P.P.S. Some people like to use the plural verb \"data are\" instead of the singular \"data is\" since data are used to refer to a collection. \"The fish are being collected\". I merely mention this as a factoid in celebration of this discussion receiving so much attention.\n  \n\n    P.P.P.P.P.S. Take a look at this \nlist of site-deaths\n to remind us of all the now dead sites that once existed.\n  \n\n    P.P.P.P.P.P.S For further motivation, consider how: \nFacebook is deleting evidence of war crimes"},
{"Title": "This meme speaks to me", "Author": "u/Fox_Uni_Charlie_Kilo", "Content": "No content"},
{"Title": "Absolutely unacceptable - Newegg shipped me drives like this", "Author": "u/redditor1101", "Content": "No content"},
{"Title": "Why throw away old ~60GB drives? Why not make something to commemorate their service?", "Author": "u/aforsberg", "Content": "No content"},
{"Title": "It’s because of youtube-dl that we have the audio recordings of Bitfinex executive admitting to bank fraud", "Author": "u/dharmatech", "Content": "No content"},
{"Title": "35+ years worth TV, 24/7. A true data hoarding legend", "Author": "u/orochimaru1999", "Content": "No content"},
{"Title": "It was a good electronics recycling day at work today.", "Author": "u/VertexBeatz", "Content": "No content"},
{"Title": "Tokyo Resident who's been filming scenes in Japan since 1990 has over 12,000 videos on youtube", "Author": "u/Ayit_Sevi", "Content": "So, I've found myself downloading a lot of historical footage and I stumbled upon this guy, \nLyle Hiroshi Saxon\n. The dude has been on youtube since 2007 and over the period of 14 years has uploaded \n12,967 videos\n. He's been a resident since 1984 and has footage dating from 1990-1993 and from 2008-present. It's by far the biggest channel I've ever downloaded.\n  \n\n    He even has a \nwebpage/blog\n Even if it looks like he hasn't updated it in a while.\n  \n\n    Thought it was interesting enough to share"},
{"Title": "Going to add some actual drives to it when I get the chance... Until then:", "Author": "Unknown author", "Content": "No content"},
{"Title": "At least 223 companies have manufactured hard disk drives. Most of that industry has vanished through bankruptcy or mergers and acquisitions. None of the first four entrants continue in the industry today.", "Author": "u/dabderax", "Content": "No content"},
{"Title": "A full house.", "Author": "u/ast3r3x", "Content": "No content"},
{"Title": "Only in San Francisco 🤣", "Author": "u/anxman", "Content": "No content"},
{"Title": "House Speaker deleted his podcast. Hoarders to the rescue", "Author": "u/harrro", "Content": "No content"},
{"Title": "Complete US PlayStation 2 manual collection posted to archive.org", "Author": "u/K1rkl4nd", "Content": "To celebrate the PlayStation 2's 22nd anniversary on Wednesday I have uploaded my complete US manual collection- personally scanned and edited to 4K resolution- to archive.org.  17GB of goodiness across 1795 titles plus an additional ~100 variants, art books, mini-guides, and comics.  The upload is done- it's \"processing\" now.  Be sure to download the original files, not anything archive.org generates (sometimes they recompress things poorly trying to OCR).\n  \n\n\nhttps://archive.org/details/kirklands-manual-labor-sony-playstation-2-usa-4k-version"},
{"Title": "60 hard drives, spinning down", "Author": "u/geerlingguy", "Content": "No content"},
{"Title": "Mistakes were made.", "Author": "u/Miss_Zia", "Content": "No content"},
{"Title": "55.5GB of Lego Instructions, time to find the rest!", "Author": "u/xiyatumerica", "Content": "No content"},
{"Title": "YouTube deleted \"SemperVideo\" a 13-year-old german educational channel focused on IT", "Author": "u/AndaPlays", "Content": "Yeah, see the title.\n  \n\n    Just a reminder that nothing is safe on YouTube and you should backup your favorite stuff.\n  \n\n    This channel had thousands of videos. Was great stuff. From how to set up basic stuff in windows to how to configures your Linux server correctly.\n  \n\n    His Twitter: \nhttps://twitter.com/SemperVideo/status/1352503560525795328\n\n\n\n\nhttps://socialblade.com/youtube/user/sempervideo\n\n\n\n    Edit:\nHe received his first Strike for a VPN video and the second one for showing how to get the new Windows 10 Version 2004 start menu. For the third one, he didn't even receive an email or notification yet for what video he got taken down.\n  \n\n\nhttp://sempervideo.de/youtube-hat-sempervideo-geloescht/\n\n\n\n\n\n    Edit 2:\nThe channel is backup. Just for how long If their ridiculous policy and bots are still up. \nhttps://twitter.com/SemperVideo/status/1352708103125561344\n\n\n\n\nhttps://www.youtube.com/user/SemperVideo\n\n\n\n    Edit 3:\nSo the channel is up again, but he still has the previous two strikes from the VPN video and the win 10 video. So It's just a matter of time again till another video will get a strike again. And If you don't know after 3 strikes on YouTube, your channels get deleted. That's what happened here.\n  \n\n    His perspective(german):\nhttps://www.youtube.com/watch?v=ZiYLPjCWoXU\n\n\n\n    In summary, he already deleted over 1k videos from YouTube after he received the second strike a few weeks ago. But with over a few thousand videos you can't really pinpoint which videos will get you maybe a strike again. If a user reports a video from him, a \"YouTube Specialist\" will look at the video who doesn't know shit about IT and then says: \"Yeah, that could be dangerous\" so here you have a strike. And after 3 you're gone."},
{"Title": "Intel suffers massive data breach involving confidential company and CPU information revealing hardcoded backdoors.", "Author": "u/kurtstir", "Content": "Intel  suffered a massive data breach earlier this year and as of today the  first associated data has begun being released.  Some users are  reporting finding hardcoded backdoors in the intel code.\n  \n\n    Some of the contents of this first release:\n  \n\n    - Intel ME Bringup guides + (flash) tooling + samples for various platforms\n  \n\n    -  Kabylake (Purley Platform) BIOS Reference Code and Sample Code +  Initialization code (some of it as exported git repos with full history)\n  \n\n    - Intel CEFDK (Consumer Electronics Firmware Development Kit (Bootloader stuff)) SOURCES\n  \n\n    - Silicon / FSP source code packages for various platforms\n  \n\n    - Various Intel Development and Debugging Tools - Simics Simulation for Rocket Lake S and potentially other platforms\n  \n\n    - Various roadmaps and other documents\n  \n\n    - Binaries for Camera drivers Intel made for SpaceX\n  \n\n    - Schematics, Docs, Tools + Firmware for the unreleased Tiger Lake platform - (very horrible) Kabylake FDK training videos\n  \n\n    - Intel Trace Hub + decoder files for various Intel ME versions\n  \n\n    - Elkhart Lake Silicon Reference and Platform Sample Code\n  \n\n    - Some Verilog stuff for various Xeon Platforms, unsure what it is exactly.\n  \n\n    - Debug BIOS/TXE builds for various Platforms\n  \n\n    - Bootguard SDK (encrypted zip)\n  \n\n    - Intel Snowridge / Snowfish Process Simulator ADK - Various schematics\n  \n\n    - Intel Marketing Material Templates (InDesign)\n  \n\n    - Lots of other things\n  \n\n\nhttps://twitter.com/deletescape/status/1291405688204402689"},
{"Title": "How books are scanned.", "Author": "u/ReturnMuch9510", "Content": "No content"},
{"Title": "Boss OGs", "Author": "u/kin_zindestroyer", "Content": "No content"},
{"Title": "Zippyshare is now officially dead. o7", "Author": "u/verpejas", "Content": "No content"},
{"Title": "You might be right Alexa", "Author": "u/chicoquadcore", "Content": "No content"},
{"Title": "Yahoo and Verizon are blocking Archive.org from archiving Groups. Archive.org is facing up to 80% data loss.", "Author": "u/AnthropicMachine", "Content": "No content"},
{"Title": "Company closed down. All PCs were on sale for $32. I chose the most expensive one", "Author": "u/yusoffb01", "Content": "No content"},
{"Title": "I just stopped the hoarding", "Author": "u/Houderebaese", "Content": "So I just deleted 5TB worth of movies I never watch and then sold my 2x12 Tb drives. To think I had a NAS with >32TB at some point...\n  \n\n    I decided/realised that the senseless hording itself made my unhappy and had me constantly occupied with backing things up, noisy hardware and fixing server infrastructure.\n  \n\n    No more, my important data now fits on 2x5 TB 2.5 inch drives + offsite backup.\n  \n\n    No idea what the point of this post is but I kind of needed to let it out 😄👍"},
{"Title": "My pain for the last few weeks.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "My Home Setup with 350tb", "Author": "u/Lintux", "Content": "No content"},
{"Title": "Archive Link In Comments. 40 years of Televison", "Author": "Unknown author", "Content": "No content"},
{"Title": "Got this letter from TDS Fiber gigabit plan ..", "Author": "u/TheMonDon", "Content": "No content"},
{"Title": ".Webp is the bane of my existence", "Author": "u/ElonTastical", "Content": "No content"},
{"Title": "My ZFS 645TB server. Dual intel gold 5222, 512 GB ram, 60 bay, 6 nvme (zil powered by Intel Optane + P4610 Intel as L2ARC + 4x 10GbE X710 SFP+. Absolute beast, which is backup server, though faster than production 😂", "Author": "u/kumits-u", "Content": "No content"},
{"Title": "My little blu-ray digitizing setup", "Author": "u/xjtian", "Content": "No content"},
{"Title": "The EU’s new \"Data Act\" will let the user of a tech products (like wearables) access all the data it generates. Imagine all the personal data we will have access to!", "Author": "u/anonboxis", "Content": "No content"},
{"Title": "Maybe I can fit one more..... :)", "Author": "u/Mara25x", "Content": "No content"},
{"Title": "When it's only 1080p on disc, but 4K on streaming.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Google Drive now flagging my illicit .DS_Store files", "Author": "u/haveasuperday", "Content": "No content"},
{"Title": "[WIP/concept] Browser extension that restores privated/deleted videos in a YouTube playlist", "Author": "u/rebane2001", "Content": "No content"},
{"Title": "Can anyone challenge this Verizon representative?", "Author": "u/Squiggledog", "Content": "No content"},
{"Title": "60 hard drives, spinning down", "Author": "u/geerlingguy", "Content": "No content"},
{"Title": "Mistakes were made.", "Author": "u/Miss_Zia", "Content": "No content"},
{"Title": "55.5GB of Lego Instructions, time to find the rest!", "Author": "u/xiyatumerica", "Content": "No content"},
{"Title": "YouTube deleted \"SemperVideo\" a 13-year-old german educational channel focused on IT", "Author": "u/AndaPlays", "Content": "Yeah, see the title.\n  \n\n    Just a reminder that nothing is safe on YouTube and you should backup your favorite stuff.\n  \n\n    This channel had thousands of videos. Was great stuff. From how to set up basic stuff in windows to how to configures your Linux server correctly.\n  \n\n    His Twitter: \nhttps://twitter.com/SemperVideo/status/1352503560525795328\n\n\n\n\nhttps://socialblade.com/youtube/user/sempervideo\n\n\n\n    Edit:\nHe received his first Strike for a VPN video and the second one for showing how to get the new Windows 10 Version 2004 start menu. For the third one, he didn't even receive an email or notification yet for what video he got taken down.\n  \n\n\nhttp://sempervideo.de/youtube-hat-sempervideo-geloescht/\n\n\n\n\n\n    Edit 2:\nThe channel is backup. Just for how long If their ridiculous policy and bots are still up. \nhttps://twitter.com/SemperVideo/status/1352708103125561344\n\n\n\n\nhttps://www.youtube.com/user/SemperVideo\n\n\n\n    Edit 3:\nSo the channel is up again, but he still has the previous two strikes from the VPN video and the win 10 video. So It's just a matter of time again till another video will get a strike again. And If you don't know after 3 strikes on YouTube, your channels get deleted. That's what happened here.\n  \n\n    His perspective(german):\nhttps://www.youtube.com/watch?v=ZiYLPjCWoXU\n\n\n\n    In summary, he already deleted over 1k videos from YouTube after he received the second strike a few weeks ago. But with over a few thousand videos you can't really pinpoint which videos will get you maybe a strike again. If a user reports a video from him, a \"YouTube Specialist\" will look at the video who doesn't know shit about IT and then says: \"Yeah, that could be dangerous\" so here you have a strike. And after 3 you're gone."},
{"Title": "Intel suffers massive data breach involving confidential company and CPU information revealing hardcoded backdoors.", "Author": "u/kurtstir", "Content": "Intel  suffered a massive data breach earlier this year and as of today the  first associated data has begun being released.  Some users are  reporting finding hardcoded backdoors in the intel code.\n  \n\n    Some of the contents of this first release:\n  \n\n    - Intel ME Bringup guides + (flash) tooling + samples for various platforms\n  \n\n    -  Kabylake (Purley Platform) BIOS Reference Code and Sample Code +  Initialization code (some of it as exported git repos with full history)\n  \n\n    - Intel CEFDK (Consumer Electronics Firmware Development Kit (Bootloader stuff)) SOURCES\n  \n\n    - Silicon / FSP source code packages for various platforms\n  \n\n    - Various Intel Development and Debugging Tools - Simics Simulation for Rocket Lake S and potentially other platforms\n  \n\n    - Various roadmaps and other documents\n  \n\n    - Binaries for Camera drivers Intel made for SpaceX\n  \n\n    - Schematics, Docs, Tools + Firmware for the unreleased Tiger Lake platform - (very horrible) Kabylake FDK training videos\n  \n\n    - Intel Trace Hub + decoder files for various Intel ME versions\n  \n\n    - Elkhart Lake Silicon Reference and Platform Sample Code\n  \n\n    - Some Verilog stuff for various Xeon Platforms, unsure what it is exactly.\n  \n\n    - Debug BIOS/TXE builds for various Platforms\n  \n\n    - Bootguard SDK (encrypted zip)\n  \n\n    - Intel Snowridge / Snowfish Process Simulator ADK - Various schematics\n  \n\n    - Intel Marketing Material Templates (InDesign)\n  \n\n    - Lots of other things\n  \n\n\nhttps://twitter.com/deletescape/status/1291405688204402689"},
{"Title": "How books are scanned.", "Author": "u/ReturnMuch9510", "Content": "No content"},
{"Title": "Boss OGs", "Author": "u/kin_zindestroyer", "Content": "No content"},
{"Title": "Zippyshare is now officially dead. o7", "Author": "u/verpejas", "Content": "No content"},
{"Title": "You might be right Alexa", "Author": "u/chicoquadcore", "Content": "No content"},
{"Title": "Yahoo and Verizon are blocking Archive.org from archiving Groups. Archive.org is facing up to 80% data loss.", "Author": "u/AnthropicMachine", "Content": "No content"},
{"Title": "Company closed down. All PCs were on sale for $32. I chose the most expensive one", "Author": "u/yusoffb01", "Content": "No content"},
{"Title": "I just stopped the hoarding", "Author": "u/Houderebaese", "Content": "So I just deleted 5TB worth of movies I never watch and then sold my 2x12 Tb drives. To think I had a NAS with >32TB at some point...\n  \n\n    I decided/realised that the senseless hording itself made my unhappy and had me constantly occupied with backing things up, noisy hardware and fixing server infrastructure.\n  \n\n    No more, my important data now fits on 2x5 TB 2.5 inch drives + offsite backup.\n  \n\n    No idea what the point of this post is but I kind of needed to let it out 😄👍"},
{"Title": "My pain for the last few weeks.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "My Home Setup with 350tb", "Author": "u/Lintux", "Content": "No content"},
{"Title": "Archive Link In Comments. 40 years of Televison", "Author": "Unknown author", "Content": "No content"},
{"Title": "Got this letter from TDS Fiber gigabit plan ..", "Author": "u/TheMonDon", "Content": "No content"},
{"Title": ".Webp is the bane of my existence", "Author": "u/ElonTastical", "Content": "No content"},
{"Title": "My ZFS 645TB server. Dual intel gold 5222, 512 GB ram, 60 bay, 6 nvme (zil powered by Intel Optane + P4610 Intel as L2ARC + 4x 10GbE X710 SFP+. Absolute beast, which is backup server, though faster than production 😂", "Author": "u/kumits-u", "Content": "No content"},
{"Title": "My little blu-ray digitizing setup", "Author": "u/xjtian", "Content": "No content"},
{"Title": "The EU’s new \"Data Act\" will let the user of a tech products (like wearables) access all the data it generates. Imagine all the personal data we will have access to!", "Author": "u/anonboxis", "Content": "No content"},
{"Title": "Maybe I can fit one more..... :)", "Author": "u/Mara25x", "Content": "No content"},
{"Title": "When it's only 1080p on disc, but 4K on streaming.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Google Drive now flagging my illicit .DS_Store files", "Author": "u/haveasuperday", "Content": "No content"},
{"Title": "[WIP/concept] Browser extension that restores privated/deleted videos in a YouTube playlist", "Author": "u/rebane2001", "Content": "No content"},
{"Title": "Can anyone challenge this Verizon representative?", "Author": "u/Squiggledog", "Content": "No content"},
{"Title": "60 hard drives, spinning down", "Author": "u/geerlingguy", "Content": "No content"},
{"Title": "Mistakes were made.", "Author": "u/Miss_Zia", "Content": "No content"},
{"Title": "55.5GB of Lego Instructions, time to find the rest!", "Author": "u/xiyatumerica", "Content": "No content"},
{"Title": "YouTube deleted \"SemperVideo\" a 13-year-old german educational channel focused on IT", "Author": "u/AndaPlays", "Content": "Yeah, see the title.\n  \n\n    Just a reminder that nothing is safe on YouTube and you should backup your favorite stuff.\n  \n\n    This channel had thousands of videos. Was great stuff. From how to set up basic stuff in windows to how to configures your Linux server correctly.\n  \n\n    His Twitter: \nhttps://twitter.com/SemperVideo/status/1352503560525795328\n\n\n\n\nhttps://socialblade.com/youtube/user/sempervideo\n\n\n\n    Edit:\nHe received his first Strike for a VPN video and the second one for showing how to get the new Windows 10 Version 2004 start menu. For the third one, he didn't even receive an email or notification yet for what video he got taken down.\n  \n\n\nhttp://sempervideo.de/youtube-hat-sempervideo-geloescht/\n\n\n\n\n\n    Edit 2:\nThe channel is backup. Just for how long If their ridiculous policy and bots are still up. \nhttps://twitter.com/SemperVideo/status/1352708103125561344\n\n\n\n\nhttps://www.youtube.com/user/SemperVideo\n\n\n\n    Edit 3:\nSo the channel is up again, but he still has the previous two strikes from the VPN video and the win 10 video. So It's just a matter of time again till another video will get a strike again. And If you don't know after 3 strikes on YouTube, your channels get deleted. That's what happened here.\n  \n\n    His perspective(german):\nhttps://www.youtube.com/watch?v=ZiYLPjCWoXU\n\n\n\n    In summary, he already deleted over 1k videos from YouTube after he received the second strike a few weeks ago. But with over a few thousand videos you can't really pinpoint which videos will get you maybe a strike again. If a user reports a video from him, a \"YouTube Specialist\" will look at the video who doesn't know shit about IT and then says: \"Yeah, that could be dangerous\" so here you have a strike. And after 3 you're gone."},
{"Title": "Intel suffers massive data breach involving confidential company and CPU information revealing hardcoded backdoors.", "Author": "u/kurtstir", "Content": "Intel  suffered a massive data breach earlier this year and as of today the  first associated data has begun being released.  Some users are  reporting finding hardcoded backdoors in the intel code.\n  \n\n    Some of the contents of this first release:\n  \n\n    - Intel ME Bringup guides + (flash) tooling + samples for various platforms\n  \n\n    -  Kabylake (Purley Platform) BIOS Reference Code and Sample Code +  Initialization code (some of it as exported git repos with full history)\n  \n\n    - Intel CEFDK (Consumer Electronics Firmware Development Kit (Bootloader stuff)) SOURCES\n  \n\n    - Silicon / FSP source code packages for various platforms\n  \n\n    - Various Intel Development and Debugging Tools - Simics Simulation for Rocket Lake S and potentially other platforms\n  \n\n    - Various roadmaps and other documents\n  \n\n    - Binaries for Camera drivers Intel made for SpaceX\n  \n\n    - Schematics, Docs, Tools + Firmware for the unreleased Tiger Lake platform - (very horrible) Kabylake FDK training videos\n  \n\n    - Intel Trace Hub + decoder files for various Intel ME versions\n  \n\n    - Elkhart Lake Silicon Reference and Platform Sample Code\n  \n\n    - Some Verilog stuff for various Xeon Platforms, unsure what it is exactly.\n  \n\n    - Debug BIOS/TXE builds for various Platforms\n  \n\n    - Bootguard SDK (encrypted zip)\n  \n\n    - Intel Snowridge / Snowfish Process Simulator ADK - Various schematics\n  \n\n    - Intel Marketing Material Templates (InDesign)\n  \n\n    - Lots of other things\n  \n\n\nhttps://twitter.com/deletescape/status/1291405688204402689"},
{"Title": "How books are scanned.", "Author": "u/ReturnMuch9510", "Content": "No content"},
{"Title": "Boss OGs", "Author": "u/kin_zindestroyer", "Content": "No content"},
{"Title": "Zippyshare is now officially dead. o7", "Author": "u/verpejas", "Content": "No content"},
{"Title": "You might be right Alexa", "Author": "u/chicoquadcore", "Content": "No content"},
{"Title": "Yahoo and Verizon are blocking Archive.org from archiving Groups. Archive.org is facing up to 80% data loss.", "Author": "u/AnthropicMachine", "Content": "No content"},
{"Title": "Company closed down. All PCs were on sale for $32. I chose the most expensive one", "Author": "u/yusoffb01", "Content": "No content"},
{"Title": "I just stopped the hoarding", "Author": "u/Houderebaese", "Content": "So I just deleted 5TB worth of movies I never watch and then sold my 2x12 Tb drives. To think I had a NAS with >32TB at some point...\n  \n\n    I decided/realised that the senseless hording itself made my unhappy and had me constantly occupied with backing things up, noisy hardware and fixing server infrastructure.\n  \n\n    No more, my important data now fits on 2x5 TB 2.5 inch drives + offsite backup.\n  \n\n    No idea what the point of this post is but I kind of needed to let it out 😄👍"},
{"Title": "My pain for the last few weeks.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "My Home Setup with 350tb", "Author": "u/Lintux", "Content": "No content"},
{"Title": "Archive Link In Comments. 40 years of Televison", "Author": "Unknown author", "Content": "No content"},
{"Title": "Got this letter from TDS Fiber gigabit plan ..", "Author": "u/TheMonDon", "Content": "No content"},
{"Title": ".Webp is the bane of my existence", "Author": "u/ElonTastical", "Content": "No content"},
{"Title": "My ZFS 645TB server. Dual intel gold 5222, 512 GB ram, 60 bay, 6 nvme (zil powered by Intel Optane + P4610 Intel as L2ARC + 4x 10GbE X710 SFP+. Absolute beast, which is backup server, though faster than production 😂", "Author": "u/kumits-u", "Content": "No content"},
{"Title": "My little blu-ray digitizing setup", "Author": "u/xjtian", "Content": "No content"},
{"Title": "The EU’s new \"Data Act\" will let the user of a tech products (like wearables) access all the data it generates. Imagine all the personal data we will have access to!", "Author": "u/anonboxis", "Content": "No content"},
{"Title": "Maybe I can fit one more..... :)", "Author": "u/Mara25x", "Content": "No content"},
{"Title": "When it's only 1080p on disc, but 4K on streaming.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Google Drive now flagging my illicit .DS_Store files", "Author": "u/haveasuperday", "Content": "No content"},
{"Title": "[WIP/concept] Browser extension that restores privated/deleted videos in a YouTube playlist", "Author": "u/rebane2001", "Content": "No content"},
{"Title": "Can anyone challenge this Verizon representative?", "Author": "u/Squiggledog", "Content": "No content"},
{"Title": "Free Modular NAS Enclosure - Stackable Drive Expansion, ITX Vertical Layout, 3D Print Files Included", "Author": "u/ethanross1a", "Content": "No content"},
{"Title": "Hello my name is Nikon_Justus and I am a DataHoarder", "Author": "u/Nikon_Justus", "Content": "No content"},
{"Title": "Took an old IBM hard drive from the 80s and turned it into an art piece", "Author": "u/NO-LAN", "Content": "No content"},
{"Title": "After hoarding over 50k YouTube videos, here is the youtube-dl command I settled on.", "Author": "u/Veloldo", "Content": "EDIT: If you are reading this, I've made a few small changes. You can find the actual scripts I use here: \nhttps://github.com/velodo/youtube-dl_script\n. While my serup works great for me, if you're looking for a more robust solution, please check out TheFrenchGhosty's scripts here: \nhttps://github.com/TheFrenchGhosty/TheFrenchGhostys-YouTube-DL-Archivist-Scripts\n, with the associated reddit thread here: \nhttps://redd.it/h7q4nz\n.\n\n\n\n    After seeing all of the posts recently regarding youtube-dl, I figured I would chime in on the options I use. There are a few things I want to implement as some point, see the bottom of this post for those. Also, if anyone sees anything that can be done better, please let me know as I am always looking for ways to improve everything I do! Also, this post isn't intended to be a guide on how to use youtube-dl, this is more for the arguments I use and why I use them. If you need help getting youtube-dl running, setting up a batch script, etc. there are plenty of guides for that sort of thing elsewhere.\n  \n\n\nThe command (DONT COPY PASTE THIS ONE):\n\n\nyoutube-dl --download-archive \"archive.log\" -i --add-metadata --all-subs --embed-subs \n--embed-thumbnail --match-filter \"playlist_title != 'Liked videos' & playlist_title != \n'Favorites'\" -f \"(bestvideo[vcodec^=av01][height>=1080][fps>30]/bestvideo[vcodec=vp9.2]\n[height>=1080][fps>30]/bestvideo[vcodec=vp9][height>=1080][fps>30]/bestvideo[vcodec^=av01]\n[height>=1080]/bestvideo[vcodec=vp9.2][height>=1080]/bestvideo[vcodec=vp9]\n[height>=1080]/bestvideo[height>=1080]/bestvideo[vcodec^=av01][height>=720]\n[fps>30]/bestvideo[vcodec=vp9.2][height>=720][fps>30]/bestvideo[vcodec=vp9][height>=720]\n[fps>30]/bestvideo[vcodec^=av01][height>=720]/bestvideo[vcodec=vp9.2]\n[height>=720]/bestvideo[vcodec=vp9][height>=720]/bestvideo[height>=720]/bestvideo)+\n(bestaudio[acodec=opus]/bestaudio)/best\" --merge-output-format mkv -o \"%cd%/%%\n(playlist_uploader)s/%%(playlist)s/%%(playlist_index)s - %%(title)s - %%(id)s.%%(ext)s\" \n\"[URL HERE TO CHANNELS PLAYLISTS]\" \n\n\nThe command again (copy paste friendly):\n\n\nyoutube-dl --download-archive \"archive.log\" -i --add-metadata --all-subs --embed-subs --embed-thumbnail --match-filter \"playlist_title != 'Liked videos' & playlist_title != 'Favorites'\" -f \"(bestvideo[vcodec^=av01][height>=1080][fps>30]/bestvideo[vcodec=vp9.2][height>=1080][fps>30]/bestvideo[vcodec=vp9][height>=1080][fps>30]/bestvideo[vcodec^=av01][height>=1080]/bestvideo[vcodec=vp9.2][height>=1080]/bestvideo[vcodec=vp9][height>=1080]/bestvideo[height>=1080]/bestvideo[vcodec^=av01][height>=720][fps>30]/bestvideo[vcodec=vp9.2][height>=720][fps>30]/bestvideo[vcodec=vp9][height>=720][fps>30]/bestvideo[vcodec^=av01][height>=720]/bestvideo[vcodec=vp9.2][height>=720]/bestvideo[vcodec=vp9][height>=720]/bestvideo[height>=720]/bestvideo)+(bestaudio[acodec=opus]/bestaudio)/best\" --merge-output-format mkv -o \"%cd%/%%(playlist_uploader)s/%%(playlist)s/%%(playlist_index)s - %%(title)s - %%(id)s.%%(ext)s\" \"[URL HERE TO CHANNELS PLAYLISTS]\" \n\n    I know it looks long and scary, let me break it down a little bit:\n  \n--download-archive \"archive.log\" \n\n    This keeps track of all the videos you have downloaded so they can be skipped over the next time it's ran or the next time it finds that video.\n  \n-i \n\n    Ignore any errors that occur while downloading. Occasionally they will happen and this just ensures things keep moving along as intended. Don't worry, the next time it is ran any videos that didn't fully download will most likely be picked right back up where it left off!\n  \n--add-metadata --all-subs --embed-subs --embed-thumbnail \n\n    These just embed metadata into the video once it's done downloading. You never know when this will come in handy, and having it all right in the video's container is nice. Just a little note, at the time of writing this post, ffmpeg can't embed images into a mkv, but the image is still downloaded and stored in the same location and with the same name as the video.\n  \n--match-filter \"playlist_title != 'Liked videos' & playlist_title != 'Favorites'\" \n\n    This will filter videos out that you don't want to download. Here is just a basic example of filtering out playlists with the title \"Liked Videos\" and \"Favorites\". I find this especially useful for filtering out playlists that contain a bunch of videos from other playlists. For example, if I'm downloading videos from a gaming channel and they have a playlist for \"Gmod\" and one for \"Minecraft PC\", but they also have one called \"PC Games\" that contains the contents of both the Gmod and the Minecraft playlists, I sometimes will want to keep those separate, so I will filter out the \"PC Games\" playlist. If there are videos in that playlist you still want, you can always add another youtube-dl command to your script with that playlist specifically. Depending on the channel, this can get rather annoying to manage, but its a good way to keep things better organized.\n  \n-f \"(bestvideo[vcodec^=av01][height>=1080][fps>30]/bestvideo[vcodec=vp9.2][height>=1080]\n[fps>30]/bestvideo[vcodec=vp9][height>=1080][fps>30]/bestvideo[vcodec^=av01]\n[height>=1080]/bestvideo[vcodec=vp9.2][height>=1080]/bestvideo[vcodec=vp9]\n[height>=1080]/bestvideo[height>=1080]/bestvideo[vcodec^=av01][height>=720]\n[fps>30]/bestvideo[vcodec=vp9.2][height>=720][fps>30]/bestvideo[vcodec=vp9][height>=720]\n[fps>30]/bestvideo[vcodec^=av01][height>=720]/bestvideo[vcodec=vp9.2][height>=720]/\nbestvideo[vcodec=vp9][height>=720]/bestvideo[height>=720]/bestvideo)+\n(bestaudio[acodec=opus]/bestaudio)/best\" \n\n    Ok. This is where things get a little tricky. I first want to start off by saying that this isn't totally necessary as all the -f command does is allows you to set preferences on what video and audio streams you want to download. If you want a basic rundown on how this works, the youtube-dl readme explains it better than I ever could. For my case here, I want to download video streams in certain codecs, which have a hierarchy of [av1>vp9.2>vp9>whatever is available]. It will keep going down the list until one is found that meets my criteria. You can also see that I prefer videos in 1080 with more than 30 fps, then 1080 30 fps, and that repeats for 720. I also prefer to get audio in opus if it's available. Just a side note for anyone wondering what vp9.2 is, it is the vp9 codec with HDR.\n  \n\n    Why bother with all of that nonsense when youtube-dl will automatically pick the best streams for you? Well, the way youtube-dl picks the best stream is based solely on bitrate. This means that for video it will usually chose the avc1 codec, which is pretty old at this point, and while it still looks good, I've found that the other codecs offer a smaller file size and similar or better quality. You may find otherwise and want to do things differently, but for me, this is how I do it as it saves hard drive space and I find the quality good. Also, as you will notice, I don't have any resolutions higher than 1080 on there. The way I have it, it should catch those higher res streams, but as of now, I don't archive many youtubers' videos that upload in higher res so I haven't found the need, but some day I'm sure I will change it. I already know your asking yourself, \"If this will catch the higher resolution streams, why don't you just leave the 720 options in there and remove the 1080?\". Well, it's because I've noticed that youtube has started to transcode many videos to the newer av1 codec, but so far most videos that I've seen only go up to 720 for the av1 codec. This means that if that stream is available, but there isn't a 1080p av1 stream, then it will always download those videos in 720p even if a higher res stream is available.\n  \n--merge-output-format mkv -o \"%cd%/%%(playlist_uploader)s/%%(playlist)s/%%(playlist_index)s - \n%%(title)s - %%(id)s.%%(ext)s\" \n\n    This just tells youtube-dl where I want the file and that I want it in an mkv container. It's pretty self explanatory, but I basically want a folder structure of \"[CHANNEL NAME]/[PLAYLIST NAME]/[PLAYLIST INDEX] - [VIDEO TITLE] - [YOUTUBE VIDEO ID].[EXTENSION]\". Feel free to customize this however you see fit. Please note that I used double % in some of these due to my script being a batch file ran on a windows VM.\n  \n\n\nThings I want to do:\n\n\n\n    - Create a docker container that runs the script. While the Windows VM is working perfect for this, it's the only thing the VM does now (used to be used for much more, but that has all been offloaded). It should be pretty easy since I leave the executables and the script all in a network share as is, so all it would need is the dependencies (which I think is only python if I'm not mistaken) and to set up a cron job.\n  \n\n    - Simplify the script a bit by using the -a argument. This would allow me to set up a file with the links I want to download. This would allow me to group a bunch of commands that all have the same arguments into 1 command.\n  \n\n    - Write a script that will move videos that were downloaded before they were put into playlists into their respective playlists once the uploader adds them. Right now what I do is download all of the uploader's playlists, then download all of their videos (using the same archive file so it doesn't re-download any). This means if the uploader is slow to add the video to a playlist, it will just be downloaded to a \"No Playlist\" folder. The other way I could do this would be to find a way to deduplicate all of the videos in the \"No Playlist\" folder and just use separate archive files for the playlist and non playlist videos, which might download some videos twice, but then later deduplicated.\n  \n\n\nFinal Thoughts:\n\n\n\n    Youtube-dl is a wonderful and powerful tool, and with all of the crap going down on YouTube, you can never be too sure what videos you love might be taken down. Just what I've managed to download has already helped me and some of my friends out. It definitely is worth your time to automate downloading videos from channels you enjoy, and with a little know-how and experimentation, it doesn't take much time or effort to get something to a point where you can set it and forget it.\n  \n\n    Anyway, that was certainly longer than I thought it would be, but I really hope it helps some of you guys out. I've gained so much knowledge from this subreddit and it would mean a lot if I gave back and helped one of you out in return. Happy Hoarding!\n  \n\n\n\n\nJust a quick edit:\n Be sure to check out the comments for some excellent ideas and more information on some things! As always, take this information and adapt it to your use case. Maybe my configuration will work perfectly for you, but more than likely you will have to tweak it a bit to get it just right for you. If you have any questions, please ask!\n  \n\n\nAnother quick edit:\n Some of the comments have brought up the fact that us as viewers of YouTube content, and even youtube-dl itself don't have any way to watch or download the original quality of the material as YouTube will automatically transcode videos when they are uploaded. This can be a problem for people who are trying to preserve things in the best quality they possibly can. If you are one of these people, you might want to try looking elsewhere for better quality releases of the content. The one example that immediately comes to mind for me is content from Rooster Teeth. The quality when downloaded directly from their website seems to be better quality than what you can pull from YouTube. For me personally, I will download some movies, and TV Shows and also most music and images in the best possible quality I can find, but when it comes to YouTube content, I just don't care as much and find the convenience of ripping directly from YouTube hard to beat. I also think the content tends to look great, especially for the file sizes, but this is obviously all up to you to decide."},
{"Title": "192TB beauty. What to do with it ?", "Author": "u/henk1313", "Content": "No content"},
{"Title": "File size of Endgame's Cinema DCP", "Author": "Unknown author", "Content": "No content"},
{"Title": "A friend calls and asks \"I can't find this video on any streaming service. Any chance you have it?\"", "Author": "u/TNightster", "Content": "No content"},
{"Title": "Remember to backup your data, you never know when a spinning disk is going to fail and then you end up with a lot of shiny drinks coasters", "Author": "u/bri999", "Content": "No content"},
{"Title": "This is what \"frustration-free\" packaging means in Europe", "Author": "u/FigureOfEight", "Content": "No content"},
{"Title": "80 TB homeserver for datahoarding", "Author": "u/kirjeveitsi", "Content": "No content"},
{"Title": "Please do not mirror YouTube on the Internet Archive in Bulk", "Author": "u/textfiles", "Content": "https://twitter.com/textfiles/status/1492209816730808331\n\n\n\n    I posted this in a twitter thread, but I thought I'd mention this (obvious) thread here as well:\n  \n\n    Every once in a while, someone gets a brilliant idea, which is not a brilliant idea, and the first step for a mountain of heartache.  The idea is \"The Internet Archive is permanency-minded, and Youtube is full of things. I should back up Youtube on Internet Archive\".\n  \n\n    Depending on the person's capabilities and their drive, they may back up a couple videos here and there, or, as sometimes people are capable of doing, they set up a massive operation to just start jamming thousands of YouTube videos in \"just in case\".  Do not do this.\n  \n\n    YouTube is a massive ecosystem of videos, ranging from:\n  \n\n\n\n\n\n    Mirrors of neat stuff from video sources\n  \n\n\n\n\n\n    Archival copies of things on other media\n  \n\n\n\n\n\n    Businesses/Channels, ad-reliant, putting out shows\n  \n\n\n\n\n\n    And more.\n  \n\n\n\n\n\n    It's actually rather complicated and there's lots of considerations.\n  \n\n    When you decide, on your own, to \"help\" by downloading dozens of terabytes of videos, sometimes sans metadata, other times with random filenames, and just shove them into the Internet Archive, you're just hurting a non-profit by doing so. You are not a hero.  Please don't.\n  \n\n    Going to say it again: Please don't.  If you have a legitimate concern of a specific situation (creator has died, the material is some sort of culturally-relevant \"leak\" or unique situation, etc.) then communicate with the Archive (or me) about it, we'll work something out.\n  \n\n    Today's writing was brought to you by someone who could have used this information in their lives 2 months ago.\n  \n\n\nUPDATE: I\n \nresponded to one of the threads generated\n \nin a way that probably applies to 90% of the issues brought up."},
{"Title": "Ok which one of you did this?", "Author": "u/drbennett75", "Content": "No content"},
{"Title": "Seagate's flex - 3 ZB shipped", "Author": "u/greasythug", "Content": "No content"},
{"Title": "Just a reminder of what we have lost, and why we feel how we feel about data. I guarantee everybody that sees this can find an artist that is near to their heart. This is completely unconscionable and my heart aches looking at this list.", "Author": "u/PoorWill", "Content": "No content"},
{"Title": "Mines still going strong 🤷", "Author": "u/apeironone", "Content": "No content"},
{"Title": "Youtube educational hacking content getting banned", "Author": "u/ignaloidas", "Content": "No content"},
{"Title": "I was told I belong here", "Author": "u/dshbak", "Content": "No content"},
{"Title": "Twitter will soon begin suspending accounts that have been inactive for 30 days", "Author": "Unknown author", "Content": "No content"},
{"Title": "Twitter removed a student’s tweets critical of exam monitoring tool due to DMCA notice; EFF claims it is textbook example of fair use", "Author": "u/retrac1324", "Content": "No content"},
{"Title": "Tumblr will ban all adult content on December 17th.", "Author": "u/yashendra2797", "Content": "Get ready to mass download your favorite adult blogs guys. This is gonna be such a punch in the gut to so many talented creators. Tumblr had some of the best captions, 3D Porn, 2D Porn, TG Porn, Art Porn, Alt Porn, and Erotica. If anyone knows of a way to mass rip sites please post them in the comments.\n  \n\n    Source:\n  \n\n\nThe Verge\n\n\n\n\nTumblr Community Policy\n\n\n\n\nTumblr Announcement\n\n\n\n    EDIT: Oh boy. \n106\n replies meant my phone was buzzing all night. Woke up 2 hours late because my phones were dead. Thanks for getting me extra sleep guys!"},
{"Title": "A backup everyone must have (the storage media may be different)", "Author": "u/psych_1337", "Content": "No content"},
{"Title": "When your boss is an insurance agent... ioSafe 1019+", "Author": "u/wirerogue", "Content": "No content"},
{"Title": "NAS in transit to new house. Baby in trunk.", "Author": "u/therealschwartz", "Content": "No content"},
{"Title": "PSA: Verbatim no longer sells real M Discs, now puts regular BD-Rs in M Disc packaging", "Author": "u/JazzKazz", "Content": "TLDR: instead of selling real M Discs, Verbatim now puts their cheap organic BD-Rs into M Disc cases and charges M Disc prices for them\n  \n\n    In July, I bought 25GB Verbatim M Discs from Amazon. Even though I bought them directly from Amazon Europe, the discs I received were not real M Discs but regular Verbatim BD-Rs with an organic layer that were made to look like M Discs. I noticed right away because the MID of the discs was \nVERBAT-IMe-000\n, which is the code for their regular BD-Rs, instead of \nMILLEN-MR1-000\n which is the MID that all 25GB M Discs have. At this point I assumed I'd been sold fakes, but 3 months later I again ordered Verbatim M Discs, this time from German retail chain Saturn, and once again received these discs that I assumed are fakes. I emailed Verbatim's customer service and \nprepared a bunch of images that show these fake M Discs next to real ones.\n But to my surprise, after a debate with customer service they told me that these are not fakes, and that these \"are the only M Discs that are going to be sold from now on\" (quote). What's insane is that these discs currently being sold are not M Discs at all, but regular organic layer Verbatim BD-Rs, yet Verbatim still calls these M Disc. When I tried calling them out on their lies by pointing out things such as the discs' MID being the same as that of regular BD-Rs and the discs having 6x burn speed despite real M Discs being 4x speed, they just chucked it up to \"the discs being completely reworked, and we moved production facility hence the new DISC IDs\". The most ridiculous part is, these \"new M Discs\" (as Verbatim support calls them) are writable in any standard Blu Ray drive, you don't even need a drive that supports M Disc burning! For those unaware, M Discs require an M Disc capable drive to be burned, because M Discs need a stronger laser than what is used for regular BDs. This stronger laser is only in M Disc drives and there is no way you could ever write a real M Disc in a non M Disc drive. Yet here we have customers being sold cheap organic layer BD-Rs and being deceived into thinking they're buying M Discs.\n  \n\n    I find this absolutely insane as people burn hundreds of these discs a day, trusting them to reliably hold precious data, yet most people aren't aware they're not burning a real M Disc, but just a garden variety BD-R that has none of the M Disc advantages that you pay for. So far the only mention of this that I've found online is a \nGerman thread from August\n where somebody received these same VERBAT-IMe-000 discs as me and thinks they're fake, not aware that Verbatim themselves are behind these discs.\n  \n\n    Some stores still have real M Discs in stock, but the majority of them (at least in Germany) now sell the new, fake kind, as I've ordered M Discs from various stores over the past few weeks and 90% of the time received the new fake kind which I returned. It probably also depends on region, I have no idea about discs in the US or other countries. \nCheck the IDs of your discs people.\n\n\n\n    Quick check:\n  \n\n\n\n\n\n    A real M Disc has a copper/gold tint on the back, the new fake ones are silver\n  \n\n\n\n\n\n    A real M Disc (25GB) has the MID/DISC ID: MILLEN-MR1-000, no matter what brand\n  \n\n\n\n\n\n    A real M Disc only burns in a drive with M Disc support"},
{"Title": "The Internet Archive is in danger", "Author": "u/Cereal_is_great", "Content": "No content"},
{"Title": "Free Modular NAS Enclosure - Stackable Drive Expansion, ITX Vertical Layout, 3D Print Files Included", "Author": "u/ethanross1a", "Content": "No content"},
{"Title": "Hello my name is Nikon_Justus and I am a DataHoarder", "Author": "u/Nikon_Justus", "Content": "No content"},
{"Title": "Took an old IBM hard drive from the 80s and turned it into an art piece", "Author": "u/NO-LAN", "Content": "No content"},
{"Title": "After hoarding over 50k YouTube videos, here is the youtube-dl command I settled on.", "Author": "u/Veloldo", "Content": "EDIT: If you are reading this, I've made a few small changes. You can find the actual scripts I use here: \nhttps://github.com/velodo/youtube-dl_script\n. While my serup works great for me, if you're looking for a more robust solution, please check out TheFrenchGhosty's scripts here: \nhttps://github.com/TheFrenchGhosty/TheFrenchGhostys-YouTube-DL-Archivist-Scripts\n, with the associated reddit thread here: \nhttps://redd.it/h7q4nz\n.\n\n\n\n    After seeing all of the posts recently regarding youtube-dl, I figured I would chime in on the options I use. There are a few things I want to implement as some point, see the bottom of this post for those. Also, if anyone sees anything that can be done better, please let me know as I am always looking for ways to improve everything I do! Also, this post isn't intended to be a guide on how to use youtube-dl, this is more for the arguments I use and why I use them. If you need help getting youtube-dl running, setting up a batch script, etc. there are plenty of guides for that sort of thing elsewhere.\n  \n\n\nThe command (DONT COPY PASTE THIS ONE):\n\n\nyoutube-dl --download-archive \"archive.log\" -i --add-metadata --all-subs --embed-subs \n--embed-thumbnail --match-filter \"playlist_title != 'Liked videos' & playlist_title != \n'Favorites'\" -f \"(bestvideo[vcodec^=av01][height>=1080][fps>30]/bestvideo[vcodec=vp9.2]\n[height>=1080][fps>30]/bestvideo[vcodec=vp9][height>=1080][fps>30]/bestvideo[vcodec^=av01]\n[height>=1080]/bestvideo[vcodec=vp9.2][height>=1080]/bestvideo[vcodec=vp9]\n[height>=1080]/bestvideo[height>=1080]/bestvideo[vcodec^=av01][height>=720]\n[fps>30]/bestvideo[vcodec=vp9.2][height>=720][fps>30]/bestvideo[vcodec=vp9][height>=720]\n[fps>30]/bestvideo[vcodec^=av01][height>=720]/bestvideo[vcodec=vp9.2]\n[height>=720]/bestvideo[vcodec=vp9][height>=720]/bestvideo[height>=720]/bestvideo)+\n(bestaudio[acodec=opus]/bestaudio)/best\" --merge-output-format mkv -o \"%cd%/%%\n(playlist_uploader)s/%%(playlist)s/%%(playlist_index)s - %%(title)s - %%(id)s.%%(ext)s\" \n\"[URL HERE TO CHANNELS PLAYLISTS]\" \n\n\nThe command again (copy paste friendly):\n\n\nyoutube-dl --download-archive \"archive.log\" -i --add-metadata --all-subs --embed-subs --embed-thumbnail --match-filter \"playlist_title != 'Liked videos' & playlist_title != 'Favorites'\" -f \"(bestvideo[vcodec^=av01][height>=1080][fps>30]/bestvideo[vcodec=vp9.2][height>=1080][fps>30]/bestvideo[vcodec=vp9][height>=1080][fps>30]/bestvideo[vcodec^=av01][height>=1080]/bestvideo[vcodec=vp9.2][height>=1080]/bestvideo[vcodec=vp9][height>=1080]/bestvideo[height>=1080]/bestvideo[vcodec^=av01][height>=720][fps>30]/bestvideo[vcodec=vp9.2][height>=720][fps>30]/bestvideo[vcodec=vp9][height>=720][fps>30]/bestvideo[vcodec^=av01][height>=720]/bestvideo[vcodec=vp9.2][height>=720]/bestvideo[vcodec=vp9][height>=720]/bestvideo[height>=720]/bestvideo)+(bestaudio[acodec=opus]/bestaudio)/best\" --merge-output-format mkv -o \"%cd%/%%(playlist_uploader)s/%%(playlist)s/%%(playlist_index)s - %%(title)s - %%(id)s.%%(ext)s\" \"[URL HERE TO CHANNELS PLAYLISTS]\" \n\n    I know it looks long and scary, let me break it down a little bit:\n  \n--download-archive \"archive.log\" \n\n    This keeps track of all the videos you have downloaded so they can be skipped over the next time it's ran or the next time it finds that video.\n  \n-i \n\n    Ignore any errors that occur while downloading. Occasionally they will happen and this just ensures things keep moving along as intended. Don't worry, the next time it is ran any videos that didn't fully download will most likely be picked right back up where it left off!\n  \n--add-metadata --all-subs --embed-subs --embed-thumbnail \n\n    These just embed metadata into the video once it's done downloading. You never know when this will come in handy, and having it all right in the video's container is nice. Just a little note, at the time of writing this post, ffmpeg can't embed images into a mkv, but the image is still downloaded and stored in the same location and with the same name as the video.\n  \n--match-filter \"playlist_title != 'Liked videos' & playlist_title != 'Favorites'\" \n\n    This will filter videos out that you don't want to download. Here is just a basic example of filtering out playlists with the title \"Liked Videos\" and \"Favorites\". I find this especially useful for filtering out playlists that contain a bunch of videos from other playlists. For example, if I'm downloading videos from a gaming channel and they have a playlist for \"Gmod\" and one for \"Minecraft PC\", but they also have one called \"PC Games\" that contains the contents of both the Gmod and the Minecraft playlists, I sometimes will want to keep those separate, so I will filter out the \"PC Games\" playlist. If there are videos in that playlist you still want, you can always add another youtube-dl command to your script with that playlist specifically. Depending on the channel, this can get rather annoying to manage, but its a good way to keep things better organized.\n  \n-f \"(bestvideo[vcodec^=av01][height>=1080][fps>30]/bestvideo[vcodec=vp9.2][height>=1080]\n[fps>30]/bestvideo[vcodec=vp9][height>=1080][fps>30]/bestvideo[vcodec^=av01]\n[height>=1080]/bestvideo[vcodec=vp9.2][height>=1080]/bestvideo[vcodec=vp9]\n[height>=1080]/bestvideo[height>=1080]/bestvideo[vcodec^=av01][height>=720]\n[fps>30]/bestvideo[vcodec=vp9.2][height>=720][fps>30]/bestvideo[vcodec=vp9][height>=720]\n[fps>30]/bestvideo[vcodec^=av01][height>=720]/bestvideo[vcodec=vp9.2][height>=720]/\nbestvideo[vcodec=vp9][height>=720]/bestvideo[height>=720]/bestvideo)+\n(bestaudio[acodec=opus]/bestaudio)/best\" \n\n    Ok. This is where things get a little tricky. I first want to start off by saying that this isn't totally necessary as all the -f command does is allows you to set preferences on what video and audio streams you want to download. If you want a basic rundown on how this works, the youtube-dl readme explains it better than I ever could. For my case here, I want to download video streams in certain codecs, which have a hierarchy of [av1>vp9.2>vp9>whatever is available]. It will keep going down the list until one is found that meets my criteria. You can also see that I prefer videos in 1080 with more than 30 fps, then 1080 30 fps, and that repeats for 720. I also prefer to get audio in opus if it's available. Just a side note for anyone wondering what vp9.2 is, it is the vp9 codec with HDR.\n  \n\n    Why bother with all of that nonsense when youtube-dl will automatically pick the best streams for you? Well, the way youtube-dl picks the best stream is based solely on bitrate. This means that for video it will usually chose the avc1 codec, which is pretty old at this point, and while it still looks good, I've found that the other codecs offer a smaller file size and similar or better quality. You may find otherwise and want to do things differently, but for me, this is how I do it as it saves hard drive space and I find the quality good. Also, as you will notice, I don't have any resolutions higher than 1080 on there. The way I have it, it should catch those higher res streams, but as of now, I don't archive many youtubers' videos that upload in higher res so I haven't found the need, but some day I'm sure I will change it. I already know your asking yourself, \"If this will catch the higher resolution streams, why don't you just leave the 720 options in there and remove the 1080?\". Well, it's because I've noticed that youtube has started to transcode many videos to the newer av1 codec, but so far most videos that I've seen only go up to 720 for the av1 codec. This means that if that stream is available, but there isn't a 1080p av1 stream, then it will always download those videos in 720p even if a higher res stream is available.\n  \n--merge-output-format mkv -o \"%cd%/%%(playlist_uploader)s/%%(playlist)s/%%(playlist_index)s - \n%%(title)s - %%(id)s.%%(ext)s\" \n\n    This just tells youtube-dl where I want the file and that I want it in an mkv container. It's pretty self explanatory, but I basically want a folder structure of \"[CHANNEL NAME]/[PLAYLIST NAME]/[PLAYLIST INDEX] - [VIDEO TITLE] - [YOUTUBE VIDEO ID].[EXTENSION]\". Feel free to customize this however you see fit. Please note that I used double % in some of these due to my script being a batch file ran on a windows VM.\n  \n\n\nThings I want to do:\n\n\n\n    - Create a docker container that runs the script. While the Windows VM is working perfect for this, it's the only thing the VM does now (used to be used for much more, but that has all been offloaded). It should be pretty easy since I leave the executables and the script all in a network share as is, so all it would need is the dependencies (which I think is only python if I'm not mistaken) and to set up a cron job.\n  \n\n    - Simplify the script a bit by using the -a argument. This would allow me to set up a file with the links I want to download. This would allow me to group a bunch of commands that all have the same arguments into 1 command.\n  \n\n    - Write a script that will move videos that were downloaded before they were put into playlists into their respective playlists once the uploader adds them. Right now what I do is download all of the uploader's playlists, then download all of their videos (using the same archive file so it doesn't re-download any). This means if the uploader is slow to add the video to a playlist, it will just be downloaded to a \"No Playlist\" folder. The other way I could do this would be to find a way to deduplicate all of the videos in the \"No Playlist\" folder and just use separate archive files for the playlist and non playlist videos, which might download some videos twice, but then later deduplicated.\n  \n\n\nFinal Thoughts:\n\n\n\n    Youtube-dl is a wonderful and powerful tool, and with all of the crap going down on YouTube, you can never be too sure what videos you love might be taken down. Just what I've managed to download has already helped me and some of my friends out. It definitely is worth your time to automate downloading videos from channels you enjoy, and with a little know-how and experimentation, it doesn't take much time or effort to get something to a point where you can set it and forget it.\n  \n\n    Anyway, that was certainly longer than I thought it would be, but I really hope it helps some of you guys out. I've gained so much knowledge from this subreddit and it would mean a lot if I gave back and helped one of you out in return. Happy Hoarding!\n  \n\n\n\n\nJust a quick edit:\n Be sure to check out the comments for some excellent ideas and more information on some things! As always, take this information and adapt it to your use case. Maybe my configuration will work perfectly for you, but more than likely you will have to tweak it a bit to get it just right for you. If you have any questions, please ask!\n  \n\n\nAnother quick edit:\n Some of the comments have brought up the fact that us as viewers of YouTube content, and even youtube-dl itself don't have any way to watch or download the original quality of the material as YouTube will automatically transcode videos when they are uploaded. This can be a problem for people who are trying to preserve things in the best quality they possibly can. If you are one of these people, you might want to try looking elsewhere for better quality releases of the content. The one example that immediately comes to mind for me is content from Rooster Teeth. The quality when downloaded directly from their website seems to be better quality than what you can pull from YouTube. For me personally, I will download some movies, and TV Shows and also most music and images in the best possible quality I can find, but when it comes to YouTube content, I just don't care as much and find the convenience of ripping directly from YouTube hard to beat. I also think the content tends to look great, especially for the file sizes, but this is obviously all up to you to decide."},
{"Title": "192TB beauty. What to do with it ?", "Author": "u/henk1313", "Content": "No content"},
{"Title": "File size of Endgame's Cinema DCP", "Author": "Unknown author", "Content": "No content"},
{"Title": "A friend calls and asks \"I can't find this video on any streaming service. Any chance you have it?\"", "Author": "u/TNightster", "Content": "No content"},
{"Title": "Remember to backup your data, you never know when a spinning disk is going to fail and then you end up with a lot of shiny drinks coasters", "Author": "u/bri999", "Content": "No content"},
{"Title": "This is what \"frustration-free\" packaging means in Europe", "Author": "u/FigureOfEight", "Content": "No content"},
{"Title": "80 TB homeserver for datahoarding", "Author": "u/kirjeveitsi", "Content": "No content"},
{"Title": "Please do not mirror YouTube on the Internet Archive in Bulk", "Author": "u/textfiles", "Content": "https://twitter.com/textfiles/status/1492209816730808331\n\n\n\n    I posted this in a twitter thread, but I thought I'd mention this (obvious) thread here as well:\n  \n\n    Every once in a while, someone gets a brilliant idea, which is not a brilliant idea, and the first step for a mountain of heartache.  The idea is \"The Internet Archive is permanency-minded, and Youtube is full of things. I should back up Youtube on Internet Archive\".\n  \n\n    Depending on the person's capabilities and their drive, they may back up a couple videos here and there, or, as sometimes people are capable of doing, they set up a massive operation to just start jamming thousands of YouTube videos in \"just in case\".  Do not do this.\n  \n\n    YouTube is a massive ecosystem of videos, ranging from:\n  \n\n\n\n\n\n    Mirrors of neat stuff from video sources\n  \n\n\n\n\n\n    Archival copies of things on other media\n  \n\n\n\n\n\n    Businesses/Channels, ad-reliant, putting out shows\n  \n\n\n\n\n\n    And more.\n  \n\n\n\n\n\n    It's actually rather complicated and there's lots of considerations.\n  \n\n    When you decide, on your own, to \"help\" by downloading dozens of terabytes of videos, sometimes sans metadata, other times with random filenames, and just shove them into the Internet Archive, you're just hurting a non-profit by doing so. You are not a hero.  Please don't.\n  \n\n    Going to say it again: Please don't.  If you have a legitimate concern of a specific situation (creator has died, the material is some sort of culturally-relevant \"leak\" or unique situation, etc.) then communicate with the Archive (or me) about it, we'll work something out.\n  \n\n    Today's writing was brought to you by someone who could have used this information in their lives 2 months ago.\n  \n\n\nUPDATE: I\n \nresponded to one of the threads generated\n \nin a way that probably applies to 90% of the issues brought up."},
{"Title": "Ok which one of you did this?", "Author": "u/drbennett75", "Content": "No content"},
{"Title": "Seagate's flex - 3 ZB shipped", "Author": "u/greasythug", "Content": "No content"},
{"Title": "Just a reminder of what we have lost, and why we feel how we feel about data. I guarantee everybody that sees this can find an artist that is near to their heart. This is completely unconscionable and my heart aches looking at this list.", "Author": "u/PoorWill", "Content": "No content"},
{"Title": "Mines still going strong 🤷", "Author": "u/apeironone", "Content": "No content"},
{"Title": "Youtube educational hacking content getting banned", "Author": "u/ignaloidas", "Content": "No content"},
{"Title": "I was told I belong here", "Author": "u/dshbak", "Content": "No content"},
{"Title": "Twitter will soon begin suspending accounts that have been inactive for 30 days", "Author": "Unknown author", "Content": "No content"},
{"Title": "Twitter removed a student’s tweets critical of exam monitoring tool due to DMCA notice; EFF claims it is textbook example of fair use", "Author": "u/retrac1324", "Content": "No content"},
{"Title": "Tumblr will ban all adult content on December 17th.", "Author": "u/yashendra2797", "Content": "Get ready to mass download your favorite adult blogs guys. This is gonna be such a punch in the gut to so many talented creators. Tumblr had some of the best captions, 3D Porn, 2D Porn, TG Porn, Art Porn, Alt Porn, and Erotica. If anyone knows of a way to mass rip sites please post them in the comments.\n  \n\n    Source:\n  \n\n\nThe Verge\n\n\n\n\nTumblr Community Policy\n\n\n\n\nTumblr Announcement\n\n\n\n    EDIT: Oh boy. \n106\n replies meant my phone was buzzing all night. Woke up 2 hours late because my phones were dead. Thanks for getting me extra sleep guys!"},
{"Title": "A backup everyone must have (the storage media may be different)", "Author": "u/psych_1337", "Content": "No content"},
{"Title": "When your boss is an insurance agent... ioSafe 1019+", "Author": "u/wirerogue", "Content": "No content"},
{"Title": "NAS in transit to new house. Baby in trunk.", "Author": "u/therealschwartz", "Content": "No content"},
{"Title": "PSA: Verbatim no longer sells real M Discs, now puts regular BD-Rs in M Disc packaging", "Author": "u/JazzKazz", "Content": "TLDR: instead of selling real M Discs, Verbatim now puts their cheap organic BD-Rs into M Disc cases and charges M Disc prices for them\n  \n\n    In July, I bought 25GB Verbatim M Discs from Amazon. Even though I bought them directly from Amazon Europe, the discs I received were not real M Discs but regular Verbatim BD-Rs with an organic layer that were made to look like M Discs. I noticed right away because the MID of the discs was \nVERBAT-IMe-000\n, which is the code for their regular BD-Rs, instead of \nMILLEN-MR1-000\n which is the MID that all 25GB M Discs have. At this point I assumed I'd been sold fakes, but 3 months later I again ordered Verbatim M Discs, this time from German retail chain Saturn, and once again received these discs that I assumed are fakes. I emailed Verbatim's customer service and \nprepared a bunch of images that show these fake M Discs next to real ones.\n But to my surprise, after a debate with customer service they told me that these are not fakes, and that these \"are the only M Discs that are going to be sold from now on\" (quote). What's insane is that these discs currently being sold are not M Discs at all, but regular organic layer Verbatim BD-Rs, yet Verbatim still calls these M Disc. When I tried calling them out on their lies by pointing out things such as the discs' MID being the same as that of regular BD-Rs and the discs having 6x burn speed despite real M Discs being 4x speed, they just chucked it up to \"the discs being completely reworked, and we moved production facility hence the new DISC IDs\". The most ridiculous part is, these \"new M Discs\" (as Verbatim support calls them) are writable in any standard Blu Ray drive, you don't even need a drive that supports M Disc burning! For those unaware, M Discs require an M Disc capable drive to be burned, because M Discs need a stronger laser than what is used for regular BDs. This stronger laser is only in M Disc drives and there is no way you could ever write a real M Disc in a non M Disc drive. Yet here we have customers being sold cheap organic layer BD-Rs and being deceived into thinking they're buying M Discs.\n  \n\n    I find this absolutely insane as people burn hundreds of these discs a day, trusting them to reliably hold precious data, yet most people aren't aware they're not burning a real M Disc, but just a garden variety BD-R that has none of the M Disc advantages that you pay for. So far the only mention of this that I've found online is a \nGerman thread from August\n where somebody received these same VERBAT-IMe-000 discs as me and thinks they're fake, not aware that Verbatim themselves are behind these discs.\n  \n\n    Some stores still have real M Discs in stock, but the majority of them (at least in Germany) now sell the new, fake kind, as I've ordered M Discs from various stores over the past few weeks and 90% of the time received the new fake kind which I returned. It probably also depends on region, I have no idea about discs in the US or other countries. \nCheck the IDs of your discs people.\n\n\n\n    Quick check:\n  \n\n\n\n\n\n    A real M Disc has a copper/gold tint on the back, the new fake ones are silver\n  \n\n\n\n\n\n    A real M Disc (25GB) has the MID/DISC ID: MILLEN-MR1-000, no matter what brand\n  \n\n\n\n\n\n    A real M Disc only burns in a drive with M Disc support"},
{"Title": "The Internet Archive is in danger", "Author": "u/Cereal_is_great", "Content": "No content"},
{"Title": "PSA: It is unwise to 3D print your HDD holders out of PLA in this heatwave. Also, RAID is not a backup", "Author": "u/theartlav", "Content": "No content"},
{"Title": "SaveVideo bot is safe for now - the takedown notice was not sent by Reddit but an impersonator", "Author": "u/i_have_20_bucks", "Content": "No content"},
{"Title": "I just put these together at work. 48 7.68TB drives in 2 Dell 740xd servers with dual Xeon Platinum processors and 768GB of RAM each.", "Author": "u/Legionnaire1856", "Content": "No content"},
{"Title": "What happened to Pornhub is a sign of things to come. Be prepared for The Great Digitial Purge.", "Author": "u/Watchmen1986", "Content": "Transitional Justice is coming. Whether it is YouTube, instagram, facebook or whatever platform you are using, a wave of self-censorship is surging. Be smart enough to save things now. Like right now."},
{"Title": "Took a chance on buying 30 drives from eBay, USPS says they care, prognosis isn't good.", "Author": "u/the1337moderate", "Content": "No content"},
{"Title": "Wikia, known for deleting wikis that aren't active enough, has acquired gaming history including Gamefaqs, Gamespot, Metacritic and other sites - They are in critical danger of being purged", "Author": "u/CreationBlues", "Content": "No content"},
{"Title": "He gets it", "Author": "u/ThePandaMan1110", "Content": "No content"},
{"Title": "The entirety of Twitch has reportedly been leaked", "Author": "u/Megalan", "Content": "No content"},
{"Title": "Developer banned from Steam after using Steam Workshop of unreleased software as a porn stash. Which one of you did this?", "Author": "u/Metastasis3", "Content": "No content"},
{"Title": "Hard drives - from 5.25 inch to 1.0 inch", "Author": "u/HTWingNut", "Content": "No content"},
{"Title": "Home made, non GMO, cruelty free, off-site backup", "Author": "u/subtepass", "Content": "No content"},
{"Title": "Czkawka 3.1.0 - new version of my app to find duplicates, similar images, same music, broken files etc.", "Author": "u/krutkrutrar", "Content": "No content"},
{"Title": "My Dad and I’s second home NAS build with a total of 80tb and plenty of streaming capability.", "Author": "u/benmilek", "Content": "No content"},
{"Title": "I hit a bit of a milestone today", "Author": "u/Beaston02", "Content": "No content"},
{"Title": "Epic Games shuts down the Unreal Engine wiki, basically the only ressource for learning the C++ aspect of it, without any real warning", "Author": "u/WPLibrar2", "Content": "No content"},
{"Title": "this is my new nas please like and subscribe", "Author": "u/jesuswhathaveidone", "Content": "No content"},
{"Title": "Z-Library Website Is Alive Again", "Author": "u/vadhavaniyafaijan", "Content": "No content"},
{"Title": "Unboxed my new NAS server just now and she’s already sitting on it", "Author": "u/blueskyn01se", "Content": "No content"},
{"Title": "Fitted out my old case with room enough for 20 HDD's of hoarding!", "Author": "u/lkashl", "Content": "No content"},
{"Title": "iFixit now has a How to guide on shucking drives", "Author": "u/Glenta3924", "Content": "No content"},
{"Title": "This is why we exist - prime arguing you don’t own what you pay for", "Author": "u/imajes", "Content": "No content"},
{"Title": "A terabyte isn’t what it used to be - 14% of Internet customers use more", "Author": "u/It_Is1-24PM", "Content": "No content"},
{"Title": "Who said they raise the price Before Black Friday?", "Author": "u/thenextbranson95", "Content": "No content"},
{"Title": "Let's Say You Wanted to Back Up The Internet Archive", "Author": "u/textfiles", "Content": "So, you think you want to back up the Internet Archive.\n\n\n\n    This is a gargantuan project and not something to be taken lightly. Definitely consider why you think you need to do this, and what exactly you hope to have at the end. There's thousands of subcollections at the Archive and maybe you actually want a smaller set of it. These instructions work for those smaller sets and you'll get it much faster.\n  \n\n    Or you're just curious as to what it would take to get \neverything\n.\n  \n\n    Well, first, bear in mind there's different classes of material in the Archive's 50+ petabytes of data storage. There's material that can be downloaded, material that can only be viewed/streamed, and material that is used internally like the wayback machine or database storage. We'll set aside the 20+ petabytes of material under the wayback for the purpose of this discussion other than you can get websites by directly downloading and mirroring as you would any web page.\n  \n\n    That leaves the many collections and items you can reach directly. They tend to be in the form of \nhttps://archive.org/details/identifier\n where \nidentifier\n is the \"item identifier\", more like a directory scattered among dozens and dozens of racks that hold the items. By default, these are completely open to downloads, unless they're set to be a variety of \"stream/sample\" settings, at which point, for the sake of this tutorial, can't be downloaded at all - just viewed.\n  \n\n    To see the directory version of an item, switch \ndetails\n to \ndownload\n, like \narchive.org/download/identifier\n - this will show you all the files residing for an item, both Original, System, and Derived. Let's talk about those three.\n  \n\n\nOriginal\n files are what were uploaded into the identifier by the user or script. They are never modifier or touched by the system. Unless something goes wrong, what you download of an original file is exactly what was uploaded.\n  \n\n\nDerived\n files are then created by the scripts and handlers within the archive to make them easier to interact with. For example, PDF files are \"derived\" into EPUBs, jpeg-sets, OCR'd textfiles, and so on.\n  \n\n\nSystem\n files are created by the processes of the Archive's scripts to either keep track of metadata, of information about the item, and so on. They are generally *.xml files, or thumbnails, or so on.\n  \n\n    In general, you only want the \nOriginal\n files as well as the metadata (from the *.xml files) to have the \"core\" of an item. This will save you a lot of disk space - the derived files can always be recreated later.\n  \n\n\nSo Anyway\n\n\n\n    The best of the ways to download from Internet Archive is using the official client. I wrote an introduction to the IA client here:\n  \n\n\nhttp://blog.archive.org/2019/06/05/the-ia-client-the-swiss-army-knife-of-internet-archive/\n\n\n\n    The direct link to the IA client is here:  \nhttps://github.com/jjjake/internetarchive\n\n\n\n    So, an initial experiment would be to download the entirety of a specific collection.\n  \n\n    To get a collection's items, do \nia search collection:collection-name --itemlist\nThen, use \nia download\n to download each individual item. You can do this with a script, and even do it in parallel. There's also the --retries command, in case systems hit load or other issues arise. (I advise checking the documentation and reading thoroughly - perhaps people can reply with recipes of what they have found.\n  \n\n    There are over 63,000,000 individual items at the Archive. Choose wisely. And good luck.\n  \n\n\nEdit, Next Day:\n\n\n\n    As is often the case when the Internet Archive's collections are discussed in this way, people are proposing the usual solutions, which I call the Big Three:\n  \n\n\n\n\n\n    Organize an ad-hoc/professional/simple/complicated shared storage scheme\n  \n\n\n\n\n\n    Go to a [corporate entity] and get some sort of discount/free service/hardware\n  \n\n\n\n\n\n    Send Over a Bunch of Hard Drives and Make a Copy\n  \n\n\n\n\n\n    I appreciate people giving thought to these solutions and will respond to them (or make new stand-along messages) in the thread. In the meantime, I will say that the Archive has endorsed and worked with a concept called The Distributed Web which has both included discussions and meetings as well as proposed technologies - at the very least, it's interesting and along the lines that people think of when they think of \"sharing\" the load. A FAQ:  \nhttps://blog.archive.org/2018/07/21/decentralized-web-faq/"},
{"Title": "Don’t lie, if they actually made it most of us would buy it… RS-232 port and all.", "Author": "u/pdmcmahon", "Content": "No content"},
{"Title": "PSA: It is unwise to 3D print your HDD holders out of PLA in this heatwave. Also, RAID is not a backup", "Author": "u/theartlav", "Content": "No content"},
{"Title": "SaveVideo bot is safe for now - the takedown notice was not sent by Reddit but an impersonator", "Author": "u/i_have_20_bucks", "Content": "No content"},
{"Title": "I just put these together at work. 48 7.68TB drives in 2 Dell 740xd servers with dual Xeon Platinum processors and 768GB of RAM each.", "Author": "u/Legionnaire1856", "Content": "No content"},
{"Title": "What happened to Pornhub is a sign of things to come. Be prepared for The Great Digitial Purge.", "Author": "u/Watchmen1986", "Content": "Transitional Justice is coming. Whether it is YouTube, instagram, facebook or whatever platform you are using, a wave of self-censorship is surging. Be smart enough to save things now. Like right now."},
{"Title": "Took a chance on buying 30 drives from eBay, USPS says they care, prognosis isn't good.", "Author": "u/the1337moderate", "Content": "No content"},
{"Title": "Wikia, known for deleting wikis that aren't active enough, has acquired gaming history including Gamefaqs, Gamespot, Metacritic and other sites - They are in critical danger of being purged", "Author": "u/CreationBlues", "Content": "No content"},
{"Title": "He gets it", "Author": "u/ThePandaMan1110", "Content": "No content"},
{"Title": "The entirety of Twitch has reportedly been leaked", "Author": "u/Megalan", "Content": "No content"},
{"Title": "Developer banned from Steam after using Steam Workshop of unreleased software as a porn stash. Which one of you did this?", "Author": "u/Metastasis3", "Content": "No content"},
{"Title": "Hard drives - from 5.25 inch to 1.0 inch", "Author": "u/HTWingNut", "Content": "No content"},
{"Title": "Home made, non GMO, cruelty free, off-site backup", "Author": "u/subtepass", "Content": "No content"},
{"Title": "Czkawka 3.1.0 - new version of my app to find duplicates, similar images, same music, broken files etc.", "Author": "u/krutkrutrar", "Content": "No content"},
{"Title": "My Dad and I’s second home NAS build with a total of 80tb and plenty of streaming capability.", "Author": "u/benmilek", "Content": "No content"},
{"Title": "I hit a bit of a milestone today", "Author": "u/Beaston02", "Content": "No content"},
{"Title": "Epic Games shuts down the Unreal Engine wiki, basically the only ressource for learning the C++ aspect of it, without any real warning", "Author": "u/WPLibrar2", "Content": "No content"},
{"Title": "this is my new nas please like and subscribe", "Author": "u/jesuswhathaveidone", "Content": "No content"},
{"Title": "Z-Library Website Is Alive Again", "Author": "u/vadhavaniyafaijan", "Content": "No content"},
{"Title": "Unboxed my new NAS server just now and she’s already sitting on it", "Author": "u/blueskyn01se", "Content": "No content"},
{"Title": "Fitted out my old case with room enough for 20 HDD's of hoarding!", "Author": "u/lkashl", "Content": "No content"},
{"Title": "iFixit now has a How to guide on shucking drives", "Author": "u/Glenta3924", "Content": "No content"},
{"Title": "This is why we exist - prime arguing you don’t own what you pay for", "Author": "u/imajes", "Content": "No content"},
{"Title": "A terabyte isn’t what it used to be - 14% of Internet customers use more", "Author": "u/It_Is1-24PM", "Content": "No content"},
{"Title": "Who said they raise the price Before Black Friday?", "Author": "u/thenextbranson95", "Content": "No content"},
{"Title": "Let's Say You Wanted to Back Up The Internet Archive", "Author": "u/textfiles", "Content": "So, you think you want to back up the Internet Archive.\n\n\n\n    This is a gargantuan project and not something to be taken lightly. Definitely consider why you think you need to do this, and what exactly you hope to have at the end. There's thousands of subcollections at the Archive and maybe you actually want a smaller set of it. These instructions work for those smaller sets and you'll get it much faster.\n  \n\n    Or you're just curious as to what it would take to get \neverything\n.\n  \n\n    Well, first, bear in mind there's different classes of material in the Archive's 50+ petabytes of data storage. There's material that can be downloaded, material that can only be viewed/streamed, and material that is used internally like the wayback machine or database storage. We'll set aside the 20+ petabytes of material under the wayback for the purpose of this discussion other than you can get websites by directly downloading and mirroring as you would any web page.\n  \n\n    That leaves the many collections and items you can reach directly. They tend to be in the form of \nhttps://archive.org/details/identifier\n where \nidentifier\n is the \"item identifier\", more like a directory scattered among dozens and dozens of racks that hold the items. By default, these are completely open to downloads, unless they're set to be a variety of \"stream/sample\" settings, at which point, for the sake of this tutorial, can't be downloaded at all - just viewed.\n  \n\n    To see the directory version of an item, switch \ndetails\n to \ndownload\n, like \narchive.org/download/identifier\n - this will show you all the files residing for an item, both Original, System, and Derived. Let's talk about those three.\n  \n\n\nOriginal\n files are what were uploaded into the identifier by the user or script. They are never modifier or touched by the system. Unless something goes wrong, what you download of an original file is exactly what was uploaded.\n  \n\n\nDerived\n files are then created by the scripts and handlers within the archive to make them easier to interact with. For example, PDF files are \"derived\" into EPUBs, jpeg-sets, OCR'd textfiles, and so on.\n  \n\n\nSystem\n files are created by the processes of the Archive's scripts to either keep track of metadata, of information about the item, and so on. They are generally *.xml files, or thumbnails, or so on.\n  \n\n    In general, you only want the \nOriginal\n files as well as the metadata (from the *.xml files) to have the \"core\" of an item. This will save you a lot of disk space - the derived files can always be recreated later.\n  \n\n\nSo Anyway\n\n\n\n    The best of the ways to download from Internet Archive is using the official client. I wrote an introduction to the IA client here:\n  \n\n\nhttp://blog.archive.org/2019/06/05/the-ia-client-the-swiss-army-knife-of-internet-archive/\n\n\n\n    The direct link to the IA client is here:  \nhttps://github.com/jjjake/internetarchive\n\n\n\n    So, an initial experiment would be to download the entirety of a specific collection.\n  \n\n    To get a collection's items, do \nia search collection:collection-name --itemlist\nThen, use \nia download\n to download each individual item. You can do this with a script, and even do it in parallel. There's also the --retries command, in case systems hit load or other issues arise. (I advise checking the documentation and reading thoroughly - perhaps people can reply with recipes of what they have found.\n  \n\n    There are over 63,000,000 individual items at the Archive. Choose wisely. And good luck.\n  \n\n\nEdit, Next Day:\n\n\n\n    As is often the case when the Internet Archive's collections are discussed in this way, people are proposing the usual solutions, which I call the Big Three:\n  \n\n\n\n\n\n    Organize an ad-hoc/professional/simple/complicated shared storage scheme\n  \n\n\n\n\n\n    Go to a [corporate entity] and get some sort of discount/free service/hardware\n  \n\n\n\n\n\n    Send Over a Bunch of Hard Drives and Make a Copy\n  \n\n\n\n\n\n    I appreciate people giving thought to these solutions and will respond to them (or make new stand-along messages) in the thread. In the meantime, I will say that the Archive has endorsed and worked with a concept called The Distributed Web which has both included discussions and meetings as well as proposed technologies - at the very least, it's interesting and along the lines that people think of when they think of \"sharing\" the load. A FAQ:  \nhttps://blog.archive.org/2018/07/21/decentralized-web-faq/"},
{"Title": "Don’t lie, if they actually made it most of us would buy it… RS-232 port and all.", "Author": "u/pdmcmahon", "Content": "No content"},
{"Title": "Some datahoarder porn :) one of my archive projects with a customer who ditched the tape towards disk/cloud archiving. 4PB here. Each orange jbod is 60 bay top loader", "Author": "u/kumits-u", "Content": "No content"},
{"Title": "ISOs are nice but sometimes you need to hoard the originals for the complete experience. (And also rip them to ISO)", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "I collect countless documents and images and organize them by year. So satisfying.", "Author": "u/dirtypark", "Content": "No content"},
{"Title": "My offsite backup!", "Author": "u/pairofcrocs", "Content": "No content"},
{"Title": "X (formerly knows as Twitter) purged all media from posts from before 2014", "Author": "u/coasterghost", "Content": "No content"},
{"Title": "Just found nearly every Playboy from January 1976 to September 2001 at the recycling drop", "Author": "u/frazzleb420", "Content": "No content"},
{"Title": "I Blame Each and Every One of You....", "Author": "u/MeatballB", "Content": "No content"},
{"Title": "Sad day at Warner Brothers", "Author": "u/imajes", "Content": "No content"},
{"Title": "My data hoarding project: scanning 15 years worth of journals & converting to PDF for archive and safekeeping", "Author": "u/thebilljim", "Content": "No content"},
{"Title": "Thanks Amazon I love dents", "Author": "u/ralphte", "Content": "No content"},
{"Title": "Lovely machine for digitalizing books", "Author": "u/Zloty_Diament", "Content": "No content"},
{"Title": "YouTube Vanced: speculation that profiting of the project with NFTs is what triggered the cease and desist", "Author": "u/EpsilonBlight", "Content": "https://arstechnica.com/gadgets/2022/03/google-shuts-down-youtube-vanced-a-popular-ad-blocking-android-app/\n\n\n\n\n\n    Just last month, Team Vanced pulled a provocative stunt involving minting a non-fungible token of the Vanced logo, and there's solid speculation that this action is what drew Google's ire. Google mostly tends to leave the Android modding community alone, but profiting off your legally dubious mod is sure to bring out the lawyers.\n  \n\n\n\n    Once again crypto is why we can't have nice things."},
{"Title": "Contrary to many posts here, at least second hand sellers know how pack things.", "Author": "u/Matti_Meikalainen", "Content": "No content"},
{"Title": "Looks like Amazon is pulling the plug on unlimited cloud storage.", "Author": "Unknown author", "Content": "No content"},
{"Title": "Do the data backup!", "Author": "u/Sarke1", "Content": "No content"},
{"Title": "Article: “10 everyday things that will vanish in the next 10 years”... I wonder what they think cloud providers use to store all that data.", "Author": "u/Sp00ky777", "Content": "No content"},
{"Title": "Internet forums are disappearing because now it's all Reddit and Discord. And that's worrying.", "Author": "u/Run_the_Line", "Content": "No content"},
{"Title": "Library Genesis Project update: 2.5 million books seeded with the world, 80 million scientific articles next", "Author": "u/shrine", "Content": "For the latest updates on the Library Genesis Seeding Project join\n \nr/libgen\n \nand\n \nr/scihub\n\n\n\n    Last month volunteers on \nr/seedboxes\n, \nr/datahoarder\n, across reddit, and around the world joined together to secure and preserve 2.5 million scientific books for humanity- for students, for doctors, for scientists, for future generations. The outpour of support for the project still leaves me in total awe. Thousands of people around the world joined our seeding effort donating bandwidth, storage, and expertise.\n  \n\n    Today we announce that the final set of 1,000 books is now seeded, saved, and preserved. Stunning generosity and heart. But our volunteers couldn’t stop at books. We have already started to secure and preserve a new library of 80 million scientific articles. And now thanks to the brave librarians at Library Genesis and SciHub and all the volunteer seeders the collections can never be taken away from humanity.\n  \n\n\nWhy are Library Genesis and SciHub vital to humanity?\n\n\n\n    Library Genesis and SciHub set out to share every scientific article and every scientific book with every single person on Earth. Their initiative fulfills United Nations/UNESCO world development goals that mandate the removal of restrictions on access to science. Big publishing companies just want “open access,” representing only about 28% of articles, and no books. They want the rest of humanity’s accumulated scientific knowledge to remain locked up behind paywalled databases and unaffordable textbooks.\n  \n\n    We said fuck that. Limiting and delaying humanity’s access to science isn’t a business, it’s a crime, one with an untold number of victims and preventable deaths. Doctors and scientists in the developing world already face unbelievable challenges in their jobs. Tearing down paywalls between them and the knowledge they need to fight for health and freedom in their homeland is the least we can do to help.\n  \n\n\nHow can I help?\n\n\n\n\n\n\n\n    Reddit’s support has been huge. In December the project’s story was published in Vice, receiving 60,000 upvotes across \nr/technology\n, \nr/futurology\n, \nr/datahoarder\n, and \nr/seedboxes\n, and shared to readers around the world in international technology news. That’s just for seeding the torrents! Imagine the stories of knowledge brought to doctors and scientists and students around the world. They hold an incredible story to tell. We need their stories next, and we can bring the crisis of access to knowledge into view with our upvotes.\n  \n\n\n\n\n\n    Our seeding project has been an incredible success thanks to literal 24/7 work of our volunteers over the last month. \nSeedbox.io\n and their provider \nNFOrce.nl\n donated a dedicated high-speed server to seed the full Library Genesis book collection. The-Eye.eu is both seeding and archiving the entirety of both library collections. You’re also welcome to join The-Eye.eu’s discord to learn how you can help seed (discord.gg/the-eye #books).\n  \n\n\n\n\n\n    Programmers are needed to help re-envision the web frontend, search engine, or distribution model (\nhttps://gitlab.com/libgen1\n). The entirety of Library Genesis is open-source, so anyone is welcome to reimagine the project.\n  \n\n\n\n\n\n\nHere's what else our communities accomplished in technical details:\n\n\n\n\n\n\n\n    Swarm peers increased from 3,000 seeders to 30,000 seeders!\n  \n\n\n\n\n\n    Swarm speeds increased from about 60KB/s on most torrents to over 100MB/s, thanks to the joint \nSeedbox.io\n and \nNFOrce.nl\n dedicated server and everyone else seeding.\n  \n\n\n\n\n\n    Refreshed and indexed 2,400 .torrent files, replacing 100+ dead trackers with new, live announce URLs\n  \n\n\n\n\n\n    The-Eye.eu began to prepare and hash-check the collection for archiving, more to come on that (TBA)\n  \n\n\n\n\n\n\nEndless thanks to everyone at\n \nthe-eye.eu\n, all the volunteers, Seedbox.io/NFOrce.nl, and UltraSeedbox for coming together to make this project happen. We brought science around the world with our torrenting, one of the many big steps in permanently unchaining and preserving all of this knowledge for humanity.\n\n\n\n\nhttps://preview.redd.it/coz7hvkh3s541.png\n\n\nRelevant Links\n\n\n\n\nhttps://phillm.net/libgen-seeds-needed.php\n\n\n\n\nhttps://phillm.net/libgen-stats-table.php\n\n\n\n\n\"Archivists Are Trying to Make Sure a ‘Pirate Bay of Science’ Never Goes Down\" by Matthew Gault in Vice News\n\n\n\n\nTorrentFreak's coverage by Andy\n\n\n\n\n/r/DataHoarder: Let's talk about datahoarding that's actually important: distributing knowledge and the role of Libgen in educating the developing world.\n\n\n\n\n/r/Seedboxes Charity Drive\n\n\n\n\n/r/Seedboxes Update"},
{"Title": "Here's a simple 7 bay CD/DVD ripping machine I just made. Works great! Time to rip 2100 CDs and 300 DVDs", "Author": "u/TVSKS", "Content": "No content"},
{"Title": "Video Archival Rack - ~50TB of Uncompressed Video Digitized (and Counting)!", "Author": "u/VincentVazzo", "Content": "No content"},
{"Title": "Bought 2 old CCTV DVR units for $25, each one had a WD Purple 4tb Drive", "Author": "u/nickdrones", "Content": "No content"},
{"Title": "Just imagine what it would be like if it were still this size... An IBM 5MB hard drive back in 1956.", "Author": "u/TinderSubThrowAway", "Content": "No content"},
{"Title": "Data hoarder Flash Drive style", "Author": "u/forlotto", "Content": "No content"},
{"Title": "Stopped at a different Costco than normal and I may have found the holy grail. St Louis Park MN.", "Author": "u/twonuh", "Content": "No content"},
{"Title": "Data-mining reveals that 80% of books published 1924-63 never had their copyrights renewed and are now in the public domain", "Author": "u/no-mad", "Content": "No content"},
{"Title": "Some datahoarder porn :) one of my archive projects with a customer who ditched the tape towards disk/cloud archiving. 4PB here. Each orange jbod is 60 bay top loader", "Author": "u/kumits-u", "Content": "No content"},
{"Title": "ISOs are nice but sometimes you need to hoard the originals for the complete experience. (And also rip them to ISO)", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "I collect countless documents and images and organize them by year. So satisfying.", "Author": "u/dirtypark", "Content": "No content"},
{"Title": "My offsite backup!", "Author": "u/pairofcrocs", "Content": "No content"},
{"Title": "X (formerly knows as Twitter) purged all media from posts from before 2014", "Author": "u/coasterghost", "Content": "No content"},
{"Title": "Just found nearly every Playboy from January 1976 to September 2001 at the recycling drop", "Author": "u/frazzleb420", "Content": "No content"},
{"Title": "I Blame Each and Every One of You....", "Author": "u/MeatballB", "Content": "No content"},
{"Title": "Sad day at Warner Brothers", "Author": "u/imajes", "Content": "No content"},
{"Title": "My data hoarding project: scanning 15 years worth of journals & converting to PDF for archive and safekeeping", "Author": "u/thebilljim", "Content": "No content"},
{"Title": "Thanks Amazon I love dents", "Author": "u/ralphte", "Content": "No content"},
{"Title": "Lovely machine for digitalizing books", "Author": "u/Zloty_Diament", "Content": "No content"},
{"Title": "YouTube Vanced: speculation that profiting of the project with NFTs is what triggered the cease and desist", "Author": "u/EpsilonBlight", "Content": "https://arstechnica.com/gadgets/2022/03/google-shuts-down-youtube-vanced-a-popular-ad-blocking-android-app/\n\n\n\n\n\n    Just last month, Team Vanced pulled a provocative stunt involving minting a non-fungible token of the Vanced logo, and there's solid speculation that this action is what drew Google's ire. Google mostly tends to leave the Android modding community alone, but profiting off your legally dubious mod is sure to bring out the lawyers.\n  \n\n\n\n    Once again crypto is why we can't have nice things."},
{"Title": "Contrary to many posts here, at least second hand sellers know how pack things.", "Author": "u/Matti_Meikalainen", "Content": "No content"},
{"Title": "Looks like Amazon is pulling the plug on unlimited cloud storage.", "Author": "Unknown author", "Content": "No content"},
{"Title": "Do the data backup!", "Author": "u/Sarke1", "Content": "No content"},
{"Title": "Article: “10 everyday things that will vanish in the next 10 years”... I wonder what they think cloud providers use to store all that data.", "Author": "u/Sp00ky777", "Content": "No content"},
{"Title": "Internet forums are disappearing because now it's all Reddit and Discord. And that's worrying.", "Author": "u/Run_the_Line", "Content": "No content"},
{"Title": "Library Genesis Project update: 2.5 million books seeded with the world, 80 million scientific articles next", "Author": "u/shrine", "Content": "For the latest updates on the Library Genesis Seeding Project join\n \nr/libgen\n \nand\n \nr/scihub\n\n\n\n    Last month volunteers on \nr/seedboxes\n, \nr/datahoarder\n, across reddit, and around the world joined together to secure and preserve 2.5 million scientific books for humanity- for students, for doctors, for scientists, for future generations. The outpour of support for the project still leaves me in total awe. Thousands of people around the world joined our seeding effort donating bandwidth, storage, and expertise.\n  \n\n    Today we announce that the final set of 1,000 books is now seeded, saved, and preserved. Stunning generosity and heart. But our volunteers couldn’t stop at books. We have already started to secure and preserve a new library of 80 million scientific articles. And now thanks to the brave librarians at Library Genesis and SciHub and all the volunteer seeders the collections can never be taken away from humanity.\n  \n\n\nWhy are Library Genesis and SciHub vital to humanity?\n\n\n\n    Library Genesis and SciHub set out to share every scientific article and every scientific book with every single person on Earth. Their initiative fulfills United Nations/UNESCO world development goals that mandate the removal of restrictions on access to science. Big publishing companies just want “open access,” representing only about 28% of articles, and no books. They want the rest of humanity’s accumulated scientific knowledge to remain locked up behind paywalled databases and unaffordable textbooks.\n  \n\n    We said fuck that. Limiting and delaying humanity’s access to science isn’t a business, it’s a crime, one with an untold number of victims and preventable deaths. Doctors and scientists in the developing world already face unbelievable challenges in their jobs. Tearing down paywalls between them and the knowledge they need to fight for health and freedom in their homeland is the least we can do to help.\n  \n\n\nHow can I help?\n\n\n\n\n\n\n\n    Reddit’s support has been huge. In December the project’s story was published in Vice, receiving 60,000 upvotes across \nr/technology\n, \nr/futurology\n, \nr/datahoarder\n, and \nr/seedboxes\n, and shared to readers around the world in international technology news. That’s just for seeding the torrents! Imagine the stories of knowledge brought to doctors and scientists and students around the world. They hold an incredible story to tell. We need their stories next, and we can bring the crisis of access to knowledge into view with our upvotes.\n  \n\n\n\n\n\n    Our seeding project has been an incredible success thanks to literal 24/7 work of our volunteers over the last month. \nSeedbox.io\n and their provider \nNFOrce.nl\n donated a dedicated high-speed server to seed the full Library Genesis book collection. The-Eye.eu is both seeding and archiving the entirety of both library collections. You’re also welcome to join The-Eye.eu’s discord to learn how you can help seed (discord.gg/the-eye #books).\n  \n\n\n\n\n\n    Programmers are needed to help re-envision the web frontend, search engine, or distribution model (\nhttps://gitlab.com/libgen1\n). The entirety of Library Genesis is open-source, so anyone is welcome to reimagine the project.\n  \n\n\n\n\n\n\nHere's what else our communities accomplished in technical details:\n\n\n\n\n\n\n\n    Swarm peers increased from 3,000 seeders to 30,000 seeders!\n  \n\n\n\n\n\n    Swarm speeds increased from about 60KB/s on most torrents to over 100MB/s, thanks to the joint \nSeedbox.io\n and \nNFOrce.nl\n dedicated server and everyone else seeding.\n  \n\n\n\n\n\n    Refreshed and indexed 2,400 .torrent files, replacing 100+ dead trackers with new, live announce URLs\n  \n\n\n\n\n\n    The-Eye.eu began to prepare and hash-check the collection for archiving, more to come on that (TBA)\n  \n\n\n\n\n\n\nEndless thanks to everyone at\n \nthe-eye.eu\n, all the volunteers, Seedbox.io/NFOrce.nl, and UltraSeedbox for coming together to make this project happen. We brought science around the world with our torrenting, one of the many big steps in permanently unchaining and preserving all of this knowledge for humanity.\n\n\n\n\nhttps://preview.redd.it/coz7hvkh3s541.png\n\n\nRelevant Links\n\n\n\n\nhttps://phillm.net/libgen-seeds-needed.php\n\n\n\n\nhttps://phillm.net/libgen-stats-table.php\n\n\n\n\n\"Archivists Are Trying to Make Sure a ‘Pirate Bay of Science’ Never Goes Down\" by Matthew Gault in Vice News\n\n\n\n\nTorrentFreak's coverage by Andy\n\n\n\n\n/r/DataHoarder: Let's talk about datahoarding that's actually important: distributing knowledge and the role of Libgen in educating the developing world.\n\n\n\n\n/r/Seedboxes Charity Drive\n\n\n\n\n/r/Seedboxes Update"},
{"Title": "Here's a simple 7 bay CD/DVD ripping machine I just made. Works great! Time to rip 2100 CDs and 300 DVDs", "Author": "u/TVSKS", "Content": "No content"},
{"Title": "Video Archival Rack - ~50TB of Uncompressed Video Digitized (and Counting)!", "Author": "u/VincentVazzo", "Content": "No content"},
{"Title": "Bought 2 old CCTV DVR units for $25, each one had a WD Purple 4tb Drive", "Author": "u/nickdrones", "Content": "No content"},
{"Title": "Just imagine what it would be like if it were still this size... An IBM 5MB hard drive back in 1956.", "Author": "u/TinderSubThrowAway", "Content": "No content"},
{"Title": "Data hoarder Flash Drive style", "Author": "u/forlotto", "Content": "No content"},
{"Title": "Stopped at a different Costco than normal and I may have found the holy grail. St Louis Park MN.", "Author": "u/twonuh", "Content": "No content"},
{"Title": "Data-mining reveals that 80% of books published 1924-63 never had their copyrights renewed and are now in the public domain", "Author": "u/no-mad", "Content": "No content"},
{"Title": "PSA: The US copyright Office is taking public comments on automated copyright filters till TONIGHT, and The Senate Judiciary Committee is considering the EARN-IT act THIS WEEK, which would create liability for user created content, and encourage/force file scanning-Encryption bans. Take action!", "Author": "u/jabberwockxeno", "Content": "This isn't strictly Datahoarding related, but obviously automated copyright filters lead to lost data and online content, and anything like the EARN-IT act which increases liability for user created content will lead to sites shutting down and lost content as well. I have cleared this with the Mod team.\n  \n\n\n\n\n\n    As stated, the US copyright office is taking information, feedback, and input on automated filters and detection systems on Copyright infringement, likely to suggest and support the proliferation of those systems. It will be holding a session on February 22nd, followed by consultation with industry groups. However,** it is also taking comments and input from the general public up till 11:59PM EST on February 8th (TODAY), with a online form, and is explicitly also open to hearing the downsides of such systems.**\n  \n\n\n\n\n\n    More information as well as links to the comment form (direct link \nhere\n can be found here: \nhttps://www.eff.org/deeplinks/2022/02/tell-copyright-office-who-really-affected-filters\n. If you're not sure what exactly to write or aren't familar with how much of a trashfire these filters tend to be, [this[() article is a good starting overview, also from the EFF, and I have compiled some other examples \nhere\n.\n  \n\n\n\n\n\n    The EARN-IT act is also being considered. Remember FOSTA-SESTA from a few years back, the legislation that was osteinbly to go after sex trafficking but really just led to dozens of major websites to shut down their legal adult content and actually made it harder for law enforcement, by their own subsequent admission, to go after actual abusers and traffickers; and which was decried by basically every Digital civil liberty and sex worker group? This is that but worse. It will remove Section 230 protection for wide swathes of websites tangentially connected to adult material, opening it up to liability over user created content, as well as creates liability for using encryption and \"advises\" websites to scan all uploaded content.\n  \n\n\n\n\n\n    More info can be found firstly here: \nhttps://www.eff.org/deeplinks/2022/02/its-back-senators-want-earn-it-bill-scan-all-online-messages\n and secondly here: \nhttps://www.techdirt.com/articles/20220203/18143448411/how-earn-it-act-is-significantly-more-dangerous-than-fosta.shtml\n and thirdly here:\nhttp://cyberlaw.stanford.edu/blog/2022/02/earn-it-act-back-and-it%E2%80%99s-more-dangerous-ever\n\n\n\n    The EFF links I have provided include and link to tools to actually leave comments for the former, and contact your representatives in the Senate for the latter. If you aren't a US citizen, I encourage you to spread the word to those who are, and I technically don't see anything requiring you're a citizen for the Copyright Office form if you pick \"Anonymous\"\n  \n\n\nIf you're seeing this on the 9th or later, it is too late to comment on the Copyright Office stuff\n (timezone shenngians aside)  \nbut there IS still time to contact your senators about EARN IT!\n EDIT: EARN-IT is allegedly going up for vote on Thursday, the 10th, though this can change, so please still contact your represenatives!\n  \n\n    Please also follow the EFF and Fight for the Future, both regularly do advocacy and legal lobbying \nfor\n digital rights and online privacy and against copyright maximalist (I am not affilated with either group, I am just a nerd who cares about this stuff way too much and both have consistently been the sources to follow for this sort of stuff)"},
{"Title": "GitHub Archive in Svalbard", "Author": "u/FreneticFrench", "Content": "No content"},
{"Title": "I thought you guys would appreciate my messy, 10x DVD ripping machine I made out of an old DVD duplicator!", "Author": "u/pairofcrocs", "Content": "No content"},
{"Title": "Well, I’m no mathematician but I think I’ll go with the 14TB. Best Buy Canada", "Author": "u/animatedhockeyfan", "Content": "No content"},
{"Title": "52% of YouTube videos live in 2010 have been deleted", "Author": "u/themadprogramer", "Content": "No content"},
{"Title": "BOUNTY: $10 000USD. Remember me? Yes, I still have not found it. Please help me find the Whole videotape of Donald Trump on The Oprah Winfrey Show, 25th of April, 1988. Season 3, Episode 5 (a 60 min. episode with a few ads).", "Author": "u/trycoconutoil", "Content": "The Discord group for anyone interested:\n \nhttps://discord.gg/JD8Je3v\n \n(ongoing discussions)\n\n\n\n    Saw this tape on Facebook back in 2015. Then, it vanished. I have been searching on and off since then.\n  \n\n\nOFFICIAL BOUNTY\n: $1000USD\n\n\n\n\nTRANSCRIPTS: $1000USD\nMust be a copy of the original Journal Graphics transcript (Harpo productions bought their inventory)\n  \n\n\nSources that are relevant for the investigation:\n\n\n\n\n\n\n\n\nhttps://thetvdb.com/series/the-oprah-winfrey-show/episodes/6650339\n (air date)\n  \n\n\n\n\n\n    Michael Cohen (trumps former lawyer) talked about the \"Catch and Kill\" method that they utilized several times. This is most likely why it's difficult (not impossible) to find the tape. Explained in short at 1:37:35 \nhttps://www.youtube.com/watch?v=v0e62bOKm8o&t=5855s&ab_channel=TheNewYorkTimes\n- \"[Cohen] was often described by the media as Trump's 'fixer'.\" - \nWiki\n\n\n\n\n\n\n\n\n3 min. \npart from the original video\n (there are more short videos out there and almost the full video in the discord group. unfortunately, the broadcasting got interrupted for about 10 min. about half a year after the original tape). NOTE! the video is no longer up but can be put up again if requested.\n  \n\n\n\n\n\n\nhttps://www.reddit.com/r/politicalfactchecking/comments/4nt6iw/donald_trump_republicans_are_dumb_why_did_this/\n (Frustrated Redditors)\n  \n\n\n\n\n\n\nhttps://www.youtube.com/watch?v=AZtfSIgsH1o\n (some YouTube video that may not be important, but the comments on it are very relevant)\n  \n\n\n\n\n\n\nhttp://www.oprah.com/own-oprahshow/what-donald-trump-told-oprah-about-his-presidential-hopes-video\n (an old link that might have shown the full episode in the past)\n  \n\n\n\n\n\n\ninteresting article\n (Interesting article on the disappearance of the video.)\n  \n\n\n\n\n\n\nAnother Reddit post by someone else asking for the same episode.\n\n\n\n\n\n\n\n\nA Reddit post about the missing episode and what OP of this post thinks about it\n.\n  \n\n\n\n\n\n    I guess this TikToker deleted her account \nbut found a tweet about her talking about it.\n (had over 1 million views).\n  \n\n\n\n\n\n\nAn old website and      its resource page image\n\n\n\n\n\n\n\n    I will give the person who can find it and send it to me $10 000USD (if you want). I'll give it through cryptocurrency, anonymous PayPal system, product(s), or other means. Several Redditors also support the bounty. That will also be included if they stick to their guns.\n  \n\n\n\n\nNOTE!\n\n\n\n    Ignore the images and fact-checker sites. \nThose are red herrings\n and so point towards something different from the year 1998. I want the entire video from \nThe Oprah Winfrey Show, 25th of April, 1988, season 3, Episode 5, 60 minutes of the show.\n DM me here on Reddit or post it publically. No short vids or re-recordings that include interruptions. Simple. All of it. The show used to be quite popular; the entire content should be out there, internet, or stored.\n  \n\n\n\n\n**Since some ask. Why do I want it?**\n\n\n\n    I want it cause it has been suppressed and repressed on the internet, and various sites and people tell me what I saw and heard didn't happen, and it bothers me. And have found this exploration quite intriguing. I do not have any political intentions; I want the truth, sweetheart, for truth's sake.\n  \n\n\nGreat References:\n\n\n\n\n\n\n\n\n$1310 bounty post from last year\n (the second post)\n  \n\n\n\n\n\n\n$300 bounty post from last year\n (the first post)\n  \n\n\n\n\n\n    Subreddit for this: \nhttps://www.reddit.com/r/BountyFindThisEpisode/\n\n\n\n\n\n\n\n    Had a website for this in the past that is no longer up, but viaprize made \nsomething similar\n\n\n\n\n\n\n\n    If someone here wants to use it for broadcast or commerce's sake. DM me, and I can give you the contact info of the person responsible for the original OWN archive. Unfortunately, we could not get it because they don't distribute for \"Personal viewing.\" And even if you are big, they seem to be quite protective of this episode in particular.\n  \n\n    We have communicated with countless people. The journalist who first rediscovered and published the tape in 2015, multiple archivists, mindless scammers and haters that help bring energy into this, stubborn and helpful companies, Lost Media YouTubers (reluctant to make a video because of potential strike), and many more.\n  \n\n    Through the years. Traces of what was will naturally disappear. Forum posts, Reddit posts, articles, websites, comments, notes, talks, even TikToks, fade away as the ripples surrounding the question loses energy. Sometimes you have to throw another stone in the pond to make it heard again.\n  \n\n    Some say you can't erase stuff from the internet. But you can most definitely hide it. So, can you find the easter egg? Or if you have it. Well, an easy prize for you, amigo/a. Buhuu to the others.\n  \n\n    Let the \nStreisand Effect\n unfold. Hopefully, it will be found this time.\n  \n\n\nBest of luck.\n\n\n\n\nThe Discord group for anyone interested:\n \nhttps://discord.gg/JD8Je3v\n (ongoing discussions)"},
{"Title": "Apparently you CAN be banned by Lego", "Author": "u/xiyatumerica", "Content": "So, I've been downloading lego instructions every day for the past few months and usually it goes fine. The script I use has a timeout so I don't overload the server and usually it works.\n  \n\n    Pro tip: don't use \"replace all\" when editing your scripts.\n  \n\n    My working timeout is 150ms. Well, I did a replace all and that accidentally changed the timeout to 1ms (I was checking I/O on my drives).\n  \n\n    It ran fine for about an hour and then I started receiving a 403 error. Apparently Lego thought I was trying to DDOS the instructions site and ip blocked me. Interestingly, shop.lego.com still worked.\n  \n\n    I was blocked over the weekend, but on Monday I was able to download again. So now I can safely download lego instructions.\n  \n\n    TLDR; Accidentally changed the timeout from 150ms to 1ms in my script which attempted to DDOS Lego's servers"},
{"Title": "YouTube Vanced has been discontinued", "Author": "u/FamousM1", "Content": "No content"},
{"Title": "Adobe Uses DMCA to Nuke Project That Keeps Flash Alive, Secure & Adware Free", "Author": "u/retrac1324", "Content": "No content"},
{"Title": "I thought this sub would appreciate this", "Author": "u/Needleroozer", "Content": "No content"},
{"Title": "Archival Suggestion - Rooster Teeth/affiliated videos", "Author": "u/FairLadyVivi", "Content": "hello everyone! It has been recently announced that Rooster Teeth (but not their Roost podcast network) will be being shuttered by Warner Bros. No information has been made yet about what will happen to content produced/owned/hosted by RT. In the past during some smaller video purges I know that members on this sub were working on archiving RT content, so I wanted to raise a bit more awareness that more of their content may disappear in the impending days/months, to ensure that decades of their productions don’t end up completely gone form the internet. I recall similar issues happening when Machinima shuttered and would hate to see the same with RT! :(\n  \n\n    My apologies if this isn’t quite right for the sub, as more of a call to action than explicit discussion post, but I can’t imagine I’m the only RT fan around wanting to make sure stuff doesn’t disappear. I just don’t have the setup to archive and hoard it all!"},
{"Title": "Obsession and anxiety in one picture.", "Author": "u/string97bean", "Content": "No content"},
{"Title": "API Clusterfuck! ~ Reddit said 'Fuck you, we don't care.' so here's where we stand.", "Author": "u/-Archivist", "Content": "Here's the bottom line....\n\n\n\n\n\n    Reddit exists to serve you ads, farm and sell your data.\n  \n\n\n\n\n\n    Reddit doesn't like or support \nyou\n data hoarding.\n  \n\n\n\n\n\n    Reddit only cares if you're making them money.\n  \n\n\n\n\n\n    Reddit says one thing and does another.\n  \n\n\n\n\n\n    Reddit will strip and ban mods that aren't willing to bend over.\n  \n\n\n\n\n\n    We could go on, but you get the point... You have no say here, you lick the boots or fuck you.\n  \n\n    So the API is about to be shafted, many apps/bots will die, other things will change, you know what's up. But the more important thing directly related to the DataHoarding community is that Reddit has now very effectively \nkilled Pushshift\n from a data hoarding perspective which was the \nonly place\n you could get the most complete up-to-date Reddit data in bulk.\n  \n\n    Reddit has now taken control of Pushshift, had them delete bulk data downloads, prevents them releasing new dumps and limits PS API access to only mods Reddit approves of.\n  \nr/DataHoarder\n moving forward....\n\n    We will continue to exist and operate as we have for as long as Reddit allows us to. We will promote alternatives for those of you who wish leave finding DataHoarder communities elsewhere. We will promote every project, tool and download that seeks to keep Reddit data available to both DataHoarders and researchers. We will continue to hoard. We will not hit any fucking delete buttons.\n  \n\n    New rule.\n  \n\n\n\n\n\n    9. \nr/techsupport\n exists.\n  \n\n\n\n\n\n    We see a lot of basic vaguely dh related tech support questions here, we're going to be more actively removing these posts. Many of these also clearly break rule 1 as they're asked every other week.\n  \n\n    Sidebar updates.\n  \n\n\n\n\n\n\nHistoric Reddit Archives & Download Tools, Etc.\n\n\n\n\n\n\n\n\n#datahoarders @ The-Eye Discord\n (tag a helper, #support exists also)\n  \n\n\n\n\n\n\nc/datahoarder @ lemmy.ml\n (experimental, we we're invited there)\n  \n\n\n\n\n\n\nr/DataHorader 2013-2023 Searchable Archives\n\n\n\n\n\n\n\n    Happy Hoarding."},
{"Title": "Google Photos Removing Unlimited Storage Option", "Author": "u/ThisAsYou", "Content": "No content"},
{"Title": "My off-site backup solution is finally coming to life thanks to the knowledge I got here", "Author": "u/olivercer", "Content": "No content"},
{"Title": "my rarbg magnet backup (268k)", "Author": "u/trilionaire07", "Content": "hey guys, i've been working on a rarbg scraping project for a few weeks now and i humbly offer the incompleted result of my labors. i think i have almost every show, but i have zero movies that aren't rarbg.\n  \n\n\nhttps://github.com/2004content/rarbg/\n\n\n\n    edit: i'm trying to focus on this one. \nhttps://www.reddit.com/r/Piracy/comments/13wn554/my_rarbg_magnet_backup_268k/"},
{"Title": "Perfect example of why I hoard", "Author": "u/nickdrones", "Content": "No content"},
{"Title": "Dang it... barely bumped it. [Gore]", "Author": "u/Mahcks", "Content": "No content"},
{"Title": "RIP Samsung spinning rust. 12 of them, 12 years old, not a single bad sector and being retired to free up bays.", "Author": "u/cantanko", "Content": "No content"},
{"Title": "Michaels has a \"Photo and Craft Keeper\" box on sale for $12.59 that's the perfect size for HDDs", "Author": "u/Kontakr", "Content": "No content"},
{"Title": "Shoutout to the University of Waterloo, for hosting 40TB of literal Linux ISOs", "Author": "u/thismustbetemporary", "Content": "Got a chuckle out of that. I discovered that the University of Waterloo is one of the few mirrors in Canada for Linux packages of various distros, and found their cool page showing all the content they're hosting. \nhttp://mirror.csclub.uwaterloo.ca/\n\n\n\n    I wish I could add my server onto Linux mirror lists like these, but it's nowhere near stable enough. Would do more harm than good for my server to be on that list.\n  \n\n    Thanks to the CS club for doing important work!!"},
{"Title": "Studio Ghibli releases 400 images from eight movies free to download online", "Author": "u/hinghenry", "Content": "No content"},
{"Title": "was not aware google scans all your private files for hate speech violations... Is this true and does this apply to all of google one storage?", "Author": "u/cooqieslayer", "Content": "No content"},
{"Title": "40-year-old Data Hoarder is suing his parents after they threw out his cherished $29,000 porn collection", "Author": "u/therourke", "Content": "No content"},
{"Title": "Got about all of these for 50$ (Roughy 40tb in differnet sizes)", "Author": "Unknown author", "Content": "No content"},
{"Title": "PSA: The US copyright Office is taking public comments on automated copyright filters till TONIGHT, and The Senate Judiciary Committee is considering the EARN-IT act THIS WEEK, which would create liability for user created content, and encourage/force file scanning-Encryption bans. Take action!", "Author": "u/jabberwockxeno", "Content": "This isn't strictly Datahoarding related, but obviously automated copyright filters lead to lost data and online content, and anything like the EARN-IT act which increases liability for user created content will lead to sites shutting down and lost content as well. I have cleared this with the Mod team.\n  \n\n\n\n\n\n    As stated, the US copyright office is taking information, feedback, and input on automated filters and detection systems on Copyright infringement, likely to suggest and support the proliferation of those systems. It will be holding a session on February 22nd, followed by consultation with industry groups. However,** it is also taking comments and input from the general public up till 11:59PM EST on February 8th (TODAY), with a online form, and is explicitly also open to hearing the downsides of such systems.**\n  \n\n\n\n\n\n    More information as well as links to the comment form (direct link \nhere\n can be found here: \nhttps://www.eff.org/deeplinks/2022/02/tell-copyright-office-who-really-affected-filters\n. If you're not sure what exactly to write or aren't familar with how much of a trashfire these filters tend to be, [this[() article is a good starting overview, also from the EFF, and I have compiled some other examples \nhere\n.\n  \n\n\n\n\n\n    The EARN-IT act is also being considered. Remember FOSTA-SESTA from a few years back, the legislation that was osteinbly to go after sex trafficking but really just led to dozens of major websites to shut down their legal adult content and actually made it harder for law enforcement, by their own subsequent admission, to go after actual abusers and traffickers; and which was decried by basically every Digital civil liberty and sex worker group? This is that but worse. It will remove Section 230 protection for wide swathes of websites tangentially connected to adult material, opening it up to liability over user created content, as well as creates liability for using encryption and \"advises\" websites to scan all uploaded content.\n  \n\n\n\n\n\n    More info can be found firstly here: \nhttps://www.eff.org/deeplinks/2022/02/its-back-senators-want-earn-it-bill-scan-all-online-messages\n and secondly here: \nhttps://www.techdirt.com/articles/20220203/18143448411/how-earn-it-act-is-significantly-more-dangerous-than-fosta.shtml\n and thirdly here:\nhttp://cyberlaw.stanford.edu/blog/2022/02/earn-it-act-back-and-it%E2%80%99s-more-dangerous-ever\n\n\n\n    The EFF links I have provided include and link to tools to actually leave comments for the former, and contact your representatives in the Senate for the latter. If you aren't a US citizen, I encourage you to spread the word to those who are, and I technically don't see anything requiring you're a citizen for the Copyright Office form if you pick \"Anonymous\"\n  \n\n\nIf you're seeing this on the 9th or later, it is too late to comment on the Copyright Office stuff\n (timezone shenngians aside)  \nbut there IS still time to contact your senators about EARN IT!\n EDIT: EARN-IT is allegedly going up for vote on Thursday, the 10th, though this can change, so please still contact your represenatives!\n  \n\n    Please also follow the EFF and Fight for the Future, both regularly do advocacy and legal lobbying \nfor\n digital rights and online privacy and against copyright maximalist (I am not affilated with either group, I am just a nerd who cares about this stuff way too much and both have consistently been the sources to follow for this sort of stuff)"},
{"Title": "GitHub Archive in Svalbard", "Author": "u/FreneticFrench", "Content": "No content"},
{"Title": "I thought you guys would appreciate my messy, 10x DVD ripping machine I made out of an old DVD duplicator!", "Author": "u/pairofcrocs", "Content": "No content"},
{"Title": "Well, I’m no mathematician but I think I’ll go with the 14TB. Best Buy Canada", "Author": "u/animatedhockeyfan", "Content": "No content"},
{"Title": "52% of YouTube videos live in 2010 have been deleted", "Author": "u/themadprogramer", "Content": "No content"},
{"Title": "BOUNTY: $10 000USD. Remember me? Yes, I still have not found it. Please help me find the Whole videotape of Donald Trump on The Oprah Winfrey Show, 25th of April, 1988. Season 3, Episode 5 (a 60 min. episode with a few ads).", "Author": "u/trycoconutoil", "Content": "The Discord group for anyone interested:\n \nhttps://discord.gg/JD8Je3v\n \n(ongoing discussions)\n\n\n\n    Saw this tape on Facebook back in 2015. Then, it vanished. I have been searching on and off since then.\n  \n\n\nOFFICIAL BOUNTY\n: $1000USD\n\n\n\n\nTRANSCRIPTS: $1000USD\nMust be a copy of the original Journal Graphics transcript (Harpo productions bought their inventory)\n  \n\n\nSources that are relevant for the investigation:\n\n\n\n\n\n\n\n\nhttps://thetvdb.com/series/the-oprah-winfrey-show/episodes/6650339\n (air date)\n  \n\n\n\n\n\n    Michael Cohen (trumps former lawyer) talked about the \"Catch and Kill\" method that they utilized several times. This is most likely why it's difficult (not impossible) to find the tape. Explained in short at 1:37:35 \nhttps://www.youtube.com/watch?v=v0e62bOKm8o&t=5855s&ab_channel=TheNewYorkTimes\n- \"[Cohen] was often described by the media as Trump's 'fixer'.\" - \nWiki\n\n\n\n\n\n\n\n\n3 min. \npart from the original video\n (there are more short videos out there and almost the full video in the discord group. unfortunately, the broadcasting got interrupted for about 10 min. about half a year after the original tape). NOTE! the video is no longer up but can be put up again if requested.\n  \n\n\n\n\n\n\nhttps://www.reddit.com/r/politicalfactchecking/comments/4nt6iw/donald_trump_republicans_are_dumb_why_did_this/\n (Frustrated Redditors)\n  \n\n\n\n\n\n\nhttps://www.youtube.com/watch?v=AZtfSIgsH1o\n (some YouTube video that may not be important, but the comments on it are very relevant)\n  \n\n\n\n\n\n\nhttp://www.oprah.com/own-oprahshow/what-donald-trump-told-oprah-about-his-presidential-hopes-video\n (an old link that might have shown the full episode in the past)\n  \n\n\n\n\n\n\ninteresting article\n (Interesting article on the disappearance of the video.)\n  \n\n\n\n\n\n\nAnother Reddit post by someone else asking for the same episode.\n\n\n\n\n\n\n\n\nA Reddit post about the missing episode and what OP of this post thinks about it\n.\n  \n\n\n\n\n\n    I guess this TikToker deleted her account \nbut found a tweet about her talking about it.\n (had over 1 million views).\n  \n\n\n\n\n\n\nAn old website and      its resource page image\n\n\n\n\n\n\n\n    I will give the person who can find it and send it to me $10 000USD (if you want). I'll give it through cryptocurrency, anonymous PayPal system, product(s), or other means. Several Redditors also support the bounty. That will also be included if they stick to their guns.\n  \n\n\n\n\nNOTE!\n\n\n\n    Ignore the images and fact-checker sites. \nThose are red herrings\n and so point towards something different from the year 1998. I want the entire video from \nThe Oprah Winfrey Show, 25th of April, 1988, season 3, Episode 5, 60 minutes of the show.\n DM me here on Reddit or post it publically. No short vids or re-recordings that include interruptions. Simple. All of it. The show used to be quite popular; the entire content should be out there, internet, or stored.\n  \n\n\n\n\n**Since some ask. Why do I want it?**\n\n\n\n    I want it cause it has been suppressed and repressed on the internet, and various sites and people tell me what I saw and heard didn't happen, and it bothers me. And have found this exploration quite intriguing. I do not have any political intentions; I want the truth, sweetheart, for truth's sake.\n  \n\n\nGreat References:\n\n\n\n\n\n\n\n\n$1310 bounty post from last year\n (the second post)\n  \n\n\n\n\n\n\n$300 bounty post from last year\n (the first post)\n  \n\n\n\n\n\n    Subreddit for this: \nhttps://www.reddit.com/r/BountyFindThisEpisode/\n\n\n\n\n\n\n\n    Had a website for this in the past that is no longer up, but viaprize made \nsomething similar\n\n\n\n\n\n\n\n    If someone here wants to use it for broadcast or commerce's sake. DM me, and I can give you the contact info of the person responsible for the original OWN archive. Unfortunately, we could not get it because they don't distribute for \"Personal viewing.\" And even if you are big, they seem to be quite protective of this episode in particular.\n  \n\n    We have communicated with countless people. The journalist who first rediscovered and published the tape in 2015, multiple archivists, mindless scammers and haters that help bring energy into this, stubborn and helpful companies, Lost Media YouTubers (reluctant to make a video because of potential strike), and many more.\n  \n\n    Through the years. Traces of what was will naturally disappear. Forum posts, Reddit posts, articles, websites, comments, notes, talks, even TikToks, fade away as the ripples surrounding the question loses energy. Sometimes you have to throw another stone in the pond to make it heard again.\n  \n\n    Some say you can't erase stuff from the internet. But you can most definitely hide it. So, can you find the easter egg? Or if you have it. Well, an easy prize for you, amigo/a. Buhuu to the others.\n  \n\n    Let the \nStreisand Effect\n unfold. Hopefully, it will be found this time.\n  \n\n\nBest of luck.\n\n\n\n\nThe Discord group for anyone interested:\n \nhttps://discord.gg/JD8Je3v\n (ongoing discussions)"},
{"Title": "Apparently you CAN be banned by Lego", "Author": "u/xiyatumerica", "Content": "So, I've been downloading lego instructions every day for the past few months and usually it goes fine. The script I use has a timeout so I don't overload the server and usually it works.\n  \n\n    Pro tip: don't use \"replace all\" when editing your scripts.\n  \n\n    My working timeout is 150ms. Well, I did a replace all and that accidentally changed the timeout to 1ms (I was checking I/O on my drives).\n  \n\n    It ran fine for about an hour and then I started receiving a 403 error. Apparently Lego thought I was trying to DDOS the instructions site and ip blocked me. Interestingly, shop.lego.com still worked.\n  \n\n    I was blocked over the weekend, but on Monday I was able to download again. So now I can safely download lego instructions.\n  \n\n    TLDR; Accidentally changed the timeout from 150ms to 1ms in my script which attempted to DDOS Lego's servers"},
{"Title": "YouTube Vanced has been discontinued", "Author": "u/FamousM1", "Content": "No content"},
{"Title": "Adobe Uses DMCA to Nuke Project That Keeps Flash Alive, Secure & Adware Free", "Author": "u/retrac1324", "Content": "No content"},
{"Title": "I thought this sub would appreciate this", "Author": "u/Needleroozer", "Content": "No content"},
{"Title": "Archival Suggestion - Rooster Teeth/affiliated videos", "Author": "u/FairLadyVivi", "Content": "hello everyone! It has been recently announced that Rooster Teeth (but not their Roost podcast network) will be being shuttered by Warner Bros. No information has been made yet about what will happen to content produced/owned/hosted by RT. In the past during some smaller video purges I know that members on this sub were working on archiving RT content, so I wanted to raise a bit more awareness that more of their content may disappear in the impending days/months, to ensure that decades of their productions don’t end up completely gone form the internet. I recall similar issues happening when Machinima shuttered and would hate to see the same with RT! :(\n  \n\n    My apologies if this isn’t quite right for the sub, as more of a call to action than explicit discussion post, but I can’t imagine I’m the only RT fan around wanting to make sure stuff doesn’t disappear. I just don’t have the setup to archive and hoard it all!"},
{"Title": "Obsession and anxiety in one picture.", "Author": "u/string97bean", "Content": "No content"},
{"Title": "API Clusterfuck! ~ Reddit said 'Fuck you, we don't care.' so here's where we stand.", "Author": "u/-Archivist", "Content": "Here's the bottom line....\n\n\n\n\n\n    Reddit exists to serve you ads, farm and sell your data.\n  \n\n\n\n\n\n    Reddit doesn't like or support \nyou\n data hoarding.\n  \n\n\n\n\n\n    Reddit only cares if you're making them money.\n  \n\n\n\n\n\n    Reddit says one thing and does another.\n  \n\n\n\n\n\n    Reddit will strip and ban mods that aren't willing to bend over.\n  \n\n\n\n\n\n    We could go on, but you get the point... You have no say here, you lick the boots or fuck you.\n  \n\n    So the API is about to be shafted, many apps/bots will die, other things will change, you know what's up. But the more important thing directly related to the DataHoarding community is that Reddit has now very effectively \nkilled Pushshift\n from a data hoarding perspective which was the \nonly place\n you could get the most complete up-to-date Reddit data in bulk.\n  \n\n    Reddit has now taken control of Pushshift, had them delete bulk data downloads, prevents them releasing new dumps and limits PS API access to only mods Reddit approves of.\n  \nr/DataHoarder\n moving forward....\n\n    We will continue to exist and operate as we have for as long as Reddit allows us to. We will promote alternatives for those of you who wish leave finding DataHoarder communities elsewhere. We will promote every project, tool and download that seeks to keep Reddit data available to both DataHoarders and researchers. We will continue to hoard. We will not hit any fucking delete buttons.\n  \n\n    New rule.\n  \n\n\n\n\n\n    9. \nr/techsupport\n exists.\n  \n\n\n\n\n\n    We see a lot of basic vaguely dh related tech support questions here, we're going to be more actively removing these posts. Many of these also clearly break rule 1 as they're asked every other week.\n  \n\n    Sidebar updates.\n  \n\n\n\n\n\n\nHistoric Reddit Archives & Download Tools, Etc.\n\n\n\n\n\n\n\n\n#datahoarders @ The-Eye Discord\n (tag a helper, #support exists also)\n  \n\n\n\n\n\n\nc/datahoarder @ lemmy.ml\n (experimental, we we're invited there)\n  \n\n\n\n\n\n\nr/DataHorader 2013-2023 Searchable Archives\n\n\n\n\n\n\n\n    Happy Hoarding."},
{"Title": "Google Photos Removing Unlimited Storage Option", "Author": "u/ThisAsYou", "Content": "No content"},
{"Title": "My off-site backup solution is finally coming to life thanks to the knowledge I got here", "Author": "u/olivercer", "Content": "No content"},
{"Title": "my rarbg magnet backup (268k)", "Author": "u/trilionaire07", "Content": "hey guys, i've been working on a rarbg scraping project for a few weeks now and i humbly offer the incompleted result of my labors. i think i have almost every show, but i have zero movies that aren't rarbg.\n  \n\n\nhttps://github.com/2004content/rarbg/\n\n\n\n    edit: i'm trying to focus on this one. \nhttps://www.reddit.com/r/Piracy/comments/13wn554/my_rarbg_magnet_backup_268k/"},
{"Title": "Perfect example of why I hoard", "Author": "u/nickdrones", "Content": "No content"},
{"Title": "Dang it... barely bumped it. [Gore]", "Author": "u/Mahcks", "Content": "No content"},
{"Title": "RIP Samsung spinning rust. 12 of them, 12 years old, not a single bad sector and being retired to free up bays.", "Author": "u/cantanko", "Content": "No content"},
{"Title": "Michaels has a \"Photo and Craft Keeper\" box on sale for $12.59 that's the perfect size for HDDs", "Author": "u/Kontakr", "Content": "No content"},
{"Title": "Shoutout to the University of Waterloo, for hosting 40TB of literal Linux ISOs", "Author": "u/thismustbetemporary", "Content": "Got a chuckle out of that. I discovered that the University of Waterloo is one of the few mirrors in Canada for Linux packages of various distros, and found their cool page showing all the content they're hosting. \nhttp://mirror.csclub.uwaterloo.ca/\n\n\n\n    I wish I could add my server onto Linux mirror lists like these, but it's nowhere near stable enough. Would do more harm than good for my server to be on that list.\n  \n\n    Thanks to the CS club for doing important work!!"},
{"Title": "Studio Ghibli releases 400 images from eight movies free to download online", "Author": "u/hinghenry", "Content": "No content"},
{"Title": "was not aware google scans all your private files for hate speech violations... Is this true and does this apply to all of google one storage?", "Author": "u/cooqieslayer", "Content": "No content"},
{"Title": "40-year-old Data Hoarder is suing his parents after they threw out his cherished $29,000 porn collection", "Author": "u/therourke", "Content": "No content"},
{"Title": "Got about all of these for 50$ (Roughy 40tb in differnet sizes)", "Author": "Unknown author", "Content": "No content"},
{"Title": "Had to add a second sata card and upgrade to a 1600 watt power supply because spinning up 17 drives was too much for my poor 900 watt...", "Author": "u/timekillerjay", "Content": "No content"},
{"Title": "Lana Del Rey says laptop containing her new album was stolen. This is why you back up your data people…", "Author": "Unknown author", "Content": "No content"},
{"Title": "Thought you guys would enjoy, this is a 20TB ssd we are building at work. All in a 2.5\" formfactor. There's so many NAND chips that we have to make a pcb that folds in half.", "Author": "u/isonotlikethat", "Content": "No content"},
{"Title": "Is $92 per lb a good price?", "Author": "u/FragileRasputin", "Content": "No content"},
{"Title": "Protect yourselves out there - NEW Drive from Amazon with 15257 Power On Hours", "Author": "u/TheWoodser", "Content": "No content"},
{"Title": "Data hoarding also means having bigger hard drives, right?", "Author": "u/VulturE", "Content": "No content"},
{"Title": "I did the math, realized that this 200 Disc CD player I got for the office can only store 130GB of audio, and I'm sad now.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Which of you fucker's did this.", "Author": "u/linuxcommunist", "Content": "No content"},
{"Title": "Inventor of cassette tape Lou Ottens passes away at 94", "Author": "u/themadprogramer", "Content": "No content"},
{"Title": "100TB! Just got to 100tb of storage on my server!", "Author": "u/mbailey5", "Content": "No content"},
{"Title": "Saying goodbye to a few fallen soldiers", "Author": "u/djlspider", "Content": "No content"},
{"Title": "Was ticketing clearance items at work and this was down to $14AUD. Snagged it instantly - perks of the job!", "Author": "u/StackProne", "Content": "No content"},
{"Title": "Your content belongs to you, not Reddit: A thread.", "Author": "u/themadprogramer", "Content": "Welcome to the \nPost-API\n dystopia! So unless you have been living under a rock, Reddit has decided to begin pay-tiering its API following the footsteps of Facebook, Google and very recently Twitter. And people are \nMAD\n!\n  \n\n    Given that here at Reddit we are a more tech-competent audience, protest has been very \ninteresting\n. We have seen Subreddit black-outs, user mass-deletions.. I think the funniest suggestion I heard came from \nu/IkePAnderson\n who suggested overwriting posts with gibberish instead.\n  \n\n    Except there's a problem: I think this general attitude will not only fail to bring change, it will give the company exactly what it wants. I mean, is there any form of dissent better than self-destruction? All the complaints being filed and the rage and vitriol are cleaning after themselves. Once the new pay-tiers come into effect, the evidence of people not welcoming the change will vanish as has already happened in the case of Facebook and Twitter whose API changes failed to attract much attention from the press.\n  \n\n    Reddit, for better or worse, is a company that derives its revenue from band-waggoning trends. The top subreddits on this site include \nr/funny\n , \nr/AskReddit\n , \nr/worldnews\n ; things that capture the here and now and are not so much concerned with posteriority. Might I remind you that just until a few months ago, threads older than 6 months would be locked not allowing further edits or comments. Reddit's revenue stream does not benefit from retaining history beyond a certain point and is only retained as a gesture for brand-loyalty. So if everyone who now despises Reddit removes their history, that's okay, those who are indifferent will get to keep the same benefits and it won't cost Reddit any more or less.\n  \n\n    I'm saying all of this to make a point that mass-deletion only hurts individuals. It hurts you, it hurts me; it hurts the dissent towards Reddit because the community becomes invisible.. Your content is yours. It's not property of Reddit. And therefore, if you so wish, you can move it to another platform. As a dissenter of the API overhaul, I think it is in our interest to do so.\n  \n\n    The fact that our content is portable in this way is a thing that scares companies, because it is dangerous. Just look at YouTube and Twitch to see how they force their big streamers into exclusivity contracts. I might be \nu/themadprogramer\n on Reddit, and my words might be attributed to that name. But I can also exist as @madpro on other platforms; whether on YouTube or Discord, or something fediversy like Mastodon or Pleroma.\n  \n\n    So I believe the best way we can petition our redress is not through mass-deletion, but rather mass-action. You're a data hoarder, just download a bulk of your comments and post to a blog. If you're not camera shy record yourself talking about the API changes and why you left Reddit and put it on YouTube or TikTok. Do you want to know the best part? Reddit can't do anything about it, even the skeptics who have suggested the possibility of the company to revert changes must concede that the company cannot suppress what is happening outside of their platform.\n  \n\n    If nothing else, I just think it's good practice to cross-post because redundancy means retention. Every one of us has a personal history and that is \npersonal\n not \nRedditorial\n. That personal history is split across mediums, as it should be, because we move in the world. Reddit is merely the context, it is neither the object nor subject.\n  \n\n    The best form of protest \ncan only be\n reclaiming our content instead of destroying it!"},
{"Title": "Spent hours prying these out... RIP fingernails but worth it for 128T's", "Author": "u/igob8a", "Content": "No content"},
{"Title": "How book publishers are trying to turn the age-old library system into a “reading as a service” through their lawsuit against The Internet Archive", "Author": "u/retrac1324", "Content": "No content"},
{"Title": "The end of an era. The last of 12 drive set of Dooms. Memes aside. Only 3 of the 16 Doom drives I originally purchased (heavily reduced price) actually died prematurely. Lab inspector is verifying the results.", "Author": "Unknown author", "Content": "No content"},
{"Title": "Had to add a second sata card and upgrade to a 1600 watt power supply because spinning up 17 drives was too much for my poor 900 watt...", "Author": "u/timekillerjay", "Content": "No content"},
{"Title": "Lana Del Rey says laptop containing her new album was stolen. This is why you back up your data people…", "Author": "Unknown author", "Content": "No content"},
{"Title": "Thought you guys would enjoy, this is a 20TB ssd we are building at work. All in a 2.5\" formfactor. There's so many NAND chips that we have to make a pcb that folds in half.", "Author": "u/isonotlikethat", "Content": "No content"},
{"Title": "Is $92 per lb a good price?", "Author": "u/FragileRasputin", "Content": "No content"},
{"Title": "Protect yourselves out there - NEW Drive from Amazon with 15257 Power On Hours", "Author": "u/TheWoodser", "Content": "No content"},
{"Title": "Data hoarding also means having bigger hard drives, right?", "Author": "u/VulturE", "Content": "No content"},
{"Title": "I did the math, realized that this 200 Disc CD player I got for the office can only store 130GB of audio, and I'm sad now.", "Author": "u/AshleyUncia", "Content": "No content"},
{"Title": "Which of you fucker's did this.", "Author": "u/linuxcommunist", "Content": "No content"},
{"Title": "Inventor of cassette tape Lou Ottens passes away at 94", "Author": "u/themadprogramer", "Content": "No content"},
{"Title": "100TB! Just got to 100tb of storage on my server!", "Author": "u/mbailey5", "Content": "No content"},
{"Title": "Saying goodbye to a few fallen soldiers", "Author": "u/djlspider", "Content": "No content"},
{"Title": "Was ticketing clearance items at work and this was down to $14AUD. Snagged it instantly - perks of the job!", "Author": "u/StackProne", "Content": "No content"},
{"Title": "Your content belongs to you, not Reddit: A thread.", "Author": "u/themadprogramer", "Content": "Welcome to the \nPost-API\n dystopia! So unless you have been living under a rock, Reddit has decided to begin pay-tiering its API following the footsteps of Facebook, Google and very recently Twitter. And people are \nMAD\n!\n  \n\n    Given that here at Reddit we are a more tech-competent audience, protest has been very \ninteresting\n. We have seen Subreddit black-outs, user mass-deletions.. I think the funniest suggestion I heard came from \nu/IkePAnderson\n who suggested overwriting posts with gibberish instead.\n  \n\n    Except there's a problem: I think this general attitude will not only fail to bring change, it will give the company exactly what it wants. I mean, is there any form of dissent better than self-destruction? All the complaints being filed and the rage and vitriol are cleaning after themselves. Once the new pay-tiers come into effect, the evidence of people not welcoming the change will vanish as has already happened in the case of Facebook and Twitter whose API changes failed to attract much attention from the press.\n  \n\n    Reddit, for better or worse, is a company that derives its revenue from band-waggoning trends. The top subreddits on this site include \nr/funny\n , \nr/AskReddit\n , \nr/worldnews\n ; things that capture the here and now and are not so much concerned with posteriority. Might I remind you that just until a few months ago, threads older than 6 months would be locked not allowing further edits or comments. Reddit's revenue stream does not benefit from retaining history beyond a certain point and is only retained as a gesture for brand-loyalty. So if everyone who now despises Reddit removes their history, that's okay, those who are indifferent will get to keep the same benefits and it won't cost Reddit any more or less.\n  \n\n    I'm saying all of this to make a point that mass-deletion only hurts individuals. It hurts you, it hurts me; it hurts the dissent towards Reddit because the community becomes invisible.. Your content is yours. It's not property of Reddit. And therefore, if you so wish, you can move it to another platform. As a dissenter of the API overhaul, I think it is in our interest to do so.\n  \n\n    The fact that our content is portable in this way is a thing that scares companies, because it is dangerous. Just look at YouTube and Twitch to see how they force their big streamers into exclusivity contracts. I might be \nu/themadprogramer\n on Reddit, and my words might be attributed to that name. But I can also exist as @madpro on other platforms; whether on YouTube or Discord, or something fediversy like Mastodon or Pleroma.\n  \n\n    So I believe the best way we can petition our redress is not through mass-deletion, but rather mass-action. You're a data hoarder, just download a bulk of your comments and post to a blog. If you're not camera shy record yourself talking about the API changes and why you left Reddit and put it on YouTube or TikTok. Do you want to know the best part? Reddit can't do anything about it, even the skeptics who have suggested the possibility of the company to revert changes must concede that the company cannot suppress what is happening outside of their platform.\n  \n\n    If nothing else, I just think it's good practice to cross-post because redundancy means retention. Every one of us has a personal history and that is \npersonal\n not \nRedditorial\n. That personal history is split across mediums, as it should be, because we move in the world. Reddit is merely the context, it is neither the object nor subject.\n  \n\n    The best form of protest \ncan only be\n reclaiming our content instead of destroying it!"},
{"Title": "Spent hours prying these out... RIP fingernails but worth it for 128T's", "Author": "u/igob8a", "Content": "No content"},
{"Title": "How book publishers are trying to turn the age-old library system into a “reading as a service” through their lawsuit against The Internet Archive", "Author": "u/retrac1324", "Content": "No content"},
{"Title": "The end of an era. The last of 12 drive set of Dooms. Memes aside. Only 3 of the 16 Doom drives I originally purchased (heavily reduced price) actually died prematurely. Lab inspector is verifying the results.", "Author": "Unknown author", "Content": "No content"}
]