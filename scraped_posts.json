[
{"Title": "Sunday Daily Thread: What's everyone working on this week?", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "Friday Daily Thread: r/Python Meta and Free-Talk Fridays", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "I made a little Python quiz for interns and new Python developers at my company", "Author": "u/Penny-loafers", "Content": "I put this quiz together to help create conversation for interns and new python developers at my company. Its based on the content from one of my favourite books (\nFluent Python\n). I hope you enjoy it!\n  \n\n\nQuiz"},
{"Title": "Open source Python projects with good software design that is worth studying", "Author": "u/bolt_runner", "Content": "What are some software projects written in python that are well-structured and use good code design practices that are worth spending time to study?"},
{"Title": "Log Monitoring with Kafka ETL using Python via Docker and Pathway", "Author": "u/muditjps", "Content": "Hi \nr/Python\n,\n  \n\n    This project is for a Streaming ETL problem statement for Fraud-detection/Log Monitoring use-case.\n  \n\n\n\n\n\n    Here's a link to the blog explainer: \nhttps://pathway.com/developers/templates/kafka-etl\n\n\n\n\n\n\n\n    GitHub Repo link:¬†\nhttps://github.com/pathwaycom/pathway/tree/main/examples/projects/kafka-ETL\n\n\n\n\n\n\nWhat the Project Does\n\n    Let's say we're monitoring logs from servers in New York and Paris. The logs have different time zones so you need to unify these different time zones into a single format to maintain data integrity. Now, Kafka is a popular ETL tool but it's usable only in Java/Scala.\n  \nTarget Audience\n\n    This is mostly for Python developers/data scientists/ML engineers and people who work on Fraud Detection or ETL.\n  \nComparison\n\n    This project leverages Pathway, a Python ETL framework powered by an underlying Rust engine that surpasses Flink/Kafka in benchmarks. With this Pythonic framework we:\n  \n\n\n\n\n\n    Extract data streams from Kafka using built-in Kafka input connectors.\n  \n\n\n\n\n\n    Convert times with varying time zones into unified timestamps the datetime module.\n  \n\n\n\n\n\n    Load the final data stream back into Kafka.\n  \n\n\n\n\n\n    The entire script is available as an app template on the repo, which can be run via Docker in minutes. Open to your feedback/questions!"},
{"Title": "Eventum: Flexible event generator", "Author": "u/rnv812", "Content": "Hi, recently I created event generator in Python called \nEventum\n.\n  \n\n    Here is a link to website: \nhttps://eventum-generatives.github.io/Website/\n\n\n\n    And the main repo: \nhttps://github.com/Eventum-Generatives/EventumCore\n\n\nWhat My Project Does\n\n    It can be used in task like:\n  \n\n\n\n\n\n    Generation of datasets\n  \n\n\n\n\n\n    Simulation of processes in real time\n  \n\n\n\n\n\n    Filling different systems with demo data\n  \n\n\n\n\n\n    Testing on arbitrary data and stress testing\n  \n\n\n\n\nTarget Audience\n\n    This generating tool is mostly for developers and people who work with data. It is also very near to \nELK\n stack, \nOpenSearch\n and SIEM systems like \nSplunk\n. But you can use it as you want :)\n  \nComparison\n\n    There is a project \nEventgen\n developed by Splunk, but Eventum has next advantages over it:\n  \n\n\n\n\n\n    More rich events scheduling\n  \n\n\n\n\n\n    Extended functionality in event templates\n  \n\n\n\n\n\n    More parametrizable configurations\n  \n\n\n\n\n\n    Has content developing tools (UI for visualization time distributions and rendering templates)"},
{"Title": "Python community in Amsterdam, The Netherlands", "Author": "u/FuturesBrightDavid", "Content": "Hi, I'm trying to find a Python community in Amsterdam in The Netherlands.  There used to be an active \nMeetUp group\n and \nSlack\n, but there has been little to no activity on either in a long, long time.\n  \n\n    Pythonistas in my city, what social / networking events or activities are there around here?"},
{"Title": "Robogram - Minimal Wrapper for Telegram Bot API in Python", "Author": "u/RitvikTheGod", "Content": "Guys, I recently released my first (in a while) open-source project wrapper on \nTelegram Bot API\n.\n  \n\n    I call it \nrobogram\n and when I was developing in Python, I had a use case to send notifications from Raspberry Pi to my iPhone via \nTelegram\n. After searching online, I found no minimalist wrapper in Python 3+ to send messages via Bot API.\n  \n\n    So, I decided to create one :-)\n  \nWhat My Project Does\n\n    Minimal Wrapper around the Telegram Bot API. It's only dependency is \nrequests\n  in Python which is ubiquitous. It allows to retrieve info on Bot, or to send messages to users via personal chat, channel, or group.\n  \nTarget Audience¬†\n\n    Toy project I just came up with, after realizing no solution out there was best fit for me. But I have deployed this on production for personal project, and it's for sure production-ready.\n  \n\n    Target audience here would be other developers who are on Telegram and looking to leverage Bot API to facilitate the sending of messages or notifications to an audience on Telegram.\n  \nComparison\n\n    Some packages out there are only async support, or only work on Python 2 (actually I found one with some popularity that doesn't work in Python 3+ at all), or are dependency- or code- heavy and can introduce code bloat, especially to small, personal projects.\n  \n\n    As someone working on a personal project myself, I wanted a lightweight solution that only used minimal dependencies such as \nrequests\n for making API requests. So, since I could not find one out there in wild, I decided to create my own!\n  \n\n    --\n  \n\n    Interested to get your thoughts, if anyone likes it I will be glad to feedback.\n  \n\n\nhttps://github.com/rnag/robogram"},
{"Title": "localslackirc - bridge slack and IRC", "Author": "u/sonobanana33", "Content": "I made a minor bugfix release of localslackirc\n  \n\n\nhttps://codeberg.org/ltworf/localslackirc\n\n\n\n    It can be installed via apt or ran from sources. No pypi package, sorry.\n  \nWhat My Project Does\n\n    After configuring it with a token from slack, it creates a local IRC server that bridges with slack.\n  \n\n    It supports threads, sending files. It doesn't support reactions.\n  \n\n    It supports muting @here notifications from certain users or certain channels.\n  \n\n    It allows to silently leave a channel, but rejoins it if the user is personally mentioned there.\n  \nTarget Audience\n\n    Mostly people who have to use slack for work and would prefer IRC.\n  \nComparison\n\n    I am not aware of a project doing the same thing. I know weechat has a slack plugin, but that's slightly different. I don't use weechat and I wanted to keep using my IRC client.\n  \n\n    out of date link to avoid the post from being removed: \nhttps://github.com/ltworf/localslackirc"},
{"Title": "Should all Python projects have type hinting?", "Author": "u/Ok-Frosting7364", "Content": "I recently released a \nvery simple API wrapper\n and in my efforts to become a better programmer I asked in a Python Discord for feedback.\n  \n\n    One bloke was very adamant I should use type hints. I understand the need/desire for type hints but this commentator basically was implying that all Python code should be written with type hints.\n  \n\n    For a simple project I didn't think it was necessary but I'm curious as to what this community thinks.\n  \n\n    How do you make the decision as to when to use type hints? Do you do it for all projects, regardless of size? What are your general thoughts?"},
{"Title": "Mirascope-Python's Alternative To Langchain", "Author": "u/Active-Fuel-49", "Content": "Mirascope is a Python library that lets you access a range of Large Language Models, but in a more straightforward and Pythonic way.\n  \n\n\nhttps://www.i-programmer.info/news/90-tools/17275-mirascope-pythons-alternative-to-langchain.html"},
{"Title": "Web scraper for protein prices", "Author": "u/Knockoutpie1", "Content": "Hey everyone, looking for some input.\n  \n\n    For work I‚Äôve worked on web scraping for prices to see if my components are adequately priced on the internet compared to competitors.\n  \n\n    I can use this for protein prices as a personal project. I have experience now with Beautiful Soup, Selenium, and Excel Power BI.\n  \n\n    What route should I go?\n  \n\n    Should I only pull pricing from Amazon? Or should I do Amazon and the manufacturer site to see which is better pricing? Ideas would be great. Should be a fun project.\n  \n\n    If I go with beautiful soup, there‚Äôs no UI and I can print all to terminal\n  \n\n    If I use selenium, I can use UC to pass anti-bot measures and also print to terminal, but it will open a browser window for each price scrape.\n  \n\n    If I use excel power BI, I‚Äôll just load data to a worksheet and pricing will update at the price of a button."},
{"Title": "Python on Cloud GPUs", "Author": "u/jrbourbeau", "Content": "Hi All,\n  \n\n    I wanted to try to speed up some Python code with a GPU recently and was pretty shocked at how difficult it is to properly set up and configure things. I have lots of experience in the PyData space, but am definitely not a cloud devops expert.\n  \n\n    So some colleagues and I wrote a decorator that automatically sets up a cloud VM, runs the decorated function, and returns the function‚Äôs result back locally to my laptop. \nHere‚Äôs an example\n that trains a PyTorch model on an NVIDIA A10 GPU on AWS.\n  \n\n    The Coiled Function API is nice because I didn‚Äôt have to build any Docker images, muck around in the AWS console, or do anything special to set up a cloud GPU. That said, there are definitely tradeoffs here. We optimized for privacy and no standing costs, so it takes ~1-2 minutes to fully spin up VMs (no warm pool of VMs waiting). We also only run on AWS/GCP/Azure so this doesn‚Äôt help with on-prem workloads.\n  \n\n    I‚Äôm definitely biased as I work at Coiled, but think this is a simple way to run Python on cloud hardware (especially for folks without a lot of cloud experience).¬†\n  \n\n    I‚Äôm curious to hear from folks here. Do you have a favorite way to run Python code on the cloud? What do you like about your current setup? For example, ergonomics, performance, something else?"},
{"Title": "Textual Serve - Serve TUIs in the browser", "Author": "u/willm", "Content": "Textual Serve (\nhttps://github.com/Textualize/textual-serve\n) is a project which serves TUIs (built with Textual) in the browser.\n  \n\n    This is self-hosted, so you don't need to rely on any external service."},
{"Title": "Python Project Management Primer", "Author": "u/Martynoas", "Content": "This article\n explores how to manage Python project environments and dependencies, as well as how to structure projects effectively."},
{"Title": "Python on ARM laptops", "Author": "u/Fun-Asparagus-837", "Content": "Hi there !\n  \n\n    I'm thinking about buying an ARM windows laptop with the new Qualcomm chips. They will replace the x86 so I was wondering : Will There be a massive risk of non-compatibility of Python packages ? I guess they are made for x86 but I don't know if it's possible to work with them with an ARM based CPU.\n  \n\n    Edit : Had a great deal on the ideapad pro 5 gen 9 so I went for it. Glad to have these incredible specs and decided to rely on x86 chip for the moment, because I wanted to avoid all the early-adoption problems"},
{"Title": "Video Quality Ranker", "Author": "u/SAV_NC", "Content": "What my project does\n\n    Ranks videos based on overall quality. Takes into account multiple metrics to determine what quality is the best.\n  \nTarget audience\n\n    Home users / Video enthusiasts\n  \nComparison\n\n    This project uses the following metrics to rank videos:\n  \n\n\n\n\n\n\nResolution\n: Higher resolution videos are preferred.\n  \n\n\n\n\n\n\nFrame Rate\n: Videos with higher frame rates are ranked higher.\n  \n\n\n\n\n\n\nBitrate\n: Higher bitrate often indicates better quality.\n  \n\n\n\n\n\n\nCodec\n: Some codecs provide better quality than others at the same bitrate.\n  \n\n\n\n\n\n    The script extracts these metrics using \nffprobe\n from the FFmpeg suite and sorts the videos accordingly. Here's how the metrics are used:\n  \n\n\n\n\n\n\nResolution\n: The script first compares the resolution (width x height) of the videos. Higher resolutions are ranked higher.\n  \n\n\n\n\n\n\nFrame Rate\n: If two videos have the same resolution, the one with the higher frame rate is ranked higher.\n  \n\n\n\n\n\n\nBitrate\n: For videos with the same resolution and frame rate, the bitrate is used to determine the quality.\n  \n\n\n\n\n\n\nCodec\n: In case of a tie in all other metrics, the codec is considered to break the tie.\n  \n\n\n\n\nAccess the Script\n\n    You can access the script on GitHub \nhere"},
{"Title": "A JIT compiler for CPython", "Author": "u/lutipri", "Content": "Brandt Bucher talks on JIT compiler for Python at CPython Core Developer Sprint. Brandt is  a member of the \nFaster CPython project\n, which is working on making the reference implementation of the language faster via a variety of techniques.\n  \n\n\nhttps://www.youtube.com/watch?v=HxSHIpEQRjs"},
{"Title": "Conway's game of life. can you find an optimization?", "Author": "u/Significant_Water_28", "Content": "little challenge for you, how fast can this be pushed in python?\n  \n\n    This function takes a numpy.ndarray / 2d numpy array, and returns the updated array. iv updated this function several times, this i the fastiest so far.\n  \n\n    numba jit dosn't like the double roll, and its faster than for loops in jit.\n  \ndef conways_game_of_life(board:numpy.ndarray):\n  n_neighbour = sum(numpy.roll(numpy.roll(board, i, 0), j, 1) for i in (-1, 0, 1) for j in (-1, 0, 1) if (i != 0 or j != 0))\n  board[(n_neighbour<2) | (n_neighbour>3)] = 0\n  board[(n_neighbour==3)] = 1\n  return board"},
{"Title": "Thursday Daily Thread: Python Careers, Courses, and Furthering Education!", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "json3pdf : Batch OCR for high quality document archiving.", "Author": "u/DrumcanSmith", "Content": "What my project does\n\n    Performs OCR on scanned Books using Microsoft Azure Document Intelligence read\n  \nTarget audience\n\n    People who are unsatisfied with traditional OCR People who want to add clear text to the original PDF and not just extract the text. People who want to archive documents at best quality.\n  \nComparasion\n\n    In my use case traditional OCR was near to useless. Tesseract was meh, Google API didn't process large files. Document Intelligence takes up to 500MB (although in practice a little less), and is possible to OCR 400-600 pages over books in batch by dividing and merging the source and results locally by only a few chunks. It doesn't provide the text in PDF form so that was my reason to start this project.\n  \n\n    Still in alpha and in separate modules and a lot of rigid coding, but it is working fine for my original task so thought maybe I'd showcase it.\n  \n\n\nhttps://github.com/DesertDoggy/json3pdf"},
{"Title": "Experimental Python Wheels for Windows on ARM64", "Author": "u/Balance-", "Content": "For anyone on a (new) Windows on Arm system, I found this great repo with Arm64 Windows wheels:\n  \n\n\n\n\n\n\nhttps://github.com/cgohlke/win_arm64-wheels\n\n\n\n\n\n\n\n\nHighlights\n\n\n\n\n\n\n\n    256 packages for Python 3.12\n  \n\n\n\n\n\n    Built with numpy 2 if possible\n  \n\n\n\n\n\n    Scipy stack: numpy with OpenBLAS, scipy, matplotlib, Pandas, scikit-learn, scikit-image, numba, etc.\n  \n\n\n\n\n\n    GIS stack: GDAL, netCDF4, pyproj, Shapely, rasterio, basemap, Fiona, etc.\n  \n\n\n\n\n\n    Image IO: Imagecodecs, Pillow, OpenImageIO, OpenEXR, pylibCZIrw, etc.\n  \n\n\n\n\n\n    Noteworthy: Pytorch, Kivy, opencv_python_headless, pymol-open-source, pywin32"},
{"Title": "Parsing Python ASTs 20x faster with Rust", "Author": "u/the1024", "Content": "https://www.gauge.sh/blog/parsing-python-asts-20x-faster-with-rust"},
{"Title": "Trying to find this package", "Author": "u/CompositePrime", "Content": "I should have saved the post but maybe 4-6 months ago I was reading a post (I am pretty sure it was in \nr/Python\n) where someone created a package that creates a visual for data contained within a list. For example, let‚Äôs say I have a data frame where one of the columns is named ‚Äúcolors‚Äù and each record contains a list of colors. One record might be [black,blue,yellow] another record might have [blue,yellow,black]. The visual had two parts where the top was a column chart to show the frequency of the list combinations and below the column chart was more of a table that showed each ‚Äúcolor‚Äù as one column and then across the row for each color and under the columns from the chart above was an indicator of sorts that would be greyed out of the color for that row was not in the corresponding columns list and highlighted another color of it was. Anyways this is probably a long shot but either the package or the name of this visual would be super helpful. Thanks python community!"},
{"Title": "Wednesday Daily Thread: Beginner questions", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "I am Nominating Myself for PSF Board of Directors", "Author": "u/tavallaie", "Content": "I am nominating myself for the PSF Board of Directors! üåü Check out my latest blog post to learn more about my journey, my commitment to the Python community, and my application for an OFAC license to expand educational activities in restricted areas.\n  \n\n    Read more at \nmy blog"},
{"Title": "Scrapegraph AI Tutorial; Scrape Websites Easily With LLaMA AI", "Author": "u/INSERT_KEYWORD", "Content": "I'm going to show you how to get Scrapegraph AI up and running, how to set up a language model, how to process JSON, scrape websites, use different AI models, and even turning your data into audio. Sounds like a lot, but it's easier than you think, and I'll walk you through it step by step.\n  \n\n\nhttps://www.scrapingbee.com/blog/scrapegraph-ai-tutorial-scrape-websites-easily-with-llama-ai/"},
{"Title": "What are the hardware requirements in a laptop to run Python + Future AI based projects?", "Author": "u/Madlynik", "Content": "I will buy a laptop for coding purposes but just started learning and practising Python using Pyecharm. What are the software requirements that lead to hardware specs a general Python coder must look into?\n  \n\n    Please suggest the hardware setup within a pocket friendly budget."},
{"Title": "Looking for a good WYZIWIG/visual editor to go with with Jinja + Weasyprint", "Author": "u/Benoss", "Content": "End goal is to produce PDF using external data and a template. Needs to support Jinja tags, conditionals and loops.\n  \n\n    Using \nhttps://github.com/Kozea/WeasyPrint\n and \nhttps://github.com/pallets/jinja\n as base stack (Open to other suggestions)\n  \n\n    I was thinking of building some base HTML templates but would be awesome if I could find a visual HTML editor that could produce code 100% compatible with Weasyprint so that end users can build templates by themselves or modify existing ones.\n  \n\n    Could be Wysiwyg based using \nhttps://editorjs.io\n or \nhttps://github.com/slab/quill\nor more advanced web builders like \nhttps://github.com/GrapesJS/grapesjs\n\n\n\n    Anybody built something similar?"},
{"Title": "NumPy 2.0.0 is the first major release since 2006.", "Author": "u/commandlineluser", "Content": "NumPy 2.0.0 is the first major release since 2006.\n  \n\n\n\n\n\n\nhttps://github.com/numpy/numpy/releases/tag/v2.0.0\n\n\n\n\n\n\n\n\nhttps://numpy.org/devdocs/release/2.0.0-notes.html\n\n\n\n\n\n\n\n\nhttps://numpy.org/devdocs/numpy_2_0_migration_guide.html"},
{"Title": "Load Tests Python Task Queues", "Author": "u/tuple32", "Content": "What My Project Does\n\n\n\n    While looking for task queues, I found that there are many options available in the Python ecosystem, making it really hard to choose the right one. To get a sense of how each library performs and to help make an informed decision, I conducted a load test on some of the most popular ones: Python-RQ, ARQ, Celery, Huey, and Dramatiq.\n  \n\n\nTarget Audience\n\n\n\n    I hope my findings can help those who are also looking for a task queue solution in Python.\n  \n\n\nComparison\n\n\n\n    Most articles out there seem to focus on comparing the features of these libraries but rarely discuss performance. While there could be a lot of improvements on my tests, I think it still provide some different insights into how each library handles heavy loads and concurrency.\n  \n\n\nLinks:\n\n\n\n    You can read  my findings¬†\non my blog\n\n\n\n    Check out the source code:¬†\non Github\n\n\n\n    Thanks"},
{"Title": "Aurora: An extensible Python static site generator", "Author": "u/zerojames_", "Content": "What My Project Does\n\n\n\n\nAurora\n is a fast, extensible Python static site generator. With Aurora, I can generate my personal website (~1,700 files, with multiple layers of jinja2 templates for each page) in < 4 seconds. Aurora generated 292,884 pages from a Hacker News post dataset in 2m:20s.\n  \n\n    Aurora supports incremental static regeneration, where pages can be regenerated in under 400ms, with hot reloading. I documented how this works \non my blog\n.\n  \n\n\nTarget Audience\n\n\n\n    I'm building Aurora to help me run my website, but it is built to be general so you can use it for your own projects. I would love feedback!\n  \n\n    I want this to be a tool for running static sites in production, at scale.\n  \n\n\nComparison\n\n\n\n    Aurora is inspired by the folder structure of Jekyll, but is written in Python. It has a hooks API that lets you define custom Python functions that manipulate the state of a page. This allows you to implement custom behaviours in isolation of the engine itself. I use this to open link previews from a cache that I plan to use on my website, among other things."},
{"Title": "Suggestion: make ray.io a part of Python's std lib", "Author": "u/jmakov", "Content": "Imagine having the option to write code once and run on multiple cores or on the cluster as part of the std lib. I know there's a company (currently) behind it - Anyscale, also not sure what the license is but other than that, what's holding the Py community back?"},
{"Title": "Advise on choosing UI technology with Python", "Author": "u/green9cactus", "Content": "I am new to python and currently working on simple 3 layer web application -\n  \n\n\n\n\n\n    frontend - ?\n  \n\n\n\n\n\n    backend API to fetch data from DB - python\n  \n\n\n\n\n\n    DB - cloud\n  \n\n\n\n\n\n    This application has main intention to fetch data from DB, display graphs , table format data etc.  also perform some combination analysis of data and show on UI.\n  \n\n    Which less complex and stable technology I should prefer for frontend ? python flask, Bulma, Mesop by google or any other ? Thank you."},
{"Title": "Tuesday Daily Thread: Advanced questions", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "Ruff: A Modern Python Linter for Error-Free and Maintainable Code", "Author": "u/ajpinedam", "Content": "Linting is essential to writing clean and readable code to share with others. A linter, like Ruff, is a tool that analyzes your code and looks for errors, stylistic issues, and suspicious constructs. Linting allows you to address issues and improve your code quality before you commit your code and share it with others.\n  \n\n    Ruff is a modern linter that‚Äôs extremely fast and has a simple interface, making it straightforward to use. It also aims to be a drop-in replacement for many other linting and formatting tools, such as Flake8, isort, and Black. It‚Äôs quickly becoming one of the most popular Python linters.\n  \nInstalling Ruff\n\n    Now that you know why linting your code is important and how Ruff is a powerful tool for the job, it‚Äôs time to install it. Thankfully, Ruff works out of the box, so no complicated installation instructions or configurations are needed to start using it.\n  \n\n    Assuming your project is already set up with a virtual environment, you can install Ruff in the following ways:\n  \n```bash\n$ python -m pip install ruff\n```\n\nYou can check that Ruff installed correctly by using the ruff version command:\n\n```bash\n$ ruff version\nruff 0.4.7\n```\nLinting Your Python Code\n\n    While linting helps keep your code consistent and error-free, it doesn‚Äôt guarantee that your code will be bug-free. Finding the bugs in your code is best handled with a debugger and adequate testing, which won‚Äôt be covered in this tutorial. Coming up in the next sections, you‚Äôll learn how to use Ruff to check for errors and speed up your workflow.\n  \nChecking for Errors\n```bash\n$ ruff check\none_ring.py:1:8: F401 [*] `os` imported but unused\none_ring.py:10:12: F821 Undefined name `name`\nFound 2 errors.\n[*] 1 fixable with the `--fix` option.\n```\n\n    Success! Ruff found two errors. Not only does it show the file and line numbers of the errors, but it also gives you error codes and messages. In addition, it lets you know that one of the two errors is fixable. Great!\n  \n\n    You can tell Ruff to fix errors by applying the --fix flag. Here‚Äôs what happens when you follow its suggestion:\n  \n```bash\n$ ruff check --fix\none_ring.py:9:12: F821 Undefined name `name`\nFound 2 errors (1 fixed, 1 remaining).\n```\n\n    You can find the rest of this Free tutorial \nhere"},
{"Title": "Advice for creating 3D modelling program", "Author": "u/Latter-History-8053", "Content": "I am creating a Python program which models 3D shapes so that they can be saved and or interacted with (i.e. rotated). The process currently takes a while to render shapes consisting of multiple materials. The libraries being implemented are currently matplotlib and numpy. What would you advise for improving the rendering process (library choice etc)?"},
{"Title": "pieshell: python for shell scripting and as an interactive shell", "Author": "u/Severe_Inflation5326", "Content": "Pieshell is a Python shell environment that combines the expressiveness of shell pipelines with the power of python iterators.\n  \n\n    It can be used in two major ways:\n  \n\n\n\n\n\n    As an interactive shell replacing e.g. bash\n  \n\n\n\n\n\n    As an ordinary python module replacing e.g. subprocess.Popen\n  \n\n\n\n\n\n    Obligatory example:\n  \n140:/home/oven/pieshell >>> for x in ls(-a) | tr(\"s\", \"S\"):\n...   if x.endswith('.py'):\n...      print x\n... \nSetup.py\n\n    Source code: \nhttps://github.com/redhog/pieshell\n\n\nWhat the project does\n\n    It's a replacement for the subprocess module, and for bash as an interactive shell, and makes interacting with shell pipelines easier.\n  \nTarget Audience\n\n    System administrators, system software developers, data scientists\n  \nComparison\n\n    While os.system is very limited but easy to use, subprocess.Popen offers a lot of flexibility, but the interface is very low level. Any actual pipelining of multiple programs is pretty much required to be done by e.g. a bash process, constructing the pipeline as a shell script string. Further, interacting with standard in and standard out requires careful IO handling.\n  \n\n    Pieshell on the other hand lets you construct pipelines as python objects. Standard io from a pipeline can be handled using iterators or async iterators. Pieshell has full asyncio integration."},
{"Title": "How does Python earn money? What would have been their business model?", "Author": "u/Civil-Captain5676", "Content": "I was wondering recently about any startup and any coding language that how does they make money. So I was curious to know about Python which is widely used"},
{"Title": "I created a script to automatically patch revanced", "Author": "u/ltlbwu", "Content": "What My Project Does\n\n\n\n    AutoReVanced is a Python script that automates downloading and patching APKs using ReVanced patches from ApkPure. It's perfect for anyone wanting to patch their revanced app.\n  \n\n\nTarget Audience\n\n\n\n    Suitable for a fun side project or hobbyists, AutoReVanced is designed for anyone wanting to customize Android apps with ReVanced patches.\n  \n\n\nComparison\n\n\n\n    Unlike alternatives, AutoReVanced is automatic.\n  \n\n    GitHub: \nautorevanced"},
{"Title": "Monday Daily Thread: Project ideas!", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "abstract-factories - a simple framework for content creation pipelines", "Author": "u/HistoricalCrow", "Content": "Hey all, my project \nabstract_factories\n is up to gauge interest and primarily feedback.\n  \n\n    The design goal is to make it easier to iterate on typical Content Creation pipeline tools (tool dev, rigging, validation, asset management etc) with a flexible framework to provide convenience, open and simple design and no dependencies (currently). It's an approach I've used a lot over the years and found it pretty versatile in production across numerous projects.\n  \nKey features\n\n\n\n\n\n    Auto-registration of matching items (types or instances) from any given path or python module.\n  \n\n\n\n\n\n    Simple or conditional item identifiers.\n  \n\n\n\n\n\n    Versioning.\n  \n\n\n\n\n\n    Recursive path searching (recursive module search in review).\n  \n\n\n\n\n\n    Dynamic resolving and importing modules in packaged (supports relative importing).\n  \n\n\n\n\nUsage Examples\n\n    There are a couple of \nsimple examples\n given along with tests to cover all of the current features.\n  \nWhat the project does\n\n    It's a convenience package for creating scalable tools and frameworks using \nAbstract Factory\n design pattern.\n  \nTarget Audience\n\n    Due to the solutions it's built for, it's aimed primarily at Technical Artists, Technical Animators, Pipeline and Tool Developers, but I'm interested in hearing about other possible applications.\n  \nComparison\n\n    Compared to other Factory and Abstract Factory convenience packages, mine is based on the work from \nthis GDC talk\n. The direct \nabstract-factories\n currently comes with a few more conveniences I've found useful during production. The idea stems from boiling down \nPyblish\n to something that became a little more reusable when writing frameworks as opposed to being the framework.\n  \n\n    Suggestions, questions, comments etc welcome."},
{"Title": "Showcase: pdf-to-podcast.com -- Convert PDF's to podcast episodes. Free and open-source :)", "Author": "u/knowsuchagency", "Content": "What My Project Does\n\n    Upload any PDF and have it converted into a podcast episode with two or more speakers discussing its contents.\n  \n\n\nhttps://github.com/knowsuchagency/pdf-to-podcast\n\n\nTarget Audience\n\n    Anyone, but other developers in-particular. The code is open-source on GitHub and there's a link to the source on \nhttps://pdf-to-podcast.com\n. I want the project to serve as an illustrative example of how to build useful things on top of LLMs with relatively little code.\n  \nComparison\n\n    I just made this for fun. It's possible there are other similar projects"},
{"Title": "Have anyone tried google/mesop", "Author": "u/codes_astro", "Content": "Google Open sourced Mesop. Mesop is a Python-based UI framework that allows you to rapidly build web apps. Used at Google for rapid internal app development similar to Streamlit.\n  \n\n    find more \nhere"},
{"Title": "I created Yu-Gi-Oh! Power of Chaos save handler", "Author": "u/wildpantz", "Content": "Quick backstory:\n  \n\n    Upper floor of my house is sort of a man-cave until we decorate it, so during this time I have two PCs which I use to play games with a friend when we have extra time to waste. The other day I remembered the game mentioned in the title and we had lots of fun playing it (there's 3 different games in this series). I decided I'd transfer the save file to my main PC so I can play when he's not visiting and I quickly learned it's an extremely annoying process to transfer save files across different PCs. Long story short, you need to find a proper registry key (which isn't always located at same spot for some reason) and you need to locate a system.dat file also located in a folder that isn't always in the same place. This process gets tedious pretty quick, so I decided to use the power of Python to make my life easier.\n  \n\n    What the project does:\n  \n\n    It's essentially a CLI save handler for the game mentioned in the title. It has 5 slots where you can backup your current save or load the backup to the computer. It can also fix minor registry issues if needed.\n  \n\n    Target audience:\n  \n\n    Given that I'm about 20 years too late... I'd say mostly people with very slow PCs or people who like to inhale nostalgia.\n  \n\n    I learned a lot about using winreg and msvcrt and getch, so while I will likely get bored of the game in the coming weeks, I'm happy I learned something new in the meantime, plus maybe someone finds it useful!\n  \n\n    Source code: \nmarkomavrinac/yugioh_poc_save_handler: Yu-Gi-Oh! Power of Chaos save handler - A script to manage your save games across multiple computers (github.com)"},
{"Title": "Tutorial: A Timely Python Multi-page Streamlit Application on Olympic Medal Winning Countries", "Author": "u/jgloewen", "Content": "Streamlit\n¬†is an open-source app framework that allows data scientists and analysts to create interactive web applications with ease.\n  \n\n    Using just a few lines of Python, you can turn data scripts into shareable web apps.\n  \n\n    And combined with a data visualization library like¬†\nPlotly,\n¬†you can create beautiful charts and maps with only a few lines of code.\n  \n\n    In this article, let me step you through how to use¬†\nStreamlit\n¬†to create a multi-page interactive application that visualizes Olympic medal data.\n  \n\n    The application will have three pages:\n  \n\n\n\n\n\n    an overview of medal counts,\n  \n\n\n\n\n\n    a country-specific analysis, and\n  \n\n\n\n\n\n    a choropleth map displaying global medal distributions.\n  \n\n\n\n\n\n    Let‚Äôs get to it!\n  \n\n    Link to free article \nHERE\n\n\n\n    Github repo \nHERE"},
{"Title": "Learning Python coming from a JVM background", "Author": "u/Human_Dependent6814", "Content": "I have 4 years worth JVM languages (Java, Kotlin) and have a need to learn some Python.  What's a good resource to get up to speed quickly with idiomatic Python?"},
{"Title": "I made a cool calendar app with PyQt6", "Author": "u/Specialist-Arachnid6", "Content": "Tempus is a calendar with horoscopes, reminders, etc made with PyQt6\n  \nWhat my Project does?\n\n    Tempus is a desktop-based calendar management application built with PyQt6, allowing users to manage their todos, reminders, and special dates efficiently. It offers features like adding, editing, and deleting tasks and reminders, as well as marking dates as special. Tempus ensures users stay organized and never miss important events. Plus, it shows you how many days are remaining until a special day in the dashboard.\n  \nTarget Audience\n\n    Well, anyone who uses a desktop calendar app I guess?\n  \nComparison\n\n    I did some research and couldn't find good calendar apps made with PyQt6.  If you guys knows any, please mention it below and I'm sorry in advance.\n  \nGitHub\n\n\nhttps://github.com/rohankishore/Tempus"},
{"Title": "Better-OrderedMultiDict - a fast pure-pyton implementation of an ordered multi-valued dictionary.", "Author": "u/JoachimCoenen", "Content": "What my project does\n\n    It provides a fast pure-python implementation of an ordered, multi-valued dictionary.\n  \nTarget audience\n\n    Python developers that need this kind of specialized functionality.\n  \n\n    This can be used in production. It has no dependencies. The code is unit-tested (almost fully, I'm working on it) It requires Python 3.12+\n  \nComparison\nComparison to dict and OrderedDict\n\n\ndict\n and \nOederedDict\n are already ordered, but they only allow one value per key. You could use a defaultdict of lists, but then you have these disadvantages:\n  \n\n\n\n\n\n    you can end up with empty lists within the dict if you aren't careful\n  \n\n\n\n\n\n    you lose the order of individual items within the dict:\n  \n\n\n\n\n\n\nitems = [(1, '1'), (2, '2'), (2, '22'), (1, '11')]\nnormal_dict = defaultdict(list)\nfor key, value in items:\n    normal_dict [key].append(value)\nom_dict = OrderedMultiDict(items)\nprint(list(normal_dict .items)) # prints [(1, ['1', '11']), (2, ['2', '22'])] \nprint(list(om\\_dict.items))     # prints [(1, '1'), (2, '2'), (2, '22'), (1, '11')]\n\n\n\n\n\n    iterating over all key/value pairs can be cumbersome as you need nested loops\n  \n\n\n\n\nComparison to \nomdict\n.\n\n\nOederedDict\n provides a (in my opinion) nicer interface with less surprising behavior or pitfalls. My implementation is also faster. e.g iterating over all items is ~5x faster.\n  \nMore info\n\n    This started as a toy project, that later became useful to me, so I decided to cleanup the code, add tests, and publish it.\n  \nfrom better_orderedmultidict import OrderedMultiDict\nomd: OrderedMultiDict[int, int] = OrderedMultiDict([(1,1), (2,2), (1,11), (2,22)])\n\nfor key in reversed(omd.unique_keys()):\n    print(f\"{key}: {omd.getall(key)}\")\n# prints:\n# 2: [2, 22]\n# 1: [1, 11]\n\nprint(omd.popfirstitem())  # prints: (1, 1)\nprint(omd.poplast(2))  # prints: 22\n\nfor key in reversed(omd.unique_keys()):\n    print(f\"{key}: {omd.getall(key)}\")\n# prints:\n# 2: [2]\n# 1: [11]\nInstallation\n\n    You can install Better-OrderedMultiDict using pip:\n  \npip install better-orderedmultidict\nContributing\n\n    If you have any suggestions or improvements for Better-OrderedMultiDict, feel free to submit a pull request or open an issue on the \nGitHub repository\n. I appreciate any feedback or contributions!\n  \nLinks\n\n    Here's the link to the GitHub repository: \nhttps://github.com/JoachimCoenen/Better-OrderedMultiDict\n\n\n\n    Here's the link to PyPi: \nhttps://pypi.org/project/better-orderedmultidict"},
{"Title": "Cant decide between flask, django ninja or fastAPI for sideproject", "Author": "u/Eggesalt", "Content": "As the title says, I cant decide what to use for rest api for mye summer project. I am uni student, so this project will only be very small scale project. I have made simpel rest apis in sll of them, but still cant decide which one to actuslly use for my project. Do anyone have any tips for which might be right one? A thing to consider for me answel is how easy it is to host."}
]