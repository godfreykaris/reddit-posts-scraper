---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/bleeddonor
Content: Python gives you wings, yes, but you used to have to wear aviator glasses
  to get through the docs on a bright display. No more. :)
Title: Python 3.12 docs include built-in support for themes, including a dark theme!
---
Author: u/Spindelkryp
Content: Heya, I have recently integrated Ruff in the Bazel monorepo of my company.
  The results were quite impressive, it takes around ~100ms to analyze and apply format
  / lint results to 1.1k python files. Integration with Bazel, however, was not exactly
  painless so I wrote a small guide for it as well as an example project. . Hope it
  helps someone! What My Project Does Guide on how to setup Ruff linting for Bazel
  based Python projects Target Audience Maintainers of large Python repos Source code
  How-to guide Source code
Title: Linting Python Monorepo with Bazel and Ruff
---
Author: u/abhi_uno
Content: 'Hello Python developers! I''m excited to announce the release of VidGear
  v0.3.3 , which brings official support for the libcamera backend in its PiGear API
  ! This update enhances the capabilities of Raspberry Pi Camera Modules and provides
  limited USB camera support. More about PiGear: PiGear is a specialized API optimized
  for Raspberry Pi üçá Boards, offering comprehensive support for camera modules (e.g.,
  OmniVision OV5647 Camera Module, Sony IMX219 Camera Module) and limited compatibility
  for USB cameras. PiGear implements a seamless and robust wrapper around the Picamera2
  Python library, simplifying integration with minimal code changes and ensuring a
  smooth transition for developers already familiar with the Picamera2 API. PiGear
  leverages the libcamera API under the hood with multi-threading, providing high-performance
  üî•, enhanced control, and functionality for Raspberry Pi camera modules. PiGear handles
  common configuration parameters and non-standard settings for various camera types,
  simplifying the integration process. PiGear currently supports PiCamera2 API parameters
  such as sensor, controls, transform, and format, with internal type and sanity checks
  for robust performance. While primarily focused on Raspberry Pi camera modules,
  PiGear also provides basic functionality for USB webcams (only with Picamera2 API),
  along with the ability to accurately differentiate between USB and Raspberry Pi
  cameras using metadata. PiGear seamlessly switches to the legacy picamera library
  if the Picamera2 library is unavailable, ensuring seamless backward compatibility.
  PiGear also provides a flexible multi-threaded framework around the complete picamera
  API, allowing developers to effortlessly exploit a wide range of parameters, such
  as brightness, saturation, sensor_mode, iso, exposure, and more. Furthermore, PiGear
  supports the use of multiple camera modules, including those found on Raspberry
  Pi Compute Module IO boards and USB cameras (only with Picamera2 API). We''re eager
  to see the innovative projects you''ll create with PiGear! For more details and
  to get started, check out our GitHub repository . Happy coding! Feel free to ask
  any questions or share your feedback below. Let''s discuss and innovate together!
  üöÄ'
Title: My library VidGear `v0.3.3` - brings libcamera API Support to python.
---
Author: u/antvas
Content: 'https://deviceandbrowserinfo.com/learning_zone/articles/detecting-headless-chrome-selenium-2024
  TL;DR The 4 techniques are the following: Using the user agent HTTP headers or with
  navigator.userAgent in JS to detect user agents linked to Headless Chrome: is Mozilla/5.0
  (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/126.0.6478.114
  Safari/537.36 Similarly, by detecting the presence of the HeadlessChrome substring
  in the sec-ch-ua header By detecting if navigator.webdriver = true in JavaScript
  By detecting the side effects of CDP (Chrome DevTools Protocol) (detailed in the
  article)'
Title: How to detect (modified|headless) Chrome instrumented with Selenium (2024 edition)
---
Author: u/sagunsh
Content: What My Project Does It s a simple web analytics app that tracks visitors
  in your website. I am using ip-api.com for geolocation and uap-python library for
  parsing user agent. At the moment, it simply logs these information to a sqlite
  database. Target Audience Anyone who is learning Python and more specifically Fast
  API and want to try building some projects. The code is available on github so feel
  free to explore, add features. Comparision Having used Django and Flask in the past,
  I made this project as a way to learn and to explore about Fast API. For a more
  sophisticated/paid alternative, check out Google Analytics, Plausible, etc. Source
  Code https://github.com/sagunsh/webanalytics
Title: I made a simple web analytics app using Fast API
---
Author: u/fesch2
Content: 'What my project does discover-plugins is a simple CLI tool that lets you
  list and filter plugins entrypoints installed into a python environment. I recently
  had to track down a bug that I ultimately resulted from a plugin I had installed
  into my environment.  To my surprise, there was no easy way to list which kind of
  plugins were installed, so I decided to build my own tool. Target Audience discover-plugins
  is intended as a debugging tool for those times when you are not quite sure which
  plugins are currently part of your python environment. Installation pipx install
  discover-plugins Usage Find all installed plugins related to pytest (the relevant
  group name is pytest11 ): discover-plugins --group pytest11 The tool defaults to
  use the first python interpreter on your path, you can optionally specify which
  interpreter to use with the --interpreter flag. The output will list all entrypoints
  belonging to the pytest11 group. For example, if you had installed a single pytest
  plugin ( pytest-aws-apigateway ) the output would look like this: { "pytest11":
  [ { "name": "pytest_httpx", "group": "pytest11", "value": "pytest_httpx" }, { "name":
  "anyio", "group": "pytest11", "value": "anyio.pytest_plugin" }, { "name": "pytest-aws-apigateway",
  "group": "pytest11", "value": "pytest_aws_apigateway.plugin" } ] } Links Link to
  GitHub: https://github.com/felixscherz/discover-plugins PyPI: https://pypi.org/project/discover-plugins/
  Let me know if the tool helped you out! Cheers!'
Title: discover-plugins - track which plugins are installed into your python environment
---
Author: u/homelander_30
Content: I guess the title explains it all, I'm looking for some personal projects
  to work or contribute on and would be really helpful if anyone is looking for a
  dev. I did look upon some open-source projects but they were too advanced and out
  of scope for me so I just wanna start small and learn.
Title: Is anyone here looking for a developer to contribute to your personal projects?
---
Author: u/Penny-loafers
Content: I put this quiz together to help create conversation for interns and new
  python developers at my company. Its based on the content from one of my favourite
  books ( Fluent Python ). I hope you enjoy it! Quiz
Title: I made a little Python quiz for interns and new Python developers at my company
---
Author: u/pdfisk
Content: 'Python is one of the world''s most popular programming languages and the
  web is the most ubiquitous application platform. There are several projects which
  aim to enable Python to run in web browsers. Brython is an implementation of Python
  3 written in JavaScript. Skulpt is an implementation of Python 2/3 written in JavaScript.
  PyScript is an implementation of Python 3 written in WebAssembly. Transcrypt is
  a Python to JavaScript compiler - unfortunately, the project seems to have been
  abandoned. Batavia is a Python virtual machine written in JavaScript - unfortunately,
  the project seems to have been abandoned. Finally, I have created VistaPython which
  is also intended to run Python 3 in web browsers but by using a bytecode interpreter
  written in JavaScript. Each design has strengths and weaknesses: Both Brython and
  Skulpt use hand-written Python parsers which are difficult to maintain. VistaPython
  uses a parser generator, Antlr , to automatically generate the JavaScript code for
  the parser. The parser can be updated to match the latest Python version by simply
  running a script. Also, both Brython and Skulpt generate JavaScript code which is
  then evaluated. In VistaPython, the compiler produces a "code object" which is then
  executed using the bytecode interpreter. The first approach will result in faster
  code whereas the second approach can be more flexible for code stepping, etc. PyScript
  is based on Pyodide which is a port of CPython to WebAssembly. PyScript can be upgraded
  the latest Python release by recompiling the latest CPython sources. Its main disadvantage
  is that it is very heavy to load and seems to run poorly on mobile devices. In VistaPython,
  the load profiles are: vm.js (Python virtual machine) 761kb Python parser 368 kb
  Mobile client GUI 2.4 Mb Desktop client GUI 2.9 Mb Compiled applications can be
  run using only the Python virtual machine (761kb). The design goal of VistaPython
  is to be able to load compiled applications from a database and run them quickly
  on any web device.'
Title: Running Python in Web Browsers
---
Author: u/SuccessfulLiving757
Content: I made a cool tool with python named Cookie Monster (not the one from sesmene
  street). It fetches cookies from a website and it is kinda broken... you can install
  it from https://sojoyork.github.io ! And yes it is one of my best python projects!
  I hope you like it.! And the GitHub repository is https://github.com/sojoyork/sojoyork.github.io
  ! (also am new to reddit)
Title: cool tool made with python
---
Author: u/SAV_NC
Content: 'Web Scraper Script What My Project Does This project scrapes websites to
  extract and display titles and links of articles. It processes multiple websites
  in parallel, fetching and parsing content to provide a consolidated list of articles
  with their full URLs. Target Audience Home users, researchers, and web enthusiasts
  who need to gather information from multiple websites quickly and efficiently. Features
  Parallel Processing : Uses ThreadPoolExecutor to fetch multiple websites concurrently,
  speeding up the scraping process. Error Handling and Logging : Provides detailed
  logging for debugging and retry mechanisms for robustness. Full URL Extraction :
  Ensures that all extracted links are complete URLs, enhancing usability. Customizable
  Headers : Allows customization of HTTP headers to mimic different browsers. Script
  Overview The script consists of several key components: Fetching URLs The script
  fetches content from the given URLs using the requests library. It includes retry
  logic with exponential backoff to handle transient errors. Parsing Content The script
  uses BeautifulSoup to parse the fetched HTML content and extract article titles
  and links. It ensures that the links are converted to full URLs using urljoin .
  Concurrent Execution The script employs ThreadPoolExecutor to fetch and parse content
  from multiple websites in parallel, improving efficiency. Access the Script You
  can access the script on GitHub here: Web Scraper Script on GitHub How to Use Install
  Dependencies : Ensure you have requests and beautifulsoup4 installed: pip install
  requests beautifulsoup4 Run the Script : Provide the URLs of the websites you want
  to scrape as arguments: python3 web-scraper.py https://yahoo.com https://sports.yahoo.com
  Conclusion This web scraper script is designed to be robust, efficient, and easy
  to use. It handles multiple websites in parallel, provides detailed logging, and
  ensures full URL extraction for all links. Ideal for users who need to quickly gather
  and consolidate information from various sources.'
Title: A simple website scraper script
---
Author: u/bolt_runner
Content: What are some software projects written in python that are well-structured
  and use good code design practices that are worth spending time to study?
Title: Open source Python projects with good software design that is worth studying
---
Author: u/muditjps
Content: 'Hi r/Python , This project is for a Streaming ETL problem statement for
  Fraud-detection/Log Monitoring use-case. Here''s a link to the blog explainer: https://pathway.com/developers/templates/kafka-etl
  GitHub Repo link: https://github.com/pathwaycom/pathway/tree/main/examples/projects/kafka-ETL
  What the Project Does Let''s say we''re monitoring logs from servers in New York
  and Paris. The logs have different time zones so you need to unify these different
  time zones into a single format to maintain data integrity. Now, Kafka is a popular
  ETL tool but it''s usable only in Java/Scala. Target Audience This is mostly for
  Python developers/data scientists/ML engineers and people who work on Fraud Detection
  or ETL. Comparison This project leverages Pathway, a Python ETL framework powered
  by an underlying Rust engine that surpasses Flink/Kafka in benchmarks. With this
  Pythonic framework we: Extract data streams from Kafka using built-in Kafka input
  connectors. Convert times with varying time zones into unified timestamps the datetime
  module. Load the final data stream back into Kafka. The entire script is available
  as an app template on the repo, which can be run via Docker in minutes. Open to
  your feedback/questions!'
Title: Log Monitoring with Kafka ETL using Python via Docker and Pathway
---
Author: u/sonobanana33
Content: 'I made a minor bugfix release of localslackirc https://codeberg.org/ltworf/localslackirc
  It can be installed via apt or ran from sources. No pypi package, sorry. What My
  Project Does After configuring it with a token from slack, it creates a local IRC
  server that bridges with slack. It supports threads, sending files. It doesn''t
  support reactions. It supports muting @here notifications from certain users or
  certain channels. It allows to silently leave a channel, but rejoins it if the user
  is personally mentioned there. Target Audience Mostly people who have to use slack
  for work and would prefer IRC. Comparison I am not aware of a project doing the
  same thing. I know weechat has a slack plugin, but that''s slightly different. I
  don''t use weechat and I wanted to keep using my IRC client. out of date link to
  avoid the post from being removed: https://github.com/ltworf/localslackirc'
Title: localslackirc - bridge slack and IRC
---
Author: u/FuturesBrightDavid
Content: Hi, I'm trying to find a Python community in Amsterdam in The Netherlands.  There
  used to be an active MeetUp group and Slack , but there has been little to no activity
  on either in a long, long time. Pythonistas in my city, what social / networking
  events or activities are there around here? Additionally, would anyone be interested
  in reviving the Python MeetUps in Amsterdam?
Title: Python community in Amsterdam, The Netherlands
---
Author: u/rnv812
Content: 'Hi, recently I created event generator in Python called Eventum . Here is
  a link to website: https://eventum-generatives.github.io/Website/ And the main repo:
  https://github.com/Eventum-Generatives/EventumCore What My Project Does It can be
  used in task like: Generation of datasets Simulation of processes in real time Filling
  different systems with demo data Testing on arbitrary data and stress testing Target
  Audience This generating tool is mostly for developers and people who work with
  data. It is also very near to ELK stack, OpenSearch and SIEM systems like Splunk
  . But you can use it as you want :) Comparison There is a project Eventgen developed
  by Splunk, but Eventum has next advantages over it: More rich events scheduling
  Extended functionality in event templates More parametrizable configurations Has
  content developing tools (UI for visualization time distributions and rendering
  templates)'
Title: 'Eventum: Flexible event generator'
---
Author: u/RitvikTheGod
Content: Guys, I recently released my first (in a while) open-source project wrapper
  on Telegram Bot API . I call it robogram and when I was developing in Python, I
  had a use case to send notifications from Raspberry Pi to my iPhone via Telegram
  . After searching online, I found no minimalist wrapper in Python 3+ to send messages
  via Bot API. So, I decided to create one :-) What My Project Does Minimal Wrapper
  around the Telegram Bot API. It's only dependency is requests in Python which is
  ubiquitous. It allows to retrieve info on Bot, or to send messages to users via
  personal chat, channel, or group. Target Audience Toy project I just came up with,
  after realizing no solution out there was best fit for me. But I have deployed this
  on production for personal project, and it's for sure production-ready. Target audience
  here would be other developers who are on Telegram and looking to leverage Bot API
  to facilitate the sending of messages or notifications to an audience on Telegram.
  Comparison Some packages out there are only async support, or only work on Python
  2 (actually I found one with some popularity that doesn't work in Python 3+ at all),
  or are dependency- or code- heavy and can introduce code bloat, especially to small,
  personal projects. As someone working on a personal project myself, I wanted a lightweight
  solution that only used minimal dependencies such as requests for making API requests.
  So, since I could not find one out there in wild, I decided to create my own! --
  Interested to get your thoughts, if anyone likes it I will be glad to feedback.
  https://github.com/rnag/robogram
Title: Robogram - Minimal Wrapper for Telegram Bot API in Python
---
Author: u/No_Coffee_9879
Content: 'Hey everyone, I just wanted to share a project I''ve been working on called
  Lambda Forge . It''s a tool designed to simplify the deployment and management of
  AWS Lambda functions. If you''re like me and spend a lot of time working with serverless
  architecture, you might find it pretty useful. What My Project Does Lambda Forge
  helps you deploy and manage AWS Lambda functions with ease. One of its standout
  features is the WebSocket connection for hot reloading of local code. It uses MQTT
  over Websockets to proxy requests to a local server, making development seamless.
  No more redeploying code just to see if your changes work! Target Audience This
  project is meant for developers who work with AWS Lambda in both production and
  development environments. Whether you''re a seasoned backend engineer or just getting
  started with serverless, Lambda Forge can help streamline your workflow. Comparison
  Compared to other deployment tools, Lambda Forge focuses on enhancing the development
  experience with hot reloading capabilities. Many existing tools require a full redeployment
  for changes to take effect, which can be time-consuming. Lambda Forge''s WebSocket
  integration saves time by allowing you to see changes in real-time without redeployment.
  If you''re interested, you can check out the documentation here: Lambda Forge Docs
  And if you want to dive into the code or contribute, here''s the GitHub repo: Lambda
  Forge on GitHub I‚Äôd love to hear your thoughts and feedback.'
Title: 'Introducing Lambda Forge: Simplifying AWS Lambda Deployment and Development!'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/Active-Fuel-49
Content: Mirascope is a Python library that lets you access a range of Large Language
  Models, but in a more straightforward and Pythonic way. https://www.i-programmer.info/news/90-tools/17275-mirascope-pythons-alternative-to-langchain.html
Title: Mirascope-Python's Alternative To Langchain
---
Author: u/jrbourbeau
Content: Hi All, I wanted to try to speed up some Python code with a GPU recently
  and was pretty shocked at how difficult it is to properly set up and configure things.
  I have lots of experience in the PyData space, but am definitely not a cloud devops
  expert. So some colleagues and I wrote a decorator that automatically sets up a
  cloud VM, runs the decorated function, and returns the function‚Äôs result back locally
  to my laptop. Here‚Äôs an example that trains a PyTorch model on an NVIDIA A10 GPU
  on AWS. The Coiled Function API is nice because I didn‚Äôt have to build any Docker
  images, muck around in the AWS console, or do anything special to set up a cloud
  GPU. That said, there are definitely tradeoffs here. We optimized for privacy and
  no standing costs, so it takes ~1-2 minutes to fully spin up VMs (no warm pool of
  VMs waiting). We also only run on AWS/GCP/Azure so this doesn‚Äôt help with on-prem
  workloads. I‚Äôm definitely biased as I work at Coiled, but think this is a simple
  way to run Python on cloud hardware (especially for folks without a lot of cloud
  experience). I‚Äôm curious to hear from folks here. Do you have a favorite way to
  run Python code on the cloud? What do you like about your current setup? For example,
  ergonomics, performance, something else?
Title: Python on Cloud GPUs
---
Author: u/Knockoutpie1
Content: Hey everyone, looking for some input. For work I‚Äôve worked on web scraping
  for prices to see if my components are adequately priced on the internet compared
  to competitors. I can use this for protein prices as a personal project. I have
  experience now with Beautiful Soup, Selenium, and Excel Power BI. What route should
  I go? Should I only pull pricing from Amazon? Or should I do Amazon and the manufacturer
  site to see which is better pricing? Ideas would be great. Should be a fun project.
  If I go with beautiful soup, there‚Äôs no UI and I can print all to terminal If I
  use selenium, I can use UC to pass anti-bot measures and also print to terminal,
  but it will open a browser window for each price scrape. If I use excel power BI,
  I‚Äôll just load data to a worksheet and pricing will update at the price of a button.
Title: Web scraper for protein prices
---
Author: u/willm
Content: Textual Serve ( https://github.com/Textualize/textual-serve ) is a project
  which serves TUIs (built with Textual) in the browser. This is self-hosted, so you
  don't need to rely on any external service.
Title: Textual Serve - Serve TUIs in the browser
---
Author: u/Martynoas
Content: This article explores how to manage Python project environments and dependencies,
  as well as how to structure projects effectively.
Title: Python Project Management Primer
---
Author: u/Fun-Asparagus-837
Content: 'Hi there ! I''m thinking about buying an ARM windows laptop with the new
  Qualcomm chips. They will replace the x86 so I was wondering : Will There be a massive
  risk of non-compatibility of Python packages ? I guess they are made for x86 but
  I don''t know if it''s possible to work with them with an ARM based CPU. Edit :
  Had a great deal on the ideapad pro 5 gen 9 so I went for it. Glad to have these
  incredible specs and decided to rely on x86 chip for the moment, because I wanted
  to avoid all the early-adoption problems'
Title: Python on ARM laptops
---
Author: u/SAV_NC
Content: 'What my project does Ranks videos based on overall quality. Takes into account
  multiple metrics to determine what quality is the best. Target audience Home users
  / Video enthusiasts Comparison This project uses the following metrics to rank videos:
  Resolution : Higher resolution videos are preferred. Frame Rate : Videos with higher
  frame rates are ranked higher. Bitrate : Higher bitrate often indicates better quality.
  Codec : Some codecs provide better quality than others at the same bitrate. The
  script extracts these metrics using ffprobe from the FFmpeg suite and sorts the
  videos accordingly. Here''s how the metrics are used: Resolution : The script first
  compares the resolution (width x height) of the videos. Higher resolutions are ranked
  higher. Frame Rate : If two videos have the same resolution, the one with the higher
  frame rate is ranked higher. Bitrate : For videos with the same resolution and frame
  rate, the bitrate is used to determine the quality. Codec : In case of a tie in
  all other metrics, the codec is considered to break the tie. Access the Script You
  can access the script on GitHub here'
Title: Video Quality Ranker
---
Author: u/lutipri
Content: Brandt Bucher talks on JIT compiler for Python at CPython Core Developer
  Sprint. Brandt is  a member of the Faster CPython project , which is working on
  making the reference implementation of the language faster via a variety of techniques.
  https://www.youtube.com/watch?v=HxSHIpEQRjs
Title: A JIT compiler for CPython
---
Author: u/Significant_Water_28
Content: 'little challenge for you, how fast can this be pushed in python? This function
  takes a numpy.ndarray / 2d numpy array, and returns the updated array. iv updated
  this function several times, this i the fastiest so far. numba jit dosn''t like
  the double roll, and its faster than for loops in jit. def conways_game_of_life(board:numpy.ndarray):
  n_neighbour = sum(numpy.roll(numpy.roll(board, i, 0), j, 1) for i in (-1, 0, 1)
  for j in (-1, 0, 1) if (i != 0 or j != 0)) board[(n_neighbour<2) | (n_neighbour>3)]
  = 0 board[(n_neighbour==3)] = 1 return board'
Title: Conway's game of life. can you find an optimization?
---
Author: u/DrumcanSmith
Content: What my project does Performs OCR on scanned Books using Microsoft Azure
  Document Intelligence read Target audience People who are unsatisfied with traditional
  OCR People who want to add clear text to the original PDF and not just extract the
  text. People who want to archive documents at best quality. Comparasion In my use
  case traditional OCR was near to useless. Tesseract was meh, Google API didn't process
  large files. Document Intelligence takes up to 500MB (although in practice a little
  less), and is possible to OCR 400-600 pages over books in batch by dividing and
  merging the source and results locally by only a few chunks. It doesn't provide
  the text in PDF form so that was my reason to start this project. Still in alpha
  and in separate modules and a lot of rigid coding, but it is working fine for my
  original task so thought maybe I'd showcase it. https://github.com/DesertDoggy/json3pdf
Title: 'json3pdf : Batch OCR for high quality document archiving.'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!'
---
Author: u/Balance-
Content: 'For anyone on a (new) Windows on Arm system, I found this great repo with
  Arm64 Windows wheels: https://github.com/cgohlke/win_arm64-wheels Highlights 256
  packages for Python 3.12 Built with numpy 2 if possible Scipy stack: numpy with
  OpenBLAS, scipy, matplotlib, Pandas, scikit-learn, scikit-image, numba, etc. GIS
  stack: GDAL, netCDF4, pyproj, Shapely, rasterio, basemap, Fiona, etc. Image IO:
  Imagecodecs, Pillow, OpenImageIO, OpenEXR, pylibCZIrw, etc. Noteworthy: Pytorch,
  Kivy, opencv_python_headless, pymol-open-source, pywin32'
Title: Experimental Python Wheels for Windows on ARM64
---
Author: u/the1024
Content: https://www.gauge.sh/blog/parsing-python-asts-20x-faster-with-rust
Title: Parsing Python ASTs 20x faster with Rust
---
Author: u/CompositePrime
Content: I should have saved the post but maybe 4-6 months ago I was reading a post
  (I am pretty sure it was in r/Python ) where someone created a package that creates
  a visual for data contained within a list. For example, let‚Äôs say I have a data
  frame where one of the columns is named ‚Äúcolors‚Äù and each record contains a list
  of colors. One record might be [black,blue,yellow] another record might have [blue,yellow,black].
  The visual had two parts where the top was a column chart to show the frequency
  of the list combinations and below the column chart was more of a table that showed
  each ‚Äúcolor‚Äù as one column and then across the row for each color and under the
  columns from the chart above was an indicator of sorts that would be greyed out
  of the color for that row was not in the corresponding columns list and highlighted
  another color of it was. Anyways this is probably a long shot but either the package
  or the name of this visual would be super helpful. Thanks python community!
Title: Trying to find this package
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Wednesday Daily Thread: Beginner questions'
---
Author: u/tavallaie
Content: I am nominating myself for the PSF Board of Directors! üåü Check out my latest
  blog post to learn more about my journey, my commitment to the Python community,
  and my application for an OFAC license to expand educational activities in restricted
  areas. Read more at my blog
Title: I am Nominating Myself for PSF Board of Directors
---
Author: u/INSERT_KEYWORD
Content: I'm going to show you how to get Scrapegraph AI up and running, how to set
  up a language model, how to process JSON, scrape websites, use different AI models,
  and even turning your data into audio. Sounds like a lot, but it's easier than you
  think, and I'll walk you through it step by step. https://www.scrapingbee.com/blog/scrapegraph-ai-tutorial-scrape-websites-easily-with-llama-ai/
Title: Scrapegraph AI Tutorial; Scrape Websites Easily With LLaMA AI
---
Author: u/Madlynik
Content: I will buy a laptop for coding purposes but just started learning and practising
  Python using Pyecharm. What are the software requirements that lead to hardware
  specs a general Python coder must look into? Please suggest the hardware setup within
  a pocket friendly budget.
Title: What are the hardware requirements in a laptop to run Python + Future AI based
  projects?
---
Author: u/Benoss
Content: End goal is to produce PDF using external data and a template. Needs to support
  Jinja tags, conditionals and loops. Using https://github.com/Kozea/WeasyPrint and
  https://github.com/pallets/jinja as base stack (Open to other suggestions) I was
  thinking of building some base HTML templates but would be awesome if I could find
  a visual HTML editor that could produce code 100% compatible with Weasyprint so
  that end users can build templates by themselves or modify existing ones. Could
  be Wysiwyg based using https://editorjs.io or https://github.com/slab/quill or more
  advanced web builders like https://github.com/GrapesJS/grapesjs Anybody built something
  similar?
Title: Looking for a good WYZIWIG/visual editor to go with with Jinja + Weasyprint
---
Author: u/commandlineluser
Content: NumPy 2.0.0 is the first major release since 2006. https://github.com/numpy/numpy/releases/tag/v2.0.0
  https://numpy.org/devdocs/release/2.0.0-notes.html https://numpy.org/devdocs/numpy_2_0_migration_guide.html
Title: NumPy 2.0.0 is the first major release since 2006.
---
Author: u/tuple32
Content: 'What My Project Does While looking for task queues, I found that there are
  many options available in the Python ecosystem, making it really hard to choose
  the right one. To get a sense of how each library performs and to help make an informed
  decision, I conducted a load test on some of the most popular ones: Python-RQ, ARQ,
  Celery, Huey, and Dramatiq. Target Audience I hope my findings can help those who
  are also looking for a task queue solution in Python. Comparison Most articles out
  there seem to focus on comparing the features of these libraries but rarely discuss
  performance. While there could be a lot of improvements on my tests, I think it
  still provide some different insights into how each library handles heavy loads
  and concurrency. Links: You can read  my findings on my blog Check out the source
  code: on Github Thanks'
Title: Load Tests Python Task Queues
---
Author: u/zerojames_
Content: What My Project Does Aurora is a fast, extensible Python static site generator.
  With Aurora, I can generate my personal website (~1,700 files, with multiple layers
  of jinja2 templates for each page) in < 4 seconds. Aurora generated 292,884 pages
  from a Hacker News post dataset in 2m:20s. Aurora supports incremental static regeneration,
  where pages can be regenerated in under 400ms, with hot reloading. I documented
  how this works on my blog . Target Audience I'm building Aurora to help me run my
  website, but it is built to be general so you can use it for your own projects.
  I would love feedback! I want this to be a tool for running static sites in production,
  at scale. Comparison Aurora is inspired by the folder structure of Jekyll, but is
  written in Python. It has a hooks API that lets you define custom Python functions
  that manipulate the state of a page. This allows you to implement custom behaviours
  in isolation of the engine itself. I use this to open link previews from a cache
  that I plan to use on my website, among other things.
Title: 'Aurora: An extensible Python static site generator'
---
Author: u/jmakov
Content: Imagine having the option to write code once and run on multiple cores or
  on the cluster as part of the std lib. I know there's a company (currently) behind
  it - Anyscale, also not sure what the license is but other than that, what's holding
  the Py community back?
Title: 'Suggestion: make ray.io a part of Python''s std lib'
---
Author: u/green9cactus
Content: I am new to python and currently working on simple 3 layer web application
  - frontend - ? backend API to fetch data from DB - python DB - cloud This application
  has main intention to fetch data from DB, display graphs , table format data etc.  also
  perform some combination analysis of data and show on UI. Which less complex and
  stable technology I should prefer for frontend ? python flask, Bulma, Mesop by google
  or any other ? Thank you.
Title: Advise on choosing UI technology with Python
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Tuesday Daily Thread: Advanced questions'
---
Author: u/ajpinedam
Content: 'Linting is essential to writing clean and readable code to share with others.
  A linter, like Ruff, is a tool that analyzes your code and looks for errors, stylistic
  issues, and suspicious constructs. Linting allows you to address issues and improve
  your code quality before you commit your code and share it with others. Ruff is
  a modern linter that‚Äôs extremely fast and has a simple interface, making it straightforward
  to use. It also aims to be a drop-in replacement for many other linting and formatting
  tools, such as Flake8, isort, and Black. It‚Äôs quickly becoming one of the most popular
  Python linters. Installing Ruff Now that you know why linting your code is important
  and how Ruff is a powerful tool for the job, it‚Äôs time to install it. Thankfully,
  Ruff works out of the box, so no complicated installation instructions or configurations
  are needed to start using it. Assuming your project is already set up with a virtual
  environment, you can install Ruff in the following ways: ```bash $ python -m pip
  install ruff ``` You can check that Ruff installed correctly by using the ruff version
  command: ```bash $ ruff version ruff 0.4.7 ``` Linting Your Python Code While linting
  helps keep your code consistent and error-free, it doesn‚Äôt guarantee that your code
  will be bug-free. Finding the bugs in your code is best handled with a debugger
  and adequate testing, which won‚Äôt be covered in this tutorial. Coming up in the
  next sections, you‚Äôll learn how to use Ruff to check for errors and speed up your
  workflow. Checking for Errors ```bash $ ruff check one_ring.py:1:8: F401 [*] `os`
  imported but unused one_ring.py:10:12: F821 Undefined name `name` Found 2 errors.
  [*] 1 fixable with the `--fix` option. ``` Success! Ruff found two errors. Not only
  does it show the file and line numbers of the errors, but it also gives you error
  codes and messages. In addition, it lets you know that one of the two errors is
  fixable. Great! You can tell Ruff to fix errors by applying the --fix flag. Here‚Äôs
  what happens when you follow its suggestion: ```bash $ ruff check --fix one_ring.py:9:12:
  F821 Undefined name `name` Found 2 errors (1 fixed, 1 remaining). ``` You can find
  the rest of this Free tutorial here'
Title: 'Ruff: A Modern Python Linter for Error-Free and Maintainable Code'
---
Author: u/Latter-History-8053
Content: I am creating a Python program which models 3D shapes so that they can be
  saved and or interacted with (i.e. rotated). The process currently takes a while
  to render shapes consisting of multiple materials. The libraries being implemented
  are currently matplotlib and numpy. What would you advise for improving the rendering
  process (library choice etc)?
Title: Advice for creating 3D modelling program
---
Author: u/Severe_Inflation5326
Content: 'Pieshell is a Python shell environment that combines the expressiveness
  of shell pipelines with the power of python iterators. It can be used in two major
  ways: As an interactive shell replacing e.g. bash As an ordinary python module replacing
  e.g. subprocess.Popen Obligatory example: 140:/home/oven/pieshell >>> for x in ls(-a)
  | tr("s", "S"): ...   if x.endswith(''.py''): ...      print x ... Setup.py Source
  code: https://github.com/redhog/pieshell What the project does It''s a replacement
  for the subprocess module, and for bash as an interactive shell, and makes interacting
  with shell pipelines easier. Target Audience System administrators, system software
  developers, data scientists Comparison While os.system is very limited but easy
  to use, subprocess.Popen offers a lot of flexibility, but the interface is very
  low level. Any actual pipelining of multiple programs is pretty much required to
  be done by e.g. a bash process, constructing the pipeline as a shell script string.
  Further, interacting with standard in and standard out requires careful IO handling.
  Pieshell on the other hand lets you construct pipelines as python objects. Standard
  io from a pipeline can be handled using iterators or async iterators. Pieshell has
  full asyncio integration.'
Title: 'pieshell: python for shell scripting and as an interactive shell'
---
Author: u/Civil-Captain5676
Content: I was wondering recently about any startup and any coding language that how
  does they make money. So I was curious to know about Python which is widely used
Title: How does Python earn money? What would have been their business model?
---
Author: u/ltlbwu
Content: 'What My Project Does AutoReVanced is a Python script that automates downloading
  and patching APKs using ReVanced patches from ApkPure. It''s perfect for anyone
  wanting to patch their revanced app. Target Audience Suitable for a fun side project
  or hobbyists, AutoReVanced is designed for anyone wanting to customize Android apps
  with ReVanced patches. Comparison Unlike alternatives, AutoReVanced is automatic.
  GitHub: autorevanced'
Title: I created a script to automatically patch revanced
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Monday Daily Thread: Project ideas!'
---
Author: u/HistoricalCrow
Content: Hey all, my project abstract_factories is up to gauge interest and primarily
  feedback. The design goal is to make it easier to iterate on typical Content Creation
  pipeline tools (tool dev, rigging, validation, asset management etc) with a flexible
  framework to provide convenience, open and simple design and no dependencies (currently).
  It's an approach I've used a lot over the years and found it pretty versatile in
  production across numerous projects. Key features Auto-registration of matching
  items (types or instances) from any given path or python module. Simple or conditional
  item identifiers. Versioning. Recursive path searching (recursive module search
  in review). Dynamic resolving and importing modules in packaged (supports relative
  importing). Usage Examples There are a couple of simple examples given along with
  tests to cover all of the current features. What the project does It's a convenience
  package for creating scalable tools and frameworks using Abstract Factory design
  pattern. Target Audience Due to the solutions it's built for, it's aimed primarily
  at Technical Artists, Technical Animators, Pipeline and Tool Developers, but I'm
  interested in hearing about other possible applications. Comparison Compared to
  other Factory and Abstract Factory convenience packages, mine is based on the work
  from this GDC talk . The direct abstract-factories currently comes with a few more
  conveniences I've found useful during production. The idea stems from boiling down
  Pyblish to something that became a little more reusable when writing frameworks
  as opposed to being the framework. Suggestions, questions, comments etc welcome.
Title: abstract-factories - a simple framework for content creation pipelines
---
Author: u/knowsuchagency
Content: What My Project Does Upload any PDF and have it converted into a podcast
  episode with two or more speakers discussing its contents. https://github.com/knowsuchagency/pdf-to-podcast
  Target Audience Anyone, but other developers in-particular. The code is open-source
  on GitHub and there's a link to the source on https://pdf-to-podcast.com . I want
  the project to serve as an illustrative example of how to build useful things on
  top of LLMs with relatively little code. Comparison I just made this for fun. It's
  possible there are other similar projects
Title: 'Showcase: pdf-to-podcast.com -- Convert PDF''s to podcast episodes. Free and
  open-source :)'
---
Author: u/codes_astro
Content: Google Open sourced Mesop. Mesop is a Python-based UI framework that allows
  you to rapidly build web apps. Used at Google for rapid internal app development
  similar to Streamlit. find more here
Title: Have anyone tried google/mesop
---
Author: u/wildpantz
Content: 'Quick backstory: Upper floor of my house is sort of a man-cave until we
  decorate it, so during this time I have two PCs which I use to play games with a
  friend when we have extra time to waste. The other day I remembered the game mentioned
  in the title and we had lots of fun playing it (there''s 3 different games in this
  series). I decided I''d transfer the save file to my main PC so I can play when
  he''s not visiting and I quickly learned it''s an extremely annoying process to
  transfer save files across different PCs. Long story short, you need to find a proper
  registry key (which isn''t always located at same spot for some reason) and you
  need to locate a system.dat file also located in a folder that isn''t always in
  the same place. This process gets tedious pretty quick, so I decided to use the
  power of Python to make my life easier. What the project does: It''s essentially
  a CLI save handler for the game mentioned in the title. It has 5 slots where you
  can backup your current save or load the backup to the computer. It can also fix
  minor registry issues if needed. Target audience: Given that I''m about 20 years
  too late... I''d say mostly people with very slow PCs or people who like to inhale
  nostalgia. I learned a lot about using winreg and msvcrt and getch, so while I will
  likely get bored of the game in the coming weeks, I''m happy I learned something
  new in the meantime, plus maybe someone finds it useful! Source code: markomavrinac/yugioh_poc_save_handler:
  Yu-Gi-Oh! Power of Chaos save handler - A script to manage your save games across
  multiple computers (github.com)'
Title: I created Yu-Gi-Oh! Power of Chaos save handler
---
Author: u/jgloewen
Content: 'Streamlit is an open-source app framework that allows data scientists and
  analysts to create interactive web applications with ease. Using just a few lines
  of Python, you can turn data scripts into shareable web apps. And combined with
  a data visualization library like Plotly, you can create beautiful charts and maps
  with only a few lines of code. In this article, let me step you through how to use
  Streamlit to create a multi-page interactive application that visualizes Olympic
  medal data. The application will have three pages: an overview of medal counts,
  a country-specific analysis, and a choropleth map displaying global medal distributions.
  Let‚Äôs get to it! Link to free article HERE Github repo HERE'
Title: 'Tutorial: A Timely Python Multi-page Streamlit Application on Olympic Medal
  Winning Countries'
---
Author: u/Human_Dependent6814
Content: I have 4 years worth JVM languages (Java, Kotlin) and have a need to learn
  some Python.  What's a good resource to get up to speed quickly with idiomatic Python?
Title: Learning Python coming from a JVM background
---
Author: u/Specialist-Arachnid6
Content: Tempus is a calendar with horoscopes, reminders, etc made with PyQt6 What
  my Project does? Tempus is a desktop-based calendar management application built
  with PyQt6, allowing users to manage their todos, reminders, and special dates efficiently.
  It offers features like adding, editing, and deleting tasks and reminders, as well
  as marking dates as special. Tempus ensures users stay organized and never miss
  important events. Plus, it shows you how many days are remaining until a special
  day in the dashboard. Target Audience Well, anyone who uses a desktop calendar app
  I guess? Comparison I did some research and couldn't find good calendar apps made
  with PyQt6.  If you guys knows any, please mention it below and I'm sorry in advance.
  GitHub https://github.com/rohankishore/Tempus
Title: I made a cool calendar app with PyQt6
---
Author: u/JoachimCoenen
Content: 'What my project does It provides a fast pure-python implementation of an
  ordered, multi-valued dictionary. Target audience Python developers that need this
  kind of specialized functionality. This can be used in production. It has no dependencies.
  The code is unit-tested (almost fully, I''m working on it) It requires Python 3.12+
  Comparison Comparison to dict and OrderedDict dict and OederedDict are already ordered,
  but they only allow one value per key. You could use a defaultdict of lists, but
  then you have these disadvantages: you can end up with empty lists within the dict
  if you aren''t careful you lose the order of individual items within the dict: items
  = [(1, ''1''), (2, ''2''), (2, ''22''), (1, ''11'')] normal_dict = defaultdict(list)
  for key, value in items: normal_dict [key].append(value) om_dict = OrderedMultiDict(items)
  print(list(normal_dict .items)) # prints [(1, [''1'', ''11'']), (2, [''2'', ''22''])]
  print(list(om\_dict.items))     # prints [(1, ''1''), (2, ''2''), (2, ''22''), (1,
  ''11'')] iterating over all key/value pairs can be cumbersome as you need nested
  loops Comparison to omdict . OederedDict provides a (in my opinion) nicer interface
  with less surprising behavior or pitfalls. My implementation is also faster. e.g
  iterating over all items is ~5x faster. More info This started as a toy project,
  that later became useful to me, so I decided to cleanup the code, add tests, and
  publish it. from better_orderedmultidict import OrderedMultiDict omd: OrderedMultiDict[int,
  int] = OrderedMultiDict([(1,1), (2,2), (1,11), (2,22)]) for key in reversed(omd.unique_keys()):
  print(f"{key}: {omd.getall(key)}") # prints: # 2: [2, 22] # 1: [1, 11] print(omd.popfirstitem())  #
  prints: (1, 1) print(omd.poplast(2))  # prints: 22 for key in reversed(omd.unique_keys()):
  print(f"{key}: {omd.getall(key)}") # prints: # 2: [2] # 1: [11] Installation You
  can install Better-OrderedMultiDict using pip: pip install better-orderedmultidict
  Contributing If you have any suggestions or improvements for Better-OrderedMultiDict,
  feel free to submit a pull request or open an issue on the GitHub repository . I
  appreciate any feedback or contributions! Links Here''s the link to the GitHub repository:
  https://github.com/JoachimCoenen/Better-OrderedMultiDict Here''s the link to PyPi:
  https://pypi.org/project/better-orderedmultidict'
Title: Better-OrderedMultiDict - a fast pure-pyton implementation of an ordered multi-valued
  dictionary.
---
Author: u/Eggesalt
Content: As the title says, I cant decide what to use for rest api for mye summer
  project. I am uni student, so this project will only be very small scale project.
  I have made simpel rest apis in sll of them, but still cant decide which one to
  actuslly use for my project. Do anyone have any tips for which might be right one?
  A thing to consider for me answel is how easy it is to host.
Title: Cant decide between flask, django ninja or fastAPI for sideproject
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/inobody_somebody
Content: 'what my project does This project is built to solve the issue of LLM unable
  to produce relevant answers for information in a particular context. uses the information  to
  train the model and stored it in a database and uses  this database to get relevant
  answers from the Model. Target audiance This project is for people who want to train
  a LLM on a particular piece of information. comparison This model only gives answers
  for information regarding the data you provided in the file. It will not answer
  any other questions including formal greetings. GitHub link : https://github.com/dharmateja2810/RAG-Retrieval-Augmented-Generation-Model'
Title: Built a RAG ( Retrieval-Augmented Generation ) model using Gemini Api.
---
Author: u/LeastPrice8673
Content: Hi I‚Äôm looking for inspiration for some stupid python automation projects.
  If you have done something funny or stupid using python automation I would love
  to hear it.
Title: Python automation ideas
---
Author: u/guangrei
Content: 'Python is a great programming language, but sometimes the indentation can
  be terrible for some people (especially people with visual impairments). So i created
  Lython . What the project does: Lython replacing the Python indentation to lua-style
  code blocks. this is example lython code def test(num) for i in range(num) do if
  i == 0 then print("zero") elif i % 2 == 1 then print("odd") else print("even") end
  # if else end # for end # def test(10) for more info, please visit lython repo.
  Target audience: Peoples with visual impairments (especially) and Programmers who
  want to write python code with new experience (generally) Repo & Source code: guangrei/lython'
Title: Lua-style code blocks for Python
---
Author: u/LordOmbro
Content: 'well, kind of. I made Pilgram, an infinite idle RPG where your character
  goes on adventures and notifies you when stuff happens. What my project does The
  bot provides a text interface with wich you can "play" an MMO RPG, it''s basically
  an online idle adventure game Target audience It''s a toy project that i made out
  of boredom, also it sounded cool Comparison I never heard of anything like this
  except for some really old browser games. Maybe i''m just not informed. More info
  How is it infinite? The secret is AI . Every quest and event in the game is generated
  by AI depending on the demand of the players, so in theory you can go on an infinite
  amount of quests. Why did i call it an MMO? Because you can kind of play with your
  friends by creating & joining guilds and by sending gifts to eachother. There even
  is a guild leaderboard to see who gets the most points :) The interface is exclusively
  text based, but the command interpreter i wrote is pretty easy to integrate in other
  places, even in GUIs if anyone wants to try. I tried out a lot of new things for
  this project, like using ORMs, writing unit tests (don''t look at those, i kinda
  got bored after a short while), using AI & writing generic enough code that it can
  be swapped with any other implementation. I think most of the code i wrote is pretty
  ok, but you can tell me what to change & what to improve if you want. Links here''s
  the link to the code: https://github.com/SudoOmbro/pilgram if you wanna try out
  the version i''m running on my server start a conversation with pilgram_bot on Telegram,
  don''t expect a balanced experience at first since that was kind of the last of
  my problems lol'
Title: I made an MMORPG with Python & Telegram in 4 weeks
---
Author: u/MDTv_Teka
Content: 'Hey guys! I''m excited to introduce Temporal Adjusters, a new Python package
  designed to make time series adjustments easier and more efficient. If you work
  with time series data, you''ll find this tool incredibly useful for various temporal
  adjustments. What my project does Adjusters are a key tool for modifying temporal
  objects. They exist to externalize the process of adjustment, permitting different
  approaches, as per the strategy design pattern. Temporal Adjuster provides tools
  that help pinpoint very specific moments in time, without having to manually count
  days, weeks, or months. In essence, a Temporal Adjuster is a function that encapsulates
  a specific date/time manipulation rule. It operates on a temporal object (representing
  a date, time, or datetime) to produce a new temporal object adjusted according to
  the rule. Examples might be an adjuster that sets the date avoiding weekends, or
  one that sets the date to the last day of the month. Installation You can install
  Temporal Adjuster using pip: pip install temporal-adjuster Usage This package provides
  a set of predefined temporal adjusters that can be used to adjust a temporal object
  in various ways. For example: >>> from datetime import date, datetime >>> from temporal_adjuster
  import TemporalAdjuster >>> from temporal_adjuster.common.enums import Weekday >>>
  TemporalAdjuster.first_day_of_next_week(date(2021, 1, 1)) datetime.date(2021, 1,
  4) >>> TemporalAdjuster.last_day_of_last_month(datetime(2021, 1, 1)) datetime.datetime(2020,
  12, 31) >>> TemporalAdjuster.first_of_year(Weekday.SATURDAY, date(2021, 1, 1)) datetime.date(2021,
  1, 2) >>> TemporalAdjuster.nth_of_month(Weekday.SUNDAY, datetime(2021, 5, 1), 2)
  datetime.datetime(2021, 5, 9) >>> TemporalAdjuster.next(Weekday.MONDAY, datetime(2021,
  2, 11), 2) datetime.datetime(2021, 2, 15) Contributing If you have any suggestions
  or improvements for pynimbar, feel free to submit a pull request or open an issue
  on the GitHub repository as per the CONTRIBUTING document. We appreciate any feedback
  or contributions! Target audience This can be used in production. It has only one
  depedency, dateutils, which if you''re manipulating temporal objects you probably
  already have. All the code is 100% unit-tested, as well as build tested for all
  supported Python versions. Comparison This is based on Java''s native TemporalAdjuster
  interfaces, but I found no similar library/functionality for Python.'
Title: 'Introducing Temporal Adjusters: Simplify Time Series Adjustments in Python!'
---
Author: u/ltlbwu
Content: 'Like the title said. I created an API fro apkpure.com . I was creating a
  script to automate YouTube Revanced, but i couldn''t find anyway to download the
  apk. You can try out the app here: https://github.com/anishomsy/apkpure What My
  Project Does It allows you to download apk from apkpure . Users can easily fetch
  specific versions of Android apps programmatically. Target Audience it is a hobby
  project, anyone can use it Comparison I did not find any existing alternatives.
  So I created my own. The only other way was to download it manually which is very
  tedious. Please lmk how i can improve. Thank you'
Title: Created an Api for APKpure
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/ogMasterPloKoon
Content: 'What My Project Does Cloudflare offers a free SQLite based database D1.
  I needed it for some personal project so I thought of creating a very simple wrapper
  for it. D1py let''s you connect to D1 database in your cloudflare account and run
  SQL queries(CRUD operations). Target audience For those who need a simple wrapper
  for Cloudflare D1 API for their projects. Comparison Right now there are no Python
  wrappers or libraries for D1 yet.... that''s why I thought of creating one. It''s
  not perfect but it is my first attempt at writing a small library/package for doing
  a task. Source Repository: https://github.com/Suleman-Elahi/D1py Feel free to drop
  any suggestions. Thanks.'
Title: 'My first Python package, D1py: A very simple library to interact with Cloudflare
  D1 Database API'
---
Author: u/mutlu_simsek
Content: 'https://github.com/perpetual-ml/perpetual What My Project Does PerpetualBooster
  is a gradient boosting machine (GBM) algorithm which doesn''t have hyperparameters
  to be tuned so that you can use it without needing hyperparameter optimization packages
  unlike other GBM algorithms. Similar to AutoML libraries, it has a budget parameter
  which ranges between (0, 1) . Increasing the budget parameter increases predictive
  power of the algorithm and gives better results on unseen data. Start with a small
  budget and increase it once you are confident with your features. If you don''t
  see any improvement with further increasing budget , it means that you are already
  extracting the most predictive power out of your data. Target Audience The project
  is meant for production. You can replace hyperparameter packages plus other gradient
  boosting algorithms with PerpetualBooster. Comparison Other gradient boosting algorithms
  (XGBoost, LightGBM, Catboost) and most of the machine learning algorithms need hyperparameter
  optimization for the best performance on unseen data. But PerpetualBooster doesn''t
  have hyperparameters so it doesn''t need hyperparameter tuning. It has a built-in
  generalization algorithm and provides the best performance. The following table
  summarizes the results for the California Housing dataset: Perpetual budget LightGBM
  n_estimators Perpetual mse LightGBM mse Perpetual cpu time LightGBM cpu time Speed-up
  0.33 100 0.192 0.192 10.1 990 98x 0.35 200 0.190 0.191 11.0 2030 186x 0.45 300 0.187
  0.188 18.7 3272 179x'
Title: Perpetual - a self-generalizing, hyperparameter-free gradient boosting machine
---
Author: u/BluesFiend
Content: 'Just released v0.8.0 of fastapi_problem to provide problem details for FastAPI
  applications. Hoping it can provide value to some other peoples projects. Code:
  https://github.com/NRWLDev/fastapi-problem Docs: https://nrwldev.github.io/fastapi-problem/
  Pypi: https://pypi.org/project/fastapi-problem/ What My Project Does Provides a
  simple exception handler and an underlying exception class heirarchy to remove the
  need to think about error management in your FastAPI project, just raise errors
  as appropriate and let the handler deal with responses. Target Audience Web developers
  Comparison There was a previous project that supported RFC7807 but that is no longer
  maintained, and is also made obsolete by RFC9457. RFC9457 For anyone who does not
  make use of FastAPI, the underlying exception library has also been released, and
  can be used to implement handlers for any web framework you might be into. https://github.com/NRWLDev/rfc9457
  https://pypi.org/project/rfc9457/'
Title: Problem details for FastAPI applications (RFC9457)
---
Author: u/MaKaNuReddit
Content: 'When I was a beginner (or maybe still I am) I struggled a lot with pythons
  import function. Over the years I went over different approaches, how to handle
  imports and ended up using mostly exclusive poetry. I''ve met a lot of people struggling
  the same way, bit always could just explain very shortly my experience. I''ve now
  decided to write it down as a scenario, where I can show and explain my pitfalls:
  https://github.com/MaKaNu/pyimport-explained'
Title: I tried to explain python imports
---
Author: u/sonobanana33
Content: 'What My Project Does It is a CLI to get songs from ultimateguitar. How it
  looks like: https://youtu.be/Spm1IIaYo8Q I''ve only tried it on linux. Available
  in debian and pypi. Target audience For musicians who also use the terminal and
  who don''t especially like the ultimateguitar website. Comparison I''m not aware
  of other projects doing the same thing. Compared to the website, it can transpose
  and it is much faster. Source Project website: https://codeberg.org/ltworf/ultimateultimateguitar
  Out of date website (just here to avoid the post to be auto-removed): https://github.com/ltworf/ultimateultimateguitar'
Title: a new version of ultimateultimateguitar
---
Author: u/17thCurlyBrace
Content: 'is there a proposal for a shorter exception handling syntax for those very
  frequent cases where a library function doesn''t return "error value" like str.index
  ? something like instead of : try: i = my_str.index("sub", st, en) except ValueError:
  # if "sub" has not been found pass else: # do stuff with i (note that i usually
  want independent error handling here) something like this : i = my_str.index("sub",
  st, en) except ValueError -1 # or maybe even return here if i == -1: # also can
  return right away if i want to avoid an indent next # do stuff with i ... i suspect
  there might be something "un-pythonic" here in what i am imagining , but please
  forgive me if that''s the case . i am a fan of Python for many years , but haven''t
  really invested any time in learning the philosophy so i am interested in what the
  community thinks about this , how ok would such syntax be from the point of the
  "Python way" , and if there is such a proposal i would like to know if i can consider
  maybe voting on it somehow'
Title: how about one-line try-except statement ?
---
Author: u/BaggiPonte
Content: uv is the "pip but blazingly fast‚Ñ¢Ô∏è because it's written in rust" and is
  developed by the same folks that did ruff. In 0.2.11 they released an experimental/preview
  command of `uv add/remove` that adds a library to pyproject.toml. It's the first
  step to become a fully-fledged package manager! I noticed you can also manage python
  installations with uv using `uv toolchain` command (i.e. be like pyenv) and run
  tools (like a smaller version of pipx) with `uv run`. I'm genuinely excited about
  this, Python packaging is going to become such a smooth experience üòé Commands are
  in preview so expect missing stuff. (I bear no affiliation with astral) https://github.com/astral-sh/uv
Title: uv added experimental commands for `uv add/remove`
---
Author: u/dxtros
Content: 'Hi Python data folks, I am excited to share Pathway, a Python data processing
  framework we built for ETL and RAG pipelines. https://github.com/pathwaycom/pathway
  What My Project Does We started Pathway to solve event processing for IoT and geospatial
  indexing. Think freight train operations in unmapped depots bringing key merchandise
  from China to Europe. This was not something we could use Flink or Elastic for.
  Then we added more connectors for streaming ETL (Kafka, Postgres CDC‚Ä¶), data indexing
  (yay vectors!), and LLM wrappers for RAG. Today Pathway provides a data indexing
  layer for live data updates, stateless and stateful data transformations over streams,
  and retrieval of structured and unstructured data. Pathway ships with a Python API
  and a Rust runtime based on Differential Dataflow to perform incremental computation.
  All the pipeline is kept in memory and can be easily deployed with Docker and Kubernetes
  (pipelines-as-code). We built Pathway to support enterprises like F1 teams and processors
  of highly sensitive information to build mission-critical data pipelines. We do
  this by putting security and performance first. For example, you can build and deploy
  self-hosted RAG pipelines with local LLM models and Pathway‚Äôs in-memory vector index,
  so no data ever leaves your infrastructure. Pathway connectors and transformations
  work with live data by default, so you can avoid expensive reprocessing and rely
  on fresh data. You can install Pathway with pip and Docker, and get started with
  templates and notebooks: https://pathway.com/developers/showcases We also host demo
  RAG pipelines implemented 100% in Pathway, feel free to interact with their API
  endpoints: https://pathway.com/solutions/rag-pipelines#try-it-out We''d love to
  hear what you think of Pathway!'
Title: Pathway - Build Mission Critical ETL and RAG in Python (used by NATO, F1)
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/marcogorelli
Content: 'In a few weeks, Polars 1.0 will be out. How exciting! You can already try
  out the pre-release by running: ``` pip install -U --pre polars ``` If you encounter
  any bugs, you can report them to https://github.com/pola-rs/polars/issues , so they
  can be fixed before 1.0 comes out. Release notes: https://github.com/pola-rs/polars/releases/tag/py-1.0.0-alpha.1'
Title: Polars 1.0 will be out in a few weeks, but you can already install the pre-release!
---
Author: u/Affectionate_Sky9709
Content: There's a promotion right now to try PyCharm, get a 30% discount, and 100%
  of what you pay goes directly to the Django Software Foundation, which maintains
  Django and keeps it free for everyone. https://jb.gg/2atgzm I hope this kind of
  post is allowed.
Title: Try PyCharm (30% off!) and they donate 100% to the Django Software Foundation
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/bleeddonor
Content: Python gives you wings, yes, but you used to have to wear aviator glasses
  to get through the docs on a bright display. No more. :)
Title: Python 3.12 docs include built-in support for themes, including a dark theme!
---
Author: u/Spindelkryp
Content: Heya, I have recently integrated Ruff in the Bazel monorepo of my company.
  The results were quite impressive, it takes around ~100ms to analyze and apply format
  / lint results to 1.1k python files. Integration with Bazel, however, was not exactly
  painless so I wrote a small guide for it as well as an example project. . Hope it
  helps someone! What My Project Does Guide on how to setup Ruff linting for Bazel
  based Python projects Target Audience Maintainers of large Python repos Source code
  How-to guide Source code
Title: Linting Python Monorepo with Bazel and Ruff
---
Author: u/abhi_uno
Content: 'Hello Python developers! I''m excited to announce the release of VidGear
  v0.3.3 , which brings official support for the libcamera backend in its PiGear API
  ! This update enhances the capabilities of Raspberry Pi Camera Modules and provides
  limited USB camera support. More about PiGear: PiGear is a specialized API optimized
  for Raspberry Pi üçá Boards, offering comprehensive support for camera modules (e.g.,
  OmniVision OV5647 Camera Module, Sony IMX219 Camera Module) and limited compatibility
  for USB cameras. PiGear implements a seamless and robust wrapper around the Picamera2
  Python library, simplifying integration with minimal code changes and ensuring a
  smooth transition for developers already familiar with the Picamera2 API. PiGear
  leverages the libcamera API under the hood with multi-threading, providing high-performance
  üî•, enhanced control, and functionality for Raspberry Pi camera modules. PiGear handles
  common configuration parameters and non-standard settings for various camera types,
  simplifying the integration process. PiGear currently supports PiCamera2 API parameters
  such as sensor, controls, transform, and format, with internal type and sanity checks
  for robust performance. While primarily focused on Raspberry Pi camera modules,
  PiGear also provides basic functionality for USB webcams (only with Picamera2 API),
  along with the ability to accurately differentiate between USB and Raspberry Pi
  cameras using metadata. PiGear seamlessly switches to the legacy picamera library
  if the Picamera2 library is unavailable, ensuring seamless backward compatibility.
  PiGear also provides a flexible multi-threaded framework around the complete picamera
  API, allowing developers to effortlessly exploit a wide range of parameters, such
  as brightness, saturation, sensor_mode, iso, exposure, and more. Furthermore, PiGear
  supports the use of multiple camera modules, including those found on Raspberry
  Pi Compute Module IO boards and USB cameras (only with Picamera2 API). We''re eager
  to see the innovative projects you''ll create with PiGear! For more details and
  to get started, check out our GitHub repository . Happy coding! Feel free to ask
  any questions or share your feedback below. Let''s discuss and innovate together!
  üöÄ'
Title: My library VidGear `v0.3.3` - brings libcamera API Support to python.
---
Author: u/antvas
Content: 'https://deviceandbrowserinfo.com/learning_zone/articles/detecting-headless-chrome-selenium-2024
  TL;DR The 4 techniques are the following: Using the user agent HTTP headers or with
  navigator.userAgent in JS to detect user agents linked to Headless Chrome: is Mozilla/5.0
  (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/126.0.6478.114
  Safari/537.36 Similarly, by detecting the presence of the HeadlessChrome substring
  in the sec-ch-ua header By detecting if navigator.webdriver = true in JavaScript
  By detecting the side effects of CDP (Chrome DevTools Protocol) (detailed in the
  article)'
Title: How to detect (modified|headless) Chrome instrumented with Selenium (2024 edition)
---
Author: u/sagunsh
Content: What My Project Does It s a simple web analytics app that tracks visitors
  in your website. I am using ip-api.com for geolocation and uap-python library for
  parsing user agent. At the moment, it simply logs these information to a sqlite
  database. Target Audience Anyone who is learning Python and more specifically Fast
  API and want to try building some projects. The code is available on github so feel
  free to explore, add features. Comparision Having used Django and Flask in the past,
  I made this project as a way to learn and to explore about Fast API. For a more
  sophisticated/paid alternative, check out Google Analytics, Plausible, etc. Source
  Code https://github.com/sagunsh/webanalytics
Title: I made a simple web analytics app using Fast API
---
Author: u/fesch2
Content: 'What my project does discover-plugins is a simple CLI tool that lets you
  list and filter plugins entrypoints installed into a python environment. I recently
  had to track down a bug that I ultimately resulted from a plugin I had installed
  into my environment.  To my surprise, there was no easy way to list which kind of
  plugins were installed, so I decided to build my own tool. Target Audience discover-plugins
  is intended as a debugging tool for those times when you are not quite sure which
  plugins are currently part of your python environment. Installation pipx install
  discover-plugins Usage Find all installed plugins related to pytest (the relevant
  group name is pytest11 ): discover-plugins --group pytest11 The tool defaults to
  use the first python interpreter on your path, you can optionally specify which
  interpreter to use with the --interpreter flag. The output will list all entrypoints
  belonging to the pytest11 group. For example, if you had installed a single pytest
  plugin ( pytest-aws-apigateway ) the output would look like this: { "pytest11":
  [ { "name": "pytest_httpx", "group": "pytest11", "value": "pytest_httpx" }, { "name":
  "anyio", "group": "pytest11", "value": "anyio.pytest_plugin" }, { "name": "pytest-aws-apigateway",
  "group": "pytest11", "value": "pytest_aws_apigateway.plugin" } ] } Links Link to
  GitHub: https://github.com/felixscherz/discover-plugins PyPI: https://pypi.org/project/discover-plugins/
  Let me know if the tool helped you out! Cheers!'
Title: discover-plugins - track which plugins are installed into your python environment
---
Author: u/homelander_30
Content: I guess the title explains it all, I'm looking for some personal projects
  to work or contribute on and would be really helpful if anyone is looking for a
  dev. I did look upon some open-source projects but they were too advanced and out
  of scope for me so I just wanna start small and learn.
Title: Is anyone here looking for a developer to contribute to your personal projects?
---
Author: u/Penny-loafers
Content: I put this quiz together to help create conversation for interns and new
  python developers at my company. Its based on the content from one of my favourite
  books ( Fluent Python ). I hope you enjoy it! Quiz
Title: I made a little Python quiz for interns and new Python developers at my company
---
Author: u/pdfisk
Content: 'Python is one of the world''s most popular programming languages and the
  web is the most ubiquitous application platform. There are several projects which
  aim to enable Python to run in web browsers. Brython is an implementation of Python
  3 written in JavaScript. Skulpt is an implementation of Python 2/3 written in JavaScript.
  PyScript is an implementation of Python 3 written in WebAssembly. Transcrypt is
  a Python to JavaScript compiler - unfortunately, the project seems to have been
  abandoned. Batavia is a Python virtual machine written in JavaScript - unfortunately,
  the project seems to have been abandoned. Finally, I have created VistaPython which
  is also intended to run Python 3 in web browsers but by using a bytecode interpreter
  written in JavaScript. Each design has strengths and weaknesses: Both Brython and
  Skulpt use hand-written Python parsers which are difficult to maintain. VistaPython
  uses a parser generator, Antlr , to automatically generate the JavaScript code for
  the parser. The parser can be updated to match the latest Python version by simply
  running a script. Also, both Brython and Skulpt generate JavaScript code which is
  then evaluated. In VistaPython, the compiler produces a "code object" which is then
  executed using the bytecode interpreter. The first approach will result in faster
  code whereas the second approach can be more flexible for code stepping, etc. PyScript
  is based on Pyodide which is a port of CPython to WebAssembly. PyScript can be upgraded
  the latest Python release by recompiling the latest CPython sources. Its main disadvantage
  is that it is very heavy to load and seems to run poorly on mobile devices. In VistaPython,
  the load profiles are: vm.js (Python virtual machine) 761kb Python parser 368 kb
  Mobile client GUI 2.4 Mb Desktop client GUI 2.9 Mb Compiled applications can be
  run using only the Python virtual machine (761kb). The design goal of VistaPython
  is to be able to load compiled applications from a database and run them quickly
  on any web device.'
Title: Running Python in Web Browsers
---
Author: u/SuccessfulLiving757
Content: I made a cool tool with python named Cookie Monster (not the one from sesmene
  street). It fetches cookies from a website and it is kinda broken... you can install
  it from https://sojoyork.github.io ! And yes it is one of my best python projects!
  I hope you like it.! And the GitHub repository is https://github.com/sojoyork/sojoyork.github.io
  ! (also am new to reddit)
Title: cool tool made with python
---
Author: u/SAV_NC
Content: 'Web Scraper Script What My Project Does This project scrapes websites to
  extract and display titles and links of articles. It processes multiple websites
  in parallel, fetching and parsing content to provide a consolidated list of articles
  with their full URLs. Target Audience Home users, researchers, and web enthusiasts
  who need to gather information from multiple websites quickly and efficiently. Features
  Parallel Processing : Uses ThreadPoolExecutor to fetch multiple websites concurrently,
  speeding up the scraping process. Error Handling and Logging : Provides detailed
  logging for debugging and retry mechanisms for robustness. Full URL Extraction :
  Ensures that all extracted links are complete URLs, enhancing usability. Customizable
  Headers : Allows customization of HTTP headers to mimic different browsers. Script
  Overview The script consists of several key components: Fetching URLs The script
  fetches content from the given URLs using the requests library. It includes retry
  logic with exponential backoff to handle transient errors. Parsing Content The script
  uses BeautifulSoup to parse the fetched HTML content and extract article titles
  and links. It ensures that the links are converted to full URLs using urljoin .
  Concurrent Execution The script employs ThreadPoolExecutor to fetch and parse content
  from multiple websites in parallel, improving efficiency. Access the Script You
  can access the script on GitHub here: Web Scraper Script on GitHub How to Use Install
  Dependencies : Ensure you have requests and beautifulsoup4 installed: pip install
  requests beautifulsoup4 Run the Script : Provide the URLs of the websites you want
  to scrape as arguments: python3 web-scraper.py https://yahoo.com https://sports.yahoo.com
  Conclusion This web scraper script is designed to be robust, efficient, and easy
  to use. It handles multiple websites in parallel, provides detailed logging, and
  ensures full URL extraction for all links. Ideal for users who need to quickly gather
  and consolidate information from various sources.'
Title: A simple website scraper script
---
Author: u/bolt_runner
Content: What are some software projects written in python that are well-structured
  and use good code design practices that are worth spending time to study?
Title: Open source Python projects with good software design that is worth studying
---
Author: u/muditjps
Content: 'Hi r/Python , This project is for a Streaming ETL problem statement for
  Fraud-detection/Log Monitoring use-case. Here''s a link to the blog explainer: https://pathway.com/developers/templates/kafka-etl
  GitHub Repo link: https://github.com/pathwaycom/pathway/tree/main/examples/projects/kafka-ETL
  What the Project Does Let''s say we''re monitoring logs from servers in New York
  and Paris. The logs have different time zones so you need to unify these different
  time zones into a single format to maintain data integrity. Now, Kafka is a popular
  ETL tool but it''s usable only in Java/Scala. Target Audience This is mostly for
  Python developers/data scientists/ML engineers and people who work on Fraud Detection
  or ETL. Comparison This project leverages Pathway, a Python ETL framework powered
  by an underlying Rust engine that surpasses Flink/Kafka in benchmarks. With this
  Pythonic framework we: Extract data streams from Kafka using built-in Kafka input
  connectors. Convert times with varying time zones into unified timestamps the datetime
  module. Load the final data stream back into Kafka. The entire script is available
  as an app template on the repo, which can be run via Docker in minutes. Open to
  your feedback/questions!'
Title: Log Monitoring with Kafka ETL using Python via Docker and Pathway
---
Author: u/sonobanana33
Content: 'I made a minor bugfix release of localslackirc https://codeberg.org/ltworf/localslackirc
  It can be installed via apt or ran from sources. No pypi package, sorry. What My
  Project Does After configuring it with a token from slack, it creates a local IRC
  server that bridges with slack. It supports threads, sending files. It doesn''t
  support reactions. It supports muting @here notifications from certain users or
  certain channels. It allows to silently leave a channel, but rejoins it if the user
  is personally mentioned there. Target Audience Mostly people who have to use slack
  for work and would prefer IRC. Comparison I am not aware of a project doing the
  same thing. I know weechat has a slack plugin, but that''s slightly different. I
  don''t use weechat and I wanted to keep using my IRC client. out of date link to
  avoid the post from being removed: https://github.com/ltworf/localslackirc'
Title: localslackirc - bridge slack and IRC
---
Author: u/FuturesBrightDavid
Content: Hi, I'm trying to find a Python community in Amsterdam in The Netherlands.  There
  used to be an active MeetUp group and Slack , but there has been little to no activity
  on either in a long, long time. Pythonistas in my city, what social / networking
  events or activities are there around here? Additionally, would anyone be interested
  in reviving the Python MeetUps in Amsterdam?
Title: Python community in Amsterdam, The Netherlands
---
Author: u/rnv812
Content: 'Hi, recently I created event generator in Python called Eventum . Here is
  a link to website: https://eventum-generatives.github.io/Website/ And the main repo:
  https://github.com/Eventum-Generatives/EventumCore What My Project Does It can be
  used in task like: Generation of datasets Simulation of processes in real time Filling
  different systems with demo data Testing on arbitrary data and stress testing Target
  Audience This generating tool is mostly for developers and people who work with
  data. It is also very near to ELK stack, OpenSearch and SIEM systems like Splunk
  . But you can use it as you want :) Comparison There is a project Eventgen developed
  by Splunk, but Eventum has next advantages over it: More rich events scheduling
  Extended functionality in event templates More parametrizable configurations Has
  content developing tools (UI for visualization time distributions and rendering
  templates)'
Title: 'Eventum: Flexible event generator'
---
Author: u/RitvikTheGod
Content: Guys, I recently released my first (in a while) open-source project wrapper
  on Telegram Bot API . I call it robogram and when I was developing in Python, I
  had a use case to send notifications from Raspberry Pi to my iPhone via Telegram
  . After searching online, I found no minimalist wrapper in Python 3+ to send messages
  via Bot API. So, I decided to create one :-) What My Project Does Minimal Wrapper
  around the Telegram Bot API. It's only dependency is requests in Python which is
  ubiquitous. It allows to retrieve info on Bot, or to send messages to users via
  personal chat, channel, or group. Target Audience Toy project I just came up with,
  after realizing no solution out there was best fit for me. But I have deployed this
  on production for personal project, and it's for sure production-ready. Target audience
  here would be other developers who are on Telegram and looking to leverage Bot API
  to facilitate the sending of messages or notifications to an audience on Telegram.
  Comparison Some packages out there are only async support, or only work on Python
  2 (actually I found one with some popularity that doesn't work in Python 3+ at all),
  or are dependency- or code- heavy and can introduce code bloat, especially to small,
  personal projects. As someone working on a personal project myself, I wanted a lightweight
  solution that only used minimal dependencies such as requests for making API requests.
  So, since I could not find one out there in wild, I decided to create my own! --
  Interested to get your thoughts, if anyone likes it I will be glad to feedback.
  https://github.com/rnag/robogram
Title: Robogram - Minimal Wrapper for Telegram Bot API in Python
---
Author: u/No_Coffee_9879
Content: 'Hey everyone, I just wanted to share a project I''ve been working on called
  Lambda Forge . It''s a tool designed to simplify the deployment and management of
  AWS Lambda functions. If you''re like me and spend a lot of time working with serverless
  architecture, you might find it pretty useful. What My Project Does Lambda Forge
  helps you deploy and manage AWS Lambda functions with ease. One of its standout
  features is the WebSocket connection for hot reloading of local code. It uses MQTT
  over Websockets to proxy requests to a local server, making development seamless.
  No more redeploying code just to see if your changes work! Target Audience This
  project is meant for developers who work with AWS Lambda in both production and
  development environments. Whether you''re a seasoned backend engineer or just getting
  started with serverless, Lambda Forge can help streamline your workflow. Comparison
  Compared to other deployment tools, Lambda Forge focuses on enhancing the development
  experience with hot reloading capabilities. Many existing tools require a full redeployment
  for changes to take effect, which can be time-consuming. Lambda Forge''s WebSocket
  integration saves time by allowing you to see changes in real-time without redeployment.
  If you''re interested, you can check out the documentation here: Lambda Forge Docs
  And if you want to dive into the code or contribute, here''s the GitHub repo: Lambda
  Forge on GitHub I‚Äôd love to hear your thoughts and feedback.'
Title: 'Introducing Lambda Forge: Simplifying AWS Lambda Deployment and Development!'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/Active-Fuel-49
Content: Mirascope is a Python library that lets you access a range of Large Language
  Models, but in a more straightforward and Pythonic way. https://www.i-programmer.info/news/90-tools/17275-mirascope-pythons-alternative-to-langchain.html
Title: Mirascope-Python's Alternative To Langchain
---
Author: u/jrbourbeau
Content: Hi All, I wanted to try to speed up some Python code with a GPU recently
  and was pretty shocked at how difficult it is to properly set up and configure things.
  I have lots of experience in the PyData space, but am definitely not a cloud devops
  expert. So some colleagues and I wrote a decorator that automatically sets up a
  cloud VM, runs the decorated function, and returns the function‚Äôs result back locally
  to my laptop. Here‚Äôs an example that trains a PyTorch model on an NVIDIA A10 GPU
  on AWS. The Coiled Function API is nice because I didn‚Äôt have to build any Docker
  images, muck around in the AWS console, or do anything special to set up a cloud
  GPU. That said, there are definitely tradeoffs here. We optimized for privacy and
  no standing costs, so it takes ~1-2 minutes to fully spin up VMs (no warm pool of
  VMs waiting). We also only run on AWS/GCP/Azure so this doesn‚Äôt help with on-prem
  workloads. I‚Äôm definitely biased as I work at Coiled, but think this is a simple
  way to run Python on cloud hardware (especially for folks without a lot of cloud
  experience). I‚Äôm curious to hear from folks here. Do you have a favorite way to
  run Python code on the cloud? What do you like about your current setup? For example,
  ergonomics, performance, something else?
Title: Python on Cloud GPUs
---
Author: u/Knockoutpie1
Content: Hey everyone, looking for some input. For work I‚Äôve worked on web scraping
  for prices to see if my components are adequately priced on the internet compared
  to competitors. I can use this for protein prices as a personal project. I have
  experience now with Beautiful Soup, Selenium, and Excel Power BI. What route should
  I go? Should I only pull pricing from Amazon? Or should I do Amazon and the manufacturer
  site to see which is better pricing? Ideas would be great. Should be a fun project.
  If I go with beautiful soup, there‚Äôs no UI and I can print all to terminal If I
  use selenium, I can use UC to pass anti-bot measures and also print to terminal,
  but it will open a browser window for each price scrape. If I use excel power BI,
  I‚Äôll just load data to a worksheet and pricing will update at the price of a button.
Title: Web scraper for protein prices
---
Author: u/willm
Content: Textual Serve ( https://github.com/Textualize/textual-serve ) is a project
  which serves TUIs (built with Textual) in the browser. This is self-hosted, so you
  don't need to rely on any external service.
Title: Textual Serve - Serve TUIs in the browser
---
Author: u/Martynoas
Content: This article explores how to manage Python project environments and dependencies,
  as well as how to structure projects effectively.
Title: Python Project Management Primer
---
Author: u/Fun-Asparagus-837
Content: 'Hi there ! I''m thinking about buying an ARM windows laptop with the new
  Qualcomm chips. They will replace the x86 so I was wondering : Will There be a massive
  risk of non-compatibility of Python packages ? I guess they are made for x86 but
  I don''t know if it''s possible to work with them with an ARM based CPU. Edit :
  Had a great deal on the ideapad pro 5 gen 9 so I went for it. Glad to have these
  incredible specs and decided to rely on x86 chip for the moment, because I wanted
  to avoid all the early-adoption problems'
Title: Python on ARM laptops
---
Author: u/SAV_NC
Content: 'What my project does Ranks videos based on overall quality. Takes into account
  multiple metrics to determine what quality is the best. Target audience Home users
  / Video enthusiasts Comparison This project uses the following metrics to rank videos:
  Resolution : Higher resolution videos are preferred. Frame Rate : Videos with higher
  frame rates are ranked higher. Bitrate : Higher bitrate often indicates better quality.
  Codec : Some codecs provide better quality than others at the same bitrate. The
  script extracts these metrics using ffprobe from the FFmpeg suite and sorts the
  videos accordingly. Here''s how the metrics are used: Resolution : The script first
  compares the resolution (width x height) of the videos. Higher resolutions are ranked
  higher. Frame Rate : If two videos have the same resolution, the one with the higher
  frame rate is ranked higher. Bitrate : For videos with the same resolution and frame
  rate, the bitrate is used to determine the quality. Codec : In case of a tie in
  all other metrics, the codec is considered to break the tie. Access the Script You
  can access the script on GitHub here'
Title: Video Quality Ranker
---
Author: u/lutipri
Content: Brandt Bucher talks on JIT compiler for Python at CPython Core Developer
  Sprint. Brandt is  a member of the Faster CPython project , which is working on
  making the reference implementation of the language faster via a variety of techniques.
  https://www.youtube.com/watch?v=HxSHIpEQRjs
Title: A JIT compiler for CPython
---
Author: u/Significant_Water_28
Content: 'little challenge for you, how fast can this be pushed in python? This function
  takes a numpy.ndarray / 2d numpy array, and returns the updated array. iv updated
  this function several times, this i the fastiest so far. numba jit dosn''t like
  the double roll, and its faster than for loops in jit. def conways_game_of_life(board:numpy.ndarray):
  n_neighbour = sum(numpy.roll(numpy.roll(board, i, 0), j, 1) for i in (-1, 0, 1)
  for j in (-1, 0, 1) if (i != 0 or j != 0)) board[(n_neighbour<2) | (n_neighbour>3)]
  = 0 board[(n_neighbour==3)] = 1 return board'
Title: Conway's game of life. can you find an optimization?
---
Author: u/DrumcanSmith
Content: What my project does Performs OCR on scanned Books using Microsoft Azure
  Document Intelligence read Target audience People who are unsatisfied with traditional
  OCR People who want to add clear text to the original PDF and not just extract the
  text. People who want to archive documents at best quality. Comparasion In my use
  case traditional OCR was near to useless. Tesseract was meh, Google API didn't process
  large files. Document Intelligence takes up to 500MB (although in practice a little
  less), and is possible to OCR 400-600 pages over books in batch by dividing and
  merging the source and results locally by only a few chunks. It doesn't provide
  the text in PDF form so that was my reason to start this project. Still in alpha
  and in separate modules and a lot of rigid coding, but it is working fine for my
  original task so thought maybe I'd showcase it. https://github.com/DesertDoggy/json3pdf
Title: 'json3pdf : Batch OCR for high quality document archiving.'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!'
---
Author: u/Balance-
Content: 'For anyone on a (new) Windows on Arm system, I found this great repo with
  Arm64 Windows wheels: https://github.com/cgohlke/win_arm64-wheels Highlights 256
  packages for Python 3.12 Built with numpy 2 if possible Scipy stack: numpy with
  OpenBLAS, scipy, matplotlib, Pandas, scikit-learn, scikit-image, numba, etc. GIS
  stack: GDAL, netCDF4, pyproj, Shapely, rasterio, basemap, Fiona, etc. Image IO:
  Imagecodecs, Pillow, OpenImageIO, OpenEXR, pylibCZIrw, etc. Noteworthy: Pytorch,
  Kivy, opencv_python_headless, pymol-open-source, pywin32'
Title: Experimental Python Wheels for Windows on ARM64
---
Author: u/the1024
Content: https://www.gauge.sh/blog/parsing-python-asts-20x-faster-with-rust
Title: Parsing Python ASTs 20x faster with Rust
---
Author: u/CompositePrime
Content: I should have saved the post but maybe 4-6 months ago I was reading a post
  (I am pretty sure it was in r/Python ) where someone created a package that creates
  a visual for data contained within a list. For example, let‚Äôs say I have a data
  frame where one of the columns is named ‚Äúcolors‚Äù and each record contains a list
  of colors. One record might be [black,blue,yellow] another record might have [blue,yellow,black].
  The visual had two parts where the top was a column chart to show the frequency
  of the list combinations and below the column chart was more of a table that showed
  each ‚Äúcolor‚Äù as one column and then across the row for each color and under the
  columns from the chart above was an indicator of sorts that would be greyed out
  of the color for that row was not in the corresponding columns list and highlighted
  another color of it was. Anyways this is probably a long shot but either the package
  or the name of this visual would be super helpful. Thanks python community!
Title: Trying to find this package
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Wednesday Daily Thread: Beginner questions'
---
Author: u/tavallaie
Content: I am nominating myself for the PSF Board of Directors! üåü Check out my latest
  blog post to learn more about my journey, my commitment to the Python community,
  and my application for an OFAC license to expand educational activities in restricted
  areas. Read more at my blog
Title: I am Nominating Myself for PSF Board of Directors
---
Author: u/INSERT_KEYWORD
Content: I'm going to show you how to get Scrapegraph AI up and running, how to set
  up a language model, how to process JSON, scrape websites, use different AI models,
  and even turning your data into audio. Sounds like a lot, but it's easier than you
  think, and I'll walk you through it step by step. https://www.scrapingbee.com/blog/scrapegraph-ai-tutorial-scrape-websites-easily-with-llama-ai/
Title: Scrapegraph AI Tutorial; Scrape Websites Easily With LLaMA AI
---
Author: u/Madlynik
Content: I will buy a laptop for coding purposes but just started learning and practising
  Python using Pyecharm. What are the software requirements that lead to hardware
  specs a general Python coder must look into? Please suggest the hardware setup within
  a pocket friendly budget.
Title: What are the hardware requirements in a laptop to run Python + Future AI based
  projects?
---
Author: u/Benoss
Content: End goal is to produce PDF using external data and a template. Needs to support
  Jinja tags, conditionals and loops. Using https://github.com/Kozea/WeasyPrint and
  https://github.com/pallets/jinja as base stack (Open to other suggestions) I was
  thinking of building some base HTML templates but would be awesome if I could find
  a visual HTML editor that could produce code 100% compatible with Weasyprint so
  that end users can build templates by themselves or modify existing ones. Could
  be Wysiwyg based using https://editorjs.io or https://github.com/slab/quill or more
  advanced web builders like https://github.com/GrapesJS/grapesjs Anybody built something
  similar?
Title: Looking for a good WYZIWIG/visual editor to go with with Jinja + Weasyprint
---
Author: u/commandlineluser
Content: NumPy 2.0.0 is the first major release since 2006. https://github.com/numpy/numpy/releases/tag/v2.0.0
  https://numpy.org/devdocs/release/2.0.0-notes.html https://numpy.org/devdocs/numpy_2_0_migration_guide.html
Title: NumPy 2.0.0 is the first major release since 2006.
---
Author: u/tuple32
Content: 'What My Project Does While looking for task queues, I found that there are
  many options available in the Python ecosystem, making it really hard to choose
  the right one. To get a sense of how each library performs and to help make an informed
  decision, I conducted a load test on some of the most popular ones: Python-RQ, ARQ,
  Celery, Huey, and Dramatiq. Target Audience I hope my findings can help those who
  are also looking for a task queue solution in Python. Comparison Most articles out
  there seem to focus on comparing the features of these libraries but rarely discuss
  performance. While there could be a lot of improvements on my tests, I think it
  still provide some different insights into how each library handles heavy loads
  and concurrency. Links: You can read  my findings on my blog Check out the source
  code: on Github Thanks'
Title: Load Tests Python Task Queues
---
Author: u/zerojames_
Content: What My Project Does Aurora is a fast, extensible Python static site generator.
  With Aurora, I can generate my personal website (~1,700 files, with multiple layers
  of jinja2 templates for each page) in < 4 seconds. Aurora generated 292,884 pages
  from a Hacker News post dataset in 2m:20s. Aurora supports incremental static regeneration,
  where pages can be regenerated in under 400ms, with hot reloading. I documented
  how this works on my blog . Target Audience I'm building Aurora to help me run my
  website, but it is built to be general so you can use it for your own projects.
  I would love feedback! I want this to be a tool for running static sites in production,
  at scale. Comparison Aurora is inspired by the folder structure of Jekyll, but is
  written in Python. It has a hooks API that lets you define custom Python functions
  that manipulate the state of a page. This allows you to implement custom behaviours
  in isolation of the engine itself. I use this to open link previews from a cache
  that I plan to use on my website, among other things.
Title: 'Aurora: An extensible Python static site generator'
---
Author: u/jmakov
Content: Imagine having the option to write code once and run on multiple cores or
  on the cluster as part of the std lib. I know there's a company (currently) behind
  it - Anyscale, also not sure what the license is but other than that, what's holding
  the Py community back?
Title: 'Suggestion: make ray.io a part of Python''s std lib'
---
Author: u/green9cactus
Content: I am new to python and currently working on simple 3 layer web application
  - frontend - ? backend API to fetch data from DB - python DB - cloud This application
  has main intention to fetch data from DB, display graphs , table format data etc.  also
  perform some combination analysis of data and show on UI. Which less complex and
  stable technology I should prefer for frontend ? python flask, Bulma, Mesop by google
  or any other ? Thank you.
Title: Advise on choosing UI technology with Python
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Tuesday Daily Thread: Advanced questions'
---
Author: u/ajpinedam
Content: 'Linting is essential to writing clean and readable code to share with others.
  A linter, like Ruff, is a tool that analyzes your code and looks for errors, stylistic
  issues, and suspicious constructs. Linting allows you to address issues and improve
  your code quality before you commit your code and share it with others. Ruff is
  a modern linter that‚Äôs extremely fast and has a simple interface, making it straightforward
  to use. It also aims to be a drop-in replacement for many other linting and formatting
  tools, such as Flake8, isort, and Black. It‚Äôs quickly becoming one of the most popular
  Python linters. Installing Ruff Now that you know why linting your code is important
  and how Ruff is a powerful tool for the job, it‚Äôs time to install it. Thankfully,
  Ruff works out of the box, so no complicated installation instructions or configurations
  are needed to start using it. Assuming your project is already set up with a virtual
  environment, you can install Ruff in the following ways: ```bash $ python -m pip
  install ruff ``` You can check that Ruff installed correctly by using the ruff version
  command: ```bash $ ruff version ruff 0.4.7 ``` Linting Your Python Code While linting
  helps keep your code consistent and error-free, it doesn‚Äôt guarantee that your code
  will be bug-free. Finding the bugs in your code is best handled with a debugger
  and adequate testing, which won‚Äôt be covered in this tutorial. Coming up in the
  next sections, you‚Äôll learn how to use Ruff to check for errors and speed up your
  workflow. Checking for Errors ```bash $ ruff check one_ring.py:1:8: F401 [*] `os`
  imported but unused one_ring.py:10:12: F821 Undefined name `name` Found 2 errors.
  [*] 1 fixable with the `--fix` option. ``` Success! Ruff found two errors. Not only
  does it show the file and line numbers of the errors, but it also gives you error
  codes and messages. In addition, it lets you know that one of the two errors is
  fixable. Great! You can tell Ruff to fix errors by applying the --fix flag. Here‚Äôs
  what happens when you follow its suggestion: ```bash $ ruff check --fix one_ring.py:9:12:
  F821 Undefined name `name` Found 2 errors (1 fixed, 1 remaining). ``` You can find
  the rest of this Free tutorial here'
Title: 'Ruff: A Modern Python Linter for Error-Free and Maintainable Code'
---
Author: u/Latter-History-8053
Content: I am creating a Python program which models 3D shapes so that they can be
  saved and or interacted with (i.e. rotated). The process currently takes a while
  to render shapes consisting of multiple materials. The libraries being implemented
  are currently matplotlib and numpy. What would you advise for improving the rendering
  process (library choice etc)?
Title: Advice for creating 3D modelling program
---
Author: u/Severe_Inflation5326
Content: 'Pieshell is a Python shell environment that combines the expressiveness
  of shell pipelines with the power of python iterators. It can be used in two major
  ways: As an interactive shell replacing e.g. bash As an ordinary python module replacing
  e.g. subprocess.Popen Obligatory example: 140:/home/oven/pieshell >>> for x in ls(-a)
  | tr("s", "S"): ...   if x.endswith(''.py''): ...      print x ... Setup.py Source
  code: https://github.com/redhog/pieshell What the project does It''s a replacement
  for the subprocess module, and for bash as an interactive shell, and makes interacting
  with shell pipelines easier. Target Audience System administrators, system software
  developers, data scientists Comparison While os.system is very limited but easy
  to use, subprocess.Popen offers a lot of flexibility, but the interface is very
  low level. Any actual pipelining of multiple programs is pretty much required to
  be done by e.g. a bash process, constructing the pipeline as a shell script string.
  Further, interacting with standard in and standard out requires careful IO handling.
  Pieshell on the other hand lets you construct pipelines as python objects. Standard
  io from a pipeline can be handled using iterators or async iterators. Pieshell has
  full asyncio integration.'
Title: 'pieshell: python for shell scripting and as an interactive shell'
---
Author: u/Civil-Captain5676
Content: I was wondering recently about any startup and any coding language that how
  does they make money. So I was curious to know about Python which is widely used
Title: How does Python earn money? What would have been their business model?
---
Author: u/ltlbwu
Content: 'What My Project Does AutoReVanced is a Python script that automates downloading
  and patching APKs using ReVanced patches from ApkPure. It''s perfect for anyone
  wanting to patch their revanced app. Target Audience Suitable for a fun side project
  or hobbyists, AutoReVanced is designed for anyone wanting to customize Android apps
  with ReVanced patches. Comparison Unlike alternatives, AutoReVanced is automatic.
  GitHub: autorevanced'
Title: I created a script to automatically patch revanced
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Monday Daily Thread: Project ideas!'
---
Author: u/HistoricalCrow
Content: Hey all, my project abstract_factories is up to gauge interest and primarily
  feedback. The design goal is to make it easier to iterate on typical Content Creation
  pipeline tools (tool dev, rigging, validation, asset management etc) with a flexible
  framework to provide convenience, open and simple design and no dependencies (currently).
  It's an approach I've used a lot over the years and found it pretty versatile in
  production across numerous projects. Key features Auto-registration of matching
  items (types or instances) from any given path or python module. Simple or conditional
  item identifiers. Versioning. Recursive path searching (recursive module search
  in review). Dynamic resolving and importing modules in packaged (supports relative
  importing). Usage Examples There are a couple of simple examples given along with
  tests to cover all of the current features. What the project does It's a convenience
  package for creating scalable tools and frameworks using Abstract Factory design
  pattern. Target Audience Due to the solutions it's built for, it's aimed primarily
  at Technical Artists, Technical Animators, Pipeline and Tool Developers, but I'm
  interested in hearing about other possible applications. Comparison Compared to
  other Factory and Abstract Factory convenience packages, mine is based on the work
  from this GDC talk . The direct abstract-factories currently comes with a few more
  conveniences I've found useful during production. The idea stems from boiling down
  Pyblish to something that became a little more reusable when writing frameworks
  as opposed to being the framework. Suggestions, questions, comments etc welcome.
Title: abstract-factories - a simple framework for content creation pipelines
---
Author: u/knowsuchagency
Content: What My Project Does Upload any PDF and have it converted into a podcast
  episode with two or more speakers discussing its contents. https://github.com/knowsuchagency/pdf-to-podcast
  Target Audience Anyone, but other developers in-particular. The code is open-source
  on GitHub and there's a link to the source on https://pdf-to-podcast.com . I want
  the project to serve as an illustrative example of how to build useful things on
  top of LLMs with relatively little code. Comparison I just made this for fun. It's
  possible there are other similar projects
Title: 'Showcase: pdf-to-podcast.com -- Convert PDF''s to podcast episodes. Free and
  open-source :)'
---
Author: u/codes_astro
Content: Google Open sourced Mesop. Mesop is a Python-based UI framework that allows
  you to rapidly build web apps. Used at Google for rapid internal app development
  similar to Streamlit. find more here
Title: Have anyone tried google/mesop
---
Author: u/wildpantz
Content: 'Quick backstory: Upper floor of my house is sort of a man-cave until we
  decorate it, so during this time I have two PCs which I use to play games with a
  friend when we have extra time to waste. The other day I remembered the game mentioned
  in the title and we had lots of fun playing it (there''s 3 different games in this
  series). I decided I''d transfer the save file to my main PC so I can play when
  he''s not visiting and I quickly learned it''s an extremely annoying process to
  transfer save files across different PCs. Long story short, you need to find a proper
  registry key (which isn''t always located at same spot for some reason) and you
  need to locate a system.dat file also located in a folder that isn''t always in
  the same place. This process gets tedious pretty quick, so I decided to use the
  power of Python to make my life easier. What the project does: It''s essentially
  a CLI save handler for the game mentioned in the title. It has 5 slots where you
  can backup your current save or load the backup to the computer. It can also fix
  minor registry issues if needed. Target audience: Given that I''m about 20 years
  too late... I''d say mostly people with very slow PCs or people who like to inhale
  nostalgia. I learned a lot about using winreg and msvcrt and getch, so while I will
  likely get bored of the game in the coming weeks, I''m happy I learned something
  new in the meantime, plus maybe someone finds it useful! Source code: markomavrinac/yugioh_poc_save_handler:
  Yu-Gi-Oh! Power of Chaos save handler - A script to manage your save games across
  multiple computers (github.com)'
Title: I created Yu-Gi-Oh! Power of Chaos save handler
---
Author: u/jgloewen
Content: 'Streamlit is an open-source app framework that allows data scientists and
  analysts to create interactive web applications with ease. Using just a few lines
  of Python, you can turn data scripts into shareable web apps. And combined with
  a data visualization library like Plotly, you can create beautiful charts and maps
  with only a few lines of code. In this article, let me step you through how to use
  Streamlit to create a multi-page interactive application that visualizes Olympic
  medal data. The application will have three pages: an overview of medal counts,
  a country-specific analysis, and a choropleth map displaying global medal distributions.
  Let‚Äôs get to it! Link to free article HERE Github repo HERE'
Title: 'Tutorial: A Timely Python Multi-page Streamlit Application on Olympic Medal
  Winning Countries'
---
Author: u/Human_Dependent6814
Content: I have 4 years worth JVM languages (Java, Kotlin) and have a need to learn
  some Python.  What's a good resource to get up to speed quickly with idiomatic Python?
Title: Learning Python coming from a JVM background
---
Author: u/Specialist-Arachnid6
Content: Tempus is a calendar with horoscopes, reminders, etc made with PyQt6 What
  my Project does? Tempus is a desktop-based calendar management application built
  with PyQt6, allowing users to manage their todos, reminders, and special dates efficiently.
  It offers features like adding, editing, and deleting tasks and reminders, as well
  as marking dates as special. Tempus ensures users stay organized and never miss
  important events. Plus, it shows you how many days are remaining until a special
  day in the dashboard. Target Audience Well, anyone who uses a desktop calendar app
  I guess? Comparison I did some research and couldn't find good calendar apps made
  with PyQt6.  If you guys knows any, please mention it below and I'm sorry in advance.
  GitHub https://github.com/rohankishore/Tempus
Title: I made a cool calendar app with PyQt6
---
Author: u/JoachimCoenen
Content: 'What my project does It provides a fast pure-python implementation of an
  ordered, multi-valued dictionary. Target audience Python developers that need this
  kind of specialized functionality. This can be used in production. It has no dependencies.
  The code is unit-tested (almost fully, I''m working on it) It requires Python 3.12+
  Comparison Comparison to dict and OrderedDict dict and OederedDict are already ordered,
  but they only allow one value per key. You could use a defaultdict of lists, but
  then you have these disadvantages: you can end up with empty lists within the dict
  if you aren''t careful you lose the order of individual items within the dict: items
  = [(1, ''1''), (2, ''2''), (2, ''22''), (1, ''11'')] normal_dict = defaultdict(list)
  for key, value in items: normal_dict [key].append(value) om_dict = OrderedMultiDict(items)
  print(list(normal_dict .items)) # prints [(1, [''1'', ''11'']), (2, [''2'', ''22''])]
  print(list(om\_dict.items))     # prints [(1, ''1''), (2, ''2''), (2, ''22''), (1,
  ''11'')] iterating over all key/value pairs can be cumbersome as you need nested
  loops Comparison to omdict . OederedDict provides a (in my opinion) nicer interface
  with less surprising behavior or pitfalls. My implementation is also faster. e.g
  iterating over all items is ~5x faster. More info This started as a toy project,
  that later became useful to me, so I decided to cleanup the code, add tests, and
  publish it. from better_orderedmultidict import OrderedMultiDict omd: OrderedMultiDict[int,
  int] = OrderedMultiDict([(1,1), (2,2), (1,11), (2,22)]) for key in reversed(omd.unique_keys()):
  print(f"{key}: {omd.getall(key)}") # prints: # 2: [2, 22] # 1: [1, 11] print(omd.popfirstitem())  #
  prints: (1, 1) print(omd.poplast(2))  # prints: 22 for key in reversed(omd.unique_keys()):
  print(f"{key}: {omd.getall(key)}") # prints: # 2: [2] # 1: [11] Installation You
  can install Better-OrderedMultiDict using pip: pip install better-orderedmultidict
  Contributing If you have any suggestions or improvements for Better-OrderedMultiDict,
  feel free to submit a pull request or open an issue on the GitHub repository . I
  appreciate any feedback or contributions! Links Here''s the link to the GitHub repository:
  https://github.com/JoachimCoenen/Better-OrderedMultiDict Here''s the link to PyPi:
  https://pypi.org/project/better-orderedmultidict'
Title: Better-OrderedMultiDict - a fast pure-pyton implementation of an ordered multi-valued
  dictionary.
---
Author: u/Eggesalt
Content: As the title says, I cant decide what to use for rest api for mye summer
  project. I am uni student, so this project will only be very small scale project.
  I have made simpel rest apis in sll of them, but still cant decide which one to
  actuslly use for my project. Do anyone have any tips for which might be right one?
  A thing to consider for me answel is how easy it is to host.
Title: Cant decide between flask, django ninja or fastAPI for sideproject
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/inobody_somebody
Content: 'what my project does This project is built to solve the issue of LLM unable
  to produce relevant answers for information in a particular context. uses the information  to
  train the model and stored it in a database and uses  this database to get relevant
  answers from the Model. Target audiance This project is for people who want to train
  a LLM on a particular piece of information. comparison This model only gives answers
  for information regarding the data you provided in the file. It will not answer
  any other questions including formal greetings. GitHub link : https://github.com/dharmateja2810/RAG-Retrieval-Augmented-Generation-Model'
Title: Built a RAG ( Retrieval-Augmented Generation ) model using Gemini Api.
---
Author: u/LeastPrice8673
Content: Hi I‚Äôm looking for inspiration for some stupid python automation projects.
  If you have done something funny or stupid using python automation I would love
  to hear it.
Title: Python automation ideas
---
Author: u/guangrei
Content: 'Python is a great programming language, but sometimes the indentation can
  be terrible for some people (especially people with visual impairments). So i created
  Lython . What the project does: Lython replacing the Python indentation to lua-style
  code blocks. this is example lython code def test(num) for i in range(num) do if
  i == 0 then print("zero") elif i % 2 == 1 then print("odd") else print("even") end
  # if else end # for end # def test(10) for more info, please visit lython repo.
  Target audience: Peoples with visual impairments (especially) and Programmers who
  want to write python code with new experience (generally) Repo & Source code: guangrei/lython'
Title: Lua-style code blocks for Python
---
Author: u/LordOmbro
Content: 'well, kind of. I made Pilgram, an infinite idle RPG where your character
  goes on adventures and notifies you when stuff happens. What my project does The
  bot provides a text interface with wich you can "play" an MMO RPG, it''s basically
  an online idle adventure game Target audience It''s a toy project that i made out
  of boredom, also it sounded cool Comparison I never heard of anything like this
  except for some really old browser games. Maybe i''m just not informed. More info
  How is it infinite? The secret is AI . Every quest and event in the game is generated
  by AI depending on the demand of the players, so in theory you can go on an infinite
  amount of quests. Why did i call it an MMO? Because you can kind of play with your
  friends by creating & joining guilds and by sending gifts to eachother. There even
  is a guild leaderboard to see who gets the most points :) The interface is exclusively
  text based, but the command interpreter i wrote is pretty easy to integrate in other
  places, even in GUIs if anyone wants to try. I tried out a lot of new things for
  this project, like using ORMs, writing unit tests (don''t look at those, i kinda
  got bored after a short while), using AI & writing generic enough code that it can
  be swapped with any other implementation. I think most of the code i wrote is pretty
  ok, but you can tell me what to change & what to improve if you want. Links here''s
  the link to the code: https://github.com/SudoOmbro/pilgram if you wanna try out
  the version i''m running on my server start a conversation with pilgram_bot on Telegram,
  don''t expect a balanced experience at first since that was kind of the last of
  my problems lol'
Title: I made an MMORPG with Python & Telegram in 4 weeks
---
Author: u/MDTv_Teka
Content: 'Hey guys! I''m excited to introduce Temporal Adjusters, a new Python package
  designed to make time series adjustments easier and more efficient. If you work
  with time series data, you''ll find this tool incredibly useful for various temporal
  adjustments. What my project does Adjusters are a key tool for modifying temporal
  objects. They exist to externalize the process of adjustment, permitting different
  approaches, as per the strategy design pattern. Temporal Adjuster provides tools
  that help pinpoint very specific moments in time, without having to manually count
  days, weeks, or months. In essence, a Temporal Adjuster is a function that encapsulates
  a specific date/time manipulation rule. It operates on a temporal object (representing
  a date, time, or datetime) to produce a new temporal object adjusted according to
  the rule. Examples might be an adjuster that sets the date avoiding weekends, or
  one that sets the date to the last day of the month. Installation You can install
  Temporal Adjuster using pip: pip install temporal-adjuster Usage This package provides
  a set of predefined temporal adjusters that can be used to adjust a temporal object
  in various ways. For example: >>> from datetime import date, datetime >>> from temporal_adjuster
  import TemporalAdjuster >>> from temporal_adjuster.common.enums import Weekday >>>
  TemporalAdjuster.first_day_of_next_week(date(2021, 1, 1)) datetime.date(2021, 1,
  4) >>> TemporalAdjuster.last_day_of_last_month(datetime(2021, 1, 1)) datetime.datetime(2020,
  12, 31) >>> TemporalAdjuster.first_of_year(Weekday.SATURDAY, date(2021, 1, 1)) datetime.date(2021,
  1, 2) >>> TemporalAdjuster.nth_of_month(Weekday.SUNDAY, datetime(2021, 5, 1), 2)
  datetime.datetime(2021, 5, 9) >>> TemporalAdjuster.next(Weekday.MONDAY, datetime(2021,
  2, 11), 2) datetime.datetime(2021, 2, 15) Contributing If you have any suggestions
  or improvements for pynimbar, feel free to submit a pull request or open an issue
  on the GitHub repository as per the CONTRIBUTING document. We appreciate any feedback
  or contributions! Target audience This can be used in production. It has only one
  depedency, dateutils, which if you''re manipulating temporal objects you probably
  already have. All the code is 100% unit-tested, as well as build tested for all
  supported Python versions. Comparison This is based on Java''s native TemporalAdjuster
  interfaces, but I found no similar library/functionality for Python.'
Title: 'Introducing Temporal Adjusters: Simplify Time Series Adjustments in Python!'
---
Author: u/ltlbwu
Content: 'Like the title said. I created an API fro apkpure.com . I was creating a
  script to automate YouTube Revanced, but i couldn''t find anyway to download the
  apk. You can try out the app here: https://github.com/anishomsy/apkpure What My
  Project Does It allows you to download apk from apkpure . Users can easily fetch
  specific versions of Android apps programmatically. Target Audience it is a hobby
  project, anyone can use it Comparison I did not find any existing alternatives.
  So I created my own. The only other way was to download it manually which is very
  tedious. Please lmk how i can improve. Thank you'
Title: Created an Api for APKpure
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/ogMasterPloKoon
Content: 'What My Project Does Cloudflare offers a free SQLite based database D1.
  I needed it for some personal project so I thought of creating a very simple wrapper
  for it. D1py let''s you connect to D1 database in your cloudflare account and run
  SQL queries(CRUD operations). Target audience For those who need a simple wrapper
  for Cloudflare D1 API for their projects. Comparison Right now there are no Python
  wrappers or libraries for D1 yet.... that''s why I thought of creating one. It''s
  not perfect but it is my first attempt at writing a small library/package for doing
  a task. Source Repository: https://github.com/Suleman-Elahi/D1py Feel free to drop
  any suggestions. Thanks.'
Title: 'My first Python package, D1py: A very simple library to interact with Cloudflare
  D1 Database API'
---
Author: u/mutlu_simsek
Content: 'https://github.com/perpetual-ml/perpetual What My Project Does PerpetualBooster
  is a gradient boosting machine (GBM) algorithm which doesn''t have hyperparameters
  to be tuned so that you can use it without needing hyperparameter optimization packages
  unlike other GBM algorithms. Similar to AutoML libraries, it has a budget parameter
  which ranges between (0, 1) . Increasing the budget parameter increases predictive
  power of the algorithm and gives better results on unseen data. Start with a small
  budget and increase it once you are confident with your features. If you don''t
  see any improvement with further increasing budget , it means that you are already
  extracting the most predictive power out of your data. Target Audience The project
  is meant for production. You can replace hyperparameter packages plus other gradient
  boosting algorithms with PerpetualBooster. Comparison Other gradient boosting algorithms
  (XGBoost, LightGBM, Catboost) and most of the machine learning algorithms need hyperparameter
  optimization for the best performance on unseen data. But PerpetualBooster doesn''t
  have hyperparameters so it doesn''t need hyperparameter tuning. It has a built-in
  generalization algorithm and provides the best performance. The following table
  summarizes the results for the California Housing dataset: Perpetual budget LightGBM
  n_estimators Perpetual mse LightGBM mse Perpetual cpu time LightGBM cpu time Speed-up
  0.33 100 0.192 0.192 10.1 990 98x 0.35 200 0.190 0.191 11.0 2030 186x 0.45 300 0.187
  0.188 18.7 3272 179x'
Title: Perpetual - a self-generalizing, hyperparameter-free gradient boosting machine
---
Author: u/BluesFiend
Content: 'Just released v0.8.0 of fastapi_problem to provide problem details for FastAPI
  applications. Hoping it can provide value to some other peoples projects. Code:
  https://github.com/NRWLDev/fastapi-problem Docs: https://nrwldev.github.io/fastapi-problem/
  Pypi: https://pypi.org/project/fastapi-problem/ What My Project Does Provides a
  simple exception handler and an underlying exception class heirarchy to remove the
  need to think about error management in your FastAPI project, just raise errors
  as appropriate and let the handler deal with responses. Target Audience Web developers
  Comparison There was a previous project that supported RFC7807 but that is no longer
  maintained, and is also made obsolete by RFC9457. RFC9457 For anyone who does not
  make use of FastAPI, the underlying exception library has also been released, and
  can be used to implement handlers for any web framework you might be into. https://github.com/NRWLDev/rfc9457
  https://pypi.org/project/rfc9457/'
Title: Problem details for FastAPI applications (RFC9457)
---
Author: u/MaKaNuReddit
Content: 'When I was a beginner (or maybe still I am) I struggled a lot with pythons
  import function. Over the years I went over different approaches, how to handle
  imports and ended up using mostly exclusive poetry. I''ve met a lot of people struggling
  the same way, bit always could just explain very shortly my experience. I''ve now
  decided to write it down as a scenario, where I can show and explain my pitfalls:
  https://github.com/MaKaNu/pyimport-explained'
Title: I tried to explain python imports
---
Author: u/sonobanana33
Content: 'What My Project Does It is a CLI to get songs from ultimateguitar. How it
  looks like: https://youtu.be/Spm1IIaYo8Q I''ve only tried it on linux. Available
  in debian and pypi. Target audience For musicians who also use the terminal and
  who don''t especially like the ultimateguitar website. Comparison I''m not aware
  of other projects doing the same thing. Compared to the website, it can transpose
  and it is much faster. Source Project website: https://codeberg.org/ltworf/ultimateultimateguitar
  Out of date website (just here to avoid the post to be auto-removed): https://github.com/ltworf/ultimateultimateguitar'
Title: a new version of ultimateultimateguitar
---
Author: u/17thCurlyBrace
Content: 'is there a proposal for a shorter exception handling syntax for those very
  frequent cases where a library function doesn''t return "error value" like str.index
  ? something like instead of : try: i = my_str.index("sub", st, en) except ValueError:
  # if "sub" has not been found pass else: # do stuff with i (note that i usually
  want independent error handling here) something like this : i = my_str.index("sub",
  st, en) except ValueError -1 # or maybe even return here if i == -1: # also can
  return right away if i want to avoid an indent next # do stuff with i ... i suspect
  there might be something "un-pythonic" here in what i am imagining , but please
  forgive me if that''s the case . i am a fan of Python for many years , but haven''t
  really invested any time in learning the philosophy so i am interested in what the
  community thinks about this , how ok would such syntax be from the point of the
  "Python way" , and if there is such a proposal i would like to know if i can consider
  maybe voting on it somehow'
Title: how about one-line try-except statement ?
---
Author: u/BaggiPonte
Content: uv is the "pip but blazingly fast‚Ñ¢Ô∏è because it's written in rust" and is
  developed by the same folks that did ruff. In 0.2.11 they released an experimental/preview
  command of `uv add/remove` that adds a library to pyproject.toml. It's the first
  step to become a fully-fledged package manager! I noticed you can also manage python
  installations with uv using `uv toolchain` command (i.e. be like pyenv) and run
  tools (like a smaller version of pipx) with `uv run`. I'm genuinely excited about
  this, Python packaging is going to become such a smooth experience üòé Commands are
  in preview so expect missing stuff. (I bear no affiliation with astral) https://github.com/astral-sh/uv
Title: uv added experimental commands for `uv add/remove`
---
Author: u/dxtros
Content: 'Hi Python data folks, I am excited to share Pathway, a Python data processing
  framework we built for ETL and RAG pipelines. https://github.com/pathwaycom/pathway
  What My Project Does We started Pathway to solve event processing for IoT and geospatial
  indexing. Think freight train operations in unmapped depots bringing key merchandise
  from China to Europe. This was not something we could use Flink or Elastic for.
  Then we added more connectors for streaming ETL (Kafka, Postgres CDC‚Ä¶), data indexing
  (yay vectors!), and LLM wrappers for RAG. Today Pathway provides a data indexing
  layer for live data updates, stateless and stateful data transformations over streams,
  and retrieval of structured and unstructured data. Pathway ships with a Python API
  and a Rust runtime based on Differential Dataflow to perform incremental computation.
  All the pipeline is kept in memory and can be easily deployed with Docker and Kubernetes
  (pipelines-as-code). We built Pathway to support enterprises like F1 teams and processors
  of highly sensitive information to build mission-critical data pipelines. We do
  this by putting security and performance first. For example, you can build and deploy
  self-hosted RAG pipelines with local LLM models and Pathway‚Äôs in-memory vector index,
  so no data ever leaves your infrastructure. Pathway connectors and transformations
  work with live data by default, so you can avoid expensive reprocessing and rely
  on fresh data. You can install Pathway with pip and Docker, and get started with
  templates and notebooks: https://pathway.com/developers/showcases We also host demo
  RAG pipelines implemented 100% in Pathway, feel free to interact with their API
  endpoints: https://pathway.com/solutions/rag-pipelines#try-it-out We''d love to
  hear what you think of Pathway!'
Title: Pathway - Build Mission Critical ETL and RAG in Python (used by NATO, F1)
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/marcogorelli
Content: 'In a few weeks, Polars 1.0 will be out. How exciting! You can already try
  out the pre-release by running: ``` pip install -U --pre polars ``` If you encounter
  any bugs, you can report them to https://github.com/pola-rs/polars/issues , so they
  can be fixed before 1.0 comes out. Release notes: https://github.com/pola-rs/polars/releases/tag/py-1.0.0-alpha.1'
Title: Polars 1.0 will be out in a few weeks, but you can already install the pre-release!
---
Author: u/Affectionate_Sky9709
Content: There's a promotion right now to try PyCharm, get a 30% discount, and 100%
  of what you pay goes directly to the Django Software Foundation, which maintains
  Django and keeps it free for everyone. https://jb.gg/2atgzm I hope this kind of
  post is allowed.
Title: Try PyCharm (30% off!) and they donate 100% to the Django Software Foundation
---
Author: u/RevolutionaryPen4661
Content: '(.venv) PS D:\flpc> python .\seed\test.py Operation  | flpc (ms)  | re (ms)
  ---------------------------------- Compile    | 1496.18077 | 0.00000 Search     |
  19.67597   | 1721.07339 Find Match | 15.62524   | 16.72506 Full Match | 15.62500   |
  0.00000 Split      | 0.00000    | 1722.88108 Find All   | 3.02815    | 1660.32910
  Find Iter  | 5.96547    | 1672.50776 Sub        | 0.00000    | 1548.61116 Subn       |
  6.70719    | 1676.84698 Escape     | 4.87757    | 0.00000 (.venv) PS D:\flpc> flpc
  is the name of the library. I named it (spelt as flacpuc). The strange thing is
  that why the compile time is high of flpc (rust) than of re module (implemented
  in Pure-Python) (it does the same thing what re.compile does in Python). The benchmark
  is done on: PATTERN = r''(\w+)\s+(\d+)'' TEXT = ''''.join(choices(ascii_letters
  + digits, k=1000)) # choices function from random module ITERATIONS = 100 The problem
  is that, the python should be slow in the parameter (Regex Compile). However, the
  rest of parameters looks great! VERY FAST!'
Title: I ported Rust's Regex Library To Python, but the time taken by the compile
  parameter was high.
---
Author: u/AlexTheRandomizer
Content: Hi guys! What are your experiences with Vedo or PyVista? Which one do you
  prefer? Did you have any specific issues which either of these libraries? I'm mostly
  interested in meshes and point clouds rendering.
Title: Vedo or PyVista?
---
Author: u/romerio86
Content: 'About a year ago, I posted on this sub. I was terrified. I was launching
  a new framework. Another framework? Yes, I was crazy enough to think we needed yet
  another framework. Thankfully, the response was great. Many were excited to try
  it. Others were understandably skeptical, and respectfully asking good questions.
  This time, I''m posting for completely different reasons. I want to share a story.
  A story of which this sub, and hundreds of you, are part. It all started 2 years
  ago, when I was laid off from my analytics consulting job. I had a well-paying,
  comfortable job in the UK. Then I moved from the UK to Poland, where I live now,
  and continued working remotely. I was living the dream; earning a London salary
  while living in a place with a lower cost of living. Until it ended with a layoff.
  I thought, this is it. My career is dead. I didn''t speak Polish properly, limiting
  my options. And finding another fully remote job working for the UK sounded overly
  optimistic at the time. Being in my mid 30s and with a family to support, I didn''t
  want to start over again. I knew Python and data analytics quite well, and also
  had frontend skills I had gained throughout the years. So I thought... I need to
  show what I can do. I didn''t have a portfolio at all; my GitHub was empty. After
  trying Streamlit, I thought the concept was great, but the execution wasn''t. So
  I wrote an article on Medium, discussing how a better, faster alternative was possible.
  I also created a POC and shared it on GitHub. Thankfully, due to contacts at my
  previous job, I was able to find another remote job, working for the UK w. With
  even better pay. So naturally, I forgot about my portfolio-building efforts. But
  after a few months, an investor (VC) from Germany reached out to me. He had seen
  the Medium article and asked me whether I''d like to do this full time. I hesitated,
  but eventually decided to explore this further. I didn''t need any investment though;
  my idea was quite simple. And to be honest, not too different from other frameworks,
  just faster. I had to think bigger. One day, at London Stansted Airport, while waiting
  to board a plane home, I decided to go for it and came up with the idea of no-code
  in the front, Python in the back. In other words, building the frontend using a
  visual editor, while allowing for full freedom in the backend using Python, and
  abstracting all the connectivity between. The VC liked the idea, but wasn''t fully
  convinced about my ability to execute. He decided not to invest. But since I liked
  the idea and thought it could go somewhere, I decided to try building it myself,
  at night, after work. For 9 months, that was my reality. Nights, weekends. If my
  baby son would wake up, early mornings too. In May 2023, I managed to get the framework
  to a state I was happy with, and launched it. The response was very good. I eventually
  got to 1000 stars on GitHub, a milestone for any open source project. To a great
  extent, thanks to the support of communities such as r/python and r/opensource .
  Also, thanks to sites like Medium and Product Hunt. A few months later, in November
  2023, the CTO of a multibillion AI company reached out to me. They wanted to acquire
  my framework, hire me, and build a team for me to continue developing it. I was
  ecstatic. He told me he''d go on a Thanksgiving break for a few days and that he''d
  reach out to me after. He never got back to me. Accepting that this wasn''t going
  to happen was tough. Two weeks later, the CTO of another AI company called me, together
  with the CEO. They also wanted to acquire me and make me a part of their team. A
  smaller company, much more interesting and already quite established, with clients
  such as Accenture and Salesforce. But with grit and determination to win in the
  space of enterprise generative AI. This time, it did work out and my framework was
  finally acquired. Now I work for them and I lead a team focused on maintaining this
  open source project. Happy to answer any questions. And THANK YOU for your support
  r/python !!! For those curious: https://github.com/writer/writer-framework'
Title: Sold my Python open source project to a San Francisco AI company. Now I work
  for them. AMA.
---
Author: u/FareedKhan557
Content: 'What My Project Does This project aims to create a small-scale text-to-video
  model that can generate videos based on text prompts. Target audience This project
  is designed for individuals who want to learn how to create their own text-to-video
  model from scratch but don''t know where to start. It will provide a basic guide
  from beginning to end, covering everything from generating the training data to
  training a model and using that trained model to generate AI videos. Comparison
  Currently available text-to-video models require high computational power, and their
  complex code makes it difficult for Rookie developers to understand the practical
  implementation, beyond just the theory. To address this, I have created a small-scale
  GAN architecture, similar to text-to-video models, which can be trained on a CPU
  or a single T4 GPU. GitHub Code, documentation, and example can all be found on
  GitHub: https://github.com/FareedKhan-dev/AI-text-to-video-model-from-scratch'
Title: Building AI Text-to-Video Model From Scratch
---
Author: u/fzumstein
Content: 'Hi all, it''s been almost 1 year since the preview of Python in Excel has
  been revealed. So I wrote up a blog post pointing out what works well and what should
  be improved: https://www.xlwings.org/blog/my-thoughts-on-python-in-excel Here‚Äôs
  the TL;DR: We wanted an alternative to VBA, but got an alternative to the Excel
  formula language Integrating the Jupyter notebook cells inside the Excel grid was
  a mistake Python in Excel isn‚Äôt suitable for Python beginners nor for interactive
  data analysis Right now, there are too many restrictions (can‚Äôt use your own packages
  and can‚Äôt connect to web APIs) Here are the current use cases I see for Python in
  Excel: Computationally intensive things like Monte Carlo simulations AI stuff via
  the included packages (scikit-learn, nltk, statsmodels, imbalanced-learn, gensim)
  Advanced visualizations via Matplotlib/Seaborn Time-series analysis (this is one
  of Excel‚Äôs blind spots) Not sure about data cleaning/data analysis: since you almost
  certainly need Power Query, it may actually be simpler and faster to just stick
  to Power Query (instead of using Power Query and Python in Excel together)'
Title: My Thoughts on Python in Excel
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!'
---
Author: u/TheRealFrostMana
Content: 'Edit: Thanks a lot to those who pointed it out: The name of the concept
  in question is actually keyword-only arguments . **kwargs is lovely as well, though!
  I learned Python as my first language and it''s the one I''m most proficient in.
  However, I''ve since written JavaScript, TypeScript, C#, and a little bit of Go.
  Even though each language has its own way of doing things, I find that I often miss
  being able to use kwargs for the sake of readability. This is what I mean: some_function(semantic_parameter_name=value1,
  explanatory_parameter_name=value2) Often times, the usage of kwargs is sufficiently
  explanatory of what the function does. Whether it''s someone else''s code or code
  that you''ve written a while back, not only does it save you having to peek at the
  function''s signature/code, it also helps piece together what a block of code intends
  to do at first glance. At this point, for codebases that I maintain, I almost exclusively
  define my functions to force the usage of kwargs: kwargs_are_mandatory(*, parameter1:
  int, parameter2: str) -> None: return When I read code in a language that doesn''t
  support some form of kwargs, I find it more difficult and time consuming to wrap
  my head around what''s happening. What are your thoughts on kwargs?'
Title: Kwargs appreciation thread
---
Author: u/ANil1729
Content: I have open-sourced a Text-To-Video-AI generated which generates video from
  a topic by collecting relevant stock videos and stitching them together similar
  to popular video tools like Invideo, Pictory etc. Link to code :- https://github.com/SamurAIGPT/Text-To-Video-AI
Title: Open-source AI shorts generator in python
---
Author: u/achaayb
Content: Hey everyone, I've been working on a simple router for Uvicorn called ASGIRouter
  . If you like how Flask handles routing but want to stick with ASGI, you might find
  this useful. What My Project Does ASGIRouter provides a minimalistic routing solution
  for ASGI applications. It offers a straightforward way to define routes, similar
  to Flask, but is built to work any asgi compatible webservers mainly uvicorn. This
  project is aimed at developers who prefer a minimalistic approach to routing in
  their ASGI applications. It's suitable for both toy projects and production use,
  depending on your needs. Compared to existing ASGI routers, ASGIRouter stands out
  for its simplicity and ease of use. While other routers might offer more features
  or complexity, ASGIRouter focuses on providing a minimalistic, Flask-like experience
  for those who want to keep things straightforward. Check it out and let me know
  what you think.
Title: Made a Minimalistic Router for Uvicorn
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Wednesday Daily Thread: Beginner questions'
---
Author: u/itssimon86
Content: 'Hey Python community! I‚Äôd like to introduce you to my indie product Apitally
  , a simple API monitoring & analytics tool for Python projects. What My Project
  Does Apitally provides insights into API traffic, errors, and performance, for the
  whole API, each endpoint and individual API consumers. It also monitors API uptime,
  alerting users when their API is down. Apitally directly integrates with various
  Python web frameworks (FastAPI, Django, Flask, Litestar) through middleware, which
  captures request & response metadata (never anything sensitive!) and asynchronously
  ships it to Apitally‚Äôs servers in regular intervals. The client library is open-source
  with the source code available on GitHub . Below is a code example, demonstrating
  how easy it is to set up Apitally for a FastAPI app (see complete setup guide here
  ): from fastapi import FastAPI from apitally.fastapi import ApitallyMiddleware app
  = FastAPI() app.add_middleware( ApitallyMiddleware, client_id="your-client-id",
  env="dev",  # or "prod" etc. ) Target Audience Engineering teams, individual developers
  and product owners who build, ship and maintain REST APIs in Python. Comparison
  The big monitoring platforms (Datadog etc.) can be a bit overwhelming & expensive,
  particularly for simpler use cases. So Apitally‚Äôs key differentiators are simplicity
  & affordability, with the goal to make it as easy as possible for users to understand
  usage of their APIs. I hope people here find this useful. Please let me know what
  you think!'
Title: A super easy-to-use API monitoring & analytics tool
---
Author: u/aman6944
Content: While monitoring my network while doing some browser automation with selenium,
  I found strange traffic. After some digging I found https://github.com/SeleniumHQ/selenium/pull/13173
  . Searching for SE_AVOID_STATS on google to disable this has only 7 results, and
  practially impossible to find. I didn't expect to see this kind of dark patterns
  telemetry in python packages - so yeah. Has anyone else seen this? Is this some
  sort of recent trend?
Title: TIL that selenium has opt out telemetry. what other common packages do this
  / similar experiences?
---
Author: u/rmpython
Content: 'Hello all! I have made an irc client with textual`. Source is available
  here: https://github.com/rmblau/textchat/ I would love any and all feedback on code
  quality and how it can be improved as well as people to test out the client. On
  first launch it will open a settings screen where you can input your user information
  once you hit the save button. Right now there''s a bug that I''m working on resolving
  where that you''ll have to quit the application once you enter your information
  and relaunch it to get it to connect. Feel free to file issues and contribute; I
  hope you all will find this fun and interesting! What My Project Does Only confirmed
  working on Linux right now.. Right now it does not support SASL, SSL, or znc. It''s
  in alpha and can be installed from pypi. Once installed it can be ran from the cmd
  line with `textchat` Target Audience This is aimed at people who love irc as much
  as I do. Comparison There didn''t seem to be any application like this so I decided
  to make it.'
Title: 'Textchat: TUI Single Server IRC Client'
---
Author: u/0akman
Content: 'Just posted a video on a case study of a Python OpenCV algo that calculates
  the contact length between the tool and the chip in a metalworking machining process.
  The images have been captured with a high-speed camera. The Python code and documentation
  on my GitHub: https://github.com/FrunzaDan/Tool-Chip_Contact_Length The video: https://youtu.be/bndai6SlF6E
  Enjoy! What My Project Does The Python algo uses Hough lines to locate the edges
  of the tool and the chip and calculate the distance between them. Target Audience
  Python OpenCV enthusiasts and people in metalworking research. Comparison I haven''t
  seen any application like this in metalworking machining.'
Title: Python Open-CV Tool-Chip Contact Length Calculation
---
Author: u/Character-Maybe-4400
Content: I have several codebases with around 500+ different tests in each. If one
  of these tests fails, I need to spend ~20 seconds to find the right file, open it
  in neovim, and find the right test function. 20 seconds might not sound like much,
  but trying not to fat-finger paths in the terminal for this amount of time makes
  my blood boil. I wanted Pytest to do this for me, thought there would be a plugin
  for it. Google brought up no results, so I asked ChatGPT. It said there's a pytest-edit
  plugin that adds an --edit option to Pytest. There isn't. So I created just that.
  Enjoy. https://github.com/MrMino/pytest-edit Now, my issue is that I don't know
  if it works on Windows/Mac with VS Code / PyCharm, etc. - so if anyone would like
  to spend some time on betatesting a small pytest plugin - issue reports & PRs very
  much welcome. What My Project Does It adds an --edit option to Pytest, that opens
  failing test code in the user's editor of choice. Target Audience Pytest users.
  Comparison AFAIK nothing like this on the market, but I hope I'm wrong. Think %edit
  magic from IPython but for failed pytest executions.
Title: ChatGPT hallucinated a plugin called pytest-edit. So I created it.
---
Author: u/AccordingBeyond2985
Content: Like the only different is in pyqt you must share the code or buy a license
  and in pyside you can share it whether you want to or not. Yet i still see so many
  videos on pyqt and not pyside
Title: Why would anyone use pyqt if pyside exists
---
Author: u/mraza007
Content: I have always been curious on how http servers works. Therefore, I decided
  to write a post on how they work and implementing a simple server in Python. Link
  to blog post
Title: Building an HTTP Server in Python
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Tuesday Daily Thread: Advanced questions'
---
Author: u/PossiblePandaYT
Content: 'What my project does Allow users to find out what frameworks, tools, engines
  a program / game was made in. Looks through a directory and searches for common
  folder structures, and file names. You can add the -d flag to do a "deep dive" and
  it will look through for strings inside of the binaries. Image Example Target Audience
  Anyone! Developers looking to learn how other programs were made, people who are
  just interested. Comparison Not sure if there are any alternatives, but another
  way of finding out how a program runs is looking through the names of files & folders.
  GitHub: https://github.com/PossiblePanda/hdiw Contributors are appreciated :), adding
  new frameworks, or improving the core of hdiw.'
Title: open source CLI tool for finding out how programs work
---
Author: u/filipemarch
Content: 'We''re excited to share that our Kivy School crowdfunding project on Kickstarter
  is over 50% funded, but we only have 2 days left to reach our goal! We want to show
  our appreciation to everyone who has supported us. Even if we don''t reach 100%
  funding, everyone who trusted us will still receive free access to all free resources
  at kivyschool.com and our course on Udemy. Kivy School is an organization made by
  volunteers to teach others how to create Python apps using the Kivy framework and
  deploy them on all platforms: Android, iOS, Windows, macOS, Linux, Raspberry and
  on your toaster! So if you are still interested on helping Kivy School or on having
  free access to our Udemy course, you can risk free pledge on the crowdfunding link
  above before it expires. Keep an eye at Kivy School, soon we will publishing about:
  Hot Reload on Android Supabase integration Sentry integration Using SQLAlchemy /
  SQLModel / Pydantic with Kivy GPS, Bluetooth, Wi-Fi, Android Services & much more!
  It is Python. It is open source. And it is free. Join us at Kivy School, and let''s
  code together!'
Title: Kivy School - Crowdfunding Update
---
Author: u/Cool-Focus6556
Content: 'Ok, so just so I have this straight: Asyncio runs in a single thread and
  uses cooperative multitasking to context switch between tasks The threading library
  creates threads and uses preemptive multitasking to context switch between threads
  Asyncio is more efficient than threading for the reasons above Both share the same
  CPU core/resources Multiprocessing is using additional cores to speed up CPU bound
  tasks So to summarize: a process can create threads and threads can create tasks
  Is it just me or do people confuse processes as threads or also confuses tasks as
  threads? This makes getting it all straight pretty confusing and so any help here
  to confirm what I‚Äôve learned above would be appreciated üôè'
Title: Async Python Clarifications
---
Author: u/hatchet-dev
Content: 'Hey everyone - I wrote up a blog post on the problems that we''ve encountered
  using Celery: https://docs.hatchet.run/blog/problems-with-celery Our issues with
  the Celery project were part of the reason why we started Hatchet . Would love to
  hear comments or feedback!'
Title: The Problems with Celery
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Monday Daily Thread: Project ideas!'
---
Author: u/PossiblePandaYT
Content: 'What my project does Allow developers to implement custom themes into their
  programs, while having a file format that is human readable Example: my_theme.eft
  - My Theme background_color : 255,255,255 : Color title : "Hi" : String number :
  5 : Int enabled : true : Bool Target Audience Developers & users who make themes
  Comparison CSS Themes - May be difficult to implement, difficult to understand for
  people who aren''t programmers JSON Themes - Viable option, may not be readable
  in some cases GitHub: https://github.com/PossiblePanda/EFT-py Contributors are greatly
  appreciated :) If you have questions feel free to ask'
Title: EFT - A file extension for implementing user created themes
---
Author: u/GhnQuix
Content: 'Hello there What my project does: I‚Äôm excited to share my Flappy Bird clone,
  written in PyQt! This project captures all the fun of the original game with key
  features like pressing the spacebar to make the bird jump. Yes, I know, getting
  that key feature was challenging! üòÉ As Richard Watterson once said: "10/10 game,
  would play again." Target Audience This game is for anyone who‚Äôs bored and looking
  for a quick, fun way to pass the time. Whether you''re a casual gamer or just curious,
  this Flappy Bird clone is a not so good way to relive the original experience. Comparison
  Think of it as a faithful recreation of Flappy Bird with a PyQt twist. Update I
  had some time, so I made an update. The pipes now start from the middle. Code You
  can check out the code here . Please note that the code is definitely not the best,
  but hey it works!'
Title: Flappy Berd in PyQt
---
Author: u/PossiblePandaYT
Content: 'What my project does Allow developers to easily log errors, messages, and
  warnings to the console, and an optional log file. Have you ever released a project,
  and then somebody runs your project and encounter an error, and you need to see
  their console? No worries, pandalog can store logs in a file wherever you choose.
  You can also have errors automatically be sent in the console & log through pandalog.
  Target Audience Developers Comparison using pandalog has many benefits over just
  using print , such as storing logs in a log file, colored output in console, extremely
  configurable You can download it on pypi by running pip install pandalog GitHub:
  https://github.com/PossiblePanda/pandalog Contributors are appreciated :)'
Title: I have made an open source library for logging errors / messages :)
---
Author: u/bettercallsenna
Content: 'Hey everyone! I‚Äôm excited to share my first Python package: Melodica Notes
  . It''s a CLI tool aimed at helping melodica players with musical scales, chords,
  and harmonics. What My Project Does: Melodica Notes helps melodica players by providing
  easy access to musical scales, chords, and harmonic information directly from the
  command line. It''s designed to be a simple yet powerful tool for both beginners
  and advanced players. Target Audience: This project is meant for anyone who plays
  the melodica (or piano), from casual hobbyists to serious musicians. It''s also
  a project for developers interested in music-related applications. While it‚Äôs fully
  functional, I consider it an evolving tool and welcome contributions to enhance
  its features. Comparison: There are other musical tools out there, but Melodica
  Notes is specifically tailored for melodica players. Unlike general-purpose music
  theory tools, this CLI focuses on the needs and nuances of melodica playing, making
  it a unique addition to the musician''s toolkit. I‚Äôd love to hear your thoughts
  and suggestions! Whether it''s feedback, feature ideas, or pull requests, I welcome
  all contributions. Your insights can help make this tool even better. Check it out
  on PyPI and feel free to dive into the code on GitHub . Thanks for your support,
  and happy coding and playing üéµ'
Title: 'Just released my first Python package: Melodica Notes üé∂'
---
Author: u/jcoelho93
Content: 'What my project does: It''s an interactive tool to help you write json or
  yaml based on a JSON schema. I built this because I thought it would be helpful
  to write values.yaml files for Helm charts. But it can be used for a lot of other
  things like CICD configuration, OpenAPI specifications, etc. Target Audience Developers
  mostly, I guess Comparison I haven''t seen anything similar to this. Except maybe
  spotlight for writing OpenAPI specs, except steer is from the command line. Code:
  Here''s the GitHub repo https://github.com/jcoelho93/steer'
Title: steer - An interactive CLI tool to write json and yaml file from JSON schemas
---
Author: u/mcharytoniuk
Content: Are there any studies, large-scale polls, or anything about async coding
  adoption in Python? I wonder how widely the community accepts it, how widespread
  its usage is, and what the general sentiment is towards it.
Title: Async Python adoption?
---
Author: u/ashok_tankala
Content: Without using decorators I think mostly we can‚Äôt build a decent application.
  They are everywhere. I wrote an article to get an understanding of Decorators. https://newsletter.piptrends.com/p/understanding-python-decorators
  I hope this will give you a good understanding of Decorators if you don't know about
  them.
Title: Understanding Python Decorators
---
Author: u/prateekvellala
Content: 'Link: https://github.com/prateekvellala/Archand What My Project Does Archand
  allows you to control your mouse entirely using hand gestures which are performed
  in the air and captured via a webcam. Archand also has a speech-to-text feature
  which is activated by a specific gesture, transforming your spoken words into written
  text on your computer. With this, you can perform any task you would normally do
  with a keyboard as well, such as visiting websites, writing emails, texting people,
  etc. Archand has the following features, each controlled by a unique hand gesture:
  Move pointer Single left click Single right click Double left click Hold left click
  and move pointer (for dragging, etc) Scroll up Scroll down Enable your microphone,
  and then whatever you say will be converted to text and typed where your cursor
  is blinking (automating keyboard functionality) Target Audience Everyone Comparison
  There is no comparison with any other projects, as I have not seen any that incorporate
  all the features I have implemented, which work accurately with both low-resolution
  integrated laptop webcams and high-end webcams. All the projects I''ve encountered
  with a similar concept mainly fall into three categories: They¬†don''t work at¬†all,
  failing¬†even to¬†move¬†the¬†cursor¬†smoothly. The cursor moves pretty well and smoothly,
  but they do not fully automate the mouse, as they always lack some other feature
  like double-clicking, right-clicking, or scrolling, etc. They have many features
  that work well, but require high-end webcams, such as the Logitech Brio.'
Title: 'Archand: Control your mouse entirely using hand gestures.'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/legend3008
Content: What my project does CopySave is an app that saves everything you copy in
  your clipboard locally, so it can be used later, thus saving time. Target Audience
  Everyone who works at a pc, with data. Programmers, especially. Comparison I couldn't
  find any similar applications. Of course there are some better ones out there. https://github.com/mpiele/CopySave
Title: CopySave - And easy to use clipboard manager
---
Author: u/stealthanthrax
Content: Hey Everyone¬†üëã The author of Robyn here. For those unaware, Robyn is one
  of the fastest Python web frameworks with a Rust runtime.Robyn offers a variety
  of features designed to enhance your web development experience. However, one topic
  that has sparked mixed feelings within the community is Robyn's choice of not supporting
  ASGI. I'd love to hear your thoughts on this. Specifically, what specific features
  of ASGI do you miss in Robyn? You can find Robyn's documentation here . We're aiming
  for a v1.0 release soon, and your feedback will be invaluable in determining whether
  introducing ASGI support should be a priority. Please avoid generic responses like
  "ASGI is a standard and should be supported." Instead, share detailed insights and
  evidence-based arguments to help me understand the tangible benefits ASGI could
  bring to Robyn or the lack of a specific ASGI feature that will hinder you from
  using Robyn. Looking forward to your feedback! Thanks again. Repo - https://github.com/sparckles/Robyn/
  Docs - https://robyn.tech/documentation
Title: 'Seeking Feedback: Should Robyn(Web Framework) Support ASGI?'
---
Author: u/TechTalksWeekly
Content: 'tldr; https://www.youtube.com/playlist?list=PLsaeJ8d49kCnv20dizZqF_EjAoAByNfMj
  long: Hello r/python ! As a part of Tech Talks Weekly newsletter , I''ve put together
  a list of the most watched Python conference talks from 2023 as a youtube playlist.
  The list is ordered by the view count for your convenience. The talks come from
  conferences like PyCon (all locations), PyData (all locations), EuroPython, Conf42
  , and many more to give you a complete overview of the landscape. I''ve built the
  playlist as a part of my newsletter called Tech Talks Weekly where once a week I
  send out all the recently uploaded tech conference talks across engineering conferences
  ( see a recent issue and subscribe if this sounds useful). Let me know what do you
  think!'
Title: YouTube playlist with 100 most-watched Python 2023 conference talks
---
Author: u/Beneficial-Ad-9243
Content: 'What My Project Does Zenaura is a cutting-edge Python library, leveraging
  Pyodide and PyScript, designed to empower developers to create lightweight, performant,
  stateful, component-based Single Page Applications (SPAs) with ease. By utilizing
  a virtual DOM implementation, Zenaura enhances performance, reactivity, responsiveness,
  and interactivity, allowing developers to build dynamic web applications using familiar
  Python concepts and syntax. key features Exceptional Developer Experience:¬†Intuitive
  and efficient development workflow. Smooth Learning Curve:¬†Easy to learn and get
  started. Modular Code Structure:¬†Write clean, readable, and maintainable code. Component-Based
  Architecture:¬†Build reusable and scalable components. Page Management:¬†Simplify
  page creation and navigation. Built-in Router:¬†Seamless client-side routing. State
  and Props Management:¬†Efficiently handle component states and properties. Dependency
  Injection:¬†Manage dependencies effortlessly. Global States and Components:¬†Share
  states and components across the application. Optimized Virtual DOM:¬†Enhance application
  performance with a highly efficient virtual DOM. Component Lifecycle Methods:¬†Control
  component behavior at different stages. Form Support:¬†Easily manage form inputs
  and validation. API Integration:¬†Integrate external APIs using the requests module.
  target Audience Python developers who want to build stateful, component based SPA
  using pure python. Comparison with existing SPA building libraries, frameworks:
  Python Integration: Leverages PyScript and Pyodide: Zenaura allows your Python code
  to be compiled and transpiled into WebAssembly (WASM), enabling the execution of
  Python in the browser. This is a significant departure from traditional JavaScript-based
  frameworks like React, Angular, and Vue, which rely solely on JavaScript for client-side
  development. Developer Ecosystem: Pythonic Development: Zenaura enables Python developers
  to build modern web applications without needing to switch to JavaScript, providing
  a seamless experience for those who are more comfortable with Python. Unified Language:
  By using Python for both front-end and back-end development, Zenaura reduces the
  context-switching overhead and allows for a more cohesive development experience.
  Performance and Efficiency: Virtual DOM Implementation: Similar to React and Vue,
  Zenaura utilizes a virtual DOM to optimize rendering performance. However, Zenaura''s
  implementation play more well with the virtual DOM as it update the real DOM in
  non-blocking asyn way. Also thanks to pydide the python interpreter is ported to
  WASM, which means less JS footprint , very light library sizes on every library
  developed around zenaura. Component-Based Architecture: Stateful Components: Zenaura''s
  component-based architecture allows for building reusable, stateful components,
  akin to React and Vue. This promotes code reusability and modularity. Ease of Learning
  and Use: Smooth Learning Curve: Zenaura offers an intuitive and straightforward
  learning path, especially for developers already familiar with Python. This makes
  it accessible and easy to adopt compared to the steeper learning curves of frameworks
  like Angular. Ecosystem and Community: Growing Python Ecosystem: By integrating
  with the Python ecosystem, Zenaura can leverage existing Python libraries and tools,
  providing a rich set of functionalities and a vibrant community for support and
  collaboration. Resources: GitHub Repository: https://github.com/ARAldhafeeri/Zenaura
  Landing Page: https://araldhafeeri.github.io/zenaura-landing-page/ Documentation:
  https://araldhafeeri.github.io/Zenaura/'
Title: Introducing Zenaura, python framework for building scalable, maintainable component
  based SPAs.
---
Author: u/benizzy1
Content: 'Hey folks! I wanted to share Burr , an open-source project we''ve been working
  on that I''m really excited about. Target Audience Developers looking to integrate
  AI into their web services, or who are curious about state machines. The problem
  Most AI-application frameworks are overly opinionated about how to craft prompts,
  interact with LLMs, and store memory in a specific format. See this comment for
  a nice summary. The problem is they often overlook more production-critical aspects
  such as managing and persisting state, integrating telemetry, bringing apps to production,
  and seamlessly switching between human input and AI decisions. What My Project Does
  Our solution is to represent applications explicitly as state machines, which offers
  several advantages: Mentally model your system as a flowchart and directly translate
  it to code Execute custom hooks before/after step execution Decouple state persistence
  from application logic Rewind back in time/test counterfactuals (load up, fork,
  and debug) Query the exact (reproducible) application state at any point in time
  This is why we built Burr -- to make these capabilities easy and accessible. The
  design starts simple: define your actions as functions (or classes) and wire them
  together in an application. Each action reads from and writes to state, and the
  application orchestrates, deciding which action to delegate to next. An OS tracking
  UI lets you inspect the current state/get at *why* your application made a certain
  decision. While most people use it for LLM-based applications (where state is often
  complex and critical), we see potential for broader applications such as running
  time-series simulations, ML training, managing parallel jobs, and more. Burr is
  entirely dependency-free (using only the standard library), though it offers plugins
  that you can opt into. We''ve gotten some great initial traction, and would love
  more users and feedback. The repository has code examples + links to get started.
  Feel free to DM if you have any questions!'
Title: '[OS] Burr -- Build AI Applications/Agents as State Machines'
---
Author: u/qabr
Content: Could you please stop using photos of snakes on your articles about Python?
  Not only is it unimaginative, stale, and clich√©, but many of us also find it genuinely
  off-putting. Our passion certainly lies in coding, not necessarily in reptiles.
  P.S. Imagine 9 out of 10 articles on Windows featuring photos of pretty youknowwhat
Title: 'Request to journalists: no snakes'
---
Author: u/Thinker_Assignment
Content: 'Hey folks, I work on dlt, the open source python library for turning messy
  jsons into clean relational tables or typed, clean parquet datasets. We recently
  created 2 new tools: A python-dict based REST API extractor where you can just declare
  how to extract, and a tool that can init the above source fully configured by reading
  an OpenAPI spec. The generation of the pipes is algorithmic and deterministic, not
  LLM based. What My Project Does dlt-init-openapi, and the REST API toolkit are tool
  designed to simplify the creation of data pipelines by automating the integration
  with APIs defined by OpenAPI specifications. The pipelines generated are customizable
  Python pipelines that use the REST API source template that dlt offers (a declarative
  python-dict first way of writing pipelines). Target Audience dlt-init-openapi is
  designed for data engineers, and other developers who frequently work with API data
  and require an efficient method to ingest and manage this data within their applications
  or services. It is particularly useful for those working in environments that support
  Python and is compatible with various operating systems, making it a versatile tool
  for both development and production environments. dlt''s loader features automatic
  typing and schema evolution and processes data in microbatches to handle memory,
  reducing maintenance to almost nothing. Comparison Both the generation and the python
  declarative REST API source are new to our industry so it''s hard to compare. dlt
  is open source and you will own your pipelines to run as you please in your existing
  orchestrators, as dlt is just a lightweight library that can run anywhere Python
  runs, including lightweight things like serverless functions. dlt is like requests
  + df.to_sql() on steroids, while the generator is similar to generators that create
  python clients for apis - which is what we basically do with extra info relevant
  to data engineering work (like incremental loading etc) Someone from community created
  a blog post comparing it to Airbyte''s low code connector: https://untitleddata.company/blog/How-to-create-a-dlt-source-with-a-custom-authentication-method-rest-api-vs-airbyte-low-code
  More Info For more detailed information on how dlt-init-openapi works and how you
  can integrate it into your projects, check out the links below: GitHub Repository
  for the tool OpenAPI specs repository you can use Video Walkthrough Colab Demo Documentation
  and Quick Start Guide blog: REST API toolkit which helps understand how to edit
  the generated pipeline'
Title: Instant Python pipeline from OpenAPI spec
---
Author: u/NINTSKARI
Content: Off with the hate, what have been the best Python projects you have worked
  on? What did the code look like? What were the standards? Why was it the best?
Title: What are the best Python projects you've worked on?
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/adityashrivastav
Content: 'What My Project Does (Link) Check this out : aditya-shrivastavv/ranwcopy
  Python program which generates random words and sentences and copy them to clipboardüóíÔ∏è.
  I created a script to automate Bing searches for reward generation üëç Excellent command
  line experience. üôÇ User friendly. üîä Produces sound so you don''t have to start at
  it. üîÅ Auto copy to clipboardüóíÔ∏è üí° Intuitive help menu Target Audience Anyone who
  wants to quickly get points from bing searches under there daily limit Comparison
  This is no comparison, this is a very unique approch to the problem. You will find
  many browser extensions which claim to do the same thing, but they don''t work like
  the search engine expects Commands Help menu ranwcopy -h #OR ranwcopy --help Start
  generating words (10 default with 8 seconds gap) ranwcopy Generate 20 words with
  9 seconds gap ranwcopy -i 20 -g 9 # or ranwcopy --iterations 20 --timegap 9 This
  is a semi automatic script'
Title: Python script to automate Bing searches for reward generation
---
Author: u/justinezila
Content: This talks about mutability as Changes inside a function affect the original
  dictionary which could lead to unexpected behaviors and hard to debug issues. Here
  is a link to the video https://www.youtube.com/watch?v=zTTDQePffxU
Title: I created a video on why you should be careful when using Python dictionaries
  as function parameter
---
Author: u/Palani-SN
Content: 'py4cli (Scalable Argument Parser) Target Audience * Developers who want
  to develop scalable cli utility tools in python using declarative programming Comparison
  * Even Though Python have great libraries for passing command line arguments, those
  libraries aren''t scalable for complex use case. So, I have developed a scalable
  argument parser, which not only helps in passing cli arguments, but also can alter
  the execution flow of the code based on arguments. * The Library have two variants
  minimal and moderate argument parsers, minimal can be used for creating simple cli
  tool, while moderate is vertically scaled version of minimal argument parser & helps
  in controlling execution flow of the tool in addition to routing the arguments to
  the respective methods. What My Project Does * The library works fine with windows
  & Linux supporting basic data types like int, float, str, list, dict, bool . Further
  developments for making the solution even more scalable is in progress. Kindly check
  out the project and documentation below, GitHub Link : https://github.com/Palani-SN/py4cli
  , * Kindly rate the project in GitHub with stars if you like PYPI Link : https://pypi.org/project/py4cli/
  * Feel free to try this out with installation and usage. I am still actively developing
  it, so any feedback/comments would be appreciated! EDIT : How is it different than
  already existing tools : argparse - argparse is good in supporting different data
  types, but might not be able to control the flow of the code, or the arguments passed
  in can not be hierarchical always, which is what I term as scalability. In py4cli,
  the motive is to have better scalability in terms of hierarchical argument parsing.
  click, typer & cyclopts - Even though they support hierarchical cli arguments parsing,
  I feel, they rely much on decorators and its arguments more than necessary, In py4cli,
  the motive is to have, no extra decorators, or annotations as code, all that needs
  to be done is define a derived class from one of the base class provided in the
  lib, as per need and you can directly pass arguments to different methods of the
  class like how you will pass args and kwargs to a function natively. Py4Cli will
  be fulfilling the very basic aspects of cli interface to parse arguments, while
  ignoring on cli sophistication to concentrate on the scalability of the arguments
  passed, and in future to pass nested configuration files as inputs, with an emphasis
  on loosely coupled architecture. Additional Resources : docs : https://github.com/Palani-SN/py4cli/blob/main/README.md
  examples : https://github.com/Palani-SN/py4cli/tree/main/EXAMPLES'
Title: py4cli (A python library for developing scalable cli utility tools using declarative
  programming)
---
Author: u/brunneis
Content: 'I''m happy to introduce fastc , a humble Python library designed to make
  text classification efficient and straightforward, especially in CPU environments.
  Whether you‚Äôre working on sentiment analysis, spam detection, or other text classification
  tasks, fastc is oriented for small models and avoids fine-tuning, making it perfect
  for resource-constrained settings. Despite its simple approach, the performance
  is quite good. Key Features Focused on CPU execution: Use efficient models like
  deepset/tinyroberta-6l-768d for embedding generation. Cosine Similarity Classification:
  Instead of fine-tuning, classify texts using cosine similarity between class embedding
  centroids and text embeddings. Efficient Multi-Classifier Execution: Run multiple
  classifiers without extra overhead when using the same model for embeddings. Easy
  Export and Loading with HuggingFace: Models can be easily exported to and loaded
  from HuggingFace. Unlike with fine-tuning, only one model for embeddings needs to
  be loaded in memory to serve any number of classifiers. https://github.com/EveripediaNetwork/fastc'
Title: Lightning-Fast Text Classification with LLM Embeddings on CPU
---
Author: u/Trinity_software
Content: https://youtu.be/sSPWHRpDZXo?si=b-HJ4Cu1sN-tFls1 This video explains how
  files ( all types) are encrypted and decrypted with PyAesCrypt module of python.
  Also using pypdf module , pdf files are password protected. Decryption of password
  protected pdf can also be done
Title: Password protect Pdf using python
---
Author: u/Loose_Read_9400
Content: Good morrow all, I have a simple rest api I have initially developed using
  Flask. This is a super low utilization app, that may receive 10-12 requests per
  week. Currently, I have it running a local network using my main machine as the
  server. This has been great for testing and development, but I need to transition
  to a more permanent hosting situation. I have been looking at Azure Functions and
  this seems like the way to go, and would fall under the free tier from what I can
  tell. Is this the way to go? OR Should i look at other options? This is something
  for work, not a personal project.
Title: RESTful API Hosting
---
Author: u/HP7933
Content: 'The Python on Microcontrollers (and Raspberry Pi) Newsletter: subscribe
  for free With the Python on Microcontrollers newsletter, you get all the latest
  information on Python running on hardware in one place! MicroPython, CircuitPython
  and Python on single Board Computers like Raspberry Pi & many more. The Python on
  Microcontrollers newsletter is the place for the latest news. It arrives Monday
  morning with all the week‚Äôs happenings. No advertising, no spam, easy to unsubscribe.
  11,023 subscribers - the largest Python on hardware newsletter out there. Catch
  all the weekly news on Python for Microcontrollers with adafruitdaily.com. This
  ad-free, spam-free weekly email is filled with CircuitPython, MicroPython, and Python
  information that you may have missed, all in one place! Ensure you catch the weekly
  Python on Hardware roundup‚Äì you can cancel anytime ‚Äì try our spam-free newsletter
  today! https://www.adafruitdaily.com/'
Title: The Python on Microcontrollers (and Raspberry Pi) Newsletter, a weekly news
  and project resource
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/Myterro
Content: 'Hello, I''m having code-review suggestion doubts about sorting alphabetically
  fields in classes, e.g. Pydantic models. For example, there''s a model: class Example(BaseModel):
  id: int name: str surname: str age: int operation: str One of developers suggests
  that fields should be sorted alphabetically: class Example(BaseModel): age: int
  id: int name: str operation: str surname: str I think there shouldn''t be any specific
  order but only developer'' subjective look at importance and connection between
  fields, like "name" and "surname" should be next to each other because they are
  in some way connected. What is your opinion? Maybe there are some PEP8 rules about
  that?'
Title: Fields and class properties should be sorted alphabetically?
---
Author: u/JosephLovesPython
Content: 'Do you feel like you''re underutilizing tuples in you code? Maybe cause
  you think lists are always the correct choice, and tuples don''t have a place to
  exist. In this video we will walk through the differences between lists and tuples,
  especially focusing on a difference very rarely discussed, albeit it being the most
  crucial one: the semantic. Following that we will elaborate how and when it is better
  to utilize either lists or tuples! Any feedback on the content would be highly appreciated
  ‚ò∫Ô∏è https://youtu.be/-sO4FG6W4ho'
Title: Tuples Are Underrated! List vs Tuple üêç
---
Author: u/buddly27
Content: As Python is one of the most popular languages, many C++ projects end up
  using Python bindings of some sort. Pytest and Sphinx are very popular frameworks
  , so many CMake modules have been written, and most projects end up including a
  copy of these modules or using some hardcoded paths . I wrote two Python packages
  to manage the installation and update of CMake configs for Pytest and Sphinx. https://github.com/python-cmake/pytest-cmake
  https://github.com/python-cmake/sphinx-cmake It uses the pip package management,
  providing a module for each package and automatically generating a configuration
  based on the package version found. > pip install pytest-cmake > pip install sphinx-cmake
  I hope this method can standardize module integration for common Python tools. Let
  me know what you think!
Title: CMake configs for Python modules (Pytest, Sphinx, ‚Ä¶)
---
Author: u/commandlineluser
Content: Details about added features in the releases of Polars 0.20.17 to Polars
  0.20.31 https://pola.rs/posts/polars-in-aggregate-jun24/
Title: 'Polars news: Faster CSV writer, dead expr elimination optimization, hiring
  engineers.'
---
Author: u/Mews75
Content: I've made this simple little package to stretch out audios https://github.com/Mews/simpleaudiostretch
  However I'm still new to uploading packages to pypi and doing documentation and
  the sorts, so I'd appreciate it if someone could review my project and see if what
  I'm doing are the best practices. Thank you in advance if anyone is willing to help
Title: Code review for my simple project
---
Author: u/salastrodaemon
Content: 'Hello r/Python , What My Project Does I wanted to share a Python project
  I''ve been working on called WavePDE. WavePDE is a simulation and animation tool
  for studying wave equations in one or two dimensions. It''s a handy tool for anyone
  interested in wave phenomena, also it''s customizable and interactive. You can adjust
  domain size, grid resolution, wave speed, time step, boundary conditions (Dirichlet
  or Neumann), initial conditions, and more. Additionally, it is possible save your
  simulations as video files for further analysis or presentations. Target Audience
  I mainly created this tool while working on my research project. It is not yet complete
  since it deadens heavily on some parts I still didn''t finish. It is about numeric
  computations of the wave equation on arbitrary boundaries. So I still need to apply
  some mask on these results and extend the Neumann conditions beyond the current
  implementation. Comparison This tool is way more customizable (at least imho) than
  other Python tools I found online. The code is more structured allowing for future
  extensibility. I also tried to make it as user-friendly as possible. I hope you
  find it useful and I would appreciate any feedback you might have. I still didn''t
  implement tests, so if you find any bugs please let me know. Also, the documentation
  is lacking, but I''m working on it. You can find the code on GitHub: https://github.com/salastro/wavepde'
Title: Wave Equation Solver in Python
---
Author: u/jgloewen
Content: The Python Shiny library is a framework for building interactive web applications
  in Python. Developed by RStudio, the same team behind the Shiny library for R, this
  library is particularly useful for data scientists and analysts who want to build
  interactive dashboards and applications without having extensive front-end development
  skills. All that is needed is knowledge of the Shiny user interface Application
  Programming Interface (API). Python Shiny can be used to develop applications that
  allow users to interact with data in real time. Data scientists can quickly prototype
  data applications and share them with anyone. How easy is it to use? Let‚Äôs use a
  simple data set and a basic interactive data visualization to take it for a test
  drive. Free article HERE .
Title: 'Tutorial: How To Create Professional Python Shiny Dashboards In A Jiffy'
---
Author: u/ManyInterests
Content: 'Months ago, PySimpleGUI relicensed from LGPL3 to a proprietary license/subscription
  model with the release of version 5 and nuked the source code and history from GitHub.
  Up until recently, the old versions of PySimpleGUI remained on PyPI. However, all
  but two of these have been deleted and those that remain are yanked . The important
  effect this has had is anyone who may have defined their requirements as something
  like PySimpleGUI<5 or PySimpleGUI==4.x.x for a now-deleted version, your installations
  will fail with a message like: ERROR: No matching distribution found for pysimplegui<5
  If you have no specific version requested for PySimpleGUI you will end up installing
  the version with a proprietary license and nagware. There are three options to deal
  with this without compeltely changing your code: Specify the latest yanked, but
  now unsupported version of PySimpleGUI PySimpleGUI==4.60.5 and hope they don''t
  delete that some time in the future Use the supported LGPL fork, FreeSimpleGUI (full
  disclosure, I maintain this fork) Pay up for a PySimpleGUI 5 license.'
Title: 'PSA: PySimpleGUI has deleted [almost] all old LGPL versions from PyPI; update
  your dependencies'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!'
---
Author: u/the1024
Content: https://github.com/gauge-sh/tach Hey everyone! Wanted to share some pretty
  significant updates to the tool I've been working on. Tach lets you define module
  boundaries and enforce rules across your modules, including isolation, dependencies,
  and strict interfaces. Some updates - Re-wrote the core in Rust, leading to a ~19x
  speed up on large repos Re-worked the interface, and added a TUI to let you interactively
  declare modules We built Tach to solve the ‚Äúball of mud‚Äù problem that we‚Äôve ran
  into throughout all of my previous work experiences. Over time, the codebase would
  become tightly coupled together, making even simple changes/refactors painful. By
  setting up module boundaries and enforcing them early on, you can avoid all of this!
  Tach is the best way to grow a modular monolith without creating a ball of mud.
  If anyone has any questions or feedback, I‚Äôd love chat! https://github.com/gauge-sh/tach
  What My Project Does Tach enables you to interactively declare module boundaries,
  dependencies between modules, and strict interfaces for those modules. You can then
  enforce those declarations through a static code check. Target Audience Teams maintaining
  python monorepos. Comparison Import linter is probably the most similar tool - for
  a github discussion on the differences, check out this link - https://github.com/gauge-sh/tach/discussions/72
Title: Tach - enforce module boundaries + deps, now in Rust ü¶Ä
---
Author: u/Littlebudddy_321
Content: 'Good "time of day" my fellow peeps What my project does: I wanted to share
  my Python game I''ve been slowly working on over the past... I''d say 1.5 years.
  It is a simple texted based resource collection game where you travel to different
  areas, collect resources, sell them in town but be careful there are bandits about,
  so don''t go too far without having some cooked fish on you... Target Audience:
  I''d say its mainly for well... everyone, anyone who enjoys text based games and
  anyone who wants to chill out on a rainy day when all the other games in their steam
  library are looking boring and they just want to relax... Comparison: I''d say Colossal
  cave adventure but that is a much bigger... better... game I would call it, but
  this is just a simple "learning python" project I started a while ago and just recently
  got back into it so I said what the heck why not finish the game. but now I''m stuck
  as to what to do next, so I thought I''d ask for play testers to come and tell me
  how bad my coding and game was so I could try and make it more playable... because
  lord knows I made it so I know how to play it but what about other people. you can
  find the code on GitHub: https://github.com/littlebudddy321/New-Lands-RPG'
Title: New Lands RPG (Play testers welcome)
---
Author: u/JaggedParadigm
Content: 'What My Project Does: Moonlighter is a game that includes a mechanic where
  you place items on shelves in your store and set the price. Customer''s reactions
  give you hints about what prices would be ideal. These reactions take the form of
  four moods: ecstatic: price too low so they are extra happy content: price is what
  they were expecting, sad: price is too high to them but they buy anyway and this
  lowers the price everyone will pay for a certain period angry: price is too high
  so they don''t buy I built a simplified version where a sad reaction doesn''t lower
  the prices customers will accept for that item using Python and SQLite. The Bayesian
  bandits algorithm is an algorithm to optimize rewards when choosing among different
  options. The probability of different rewards (e.g. revenue) is kept track of and
  updated as rewards for options are collected. When a new option is to be selected
  a competition occurs where the rewards are sampled from these probability distributions
  and the option with the highest reward is chosen. For this simulation, the reward
  distributions are the probability that a price is the ideal price for that item.
  This scenario is so simple that the probability of any particular ideal price is
  flat or the same for all prices between an upper and lower bound and zero outside.
  This makes item/price selection simply randomly selecting a price from the lower
  to upper bounds for every item and selecting the item with the highest price. Customer
  reaction moods update the item upper/lower price bounds in these ways: ecstatic
  or content: lower bound is set to price plus 1 gold sad: lower bound is set to price
  if upper and lower bounds don''t match angry: upper bound set to price minus 1 gold
  if the upper and lower bounds don''t match The SQLite database keeps track of items
  in your inventory, items on shelves, customer reactions, item price bounds, and
  Thompson competitions (i.e. prices randomly chosen between price bounds for each
  item). The algorithm ended up identifying groups of items with the same ideal prices
  and selling them off from highest to lowest. For the full write up and a lot of
  pretty graphs check out the article in the link below. I''ve also included the Github
  link for those that want to see the full implementation and/or a Jupyter notebook
  where I generate the plots. Full write-up: https://cmshymansky.com/MoonlighterBayesianBanditsPricing/?source=rPython
  Github: https://github.com/JaggedParadigm/moonlighter_bayesian_bandit_pricing Target
  Audience: This a toy, though the Thompson sampling code could be hacked into something
  useful. Comparison: To my knowledge, I am the first to apply the Bayesian bandits
  algorithm to a Moonlighter shop simulation. However, pricing via Bayesian bandits
  is a classic application and there are many blogs and scientific papers on the topic.'
Title: Bayesian bandits item pricing in a simplified Moonlighter shop simulation using
  Python and SQLite
---
Author: u/wwwillchen
Content: 'What my project does: I‚Äôm excited to share about Mesop - a new, open-source
  Python UI framework that enables Python developers to quickly build delightful web
  apps in a scalable way. A small team of us at Google have been developing Mesop
  as an unofficial 20% project for the past few months. A wide range of research and
  product teams at Google have been using it to rapidly build internal apps and we‚Äôve
  gotten a lot of positive feedback internally so now we‚Äôre looking to get feedback
  from the open-source community. Target audience: Python developers looking to build
  AI demos & internal apps. Comparison: We think that Mesop provides a unique approach
  to building web UIs in Python compared to existing alternatives like Streamlit and
  Gradio - making it both easy to get started and also flexible enough to build customized
  UIs for a wide range of use cases. You can learn more about why we built Mesop here
  . To look at some example Mesop apps, check out our demo gallery . Also, the demo
  gallery itself is built with Mesop which demonstrates the type of flexibility you
  have in building apps with Mesop. GitHub repo: https://github.com/google/mesop'
Title: Mesop, open-source Python UI framework used at Google to quickly build delightful
  web apps
---
Author: u/phofl93
Content: 'My colleagues and I have been working on making Dask fast. It‚Äôs been fun.
  Dask DataFrame is now 20x faster and ~50% faster than Spark (but it depends a lot
  on the workload). I wrote a blog post on what we did: https://docs.coiled.io/blog/dask-dataframe-is-fast.html
  Really, this came down not to doing one thing really well, but doing lots of small
  things ‚Äúpretty good‚Äù. Some of the most prominent changes include: Apache Arrow support
  in pandas Better shuffling algorithm for faster joins Automatic query optimization
  There are a bunch of other improvements too like copy-on-write for pandas 2.0 which
  ensures copies are only triggered when necessary, GIL fixes in pandas, better serialization,
  a new parquet reader, etc. We were able to get a 20x speedup on traditional DataFrame
  benchmarks. I‚Äôd love it if people tried things out or suggested improvements we
  might have overlooked. Blog post: https://docs.coiled.io/blog/dask-dataframe-is-fast.html'
Title: Dask DataFrame is Fast Now!
---
Author: u/EngineeringFit5761
Content: 'Hi everyone! I''m sharing with you a Python tool I''ve built and been using,
  intended to haste new-page creation in WordPress (with Elementor plugin). It''s
  a simple app, but has great expansion potential and it''s really easy to use. To
  start, you will previously need a WordPress site with Elementor installed and activated,
  and the content you want to introduce into the new page. Run the program, add sections,
  choose your desired structure, and select the right widgets for your content. Once
  you''ve loaded the content, add your credentials and click Confirm & Run (or just
  press Enter). The system will do the rest :) You can download and see the project
  at: https://github.com/MauBorre/WordPress-new-page-auto Hope you find it useful!
  üòÅ'
Title: Automate your WordPress new-page creation with Python
---
Author: u/gi0baro
Content: 'Granian ‚Äì the Rust HTTP server for Python applications ‚Äì 1.4 was released!
  Blog post: https://polar.sh/emmett-framework/posts/granian-1-4 Release details:
  https://github.com/emmett-framework/granian/releases/tag/v1.4.0 Repo: https://github.com/emmett-framework/granian'
Title: Granian 1.4 is out
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Wednesday Daily Thread: Beginner questions'
---
Author: u/TwistedMinda
Content: 'Please check out my Desktoppy Server . What My Project Does It allows you
  to run your own personal AI on your computer, say bye-bye rate-limits and paywalls
  from mainstream AI''s. It uses ollama internally so you can use all the open-source
  Models but by default it''s using: LLama3 for text-generation LLava for image recognition
  Stable Diffusion 2 for image generation Target Audience Perfect for new-comers...
  I wish I had this when I started tackling AI dev. I think it can be a good base
  to create your awesome AI-powered products! Please let me know what you think about
  it! Comparison It differentiates from the other zillion starters by being very basic,
  allowing for full customization, and joining the 3 models together into 1 for a
  multi-modal feeling. Easiest possible setup, even for those who don''t know the
  tools yet, all you need is Python3 installed on your PC. Basically a tutorial-starter-multimodal.
  Much love Link: https://github.com/TwistedMinda/desktoppy-server The very basic
  Web UI that goes along with it: https://github.com/TwistedMinda/desktoppy-web'
Title: My little ChatGPT-Multimodal Server Starter
---
Author: u/pdcz
Content: 'Hi everyone, I''d like to share couple of news regarding my personal project:
  New documentation written in Ludic showcasing it''s capabilities: https://getludic.dev/docs/
  New section regrading Layouts inspired from the Every Layout Book: https://getludic.dev/catalog/layouts
  Cookiecutter template to get quickly started: https://github.com/paveldedik/ludic-template
  I have a lot of plans with this project and I''d appreciate any feedback. About
  The Project Ludic allows web development in pure Python with components. It uses
  HTMX to add UI interactivity and has a catalog of components. Target Audience Web
  developers People who want to build HTML pages in Python with typing People without
  knowledge of JavaScript who want to build interactive UIs People who want to use
  HTMX in their projects Comparison With Similar Tools Feature Ludic FastUI Reflex
  HTML rendering Server Side Client Side Client Side Uses Template Engine No No No
  UI interactivity </> htmx React React Backend framework Starlette FastAPI FastAPI
  Client-Server Communication HTML + REST JSON + REST WebSockets Any feedback is highly
  appreciated.'
Title: 'Ludic Update: Web Apps in pure Python with HTMX, Themes, Component Catalog,
  new Documentation'
---
Author: u/treyhunner
Content: Python 3.12 comes bundled with 50 command-line tools. For example, python
  -m webbrowser http://example.com opens a web browser, python -m sqlite3 launches
  a sqlite prompt, and python -m ast my_file.py shows the abstract syntax tree for
  a given Python file. I've dug into each of them and categorized them based on their
  purpose and how useful they are. Python's many command-line tools
Title: Python's many command-line utilities
---
Author: u/Jaeger1987
Content: 'What My Project Does Hello everyone! I''ve just released a new Python package,
  notion2pandas, which allows you to import a Notion database into a pandas dataframe
  with just one line of code, and to update a Notion database from a pandas dataframe
  also with just one line of code. Target Audience Whether you''re a data scientist,
  a data engineer, a Python enthusiast, or just curious, ''pip install notion2pandas''
  from the terminal, follow the tutorial in the README, and happy coding! üîó GitLab
  repo: https://gitlab.com/Jaeger87/notion2pandas Key Features Easy to use . import
  in a single line of code, export with another single line of code No more boring
  parsing . You can import any Notion Database in a pandas framework Flexibility .
  If you don''t like the default parsing mode of a data provided by notion2pandas,
  you can use your own parse function for a specific kind of data. Maintainability
  . If Notion broke something with an update, the possibility to provide a different
  parsing function allows you to use Notion2Pandas even if it''s not updated with
  latest notion update. Quick Start In the ReadMe you can find everything you need
  to start. Comparison When I started this project, I couldn''t find anything capable
  of transforming a Notion database into a pandas DataFrame without specifying how
  to parse the data. If you got any kind of feedback I''m really curious to read it!'
Title: 'Notion2Pandas: A new python package to import Notion Database into Pandas
  framework and viceversa'
---
Author: u/VoyZan
Content: 'If you''re interested in Python multiprocessing, I''d appreciate if you
  read this and share your thoughts: tl;dr: I''ve implemented a cross-process request
  rate limiter, allowing for N requests per T seconds. See it in this Gist . Problem
  Request rate limiting (or throttling) requires a place in memory to track the the
  amount of calls already made - some kind of counter . Multiprocessing is not great
  at having a single shared variable. I have a use case for a multiprocessing system
  in which each process can make a number of requests to a REST API server. That server
  imposes a 1000 requests per minute limit. Hence I needed a way to implement a rate
  limiter that would work across processes and threads. I''ve spent the past 2 days
  digging through a ton of SO posts and articles suggesting how to do it, and I came
  at a few bad solutions. I finally came up with one that I think works quite well.
  It uses a multiprocessing.Manager , and its Value , Lock and Condition proxies.
  Solution I''ve created a CrossProcessThrottle class which stores that counter .
  The way that the information about the counter is shared with all the processes
  and threads is through a ThrottleBarrier class instance. Its wait method will do
  the following: def wait(self): with self._condition: self._condition.wait() with
  self._lock: self._counter.value += 1 Wait for the shared Condition - this will stop
  all the processes and their threads and keep them dormant. If the CrossProcessThrottle
  calculates that we have available requests (ie. the counter is below max_requests
  , so we don''t need to limit the requests), it uses Condition.notify(n) ( docs )
  in order to let n amount of threads through and carry out the request. Once approved,
  each process/thread will bump the shared Value , indicating that a new request was
  made. That Value is then used by the CrossProcessThrottle to figure out how many
  requests have been made since the last check, and adjust its counter . If counter
  is equal or greater than max_requests , the Condition will be used to stop all processes
  and threads, until enough time passes. The following is the example code using this
  system. You can find it in this Gist if you prefer. import datetime from concurrent.futures
  import ProcessPoolExecutor, ThreadPoolExecutor from ratelimiter import ThrottleBarrier,
  CrossProcessesThrottle def log(*args, **kwargs): print(datetime.datetime.now().strftime(''[%H:%M:%S]''),
  *args, **kwargs) def task(i, j, throttle_barrier: ThrottleBarrier): # This will
  block until there is a free slot to make a request throttle_barrier.wait() log(f''request:
  {i:2d}, {j:2d}  (process, thread)'') # make the request here... def worker(i, throttle_barrier:
  ThrottleBarrier): # example process worker, starting a bunch of threads with ThreadPoolExecutor(max_workers=5)
  as executor: for j in range(5): executor.submit(task, i, j, throttle_barrier) if
  __name__ == ''__main__'': cross_process_throttle = CrossProcessesThrottle(max_requests=3,
  per_seconds=10) throttle_barrier = cross_process_throttle.get_barrier() log(''start'')
  futures = [] # schedule 9 jobs, which should exceed our limit of 3 requests per
  10 seconds with ProcessPoolExecutor(max_workers=10) as executor: for i in range(3):
  futures.append(executor.submit(worker, i, throttle_barrier)) while len(futures):
  # calling this method carries out the rate limit calculation cross_process_throttle.cycle()
  for future in futures: if future.done(): futures.remove(future) log(''finish'')
  I''ve uploaded the source code for CrossProcessThrottle and ThrottleBarrier as a
  Gist too . Calculating the counter is a bit more code, so I refrain from sharing
  it here, but in a nutshell: Store the last amount of requests made as last_counter
  , initialised as 0 Every time the cycle() is called, compare the difference between
  the current counter and the last_counter The difference is how many requests have
  been made since the last check, hence we increment the counter by that many. We
  calculate how many calls remaining are allowed: remaining_calls = max_requests -
  counter And notify that many threads to go ahead and proceed: condition.notify(remaining_calls)
  The actual process is a little more involved, as at the step 3 we need to store
  not only the amount of calls made, but also the times they''ve been made at - so
  that we can be checking against these later and decrease the counter . You can see
  it in detail in the Gist . If you''ve read through the code - what are your thoughts?
  Am I missing something here? In my tests it works out pretty nicely, producing:
  [14:57:26] start [14:57:26] Calls in the last 10 seconds: current=0 :: remaining=3
  :: total=0 :: next slot in=0s [14:57:27] request:  0,  1  (process, thread) [14:57:27]
  request:  0,  0  (process, thread) [14:57:27] request:  0,  2  (process, thread)
  [14:57:31] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=3 ::
  next slot in=7s [14:57:36] Calls in the last 10 seconds: current=3 :: remaining=0
  :: total=3 :: next slot in=2s [14:57:38] request:  0,  4  (process, thread) [14:57:38]
  request:  0,  3  (process, thread) [14:57:38] request:  1,  0  (process, thread)
  [14:57:41] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=6 ::
  next slot in=7s [14:57:46] Calls in the last 10 seconds: current=3 :: remaining=0
  :: total=6 :: next slot in=2s [14:57:48] request:  2,  0  (process, thread) [14:57:48]
  request:  1,  1  (process, thread) [14:57:48] request:  1,  2  (process, thread)
  [14:57:51] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=9 ::
  next slot in=8s [14:57:56] Calls in the last 10 seconds: current=3 :: remaining=0
  :: total=9 :: next slot in=3s [14:57:59] request:  2,  4  (process, thread) [14:57:59]
  request:  2,  2  (process, thread) [14:57:59] request:  2,  1  (process, thread)
  [14:58:01] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=12 ::
  next slot in=8s [14:58:06] Calls in the last 10 seconds: current=3 :: remaining=0
  :: total=12 :: next slot in=3s [14:58:09] request:  1,  3  (process, thread) [14:58:09]
  request:  1,  4  (process, thread) [14:58:09] request:  2,  3  (process, thread)
  [14:58:10] finish I''ve also tested it with 1000s scheduled jobs to 60 processes,
  each spawning several threads, each of which simulates a request. The requests are
  limited as expected, up to N per T seconds. I really like that I can construct a
  single ThrottleBarrier instance that can be passed to all processes and simply call
  the wait method to get permission for a request. It feels like an elegant solution.
  Research There are a bunch of libraries for rate limiting, some claiming to support
  multiprocess, however I couldn''t get them to do so: https://pypi.org/project/ratelimit/
  https://pypi.org/project/ratelimiter/ https://pypi.org/project/ratemate/ https://github.com/JWCook/requests-ratelimiter
  There''s a few SO threads and posts discussing the process too, however they either
  don''t consider multiprocessing, or when they do they don''t allow using ProcessPoolExecutor
  : https://stackoverflow.com/questions/69306420/rate-limit-api-multi-process https://stackoverflow.com/questions/40748687/python-api-rate-limiting-how-to-limit-api-calls-globally
  https://gist.github.com/justinvanwinkle/d9f04950083c4554835c1a35f9d22dad https://stackoverflow.com/questions/6920858/interprocess-communication-in-python
  The issue with ProcessPoolExecutor comes up when you try to use shared resources
  as it raises an error along the lines of: Synchronized objects should only be shared
  between processes through inheritance And to be fair the Googling didn''t really
  help me figuring out how to get around it, just finding more people struggling with
  the issue: https://stackoverflow.com/questions/69907453/lock-objects-should-only-be-shared-between-processes-through-inheritance
  https://github.com/python/cpython/issues/79967#issuecomment-1455216546 The solution
  would be to not use the ProcessPoolExecutor but that was a bummer. This comment
  helped me to find the way I''ve ended up using: https://stackoverflow.com/a/65377770/3508719
  I''m glad that using the SyncManager and its proxies I managed to come up with a
  solution that allows me to use the executor. Note I use multiprocessing instead
  of multithreading as there is some post-processing done to the data returned from
  the REST API. I imagine that for better efficiency I could split the system into
  a single process that does a lot of multithreading for REST API interaction, and
  then pass the returned data to several processes for post-processing. I didn''t
  have time to do it at the moment, but I''m aware of this as a potential alternative.
  I''ve built an earlier version of the rate limiter using multiprocessing Listener
  and Client - and carried out the communication through sockets/pipes. While this
  is useful to know about for inter-process communication, it turned out to be too
  slow and not support 100s of concurrent requests. If one of the existing libraries
  (eg. one of the ones I''ve listed) supports cross-process rate limiting with ProcessPoolExecutor
  , I''d love to see how to do it, please share an example! Multiprocessing can be
  a pain üò≠ Any feedback on my implementation welcome!'
Title: Rate Limiting + Multiprocessing = Nightmare? But I think I've found one nice
  way to do it ü§û
---
Author: u/britishbanana
Content: I'm interested in using cython specifically for introducing static typing
  to parts of a code base. For anyone who has used cython, could you give any details
  about your experience with introducing it gradually, how it changed the deployment
  and execution processes, how well it played with code that is calling lots of 3rd
  party frameworks. Also curious to hear about any headaches or issues it introduced.
  I'm less interested in the performance benefits, more interested in static type
  checks. I do use mypy already but I'm left quite lacking with it compared to real
  compilation checks. I'm curious more generally about the possibility of having a
  code base that mixes static and dynamic typing, and if I could stay in Python while
  doing that instead of going to Rust that would really simplify things. Thanks!
Title: Using python for static typing benefits
---
Author: u/maurinhoandre
Content: 'What My Project Does: PyODMongo is a modern Python library that serves as
  a robust Object-Document Mapper (ODM) and seamlessly bridges the gap between Python
  and MongoDB. It offers an intuitive and efficient way to interact with documents.
  Built on top of Pydantic V2, PyODMongo ensures that documents in the database rigorously
  represent the structure of Python objects. This means that documents are saved and
  retrieved from the database exactly as a Python object is structured, regardless
  of how nested the objects are and whether they are stored persistently or by reference.
  PyODMongo can automatically populate these documents. Target Audience: Backend developers
  who want a simple and efficient way to work with MongoDB Comparison: ODMantic ODM
  GitHub repository PyPi'
Title: PyODMongo an ODM for MongoDB
---
Author: u/jgloewen
Content: 'Streamlit¬†is becoming an increasingly a popular framework for data visualization
  prototyping with Python. The¬†Streamlit¬†framework saves time, effort, and reduces
  the complexity traditionally associated with crafting maps and charts.Particularly
  if we approach application development with a modular approach. Starting simple,
  let‚Äôs put together 4 specific examples that leverage¬†Streamlit¬†for interactive data
  visualization: A global choropleth map for a dataset for a specific year. An animated
  global choropleth map for a dataset across a number of years An animated choropleth
  map for a specific region A line chart to provide an alternative representation
  of the data Link to tutorial HERE'
Title: Tutorial on Surprisingly Simple Python Streamlit Dashboards
---
Author: u/DouweOsinga
Content: What My Project Does This is a small Python script that runs inside a Google
  Sheet by way of the Python add-on . It uses the reddit api to fetch posts from Ask
  Reddit twice daily. For posts with enough upvotes, it uses the OpenAI API to summarize
  an answer to the question based on the comments. I then inserts any new questions
  and their answers into the spreadsheet and uses the Twitter API to also post the
  answer to Twitter I mean X. Should be interesting to anybody looking to connect
  (a subset) of those APIs. Target Audience Anybody who is looking to mash-up different
  APIs (Python is great at this and I feel like it is getting a little harder to do
  this every year). Comparison I'm not aware of any Python code that does this. Even
  finding a good example of the V2 twitter API is harder than it seems. To accomplish
  some of this, you could try to ask ChatGPT directly to summarize the answers for
  a url but when I tried it said it couldn't access Reddit. Resource The spreadsheet
  where this happens The twitter bot in action The source code (or make a copy of
  the spreadsheet to see)
Title: Self updating spreadsheet with popular questions from Ask Reddit and summarized
  answers using OpenAI
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Tuesday Daily Thread: Advanced questions'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Monday Daily Thread: Project ideas!'
---
Author: u/pappuks
Content: 'What My Project Does: I finally got some time to attempt the 1 Billion Row
  Challenge (1BRC) ( https://www.morling.dev/blog/one-billion-row-challenge/ ) where
  we are supposed to process a file with 1 billion records of temperature values for
  cities and print a sorted list with min, max and mean temperature per city. I am
  a sucker for optimization. So when I heard about 1BRC I got intrigued and in the
  last few days started experimenting with python implementations. I achieved my goal
  and implemented the fastest implementation running on CPython, without any external
  libraries. My motivation for CPython was so that I can apply any of the learning''s
  in my day to day work, as I don''t see us moving to PyPy any time sooner. You can
  check out the performance numbers and implementation at : https://github.com/pappuks/1brc
  Few learning''s: Python Multiprocessing is very powerful in enabling multi core
  processing and overcoming GIL bottleneck for multi-threading. Using `Pool.starmap`
  is the easiest way to spawn child processes and collect response. AI code generation
  can help you jump start your implementation, but it will most likely be sub-optimal
  and you need to spend time in optimizing the code by understanding the core logic.
  PyPy gives good boost over CPython but compatibility of PyPy with external libraries
  is a limiting factor. Mypyc compilation was not any faster than default CPython
  implementation. Always measure after making the change. Optimizing for PyPy does
  not make the implementation any faster in CPython, but optimizing for CPython does
  make the implementation faster in PyPy. Target Audience: This is a hobby project,
  but most of the findings and learning can be applied to production projects as well.
  And given that all optimizations are done on CPython its applicability to production
  is easy. Comparison: This is the fastest CPython implementation for solving the
  1BRC problem. The detailed comparison is provided in the above github repository.
  Interpreter File Time (sec) Python3 py_1brc_final.py 24.882 Python3 py_1brc_mypyc.py
  (process_chunk.py precompiled using mypyc) 24.441 Python3 calculateAverage.py (from
  https://github.com/ifnesi/1brc ) 36.303 Python3 calculateAveragePyPy.py (from https://github.com/ifnesi/1brc
  ) 60.60 Python3 doug_booty4.py (from https://github.com/dougmercer-yt/1brc ) 62.91'
Title: 1BRC solution using CPython
---
Author: u/GabelSnabel
Content: Hey r/Python ! A while ago , I introduced you to PgQueuer , a Python library
  designed for handling job queues using Postgres native functionalities. If you've
  started using PgQueuer, I‚Äôm keen to initiate a discussion on your experiences with
  it. How and where have you integrated PgQueuer into your projects? Any difficulties
  or shortcomings you‚Äôve experienced while using PgQueuer? Thoughts on the library‚Äôs
  efficiency and features?
Title: Community Insights on PgQueuer
---
Author: u/fohrloop
Content: 'Hi all, I had previously a problem that I wanted to run some long running
  python scripts without being interrupted by the automatic suspend. I did not find
  a package that would solve the problem, so I decided to create my own. In the design,
  I have selected non-disruptive methods which do not rely on mouse movement or pressing
  a button like F15 or alter system settings. Instead, I''ve chosen methods that use
  the APIs and executables meant specifically for the purpose. I''ve just released
  wakepy 0.9.0 which supports Windows, macOS, Gnome, KDE and freedesktop.org compliant
  DEs. GitHub: https://github.com/fohrloop/wakepy Comparison to other alternatives:
  typical other solutions rely on moving the mouse using some library or pressing
  F15. These might cause problems as your mouse will not be as accurate if it moves
  randomly, and pressing F15 or other key might have side effects on some systems.
  Other solutions might also prevent screen lock (e.g. wiggling mouse or pressing
  a button), but wakepy has a mode for just preventing the automatic sleep, which
  is better for security and advisable if the display is not required. Hope you like
  it, and I would be happy to hear your thoughts and answer to any questions!'
Title: 'Keep system awake (prevent sleep) using python: wakepy'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/Content_Ad_4153
Content: 'Problem Statement I recently explored SonarQube for static code analysis.
  While it‚Äôs a great tool, the free edition lacks the ability to generate PDF reports,
  making it hard to share issues. There was no maintained plugin available, so I decided
  to solve this problem myself. Target Audience This started as a hobby/side project,
  but I wanted to share it in case others find it useful. I''m open to suggestions
  and feedback! Comparison with Similar Tools There was only one similar tool in the
  Sonar Marketplace, but it‚Äôs no longer maintained. Project Details I''ve developed
  and published a Python library called RedCoffee, which generates PDF reports from
  SonarQube analysis. You can find it on PyPi and GitHub. Links: PyPi: RedCoffee GitHub:
  RedCoffee Repository Feel free to check it out and let me know your thoughts!'
Title: PDF Reports for SonarQube Analysis ( Community Edition )
---
Author: u/Eastern_Reporter_834
Content: Hello everyone! What My Project Does I'm excited to share ReqFlow - a Python
  library designed to make API testing straightforward and efficient. It offers a
  fluent interface for building and validating HTTP requests, making it a handy tool
  for small-sized testing frameworks or utilities. While it's still in development
  and might have some bugs, I would love your feedback and contributions to improve
  it! Target Audience It would be suitable for beginners due to its reduced entry
  barrier and also supports advanced use cases with a RestAssured-like approach. Comparison
  While standard approaches for API testing with Python (e.g., requests ) definitely
  makes sense, ReqFlow provides a more fluent and expressive syntax, making it easier
  to write and understand tests. Check it out on GitHub and the docs at reqflow.org
  . All feedback and contributions are welcome! üôÇ
Title: ReqFlow - Simplifying API Testing with Python
---
Author: u/good-guy-coder
Content: 'I''m super excited to share NiimPrintX, a desktop app I''ve been working
  on for NiimBot label printers. This is my first release, and I am actively working
  on adding new functionalities. What My Project Does: NiimPrintX offers both a command
  line and graphical user interface app to connect with your NiimBot printer. It connects
  via Bluetooth and makes label printing a breeze. The app is developed completely
  using Python 3.12 and the Tkinter library for the GUI. GitHub Repository: NiimPrintX
  Target Audience: This project is aimed at hobbyists who use NiimBot label printers.
  It''s a proof of concept project for me to learn GUI app development in Python.
  Comparison: Currently, there is no desktop app support for NiimBot thermal label
  printers. Only the official Android/iOS app is available, and it has limited functionality
  without a paid subscription. NiimPrintX aims to fill this gap by providing a free,
  more versatile desktop solution. Supported Printer Models: D11/B21/B1 D110 B18 Cool
  Features: Bluetooth Auto Discovery: Automatically finds your printer using its model
  name. Easy Label Design: Create labels with a simple and intuitive GUI. Predefined
  Icons: Spice up your labels with built-in icons. Cross-Platform: Works on Mac, Windows,
  and Linux. Advanced Print Options: Includes calibration features for perfect prints.
  Coming Soon: Barcode Creation: Make your own barcodes right in the app. QR Code
  Printing: Generate and print QR codes. Better Object Alignment: More shapes and
  borders for your designs. I''m constantly working on adding new features, so keep
  an eye out for updates! Check out the GitHub repo for more info and installation
  instructions: NiimPrintX I''d love to hear what you think! Drop a comment or open
  an issue on GitHub with any feedback or suggestions.'
Title: 'NiimPrintX: A desktop app for NiimBot Label Printers developed in Python'
---
Author: u/radumarias
Content: 'https://github.com/radumarias/zeroize-python What My Project Does: Clear
  secrets from memory. Built on stable Rust primitives which guarantee memory is zeroed
  using an operation will not be ''optimized away'' by the compiler. Target Audience
  it can be used in production, it''s just a simple wrapper over zeroize crate from
  Rust Comparison Personally I didn''t found an easy and safe solution in Python to
  do this, hence I created this lib'
Title: 'zeroize: Securely clear secrets from memory'
---
Author: u/radumarias
Content: 'https://github.com/radumarias/rencrypt-python What My Project Does: A Python
  encryption library implemented in Rust. It supports AEAD with AES-GCM and ChaCha20Poly1305
  . It uses ring to handle encryption. If offers slightly higher speed compared to
  other Python libs, especially for small chunks of data. Target Audience This lib
  hasn''t been audited, but it mostly wraps ring crate which is a well known library,
  so in principle it should offer as similar level of security. This is still under
  development. Please do not use it with sensitive data just yet. Comparison If offers
  slightly higher speed compared to other Python libs, especially for small chunks
  of data. I compared it to PyFLocker , cryptography , NaCl ( l ibsodium ) , PyCryptodome
  . The API also tries to be easy to use but it''s more optimized for speed than usability.'
Title: 'A blend of Rust and Python: a faster encryption for Python'
---
Author: u/eonlav
Content: 'What My Project Does Allows you to have a voice-to-voice interaction with
  an LLM, similar to the ChatGPT app, except with all inference running locally. You
  can choose from a few different open-weight models. Video running Phi-2 model on
  a MacBook Air with 8GB RAM, all CPU Target Audience Devs looking to experiment with
  integrating on-device AI into their software. Comparison JARVIS - an all API-based
  solution using DeepGram, OpenAI and ElevenLabs Local Talking LLM - a higher-latency,
  more resource intensive local approach using Whisper, Llama and Bark, but with no
  wake word. Source code: https://github.com/Picovoice/pico-cookbook/tree/main/recipes/llm-voice-assistant/python'
Title: AI Voice Assistant using on-device LLM, STT, TTS and Wake Word tech
---
Author: u/Zorgon-589
Content: 'WHAT MY PROJECT DOES: Solves basic arithmetic problems in an interactive
  way in python. TARGET AUDIENCE: Anyone, it''s just a program to get practice using
  loops, lists, and functions. COMPARISON: This program functions as a calculator
  without the use of the eval() function to make everything superfluously easy. It''s
  not perfect and my next version is gonna try and address queries with parenthesis
  and multiple operators! See the below link for github: https://github.com/Zorgon589/Calculator/tree/main'
Title: Calculator without eval()
---
Author: u/radumarias
Content: REncrypt What My Project Does A Python encryption library implemented in
  Rust. It supports AEAD with AES-GCM and ChaCha20Poly1305. It uses ring to handle
  encryption. If offers slightly higher speed compared to other Python libs, especially
  for small chunks of data. The API also tries to be easy to use but it's more optimized
  for speed than usability. So if you are open to experiment and want to achieve the
  highest possible encryption speed, consider giving it a try. Target Audience This
  is just a toy project as a learning experience Comparison This is slightly faster
  than PyFLocker which from my benchmarks is the faster among other Python libs like
  cryptography, NaCl (libsodium), PyCryptodome
Title: 'A blend of Rust and Python: speeding up Python encryption'
---
Author: u/neozhaoliang
Content: 'What My Project Does An open-source RAG (Retrieval-Augmented Generation)
  engine based on deep document understanding. It offers layout recognition, OCR-based
  chunking templates for data cleasing and provides hallucination-free answers with
  traceable citations. Compatible with mainstream LLMs. Target Audience RAG applications
  developers. Comparison It offers various chunking templates for various fils categories,
  such as resume, legal documents, table, and print copies. Enables human intervention
  in chunking, making the data cleansing process no longer a black box. It not only
  presents answers but also offers quick views of references and links to the citations
  when answering to queries. Link: https://github.com/infiniflow/ragflow'
Title: 'RAGFlow: Deep document understanding RAG engine'
---
Author: u/ALior1
Content: 'So I''m trying to do a small refresher in design patterns and I reached
  the Observer pattern. And I''m encounter a circular import error that I''m not sure
  how to solve. At first I had two files: `observers.py` and `subjects.py`, which
  each contained the abstract class and some concrete ones. But because each  had
  to know about the other, I got a circler import error. I tried to put them in the
  same file, but than the first cant use the second. Also tried to put the Observer
  in the "subjects.py" file, textualy before "Subject", that worked, but not clear
  to me why. I know that in compiled languages, they just use an interface, but we
  dont have it in Python. Tried to solved it in a various ways, but want to hear others,
  how you think this can be solved and opinons on this. The base classes are: class
  Subject(ABC): @abstractmethod def attach(self, observer: Observer) -> None: # The
  Observer is in the method parameters, so we need to import it pass class Observer(ABC):
  @abstractmethod def update(self, subject: Subject) -> None: # The Subjectis in the
  method parameters, so we need to import it pass'
Title: Circler imports in Observer design pattern in Python
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/radumarias
Content: '[ https://github.com/radumarias/rencrypt-python](https://github.com/radumarias/rencrypt-python)
  * **What My Project Does** A Python encryption library implemented in Rust. It supports
  AEAD with AES-GCM and ChaCha20Poly1305. It uses ring to handle encryption.If offers
  slightly higher speed compared to other Python libs, especially for small chunks
  of data. The API also tries to be easy to use but it''s more optimized for speed
  than usability. So if you are open to experiment and want to achieve the highest
  possible encryption speed, consider giving it a try. * **Target Audience** This
  is just a toy project as a learning experience * **Comparison** This is slightly
  faster than PyFLocker which from my benchmarks is the faster among other Python
  libs like cryptography, NaCl (libsodium), PyCryptodome'
Title: 'New project: A blend of Rust and Python: speeding up Python encryption'
---
Author: u/crawles89
Content: 'What it does: It is for building AI agents that perform tasks for you on
  Android using LLMs. Agents read the screen and perform actions like clicking, typing,
  and dragging. It includes a test suite of 116 tasks across 20 real-world apps to
  evaluate agent performance. Think of each task like a unit test, with a setup, evaluation,
  and tear down procedure. Every task is written in Python. The most powerful agents
  should be able to pass all of them. Target Audience: Anyone looking to experiment
  with LLM for controlling Android UIs. You can download any app you‚Äôd like and test
  out the default agent, M3A, on it. Just give it a task like ‚ÄúShow my most recent
  purchases on Amazon.‚Äù You can also build your own agent. Comparison For desktop
  OSes, there is OSWorld , although it requires costly commercial software (VMWare)
  to run. AndroidWorld only requires free Android emulator. While this is OSS and
  for research, the closest commercial product would be the Rabbit R1 . They should
  test their agent on AndroidWorld to improve accuracy before shipping again :P Link
  to repo: https://github.com/google-research/android_world'
Title: AndroidWorld ‚Äî Build and test AI agents on Android
---
Author: u/Sn3llius
Content: Hey everyone, I'm a Rio developer, and I just wanted to say thanks for all
  the feedback we've received so far! Since our launch, we've implemented a lot of
  the features you asked for! As requested, we are currently working on an in-depth
  technical description of Rio, explaining how it works under the hood. So stay tuned!
  We are looking forward to your feedback, so let us hear from you! :) GitHub
Title: 'Rio: WebApps in pure Python ‚Äì Thanks and Feedback wanted!'
---
Author: u/monorepo
Content: 'This years SO survey is out now. It includes questions for Python tooling
  and frameworks. Contribute when you can, it closes soon. It takes ~10 minutes to
  finish. Link to the survey: https://stackoverflow.az1.qualtrics.com/jfe/form/SV_6rJVT6XXsfTo1JI'
Title: 2024 StackOverflow Survey
---
Author: u/SpareRevolution1487
Content: 'What my library does You can easily and powerfully perform caching and memoizing
  operations in your Python projects using my library. This library is written in
  Rust, which makes its performance very fast and efficient. By using this library,
  you can use 7 different caching algorithms that allow you to choose the best algorithm
  based on your needs. One prominent feature of this library is its simplicity to
  work with. You just need to import the library into your project and then behave
  with it like a dictionary. Therefore, if you are looking for a powerful, fast, and
  simple library for caching and memoizing in Python, my library will be responsive
  to your needs. By using this library, you can improve the performance of your program
  and significantly reduce the execution time of your Python code. Target Audience
  For anyone who needs caching and values speed Comparison When compared to other
  caching libraries: It''s very faster than others (about 5-20x) It''s very simple
  and easy to use It''s completely thread-safe (uses RwLock) It uses lower memory
  than others You can see benchmark here: https://github.com/awolverp/cachebox-benchmark
  More Info My project github: https://github.com/awolverp/cachebox'
Title: 'cachebox: The fastest caching library written in Rust'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/PyDataAmsterdam
Content: Hey all, we will close the Call for Proposals portal this Sunday, June 2
  , for our PyData Amsterdam 2024 Conference which will take place on September 18-20
  in Amsterdam. We are looking for presentations that can captivate our audience,
  provide invaluable insights, and foster community learning. Don't miss this chance
  to speak on stage in front of over 800 attendees in the field of Data & AI. Submit
  a talk here > https://amsterdam2024.pydata.org/cfp/cfp
Title: PyData Amsterdam 2024 Call for Proposals closes on Sunday, June 2
---
Author: u/CanaryHill
Content: 'What My Project Does Zango, built on top of Django, is further opinionated
  towards building enterprise ready custom business apps. Includes additional batteries
  for out of the box enterprise readiness and rapid app development. Growing ecosystem
  of packages that serves as building blocks of apps. Zango also enables multi-tenancy
  where each tenant, representing an app/microservices, can be deployed independently
  on the same underlying monolith. Tenants have logically seperated db, codebase as
  well as deployment. This significantly cuts down per app hosting cost and enables
  microservices pattern without the cost overhead. Target Audience Enterprises: Benefits
  from the open core concept. No vendor lock-ins. Rapid development with out-of-the-box
  enterprise readiness. Startups: Get productive from day-1. Leverage packages to
  reach MVP really fast and not be constrained by limit on customizability (as with
  low-code/no-code solutions). Lowest cost of hosting if you have multiple apps or
  building microservices. Consulting/ Development companies: Increase development
  efficiency and optimize on hosting cost. You: If you are looking to develop any
  bespoke app, give it a try :) Comparison Web dev frameworks(e.g. Django): Not opinionated
  for enterprise readiness/ business apps. Zango enables faster development, lower
  opex and and built-in compliance and enterprise readiness Proprietary platforms
  (e.g. Salesforce): No vendor lock-in. Faster development Low-Code / No-Code: Limited
  customizability. More Info Know more at the project''s Github repo: https://github.com/Healthlane-Technologies/Zango'
Title: Zango - New python framework for building enterprise ready business apps. Salesforce
  alternative.
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Tuesday Daily Thread: Advanced questions'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Monday Daily Thread: Project ideas!'
---
Author: u/pappuks
Content: 'What My Project Does: I finally got some time to attempt the 1 Billion Row
  Challenge (1BRC) ( https://www.morling.dev/blog/one-billion-row-challenge/ ) where
  we are supposed to process a file with 1 billion records of temperature values for
  cities and print a sorted list with min, max and mean temperature per city. I am
  a sucker for optimization. So when I heard about 1BRC I got intrigued and in the
  last few days started experimenting with python implementations. I achieved my goal
  and implemented the fastest implementation running on CPython, without any external
  libraries. My motivation for CPython was so that I can apply any of the learning''s
  in my day to day work, as I don''t see us moving to PyPy any time sooner. You can
  check out the performance numbers and implementation at : https://github.com/pappuks/1brc
  Few learning''s: Python Multiprocessing is very powerful in enabling multi core
  processing and overcoming GIL bottleneck for multi-threading. Using `Pool.starmap`
  is the easiest way to spawn child processes and collect response. AI code generation
  can help you jump start your implementation, but it will most likely be sub-optimal
  and you need to spend time in optimizing the code by understanding the core logic.
  PyPy gives good boost over CPython but compatibility of PyPy with external libraries
  is a limiting factor. Mypyc compilation was not any faster than default CPython
  implementation. Always measure after making the change. Optimizing for PyPy does
  not make the implementation any faster in CPython, but optimizing for CPython does
  make the implementation faster in PyPy. Target Audience: This is a hobby project,
  but most of the findings and learning can be applied to production projects as well.
  And given that all optimizations are done on CPython its applicability to production
  is easy. Comparison: This is the fastest CPython implementation for solving the
  1BRC problem. The detailed comparison is provided in the above github repository.
  Interpreter File Time (sec) Python3 py_1brc_final.py 24.882 Python3 py_1brc_mypyc.py
  (process_chunk.py precompiled using mypyc) 24.441 Python3 calculateAverage.py (from
  https://github.com/ifnesi/1brc ) 36.303 Python3 calculateAveragePyPy.py (from https://github.com/ifnesi/1brc
  ) 60.60 Python3 doug_booty4.py (from https://github.com/dougmercer-yt/1brc ) 62.91'
Title: 1BRC solution using CPython
---
Author: u/GabelSnabel
Content: Hey r/Python ! A while ago , I introduced you to PgQueuer , a Python library
  designed for handling job queues using Postgres native functionalities. If you've
  started using PgQueuer, I‚Äôm keen to initiate a discussion on your experiences with
  it. How and where have you integrated PgQueuer into your projects? Any difficulties
  or shortcomings you‚Äôve experienced while using PgQueuer? Thoughts on the library‚Äôs
  efficiency and features?
Title: Community Insights on PgQueuer
---
Author: u/fohrloop
Content: 'Hi all, I had previously a problem that I wanted to run some long running
  python scripts without being interrupted by the automatic suspend. I did not find
  a package that would solve the problem, so I decided to create my own. In the design,
  I have selected non-disruptive methods which do not rely on mouse movement or pressing
  a button like F15 or alter system settings. Instead, I''ve chosen methods that use
  the APIs and executables meant specifically for the purpose. I''ve just released
  wakepy 0.9.0 which supports Windows, macOS, Gnome, KDE and freedesktop.org compliant
  DEs. GitHub: https://github.com/fohrloop/wakepy Comparison to other alternatives:
  typical other solutions rely on moving the mouse using some library or pressing
  F15. These might cause problems as your mouse will not be as accurate if it moves
  randomly, and pressing F15 or other key might have side effects on some systems.
  Other solutions might also prevent screen lock (e.g. wiggling mouse or pressing
  a button), but wakepy has a mode for just preventing the automatic sleep, which
  is better for security and advisable if the display is not required. Hope you like
  it, and I would be happy to hear your thoughts and answer to any questions!'
Title: 'Keep system awake (prevent sleep) using python: wakepy'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/Content_Ad_4153
Content: 'Problem Statement I recently explored SonarQube for static code analysis.
  While it‚Äôs a great tool, the free edition lacks the ability to generate PDF reports,
  making it hard to share issues. There was no maintained plugin available, so I decided
  to solve this problem myself. Target Audience This started as a hobby/side project,
  but I wanted to share it in case others find it useful. I''m open to suggestions
  and feedback! Comparison with Similar Tools There was only one similar tool in the
  Sonar Marketplace, but it‚Äôs no longer maintained. Project Details I''ve developed
  and published a Python library called RedCoffee, which generates PDF reports from
  SonarQube analysis. You can find it on PyPi and GitHub. Links: PyPi: RedCoffee GitHub:
  RedCoffee Repository Feel free to check it out and let me know your thoughts!'
Title: PDF Reports for SonarQube Analysis ( Community Edition )
---
Author: u/Eastern_Reporter_834
Content: Hello everyone! What My Project Does I'm excited to share ReqFlow - a Python
  library designed to make API testing straightforward and efficient. It offers a
  fluent interface for building and validating HTTP requests, making it a handy tool
  for small-sized testing frameworks or utilities. While it's still in development
  and might have some bugs, I would love your feedback and contributions to improve
  it! Target Audience It would be suitable for beginners due to its reduced entry
  barrier and also supports advanced use cases with a RestAssured-like approach. Comparison
  While standard approaches for API testing with Python (e.g., requests ) definitely
  makes sense, ReqFlow provides a more fluent and expressive syntax, making it easier
  to write and understand tests. Check it out on GitHub and the docs at reqflow.org
  . All feedback and contributions are welcome! üôÇ
Title: ReqFlow - Simplifying API Testing with Python
---
Author: u/good-guy-coder
Content: 'I''m super excited to share NiimPrintX, a desktop app I''ve been working
  on for NiimBot label printers. This is my first release, and I am actively working
  on adding new functionalities. What My Project Does: NiimPrintX offers both a command
  line and graphical user interface app to connect with your NiimBot printer. It connects
  via Bluetooth and makes label printing a breeze. The app is developed completely
  using Python 3.12 and the Tkinter library for the GUI. GitHub Repository: NiimPrintX
  Target Audience: This project is aimed at hobbyists who use NiimBot label printers.
  It''s a proof of concept project for me to learn GUI app development in Python.
  Comparison: Currently, there is no desktop app support for NiimBot thermal label
  printers. Only the official Android/iOS app is available, and it has limited functionality
  without a paid subscription. NiimPrintX aims to fill this gap by providing a free,
  more versatile desktop solution. Supported Printer Models: D11/B21/B1 D110 B18 Cool
  Features: Bluetooth Auto Discovery: Automatically finds your printer using its model
  name. Easy Label Design: Create labels with a simple and intuitive GUI. Predefined
  Icons: Spice up your labels with built-in icons. Cross-Platform: Works on Mac, Windows,
  and Linux. Advanced Print Options: Includes calibration features for perfect prints.
  Coming Soon: Barcode Creation: Make your own barcodes right in the app. QR Code
  Printing: Generate and print QR codes. Better Object Alignment: More shapes and
  borders for your designs. I''m constantly working on adding new features, so keep
  an eye out for updates! Check out the GitHub repo for more info and installation
  instructions: NiimPrintX I''d love to hear what you think! Drop a comment or open
  an issue on GitHub with any feedback or suggestions.'
Title: 'NiimPrintX: A desktop app for NiimBot Label Printers developed in Python'
---
Author: u/radumarias
Content: 'https://github.com/radumarias/zeroize-python What My Project Does: Clear
  secrets from memory. Built on stable Rust primitives which guarantee memory is zeroed
  using an operation will not be ''optimized away'' by the compiler. Target Audience
  it can be used in production, it''s just a simple wrapper over zeroize crate from
  Rust Comparison Personally I didn''t found an easy and safe solution in Python to
  do this, hence I created this lib'
Title: 'zeroize: Securely clear secrets from memory'
---
Author: u/radumarias
Content: 'https://github.com/radumarias/rencrypt-python What My Project Does: A Python
  encryption library implemented in Rust. It supports AEAD with AES-GCM and ChaCha20Poly1305
  . It uses ring to handle encryption. If offers slightly higher speed compared to
  other Python libs, especially for small chunks of data. Target Audience This lib
  hasn''t been audited, but it mostly wraps ring crate which is a well known library,
  so in principle it should offer as similar level of security. This is still under
  development. Please do not use it with sensitive data just yet. Comparison If offers
  slightly higher speed compared to other Python libs, especially for small chunks
  of data. I compared it to PyFLocker , cryptography , NaCl ( l ibsodium ) , PyCryptodome
  . The API also tries to be easy to use but it''s more optimized for speed than usability.'
Title: 'A blend of Rust and Python: a faster encryption for Python'
---
Author: u/eonlav
Content: 'What My Project Does Allows you to have a voice-to-voice interaction with
  an LLM, similar to the ChatGPT app, except with all inference running locally. You
  can choose from a few different open-weight models. Video running Phi-2 model on
  a MacBook Air with 8GB RAM, all CPU Target Audience Devs looking to experiment with
  integrating on-device AI into their software. Comparison JARVIS - an all API-based
  solution using DeepGram, OpenAI and ElevenLabs Local Talking LLM - a higher-latency,
  more resource intensive local approach using Whisper, Llama and Bark, but with no
  wake word. Source code: https://github.com/Picovoice/pico-cookbook/tree/main/recipes/llm-voice-assistant/python'
Title: AI Voice Assistant using on-device LLM, STT, TTS and Wake Word tech
---
Author: u/Zorgon-589
Content: 'WHAT MY PROJECT DOES: Solves basic arithmetic problems in an interactive
  way in python. TARGET AUDIENCE: Anyone, it''s just a program to get practice using
  loops, lists, and functions. COMPARISON: This program functions as a calculator
  without the use of the eval() function to make everything superfluously easy. It''s
  not perfect and my next version is gonna try and address queries with parenthesis
  and multiple operators! See the below link for github: https://github.com/Zorgon589/Calculator/tree/main'
Title: Calculator without eval()
---
Author: u/radumarias
Content: REncrypt What My Project Does A Python encryption library implemented in
  Rust. It supports AEAD with AES-GCM and ChaCha20Poly1305. It uses ring to handle
  encryption. If offers slightly higher speed compared to other Python libs, especially
  for small chunks of data. The API also tries to be easy to use but it's more optimized
  for speed than usability. So if you are open to experiment and want to achieve the
  highest possible encryption speed, consider giving it a try. Target Audience This
  is just a toy project as a learning experience Comparison This is slightly faster
  than PyFLocker which from my benchmarks is the faster among other Python libs like
  cryptography, NaCl (libsodium), PyCryptodome
Title: 'A blend of Rust and Python: speeding up Python encryption'
---
Author: u/neozhaoliang
Content: 'What My Project Does An open-source RAG (Retrieval-Augmented Generation)
  engine based on deep document understanding. It offers layout recognition, OCR-based
  chunking templates for data cleasing and provides hallucination-free answers with
  traceable citations. Compatible with mainstream LLMs. Target Audience RAG applications
  developers. Comparison It offers various chunking templates for various fils categories,
  such as resume, legal documents, table, and print copies. Enables human intervention
  in chunking, making the data cleansing process no longer a black box. It not only
  presents answers but also offers quick views of references and links to the citations
  when answering to queries. Link: https://github.com/infiniflow/ragflow'
Title: 'RAGFlow: Deep document understanding RAG engine'
---
Author: u/ALior1
Content: 'So I''m trying to do a small refresher in design patterns and I reached
  the Observer pattern. And I''m encounter a circular import error that I''m not sure
  how to solve. At first I had two files: `observers.py` and `subjects.py`, which
  each contained the abstract class and some concrete ones. But because each  had
  to know about the other, I got a circler import error. I tried to put them in the
  same file, but than the first cant use the second. Also tried to put the Observer
  in the "subjects.py" file, textualy before "Subject", that worked, but not clear
  to me why. I know that in compiled languages, they just use an interface, but we
  dont have it in Python. Tried to solved it in a various ways, but want to hear others,
  how you think this can be solved and opinons on this. The base classes are: class
  Subject(ABC): @abstractmethod def attach(self, observer: Observer) -> None: # The
  Observer is in the method parameters, so we need to import it pass class Observer(ABC):
  @abstractmethod def update(self, subject: Subject) -> None: # The Subjectis in the
  method parameters, so we need to import it pass'
Title: Circler imports in Observer design pattern in Python
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/radumarias
Content: '[ https://github.com/radumarias/rencrypt-python](https://github.com/radumarias/rencrypt-python)
  * **What My Project Does** A Python encryption library implemented in Rust. It supports
  AEAD with AES-GCM and ChaCha20Poly1305. It uses ring to handle encryption.If offers
  slightly higher speed compared to other Python libs, especially for small chunks
  of data. The API also tries to be easy to use but it''s more optimized for speed
  than usability. So if you are open to experiment and want to achieve the highest
  possible encryption speed, consider giving it a try. * **Target Audience** This
  is just a toy project as a learning experience * **Comparison** This is slightly
  faster than PyFLocker which from my benchmarks is the faster among other Python
  libs like cryptography, NaCl (libsodium), PyCryptodome'
Title: 'New project: A blend of Rust and Python: speeding up Python encryption'
---
Author: u/crawles89
Content: 'What it does: It is for building AI agents that perform tasks for you on
  Android using LLMs. Agents read the screen and perform actions like clicking, typing,
  and dragging. It includes a test suite of 116 tasks across 20 real-world apps to
  evaluate agent performance. Think of each task like a unit test, with a setup, evaluation,
  and tear down procedure. Every task is written in Python. The most powerful agents
  should be able to pass all of them. Target Audience: Anyone looking to experiment
  with LLM for controlling Android UIs. You can download any app you‚Äôd like and test
  out the default agent, M3A, on it. Just give it a task like ‚ÄúShow my most recent
  purchases on Amazon.‚Äù You can also build your own agent. Comparison For desktop
  OSes, there is OSWorld , although it requires costly commercial software (VMWare)
  to run. AndroidWorld only requires free Android emulator. While this is OSS and
  for research, the closest commercial product would be the Rabbit R1 . They should
  test their agent on AndroidWorld to improve accuracy before shipping again :P Link
  to repo: https://github.com/google-research/android_world'
Title: AndroidWorld ‚Äî Build and test AI agents on Android
---
Author: u/Sn3llius
Content: Hey everyone, I'm a Rio developer, and I just wanted to say thanks for all
  the feedback we've received so far! Since our launch, we've implemented a lot of
  the features you asked for! As requested, we are currently working on an in-depth
  technical description of Rio, explaining how it works under the hood. So stay tuned!
  We are looking forward to your feedback, so let us hear from you! :) GitHub
Title: 'Rio: WebApps in pure Python ‚Äì Thanks and Feedback wanted!'
---
Author: u/monorepo
Content: 'This years SO survey is out now. It includes questions for Python tooling
  and frameworks. Contribute when you can, it closes soon. It takes ~10 minutes to
  finish. Link to the survey: https://stackoverflow.az1.qualtrics.com/jfe/form/SV_6rJVT6XXsfTo1JI'
Title: 2024 StackOverflow Survey
---
Author: u/SpareRevolution1487
Content: 'What my library does You can easily and powerfully perform caching and memoizing
  operations in your Python projects using my library. This library is written in
  Rust, which makes its performance very fast and efficient. By using this library,
  you can use 7 different caching algorithms that allow you to choose the best algorithm
  based on your needs. One prominent feature of this library is its simplicity to
  work with. You just need to import the library into your project and then behave
  with it like a dictionary. Therefore, if you are looking for a powerful, fast, and
  simple library for caching and memoizing in Python, my library will be responsive
  to your needs. By using this library, you can improve the performance of your program
  and significantly reduce the execution time of your Python code. Target Audience
  For anyone who needs caching and values speed Comparison When compared to other
  caching libraries: It''s very faster than others (about 5-20x) It''s very simple
  and easy to use It''s completely thread-safe (uses RwLock) It uses lower memory
  than others You can see benchmark here: https://github.com/awolverp/cachebox-benchmark
  More Info My project github: https://github.com/awolverp/cachebox'
Title: 'cachebox: The fastest caching library written in Rust'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/PyDataAmsterdam
Content: Hey all, we will close the Call for Proposals portal this Sunday, June 2
  , for our PyData Amsterdam 2024 Conference which will take place on September 18-20
  in Amsterdam. We are looking for presentations that can captivate our audience,
  provide invaluable insights, and foster community learning. Don't miss this chance
  to speak on stage in front of over 800 attendees in the field of Data & AI. Submit
  a talk here > https://amsterdam2024.pydata.org/cfp/cfp
Title: PyData Amsterdam 2024 Call for Proposals closes on Sunday, June 2
---
Author: u/CanaryHill
Content: 'What My Project Does Zango, built on top of Django, is further opinionated
  towards building enterprise ready custom business apps. Includes additional batteries
  for out of the box enterprise readiness and rapid app development. Growing ecosystem
  of packages that serves as building blocks of apps. Zango also enables multi-tenancy
  where each tenant, representing an app/microservices, can be deployed independently
  on the same underlying monolith. Tenants have logically seperated db, codebase as
  well as deployment. This significantly cuts down per app hosting cost and enables
  microservices pattern without the cost overhead. Target Audience Enterprises: Benefits
  from the open core concept. No vendor lock-ins. Rapid development with out-of-the-box
  enterprise readiness. Startups: Get productive from day-1. Leverage packages to
  reach MVP really fast and not be constrained by limit on customizability (as with
  low-code/no-code solutions). Lowest cost of hosting if you have multiple apps or
  building microservices. Consulting/ Development companies: Increase development
  efficiency and optimize on hosting cost. You: If you are looking to develop any
  bespoke app, give it a try :) Comparison Web dev frameworks(e.g. Django): Not opinionated
  for enterprise readiness/ business apps. Zango enables faster development, lower
  opex and and built-in compliance and enterprise readiness Proprietary platforms
  (e.g. Salesforce): No vendor lock-in. Faster development Low-Code / No-Code: Limited
  customizability. More Info Know more at the project''s Github repo: https://github.com/Healthlane-Technologies/Zango'
Title: Zango - New python framework for building enterprise ready business apps. Salesforce
  alternative.
---
Author: u/Zahlii
Content: 'What the Project Does The idea is to provide an easy to use (and fully typed,
  including camera settings!) abstraction around libgphoto2, allowing even non-tech-savy
  users to write Python scripts/sequences to take pictures. Generally, it supports
  all cameras that libgphoto2 also supports! Possible use cases are: Source code/examples
  available here (this one can be used to automatically take an image once a lightning
  strike is detected): https://github.com/Zahlii/pyDSLR/blob/main/examples/lightning_trigger.py
  Lightning trigger (showcased) Bulb capture (showcased) High Speed capture (e.g.
  using computer vision to detect animals and use the camera as part of a wildlife
  trap, partly showcased) Photo booths Timelapses (also for cameras that don''t naturally
  support them) Focus bracketing (also for cameras that don''t natively support them)
  Astro stacking (Taking hundreds of long exposures with fixed settings after another)
  With a computer-controllable astro mount we could also track the camera based on
  preview images Target Audience For now, mainly Python hobby photographers, but in
  the future hopefully also less tech savy hobbysts. Right now it is obviously still
  a work in progress (with only types available for my Canon R6II), and I am inviting
  people to reach out to me if they are interested in participating or have cameras
  to add to our types :) Comparison with Other Libraries When compared to other library
  around it: We wrap python-gphoto2''s low level API gphoto2-cffi is an alternative,
  but not maintained in 7 years, lacks typing support and doesn''t provide much benefits
  over existing low-level APIs'
Title: 'pyDSLR: Easy-to-use wrapper around libgphoto2 to control your DSLR/DSLM from
  Linux/MacOS'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!'
---
Author: u/HP7933
Content: 'The Python on Microcontrollers (and Raspberry Pi) Newsletter: subscribe
  for free With the Python on Microcontrollers newsletter, you get all the latest
  information on Python running on hardware in one place! MicroPython, CircuitPython
  and Python on single Board Computers like Raspberry Pi & many more. The Python on
  Microcontrollers newsletter is the place for the latest news. It arrives Monday
  morning with all the week‚Äôs happenings. No advertising, no spam, easy to unsubscribe.
  11,019 subscribers - the largest Python on hardware newsletter out there. Catch
  all the weekly news on Python for Microcontrollers with adafruitdaily.com . This
  ad-free, spam-free weekly email is filled with CircuitPython, MicroPython, and Python
  information that you may have missed, all in one place! Ensure you catch the weekly
  Python on Hardware roundup ‚Äì you can cancel anytime . Try our spam-free newsletter
  today! https://www.adafruitdaily.com/'
Title: The Python on Microcontrollers (and Raspberry Pi) Newsletter, a weekly news
  and project resource
---
Author: u/nicoloboschi
Content: 'Poetry plugin to generate Dockerfile and images automatically This project
  lets you generate a docker image or just a Dockerfile for your poetry application
  without manual setup It is meant for production images. https://github.com/nicoloboschi/poetry-dockerize-plugin
  https://pypi.org/project/poetry-dockerize-plugin/ Get started with poetry self add
  poetry-dockerize-plugin@latest This command generates a production-ready, optimized
  python image: poetry dockerize or to generate a Dockerfile poetry dockerize --generate'
Title: From poetry to docker - easy way
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Wednesday Daily Thread: Beginner questions'
---
Author: u/greenrobot_de
Content: ObjectBox ( GitHub ) is an embedded database for Python objects and high-dimensional
  vectors. Today is it's first stable release for Python developers. It's very lightweight
  similar to SQLite, but built for objects so it's faster as there's no SQL layer
  in-between. It's the very first vector database that also runs on smaller low-memory
  devices. The article comes with first benchmarks and hints at the LangChain integration.
Title: A "new" Object & Vector Database for Python
---
Author: u/must1088
Content: https://github.com/must108/musicnotes What My Project Does musicnotes is
  a small open-source project that lets you play musical instruments (currently, only
  piano and guitar) in your Python programs. I created this project as I wanted to
  create a simple and useful open-source project for beginner developers to easily
  contribute to the project. I know it's hard to find good open-source projects for
  new developers. Target Audience Developers looking to add sounds to small games,
  or just have fun while learning Python in general. This library could also be used
  to teach Python and coding in a fun way. This project was also made to allow new
  Python developers to easily contribute to open-source! Feel free to star the repository,
  and download with pip install musicnotes ! You can also create a pull request with
  any changes you find useful, and visit the GitHub repository if you find any setbacks
  while using this module. There are a few things that can be worked on listed in
  the README of the repository if you're looking for a place to get started. Comparison
  This project is very simple and easy to use, and is easy to contribute to as well,
  which is one of the primary goals of the project.
Title: 'musicnotes: Python module for playing musical instruments!'
---
Author: u/XUtYwYzz
Content: 'I saw the words ''visual effects'', just give me GIFs Understandable, visit
  the Effects Showroom first. Then come back if you like what you see. What My Project
  Does TerminalTextEffects (TTE) is a terminal visual effects engine. TTE can be installed
  as a system application to produce effects in your terminal, or as a Python library
  to enable effects within your Python scripts/applications. TTE includes a growing
  library of built-in effects which showcase the engine''s features. Use cases: Invoke
  at terminal launch to produce an animation (ex: fetch). Alias system commands to
  animate output. Invoke on SSH session to blow people''s minds when they log in.
  Use in your project to produce animated prompts, logos, etc. Target Audience TTE
  is a terminal toy (and now a Python library) that anybody can use to add visual
  flair to their terminal or projects. It works best in Linux but is functional in
  the new Windows Terminal. Every effect allows for significant customization including
  color gradient stops and directions as well as many effect-specific options. Customization
  is exposed via command-line arguments and through the Config class interface. The
  effect examples shown in the documentation represent a single configuration. Your
  experience can be very different with a little tweaking to match your system theme
  and preferences. Comparison I don''t know of any other projects like TTE. It''s
  a completely useless and over-engineered side-project that''s turned into a whole
  thing. Have fun. More Info The GitHub README has some effect examples, installation
  instructions and some basic quick-start info.'
Title: TerminalTextEffects (TTE) - A terminal visual effects engine, application,
  and library.
---
Author: u/SuperMB13
Content: 'Been working on a python tool for VS Code. Curious to get peoples'' opinion
  on how they run python files (not notebooks) within VS Code. Do you typically run
  files python by: Typing the python command into the integrated terminal Clicking
  the run button at the top of the file Pressing F5 for debugging Pressing Ctrl+F5
  for run but not debug Creating a custom keyboard shortcut Other Let me know your
  thoughts, I appreciate the insights!'
Title: Preferred method to run python in VS Code
---
Author: u/justme_sam
Content: 'Have you ever faced a moment when your code is a mess of nested classes
  and functions, and you have to dig through dozens of levels to understand a simple
  function? Gloe (pronounced like ‚Äúglow‚Äù) is a library designed to assist you organize
  your code into a type-safe flow, making it flat and linear. What My Project Does
  Here‚Äôs what it can do for you: Write type-safe pipelines with pure Python. Express
  your code as a set of atomic and extensible units of responsibility called transformers
  . Validate the input and output of transformers, and changes between them during
  execution. Mix sync and async¬†code without worrying about its concurrent nature.
  Keep your code readable and maintainable , even for complex flows . Visualize you
  pipelines and the data flowing through them. Use it anywhere without changing your
  existing workflow. Target Audience : any Python developer who sees their code as
  a flow (a series of sequential operations) and wants to improve its readability
  and maintainability. It''s production-ready! Comparison : Currently, unlike platforms
  like¬†Air Flow¬†that include scheduler backends for task orchestration, Gloe‚Äôs primary
  purpose is to aid in development. The graph structure aims to make the code¬†more
  flat and readable. Example of usage in a server: send_promotion = ( get_users >>
  ( filter_basic_subscription >> send_basic_subscription_promotion_email, filter_premium_subscription
  >> send_premium_subscription_promotion_email, ) >> log_emails_result ) @users_router.post(''/send-promotion/{role}'')
  def send_promotion_emails_route(role: str): return send_promotion(role) Full code
  . Links : github.com/ideos/gloe gloe.ideos.com.br'
Title: 'Gloe: A lightweight lib to create readable and type-safe pipelines'
---
Author: u/ThePawners
Content: 'What My Project Does: This project aims to provide a simple and efficient
  way to manage a collection of books through various API endpoints. This API allows
  you to: Get a list of all books. Add a new book. Get a book by its isbn. Update
  an existing book by its isbn. Delete a book by its isbn. API Endpoints: GET /api/v1/books
  - Retrieve all books. POST /api/v1/books - Add a new book. GET /api/v1/books/<ISBN>
  - Retrieve a book by its ISBN. PUT /api/v1/books/<ISBN> - Update a book by its ISBN.
  DELETE /api/v1/books/<ISBN> - Delete a book by its ISBN. Target Audience: Anyone
  who is interested to integrate book management api into their applications. Website
  API: Book Management API GitHub Repo: Book-Management-API on GitHub Follow Me: IG:
  @nordszamora Threads: @nordszamora Tiktok: @nordszamora Github: @nordszamora'
Title: Book Management Restful-API
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Tuesday Daily Thread: Advanced questions'
---
Author: u/danyourmaster
Content: 'What it does: Today, I released the first working version of my SH1106 app
  framework for Raspberry Pi on PyPI! The SH1106 is an affordable OLED screen, costing
  under $3, and it''s perfect for projects of all sizes. This package enables the
  creation of apps for it with graphics support, state management, image conversion
  utilities, and custom fonts. Check it out here: SH1106 Framework on PyPI . Target
  audience: The package is mainly aimed at hobbyists who want to create small projects
  using the SH1106 OLED without having to manually write a lot of the graphics code
  typically needed on top of standard packages. I am also developing a hardware synthesizer
  keyboard from scratch that utilizes this framework extensively. So far, the framework
  handles the massive scaling required for this project excellently in terms of both
  code organization and performance. Comparison: This package offers several advantages
  over other SH1106 packages: Improved Rendering Speed: It significantly speeds up
  the rendering time for a given frame by writing all graphical operations to a pixel
  array, which is then loaded onto the screen using low-level functions from the excellent
  luma.oled package. Efficient Resource Management: All images and fonts are pre-loaded
  during the initialization of the framework, reducing the processing time during
  rendering. State Management: A simple yet effective state management system is implemented,
  making app creation straightforward from the start. You can also check out the project
  on GitHub: SH1106 Framework on GitHub . I''d love to answer any questions you have
  in the comments! I hope you find some cool uses for it. Cheers! :)'
Title: SH1106 OLED Screen App Framework for Raspberry Pi - Now on PyPI
---
Author: u/coryalanfitz
Content: 'https://github.com/coryfitz/crowbar What it does: I''m working on a way
  of simplifying your Python dependency management. Basically, it handles virtual
  environments so you don‚Äôt have to think about them. First: pip install crowbar-package-manager
  Basically you just install and run things with the crowbar command rather than pip:
  crowbar install package_name And then you also run things with the crowbar command
  rather than using "python" - crowbar then runs the program based on the packages
  in the local environment rather than having to activate your virtual environment.
  It''s inspired by npm if you''ve used that with js. Target audience: Anyone who
  currently uses the standard package management tools (requirements.txt, pip, etc)
  and wants to automate some of those processes. Comparison: The workflow is most
  similar to Poetry but there are a couple of major differences - for one thing, Crowbar
  only does package management; it doesn''t create a project structure for you. Also,
  Poetry puts all of your environments in a central repository - Crowbar keeps it
  in your project folder. Unlike Poetry or any of the other dependency management
  tools out there, you don''t have to buy into a completely different way of structuring
  your dependencies or your projects. A project that you use Crowbar on is identical
  to one where you used pip, venv, and requirements.txt - and if you try Crowbar and
  decide you don''t like it, just activate your virtual environment like normal.'
Title: Crowbar - Package Management without Venv
---
Author: u/Cerricola
Content: When working with Matlab I love how I can run the code step by step to debug
  it. Even being able to "step in" functions and loops. Then, I was looking to an
  IDE with a similar functionality for Python. Nowadays I'm using Spyder.
Title: An IDE with the same step by step functionality as in Matlab
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Monday Daily Thread: Project ideas!'
---
Author: u/Mews75
Content: What My Project Does Because spotify made their lyrics menu a premium only
  feature, I thought I'd make my own replacement for it. The app connects to your
  spotify account, fetches the lyrics from various websites, and then syncs them automatically
  to what is currently playing. Basically does the exact same as the lyrics menu used
  to do. Target Audience Anyone who wants to see the lyrics to songs really. Comparison
  Most other apps that I've found are either browser only, or don't actually sync
  the lyrics to the song, they just show the entire lyrics at once. In comparison,
  my app shows the lyrics line by line, synced with the song, and also has (in my
  opinion lol) a fairly nice looking ui. It's also very easy to use for non programmers
  too, since you can just download an executable to use the app. It's available for
  free here https://github.com/Mews/spotify-lyrics
Title: Spotify Lyrics visualizer
---
Author: u/Status_Bid_1604
Content: What My Project Does Simplifies the interaction with the ShipEngine API with
  most response and requests built as objects, which in my opinion makes interaction
  much easier. This is my first released package so all criticism and feedback is
  very welcome. Target Audience Anyone who deals with the current ShipEngine API using
  Python. Comparison There is an official ShipEngine API module that is created by
  the company but I have found it somewhat lack luster with no way to create batches
  or bulk shipments (and other missing functionality), this is much more suited to
  accomplishing that task. Links https://github.com/Sen-tio/unofficial-shipengine
Title: I created an unofficial module for the ShipEngine API
---
Author: u/realretooth
Content: Introducing Xenharmlib (Source code here ) What My Project Does (taken from
  the docs) Xenharmlib is a music theory library for the exploration and research
  of microtonality, diatonic set theory, non-standard notations, and many more. The
  library implements a superset of Western classical music theory, so you can also
  use it to compose and analyze music in the boundaries of the common practice period
  or 20th century Western music. Target Audience Composers who want to get answers
  to theoretical questions pertaining to structures of musical scales, note intervals,
  frequencies and frequency ratios in equal division tunings. People who want to explore
  microtonality or non-western musical theory in general. Comparison * mingus Xenharmlib
  is pretty much on-par with features in mingus, however extends those features to
  all sorts of equal division temperaments. * pytuning supports more slightly tuning
  methods and export formats, however does not support microtonal notation or note
  / interval calculation * music21 is much more mature in providing an analytical
  toolset, however supports only traditional western equal temperament
Title: Xenharmlib - An advanced music theory library that supports microtonality
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/nginx26
Content: Good evening! I have created a new projectfor adding events to google calendar
  based on the text a user inputs. What My Project Does The project is a tool that
  uses large language models to understand the user's input and add events to the
  user's Google Calendar based on the user's input. It uses Ollama for natural language
  understanding and Google Calendar API for adding events to the user's calendar.
  How My Project Works Ollama uses Llama 3 with pre-instructions to act as a calendar
  event planner. The tool uses the model to generate responses to extract the event's
  details from the user's input inserted in the Web Interface. tool then asks the
  user to confirm the details extracted from the user's input and adds the event to
  the user's Google Calendar (example shown here ) References Checkout my github repository
  AIPlanner for more details about the project.
Title: 'AI planner: AI tool for efficient event scheduling in Google Calendar.'
---
Author: u/Brilliant_Emphasis63
Content: Introducing PyPods What My Project Does A Python library designed to manage
  monolithic project architectures by isolating dependencies. Traditionally, monolithic
  architectures cluster all dependencies into one project, creating complexities and
  potential conflicts. PyPods offers a solution by isolating these dependencies and
  enabling the main project to communicate with them via remote procedure calls. This
  approach eliminates the need to install dependencies directly in the main project.
  Feel free to take a look and I am happy to receive some feedback! Target Audience
  Production grade. Comparison This solution is inspired by Babashka pods in the Clojure
  world.
Title: 'PyPods: A lightweight solution to execute Python dependencies in an isolated
  fashion.'
---
Author: u/Reasonable-Zone-7909
Content: 'What My Project Does Hi! This is my first time doing a python project more
  than a few hours in size. I made a chat app which features E2E encryption using
  a passcode and has a multiclient architecture. All comments are welcome! Target
  Audience It is just a toy project for my portfolio. Comparison Compared to other
  chat clients, this one uses a passphrase to encrypt all data, with the passphrase
  being chosen out of the app, for instance on a dinner. But I think that IRC already
  has this, so it doesn''t differ much XD. Git link: https://github.com/xxzoltanxx/Balvan-Chat'
Title: I made a desktop chat app :)
---
Author: u/Zaloog1337
Content: 'Hi everyone, Ive reached a state of my current project, where I want to
  share it with you, and gather some feedback. This is my first time using rye and
  I am surprised, how Hassle-Free building a package with it went. Source Code: github
  Installation python -m pip install rye-tui for CLI Tools I recommend using pipx
  or rye. pipx install rye-tui rye install rye-tui After Installation you can open
  the TUI using trye in your Terminal. On first use a config file is generated. After
  that use trye again in your rye managed project What My Project Does A Text-based
  User Interface (TUI) for rye written in python using Textual Current State Currently
  rye-tui supports the following functionalities of rye: creating new projects (flag-support
  coming soon) adding normal and dev dependencies (flag-support coming soon) pinning
  versions Syncing (flag-support coming soon) changing rye''s configuration (sources
  and default coming soon) Target Audience Python developers and rye users who like
  a UI to manage their rye projects. Comparison To my knowledge there is no similar
  tool for rye. Maybe the Anaconda UI comes closest for Anaconda Users. Last Words
  Feel free to try(e) it out. Happy to hear your feedback.'
Title: Rye-Tui, a Text-based User Interface (TUI) to manage rye projects
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/Zahlii
Content: 'What the Project Does The idea is to provide an easy to use (and fully typed,
  including camera settings!) abstraction around libgphoto2, allowing even non-tech-savy
  users to write Python scripts/sequences to take pictures. Generally, it supports
  all cameras that libgphoto2 also supports! Possible use cases are: Source code/examples
  available here (this one can be used to automatically take an image once a lightning
  strike is detected): https://github.com/Zahlii/pyDSLR/blob/main/examples/lightning_trigger.py
  Lightning trigger (showcased) Bulb capture (showcased) High Speed capture (e.g.
  using computer vision to detect animals and use the camera as part of a wildlife
  trap, partly showcased) Photo booths Timelapses (also for cameras that don''t naturally
  support them) Focus bracketing (also for cameras that don''t natively support them)
  Astro stacking (Taking hundreds of long exposures with fixed settings after another)
  With a computer-controllable astro mount we could also track the camera based on
  preview images Target Audience For now, mainly Python hobby photographers, but in
  the future hopefully also less tech savy hobbysts. Right now it is obviously still
  a work in progress (with only types available for my Canon R6II), and I am inviting
  people to reach out to me if they are interested in participating or have cameras
  to add to our types :) Comparison with Other Libraries When compared to other library
  around it: We wrap python-gphoto2''s low level API gphoto2-cffi is an alternative,
  but not maintained in 7 years, lacks typing support and doesn''t provide much benefits
  over existing low-level APIs'
Title: 'pyDSLR: Easy-to-use wrapper around libgphoto2 to control your DSLR/DSLM from
  Linux/MacOS'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!'
---
Author: u/HP7933
Content: 'The Python on Microcontrollers (and Raspberry Pi) Newsletter: subscribe
  for free With the Python on Microcontrollers newsletter, you get all the latest
  information on Python running on hardware in one place! MicroPython, CircuitPython
  and Python on single Board Computers like Raspberry Pi & many more. The Python on
  Microcontrollers newsletter is the place for the latest news. It arrives Monday
  morning with all the week‚Äôs happenings. No advertising, no spam, easy to unsubscribe.
  11,019 subscribers - the largest Python on hardware newsletter out there. Catch
  all the weekly news on Python for Microcontrollers with adafruitdaily.com . This
  ad-free, spam-free weekly email is filled with CircuitPython, MicroPython, and Python
  information that you may have missed, all in one place! Ensure you catch the weekly
  Python on Hardware roundup ‚Äì you can cancel anytime . Try our spam-free newsletter
  today! https://www.adafruitdaily.com/'
Title: The Python on Microcontrollers (and Raspberry Pi) Newsletter, a weekly news
  and project resource
---
Author: u/nicoloboschi
Content: 'Poetry plugin to generate Dockerfile and images automatically This project
  lets you generate a docker image or just a Dockerfile for your poetry application
  without manual setup It is meant for production images. https://github.com/nicoloboschi/poetry-dockerize-plugin
  https://pypi.org/project/poetry-dockerize-plugin/ Get started with poetry self add
  poetry-dockerize-plugin@latest This command generates a production-ready, optimized
  python image: poetry dockerize or to generate a Dockerfile poetry dockerize --generate'
Title: From poetry to docker - easy way
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Wednesday Daily Thread: Beginner questions'
---
Author: u/greenrobot_de
Content: ObjectBox ( GitHub ) is an embedded database for Python objects and high-dimensional
  vectors. Today is it's first stable release for Python developers. It's very lightweight
  similar to SQLite, but built for objects so it's faster as there's no SQL layer
  in-between. It's the very first vector database that also runs on smaller low-memory
  devices. The article comes with first benchmarks and hints at the LangChain integration.
Title: A "new" Object & Vector Database for Python
---
Author: u/must1088
Content: https://github.com/must108/musicnotes What My Project Does musicnotes is
  a small open-source project that lets you play musical instruments (currently, only
  piano and guitar) in your Python programs. I created this project as I wanted to
  create a simple and useful open-source project for beginner developers to easily
  contribute to the project. I know it's hard to find good open-source projects for
  new developers. Target Audience Developers looking to add sounds to small games,
  or just have fun while learning Python in general. This library could also be used
  to teach Python and coding in a fun way. This project was also made to allow new
  Python developers to easily contribute to open-source! Feel free to star the repository,
  and download with pip install musicnotes ! You can also create a pull request with
  any changes you find useful, and visit the GitHub repository if you find any setbacks
  while using this module. There are a few things that can be worked on listed in
  the README of the repository if you're looking for a place to get started. Comparison
  This project is very simple and easy to use, and is easy to contribute to as well,
  which is one of the primary goals of the project.
Title: 'musicnotes: Python module for playing musical instruments!'
---
Author: u/XUtYwYzz
Content: 'I saw the words ''visual effects'', just give me GIFs Understandable, visit
  the Effects Showroom first. Then come back if you like what you see. What My Project
  Does TerminalTextEffects (TTE) is a terminal visual effects engine. TTE can be installed
  as a system application to produce effects in your terminal, or as a Python library
  to enable effects within your Python scripts/applications. TTE includes a growing
  library of built-in effects which showcase the engine''s features. Use cases: Invoke
  at terminal launch to produce an animation (ex: fetch). Alias system commands to
  animate output. Invoke on SSH session to blow people''s minds when they log in.
  Use in your project to produce animated prompts, logos, etc. Target Audience TTE
  is a terminal toy (and now a Python library) that anybody can use to add visual
  flair to their terminal or projects. It works best in Linux but is functional in
  the new Windows Terminal. Every effect allows for significant customization including
  color gradient stops and directions as well as many effect-specific options. Customization
  is exposed via command-line arguments and through the Config class interface. The
  effect examples shown in the documentation represent a single configuration. Your
  experience can be very different with a little tweaking to match your system theme
  and preferences. Comparison I don''t know of any other projects like TTE. It''s
  a completely useless and over-engineered side-project that''s turned into a whole
  thing. Have fun. More Info The GitHub README has some effect examples, installation
  instructions and some basic quick-start info.'
Title: TerminalTextEffects (TTE) - A terminal visual effects engine, application,
  and library.
---
Author: u/SuperMB13
Content: 'Been working on a python tool for VS Code. Curious to get peoples'' opinion
  on how they run python files (not notebooks) within VS Code. Do you typically run
  files python by: Typing the python command into the integrated terminal Clicking
  the run button at the top of the file Pressing F5 for debugging Pressing Ctrl+F5
  for run but not debug Creating a custom keyboard shortcut Other Let me know your
  thoughts, I appreciate the insights!'
Title: Preferred method to run python in VS Code
---
Author: u/justme_sam
Content: 'Have you ever faced a moment when your code is a mess of nested classes
  and functions, and you have to dig through dozens of levels to understand a simple
  function? Gloe (pronounced like ‚Äúglow‚Äù) is a library designed to assist you organize
  your code into a type-safe flow, making it flat and linear. What My Project Does
  Here‚Äôs what it can do for you: Write type-safe pipelines with pure Python. Express
  your code as a set of atomic and extensible units of responsibility called transformers
  . Validate the input and output of transformers, and changes between them during
  execution. Mix sync and async¬†code without worrying about its concurrent nature.
  Keep your code readable and maintainable , even for complex flows . Visualize you
  pipelines and the data flowing through them. Use it anywhere without changing your
  existing workflow. Target Audience : any Python developer who sees their code as
  a flow (a series of sequential operations) and wants to improve its readability
  and maintainability. It''s production-ready! Comparison : Currently, unlike platforms
  like¬†Air Flow¬†that include scheduler backends for task orchestration, Gloe‚Äôs primary
  purpose is to aid in development. The graph structure aims to make the code¬†more
  flat and readable. Example of usage in a server: send_promotion = ( get_users >>
  ( filter_basic_subscription >> send_basic_subscription_promotion_email, filter_premium_subscription
  >> send_premium_subscription_promotion_email, ) >> log_emails_result ) @users_router.post(''/send-promotion/{role}'')
  def send_promotion_emails_route(role: str): return send_promotion(role) Full code
  . Links : github.com/ideos/gloe gloe.ideos.com.br'
Title: 'Gloe: A lightweight lib to create readable and type-safe pipelines'
---
Author: u/ThePawners
Content: 'What My Project Does: This project aims to provide a simple and efficient
  way to manage a collection of books through various API endpoints. This API allows
  you to: Get a list of all books. Add a new book. Get a book by its isbn. Update
  an existing book by its isbn. Delete a book by its isbn. API Endpoints: GET /api/v1/books
  - Retrieve all books. POST /api/v1/books - Add a new book. GET /api/v1/books/<ISBN>
  - Retrieve a book by its ISBN. PUT /api/v1/books/<ISBN> - Update a book by its ISBN.
  DELETE /api/v1/books/<ISBN> - Delete a book by its ISBN. Target Audience: Anyone
  who is interested to integrate book management api into their applications. Website
  API: Book Management API GitHub Repo: Book-Management-API on GitHub Follow Me: IG:
  @nordszamora Threads: @nordszamora Tiktok: @nordszamora Github: @nordszamora'
Title: Book Management Restful-API
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Tuesday Daily Thread: Advanced questions'
---
Author: u/danyourmaster
Content: 'What it does: Today, I released the first working version of my SH1106 app
  framework for Raspberry Pi on PyPI! The SH1106 is an affordable OLED screen, costing
  under $3, and it''s perfect for projects of all sizes. This package enables the
  creation of apps for it with graphics support, state management, image conversion
  utilities, and custom fonts. Check it out here: SH1106 Framework on PyPI . Target
  audience: The package is mainly aimed at hobbyists who want to create small projects
  using the SH1106 OLED without having to manually write a lot of the graphics code
  typically needed on top of standard packages. I am also developing a hardware synthesizer
  keyboard from scratch that utilizes this framework extensively. So far, the framework
  handles the massive scaling required for this project excellently in terms of both
  code organization and performance. Comparison: This package offers several advantages
  over other SH1106 packages: Improved Rendering Speed: It significantly speeds up
  the rendering time for a given frame by writing all graphical operations to a pixel
  array, which is then loaded onto the screen using low-level functions from the excellent
  luma.oled package. Efficient Resource Management: All images and fonts are pre-loaded
  during the initialization of the framework, reducing the processing time during
  rendering. State Management: A simple yet effective state management system is implemented,
  making app creation straightforward from the start. You can also check out the project
  on GitHub: SH1106 Framework on GitHub . I''d love to answer any questions you have
  in the comments! I hope you find some cool uses for it. Cheers! :)'
Title: SH1106 OLED Screen App Framework for Raspberry Pi - Now on PyPI
---
Author: u/coryalanfitz
Content: 'https://github.com/coryfitz/crowbar What it does: I''m working on a way
  of simplifying your Python dependency management. Basically, it handles virtual
  environments so you don‚Äôt have to think about them. First: pip install crowbar-package-manager
  Basically you just install and run things with the crowbar command rather than pip:
  crowbar install package_name And then you also run things with the crowbar command
  rather than using "python" - crowbar then runs the program based on the packages
  in the local environment rather than having to activate your virtual environment.
  It''s inspired by npm if you''ve used that with js. Target audience: Anyone who
  currently uses the standard package management tools (requirements.txt, pip, etc)
  and wants to automate some of those processes. Comparison: The workflow is most
  similar to Poetry but there are a couple of major differences - for one thing, Crowbar
  only does package management; it doesn''t create a project structure for you. Also,
  Poetry puts all of your environments in a central repository - Crowbar keeps it
  in your project folder. Unlike Poetry or any of the other dependency management
  tools out there, you don''t have to buy into a completely different way of structuring
  your dependencies or your projects. A project that you use Crowbar on is identical
  to one where you used pip, venv, and requirements.txt - and if you try Crowbar and
  decide you don''t like it, just activate your virtual environment like normal.'
Title: Crowbar - Package Management without Venv
---
Author: u/Cerricola
Content: When working with Matlab I love how I can run the code step by step to debug
  it. Even being able to "step in" functions and loops. Then, I was looking to an
  IDE with a similar functionality for Python. Nowadays I'm using Spyder.
Title: An IDE with the same step by step functionality as in Matlab
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Monday Daily Thread: Project ideas!'
---
Author: u/Mews75
Content: What My Project Does Because spotify made their lyrics menu a premium only
  feature, I thought I'd make my own replacement for it. The app connects to your
  spotify account, fetches the lyrics from various websites, and then syncs them automatically
  to what is currently playing. Basically does the exact same as the lyrics menu used
  to do. Target Audience Anyone who wants to see the lyrics to songs really. Comparison
  Most other apps that I've found are either browser only, or don't actually sync
  the lyrics to the song, they just show the entire lyrics at once. In comparison,
  my app shows the lyrics line by line, synced with the song, and also has (in my
  opinion lol) a fairly nice looking ui. It's also very easy to use for non programmers
  too, since you can just download an executable to use the app. It's available for
  free here https://github.com/Mews/spotify-lyrics
Title: Spotify Lyrics visualizer
---
Author: u/Status_Bid_1604
Content: What My Project Does Simplifies the interaction with the ShipEngine API with
  most response and requests built as objects, which in my opinion makes interaction
  much easier. This is my first released package so all criticism and feedback is
  very welcome. Target Audience Anyone who deals with the current ShipEngine API using
  Python. Comparison There is an official ShipEngine API module that is created by
  the company but I have found it somewhat lack luster with no way to create batches
  or bulk shipments (and other missing functionality), this is much more suited to
  accomplishing that task. Links https://github.com/Sen-tio/unofficial-shipengine
Title: I created an unofficial module for the ShipEngine API
---
Author: u/realretooth
Content: Introducing Xenharmlib (Source code here ) What My Project Does (taken from
  the docs) Xenharmlib is a music theory library for the exploration and research
  of microtonality, diatonic set theory, non-standard notations, and many more. The
  library implements a superset of Western classical music theory, so you can also
  use it to compose and analyze music in the boundaries of the common practice period
  or 20th century Western music. Target Audience Composers who want to get answers
  to theoretical questions pertaining to structures of musical scales, note intervals,
  frequencies and frequency ratios in equal division tunings. People who want to explore
  microtonality or non-western musical theory in general. Comparison * mingus Xenharmlib
  is pretty much on-par with features in mingus, however extends those features to
  all sorts of equal division temperaments. * pytuning supports more slightly tuning
  methods and export formats, however does not support microtonal notation or note
  / interval calculation * music21 is much more mature in providing an analytical
  toolset, however supports only traditional western equal temperament
Title: Xenharmlib - An advanced music theory library that supports microtonality
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/nginx26
Content: Good evening! I have created a new projectfor adding events to google calendar
  based on the text a user inputs. What My Project Does The project is a tool that
  uses large language models to understand the user's input and add events to the
  user's Google Calendar based on the user's input. It uses Ollama for natural language
  understanding and Google Calendar API for adding events to the user's calendar.
  How My Project Works Ollama uses Llama 3 with pre-instructions to act as a calendar
  event planner. The tool uses the model to generate responses to extract the event's
  details from the user's input inserted in the Web Interface. tool then asks the
  user to confirm the details extracted from the user's input and adds the event to
  the user's Google Calendar (example shown here ) References Checkout my github repository
  AIPlanner for more details about the project.
Title: 'AI planner: AI tool for efficient event scheduling in Google Calendar.'
---
Author: u/Brilliant_Emphasis63
Content: Introducing PyPods What My Project Does A Python library designed to manage
  monolithic project architectures by isolating dependencies. Traditionally, monolithic
  architectures cluster all dependencies into one project, creating complexities and
  potential conflicts. PyPods offers a solution by isolating these dependencies and
  enabling the main project to communicate with them via remote procedure calls. This
  approach eliminates the need to install dependencies directly in the main project.
  Feel free to take a look and I am happy to receive some feedback! Target Audience
  Production grade. Comparison This solution is inspired by Babashka pods in the Clojure
  world.
Title: 'PyPods: A lightweight solution to execute Python dependencies in an isolated
  fashion.'
---
Author: u/Reasonable-Zone-7909
Content: 'What My Project Does Hi! This is my first time doing a python project more
  than a few hours in size. I made a chat app which features E2E encryption using
  a passcode and has a multiclient architecture. All comments are welcome! Target
  Audience It is just a toy project for my portfolio. Comparison Compared to other
  chat clients, this one uses a passphrase to encrypt all data, with the passphrase
  being chosen out of the app, for instance on a dinner. But I think that IRC already
  has this, so it doesn''t differ much XD. Git link: https://github.com/xxzoltanxx/Balvan-Chat'
Title: I made a desktop chat app :)
---
Author: u/Zaloog1337
Content: 'Hi everyone, Ive reached a state of my current project, where I want to
  share it with you, and gather some feedback. This is my first time using rye and
  I am surprised, how Hassle-Free building a package with it went. Source Code: github
  Installation python -m pip install rye-tui for CLI Tools I recommend using pipx
  or rye. pipx install rye-tui rye install rye-tui After Installation you can open
  the TUI using trye in your Terminal. On first use a config file is generated. After
  that use trye again in your rye managed project What My Project Does A Text-based
  User Interface (TUI) for rye written in python using Textual Current State Currently
  rye-tui supports the following functionalities of rye: creating new projects (flag-support
  coming soon) adding normal and dev dependencies (flag-support coming soon) pinning
  versions Syncing (flag-support coming soon) changing rye''s configuration (sources
  and default coming soon) Target Audience Python developers and rye users who like
  a UI to manage their rye projects. Comparison To my knowledge there is no similar
  tool for rye. Maybe the Anaconda UI comes closest for Anaconda Users. Last Words
  Feel free to try(e) it out. Happy to hear your feedback.'
Title: Rye-Tui, a Text-based User Interface (TUI) to manage rye projects
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/MoodAppropriate4108
Content: 'What My Project Does : I built a pipeline of¬†Dagger¬†modules to send my wife
  and I SMSs twice a week with actionable financial advice generated by AI based on
  data from bank accounts regarding our daily spending. Details: Dagger is an open
  source programmable CI/CD engine. I built each step in the pipeline as a Dagger
  method. Dagger spins up ephemeral containers, running everything within its own
  container. I use GitHub Actions to trigger dagger methods that; retrieve data from
  a source filter for new transactions Categorizes transactions using a zero shot
  model, facebook/bart-large-mnli through the HuggingFace API. This process is optimized
  by sending data in dynamically sized batches asynchronously. Writes the data to
  a MongoDB database Retrieves the data, using Atlas search to aggregate the data
  by week and categories Sends the data to openAI to generate financial advice. In
  this module, I implement a memory using LangChain. I store this memory in MongoDB
  to persist the memory between build runs. I designed the database to rewrite the
  data whenever I receive new data. The memory keeps track of feedback given, enabling
  the advice to improve based on feedback This response is sent via SMS through the
  TextBelt API Full Blog: https://emmanuelsibanda.hashnode.dev/a-dagger-pipeline-sending-weekly-smss-with-financial-advice-generated-by-ai
  Video Demo: https://youtu.be/S45n89gzH4Y GitHub Repo: https://github.com/EmmS21/daggerverse
  Target Audience: Personal project (family and friends) Comparison : We have too
  many budgeting apps and wanted to receive this advice via SMS, personalizing it
  based on our changing financial goals A screenshot of the message sent: https://ibb.co/Qk1wXQK'
Title: I built a pipeline sending my wife and I SMSs twice a week with budgeting advice
  generated by AI
---
Author: u/RevolutionaryPen4661
Content: 'There was a JSX-style syntax preprocessor for Python called " Packed ,"
  which allowed us to write JSX inside Python (*.pyx and *.py) files. It''s unclear
  why they chose *.pyx for the file extension, as it conflicts with the naming of
  Cythonic file extensions (I have checked their issues). This project might have
  thrived with sufficient contributions and could have changed the way apps are built.
  However, the project is now archived on GitHub. The last commit was 5 years ago
  (LICENSE), and the last development commit was 9 years ago. This repository needs
  someone to revive it, but I don''t have enough experience to take on that task.
  Even though I don''t have enough information, we should start with Rust + Python
  to build a compiler (aka. template replacer) (this doesn''t compile Python but replaces
  all JSX with a dictionary) and cleaner syntax. Integration with Django (Packed has
  an example too), Flask, FastAPI, Robyn etc. We may also need plugins for the language
  server, I recommend supporting with *.pyh or *.psx (a fork renamed name) the extension
  file name (Derived from Python + HTML). VSCODE and NVIM Extensions are required
  to build support for this. The existing modern syntax of native Python will continue
  to support this syntax. I made a Handlebars Extension for the community back in
  the day of 2022 but I don''t want to continue the development for it because later
  I disliked the syntax of handlebars (opinion, you''re point of view may contrast
  with my thoughts). We can use emmet for writing easy HTML. @packed def tag(self):
  share = get_share_link() return <a href={share}>Share on internet</a> The main point
  of view is that somehow make returnable components as üëÜ instead of doing this üëá
  def app(): return div(div(p("Hello World")),span("Not a Good Approach for someone
  (opinion)"))'
Title: JSX Syntax inside Python files. (Packed)
---
Author: u/mlejva
Content: What My Project Does Hey everyone! I'm the CEO of the company that built
  an SDK that makes it easy to build custom code interpreters for AI apps . We're
  a company called E2B [0]. We're building and open-source [1] secure environments
  for running untrusted AI-generated code and AI agents. We call these environments
  sandboxes and they are built on top of micro VM called Firecracker [2]. We specifically
  decided to use Firecrackers instead of containers because of their security and
  ability to do snapshots. You can think of us as giving small cloud computers to
  LLMs. We recently created a dedicated SDK for building custom code interpreters
  in Python or JS/TS. We saw this need after a lot of our users have been adding code
  execution capabilities to their AI apps with our core SDK [3]. These use cases were
  often centered around AI data analysis so code interpreter-like behavior made sense
  The way our code interpret SDK works is by spawning an E2B sandbox with Jupyter
  Server. We then communicate with this Jupyter server through Jupyter Kernel messaging
  protocol [4]. Here's our cookbook showing how to add code interpreter to different
  models [5]. We don't do any wrapping around LLM, any prompting, or any agent-like
  framework. We leave all of that to our users. We're really just a boring code execution
  layer that sits at the bottom. We're building for the future software that will
  be building another software. Our long-term plan is to build an automated AWS for
  AI apps and agents where AI can build and deploy its own software while giving developers
  powerful observability into what's happening inside our sandboxes. With everything
  being open-source. Happy to answer any questions and hear feedback! Target Audience
  You can use it in production. We have companies using us in production already.
  Comparison Alternatives we usually see are serverless functions or Docker containers.
  Both have security issues. With serverless functions you can leak data between users
  and with containers you don't really have true isolation. Containers were made for
  packaging and portability, not security. Links https://github.com/e2b-dev/code-interpreter
  [0] https://e2b.dev/ [1] https://github.com/e2b-dev [2] https://github.com/firecracker-microvm/firecracker
  [3] https://e2b.dev/docs [4] https://jupyter-client.readthedocs.io/en/latest/messaging.html
  [5] https://github.com/e2b-dev/e2b-cookbook
Title: We built open-source SDK for adding custom code interpreters to AI apps
---
Author: u/Potato_eating_a_dog
Content: https://github.com/william7491681/APOD_Wallpaper_Script What my project does
  NASA has a ton of accessible API's, one of which being the APOD (Astronomy Picture
  Of the Day) API. I made a script to get the last 9 pictures of the day and set them
  as my Windows 10 background, and then used task scheduler to have the script re-run
  every day at noon and whenever the computer boots up. It's fairly hard coded for
  my setup (specific file paths, 1920x1080 monitor, etc), but it shouldn't be too
  hard to change if one wanted to. Target audience Anyone who likes space backgrounds
  Comparison Idk, automod made me put this section
Title: I made a small Python script that uses NASA'S APOD API to set cool backgrounds
  on a Windows machine
---
Author: u/atharvaaalok1
Content: 'What My Project Does: Hello all, I am a student at Stanford University,
  I was on a gap year due to medical conditions and to utilitze my time I was studying
  deep learning. And Voila... I''ve developed a deep learning library, DeepFusion
  ! Details: It''s customizable and has an easily accessible and highly intuitive
  codebase. One can just dive right in and effortlessly understand the source code.
  You can download it from: github at https://github.com/atharvaaalok/deepfusion or
  install using pip install deepfusion (easy!) For a series of examples explaining
  the usage and features refer demo or tutorials . Target Audience: Machine learning
  and python enthusiasts. Comparison: DeepFusion allows explicit access to all activations
  in a neural network, therefore, making applications such as neural style transfer
  much easier to perform. It also provides an easy user interface for forward and
  backward pass profiling, multiple loss functions, automated training, gpu training
  etc.'
Title: 'DeepFusion: a highly modular Deep Learning Framework.'
---
Author: u/mrocklin
Content: 'I hit publish on a blogpost last week on running Spark, Dask, DuckDB, and
  Polars on the TPC-H benchmark across a variety of scales (10 GiB, 100 GiB, 1 TiB,
  10 TiB), both locally on a Macbook Pro and on the cloud.¬† It‚Äôs a broad set of configurations.¬†
  The results are interesting. No project wins uniformly.¬† They all perform differently
  at different scales: DuckDB and Polars are crazy fast on local machines Dask and
  DuckDB seem to win on cloud and at scale Dask ends up being most robust, especially
  at scale DuckDB does shockingly well on large datasets on a single large machine
  Spark performs oddly poorly, despite being the standard choice üò¢ Tons of charts
  in this post to try to make sense of the data.¬† If folks are curious, here‚Äôs the
  post: https://docs.coiled.io/blog/tpch.html And here''s the code. Performance isn‚Äôt
  everything of course.¬† Each project has its die-hard fans/critics for loads of different
  reasons. I''d be curious to hear if people want to defend/critique their project
  of choice.'
Title: 'TPC-H Cloud Benchmarks: Spark, Dask, DuckDB, Polars'
---
Author: u/sepandhaghighi
Content: 'GitHub Repo: https://github.com/sepandhaghighi/mytimer What My Project Does:
  MyTimer is a Python CLI project that provides a simple, efficient timer for terminal
  users, particularly targeting the geek community. It allows users to set timers
  directly from their command line interface, offering a distraction-free experience.
  mytimer --hour=12 --minute=34 --second=56 --alarm --alarm-repeat=5 ___    ______          ______   _     _         _______  _______
  (___)  (_____ \        (_____ \ | |   (_)       (_______)(_______) _     ____) )   _    _____)
  )| |_____    _    ______   ______ | |   / ____/   (_)  (_____ ( |_____  |  (_)  (_____
  \ |  ___ \ _| |_ | (_____    _    _____) )      | |   _    _____) )| |___) ) (_____)|_______)  (_)  (______/       |_|  (_)  (______/
  |______/ Target Audience: Developers who spend a significant amount of time working
  in the terminal :) Comparison: MyTimer supports more features compared to countdown
  MyTimer offers a greater variety of faces and functions than timer-cli'
Title: 'MyTimer v1.3: A Geeky Timer for Terminal Enthusiasts'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/ryanstephendavis
Content: First timer this year, currently at the airport leaving Pittsburgh after
  6 days of PyCon... I've never seen such an intelligent, inclusive, humble, diverse,
  and inspiring group of human beings.  The Python community serves as a beautiful
  model of what tech culture should strive towards. I could go on and on about how
  much fun I had, but in short, thanks to all the volunteers, staff, and FOSS developers
  that have cultivated such an amazing culture.
Title: Thank You PyConUS 2024 !!!
---
Author: u/zzoetrop_1999
Content: I'm giving a talk on polars in July. It's been pretty fast for us, but I'm
  curious to hear some examples of improvements other people have seen. I got one
  process down from over three minutes to around 10 seconds. Also curious whether
  people have switched over to using polars instead of pandas or they reserve it for
  specific use cases.
Title: Speed improvements in Polars over Pandas
---
Author: u/shekhuu
Content: Hi everyone, I was building something that required me to communicate over
  USB to Raspberry Pi Pico using Pyusb Python. So I decided to make a blog post about
  it showing the concepts, process, and source code. Check out the blog post here!
  Check out the source code here!
Title: Interfacing Custom USB endpoints using Python!
---
Author: u/jonocodes
Content: What My Project Does I made this library to help assert test responses inline
  while directing the comparison to be as rigid or lax as it needs to be. Motivation
  I write a lot of tests that assert values in complex nested dictionaries. But really
  I only need to check some parts in the response, not all of it. I often find myself
  transforming the response or maliciously extracting the important parts I need -
  in order to satisfy the assertions. This gets messy and can make tests hard to follow.
  Target Audience Anyone who writes tests. This is particularly useful if you generate
  fake data in your tests with something like Faker, Factory Boy, or Model Bakery.
  Comparison I have not found a like-project. Searched high and low in PyPI. If such
  a library existed, I would not have written one myself. Feedback appreciated. See
  PyPI project for basic use and github tests for more complex examples .
Title: 'Mystique: Sparse data matching for Python tests'
---
Author: u/WyseTwist
Content: 'Midnight Player - a simple python audiplayer for playing audio What My Project
  Does: My project is just an audio player for playing music, it can play audio from
  folders, supports different audio formats like Flac, Mp3 and can show some information
  about the track. Player uses subprocess to access ffmpeg, then it decodes the audio
  file into pcm format, then plays this file using sounddevice library. the use of
  these libraries is to ensure that the audio file does not lose quality during processing.
  Target Audience: This project was made to increase experience in python programming
  and to understand how the audio playback process works, but the project is also
  useful for people who are interested in learning the structure of the audio player
  as it is open source. Comparison: First of all you should understand that this player
  is not trying to compete with large-scale projects like AIMP because I developed
  this project alone and the project was written in a short period of time. But if
  you compare with other python audio players on github you will notice that many
  people use wrong libraries like qmediaplayer or pygame mixer to create their audio
  player, which are not designed for wide support of audio formats, my project is
  much more complex to operate audio file. Packages and source code can be found here:
  https://github.com/Niamorro/Midnight-Player'
Title: I made python audioplayer with FFmpeg and Qt6
---
Author: u/johnfraney
Content: Hi! I've been enjoying using PyPI's trusted publishing for the Python packages
  I maintain and I threw together a little post showing how I'm using that along with
  Poetry to publish a package from GitHub https://johnfraney.ca/blog/how-to-publish-a-python-package-with-poetry-and-github-actions/
  If you've got any tips for publishing a Python package, I'd be happy to hear those,
  too
Title: How to publish a Python package with GitHub Actions using Poetry
---
Author: u/PyjamaZombie
Content: My project below, to put it simply, periodically checks the console.log for
  when a player join event occurs, when it does, it extracts the player's identifiers
  ( player_name and identity_id ). This is then checked against either, a JSON or,
  a database. I have incorporated standard logging, command-line arguments and threading
  to handle each player process individually. The target audience for this is the
  Arma Reforger community, for which, the application is made for. Currently, to my
  knowledge, there is no application like this available to the Arma Reforger community.
  I am very open to feedback, contributions and advice as want to expand this as much
  as possible! https://github.com/BreathXV/ReforgerWhitelistPy
Title: Reforger Whitelist Py
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!'
---
Author: u/frankstan33
Content: 'Comparison It is inspired from the existing tree command on linux and windows
  too So basically it is just like the tree command, it shows you a tree of the current
  directory structure. What My Project Does It basically gives you a birds eye view
  of your dir structure and quickly navigate to the folder you want to without having
  to know its path or doing cd ../../.. many times. There are a bunch of command line
  args such as setting the paths, flags to show dot directories, set head height (no.
  of parent dirs shown) and tail height (depth). You can traverse around the tree
  using various key presses (inspired from vim keybindings) and based on the given
  argument (-o, -c or --copy) you can output the value (the node to which you traversed),
  cd into it and have it copied into your clipboard.J I had created this for my assignment
  and had a lot of fun with it. Tried to implement as much clean code and good design
  as I could but its still a mess and active work in progress tbh (added unit tests
  lol). And the rendering is still a little slow. Do check it out: pranavpa8788/trav:
  A Traversible Tree command line program (github.com) and let me know what you guys
  think. It is built with support for Windows and Linux, some installation stuff might
  be needed though, and I''ll update those steps soon in the github page Target Audience
  For anyone really, especially if you use a lot of terminal (Had to add the titles
  because my post was getting auto-deleted lol) Link to video demo: https://streamable.com/ds911k'
Title: I made a Traversible Tree in Python
---
Author: u/aoeu512
Content: I've seen programmable semantics (eval-hacking, macros) in LISPs and in Haskell-likes(Monads/Template
  Haskell), the overall techinque in OOP languages is called "Aspect Oriented Programming".  Has
  this kind of thing been discussed before, and is it Pythonic it could allow a lot
  of Python code to be shorter.  Python has sys.set_trace that sort of allows some
  form of programmable semantics but its mostly for debugging. Programmable assignment(variables)
  are like setters/getters/properties, but instead of being run on o.x = 5, you could
  run them on "all local assignments" isnside a context manager or in a decorated
  function.  On every assignment you could do stuff like log the values, update dependencies,
  notify objects, do a database transaction, do persistance, calculate other values,
  without having to explicitly do so for every assignment statement. Programmable
  semicolons (such as Haskell Monads, or reprogramming Lisp do/progn/let) could allow
  you to have the same code run either synchronous, async, get undo/history support,
  break on error, rollback, logging in between lines, changing local/global variables
  in between each line, database access in between lines, checking values for errors,
  ignoring certain statements, etc...  You can think of a semicolon like an "unrolled
  for loop"/iterator ran for each code line.  It would be like async but you can change
  a piece of code to be sync or async at run time by changing the context manager
  you are in.  Programmable "call" can change the default call operation in a context
  manager for all functions and be similar to semicolons. Programmable eval would
  allow you to change the order of operations, choose to ignore certain functions,
  allow you replace certain expensive expressions with others, allow you to keep a
  trace of all evaluations taking place, you can turn an expression/program into an
  interator allowing you to pretty cool stuff.
Title: Programmable Semantics (Eval, Semicolon, Assignment) for Python
---
Author: u/young-and-ignorant
Content: 'Haven''t seen this syntax used very often and was wondering why. During
  error handling, if you have something to run independent of the success, you can
  use finally. from your_library import DataProcess engine = DataProcess() try: engine.io()
  engine.process() engine.some_more_io() except Exception as e: engine.revert() raise
  e finally: engine.cleanup() VS from your_library import DataProcess engine = DataProcess()
  try: engine.io() engine.process() engine.some_more_io() except Exception as e: engine.revert()
  engine.cleanup() raise e engine.cleanup() VS from your_library import DataProcess
  from contextlib import contextmanager @contextmanager def process_data(engine: DataProcess):
  try: engine.io() yield engine except Exception as e: engine.revert() raise e finally:
  engine.cleanup() proc = DataProcess() with process_data(proc) as engine: engine.process()
  engine.some_more_io()'
Title: try... except... finally!
---
Author: u/autokitteh
Content: 'Durable Python enables developers to write Python code while an underlying
  system ensures reliability and resilience. It automatically handles state persistence,
  fault tolerance, and retry mechanisms, allowing developers to focus on business
  logic without worrying about infrastructure concerns. Consider the following code,
  in case the process terminates in the middle of execution, in case the process is
  killed or due to hardware failure, the process will not complete. import requests
  import time SLEEP_SECONDS = 3 URL = "http://localhost:9980/webtools/api/msgs" def
  on_http_get(data): for i in range(10): print("Loop iteration: %d of 10" % (i + 1))
  # Send a POST request to the application requests.post(URL, data = "This is my "
  + str(i) + " iteration...") time.sleep(SLEEP_SECONDS) But actually, I would like
  the process to survive restarts and continue from the spot it terminated, especially
  if it''s a long running process. For this we need Durable Python. I was wondering
  which use cases can take advantage of this technology.'
Title: Durable Python - Infrastructure failures should not stop the process
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Wednesday Daily Thread: Beginner questions'
---
Author: u/AlSweigart
Content: 'https://www.humblebundle.com/books/dive-into-dev-ops-no-starch-books Be
  sure to click on "Adjust Donation" and "Custom Amount" and then max out the amount
  going to the Python Software Foundation. (From $1.75 to $24.50!) For $30 you get
  the following ebooks from No Starch Press: Automate the Boring Stuff with Python,
  2nd Edition DevOps for the Desperate How Linux Works, 3rd Edition The Book of Kubernetes
  PowerShell for Sysadmins Practical Vulnerability Management Practical SQL, 2nd Edition
  Practical Linux Forensics Eloquent JavaScript, 3rd Edition Cybersecurity for Small
  Networks The Linux Command Line, 2nd Edition Web Security for Developers MySQL Crash
  Course Designing Secure Software Network Programming with Go Practice of Network
  Security Monitoring Network Flow Analysis Absolute FreeBSD, 3rd Edition Absolute
  OpenBSD, 2nd Edition Linux Firewalls Pentesting Azure Applications The Book of PF,
  3rd Edition'
Title: Dive into DevOps ebook Humble Bundle supporting the Python Software Foundation
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Tuesday Daily Thread: Advanced questions'
---
Author: u/Stanulilic
Content: Hey r/python ! I wrote a guide on how to use Pytest, covering a bunch of
  important features like designing tests, filtering tests, parameterizing tests,
  fixtures, and more. Check it out on this link .
Title: A Beginner's Guide to Unit Testing with Pytest
---
Author: u/alex-gutev
Content: 'live-cells-py (Live Cells Python) is a reactive programming library which
  I ported from Live Cells for Dart. What my project Does: You can declare cells which
  are observable containers for data: import live_cells as lc a = lc.mutable(0) Cells
  can be defined as a function of other cells: a = lc.mutable(0) b = lc.mutable(1)
  c = lc.computed(lambda: a() + b()) c is defined as the sum of the values of cells
  a and b . The value of c is automatically recomputed when the value of either a
  or b changes. The definition of c can be simplified to the following: c = a + b
  Which reads like an ordinary variable definition You can define a watch function
  which runs whenever the value of a cell changes: lc.watch(lambda: print(f''The sum
  is {c()}'')) This watch function, which prints the value of c to standard output,
  is run automatically whenever the value of c changes. More complex computed cells
  and watch functions can be defined using decorators: n = lc.mutable(5) @lc.computed
  def n_factorial(): result = 1 m = n() while m > 0: result *= m m -= 1 return m @lc.watch
  def watch_factorial(): print(f''{n()}! = {n_factorial()}'') I''ve found this paradigm
  to be very useful for handling events and keeping the state of an application, be
  it a GUI desktop application, systems software or a server, in sync between its
  various components, which is why I ported this library to Python so I can use the
  same paradigm, with a similar API, on the backend as well. Target Audience This
  project is intended for those who are looking for a declarative solution to handling
  and reacting to events in Python applications that is simple and intuitive to use
  and doesn''t require excessive boilerplate. Particularly if you''re used to working
  with signals in JavaScript, you will quickly pick up this library. Comparison The
  de-facto standard for reactive programming is the ReactiveX (RX) series of libraries
  available for various programming languages. The main difference between RxPy and
  Live Cells is in the design of the API, with the main difference being that cells
  are self-subscribing. Referring to the examples shown in the previous sections,
  you do not have to explicitly "connect", "subscribe" to cells nor do you need a
  "map" or "zip" construct to build more complicated reactive pipelines. Instead you
  simply reference whatever you need and the subscription to the dependencies is handled
  automatically by the library. The source code and package is available at: https://github.com/alex-gutev/live_cells_py
  https://pypi.org/project/live-cells-py/ The documentation is available at: https://alex-gutev.github.io/live_cells_py/basics/cells.html'
Title: Reactive programming for Python with live-cells-py
---
Author: u/MoodAppropriate4108
Content: 'What My Project Does : I built a pipeline of¬†Dagger¬†modules to send my wife
  and I SMSs twice a week with actionable financial advice generated by AI based on
  data from bank accounts regarding our daily spending. Details: Dagger is an open
  source programmable CI/CD engine. I built each step in the pipeline as a Dagger
  method. Dagger spins up ephemeral containers, running everything within its own
  container. I use GitHub Actions to trigger dagger methods that; retrieve data from
  a source filter for new transactions Categorizes transactions using a zero shot
  model, facebook/bart-large-mnli through the HuggingFace API. This process is optimized
  by sending data in dynamically sized batches asynchronously. Writes the data to
  a MongoDB database Retrieves the data, using Atlas search to aggregate the data
  by week and categories Sends the data to openAI to generate financial advice. In
  this module, I implement a memory using LangChain. I store this memory in MongoDB
  to persist the memory between build runs. I designed the database to rewrite the
  data whenever I receive new data. The memory keeps track of feedback given, enabling
  the advice to improve based on feedback This response is sent via SMS through the
  TextBelt API Full Blog: https://emmanuelsibanda.hashnode.dev/a-dagger-pipeline-sending-weekly-smss-with-financial-advice-generated-by-ai
  Video Demo: https://youtu.be/S45n89gzH4Y GitHub Repo: https://github.com/EmmS21/daggerverse
  Target Audience: Personal project (family and friends) Comparison : We have too
  many budgeting apps and wanted to receive this advice via SMS, personalizing it
  based on our changing financial goals A screenshot of the message sent: https://ibb.co/Qk1wXQK'
Title: I built a pipeline sending my wife and I SMSs twice a week with budgeting advice
  generated by AI
---
Author: u/RevolutionaryPen4661
Content: 'There was a JSX-style syntax preprocessor for Python called " Packed ,"
  which allowed us to write JSX inside Python (*.pyx and *.py) files. It''s unclear
  why they chose *.pyx for the file extension, as it conflicts with the naming of
  Cythonic file extensions (I have checked their issues). This project might have
  thrived with sufficient contributions and could have changed the way apps are built.
  However, the project is now archived on GitHub. The last commit was 5 years ago
  (LICENSE), and the last development commit was 9 years ago. This repository needs
  someone to revive it, but I don''t have enough experience to take on that task.
  Even though I don''t have enough information, we should start with Rust + Python
  to build a compiler (aka. template replacer) (this doesn''t compile Python but replaces
  all JSX with a dictionary) and cleaner syntax. Integration with Django (Packed has
  an example too), Flask, FastAPI, Robyn etc. We may also need plugins for the language
  server, I recommend supporting with *.pyh or *.psx (a fork renamed name) the extension
  file name (Derived from Python + HTML). VSCODE and NVIM Extensions are required
  to build support for this. The existing modern syntax of native Python will continue
  to support this syntax. I made a Handlebars Extension for the community back in
  the day of 2022 but I don''t want to continue the development for it because later
  I disliked the syntax of handlebars (opinion, you''re point of view may contrast
  with my thoughts). We can use emmet for writing easy HTML. @packed def tag(self):
  share = get_share_link() return <a href={share}>Share on internet</a> The main point
  of view is that somehow make returnable components as üëÜ instead of doing this üëá
  def app(): return div(div(p("Hello World")),span("Not a Good Approach for someone
  (opinion)"))'
Title: JSX Syntax inside Python files. (Packed)
---
Author: u/mlejva
Content: What My Project Does Hey everyone! I'm the CEO of the company that built
  an SDK that makes it easy to build custom code interpreters for AI apps . We're
  a company called E2B [0]. We're building and open-source [1] secure environments
  for running untrusted AI-generated code and AI agents. We call these environments
  sandboxes and they are built on top of micro VM called Firecracker [2]. We specifically
  decided to use Firecrackers instead of containers because of their security and
  ability to do snapshots. You can think of us as giving small cloud computers to
  LLMs. We recently created a dedicated SDK for building custom code interpreters
  in Python or JS/TS. We saw this need after a lot of our users have been adding code
  execution capabilities to their AI apps with our core SDK [3]. These use cases were
  often centered around AI data analysis so code interpreter-like behavior made sense
  The way our code interpret SDK works is by spawning an E2B sandbox with Jupyter
  Server. We then communicate with this Jupyter server through Jupyter Kernel messaging
  protocol [4]. Here's our cookbook showing how to add code interpreter to different
  models [5]. We don't do any wrapping around LLM, any prompting, or any agent-like
  framework. We leave all of that to our users. We're really just a boring code execution
  layer that sits at the bottom. We're building for the future software that will
  be building another software. Our long-term plan is to build an automated AWS for
  AI apps and agents where AI can build and deploy its own software while giving developers
  powerful observability into what's happening inside our sandboxes. With everything
  being open-source. Happy to answer any questions and hear feedback! Target Audience
  You can use it in production. We have companies using us in production already.
  Comparison Alternatives we usually see are serverless functions or Docker containers.
  Both have security issues. With serverless functions you can leak data between users
  and with containers you don't really have true isolation. Containers were made for
  packaging and portability, not security. Links https://github.com/e2b-dev/code-interpreter
  [0] https://e2b.dev/ [1] https://github.com/e2b-dev [2] https://github.com/firecracker-microvm/firecracker
  [3] https://e2b.dev/docs [4] https://jupyter-client.readthedocs.io/en/latest/messaging.html
  [5] https://github.com/e2b-dev/e2b-cookbook
Title: We built open-source SDK for adding custom code interpreters to AI apps
---
Author: u/Potato_eating_a_dog
Content: https://github.com/william7491681/APOD_Wallpaper_Script What my project does
  NASA has a ton of accessible API's, one of which being the APOD (Astronomy Picture
  Of the Day) API. I made a script to get the last 9 pictures of the day and set them
  as my Windows 10 background, and then used task scheduler to have the script re-run
  every day at noon and whenever the computer boots up. It's fairly hard coded for
  my setup (specific file paths, 1920x1080 monitor, etc), but it shouldn't be too
  hard to change if one wanted to. Target audience Anyone who likes space backgrounds
  Comparison Idk, automod made me put this section
Title: I made a small Python script that uses NASA'S APOD API to set cool backgrounds
  on a Windows machine
---
Author: u/atharvaaalok1
Content: 'What My Project Does: Hello all, I am a student at Stanford University,
  I was on a gap year due to medical conditions and to utilitze my time I was studying
  deep learning. And Voila... I''ve developed a deep learning library, DeepFusion
  ! Details: It''s customizable and has an easily accessible and highly intuitive
  codebase. One can just dive right in and effortlessly understand the source code.
  You can download it from: github at https://github.com/atharvaaalok/deepfusion or
  install using pip install deepfusion (easy!) For a series of examples explaining
  the usage and features refer demo or tutorials . Target Audience: Machine learning
  and python enthusiasts. Comparison: DeepFusion allows explicit access to all activations
  in a neural network, therefore, making applications such as neural style transfer
  much easier to perform. It also provides an easy user interface for forward and
  backward pass profiling, multiple loss functions, automated training, gpu training
  etc.'
Title: 'DeepFusion: a highly modular Deep Learning Framework.'
---
Author: u/mrocklin
Content: 'I hit publish on a blogpost last week on running Spark, Dask, DuckDB, and
  Polars on the TPC-H benchmark across a variety of scales (10 GiB, 100 GiB, 1 TiB,
  10 TiB), both locally on a Macbook Pro and on the cloud.¬† It‚Äôs a broad set of configurations.¬†
  The results are interesting. No project wins uniformly.¬† They all perform differently
  at different scales: DuckDB and Polars are crazy fast on local machines Dask and
  DuckDB seem to win on cloud and at scale Dask ends up being most robust, especially
  at scale DuckDB does shockingly well on large datasets on a single large machine
  Spark performs oddly poorly, despite being the standard choice üò¢ Tons of charts
  in this post to try to make sense of the data.¬† If folks are curious, here‚Äôs the
  post: https://docs.coiled.io/blog/tpch.html And here''s the code. Performance isn‚Äôt
  everything of course.¬† Each project has its die-hard fans/critics for loads of different
  reasons. I''d be curious to hear if people want to defend/critique their project
  of choice.'
Title: 'TPC-H Cloud Benchmarks: Spark, Dask, DuckDB, Polars'
---
Author: u/sepandhaghighi
Content: 'GitHub Repo: https://github.com/sepandhaghighi/mytimer What My Project Does:
  MyTimer is a Python CLI project that provides a simple, efficient timer for terminal
  users, particularly targeting the geek community. It allows users to set timers
  directly from their command line interface, offering a distraction-free experience.
  mytimer --hour=12 --minute=34 --second=56 --alarm --alarm-repeat=5 ___    ______          ______   _     _         _______  _______
  (___)  (_____ \        (_____ \ | |   (_)       (_______)(_______) _     ____) )   _    _____)
  )| |_____    _    ______   ______ | |   / ____/   (_)  (_____ ( |_____  |  (_)  (_____
  \ |  ___ \ _| |_ | (_____    _    _____) )      | |   _    _____) )| |___) ) (_____)|_______)  (_)  (______/       |_|  (_)  (______/
  |______/ Target Audience: Developers who spend a significant amount of time working
  in the terminal :) Comparison: MyTimer supports more features compared to countdown
  MyTimer offers a greater variety of faces and functions than timer-cli'
Title: 'MyTimer v1.3: A Geeky Timer for Terminal Enthusiasts'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/ryanstephendavis
Content: First timer this year, currently at the airport leaving Pittsburgh after
  6 days of PyCon... I've never seen such an intelligent, inclusive, humble, diverse,
  and inspiring group of human beings.  The Python community serves as a beautiful
  model of what tech culture should strive towards. I could go on and on about how
  much fun I had, but in short, thanks to all the volunteers, staff, and FOSS developers
  that have cultivated such an amazing culture.
Title: Thank You PyConUS 2024 !!!
---
Author: u/zzoetrop_1999
Content: I'm giving a talk on polars in July. It's been pretty fast for us, but I'm
  curious to hear some examples of improvements other people have seen. I got one
  process down from over three minutes to around 10 seconds. Also curious whether
  people have switched over to using polars instead of pandas or they reserve it for
  specific use cases.
Title: Speed improvements in Polars over Pandas
---
Author: u/shekhuu
Content: Hi everyone, I was building something that required me to communicate over
  USB to Raspberry Pi Pico using Pyusb Python. So I decided to make a blog post about
  it showing the concepts, process, and source code. Check out the blog post here!
  Check out the source code here!
Title: Interfacing Custom USB endpoints using Python!
---
Author: u/jonocodes
Content: What My Project Does I made this library to help assert test responses inline
  while directing the comparison to be as rigid or lax as it needs to be. Motivation
  I write a lot of tests that assert values in complex nested dictionaries. But really
  I only need to check some parts in the response, not all of it. I often find myself
  transforming the response or maliciously extracting the important parts I need -
  in order to satisfy the assertions. This gets messy and can make tests hard to follow.
  Target Audience Anyone who writes tests. This is particularly useful if you generate
  fake data in your tests with something like Faker, Factory Boy, or Model Bakery.
  Comparison I have not found a like-project. Searched high and low in PyPI. If such
  a library existed, I would not have written one myself. Feedback appreciated. See
  PyPI project for basic use and github tests for more complex examples .
Title: 'Mystique: Sparse data matching for Python tests'
---
Author: u/WyseTwist
Content: 'Midnight Player - a simple python audiplayer for playing audio What My Project
  Does: My project is just an audio player for playing music, it can play audio from
  folders, supports different audio formats like Flac, Mp3 and can show some information
  about the track. Player uses subprocess to access ffmpeg, then it decodes the audio
  file into pcm format, then plays this file using sounddevice library. the use of
  these libraries is to ensure that the audio file does not lose quality during processing.
  Target Audience: This project was made to increase experience in python programming
  and to understand how the audio playback process works, but the project is also
  useful for people who are interested in learning the structure of the audio player
  as it is open source. Comparison: First of all you should understand that this player
  is not trying to compete with large-scale projects like AIMP because I developed
  this project alone and the project was written in a short period of time. But if
  you compare with other python audio players on github you will notice that many
  people use wrong libraries like qmediaplayer or pygame mixer to create their audio
  player, which are not designed for wide support of audio formats, my project is
  much more complex to operate audio file. Packages and source code can be found here:
  https://github.com/Niamorro/Midnight-Player'
Title: I made python audioplayer with FFmpeg and Qt6
---
Author: u/johnfraney
Content: Hi! I've been enjoying using PyPI's trusted publishing for the Python packages
  I maintain and I threw together a little post showing how I'm using that along with
  Poetry to publish a package from GitHub https://johnfraney.ca/blog/how-to-publish-a-python-package-with-poetry-and-github-actions/
  If you've got any tips for publishing a Python package, I'd be happy to hear those,
  too
Title: How to publish a Python package with GitHub Actions using Poetry
---
Author: u/PyjamaZombie
Content: My project below, to put it simply, periodically checks the console.log for
  when a player join event occurs, when it does, it extracts the player's identifiers
  ( player_name and identity_id ). This is then checked against either, a JSON or,
  a database. I have incorporated standard logging, command-line arguments and threading
  to handle each player process individually. The target audience for this is the
  Arma Reforger community, for which, the application is made for. Currently, to my
  knowledge, there is no application like this available to the Arma Reforger community.
  I am very open to feedback, contributions and advice as want to expand this as much
  as possible! https://github.com/BreathXV/ReforgerWhitelistPy
Title: Reforger Whitelist Py
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!'
---
Author: u/frankstan33
Content: 'Comparison It is inspired from the existing tree command on linux and windows
  too So basically it is just like the tree command, it shows you a tree of the current
  directory structure. What My Project Does It basically gives you a birds eye view
  of your dir structure and quickly navigate to the folder you want to without having
  to know its path or doing cd ../../.. many times. There are a bunch of command line
  args such as setting the paths, flags to show dot directories, set head height (no.
  of parent dirs shown) and tail height (depth). You can traverse around the tree
  using various key presses (inspired from vim keybindings) and based on the given
  argument (-o, -c or --copy) you can output the value (the node to which you traversed),
  cd into it and have it copied into your clipboard.J I had created this for my assignment
  and had a lot of fun with it. Tried to implement as much clean code and good design
  as I could but its still a mess and active work in progress tbh (added unit tests
  lol). And the rendering is still a little slow. Do check it out: pranavpa8788/trav:
  A Traversible Tree command line program (github.com) and let me know what you guys
  think. It is built with support for Windows and Linux, some installation stuff might
  be needed though, and I''ll update those steps soon in the github page Target Audience
  For anyone really, especially if you use a lot of terminal (Had to add the titles
  because my post was getting auto-deleted lol) Link to video demo: https://streamable.com/ds911k'
Title: I made a Traversible Tree in Python
---
Author: u/aoeu512
Content: I've seen programmable semantics (eval-hacking, macros) in LISPs and in Haskell-likes(Monads/Template
  Haskell), the overall techinque in OOP languages is called "Aspect Oriented Programming".  Has
  this kind of thing been discussed before, and is it Pythonic it could allow a lot
  of Python code to be shorter.  Python has sys.set_trace that sort of allows some
  form of programmable semantics but its mostly for debugging. Programmable assignment(variables)
  are like setters/getters/properties, but instead of being run on o.x = 5, you could
  run them on "all local assignments" isnside a context manager or in a decorated
  function.  On every assignment you could do stuff like log the values, update dependencies,
  notify objects, do a database transaction, do persistance, calculate other values,
  without having to explicitly do so for every assignment statement. Programmable
  semicolons (such as Haskell Monads, or reprogramming Lisp do/progn/let) could allow
  you to have the same code run either synchronous, async, get undo/history support,
  break on error, rollback, logging in between lines, changing local/global variables
  in between each line, database access in between lines, checking values for errors,
  ignoring certain statements, etc...  You can think of a semicolon like an "unrolled
  for loop"/iterator ran for each code line.  It would be like async but you can change
  a piece of code to be sync or async at run time by changing the context manager
  you are in.  Programmable "call" can change the default call operation in a context
  manager for all functions and be similar to semicolons. Programmable eval would
  allow you to change the order of operations, choose to ignore certain functions,
  allow you replace certain expensive expressions with others, allow you to keep a
  trace of all evaluations taking place, you can turn an expression/program into an
  interator allowing you to pretty cool stuff.
Title: Programmable Semantics (Eval, Semicolon, Assignment) for Python
---
Author: u/young-and-ignorant
Content: 'Haven''t seen this syntax used very often and was wondering why. During
  error handling, if you have something to run independent of the success, you can
  use finally. from your_library import DataProcess engine = DataProcess() try: engine.io()
  engine.process() engine.some_more_io() except Exception as e: engine.revert() raise
  e finally: engine.cleanup() VS from your_library import DataProcess engine = DataProcess()
  try: engine.io() engine.process() engine.some_more_io() except Exception as e: engine.revert()
  engine.cleanup() raise e engine.cleanup() VS from your_library import DataProcess
  from contextlib import contextmanager @contextmanager def process_data(engine: DataProcess):
  try: engine.io() yield engine except Exception as e: engine.revert() raise e finally:
  engine.cleanup() proc = DataProcess() with process_data(proc) as engine: engine.process()
  engine.some_more_io()'
Title: try... except... finally!
---
Author: u/autokitteh
Content: 'Durable Python enables developers to write Python code while an underlying
  system ensures reliability and resilience. It automatically handles state persistence,
  fault tolerance, and retry mechanisms, allowing developers to focus on business
  logic without worrying about infrastructure concerns. Consider the following code,
  in case the process terminates in the middle of execution, in case the process is
  killed or due to hardware failure, the process will not complete. import requests
  import time SLEEP_SECONDS = 3 URL = "http://localhost:9980/webtools/api/msgs" def
  on_http_get(data): for i in range(10): print("Loop iteration: %d of 10" % (i + 1))
  # Send a POST request to the application requests.post(URL, data = "This is my "
  + str(i) + " iteration...") time.sleep(SLEEP_SECONDS) But actually, I would like
  the process to survive restarts and continue from the spot it terminated, especially
  if it''s a long running process. For this we need Durable Python. I was wondering
  which use cases can take advantage of this technology.'
Title: Durable Python - Infrastructure failures should not stop the process
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Wednesday Daily Thread: Beginner questions'
---
Author: u/AlSweigart
Content: 'https://www.humblebundle.com/books/dive-into-dev-ops-no-starch-books Be
  sure to click on "Adjust Donation" and "Custom Amount" and then max out the amount
  going to the Python Software Foundation. (From $1.75 to $24.50!) For $30 you get
  the following ebooks from No Starch Press: Automate the Boring Stuff with Python,
  2nd Edition DevOps for the Desperate How Linux Works, 3rd Edition The Book of Kubernetes
  PowerShell for Sysadmins Practical Vulnerability Management Practical SQL, 2nd Edition
  Practical Linux Forensics Eloquent JavaScript, 3rd Edition Cybersecurity for Small
  Networks The Linux Command Line, 2nd Edition Web Security for Developers MySQL Crash
  Course Designing Secure Software Network Programming with Go Practice of Network
  Security Monitoring Network Flow Analysis Absolute FreeBSD, 3rd Edition Absolute
  OpenBSD, 2nd Edition Linux Firewalls Pentesting Azure Applications The Book of PF,
  3rd Edition'
Title: Dive into DevOps ebook Humble Bundle supporting the Python Software Foundation
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Tuesday Daily Thread: Advanced questions'
---
Author: u/Stanulilic
Content: Hey r/python ! I wrote a guide on how to use Pytest, covering a bunch of
  important features like designing tests, filtering tests, parameterizing tests,
  fixtures, and more. Check it out on this link .
Title: A Beginner's Guide to Unit Testing with Pytest
---
Author: u/alex-gutev
Content: 'live-cells-py (Live Cells Python) is a reactive programming library which
  I ported from Live Cells for Dart. What my project Does: You can declare cells which
  are observable containers for data: import live_cells as lc a = lc.mutable(0) Cells
  can be defined as a function of other cells: a = lc.mutable(0) b = lc.mutable(1)
  c = lc.computed(lambda: a() + b()) c is defined as the sum of the values of cells
  a and b . The value of c is automatically recomputed when the value of either a
  or b changes. The definition of c can be simplified to the following: c = a + b
  Which reads like an ordinary variable definition You can define a watch function
  which runs whenever the value of a cell changes: lc.watch(lambda: print(f''The sum
  is {c()}'')) This watch function, which prints the value of c to standard output,
  is run automatically whenever the value of c changes. More complex computed cells
  and watch functions can be defined using decorators: n = lc.mutable(5) @lc.computed
  def n_factorial(): result = 1 m = n() while m > 0: result *= m m -= 1 return m @lc.watch
  def watch_factorial(): print(f''{n()}! = {n_factorial()}'') I''ve found this paradigm
  to be very useful for handling events and keeping the state of an application, be
  it a GUI desktop application, systems software or a server, in sync between its
  various components, which is why I ported this library to Python so I can use the
  same paradigm, with a similar API, on the backend as well. Target Audience This
  project is intended for those who are looking for a declarative solution to handling
  and reacting to events in Python applications that is simple and intuitive to use
  and doesn''t require excessive boilerplate. Particularly if you''re used to working
  with signals in JavaScript, you will quickly pick up this library. Comparison The
  de-facto standard for reactive programming is the ReactiveX (RX) series of libraries
  available for various programming languages. The main difference between RxPy and
  Live Cells is in the design of the API, with the main difference being that cells
  are self-subscribing. Referring to the examples shown in the previous sections,
  you do not have to explicitly "connect", "subscribe" to cells nor do you need a
  "map" or "zip" construct to build more complicated reactive pipelines. Instead you
  simply reference whatever you need and the subscription to the dependencies is handled
  automatically by the library. The source code and package is available at: https://github.com/alex-gutev/live_cells_py
  https://pypi.org/project/live-cells-py/ The documentation is available at: https://alex-gutev.github.io/live_cells_py/basics/cells.html'
Title: Reactive programming for Python with live-cells-py
---
Author: u/klargstein
Content: 'You guys really need to check this. I believe new comers to python would
  love to tinker with the android ecosystem from the safety of python :-) Imgur: https://imgur.com/gallery/DtfwOVi
  https://www.kickstarter.com/projects/kivyschool/the-pain-free-python-on-android-essentials-course
  Edit: added imgur link.'
Title: The possibility to build Android apps with python professionally is here and
  needs your support.
---
Author: u/vikashgraja
Content: 'I‚Äôm an intern in a company and I automated some processes using python.
  My company‚Äôs IT wing said that as long as it is a licensed software you can use
  it in our company. In my mind I was like where the f I‚Äôm going to get a license
  for an open source software. Note : They mention that another team has been using
  licensed python. I thought either IT is so stupid or that team is so smart that
  they brought license for pycharm or anaconda (claim that it is a Python license)
  and fooled IT. If I am wrong then tell me where I can get that license. And I am
  also looking for job in data analyst.'
Title: You should only use licensed version of python
---
Author: u/Soolsily
Content: 'What My Project Does Hey everyone, just released 8 new pip components for
  plotly and dash including: Full Calendar Component - A Full Calendar Component for
  Dash Dash Summernote - A rich text WYSIWYG Editor for Dash Dash Emoji Mart - A Slack-like
  Emoji Picker for Dash Dash Charty - A Charting Library for Dash Dash Image Gallery
  - A Image Gallery Component for Dash Dash Swiper - A Swiper Component for Dash Dash
  Insta Stories - An Instagram Stories Component for Dash Dash Credit Cards - A Credit
  Card Component for Dash Documentation can be found here: https://pip-docs.onrender.com/
  The repo for the github can be found here: https://github.com/pip-install-python/pip-docs
  Target Audience Plotly dash and Python developers. Comparison All these are new
  components for the dash framework, but based on javascript or react projects which
  were forked and edited to work specifically for dash.'
Title: Dash Pip Components
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Monday Daily Thread: Project ideas!'
---
Author: u/Ok_Employ_2414
Content: 'I made a python package for S-transform with Hyperbolic window (Hyperbolic
  S-transform or HSTransform package). This is my first time publishing a python package,
  so the project is still far from stable and still under beta release. What my project
  does: This transformation is applied to signal processing, analyzing transient changes
  of a signal during very short-time. Some special use case can be in power system
  signal, or Geophysical signal analysis, or MRI ... Target audience: anyone who is
  interested in signal processing or power system analysis or geographical analysis.
  Comparison: The comparison with Wavelet Transform has been shown. (which shows more
  potential in detecting transient changes) I would highly appreciate some feedback,
  before progressing further. HSTransform¬†is available on pypi . Link to source code
  in github Quick Usage import numpy as np from hstransform import HSTransform # Create
  input signal (for example: Voltage signal) t = np.linspace(0, 10, 100) # timeseries
  V_m = 220*np.sqrt(2)  # peak voltage f_V = 50  # frequency phi_V = 0  # phase V_clean
  = V_m * np.sin(2 * np.pi * f_V * t + phi_V) # Create voltage sag/dip (80% of the
  nominal voltage for 0.15 second) V_sag = np.where((t >= 2) & (t <= 3.5), 0.5 * V_clean,
  V_clean) # Create an instance of HSTransform hs = HSTransform() # Perform the transform
  signal = V_sag S_transformed = hs.fit_transform(t, signal)'
Title: HS-transform, python package for hyperbolic S-transform in signal processing
---
Author: u/poopatroopa3
Content: 'https://brunodantas.github.io/pydash-cheatsheet/en/ What my project does:
  pydash is a library with great potential to make you code more Functional and simple.
  I made this cheatsheet a while ago to highlight some of the most useful functions
  of the library, since there are so many. I hope it''s useful. Target audience: anyone
  who is interested in pydash, functional programming, not reinventing the wheel.
  Comparison: on Google you can find cheatsheets for Lodash, which is the original
  Javascript library which pydash is inspired by, but no cheatsheets for pydash itself.
  Note that many pydash functions are already implemented in modern Python, so I did
  not include those in the cheatsheet. I made this programatically using Material
  for Mkdocs , which I also recommend. https://github.com/brunodantas/pydash-cheatsheet'
Title: I made a cheatsheet for pydash
---
Author: u/TraditionalDistrict9
Content: 'Hey all, I am not the original creator, but found that 4yo project, and
  decided to revive it! What my project does: IconMatch is library allowing you to
  extract icons and letter positions from image or from display! There is also realtime
  demo on repo showcasing how it works! Target Audience : For all detecting objects
  from display! Comparison : I did not find other project like that - but it was my
  first find too! It is also not OCR! https://github.com/NativeSensors/IconMatch Have
  fun!'
Title: IconMatch - find icons and letters positions from images!
---
Author: u/jgloewen
Content: 'Interactive web applications for data visualization improve user engagement
  and understanding. These days, Streamlit is a very popular framework used to provide
  web applications for data science. It is a terrific programming tool to have in
  you Python knowledge toolbox. Here‚Äôs a fun and practical tutorial on how to create
  a simple interactive and dynamic Streamlit application. This application generates
  a beautiful and original map using the prettymaps library. Free article: HERE'
Title: 'Tutorial: Simple Pretty Maps That Will Improve Your Python Streamlit Skills'
---
Author: u/MohamedElfatih
Content: 'What does my project do Hi everyone I‚Äôm excited to share a project I‚Äôve
  been working on: an interactive 8-puzzle game built using Python and Pygame. This
  project also includes several solvers based on classic search algorithms. Technical
  details: Python: the primary language in the project. Pygame: for rendering and
  handling user interaction. Search algorithms: implement depth first search (dfs)
  and A star search for solving the puzzle. By default A star search is used because
  it finds the solution faster than dfs Target Audience This is a toy project I did
  for fun. You can find the project in GitHub: link I would love to get your feedback,
  contributions, and if you find it interesting or helpful, please give it a star
  on GitHub. Your support and feedback will help me improve and add more features!Thank
  you for checking out my project!'
Title: Interactive 8-Puzzle Game
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/Slow_Scene_7972
Content: 'Optimize Your Python Workflow: Proven Techniques for Crafting Production-Ready
  Code Link'
Title: 'Mastering Python: 7 Strategies for Writing Clear, Organized, and Efficient
  Code'
---
Author: u/abdirxhmxn
Content: 'Hey everyone! I recently completed a fun project that I think fans of "An
  Understated Dominance" will appreciate, especially those who have struggled with
  reading the novel online due to website clutter and distractions. I''ve created
  a clean, distraction-free EPUB version of the novel that you can download and read
  on your preferred device. You can get it here: EPUB Download . Why I did this: The
  original website hosting the novel has a lot of distractions that can take away
  from the reading experience. My goal was to provide a seamless reading experience
  that allows you to fully immerse yourself in the story without unnecessary interruptions.
  Project Details: For those interested in the technical side, here''s a brief overview
  of how I created the EPUB: Web Scraping: I used Python with libraries like requests
  and BeautifulSoup to scrape all 2240 chapters of the novel. Concurrency: Leveraged
  concurrent.futures to speed up the scraping process. Retries: Implemented retry
  logic with tenacity to handle any request failures. EPUB Creation: Used ebooklib
  to compile the scraped content into an EPUB file, complete with chapter headers
  and a cover image. You can check out the full code for this project on my GitHub:
  GitHub Repository . Feedback & Collaboration: I‚Äôd love to hear your thoughts on
  the EPUB. Feel free to download, read, and let me know if you encounter any issues
  or have suggestions for improvements. If you''re interested in collaborating on
  similar projects or have any ideas, I''m all ears! Enjoy the novel, and happy reading!'
Title: Enhanced EPUB Version of "An Understated Dominance" Available for Fans!
---
Author: u/yakimka
Content: 'What My Project Does Picodi is a lightweight and easy-to-use Dependency
  Injection ( DI ) library for Python. Picodi supports both synchronous and asynchronous
  contexts and offers features like resource lifecycle management. Think about Picodi
  as a decorator that helps you manage your dependencies without the need for a full-blown
  DI container. Key Features üåü Simple and lightweight üì¶ Zero dependencies ‚è±Ô∏è Supports
  both sync and async contexts üîÑ Resource lifecycle management üîç Type hints support
  üêç Python & PyPy 3.10+ support Quick Start Here‚Äôs a quick example of how Picodi works:
  import asyncio from collections.abc import Callable from datetime import date from
  typing import Any import httpx from picodi import Provide, init_resources, inject,
  resource, shutdown_resources from picodi.helpers import get_value def get_settings()
  -> dict: return { "nasa_api": { "api_key": "DEMO_KEY", "base_url": "https://api.nasa.gov",
  "timeout": 10, } } @inject def get_setting(path: str, settings: dict = Provide(get_settings))
  -> Callable[[], Any]: value = get_value(path, settings) return lambda: value @resource
  @inject async def get_nasa_client( api_key: str = Provide(get_setting("nasa_api.api_key")),
  base_url: str = Provide(get_setting("nasa_api.base_url")), timeout: int = Provide(get_setting("nasa_api.timeout")),
  ) -> httpx.AsyncClient: async with httpx.AsyncClient( base_url=base_url, params={"api_key":
  api_key}, timeout=timeout ) as client: yield client @inject async def get_apod(
  date: date, client: httpx.AsyncClient = Provide(get_nasa_client) ) -> dict[str,
  Any]: response = await client.get("/planetary/apod", params={"date": date.isoformat()})
  response.raise_for_status() return response.json() async def main(): await init_resources()
  apod_data = await get_apod(date(2011, 7, 19)) print("Title:", apod_data["title"])
  await shutdown_resources() if __name__ == "__main__": asyncio.run(main()) This example
  demonstrates how Picodi handles dependency injection for both synchronous and asynchronous
  functions, manages resource lifecycles, and provides a clean and efficient way to
  structure your code. For more examples and detailed documentation, check out the
  GitHub repository Target Audience Picodi is perfect for developers who want to simplify
  dependency management in their Python applications, but don''t want to deal with
  the complexity of larger DI frameworks. Picodi can help you write cleaner and more
  maintainable code. Comparison Unlike other DI libraries, Picodi does not have wiring,
  a large set of different types of providers, or the concept of a container. Picodi
  prioritizes simplicity, so it includes only the most essential features: dependency
  injection, resource lifecycle management, and dependency overriding. Get Involved
  Picodi is still in the experimental stage, and I''m looking for feedback from the
  community. If you have any suggestions, encounter any issues, or want to contribute,
  please check out the GitHub repository and let me know.'
Title: Picodi - Simplifying Dependency Injection in Python
---
Author: u/moonbunR
Content: Homoiconic, what does it mean? In simple terms, homoiconic code is when code
  is treated as data and can be manipulated as you would data. This means the code
  can be changed, new functions and variables added, the code can generate new code
  or even examine and modify its own structure and behavior all while it is running.
  That‚Äôs why homoiconic languages like Lisp are so powerful. But what if we can make
  a homoiconic python code, where the code and the data are one and the same and can
  be modified in the same way? This guide does a good job in trying to explain how
  you would create a python version of the ‚ÄúLisp in Lisp‚Äù code which would give you
  access to all those homoiconic features that Lisp brags of like the macro systems,
  the expressiveness and flexibility, the metaprogramming etc. while still using python.
  What do you guys think of this?
Title: Homoiconic Python Code
---
Author: u/AND_MY_HAX
Content: 'What My Project Does https://github.com/treykeown/arguably arguably makes
  it super simple to define complex CLIs. It uses your function signatures and docstrings
  to set everything up. Here''s how it works: Adding the @arguably.command decorator
  to a function makes it appear on the CLI. If multiple functions are decorated, they''ll
  all be set up as subcommands. You can even set up multiple levels of subcommands.
  The function name, signature, and docstring are used to automatically set up the
  CLI Call arguably.run() to parse the arguments and invoke the appropriate command
  A small example: #!/usr/bin/env python3 import arguably @arguably.command def some_function(required,
  not_required=2, *others: int, option: float = 3.14): """ this function is on the
  command line! Args: required: a required argument not_required: this one isn''t
  required, since it has a default value *others: all the other positional arguments
  go here option: [-x] keyword-only args are options, short name is in brackets """
  print(f"{required=}, {not_required=}, {others=}, {option=}") if __name__ == "__main__":
  arguably.run() becomes user@machine:~$ ./readme-1.py -h usage: readme-1.py [-h]
  [-x OPTION] required [not-required] [others ...] this function is on the command
  line! positional arguments: required             a required parameter (type: str)
  not-required         this one isn''t required, since it has a default (type: int,
  default: 2) others               all the other positional arguments go here (type:
  int) options: -h, --help           show this help message and exit -x, --option
  OPTION  an option, short name is in brackets (type: float, default: 3.14) It can
  easily hand some very complex cases, like passing in QEMU-style arguments to automatically
  instantiated different types of classes: user@machine:~$ ./readme-2.py --nic tap,model=e1000
  --nic user,hostfwd=tcp::10022-:22 nic=[TapNic(model=''e1000''), UserNic(hostfwd=''tcp::10022-:22'')]
  You can also auto-generate a CLI for your script through python3 -m arguably your_script.py
  , more on that here . Target Audience If you''re writing a script or tool, and you
  need a quick and effective way to run it from the command line, arguably was made
  for you. It''s great for things where a CLI is essential, but doesn''t need tons
  of customization. arguably makes some opinionated decisions that keep things simple
  for you, but doesn''t expose ways of handling things like error messages. I put
  in the work to create GitHub workflows, documentation, and proper tests for arguably
  . I want this to be useful for the community at large, and a tool that you can rely
  on. Let me know if you''re having trouble with your use case! Comparison There are
  plenty of other tools for making CLIs out there. My goal was to build one that''s
  unobtrusive and easy to integrate. I wrote a whole page on the project goals here:
  https://treykeown.github.io/arguably/why/ A quick comparison: argparse - this is
  what arguably uses under the hood. The end user experience should be similar - arguably
  just aims to make it easy to set up. click - a powerhouse with all the tools you''d
  ever want. Use this if you need extensive customization and don''t mind some verbosity.
  typer - also a great option, and some aspects are similar design-wise. It also uses
  functions with a decorator to set up commands, and also uses the function signature.
  A bit more verbose, though like click , has more customization options. fire - super
  easy to generate CLIs. arguably tries to improve on this by utilizing type hints
  for argument conversion, and being a little more of a middle ground between this
  and the more traditional ways of writing CLIs in Python. This project has been a
  labor of love to make CLI generation as easy as it should be. Thanks for checking
  it out!'
Title: The best Python CLI library, arguably.
---
Author: u/YounesWinter
Content: 'With Python i created a tool that enables users to download LinkedIn Learning
  courses, including the often overlooked but incredibly valuable exercise files.
  This feature sets our project apart, offering a complete learning experience by
  providing both the course videos and the materials needed for practical application.
  What great about it and beyond other tools in the same genre concerned LinkedIn
  Learning Downloaders, now you can download the whole courses from a path link. this
  is was never possible without Python. For more detailed information, visit the repo
  : https://github.com/M0r0cc4nGh0st/LinkedIn-Learning-Downloader'
Title: LinkedIn-Learning-Downloader v1.1
---
Author: u/shekhuu
Content: 'Hello there, I just created a template for creating a backend for your SaaS
  products. What my project does: It is a FastAPI project/template for creating SaaS
  backends and admin dashboards. Comparison: Out of the box, it supports Licence key
  generation and validation. OAuth 2 authentication with scopes. Endpoints with pagination
  and filters to easily integrate with an admin dashboard. Passwords are securely
  stored using hashing. used PostgreSQL for database Target Audience: Production Check
  it here! Update 1 : Added pre-commit hooks, tox for testing and linting.'
Title: FastAPI Backend Template for SaaS products
---
Author: u/VladTbk
Content: 'Recently, I found out about the this "Easter egg" in python3. Adding import
  this into a py file will print "The Zen of Python" by Tim Peters. Also, this has
  two attributes: this.s and this.d , which I guess form the actual Easter egg. this.s
  returns an encrypted version of "The Zen" and this.d well, see for yourself, maybe
  you''ll solve the puzzle.'
Title: this.s and this.d
---
Author: u/AbideByReason
Content: 'I made a YouTube video which previews the zoom and explains the code, which
  you can find here: https://youtu.be/HtNUFdh2sjg What my project does: it creates
  a Mandelbrot Zoom. Comparison: it uses Pillow and consists of just 2 main blocks
  of code: one is the main function that finds which points are in the Mandelbrot
  Set and the other is the main loop that applies appropriate colors to each image.
  It gives the option of being black and white OR in color. It works fairly well but
  can definitely be faster if parallelized. I''d love to hear any suggestions on how
  it can be improved. Target Audience: fun/toy project Source code is here: https://github.com/AbideByReason/Python_Notebooks/tree/main'
Title: I made a Mandelbrot Zoom using Python
---
Author: u/PieChartPirate
Content: 'What the project does: data animation library for time-series data. Currently
  it supports the following chart types: Bar races Animated Pie Charts Animated Line
  Charts Animated Stacked Area Charts Animated (World) Maps You can find some simple
  example charts here: https://www.sjdataviz.com/software It is on pypi, you can install
  it using: pip install sjvisualizer It is fully based on TkInter to draw the graph
  shapes to the screen, which gives a lot of flexibility. You can also mix and match
  the different chart types in a single animation. Target audience: people interested
  in data animation for presentations or social media content creation Alternatives:
  I only know one alternative which is bar-chart-race, the ways sjvisualizer is better:
  Smoother animation, bar-chart-race isn''t the quite choppy I would say Load custom
  icons for each data category (flag icons for countries for example) Number of supported
  chart types Mix and match different chart types in a single animation, have a bar
  race to show the ranking, and a smaller pie chart showing the percentages of the
  whole Based on TkInter, easy to add custom elements through the standard python
  GUI library Topics to improve (contributions welcome): Documentation Improve built
  in screen recorder, performance takes a hit when using the built in screen recorder
  Additional chart types: bubble charts, lollipop charts, etc Improve the way data
  can be loaded into the library (currently only supports reading into a dataframe
  from Excel) Sorry for the long post, you can find it here on GitHub: https://github.com/SjoerdTilmans/sjvisualizer'
Title: 'sjvisualizer: a python package to animate time-series data'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/HP7933
Content: 'The Python on Microcontrollers (and Raspberry Pi) Newsletter: subscribe
  for free With the Python on Microcontrollers newsletter, you get all the latest
  information on Python running on hardware in one place! MicroPython, CircuitPython
  and Python on single Board Computers like Raspberry Pi & many more. The Python on
  Microcontrollers newsletter is the place for the latest news. It arrives Monday
  morning with all the week‚Äôs happenings. No advertising, no spam, easy to unsubscribe.
  10,998 subscribers - the largest Python on hardware newsletter out there. (2 more
  for 11k!) Catch all the weekly news on Python for Microcontrollers with adafruitdaily.com
  . This ad-free, spam-free weekly email is filled with CircuitPython, MicroPython,
  and Python information that you may have missed, all in one place! Ensure you catch
  the weekly Python on Hardware roundup‚Äì you can cancel anytime ‚Äì try our spam-free
  newsletter today! https://www.adafruitdaily.com/'
Title: The Python on Microcontrollers (and Raspberry Pi) Newsletter, a weekly news
  and project resource
---
Author: u/mehul_gupta1997
Content: 'Check this video tutorial to explore different AutoEDA python packages like
  pandas-profiling, sweetviz, dataprep,etc which can enable automatic data analysis
  within minutes without any effort : https://youtu.be/Z7RgmM4cI2I?si=8GGM50qqlN0lGzry'
Title: Auto Data Analysis python packages to know
---
Author: u/BeerIsTheMindKiller
Content: 'Hey! Messing around with instaviz, cool library, highly recommend. You can
  visualize a function''s bytecode as well as AST and some other stuff. i entered
  this: def f(): x = 1 + 2 - 10**2 return x I was expecting the AST nodes for 1 +
  2 - 10**2 to be rearranged somehow, with 10**2 being moved to the left hand of the
  expression, because exponents get evaluated before addition/subtraction. but no!
  just looks like this: ... (more tree up here) BinOp |                    \                 \
  BinOp          Sub             BinOp |    \      \                           /    |    \
  1  ADD  2                       10 POW 2 I was assuming operator precedence was
  implemented as the AST level. Seems no - I would assume that the tree would''ve
  had the 10 POW 2 on the left. Does it happen at the control flow graph phase? I
  can imagine the interpreter itself handles it. danke danke danke danke'
Title: 'Folks who know the internals: Where does operator precedence "happen"?'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/rejectedlesbian
Content: https://github.com/nevakrien/time_machine_pip this is a fairly simple project
  barely anything to it but I think its promising the idea is to put pip in a time
  machine so it can not use package versions that were made after the project is made.
  I am doing this by proxiying pypi and cutting out the newer versions. initial tests
  show that pip respects the proxy and works like you would expect
Title: pip time machine
---
Author: u/iryna_kondr
Content: 'Motivation Chatbots are among the most popular applications of large language
  models (LLMs). Often, an LLM''s internal knowledge base is adequate for answering
  users questions. However, in those cases, the model may generate outdated, incorrect,
  or too generic responses when specificity is expected. These challenges can be partially
  addressed by supplementing the LLM with an external knowledge base and employing
  the retrieval-augmented generation (RAG) technique. However, if user queries are
  complex, it may be necessary to break the task into several sub-parts. In such cases,
  relying solely on the RAG technique may not be sufficient, and the use of agents
  may be required. The fundamental concept of agents involves using a language model
  to determine a sequence of actions (including the usage of external tools) and their
  order. One possible action could be retrieving data from an external knowledge base
  in response to a user''s query. In this tutorial, we will develop a simple Agent
  that accesses multiple data sources and invokes data retrieval when needed. We will
  use a Dingo framework that allows the development of LLM pipelines and autonomous
  agents. RAG Agent Architecture and Technical Stack The application will consist
  of the following components: Streamlit : provides a frontend interface for users
  to interact with a chatbot. FastAPI : facilitates communication between the frontend
  and backend. Dingo Agent :¬†agent powered by GPT-4 Turbo model from OpenAI that has
  access to provided knowledge bases and invokes data retrieval from them if needed.
  LLMs docs: a vector store containing documentation about the recently released Phi-3
  (from Microsoft) and Llama 3 (from Meta) models. Audio gen docs: a vector store
  containing documentation about the recently released OpenVoice model from MyShell
  . Embedding V3 small model from OpenAI: computes text embeddings. QDrant : vector
  database that stores embedded chunks of text. Implementation Step 0: Install the
  Dingo framework: pip install agent-dingo Set the OPENAI_API_KEY environment variable
  to your OpenAI API key: export OPENAI_API_KEY=your-api-key Step 1: Create a component.py
  file, and initialize an embedding model, a chat model, and two vector stores: one
  for storing documentation of Llama 3 and Phi-3, and another for storing documentation
  of OpenVoice. # component.py from agent_dingo.rag.embedders.openai import OpenAIEmbedder
  from agent_dingo.rag.vector_stores.qdrant import Qdrant from agent_dingo.llm.openai
  import OpenAI # Initialize an embedding model embedder = OpenAIEmbedder(model="text-embedding-3-small")
  # Initialize a vector store with information about Phi-3 and Llama 3 models llm_vector_store
  = Qdrant(collection_name="llm", embedding_size=1536, path="./qdrant_db_llm") # Initialize
  a vector store with information about OpenVoice model audio_gen_vector_store = Qdrant(collection_name="audio_gen",
  embedding_size=1536, path="./qdrant_db_audio_gen") # Initialize an LLM llm = OpenAI(model
  = "gpt-3.5-turbo") Step 2: Create a build.py file. Parse, chunk into smaller pieces,
  and embed websites containing documentation of the above-mentioned models. The embedded
  chunks are used to populate the corresponding vector stores. # build.py from components
  import llm_vector_store, audio_gen_vector_store, embedder from agent_dingo.rag.readers.web
  import WebpageReader from agent_dingo.rag.chunkers.recursive import RecursiveChunker
  # Read the content of the websites reader = WebpageReader() phi_3_docs = reader.read("https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/")
  llama_3_docs = reader.read("https://ai.meta.com/blog/meta-llama-3/") openvoice_docs
  = reader.read("https://research.myshell.ai/open-voice") # Chunk the documents chunker
  = RecursiveChunker(chunk_size=512) phi_3_chunks = chunker.chunk(phi_3_docs) llama_3_chunks
  = chunker.chunk(llama_3_docs) openvoice_chunks = chunker.chunk(openvoice_docs) #
  Embed the chunks for doc in [phi_3_chunks, llama_3_chunks, openvoice_chunks]: embedder.embed_chunks(doc)
  # Populate LLM vector store with embedded chunks about Phi-3 and Llama 3 for chunk
  in [phi_3_chunks, llama_3_chunks]: llm_vector_store.upsert_chunks(chunk) # Populate
  audio gen vector store with embedded chunks about OpenVoice audio_gen_vector_store.upsert_chunks(openvoice_chunks)
  Run the script: python build.py At this step, we have successfully created vector
  stores. Step 3: Create serve.py file, and build a RAG pipeline. To access the pipeline
  from the Streamlit application, we can serve it using the serve_pipeline function,
  which provides a REST API compatible with the OpenAI API. # serve.py from agent_dingo.agent
  import Agent from agent_dingo.serve import serve_pipeline from components import
  llm_vector_store, audio_gen_vector_store, embedder, llm agent = Agent(llm, max_function_calls=3)
  # Define a function that an agent can call if needed u/agent.function def retrieve(topic:
  str, query: str) -> str: """Retrieves the documents from the vector store based
  on the similarity to the query. This function is to be used to retrieve the additional
  information in order to answer users'' queries. Parameters ---------- topic : str
  The topic, can be either "large_language_models" or "audio_generation_models". "large_language_models"
  covers the documentation of Phi-3 family of models from Microsoft and Llama 3 model
  from Meta. "audio_generation_models" covers the documentation of OpenVoice voice
  cloning model from MyShell. Enum: ["large_language_models", "audio_generation_models"]
  query : str A string that is used for similarity search of document chunks. Returns
  ------- str JSON-formatted string with retrieved chunks. """ print(f''called retrieve
  with topic {topic} and query {query}'') if topic == "large_language_models": vs
  = llm_vector_store elif topic == "audio_generation_models": vs = audio_gen_vector_store
  else: return "Unknown topic. The topic must be one of `large_language_models` or
  `audio_generation_models`" query_embedding = embedder.embed(query)[0] retrieved_chunks
  = vs.retrieve(k=5, query=query_embedding) print(f''retrieved data: {retrieved_chunks}'')
  return str([chunk.content for chunk in retrieved_chunks]) # Create a pipeline pipeline
  = agent.as_pipeline() # Serve the pipeline serve_pipeline( {"gpt-agent": pipeline},
  host="127.0.0.1", port=8000, is_async=False, ) Run the script: python serve.py At
  this stage, we have an openai-compatible backend with a model named gpt-agent ,
  running on http://127.0.0.1:8000/ . The Streamlit application will send requests
  to this backend. Step 4: Create app.py file, and build a chatbot UI: # app.py import
  streamlit as st from openai import OpenAI st.title("ü¶ä Agent") # provide any string
  as an api_key parameter client = OpenAI(base_url="http://127.0.0.1:8000", api_key="123")
  if "openai_model" not in st.session_state: st.session_state["openai_model"] = "gpt-agent"
  if "messages" not in st.session_state: st.session_state.messages = [] for message
  in st.session_state.messages: avatar = "ü¶ä" if message["role"] == "assistant" else
  "üë§" with st.chat_message(message["role"], avatar=avatar): st.markdown(message["content"])
  if prompt := st.chat_input("How can I assist you today?"): st.session_state.messages.append({"role":
  "user", "content": prompt}) with st.chat_message("user", avatar="üë§"): st.markdown(prompt)
  with st.chat_message("assistant", avatar="ü¶ä"): stream = client.chat.completions.create(
  model=st.session_state["openai_model"], messages=[ {"role": m["role"], "content":
  m["content"]} for m in st.session_state.messages ], stream=False, ) response = st.write_stream((i
  for i in stream.choices[0].message.content)) st.session_state.messages.append({"role":
  "assistant", "content": response}) Run the application: streamlit run app.py üéâ¬†We
  have successfully built an Agent that is augmented with the technical documentation
  of several newly released generative models and can retrieve information from these
  documents if necessary.¬†Let‚Äôs ask some technical questions, and check the generated
  output: Conclusion In this tutorial, we have developed a RAG agent that can access
  external knowledge bases, selectively decide whether to access the external data,
  which data source to use (and how many times), and how to rewrite the user''s query
  before retrieving the data. It can be seen that the Dingo framework enhances the
  development of LLM-based applications by allowing developers to quickly and easily
  create application prototypes.'
Title: Building an LLM chat application using RAG Agent
---
Author: u/These_Shoe3594
Content: What are all the changes needs to be done when I change the version of Wergzeug
  from 2.3.8 to 3.0.0 ? There are some CVE fixes available in the latest 3.x version
  of werkzueg. To take the fixes as part of my code, we want to upgrade the version.
  When I do so, I‚Äôve faced lot of breakages. I found some on documents and release
  notes. But it would be easier if someone already did some changes regarding this.
Title: What changes needs to be done when I change the version of Wergzeug from 2.3.8
  to 3.0.0 ?
---
Author: u/yngwieHero
Content: 'Hi, Recently I played a bit with LLMs, specifcally exploring ways of running
  the models locally and building prompts using LangChain. As a result ended up coding
  a small recommendation system, powered with Llama3-7b model, which suggests topics
  to read on HackerNews. Wanted to share my experiences, so I wrote a small article
  where I described all my findings. Hope you''ll like it: https://lukaszksiezak.github.io/ScrapyToLLM/
  Github repo: https://github.com/lukaszksiezak/ScrapyToLLM What the project does:
  It''s a Python application which uses scrapy to scrape HackerNews page. Scraped
  articles are pipelined to redis, which is then feeding Llama3 using langchain. Prompter
  is configured to serve a user articles which are matching his request. Target Audience
  : I think it suits the best all the people who are looking for a Hello World projects
  using LLMs. I think it also reveals some difficulties related to LLM tech, what
  potential problems could be found in production systems. Comparison: Recommendation
  systems are widely used and known, however LLMs are the ones which may work out
  of the box when appropriate prompt is given. It''s kind of interesting to explore
  various usages of the technology and take part in fast grow of that stack. Cheers.'
Title: Langchain using llama3 to build recommendation system
---
Author: u/monorepo
Content: Official Event
Title: PyCon US 2024 is here!
---
Author: u/arnaupv
Content: Miguel Algorri and Arnau Pont V√≠lchez here, blat co-founders! Target Audience
  People who need to collect public data from the web (pricing, articles, reviews,
  leads etc). What does our Project Do? At blat we aim to deliver production-ready
  web scraping code in minutes (written in Python, Scrapy framework). This is feasible
  thanks to our Web Scraping AI Agent üß†. Here our CLI to interact with the Web Scraping
  AI Agent (github) . Too good to be true? Check our video Comparison There are lots
  of other tools in the market, like Zyte , Apify , Kadoa . All those are great tools
  for web scraping purposes. The main difference with our competitors is that we give
  you the Python code that's ready to use (you host it, you run it). Also, once created,
  the code does not use AI for parsing HTMLs, so it's more efficient and deterministic.
  What are we looking for? We encourage you to register as a alpha testers üí™¬†if you
  are willing to have a better and more automated web scraping experience. Here our
  CLI to interact with the Web Scraping AI Agent (github)
Title: Blat AI generates Python code to do web-scraping (code based on Scrapy framework)
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!'
---
Author: u/__tosh
Content: 'What My Project Does A few days ago I wrote a simple python script (" Atlas
  ") that turns the Apple Health export.xml file (which is about 1 GB in my case,
  with about 10 years of data) into a very simple parquet file (a bit like a compressed
  CSV) that is also way smaller (40 MB). The parquet file has 5 columns: type (e.g.
  "CyclingDistance") value (e.g. "12.100") and 3 datetime timestamps: start end created
  This makes it way easier to do data exploration. Here are a few example charts I
  generated using Clickhouse (chDB) and Vega-Altair in a Quarto notebook. Step Count:
  https://x.com/__tosh/status/1785397655784337684 Environmental Noise: https://x.com/__tosh/status/1787530483208786029
  Sleep Duration & States: https://x.com/__tosh/status/1786505867438768254 Coffee
  Consumption: https://x.com/__tosh/status/1783906333911076996 Coffee after 17:00:
  https://twitter.com/__tosh/status/1789304034442043421/photo/1 Target Audience For
  everyone who would like to explore their own Apple Health data or see how to work
  with a simple .parquet file using Clickhouse (chDB), Vega-Altair and Quarto. Quarto
  notebook: https://github.com/atlaslib/atlas/blob/main/examples/apple-health-exploration-clickhouse-chdb-altair-quarto/index.qmd
  In the repo on Github I''ve added also added instructions for how to get your export.xml
  file from Apple Health and how to install the python script via pip to use it as
  a command line tool: https://github.com/atlaslib/atlas (‚≠êÔ∏è star to stay tuned for
  updates) Curious if you have charts that you would be interested in. Happy to add
  more examples over the next days! Comparison This is me playing around with the
  data and wrapping the script up in a pip package to make it easier for others to
  install and use. You can also explore the data in the Apple Health app but why would
  you if you can also explore it with your favorite programming language?'
Title: Apple Health data exploration with Atlas, Clickhouse, Vega-Altair, Quarto
---
Author: u/_dwightshrute
Content: Hello, I made this Minesweeper bot that I wanted to share with you all. What
  My Project Does - The bot takes a screenshot of the board and runs a classification
  algorithm to extract the contents of the board. It then analyzes the board, finds
  as many mines as it can, and sends clicks. If it cannot find any mines then it guesses
  the most probable position of a mine. Target Audience - It's a toy project for anyone
  interested in algorithms or problem-solving. Comparison - This is just my attempt
  at making a minesweeper bot. I'm sure there are many bots out there that are much
  more efficient than this. do let me know, if you feel anything can be done better
  :)
Title: I made a python bot that plays minesweeper
---
Author: u/prime_danger
Content: Hey guys, I have worked on building multiple ai/ml usecases and their specific
  backends. But now I want build interfaces for easy and quick integration. I saw
  a blog which used FastUI which looks quick decent but when I tried it just showed
  me a Json of elements on the page. Are there any other libraries I should use? ü§î
Title: Production grade AI Web apps, just using python ?
---
Author: u/pyeri
Content: So it was a long time ago in the good old Python 2.x days (circa 2010 probably)
  that I had learned PyGame with some tutorials at my former work place. But nowadays
  since I mostly freelance with business apps, I never felt the need for it. But since
  such a game development project is on the horizon after all these years, I was wondering
  if PyGame can still be up for the task with Python 3.x? Or is there a better Python
  library available these days? I don't need any advanced gaming features of modern
  day VFX or anything, all I need is some basic Mario/Luigi style graphics, that's
  all!
Title: Is PyGame still alive?
---
Author: u/bencherdev
Content: 'If you have ever wanted to track the size of your PyInstaller packages in
  CI, Bencher now supports tracking your package size: https://bencher.dev/docs/how-to/track-file-size/'
Title: Track the size of your PyInstaller packages in CI
---
Author: u/BX1959
Content: 'My wife and I use the Huckleberry app to track our baby''s sleep periods.
  Although the free version of the app allows you to view a number of sleep-related
  metrics, I also wanted to see whether his longest nightly sleep stretches were getting
  longer over time. Therefore, I created a Python project to help me answer this and
  other questions I had about my baby''s sleep. What My Project Does This project
  reads in data from a Huckleberry .csv export (or a separate custom .csv file); analyzes
  its sleep information; and then produces a number of visualizations . Personally,
  I''ve found that running the code and viewing its output helps reassure me that
  our baby is making progress with sleep, even if he seems to have some setbacks now
  and then! I hope you''ll find it useful as well in evaluating the effectiveness
  of your sleep training approach. Target Audience This project can be useful for
  any parent who wishes to see how his or her baby''s sleep is improving over time.
  (It could be used for other age ranges as well, but the code and visualizations
  are geared towards infant sleep data.) The project''s readme has instructions on
  using the code to track your own baby''s sleep data. Comparison This project is
  released under the open-source MIT license, so you are welcome to use and modify
  it for free. (I imagine that this is not the case for many sleep analysis tools.)
  As noted earlier, the project allows you to see how your baby''s longest daily sleep
  stretch has improved over time. (The longer your baby sleeps at any given point,
  the longer you get to sleep, so I think this metric is of great interest to most
  parents!) I don''t think the free version of Huckleberry includes this data in line
  chart form, though you can get a sense of this improvement by scrolling through
  your daily sleep data. This script also separates individaul sleep entries into
  their respective daytime and nighttime components. For instance, if your baby slept
  from 6 AM to 9 AM, and you''ve specified the nighttime period to end at 7 AM (the
  default setting), the script will treat this entry as one hour of nighttime sleep
  and 2 hours of daytime sleep. I don''t think Huckleberry offers this same functionality,
  though I could be wrong. (Note: The sample data shown within the project is completely
  made up using another Python script , and is not meant to reflect normal sleep patterns
  in infants.)'
Title: I created a Python script that makes it easier to track how your baby's sleep
  is improving
---
Author: u/pp314159
Content: 'I''m working on an open-source framework for converting Python notebooks
  into web applications, it is called Mercury . Recently, I have added an option to
  execute notebooks with REST API. You can pass paramters in POST request body to
  the notebook, execute all cells and return JSON as response. I''m also running a
  SaaS service, Mercury Cloud where you can deploy notebooks with one-click with unique
  website domain. What My Project Does It makes Python notebooks extermely easy to
  integrate with custom ChatGPT, so GPT can execute Python notebooks and get response.
  It is 3-steps process: Create Python notebook, with Mercury widgets to accept parameters
  and return JSON response. Deploy notebook online - it can be done in 1 minute with
  Mercury Cloud Configure ChatGPT Actions - it is quick, because Mercury automatically
  generates OpenAPI schema based on your notebooks. You can read more in article how
  ChatGPT is talking with all my Python notebooks . Target Audience This solution
  is perfect for people: that would like to quickly create custom API for ChatGPT
  with Python, that don''t want to manage server by themself. Comparison I think that
  building API with Python notebooks is alternative for full REST API development
  with Django, Flask or FastAPI, if you quickly need few endpoints that will expose
  your Python code. Examples I have created example notebooks that are used by ChatGPT:
  notebook to send email directly from ChatGPT notebook to query Postgres database
  with SQL from ChatGPT notebook to access Google Sheets in custom ChatGPT'
Title: ChatGPT can talk with all my Python notebooks
---
Author: u/Clickyz
Content: Hello guys I recently decided to move from nodejs(expressjs) to python for
  general purposes but mostly for backend. I have couple of questions. Will i regret
  my migration to python? :) Which framework you suggest for backend solo dev? And
  what tips are you suggesting me in general to get used to python.
Title: Framework to use for backend
---
Author: u/Thinker_Assignment
Content: 'Hey there, you are probably familiar with REST APIs. We at dlt library added
  a new way to get data from apis (and dlt can already load it with best practice
  to db or parquet). We already did some internal hackathons but we would appreciate
  your feedback so we can improve it further - Our new REST API Source is a short,
  declarative configuration driven way of creating sources. - Our new REST API Client
  is a collection of Python helpers used by the above source, which you can also use
  as a standalone, config-free, imperative high-level abstraction for building pipelines.
  You can read more about the source here or go to our docs for the REST APIClient
  info https://github.com/dlt-hub/verified-sources/tree/master/sources/rest_api PS:
  see you at Pycon Pittsburgh!'
Title: New Python-only abstractions for extracting data from apis
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Wednesday Daily Thread: Beginner questions'
---
Author: u/AbhishekSuryavanshee
Content: 'What My Project Does: I''m excited to introduce my latest project built
  with Python ‚Äì an interactive data visualization application using Plotly Dash. This
  project aims to empower users to explore and analyze datasets dynamically through
  interactive visualizations. By leveraging Plotly Dash''s capabilities, users can
  interact with data in real-time, customize visualizations on the fly, and gain deeper
  insights with just a few clicks. Target Audience: This project caters to a wide
  range of users, from data enthusiasts and analysts to professionals seeking to communicate
  insights effectively. Whether you''re a data scientist exploring patterns in large
  datasets or a business analyst presenting findings to stakeholders, this tool is
  designed to streamline your workflow and enhance your data storytelling capabilities.
  It''s suitable for both production-grade applications and educational purposes,
  offering a versatile platform for data visualization tasks of varying complexity.
  Comparison: Unlike traditional static charts or cumbersome data exploration tools,
  this Plotly Dash application stands out for its interactivity and flexibility. While
  existing alternatives may offer basic charting functionalities, they often lack
  the dynamic capabilities required for in-depth data exploration. With Plotly Dash,
  users can manipulate charts in real-time, zoom in on specific data points, filter
  datasets dynamically, and even integrate interactive components like dropdowns and
  sliders for a more immersive experience. This project takes data visualization to
  the next level by providing a user-friendly interface coupled with powerful interactivity,
  setting it apart as a top choice for visualizing and analyzing datasets. Source
  Code: You can access the source code for this project on GitHub: Interactive Data
  Visualization with Plotly Dash Website: For more information and to see the project
  in action, visit : https://www.aspiresoftserv.com/'
Title: 'Interactive Data Visualization with Python: A Showcase of Plotly Dash'
---
Author: u/madnirua
Content: 'https://slint.dev/blog/slint-1.6-released Slint is a declarative GUI toolkit
  to build native user interfaces for desktop and embedded applications. Find more
  information at https://slint.dev/ or check out the source code at https://github.com/slint-ui/slint
  . EDIT: The Python APIs are currently in alpha. More info -- https://github.com/slint-ui/slint/tree/master/api/python'
Title: Declarative GUI Slint v1.6 released with Design Mode (WYSIWYG) Improvements
---
Author: u/chione99
Content: Hi, Just want to know how difficult is it to manage your own pypi clone and
  how do you recommend to create a seperation between dev and prod systems.
Title: Implementing your own pypi clone
---
Author: u/SAV_NC
Content: 'ü¶ë Squid Proxy Manager Script Hello fellow Python enthusiasts! I''ve created
  a Python script that makes managing your Squid Proxy Server a breeze. If you''re
  looking for an efficient and straightforward way to interact with your Squid server
  remotely, this script is for you. üéâ What My Project Does The Squid Proxy Manager
  script allows you to manage your Squid Proxy Server remotely using a simple command-line
  interface. Here are some of the key features: Check Squid Service Status : Quickly
  check if your Squid service is running or not. Start/Stop/Restart Service : Easily
  control the Squid service remotely. View Logs : Access the latest entries in your
  Squid access logs. View Configuration : Display the current Squid configuration
  file. Update Configuration : Replace the existing Squid configuration with a new
  one. Reload Service : Reload the Squid service to apply changes without restarting.
  Target Audience This script is designed for anyone who manages a Squid Proxy Server
  and prefers a command-line tool for remote management. If you are comfortable using
  Python and SSH, this tool will streamline your workflow and enhance your productivity.
  Differences Here are some aspects that make this Squid Proxy Manager script stand
  out: Remote Management : Manage your Squid server without needing physical access,
  thanks to SSH connectivity. Ease of Use : The script provides a simple and intuitive
  command-line interface, making it easy to perform various tasks. Comprehensive Features
  : From checking service status to updating configurations and viewing logs, this
  script covers all essential Squid management tasks. Error Handling and Logging :
  Detailed logging and error handling ensure you know exactly what''s happening and
  can troubleshoot issues effectively. üöÄ Usage Installation : Ensure you have the
  required libraries installed: pip install paramiko termcolor Running the Script
  : Use the script with appropriate arguments to manage your Squid Proxy Server. Here''s
  an example command to check the Squid service status: ./squid_proxy_manager.py 192.168.2.111
  22 username password --check-status Updating Configuration : Create a new configuration
  file (e.g., new_squid.conf ) with your desired settings. Run the script to update
  the Squid configuration: ./squid_proxy_manager.py 192.168.2.111 22 username password
  --update-config new_squid.conf üíª Script Example Here''s a snippet of the script
  to give you an idea of its simplicity and functionality: #!/usr/bin/env python3
  import paramiko import argparse import logging import sys import os from termcolor
  import colored class SquidProxyManager: def __init__(self, hostname, port, username,
  password): self.hostname = hostname self.port = port self.username = username self.password
  = password self.client = paramiko.SSHClient() self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
  def connect(self): try: logging.info(colored("Attempting to connect to {}:{}".format(self.hostname,
  self.port), ''cyan'')) self.client.connect(self.hostname, port=self.port, username=self.username,
  password=self.password) logging.info(colored(f"Connected to {self.hostname} on port
  {self.port}", ''green'')) except Exception as e: logging.error(colored(f"Failed
  to connect: {e}", ''red'')) sys.exit(1) def disconnect(self): self.client.close()
  logging.info(colored("Disconnected from the server", ''green'')) def execute_command(self,
  command): logging.info(colored("Executing command: {}".format(command), ''cyan''))
  try: stdin, stdout, stderr = self.client.exec_command(command) stdout.channel.recv_exit_status()
  out = stdout.read().decode() err = stderr.read().decode() if err: logging.error(colored(f"Error
  executing command ''{command}'': {err}", ''red'')) else: logging.info(colored(f"Successfully
  executed command ''{command}''", ''green'')) return out, err except Exception as
  e: logging.error(colored(f"Exception during command execution ''{command}'': {e}",
  ''red'')) return "", str(e) # More functions here... def parse_args(): parser =
  argparse.ArgumentParser(description="Squid Proxy Manager") parser.add_argument(''hostname'',
  help="IP address of the Squid proxy server") parser.add_argument(''port'', type=int,
  help="Port number for SSH connection") parser.add_argument(''username'', help="SSH
  username") parser.add_argument(''password'', help="SSH password") parser.add_argument(''--check-status'',
  action=''store_true'', help="Check Squid service status") parser.add.add_argument(''--start'',
  action=''store_true'', help="Start Squid service") parser.add.add_argument(''--stop'',
  action=''store_true'', help="Stop Squid service") parser.add.add_argument(''--restart'',
  action=''store_true'', help="Restart Squid service") parser.add.add_argument(''--view-logs'',
  action=''store_true'', help="View Squid logs") parser.add.add_argument(''--view-config'',
  action=''store_true'', help="View Squid configuration") parser.add.add_argument(''--update-config'',
  help="Update Squid configuration with provided data") parser.add.add_argument(''--reload'',
  action=''store_true'', help="Reload Squid service") return parser.parse_args() def
  main(): logging.basicConfig(level=logging.INFO, format=''%(asctime)s - %(levelname)s
  - %(message)s'') args = parse_args() logging.info(colored("Initializing Squid Proxy
  Manager script", ''cyan'')) manager = SquidProxyManager(args.hostname, args.port,
  args.username, args.password) manager.connect() try: if args.check_status: manager.check_squid_status()
  if args.start: manager.start_squid() if args.stop: manager.stop_squid() if args.restart:
  manager.restart_squid() if args.view_logs: manager.view_squid_logs() if args.view_config:
  manager.view_squid_config() if args.update_config: if not args.update_config.endswith(''.conf''):
  logging.error(colored("The provided file must have a .conf extension", ''red''))
  elif not os.path.isfile(args.update_config): logging.error(colored(f"Configuration
  file {args.update_config} not found", ''red'')) else: try: with open(args.update_config,
  ''r'') as config_file: config_data = config_file.read() manager.update_squid_config(config_data)
  except Exception as e: logging.error(colored(f"Error reading configuration file
  {args.update_config}: {e}", ''red'')) if args.reload: manager.reload_squid() finally:
  manager.disconnect() logging.info(colored("Squid Proxy Manager operations completed",
  ''green'')) if __name__ == "__main__": main() üåü Benefits Remote Management : No
  need to be physically present to manage your Squid server. Ease of Use : Simple
  command-line interface for quick operations. Versatility : Supports various Squid
  management tasks, from checking status to updating configurations and viewing logs.
  üì¢ Get Involved! If you find this script useful, feel free to give it a try and share
  your feedback. Contributions and suggestions are always welcome! Comments however,
  that are unhelpful and serve no purpose to better the script or the author in their
  python scripting abilities are not welcome! Keep the nasty to yourself. Access the
  script You can find the script here on GitHub. Happy coding! üöÄ'
Title: Manage Your Squid Proxy Server Efficiently with This Python Script
---
Author: u/BasePlate_Admin
Content: 'github documentation What my project does : It gets the dominant color/color
  palette from given image. Target Audience: Anyone Usage modern_colorthief exposes
  two functions get_color and get_palette Here is how to use get_color: from modern_colorthief
  import get_color # Path to any image path = ... print(get_color(path)) # returns
  tuple[int,int,int] Here is how to use get_palette: from modern_colorthief import
  get_color # Path to any image path = ... print(get_palette(path)) # returns list[tuple[int,int,int]]
  Goals: Bring color-thief-rs to python Benchmarks: Written in deatils Gist: Python
  Took:            0.09976800000004005 CPP Took:               0.008461299999908078
  RUST Took:              0.008549499994842336 Python Took:            0.0960583999985829
  CPP Took:               0.008564600000681821 RUST Took:              0.007692700004554354
  Differences With fast-colorthief Supports more architectures. ( pybind11 vs pyo3
  ) Doesn''t have a hard dependency on numpy Code is simple compared to fast-colorthief''s
  CPP codebase Automated tooling powered by maturin and github-actions The size of
  fast-colorthief is 52kb-60kb. With color-thief-py Superior execution time (nearly
  100x) Doesn''t have a hard dependency on pillow color-thief''s codebase is not in
  par with modern python versions If you like this project please star this repository'
Title: modern_colorthief - Modified Median Cut Quantization algorithm in rust + python
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Tuesday Daily Thread: Advanced questions'
---
Author: u/framelanger
Content: Hey, I am (re)releasing a project called Frame that I've been working on
  to create a language and transpiler to easily create state machines/automata in
  Python. It also is able to generate UML documentation as well. This project is for
  people who are interested in programming state machines for a wide range of purposes
  such as game programming, workflows, MBSE modeling as well as school projects for
  comp sci theory. It is also useful simply for generating flow documentation. The
  Framepiler (Frame transpiler) is in beta at this time. It would be great to get
  feedback from the Python community on any gaps in key functionality or bugs. Low-code/no-code
  workflow tools are often problematic for creating state machine like flows. Frame
  is intended to give a textual way to accomplish the same thing, but without having
  to "draw" your software and with the ability to use all the standard devops tooling
  and processes for "normal" development processes. There is also a VSCode extension
  and a playground environment to experiment in. Very much hoping to connect with
  people who might find this interesting and useful. If that is you, please take a
  look at the Overview and the Getting Started articles. Here is a link to the GitHub
  Framepiler Project as well. Please LMK if you have any questions or interest in
  the project. Thanks! Mark
Title: Frame - a new language for programming state machines in Python
---
Author: u/kernelslayer
Content: What My Project Does  - This is a Python package to easily add string token
  based pagination. Currently it supports SQLModel and SQLAlchemy ORMs. Recently I
  wanted to add pagination in one of my Python projects and in the API response, I
  had to return a string next page token. Now I could not find a straight-forward
  way of doing this in Python. All of the tutorials or blog posts I saw, there in
  the response the server always returned a page_number , page_size , and total_elements
  and then the onus was on the calling service to adjust this accordingly. Comparison
  - The current packages and methods requires some changes in the app layer as well.
  I tried using a few but those did not satisfy the use case and were also a bit harder
  to implement. I could not find a easy to use option. The present ones returned integers
  instead of a string token I wanted it to be simpler, just like OpenSearch - you
  call its search API and it returns 10 elements and a next_page_token and then for
  the next 10 (or you configure this using the size parameter) you use the next_page_token
  in the subsequent request to get to the new page. I ended up doing a lot of if-else
  checks and encoding and decoding, so I decided to create this library. Target Audience
  - This is production ready, have been using it in one of my projects. Hope some
  of you folks find it useful :) Here is the link to the PyPi repository and here
  is the GitHub repo
Title: SQLPage - a Python library to add string token based pagination easily
---
Author: u/Balance-
Content: 'Main Changes Add GUI functions Vehicle tracking: You can now track a specific
  vehicle to see their route Dataframe viewer: Stats can be confirmed Improve vehicle
  routing functions Add example of routing optimization Change documentation ''s theme
  for better indexing UXsim UXsim is a free, open-source macroscopic and mesoscopic
  network traffic flow simulator written in Python. It simulates the movements of
  car travelers and traffic congestion in road networks. It is suitable for simulating
  large-scale (e.g., city-scale) traffic phenomena. UXsim is especially useful for
  scientific and educational purposes because of its simple, lightweight, and customizable
  features, but users are free to use UXsim for any purpose.'
Title: UXsim 1.3.0 released with vehicle tracking and improved vehicle routing
---
Author: u/Babe_My_Name_Is_Hung
Content: 'Hi everyone! I recently finished a small side project for my graduating
  thesis, which is about experimenting with RAG-based frameworks in improving resume
  screening. What my project does: The project for the thesis is a GPT-4 Chatbot with
  RAG Fusion retrieval. Given a job description as input, the system retrieves the
  most relevant candidate profiles to perform follow-up tasks such as analysis, summarization,
  and decision-making, which can assist the screening process better. The revolving
  idea is that the similarity-based retrieval process can effectively narrow the initial
  large pool of applicants down to the most relevant resumes. However, this simple
  similarity ranking should not be used to evaluate a candidate''s actual ability.
  Therefore, the top resumes are used to augment the GPT-4 Chatbot so it can be conditioned
  on these profiles and perform further downstream tasks. Target audience: The repo
  contains the link to my paper and the notebooks that were used to design the prototype
  program and conduct some experiments. For the newcomers to RAG/RAG Fusion, or people
  who are just interested in building a RAG-based chatbots, this can be especially
  helpful. Feel free to check them out too! Comparison: I''m not sure if there''s
  any similar project out there, but the program is sort of designed to move the resume
  screening process away from existing keyword-based methods. It''s much more versatile
  in use cases and also more effective in handling resumes. The project is very far
  from being perfect. Because of that, I share this with the hope to receive suggestions
  and feedback from you. If you have time, please give the project a visit here: GitHub'
Title: Resume Screening Chatbot using RAG Fusion
---
Author: u/foadsf
Content: 'Five years ago, I posted about JModelica, a fantastic open-source tool for
  simulating complex systems that combined the ease of Python with the strength of
  Modelica. Sadly, the project went quiet, but I''m thrilled to share that, thanks
  to the dedication of a few folks (myself included!), JModelica is back! You can
  find the revived project on GitHub: https://github.com/JModelica/JModelica . What
  JModelica Does: JModelica provides a way to write complex simulations using the
  Modelica language, which is known for its ability to handle differential equations
  and model physical systems beautifully. The magic of JModelica lies in its Python
  integration‚Äîyou can solve your Modelica models and access the results directly in
  Python for in-depth analysis, visualization, and even optimization using libraries
  you already love! Target Audience: This project is geared toward anyone interested
  in modeling and simulating complex systems, particularly those with a background
  in engineering, physics, or related fields. If you''ve struggled with Python''s
  ODE solvers or wish for a more elegant way to model physical interactions, JModelica
  offers a compelling solution. It''s ready for research, educational projects, and
  even more ambitious endeavors! Comparison: JModelica stands alongside OpenModelica
  as a champion of open-source Modelica tools. While OpenModelica is known for its
  user-friendly graphical interface, JModelica shines in its seamless integration
  with Python, giving you the best of both worlds! It''s a powerful alternative to
  proprietary software like Simulink, providing transparency, flexibility, and a thriving
  community. We''re actively working on squashing bugs, adding features, and making
  JModelica more accessible across different platforms (Windows and macOS support
  are on the horizon!). Anyone interested in contributing is welcome! Whether you''re
  a Modelica expert or a curious newcomer, this project has a place for you. Check
  out the GitHub repository to explore the code, open issues, or submit pull requests.'
Title: 'Giving New Life to JModelica: Bringing Powerful Modelica Simulations to Python'
---
Author: u/realazthat
Content: 'What My Project Does What My Project Does: snipinator is a CLI to embed
  (testable) snippets from your codebase into your README, using Jinja2 and functions
  provided by snipinator to assist with embedding code, shell output, etc. Please
  provide any feedback in the comments or GH issues. Target Audience Target Audience:
  Developers of {GitHub,other} projects that have a README. It works for me, it might
  work for you. Comparison Features: Supports anything Jinja2 supports. First-class
  support for python source code. Can include python function signatures, docstrings,
  entire function source code, classes. Snip from any source code language . Put delimiter
  markers into the code (e.g # START_SNIPPET , # END_TEMPLATE ), and use snippet()
  . First-class support for Markdown templates (with backtickify , decomentify ).
  Can include shell output . Supports ANSI colors with SVG output. More robust references/links
  to local files using path() . I keep a table of similar projects in my README at
  realazthat/snipinator: Related Projects . Not complete, and not necessarily up to
  date. Make a PR to README.md.jinja , (see realazthat/snipinator/Contributions )
  to insert/modify the table. Project Stars Last Update Language Platform Similarity
  X Obviousness mdx-js/mdx 16.8k 2024/04/17 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê zakhenry/embedme 222 2023/11/08
  JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê cmacmackin/markdown-include 95 2023/02/07 Python N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê BurdetteLamar/markdown_helper
  38 2020/03/16 Ruby N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê SimonCropp/MarkdownSnippets 23 2024/04/23 .NET N/A
  ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê endocode/snippetextractor 4 2014/08/16 C++ N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê polywrap/doc-snippets
  3 2023/09/26 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê JulianCataldo/remark-embed 2 2022/09/22 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê xrd/oreilly-snippets
  2 2015/10/15 Ruby N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê DamonOehlman/injectcode 1 2021/08/01 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê electrovir/markdown-code-example-inserter
  1 2024/02/19 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê andersfischernielsen/Simple-Embedded-Markdown-Code-Snippets
  1 2021/02/12 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ildar-shaimordanov/git-markdown-snippet 0 2021/09/14 Perl
  N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê teyc/markdown-snippet 0 2024/01/22 Powershell N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê marc-bouvier-graveyard/baldir_markdown
  0 2020/06/15 Python N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê dineshsonachalam/markdown-autodocs 176 2022/09/19
  JS GH Action ‚≠ê‚≠ê‚≠ê‚≠ê tokusumi/markdown-embed-code 28 2022/01/05 Python GH Action ‚≠ê‚≠ê‚≠ê‚≠ê
  sammndhr/gridsome-remark-embed-snippet 2 2021/06/14 JS Gridsome ‚≠ê‚≠ê‚≠ê‚≠ê NativeScript/markdown-snippet-injector
  4 2019/01/24 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê fuxingloh/remark-code-import-replace 0 2022/12/21 JS Remark?
  ‚≠ê‚≠ê‚≠ê‚≠ê szkiba/mdcode 15 2014/02/12 Go N/A ‚≠ê‚≠ê‚≠ê devincornell/pymddoc 0 2023/12/01 Python
  Python ‚≠ê‚≠ê‚≠ê shiftkey/scribble ( docs ) 40 2013/08/08 .NET N/A ‚≠ê‚≠ê calebpeterson/jest-transformer-test-md
  2 2020/08/21 JS Jest Tests ‚≠ê‚≠ê tjstankus/commitate 0 2014/05/29 Ruby N/A ‚≠ê GitHub
  Docs: Creating a permanent link to a code snippet N/A N/A N/A N/A ‚≠ê javierfernandes/markdown-exercises
  1 2017/05/01 JS N/A ‚≠ê gatsby-remark-embed-snippet N/A (55k) 2024/01/23 JS Gatsby
  ‚≠ê ARMmbed/snippet 6 2021/08/05 Python N/A ? drewavis/markdowninclude 1 2024/04/06
  JS VSCode Extension ? romnn/embedme 0 2024/04/18 Go N/A ? The 5 star projects have
  the bare minimum of being able to embed a file, and run via CLI. Snipinator does
  have other features (such as shell() ), implemented as I needed them (and listed
  below) which I do not think any of these have in combination. Some of these projects
  are not CLIs. mdx-js/mdx is the closest in terms of flexibility, but it is JS +
  components, which may not be everyone''s cup of tea. Usage: Example template README:
  (./snipinator/examples/EXAMPLE.md.jinja2): # A README Here is a code snippet: <!--{{
  pysnippet(path=''snipinator/examples/code.py'', symbol=''MyClass'', backtickify=''py'',
  decomentify=''nl'') }}--> Note that `code.py` has a test: {{path(''./snipinator/examples/code_test.py'',
  link=''md'')}}. Generating the README: $ python -m snipinator.cli -t snipinator/examples/EXAMPLE.md.jinja2
  <!-- WARNING: This file is auto-generated by snipinator. Do not edit directly. SOURCE:
  `snipinator/examples/EXAMPLE.md.jinja2`. --> # A README Here is a code snippet:
  <!----> ```py class MyClass: """This is a global class""" def __init__(self, name):
  self.name = name def MyClassMethod(self): """This is a method of MyClass""" print(self.name)
  ``` <!----> Note that `code.py` has a test: [./snipinator/examples/code_test.py](./snipinator/examples/code_test.py).'
Title: CLI to embed code snippets in your README, from actual (testable) code
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Monday Daily Thread: Project ideas!'
---
Author: u/teamamentum
Content: 'What My Project Does Overlaying intensity plots onto a geographical map
  using cartopy/matplotlib can be complex. So we created this map_plotter package
  to abstract away that complexity for a common use case. Installation (opinionated
  use of conda to avoid cartopy dependency hell and install precompiled binaries)
  conda install cartopy git clone git@github.com:amentumspace/map_plotter.git cd map_plotter
  pip install . Usage import map_plotter map_plotter.plot(lons_g, lats_g, variable,
  units="m/s", img_name="image.png", save=True, plot=True, title="something", zlims=[0,10])
  Whereby: lons_g and lats_g represent 2D matrices / grids of longitudes and latitudes.
  values is the matrix of values to be plotted (same grid dimensions). units and img_name
  (self explanatory). save & plot boolean flags to save the file and plot to screen,
  respectively. zlims define the color scale minimum and maximum. Target Audience
  Python developers or data scientists or scientists or any Pythonista wanting a simple
  way to quickly plot an intensity map onto a geographical map. Comparison Differs
  from using cartopy and matplotlib in its ease-of-use, but it is less customisable
  (can''t change projections, colors). Regardless, it''s convenient and at least provides
  a starting point for customisation. Similar functionality can be had from geopandas
  or folium (although cartopy/matplotlib suited our needs better).'
Title: map_plotter - abstracts complexity of creating intensity plots overlaid onto
  global map
---
Author: u/AlSweigart
Content: 'What My Project Does This is a music video of the output of a Python program:
  https://www.youtube.com/watch?v=Sjk4UMpJqVs I''m the author of Automate the Boring
  Stuff with Python and I teach people to code. As part of that, I created something
  I call "scroll art". Scroll art is a program that prints text from a loop, eventually
  filling the screen and causing the text to scroll up. (Something like those BASIC
  programs that are 10 PRINT "HELLO"; 20 GOTO 10) Once printed, text cannot be erased,
  it can only be scrolled up. It''s an easy and artistic way for beginners to get
  into coding, but it''s surprising how sophisticated they can become. The source
  code for this animation is here: https://github.com/asweigart/scrollart/blob/main/python/forbiddenzone.py
  (read the comments at the top to figure out how to run it with the forbiddenzonecontrol.py
  program which is also in that repo) The output text is procedurally generated from
  random numbers, so like a lava lamp, it is unpredictable and never exactly the same
  twice. This video is a collection of scroll art to the music of "The Forbidden Zone,"
  which was released in 1980 by the band Oingo Boingo, led by Danny Elfman (known
  for composing the theme song to The Simpsons.) It was used in a cult classic movie
  of the same name, but also the intro for the short-run Dilbert animated series.
  Target Audience Anyone (including beginners) who wants ideas for creating generative
  art without needing to know a ton of math or graphics concepts. You can make scroll
  art with print() and loops and random numbers. But there''s a surprising amount
  of sophistication you can put into these programs as well. Comparison Because it''s
  just text, scroll art doesn''t have such a high barrier to entry compared with many
  computer graphics and generative artwork. The constraints lower expectations and
  encourage creativity within a simple context. I''ve produced scroll art examples
  on https://scrollart.org I also gave a talk on scroll art at PyTexas 2024: https://www.youtube.com/watch?v=SyKUBXJLL50'
Title: '2,000 lines of Python code to make this scrolling ASCII art animation: "The
  Forbidden Zone"'
---
Author: u/rageagainistjg
Content: After playing around with a dataframe‚Äîapplying filters or other transformations‚ÄîI'm
  curious about your methods for reviewing the changes. In VS Code, the variable explorer
  is quite handy for a quick look at the modified dataframe. Alternatively, when working
  in a Jupyter notebook within VS Code, exporting the data to an Excel file provides
  a detailed view and allows for an easy deep dive into the results. What are your
  preferred practices for ensuring your data adjustments are precisely what you intended?
Title: Reviewing Dataframe Changes? Looking for Your Preferred Methods!
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/Cool-Nefariousness76
Content: 'Hi everybody, over the last year I''ve been developing a library that adds
  some Cython 3.0 annotations to existing python code. What My Project Does: For example
  if it sees a for i in range(): in a function it recognizes i as an integer and adds
  a i = cython.declare(cython.int) line at the beginning of the function. It actually
  uses the built-in ast module under the hood for parsing, I found it a super useful
  library! Target Audience: It is a side project I made mainly for fun. I don''t know
  if it can be of interest to anybody, or if it could have some potential utility.
  Comparison: I did not find anything similar. There are a lot of very cool projects
  like mypyc for example, but nothing that does this tiny little code generation specific
  to Cython. The link to the repository is here: https://github.com/nucccc/markarth'
Title: Library for automatic Cython 3.0 code annotations generation.
---
Author: u/kostakos14
Content: Hey folks, looking to use one library to implement some background scheduling
  logic on my application. I find in Google search APScheduler to be frequently mentioned,
  but I can see the Schedule package has more GH stars. Was curious if anybody has
  used one of them, and which one would you recommend based on your own experience.
Title: APScheduler vs Schedule package
---
Author: u/devotaku
Content: 'Excited to share my personal open-source project: Notolog - Python Markdown
  Editor (MIT License). The main motivation for developing another markdown editor
  was my passion for learning new things and enhancing my development skills in Python.
  I developed it in my spare time over a few months, despite having no prior experience
  in creating full-scale Python applications. What My Project Does ‚àó Multiplatform
  ‚àó Markdown async syntax highlighting created by me ‚àó Several pre-installed color
  themes ‚àó Supports English and 17 other languages right out of the box ‚àó Integration
  with OpenAI API for AI-assisted features ‚àó Optional file encryption/decryption Target
  Audience Primarily developers who write markdown documents and notes. Comparison
  This is more of a personal learning project, so it''s hard to compare it directly
  with others. How to install Discover Notolog on GitHub üåü and PyPI . Installation
  is as easy as running a single command: pip install notolog'
Title: 'Introducing Notolog: Python Markdown Editor built with PySide6'
---
Author: u/Royal_Section4889
Content: 'I have been using zabbix for monitoring a lot of metrics in my work, none
  of the most popular zabbix were capable of doing async tasks, so I''ve developed
  some simple package capable of doing this. Tests, examples and how-tos can be found
  here: https://github.com/gustavofbreunig/zabbix-sender-async What My Project Does
  Send zabbix sender messages using asyncio tasks. Target Audience SysAdmins who use
  Zabbix to monitor a large number of metrics. Comparison Instead of doing traditional
  way, using these abandoned library: https://github.com/adubkov/py-zabbix from pyzabbix
  import ZabbixMetric, ZabbixSender # Send metrics to zabbix trapper packet = [ ZabbixMetric(''hostname1'',
  ''test[cpu_usage]'', 2), ZabbixMetric(''hostname1'', ''test[system_status]'', "OK"),
  ZabbixMetric(''hostname1'', ''test[disk_io]'', ''0.1''), ZabbixMetric(''hostname1'',
  ''test[cpu_usage]'', 20, 1411598020), ] result = ZabbixSender(use_config=True).send(packet)
  You can do this: async def sendmetrics(): sender = AsyncSender(''localhost'', 10051)
  metric = ItemData(host=''hostname'', key=''test.metric.text'', value=''test package
  import'') result = await sender.send(metric)'
Title: I've developed a library for send metrics to zabbix asynchronously
---
Author: u/asksumanth
Content: 'What my project does : It supports services like IBM Watson, Acapela and
  Stream labs'' demo websites to convert your text to speech. Target audience : It''s
  a toy project and would not recommend you to use in Production. Comparison : It''s
  wayyyyy easy to use. Just pip install and use in your project. No extra setup required
  like other libraries. Also supports various languages and voices and accents. Check
  docs for more. Here is the link to repository. Please go do check it out and star
  it if it''s helpful to you guys. Thank you. I made this library taking inspiration
  from this php tts library by chrisjp.'
Title: I made a Python text to speech library - Pyt2s
---
Author: u/Spiffidimus
Content: I made a library to create interactive plots in the terminal ( pip install
  itrm ). It uses braille characters (by default) to display the data with sub-character
  resolution. There are several keybindings for moving a vertical cursor left and
  right, for zooming in or out on data, and for changing which curve to focus on.
  There are occasions (such as when working with a server) where MatPlotLib is not
  an option and the terminal is the only available tool. But, in my opinion, it is
  actually faster to use this tool (itrm) to zoom in on interesting parts of data
  and analyze patterns than using other tools like MatPlotLib. In fact, with large
  data sets (~1 million points), this tool actually renders faster than MatPlotLib.
  Please check it out and let know what you think.
Title: Interactive plots in the terminal
---
Author: u/VoyZan
Content: 'Hi! I want to share a library I''ve built recently. IBind is a REST and
  WebSocket Python client for Interactive Brokers Client Portal Web API . It is directed
  at IBKR users. You can find IBind on GitHub: https://github.com/Voyz/ibind What
  My Project Does: It is a REST and WebSocket API for the Interactive Brokers'' Web
  API. I''m particularly proud of a few things in this release: The REST and WebSocket
  API clients are based on an abstract base class RestClient and WsClient accordingly.
  These could be implemented to use some other Web APIs in a relatively straightforward
  way. I have in fact used a version of that WsClient for a cryptocurrency WebSocket
  API, and it is nice to see it adapt to a different environment. I''ve covered most
  of the codebase with automated tests (appx 80%). Contrary to some of my other libraries,
  these are mainly integration tests which feel to provide a stronger test coverage
  than only unit tests. I''ve learned how to use class mixins in this project, and
  it aids the maintainability by a lot! The REST client itself is pretty barebone,
  but has a lot of mixin classes - all corresponding to the endpoint categories the
  broker uses, making it easy to search for the right piece of code and documentation.
  There''s a lot of things that make this client as plug-and-play as possible. The
  broker requires the user to specify a bunch of things - account ids, certificates,
  URLs, etc. - which the class either reads from the environment variables or assumes
  (given that some things would be common for most users). In either case, all these
  are customisable by parameters if needed, but it is nice to just write client =
  IbkrClient() in various projects having set just a couple of env vars. I think the
  documentation is pretty in-depth but readable. It''s always hard to judge whether
  docs are well written, but I think it is nicely broken down. Also, I managed to
  use pydoc-markdown package to create API reference in markdown, which works nicely
  with the GitHub Wiki. I''d prefer it to be even easier, but compared to Sphinx and
  readthedocs it''s a much quicker job. The WebSocket class does a ton to keep the
  connection alive and recover from connection losses. Maintaining active subscriptions
  after a re-connect can be a real pain, and I think this class does it in a nice
  and reliable way. I''ve tested it for various types of connectivity loss, and it
  manages to recover and re-establish the WebSocket data stream. Pretty crucial in
  the trading environment. I made a nice logo for it ü•≥ Target Audience: Traders using
  IBKR who want to automate their trading through this Web API. Comparison (A brief
  comparison explaining how it differs from existing alternatives.) : There are two
  similar libraries that I know of. They aren''t bad, but seem not very well maintained
  and incomplete: https://github.com/areed1192/interactive-brokers-api - outdated
  and stale, last update 3 years ago https://github.com/utilmon/EasyIB - stale and
  incomplete The library I''ve published covers a much wider range of endpoints, adds
  WebSocket support and a bunch of wrapper methods to simplify the usage of the API.
  IBind has a bunch of features that make using the IBKR APIs much easier. Some of
  these are: REST: Automated question/answer handling - streamlining placing orders.
  Parallel requests - speeding up collection of price data. Rate limiting - guarding
  against account bans. Conid unpacking - helping to find the right contract. WebSocket:
  WebSocket thread lifecycle handling - ensuring the connection is alive. Thread-safe
  Queue data stream - exposing the collected data in a safe way. Internal subscription
  tracking - recreating subscriptions upon re-connections. Health monitoring - Acting
  on unusual ping or heartbeat. REST Example: from ibind import IbkrClient # Construct
  the client client = IbkrClient() print(client.tickle().data) WebSocket Example:
  from ibind import IbkrWsKey, IbkrWsClient # Construct the client. ws_client = IbkrWsClient(start=True)
  # Choose the WebSocket channel key = IbkrWsKey.PNL # Subscribe to the PNL channel
  ws_client.subscribe(channel=key.channel) print(ws_client.get(key)) I just wanted
  to share my experience of publishing Open Source. For some reason I get a lot of
  motivation when I can publish code that makes peoples'' lives easier. The library
  could use some code review on it, so if you‚Äôd feel like reading some code and helping
  out - drop me a message. Other than that, happy to answer any questions, and - if
  you are an algo trader - let me know if you get a chance to use it. Thanks for reading!'
Title: Hi! I've published a Python client for IBKR REST and WebSocket APIs - IBind.
  Hope you like it üëã
---
Author: u/jgloewen
Content: 'Python Streamlit is a terrific tool for creating interactive data visualizations.
  It packages all your visualizations up into a neat little application - including
  charts and maps - and displays them in your default browser. No muss, no fuss. Recently,
  I found a new dataset (to me) on the UN High Commission for Refugees (UNHCR) website.
  It contains country-to-country movements for refugees both from origin country and
  country of asylum Using this dataset, here''s a step-by-step on how to code a Python
  Streamlit application that has: A dropdown menu to select by country A second dropdown
  menu to select by year Radio buttons (2) to select country of origin or county of
  asylum A global choropleth map to display the results by country and year. Free
  article HERE .'
Title: 'Python Streamlit Spotlight Tutorial: an Interactive Dashboard using UNHCR
  Refugee Data'
---
Author: u/nicanorflavier
Content: 'Hey folks, I''ve been dabbling with a Python project recently that''s all
  about making life easier for us I.T. people. It''s a nifty little tool that calculates
  IP subnets and does IP calculations from the command or CLI. Here''s the GitHub
  link and the code: https://github.com/nicanorflavier/ipnet I‚Äôm pretty stoked about
  it, but I know there‚Äôs always room for improvement. So, I thought, better to turn
  to than the wise minds of this python community? I‚Äôm all ears for any feedback,
  tips, tricks, or advice you guys might have. Thanks a ton in advance!'
Title: IP subnet or IP calculator tool need feedback
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/60percentcocoa
Content: 'Wrote this as a tool to keep README coverage badges up to date without relying
  on 3rd party services or having to do anything extra, thought others might get some
  utility out of it: coverage-pre-commit . A .coverage file is expected at the root
  of the project, generated by running coverage run directly or using a plugin such
  as pytest-cov when running tests. Most convenient when used as a pre-push hook imo.
  Feel free to opine, be it positive or negative!'
Title: Pre-commit hook to keep coverage badge in README up to date
---
Author: u/daivushe1
Content: 'I''m thrilled to share my first open-source project with you all: PyWolt
  ! üéâ PyWolt is a Python library that makes it super easy to interact with the Wolt
  API. What My Project Does: Discover Venues: Find nearby spots to grab a bite. Explore
  Menus: Dive into a venue''s menu and pick your favorites. Target Audience: Software
  Engineers : Professionals who build web or mobile applications, particularly those
  in the food delivery or restaurant industry, looking to incorporate Wolt''s services
  seamlessly into their platforms. Data Scientists/Analysts : Individuals analyzing
  food delivery data, consumer behavior, or market trends, who may utilize PyWolt
  to gather data from Wolt''s API for analysis and insights. Students/Learners : Those
  studying Python programming, web development, or API integration, who can use PyWolt
  as a practical example or learning tool to understand how to interact with RESTful
  APIs in Python. Freelancers/Entrepreneurs : Independent developers or startup founders
  looking to build new food-related applications or services leveraging Wolt''s platform
  without reinventing the wheel. Comparison: woltcheck : only offers a script to check
  if a wolt restaurant is ready to deliver to your location. what-to-eat : a pretty
  neat cli tool that offers all of pywolt''s functionality. In my opinion it overcomplicates
  things a little, and doesn''t offer straight-forward RESTful functionality to interact
  with the API itself.'
Title: 'PyWolt: Wolt food delivery service API wrapper'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/Rawing7
Content: 'I''m Paul, one of the creators of Rio. Over the years I''ve tried many different
  established python GUI frameworks, but none of them really satisfied me. So I teamed
  up with a few like minded developers and spent the last few months to create our
  own framework. Rio is the result of this effort. What My Project Does Rio is a brand
  new GUI framework that lets you create modern web apps in just a few lines of Python.
  Our goal is to simplify web and app development, so you can focus on the things
  you care about, instead of wasting countless hours on frustrating user interface
  details. We do this by following the core principles of Python that we all know
  and love. Python is supposed to be simple and compact - and so is Rio. There is
  no need to learn any additional languages such as HTML, CSS or JavaScript, because
  all of the UI, Logic, Components and even layouting is done entirely in Python.
  There‚Äôs not even a distinction between front-end and back-end. Rio handles all of
  the communication transparently for you. Key Features Full-Stack Web Development:
  Rio handles front-end and backend for you. In fact, you won''t even notice they
  exist. Create your UI, and Rio will take care of the rest. Python Native: Rio apps
  are written in 100% Python, meaning you don''t need to write a single line of CSS
  or JavaScript. Modern Python: We embrace modern Python features, such as type annotations
  and asynchrony. This keeps your code clean and maintainable, and helps your code
  editor help you out with code completions and type checking. Python Debugger Compatible:
  Since Rio runs on Python, you can connect directly to the running process with a
  debugger. This makes it easy to identify and fix bugs in your code. Declarative
  Interface: Rio apps are built using reusable components, inspired by React, Flutter
  & Vue. They''re declaratively combined to create modular and maintainable UIs. Batteries
  included: Over 50 builtin components based on Google''s Material Design Demo Video
  Target Audience Whether you need to build dashboards, CRUD apps, or just want to
  make a personal website, Rio makes it possible without any web development knowledge.
  Because Rio was developed from the ground up for Python programmers, it was designed
  to be concise and readable, just like Python itself. Comparison Rio doesn''t just
  serve HTML templates like you might be used to from frameworks like Flask. In Rio
  you define components as simple dataclasses with a React/Flutter style build method.
  Rio continuously watches your attributes for changes and updates the UI as necessary.
  class MyComponent(rio.Component): clicks: int = 0 def _on_press(self) -> None: self.clicks
  += 1 def build(self) -> rio.Component: return rio.Column( rio.Button(''Click me'',
  on_press=self._on_press), rio.Text(f''You clicked the button {self.clicks} time(s)''),
  ) app = rio.App(build=MyComponent) app.run_in_browser() Notice how there is no need
  for any explicit HTTP requests. In fact there isn''t even a distinction between
  frontend and backend. Rio handles all communication transparently for you. Unlike
  ancient libraries like Tkinter, Rio ships with over 50 builtin components in Google''s
  Material Design. Moreover the same exact codebase can be used for both local apps
  and websites. We Want Your Feedback! The first alpha version of Rio is available
  on PyPi now: pip install rio-ui rio new my-project --template tic-tac-toe cd my-project
  rio run Discord GitHub Tutorial Website Let us know what you think - any feedback,
  ideas, or even a helping hand are hugely welcome! Just hop on our Discord server
  and say hello!'
Title: I made a React-like web framework for Python üëã
---
Author: u/treyhunner
Content: 'Python 3.13.0 beta 1 was released today. The feature I''m most excited about
  is the new Python REPL. Here''s a summary of my favorite features in the new REPL
  along with animated gifs . The TLDR: Support for block-leveling history and block-level
  editing Pasting code (even with blank lines within it) works as expected now Typing
  exit will exit (no more Use exit() or Ctrl-D (i.e. EOF) to exit message)'
Title: The new REPL in Python 3.13.0 beta 1
---
Author: u/TokenChingy
Content: 'I was doing some light reading and stumbled across Steve Gribbles Power
  vs Speed Calculator and thought I''d give it a go at rebuilding it based on his
  Physics model using Python. Then I wrote an article about. Thought I''d share it
  with you all: Calculating Virtual Cycling Power (jasonlei.com)'
Title: Calculating Virtual Cycling Power With Python
---
Author: u/Balance-
Content: 'Main Changes Add GUI functions Vehicle tracking: You can now track a specific
  vehicle to see their route Dataframe viewer: Stats can be confirmed Improve vehicle
  routing functions Add example of routing optimization Change documentation ''s theme
  for better indexing UXsim UXsim is a free, open-source macroscopic and mesoscopic
  network traffic flow simulator written in Python. It simulates the movements of
  car travelers and traffic congestion in road networks. It is suitable for simulating
  large-scale (e.g., city-scale) traffic phenomena. UXsim is especially useful for
  scientific and educational purposes because of its simple, lightweight, and customizable
  features, but users are free to use UXsim for any purpose.'
Title: UXsim 1.3.0 released with vehicle tracking and improved vehicle routing
---
Author: u/Babe_My_Name_Is_Hung
Content: 'Hi everyone! I recently finished a small side project for my graduating
  thesis, which is about experimenting with RAG-based frameworks in improving resume
  screening. What my project does: The project for the thesis is a GPT-4 Chatbot with
  RAG Fusion retrieval. Given a job description as input, the system retrieves the
  most relevant candidate profiles to perform follow-up tasks such as analysis, summarization,
  and decision-making, which can assist the screening process better. The revolving
  idea is that the similarity-based retrieval process can effectively narrow the initial
  large pool of applicants down to the most relevant resumes. However, this simple
  similarity ranking should not be used to evaluate a candidate''s actual ability.
  Therefore, the top resumes are used to augment the GPT-4 Chatbot so it can be conditioned
  on these profiles and perform further downstream tasks. Target audience: The repo
  contains the link to my paper and the notebooks that were used to design the prototype
  program and conduct some experiments. For the newcomers to RAG/RAG Fusion, or people
  who are just interested in building a RAG-based chatbots, this can be especially
  helpful. Feel free to check them out too! Comparison: I''m not sure if there''s
  any similar project out there, but the program is sort of designed to move the resume
  screening process away from existing keyword-based methods. It''s much more versatile
  in use cases and also more effective in handling resumes. The project is very far
  from being perfect. Because of that, I share this with the hope to receive suggestions
  and feedback from you. If you have time, please give the project a visit here: GitHub'
Title: Resume Screening Chatbot using RAG Fusion
---
Author: u/foadsf
Content: 'Five years ago, I posted about JModelica, a fantastic open-source tool for
  simulating complex systems that combined the ease of Python with the strength of
  Modelica. Sadly, the project went quiet, but I''m thrilled to share that, thanks
  to the dedication of a few folks (myself included!), JModelica is back! You can
  find the revived project on GitHub: https://github.com/JModelica/JModelica . What
  JModelica Does: JModelica provides a way to write complex simulations using the
  Modelica language, which is known for its ability to handle differential equations
  and model physical systems beautifully. The magic of JModelica lies in its Python
  integration‚Äîyou can solve your Modelica models and access the results directly in
  Python for in-depth analysis, visualization, and even optimization using libraries
  you already love! Target Audience: This project is geared toward anyone interested
  in modeling and simulating complex systems, particularly those with a background
  in engineering, physics, or related fields. If you''ve struggled with Python''s
  ODE solvers or wish for a more elegant way to model physical interactions, JModelica
  offers a compelling solution. It''s ready for research, educational projects, and
  even more ambitious endeavors! Comparison: JModelica stands alongside OpenModelica
  as a champion of open-source Modelica tools. While OpenModelica is known for its
  user-friendly graphical interface, JModelica shines in its seamless integration
  with Python, giving you the best of both worlds! It''s a powerful alternative to
  proprietary software like Simulink, providing transparency, flexibility, and a thriving
  community. We''re actively working on squashing bugs, adding features, and making
  JModelica more accessible across different platforms (Windows and macOS support
  are on the horizon!). Anyone interested in contributing is welcome! Whether you''re
  a Modelica expert or a curious newcomer, this project has a place for you. Check
  out the GitHub repository to explore the code, open issues, or submit pull requests.'
Title: 'Giving New Life to JModelica: Bringing Powerful Modelica Simulations to Python'
---
Author: u/realazthat
Content: 'What My Project Does What My Project Does: snipinator is a CLI to embed
  (testable) snippets from your codebase into your README, using Jinja2 and functions
  provided by snipinator to assist with embedding code, shell output, etc. Please
  provide any feedback in the comments or GH issues. Target Audience Target Audience:
  Developers of {GitHub,other} projects that have a README. It works for me, it might
  work for you. Comparison Features: Supports anything Jinja2 supports. First-class
  support for python source code. Can include python function signatures, docstrings,
  entire function source code, classes. Snip from any source code language . Put delimiter
  markers into the code (e.g # START_SNIPPET , # END_TEMPLATE ), and use snippet()
  . First-class support for Markdown templates (with backtickify , decomentify ).
  Can include shell output . Supports ANSI colors with SVG output. More robust references/links
  to local files using path() . I keep a table of similar projects in my README at
  realazthat/snipinator: Related Projects . Not complete, and not necessarily up to
  date. Make a PR to README.md.jinja , (see realazthat/snipinator/Contributions )
  to insert/modify the table. Project Stars Last Update Language Platform Similarity
  X Obviousness mdx-js/mdx 16.8k 2024/04/17 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê zakhenry/embedme 222 2023/11/08
  JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê cmacmackin/markdown-include 95 2023/02/07 Python N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê BurdetteLamar/markdown_helper
  38 2020/03/16 Ruby N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê SimonCropp/MarkdownSnippets 23 2024/04/23 .NET N/A
  ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê endocode/snippetextractor 4 2014/08/16 C++ N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê polywrap/doc-snippets
  3 2023/09/26 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê JulianCataldo/remark-embed 2 2022/09/22 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê xrd/oreilly-snippets
  2 2015/10/15 Ruby N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê DamonOehlman/injectcode 1 2021/08/01 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê electrovir/markdown-code-example-inserter
  1 2024/02/19 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê andersfischernielsen/Simple-Embedded-Markdown-Code-Snippets
  1 2021/02/12 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ildar-shaimordanov/git-markdown-snippet 0 2021/09/14 Perl
  N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê teyc/markdown-snippet 0 2024/01/22 Powershell N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê marc-bouvier-graveyard/baldir_markdown
  0 2020/06/15 Python N/A ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê dineshsonachalam/markdown-autodocs 176 2022/09/19
  JS GH Action ‚≠ê‚≠ê‚≠ê‚≠ê tokusumi/markdown-embed-code 28 2022/01/05 Python GH Action ‚≠ê‚≠ê‚≠ê‚≠ê
  sammndhr/gridsome-remark-embed-snippet 2 2021/06/14 JS Gridsome ‚≠ê‚≠ê‚≠ê‚≠ê NativeScript/markdown-snippet-injector
  4 2019/01/24 JS N/A ‚≠ê‚≠ê‚≠ê‚≠ê fuxingloh/remark-code-import-replace 0 2022/12/21 JS Remark?
  ‚≠ê‚≠ê‚≠ê‚≠ê szkiba/mdcode 15 2014/02/12 Go N/A ‚≠ê‚≠ê‚≠ê devincornell/pymddoc 0 2023/12/01 Python
  Python ‚≠ê‚≠ê‚≠ê shiftkey/scribble ( docs ) 40 2013/08/08 .NET N/A ‚≠ê‚≠ê calebpeterson/jest-transformer-test-md
  2 2020/08/21 JS Jest Tests ‚≠ê‚≠ê tjstankus/commitate 0 2014/05/29 Ruby N/A ‚≠ê GitHub
  Docs: Creating a permanent link to a code snippet N/A N/A N/A N/A ‚≠ê javierfernandes/markdown-exercises
  1 2017/05/01 JS N/A ‚≠ê gatsby-remark-embed-snippet N/A (55k) 2024/01/23 JS Gatsby
  ‚≠ê ARMmbed/snippet 6 2021/08/05 Python N/A ? drewavis/markdowninclude 1 2024/04/06
  JS VSCode Extension ? romnn/embedme 0 2024/04/18 Go N/A ? The 5 star projects have
  the bare minimum of being able to embed a file, and run via CLI. Snipinator does
  have other features (such as shell() ), implemented as I needed them (and listed
  below) which I do not think any of these have in combination. Some of these projects
  are not CLIs. mdx-js/mdx is the closest in terms of flexibility, but it is JS +
  components, which may not be everyone''s cup of tea. Usage: Example template README:
  (./snipinator/examples/EXAMPLE.md.jinja2): # A README Here is a code snippet: <!--{{
  pysnippet(path=''snipinator/examples/code.py'', symbol=''MyClass'', backtickify=''py'',
  decomentify=''nl'') }}--> Note that `code.py` has a test: {{path(''./snipinator/examples/code_test.py'',
  link=''md'')}}. Generating the README: $ python -m snipinator.cli -t snipinator/examples/EXAMPLE.md.jinja2
  <!-- WARNING: This file is auto-generated by snipinator. Do not edit directly. SOURCE:
  `snipinator/examples/EXAMPLE.md.jinja2`. --> # A README Here is a code snippet:
  <!----> ```py class MyClass: """This is a global class""" def __init__(self, name):
  self.name = name def MyClassMethod(self): """This is a method of MyClass""" print(self.name)
  ``` <!----> Note that `code.py` has a test: [./snipinator/examples/code_test.py](./snipinator/examples/code_test.py).'
Title: CLI to embed code snippets in your README, from actual (testable) code
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Monday Daily Thread: Project ideas!'
---
Author: u/teamamentum
Content: 'What My Project Does Overlaying intensity plots onto a geographical map
  using cartopy/matplotlib can be complex. So we created this map_plotter package
  to abstract away that complexity for a common use case. Installation (opinionated
  use of conda to avoid cartopy dependency hell and install precompiled binaries)
  conda install cartopy git clone git@github.com:amentumspace/map_plotter.git cd map_plotter
  pip install . Usage import map_plotter map_plotter.plot(lons_g, lats_g, variable,
  units="m/s", img_name="image.png", save=True, plot=True, title="something", zlims=[0,10])
  Whereby: lons_g and lats_g represent 2D matrices / grids of longitudes and latitudes.
  values is the matrix of values to be plotted (same grid dimensions). units and img_name
  (self explanatory). save & plot boolean flags to save the file and plot to screen,
  respectively. zlims define the color scale minimum and maximum. Target Audience
  Python developers or data scientists or scientists or any Pythonista wanting a simple
  way to quickly plot an intensity map onto a geographical map. Comparison Differs
  from using cartopy and matplotlib in its ease-of-use, but it is less customisable
  (can''t change projections, colors). Regardless, it''s convenient and at least provides
  a starting point for customisation. Similar functionality can be had from geopandas
  or folium (although cartopy/matplotlib suited our needs better).'
Title: map_plotter - abstracts complexity of creating intensity plots overlaid onto
  global map
---
Author: u/AlSweigart
Content: 'What My Project Does This is a music video of the output of a Python program:
  https://www.youtube.com/watch?v=Sjk4UMpJqVs I''m the author of Automate the Boring
  Stuff with Python and I teach people to code. As part of that, I created something
  I call "scroll art". Scroll art is a program that prints text from a loop, eventually
  filling the screen and causing the text to scroll up. (Something like those BASIC
  programs that are 10 PRINT "HELLO"; 20 GOTO 10) Once printed, text cannot be erased,
  it can only be scrolled up. It''s an easy and artistic way for beginners to get
  into coding, but it''s surprising how sophisticated they can become. The source
  code for this animation is here: https://github.com/asweigart/scrollart/blob/main/python/forbiddenzone.py
  (read the comments at the top to figure out how to run it with the forbiddenzonecontrol.py
  program which is also in that repo) The output text is procedurally generated from
  random numbers, so like a lava lamp, it is unpredictable and never exactly the same
  twice. This video is a collection of scroll art to the music of "The Forbidden Zone,"
  which was released in 1980 by the band Oingo Boingo, led by Danny Elfman (known
  for composing the theme song to The Simpsons.) It was used in a cult classic movie
  of the same name, but also the intro for the short-run Dilbert animated series.
  Target Audience Anyone (including beginners) who wants ideas for creating generative
  art without needing to know a ton of math or graphics concepts. You can make scroll
  art with print() and loops and random numbers. But there''s a surprising amount
  of sophistication you can put into these programs as well. Comparison Because it''s
  just text, scroll art doesn''t have such a high barrier to entry compared with many
  computer graphics and generative artwork. The constraints lower expectations and
  encourage creativity within a simple context. I''ve produced scroll art examples
  on https://scrollart.org I also gave a talk on scroll art at PyTexas 2024: https://www.youtube.com/watch?v=SyKUBXJLL50'
Title: '2,000 lines of Python code to make this scrolling ASCII art animation: "The
  Forbidden Zone"'
---
Author: u/rageagainistjg
Content: After playing around with a dataframe‚Äîapplying filters or other transformations‚ÄîI'm
  curious about your methods for reviewing the changes. In VS Code, the variable explorer
  is quite handy for a quick look at the modified dataframe. Alternatively, when working
  in a Jupyter notebook within VS Code, exporting the data to an Excel file provides
  a detailed view and allows for an easy deep dive into the results. What are your
  preferred practices for ensuring your data adjustments are precisely what you intended?
Title: Reviewing Dataframe Changes? Looking for Your Preferred Methods!
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Sunday Daily Thread: What''s everyone working on this week?'
---
Author: u/Cool-Nefariousness76
Content: 'Hi everybody, over the last year I''ve been developing a library that adds
  some Cython 3.0 annotations to existing python code. What My Project Does: For example
  if it sees a for i in range(): in a function it recognizes i as an integer and adds
  a i = cython.declare(cython.int) line at the beginning of the function. It actually
  uses the built-in ast module under the hood for parsing, I found it a super useful
  library! Target Audience: It is a side project I made mainly for fun. I don''t know
  if it can be of interest to anybody, or if it could have some potential utility.
  Comparison: I did not find anything similar. There are a lot of very cool projects
  like mypyc for example, but nothing that does this tiny little code generation specific
  to Cython. The link to the repository is here: https://github.com/nucccc/markarth'
Title: Library for automatic Cython 3.0 code annotations generation.
---
Author: u/kostakos14
Content: Hey folks, looking to use one library to implement some background scheduling
  logic on my application. I find in Google search APScheduler to be frequently mentioned,
  but I can see the Schedule package has more GH stars. Was curious if anybody has
  used one of them, and which one would you recommend based on your own experience.
Title: APScheduler vs Schedule package
---
Author: u/devotaku
Content: 'Excited to share my personal open-source project: Notolog - Python Markdown
  Editor (MIT License). The main motivation for developing another markdown editor
  was my passion for learning new things and enhancing my development skills in Python.
  I developed it in my spare time over a few months, despite having no prior experience
  in creating full-scale Python applications. What My Project Does ‚àó Multiplatform
  ‚àó Markdown async syntax highlighting created by me ‚àó Several pre-installed color
  themes ‚àó Supports English and 17 other languages right out of the box ‚àó Integration
  with OpenAI API for AI-assisted features ‚àó Optional file encryption/decryption Target
  Audience Primarily developers who write markdown documents and notes. Comparison
  This is more of a personal learning project, so it''s hard to compare it directly
  with others. How to install Discover Notolog on GitHub üåü and PyPI . Installation
  is as easy as running a single command: pip install notolog'
Title: 'Introducing Notolog: Python Markdown Editor built with PySide6'
---
Author: u/Royal_Section4889
Content: 'I have been using zabbix for monitoring a lot of metrics in my work, none
  of the most popular zabbix were capable of doing async tasks, so I''ve developed
  some simple package capable of doing this. Tests, examples and how-tos can be found
  here: https://github.com/gustavofbreunig/zabbix-sender-async What My Project Does
  Send zabbix sender messages using asyncio tasks. Target Audience SysAdmins who use
  Zabbix to monitor a large number of metrics. Comparison Instead of doing traditional
  way, using these abandoned library: https://github.com/adubkov/py-zabbix from pyzabbix
  import ZabbixMetric, ZabbixSender # Send metrics to zabbix trapper packet = [ ZabbixMetric(''hostname1'',
  ''test[cpu_usage]'', 2), ZabbixMetric(''hostname1'', ''test[system_status]'', "OK"),
  ZabbixMetric(''hostname1'', ''test[disk_io]'', ''0.1''), ZabbixMetric(''hostname1'',
  ''test[cpu_usage]'', 20, 1411598020), ] result = ZabbixSender(use_config=True).send(packet)
  You can do this: async def sendmetrics(): sender = AsyncSender(''localhost'', 10051)
  metric = ItemData(host=''hostname'', key=''test.metric.text'', value=''test package
  import'') result = await sender.send(metric)'
Title: I've developed a library for send metrics to zabbix asynchronously
---
Author: u/asksumanth
Content: 'What my project does : It supports services like IBM Watson, Acapela and
  Stream labs'' demo websites to convert your text to speech. Target audience : It''s
  a toy project and would not recommend you to use in Production. Comparison : It''s
  wayyyyy easy to use. Just pip install and use in your project. No extra setup required
  like other libraries. Also supports various languages and voices and accents. Check
  docs for more. Here is the link to repository. Please go do check it out and star
  it if it''s helpful to you guys. Thank you. I made this library taking inspiration
  from this php tts library by chrisjp.'
Title: I made a Python text to speech library - Pyt2s
---
Author: u/Spiffidimus
Content: I made a library to create interactive plots in the terminal ( pip install
  itrm ). It uses braille characters (by default) to display the data with sub-character
  resolution. There are several keybindings for moving a vertical cursor left and
  right, for zooming in or out on data, and for changing which curve to focus on.
  There are occasions (such as when working with a server) where MatPlotLib is not
  an option and the terminal is the only available tool. But, in my opinion, it is
  actually faster to use this tool (itrm) to zoom in on interesting parts of data
  and analyze patterns than using other tools like MatPlotLib. In fact, with large
  data sets (~1 million points), this tool actually renders faster than MatPlotLib.
  Please check it out and let know what you think.
Title: Interactive plots in the terminal
---
Author: u/VoyZan
Content: 'Hi! I want to share a library I''ve built recently. IBind is a REST and
  WebSocket Python client for Interactive Brokers Client Portal Web API . It is directed
  at IBKR users. You can find IBind on GitHub: https://github.com/Voyz/ibind What
  My Project Does: It is a REST and WebSocket API for the Interactive Brokers'' Web
  API. I''m particularly proud of a few things in this release: The REST and WebSocket
  API clients are based on an abstract base class RestClient and WsClient accordingly.
  These could be implemented to use some other Web APIs in a relatively straightforward
  way. I have in fact used a version of that WsClient for a cryptocurrency WebSocket
  API, and it is nice to see it adapt to a different environment. I''ve covered most
  of the codebase with automated tests (appx 80%). Contrary to some of my other libraries,
  these are mainly integration tests which feel to provide a stronger test coverage
  than only unit tests. I''ve learned how to use class mixins in this project, and
  it aids the maintainability by a lot! The REST client itself is pretty barebone,
  but has a lot of mixin classes - all corresponding to the endpoint categories the
  broker uses, making it easy to search for the right piece of code and documentation.
  There''s a lot of things that make this client as plug-and-play as possible. The
  broker requires the user to specify a bunch of things - account ids, certificates,
  URLs, etc. - which the class either reads from the environment variables or assumes
  (given that some things would be common for most users). In either case, all these
  are customisable by parameters if needed, but it is nice to just write client =
  IbkrClient() in various projects having set just a couple of env vars. I think the
  documentation is pretty in-depth but readable. It''s always hard to judge whether
  docs are well written, but I think it is nicely broken down. Also, I managed to
  use pydoc-markdown package to create API reference in markdown, which works nicely
  with the GitHub Wiki. I''d prefer it to be even easier, but compared to Sphinx and
  readthedocs it''s a much quicker job. The WebSocket class does a ton to keep the
  connection alive and recover from connection losses. Maintaining active subscriptions
  after a re-connect can be a real pain, and I think this class does it in a nice
  and reliable way. I''ve tested it for various types of connectivity loss, and it
  manages to recover and re-establish the WebSocket data stream. Pretty crucial in
  the trading environment. I made a nice logo for it ü•≥ Target Audience: Traders using
  IBKR who want to automate their trading through this Web API. Comparison (A brief
  comparison explaining how it differs from existing alternatives.) : There are two
  similar libraries that I know of. They aren''t bad, but seem not very well maintained
  and incomplete: https://github.com/areed1192/interactive-brokers-api - outdated
  and stale, last update 3 years ago https://github.com/utilmon/EasyIB - stale and
  incomplete The library I''ve published covers a much wider range of endpoints, adds
  WebSocket support and a bunch of wrapper methods to simplify the usage of the API.
  IBind has a bunch of features that make using the IBKR APIs much easier. Some of
  these are: REST: Automated question/answer handling - streamlining placing orders.
  Parallel requests - speeding up collection of price data. Rate limiting - guarding
  against account bans. Conid unpacking - helping to find the right contract. WebSocket:
  WebSocket thread lifecycle handling - ensuring the connection is alive. Thread-safe
  Queue data stream - exposing the collected data in a safe way. Internal subscription
  tracking - recreating subscriptions upon re-connections. Health monitoring - Acting
  on unusual ping or heartbeat. REST Example: from ibind import IbkrClient # Construct
  the client client = IbkrClient() print(client.tickle().data) WebSocket Example:
  from ibind import IbkrWsKey, IbkrWsClient # Construct the client. ws_client = IbkrWsClient(start=True)
  # Choose the WebSocket channel key = IbkrWsKey.PNL # Subscribe to the PNL channel
  ws_client.subscribe(channel=key.channel) print(ws_client.get(key)) I just wanted
  to share my experience of publishing Open Source. For some reason I get a lot of
  motivation when I can publish code that makes peoples'' lives easier. The library
  could use some code review on it, so if you‚Äôd feel like reading some code and helping
  out - drop me a message. Other than that, happy to answer any questions, and - if
  you are an algo trader - let me know if you get a chance to use it. Thanks for reading!'
Title: Hi! I've published a Python client for IBKR REST and WebSocket APIs - IBind.
  Hope you like it üëã
---
Author: u/jgloewen
Content: 'Python Streamlit is a terrific tool for creating interactive data visualizations.
  It packages all your visualizations up into a neat little application - including
  charts and maps - and displays them in your default browser. No muss, no fuss. Recently,
  I found a new dataset (to me) on the UN High Commission for Refugees (UNHCR) website.
  It contains country-to-country movements for refugees both from origin country and
  country of asylum Using this dataset, here''s a step-by-step on how to code a Python
  Streamlit application that has: A dropdown menu to select by country A second dropdown
  menu to select by year Radio buttons (2) to select country of origin or county of
  asylum A global choropleth map to display the results by country and year. Free
  article HERE .'
Title: 'Python Streamlit Spotlight Tutorial: an Interactive Dashboard using UNHCR
  Refugee Data'
---
Author: u/nicanorflavier
Content: 'Hey folks, I''ve been dabbling with a Python project recently that''s all
  about making life easier for us I.T. people. It''s a nifty little tool that calculates
  IP subnets and does IP calculations from the command or CLI. Here''s the GitHub
  link and the code: https://github.com/nicanorflavier/ipnet I‚Äôm pretty stoked about
  it, but I know there‚Äôs always room for improvement. So, I thought, better to turn
  to than the wise minds of this python community? I‚Äôm all ears for any feedback,
  tips, tricks, or advice you guys might have. Thanks a ton in advance!'
Title: IP subnet or IP calculator tool need feedback
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Saturday Daily Thread: Resource Request and Sharing! Daily Thread'
---
Author: u/60percentcocoa
Content: 'Wrote this as a tool to keep README coverage badges up to date without relying
  on 3rd party services or having to do anything extra, thought others might get some
  utility out of it: coverage-pre-commit . A .coverage file is expected at the root
  of the project, generated by running coverage run directly or using a plugin such
  as pytest-cov when running tests. Most convenient when used as a pre-push hook imo.
  Feel free to opine, be it positive or negative!'
Title: Pre-commit hook to keep coverage badge in README up to date
---
Author: u/daivushe1
Content: 'I''m thrilled to share my first open-source project with you all: PyWolt
  ! üéâ PyWolt is a Python library that makes it super easy to interact with the Wolt
  API. What My Project Does: Discover Venues: Find nearby spots to grab a bite. Explore
  Menus: Dive into a venue''s menu and pick your favorites. Target Audience: Software
  Engineers : Professionals who build web or mobile applications, particularly those
  in the food delivery or restaurant industry, looking to incorporate Wolt''s services
  seamlessly into their platforms. Data Scientists/Analysts : Individuals analyzing
  food delivery data, consumer behavior, or market trends, who may utilize PyWolt
  to gather data from Wolt''s API for analysis and insights. Students/Learners : Those
  studying Python programming, web development, or API integration, who can use PyWolt
  as a practical example or learning tool to understand how to interact with RESTful
  APIs in Python. Freelancers/Entrepreneurs : Independent developers or startup founders
  looking to build new food-related applications or services leveraging Wolt''s platform
  without reinventing the wheel. Comparison: woltcheck : only offers a script to check
  if a wolt restaurant is ready to deliver to your location. what-to-eat : a pretty
  neat cli tool that offers all of pywolt''s functionality. In my opinion it overcomplicates
  things a little, and doesn''t offer straight-forward RESTful functionality to interact
  with the API itself.'
Title: 'PyWolt: Wolt food delivery service API wrapper'
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Friday Daily Thread: r/Python Meta and Free-Talk Fridays'
---
Author: u/Rawing7
Content: 'I''m Paul, one of the creators of Rio. Over the years I''ve tried many different
  established python GUI frameworks, but none of them really satisfied me. So I teamed
  up with a few like minded developers and spent the last few months to create our
  own framework. Rio is the result of this effort. What My Project Does Rio is a brand
  new GUI framework that lets you create modern web apps in just a few lines of Python.
  Our goal is to simplify web and app development, so you can focus on the things
  you care about, instead of wasting countless hours on frustrating user interface
  details. We do this by following the core principles of Python that we all know
  and love. Python is supposed to be simple and compact - and so is Rio. There is
  no need to learn any additional languages such as HTML, CSS or JavaScript, because
  all of the UI, Logic, Components and even layouting is done entirely in Python.
  There‚Äôs not even a distinction between front-end and back-end. Rio handles all of
  the communication transparently for you. Key Features Full-Stack Web Development:
  Rio handles front-end and backend for you. In fact, you won''t even notice they
  exist. Create your UI, and Rio will take care of the rest. Python Native: Rio apps
  are written in 100% Python, meaning you don''t need to write a single line of CSS
  or JavaScript. Modern Python: We embrace modern Python features, such as type annotations
  and asynchrony. This keeps your code clean and maintainable, and helps your code
  editor help you out with code completions and type checking. Python Debugger Compatible:
  Since Rio runs on Python, you can connect directly to the running process with a
  debugger. This makes it easy to identify and fix bugs in your code. Declarative
  Interface: Rio apps are built using reusable components, inspired by React, Flutter
  & Vue. They''re declaratively combined to create modular and maintainable UIs. Batteries
  included: Over 50 builtin components based on Google''s Material Design Demo Video
  Target Audience Whether you need to build dashboards, CRUD apps, or just want to
  make a personal website, Rio makes it possible without any web development knowledge.
  Because Rio was developed from the ground up for Python programmers, it was designed
  to be concise and readable, just like Python itself. Comparison Rio doesn''t just
  serve HTML templates like you might be used to from frameworks like Flask. In Rio
  you define components as simple dataclasses with a React/Flutter style build method.
  Rio continuously watches your attributes for changes and updates the UI as necessary.
  class MyComponent(rio.Component): clicks: int = 0 def _on_press(self) -> None: self.clicks
  += 1 def build(self) -> rio.Component: return rio.Column( rio.Button(''Click me'',
  on_press=self._on_press), rio.Text(f''You clicked the button {self.clicks} time(s)''),
  ) app = rio.App(build=MyComponent) app.run_in_browser() Notice how there is no need
  for any explicit HTTP requests. In fact there isn''t even a distinction between
  frontend and backend. Rio handles all communication transparently for you. Unlike
  ancient libraries like Tkinter, Rio ships with over 50 builtin components in Google''s
  Material Design. Moreover the same exact codebase can be used for both local apps
  and websites. We Want Your Feedback! The first alpha version of Rio is available
  on PyPi now: pip install rio-ui rio new my-project --template tic-tac-toe cd my-project
  rio run Discord GitHub Tutorial Website Let us know what you think - any feedback,
  ideas, or even a helping hand are hugely welcome! Just hop on our Discord server
  and say hello!'
Title: I made a React-like web framework for Python üëã
---
Author: u/treyhunner
Content: 'Python 3.13.0 beta 1 was released today. The feature I''m most excited about
  is the new Python REPL. Here''s a summary of my favorite features in the new REPL
  along with animated gifs . The TLDR: Support for block-leveling history and block-level
  editing Pasting code (even with blank lines within it) works as expected now Typing
  exit will exit (no more Use exit() or Ctrl-D (i.e. EOF) to exit message)'
Title: The new REPL in Python 3.13.0 beta 1
---
Author: u/TokenChingy
Content: 'I was doing some light reading and stumbled across Steve Gribbles Power
  vs Speed Calculator and thought I''d give it a go at rebuilding it based on his
  Physics model using Python. Then I wrote an article about. Thought I''d share it
  with you all: Calculating Virtual Cycling Power (jasonlei.com)'
Title: Calculating Virtual Cycling Power With Python
---
Author: u/FI_Mihej
Content: 'InterProcessPyObjects Python package github.com/FI-Mihej/InterProcessPyObjects
  If you like the project, consider giving it a star on GitHub to show your support
  and help further development. :) pypi.org/project/InterProcessPyObjects What My
  Project Does InterProcessPyObjects is a part of the Cengal library. If you have
  any questions or would like to participate in discussions, feel free to join the
  Cengal Discord . Your support and involvement are greatly appreciated as Cengal
  evolves. This high-performance package delivers blazing-fast inter-process communication
  through shared memory, enabling Python objects to be shared across processes with
  exceptional efficiency. By minimizing the need for frequent serialization-deserialization,
  it enhances overall speed and responsiveness. The package offers a comprehensive
  suite of functionalities designed to support a diverse array of Python types and
  facilitate asynchronous IPC, optimizing performance for demanding applications.
  Target Audience This project is designed for production environments, offering a
  stable API suitable for developers looking to implement fast inter-process communication.
  Whether you''re building complex systems or require robust data sharing and modification
  across processes, InterProcessPyObjects is ready to meet your needs. Comparison
  Comparison with multiprocessing.shared_memory While both InterProcessPyObjects and
  multiprocessing.shared_memory facilitate inter-process communication, there are
  several key differences to note. Unlike multiprocessing.shared_memory, InterProcessPyObjects
  offers the following enhancements: High-Performance Mutable Objects: Both connected
  processes can modify shared objects at runtime, and these changes are immediately
  reflected on the other side. This feature not only increases flexibility but also
  delivers exceptional performance, with the capability to handle up to several million
  changes per second. Synchronization Features: Ensures that operations are thread-safe
  and data integrity is maintained across processes. Message Queue: Integrates a system
  for queuing messages, making communication between processes more structured and
  reliable. Extended Type Support: Supports a broad range of data types, including
  custom classes, which goes beyond the basic types typically handled by multiprocessing.shared_memory.
  These features make InterProcessPyObjects a more robust option for developers requiring
  advanced inter-process communication capabilities. API State Stable. Guaranteed
  not to have breaking changes in the future. (see github.com/FI-Mihej/InterProcessPyObjects?tab=readme-ov-file#api-state
  for details) Key Features Shared Memory Communication: Enables sharing of Python
  objects directly between processes using shared memory. Utilizes a linked list of
  global messages to inform connected processes about new shared objects. Lock-Free
  Synchronization: Uses memory barriers for efficient communication, avoiding slow
  syscalls. Ensures each process can access and modify shared memory without contention.
  Supported Python Types: Handles various Python data structures including: Basic
  types: None , bool , 64-bit int , large int (arbitrary precision integers), float
  , complex , bytes , bytearray , str . Standard types: Decimal , slice , datetime
  , timedelta , timezone , date , time Containers: tuple , list , classes inherited
  from: AbstractSet ( frozenset ), MutableSet ( set ), Mapping and MutableMapping
  ( dict ). Pickable classes instances: custom classes including dataclass Allows
  mutable containers (lists, sets, mappings) to save basic types ( None , bool , 64
  bit int , float ) internally, optimizing memory use and speed. NumPy and Torch Support:
  Supports numpy arrays by creating shared bytes objects coupled with independent
  arrays. Supports torch tensors by coupling them with shared numpy arrays. Custom
  Class Support: Projects pickable custom classes instances (including dataclasses
  ) onto shared dictionaries in shared memory. Modifies the class instance to override
  attribute access methods, managing data fields within the shared dictionary. supports
  classes with or without __dict__ attr supports classes with or without __slots__
  attr Asyncio Compatibility: Provides a wrapper module for async-await functionality,
  integrating seamlessly with asyncio. Ensures asynchronous operations work smoothly
  with the package''s lock-free approach. Main principles only one process has access
  to the shared memory at the same time working cycle: work on your tasks acquire
  access to shared memory work with shared memory as fast as possible (read and/or
  update data structures in shared memory) release access to shared memory continue
  your work on other tasks do not forget to manually destroy your shared objects when
  they are not needed already feel free to not destroy your shared object if you need
  it for a whole run and/or do not care about the shared memory waste data will not
  be preserved between Creator''s sessions. Shared memory will be wiped just before
  Creator finished its work with a shared memory instance (Consumer''s session will
  be finished already at this point) Examples An async examples (with asyncio): sender.py
  receiver.py shared_objects__types.py Receiver.py performance measurements CPU: i5-3570@3.40GHz
  (Ivy Bridge) RAM: 32 GBytes, DDR3, dual channel, 655 MHz OS: Ubuntu 20.04.6 LTS
  under WSL2. Windows 10 async with ashared_memory_context_manager.if_has_messages()
  as shared_memory: # Taking a message with an object from the queue. sso: SomeSharedObject
  = shared_memory.value.take_message()  # 5_833 iterations/seconds # We create local
  variables once in order to access them many times in the future, ensuring high performance.
  # Applying a principle that is widely recommended for improving Python code. company_metrics:
  List = sso.company_info.company_metrics  # 12_479 iterations/seconds some_employee:
  Employee = sso.company_info.some_employee  # 10_568 iterations/seconds data_dict:
  Dict = sso.data_dict  # 16_362 iterations/seconds numpy_ndarray: np.ndarray = data_dict[''key3'']  #
  26_223 iterations/seconds # Optimal work with shared data (through local variables):
  async with ashared_memory_context_manager as shared_memory: # List k = company_metrics[CompanyMetrics.avg_salary]  #
  1_535_267 iterations/seconds k = company_metrics[CompanyMetrics.employees]  # 1_498_278
  iterations/seconds k = company_metrics[CompanyMetrics.in_a_good_state]  # 1_154_454
  iterations/seconds k = company_metrics[CompanyMetrics.websites]  # 380_258 iterations/seconds
  company_metrics[CompanyMetrics.annual_income] = 2_000_000.0  # 1_380_983 iterations/seconds
  company_metrics[CompanyMetrics.employees] = 20  # 1_352_799 iterations/seconds company_metrics[CompanyMetrics.avg_salary]
  = 5_000.0  # 1_300_966 iterations/seconds company_metrics[CompanyMetrics.in_a_good_state]
  = None  # 1_224_573 iterations/seconds company_metrics[CompanyMetrics.in_a_good_state]
  = False  # 1_213_175 iterations/seconds company_metrics[CompanyMetrics.avg_salary]
  += 1.1  # 299_415 iterations/seconds company_metrics[CompanyMetrics.employees] +=
  1  # 247_476 iterations/seconds company_metrics[CompanyMetrics.emails] = tuple()  #
  55_335 iterations/seconds (memory allocation performance is planned to be improved)
  company_metrics[CompanyMetrics.emails] = (''sails@company.com'',)  # 30_314 iterations/seconds
  (memory allocation performance is planned to be improved) company_metrics[CompanyMetrics.emails]
  = (''sails@company.com'', ''support@company.com'')  # 20_860 iterations/seconds
  (memory allocation performance is planned to be improved) company_metrics[CompanyMetrics.websites]
  = [''http://company.com'', ''http://company.org'']  # 10_465 iterations/seconds
  (memory allocation performance is planned to be improved) # Method call on a shared
  object that changes a property through the method some_employee.increase_years_of_employment()  #
  80548 iterations/seconds # Object properties k = sso.int_value  # 850_098 iterations/seconds
  k = sso.str_value  # 228_966 iterations/seconds sso.int_value = 200  # 207_480 iterations/seconds
  sso.int_value += 1  # 152_263 iterations/seconds sso.str_value = ''Hello. ''  #
  52_390 iterations/seconds (memory allocation performance is planned to be improved)
  sso.str_value += ''!''  # 35_823 iterations/seconds (memory allocation performance
  is planned to be improved) # Numpy.ndarray numpy_ndarray += 10  # 403_646 iterations/seconds
  numpy_ndarray -= 15  # 402_107 iterations/seconds # Dict k = data_dict[''key1'']  #
  87_558 iterations/seconds k = data_dict[(''key'', 2)]  # 49_338 iterations/seconds
  data_dict[''key1''] = 200  # 86_744 iterations/seconds data_dict[''key1''] += 3  #
  41_409 iterations/seconds data_dict[''key1''] *= 1  # 40_927 iterations/seconds
  data_dict[(''key'', 2)] = ''value2''  # 31_460 iterations/seconds (memory allocation
  performance is planned to be improved) data_dict[(''key'', 2)] = data_dict[(''key'',
  2)] + ''d''  # 18_972 iterations/seconds (memory allocation performance is planned
  to be improved) data_dict[(''key'', 2)] = ''value2''  # 10_941 iterations/seconds
  (memory allocation performance is planned to be improved) data_dict[(''key'', 2)]
  += ''d''  # 16_568 iterations/seconds (memory allocation performance is planned
  to be improved) # An example of non-optimal work with shared data (without using
  a local variables): async with ashared_memory_context_manager as shared_memory:
  # An example of a non-optimal method call (without using a local variable) that
  changes a property through the method sso.company_info.some_employee.increase_years_of_employment()  #
  9_418 iterations/seconds # An example of non-optimal work with object properties
  (without using local variables) k = sso.company_info.income  # 20_445 iterations/seconds
  sso.company_info.income = 3_000_000.0  # 13_899 iterations/seconds sso.company_info.income
  *= 1.1  # 17_272 iterations/seconds sso.company_info.income += 500_000.0  # 18_376
  iterations/seconds # Example of non-optimal usage of numpy.ndarray without a proper
  local variable data_dict[''key3''] += 10  # 6_319 iterations/seconds # Notify the
  sender about the completion of work on the shared object async with ashared_memory_context_manager
  as shared_memory: sso.some_processing_stage_control = True  # 298_968 iterations/seconds
  Throughput Benchmarks CPU: i5-3570@3.40GHz (Ivy Bridge) RAM: 32 GBytes, DDR3, dual
  channel, 655 MHz OS: Ubuntu 20.04.6 LTS under WSL2. Windows 10 Refference results
  (sysbench) sysbench memory --memory-oper=write run 5499.28 MiB/sec Benchmarks results
  table GiB/s Approach sync/async Throughput GiB/s InterProcessPyObjects (sync) sync
  3.770 InterProcessPyObjects + uvloop async 3.222 InterProcessPyObjects + asyncio
  async 3.079 multiprocessing.shared_memory * sync 2.685 uvloop.UnixDomainSockets
  async 0.966 asyncio + cengal.Streams async 0.942 uvloop.Streams async 0.922 asyncio.Streams
  async 0.784 asyncio.UnixDomainSockets async 0.708 multiprocessing.Queue sync 0.669
  multiprocessing.Pipe sync 0.469 * multiprocessing.shared_memory.py - simple implementation.
  This is a simple implementation because it uses a similar approach to the one used
  in uvloop.* , asyncio.* , multiprocessing.Queue , and multiprocessing.Pipe benchmarking
  scripts. Similar implementations are expected to be used by the majority of projects.
  Todo Connect more than two processes Use third-party fast hashing implementations
  instead of or in addition to built in hash() call Continuous performance improvements
  Conclusion This Python package provides a robust solution for inter-process communication,
  supporting a variety of Python data structures, types, and third-party libraries.
  Its lock-free synchronization and asyncio compatibility make it an ideal choice
  for high-performance, concurrent execution. Based on Cengal This is a stand-alone
  package for a specific Cengal module. Package is designed to offer users the ability
  to install specific Cengal functionality without the burden of the library''s full
  set of dependencies. The core of this approach lies in our ''cengal-light'' package,
  which houses both Python and compiled Cengal modules. The ''cengal'' package itself
  serves as a lightweight shell, devoid of its own modules, but dependent on ''cengal-light[full]''
  for a complete Cengal library installation with all required dependencies. An equivalent
  import: from cengal.hardware.memory.shared_memory import * from cengal.parallel_execution.asyncio.ashared_memory_manager
  import * Cengal library can be installed by: pip install cengal https://github.com/FI-Mihej/Cengal
  https://pypi.org/project/cengal/ Projects using Cengal CengalPolyBuild - A Comprehensive
  and Hackable Build System for Multilingual Python Packages: Cython (including automatic
  conversion from Python to Cython), C/C++, Objective-C, Go, and Nim, with ongoing
  expansions to include additional languages. (Planned to be released soon) cengal_app_dir_path_finder
  - A Python module offering a unified API for easy retrieval of OS-specific application
  directories, enhancing data management across Windows, Linux, and macOS cengal_cpu_info
  - Extended, cached CPU info with consistent output format. cengal_memory_barriers
  - Fast cross-platform memory barriers for Python. flet_async - wrapper which makes
  Flet async and brings booth Cengal.coroutines and asyncio to Flet (Flutter based
  UI) justpy_containers - wrapper around JustPy in order to bring more security and
  more production-needed features to JustPy (VueJS based UI) Bensbach - decompiler
  from Unreal Engine 3 bytecode to a Lisp-like script and compiler back to Unreal
  Engine 3 bytecode. Made for a game modding purposes Realistic-Damage-Model-mod-for-Long-War
  - Mod for both the original XCOM:EW and the mod Long War. Was made with a Bensbach,
  which was made with Cengal SmartCATaloguer.com - TagDB based catalog of images (tags),
  music albums (genre tags) and apps (categories) License Licensed under the Apache
  License, Version 2.0.'
Title: 'InterProcessPyObjects: Fast IPC for Sharing and Modifying Objects Across Processes'
---
Author: u/ARandomBoiIsMe
Content: 'Source code What My Project Does: It acts as a wrapper for the AzuraCast
  API, providing custom functions and classes for more straightforward use of the
  API in python projects. Target Audience: Python users who are interested in programmatically
  interacting with online radios hosted on AzuraCast . Comparison: The idea of API
  Wrappers is not new. However, I noticed that the only existing wrapper for this
  API is written in PHP , which I am not experienced with. I created this project
  so I, and other python programmers by extension, could have an easier time working
  with the API. This is my first "major" programming project, so thoughts and feedback
  are welcome and greatly appreciated. PS: Shoutout to PRAW for "inspiring" basically
  everything about the project''s structure and functionality.'
Title: 'AzuracastPy: An Unofficial Python Wrapper for the Azuracast API.'
---
Author: u/RevolutionaryPen4661
Content: 'PYPI (From the README, Released Last Year, Edited by Grammarly) Github pip
  install diskcache The cloud-based computing of 2024 puts a premium on memory. Gigabytes
  of space are left on disks as processes vie for memory. Memcached (and sometimes
  Redis) is used as a cache among these processes. Wouldn‚Äôt it be nice to leverage
  empty disk space for caching? Django is Python‚Äôs most popular web framework and
  has several caching backends. Unfortunately, the file-based cache in Django is essentially
  broken. The culling method is random and large caches repeatedly scan a cache directory
  which slows linearly with growth. Can you allow it to take sixty milliseconds to
  store a key in a cache with a thousand items? Is it that fast? In [1]: import pylibmc
  In [2]: client = pylibmc.Client([''127.0.0.1''], binary=True) In [3]: client[b''key'']
  = b''value'' In [4]: %timeit client[b''key''] 10000 loops, best of 3: 25.4 ¬µs per
  loop In [5]: import diskcache as dc In [6]: cache = dc.Cache(''tmp'') In [7]: cache[b''key'']
  = b''value'' In [8]: %timeit cache[b''key''] 100000 loops, best of 3: 11.8 ¬µs per
  loop'
Title: 'diskcache: This key-value store library is faster than Redis and Memcached
  üòÆ (built by Grant Jenks)'
---
Author: u/Dry_Raspberry4514
Content: I am using quart framework ( https://quart.palletsprojects.com ) for a number
  of microservices in a SaaS application. However, I hardly hear anything about this
  framework on any social media platform which seems to be dominated by FastAPI. Also
  I'm unable to find which all projects/companies are using this framework. All this
  is leading to anxiety around the future of this project. Are there any well known
  projects / companies which are using this framework for microservices?
Title: Who is using quart framework for microservices?
---
Author: u/olive_oil_for_you
Content: 'I made this visualisation with this code . I have three questions: Is Plotly
  supposed to be this cumbersome to tweak? Would other libraries require the same
  amount of code to add the details I did? Can my code be reduced in size? Maybe it''s
  me who is complicating things with Plotly and there are easier ways to do what I
  am doing. Any R enthusiast who can tell me how much shorter this code would look
  like with ggplot2? I asked ChatGPT but the result was garbage. Bonus question: This
  took me an entire morning. Is it normal to be "that slow" to plot a simple figure?'
Title: Why is Plotly so cumbersome to tweak?
---
Author: u/Financial_Muffin396
Content: 'Hi all, I initially started this adventure by trying to automate bug fixes
  with the help of LLMs. However, I received feedback saying the fixes aren''t always
  correct, leading to the question: why bother reviewing PRs that might add more issues?
  (It''s really hard for LLMs to say "I don''t know"). So, I decided to focus on reliability
  perfecting unit tests. The source code is available at: https://github.com/CaptureFlow/captureflow-py
  What My Project Does: It incorporates a tracer client-side Python library and a
  backend that accumulates such traces and is capable of proposing code improvements
  and generating tests for your repository. It traverses the execution graph, extracts
  relevant parts, enriches them with implementation data from the GitHub API, and
  then generates tests with the help of GPT4. Target Audience: Python users interested
  in discovering what LLMs can achieve when given detailed runtime information from
  your app. Generally, this approach somewhat reverses the concept of TDD, but in
  my day job I deal with many legacy apps that have poor test coverage, and having
  it really helps. I suspect I‚Äôm not alone in finding value in this. Comparison: I
  think idea of using LLMs to generate tests is not new, but generating them actually
  based on application''s performance is inspired by Jane Street''s article on how
  they automated test boilerplate creation and recent Facebook''s research paper .
  Disclaimer: More work needs to be done to make it work for any Python app and not
  just a subset of FastAPI servers. I''m curious if you folks would find it useful.
  Example: you can check this PR for reference. feedback / stars / contributions are
  welcome.'
Title: I connected LLM to Python runtime and generated unit-tests (OpenSource)
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!'
---
Author: u/globalwarming_isreal
Content: 'Hello all, This is probably my first post here. I usuallly lurk around here
  and Django subreddits. I''ve been brewing up an idea and I need your input before
  I take the plunge! Picture this: a website like FreeCodeCamp but for python and
  related technologies, a learning oasis where anyone can kickstart their journey
  from Python newbie to job-ready pro, and it''s all free! But here''s the thing,
  I want this to be our platform, crafted with your needs and dreams in mind. So,
  before I start, I need to know: would this be something that gets you excited? Imagine
  quizzes helping you find your starting point, interactive challenges that keep you
  in the zone, and a supportive community to cheer you on every step of the way. Plus,
  videos, written tutorials, and a progress tracker to keep you motivated! What would
  make you go, "Wow, I need this in my life!"? What features would you love to see?
  Any suggestions or wild ideas ? My aim is to give back to the community by assisting
  new learners in navigating common pitfalls when they start their Python journey'
Title: 'Seeking Your Input: Let''s Co-Create FreeCodeCamp for python together'
---
Author: u/jgloewen
Content: 'With the current global deluge of data and information, there has never
  been a more important to visualize your data in a clear and simple manner. Python
  is a terrific tool to help us do this. The key to this lies in choosing the the
  right data visualization techniques to tell the most interesting and relevant story.
  Three useful visuals are: small multiples heat maps stacked area charts In this
  tutorial, using pandas, seaborn, and matplotlib.pyplot, we create the Python code
  for each data visual Link to free Tutorial'
Title: Tutorial on Creating Useful Data Visuals with Python seaborn and matplotlib
  libraries
---
Author: u/Shawn-Yang25
Content: 'In rpc/serialization systems, we often need to send namespace/path/filename/fieldName/packageName/moduleName/className/enumValue
  string between processes. Those strings are mostly ascii strings. In order to transfer
  between processes, we encode such strings using utf-8 encodings. Such encoding will
  take one byte for every char, which is not space efficient actually. If we take
  a deeper look, we will found that most chars are lowercase chars, ., $ and _, which
  can be expressed in a much smaller range 0~32. But one byte can represent range
  0~255, the significant bits are wasted, and this cost is not ignorable. In a dynamic
  serialization framework, such meta will take considerable cost compared to actual
  data. So we proposed a new string encoding which we called meta string encoding
  in Fury. It will encode most chars using 5 bits instead of 8 bits in utf-8 encoding,
  which can bring 37.5% space cost savings compared to utf-8 encoding. For string
  can''t be represented by 5 bits, we also proposed encoding using 6 bits which can
  bring 25% space cost savings More details can be found in: https://fury.apache.org/blog/fury_meta_string_37_5_percent_space_efficient_encoding_than_utf8
  and https://github.com/apache/incubator-fury/blob/main/docs/specification/xlang_serialization_spec.md#meta-string'
Title: 'Rethinking String Encoding: a 37.5% space efficient string encoding than UTF-8
  in Apache Fury'
---
Author: u/RJW-20
Content: 'I''ve made my first bit of useful software and I wanted to share it here.
  I''d love some feedback (and it would be amazing to hear if someone has used it!)
  What My Project Does: Using the third party requests package, the script interacts
  with the Spotify web API to request all albums from the given Artist, then all the
  tracks from all of those albums. It then goes through the list to remove any duplicates
  and also tries to remove any unwanted versions (only done by examining the name
  of the track, since Spotify does not attribute a version type to its tracks). Once
  that''s done a playlist is then created on your Spotify account with the name of
  the Artist and all the tracks are posted there in chronological (essentially per
  album) order. Target Audience: Anyone who struggles like me when they find a new
  Artist and they want to listen to every conceivable song from them! Link to GitHub:
  https://github.com/RJW20/spotify-artist-to-playlist'
Title: Python script to convert Spotify Artists to Playlists
---
Author: u/BullCityPicker
Content: I'm doing most of my work behind a government firewall, and I'm having trouble
  connecting to certain sites.   I can do the usual "pip" installs just fine, but
  I'm talking about packages that need to download data to do their job.  An example
  is the NLTK (Natural Language Toolkit) package, which downloads dictionaries, lookup
  tables for sentiment analysis, and so on.  I know what sites to open up for that
  particular problem (pastebin.com and nltk.org), but I wonder if anybody's made a
  list of such sites for different packages. I can ask for the two sites I know about
  to be opened up, but I'd like to have a more comprehensive list so I don't have
  to go through the red tape multiple times.
Title: List of Sites that Packages Need to Connect to?
---
Author: u/AutoModerator
Content: Daily Thread
Title: 'Wednesday Daily Thread: Beginner questions'
---
Author: u/zurtex
Content: 'I''d like to call attention to pip 24.1 beta asit is unusual for the pip
  team to release betas: https://pip.pypa.io/en/latest/news/#b1-2024-05-06 https://pypi.org/project/pip/24.1b1/
  You can install with: python -m pip install pip==24.1b1 In particular they have
  upgraded their vendored version of packaging from 21.3 to 24.0, this was a big effort
  and fixed many bugs , included significant performance improvements, and will allow
  pip to support free threaded packages . However, it also means legacy versions and
  specifiers are no longer compatible with pip. Because this was such a big land the
  pip maintainers have released a beta in the hopes people will test their workflows,
  and if something fails in an expected way report their steps as best as possible
  back to pip: https://github.com/pypa/pip/issues I''ve been testing, and contributing
  a little bit, to the improved performance in this release, it is most noticeable
  on large dependency trees or long backtracking. For example, a dry run of "apache-airflow[all]"
  using cached packages on my machine goes from ~418 seconds to ~185 seconds.'
Title: Pip 24.1 beta released, and it's a big one
---
Author: u/jpjacobpadilla
Content: Do you understand how asyncio works behind the scenes? Read this article
  and see how you can use Python generators to create your own version of asyncio,
  and then use the __await__ dunder method to use the async/await keywords to come
  full circle! https://jacobpadilla.com/articles/recreating-asyncio
Title: 'How Python Asyncio Works: Recreating it from Scratch'
