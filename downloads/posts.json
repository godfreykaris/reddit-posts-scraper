[
{"Title": "Sunday Daily Thread: What's everyone working on this week?", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "Saturday Daily Thread: Resource Request and Sharing! Daily Thread", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "My library VidGear `v0.3.3` - brings libcamera API Support to python.", "Author": "u/abhi_uno", "Content": "Hello Python developers! I'm excited to announce the release of VidGear v0.3.3 , which brings official support for the libcamera backend in its PiGear API ! This update enhances the capabilities of Raspberry Pi Camera Modules and provides limited USB camera support. More about PiGear: PiGear is a specialized API optimized for Raspberry Pi üçá Boards, offering comprehensive support for camera modules (e.g., OmniVision OV5647 Camera Module, Sony IMX219 Camera Module) and limited compatibility for USB cameras. PiGear implements a seamless and robust wrapper around the Picamera2 Python library, simplifying integration with minimal code changes and ensuring a smooth transition for developers already familiar with the Picamera2 API. PiGear leverages the libcamera API under the hood with multi-threading, providing high-performance üî•, enhanced control, and functionality for Raspberry Pi camera modules. PiGear handles common configuration parameters and non-standard settings for various camera types, simplifying the integration process. PiGear currently supports PiCamera2 API parameters such as sensor, controls, transform, and format, with internal type and sanity checks for robust performance. While primarily focused on Raspberry Pi camera modules, PiGear also provides basic functionality for USB webcams (only with Picamera2 API), along with the ability to accurately differentiate between USB and Raspberry Pi cameras using metadata. PiGear seamlessly switches to the legacy picamera library if the Picamera2 library is unavailable, ensuring seamless backward compatibility. PiGear also provides a flexible multi-threaded framework around the complete picamera API, allowing developers to effortlessly exploit a wide range of parameters, such as brightness, saturation, sensor_mode, iso, exposure, and more. Furthermore, PiGear supports the use of multiple camera modules, including those found on Raspberry Pi Compute Module IO boards and USB cameras (only with Picamera2 API). We're eager to see the innovative projects you'll create with PiGear! For more details and to get started, check out our GitHub repository . Happy coding! Feel free to ask any questions or share your feedback below. Let's discuss and innovate together! üöÄ"},
{"Title": "discover-plugins - track which plugins are installed into your python environment", "Author": "u/fesch2", "Content": "What my project does discover-plugins is a simple CLI tool that lets you list and filter plugins entrypoints installed into a python environment. I recently had to track down a bug that I ultimately resulted from a plugin I had installed into my environment.  To my surprise, there was no easy way to list which kind of plugins were installed, so I decided to build my own tool. Target Audience discover-plugins is intended as a debugging tool for those times when you are not quite sure which plugins are currently part of your python environment. Installation pipx install discover-plugins Usage Find all installed plugins related to pytest (the relevant group name is pytest11 ): discover-plugins --group pytest11 The tool defaults to use the first python interpreter on your path, you can optionally specify which interpreter to use with the --interpreter flag. The output will list all entrypoints belonging to the pytest11 group. For example, if you had installed a single pytest plugin ( pytest-aws-apigateway ) the output would look like this: { \"pytest11\": [ { \"name\": \"pytest_httpx\", \"group\": \"pytest11\", \"value\": \"pytest_httpx\" }, { \"name\": \"anyio\", \"group\": \"pytest11\", \"value\": \"anyio.pytest_plugin\" }, { \"name\": \"pytest-aws-apigateway\", \"group\": \"pytest11\", \"value\": \"pytest_aws_apigateway.plugin\" } ] } Links Link to GitHub: https://github.com/felixscherz/discover-plugins PyPI: https://pypi.org/project/discover-plugins/ Let me know if the tool helped you out! Cheers!"},
{"Title": "Is anyone here looking for a developer to contribute to your personal projects?", "Author": "u/homelander_30", "Content": "I guess the title explains it all, I'm looking for some personal projects to work or contribute on and would be really helpful if anyone is looking for a dev. I did look upon some open-source projects but they were too advanced and out of scope for me so I just wanna start small and learn."},
{"Title": "cool tool made with python", "Author": "u/SuccessfulLiving757", "Content": "I made a cool tool with python named Cookie Monster (not the one from sesmene street). It fetches cookies from a website and it is kinda broken... you can install it from https://sojoyork.github.io ! And yes it is one of my best python projects! I hope you like it.! And the GitHub repository is https://github.com/sojoyork/sojoyork.github.io ! (also am new to reddit)"},
{"Title": "I made a little Python quiz for interns and new Python developers at my company", "Author": "u/Penny-loafers", "Content": "I put this quiz together to help create conversation for interns and new python developers at my company. Its based on the content from one of my favourite books ( Fluent Python ). I hope you enjoy it! Quiz"},
{"Title": "Running Python in Web Browsers", "Author": "u/pdfisk", "Content": "Python is one of the world's most popular programming languages and the web is the most ubiquitous application platform. There are several projects which aim to enable Python to run in web browsers. Brython is an implementation of Python 3 written in JavaScript. Skulpt is an implementation of Python 2/3 written in JavaScript. PyScript is an implementation of Python 3 written in WebAssembly. Transcrypt is a Python to JavaScript compiler - unfortunately, the project seems to have been abandoned. Batavia is a Python virtual machine written in JavaScript - unfortunately, the project seems to have been abandoned. Finally, I have created VistaPython which is also intended to run Python 3 in web browsers but by using a bytecode interpreter written in JavaScript. Each design has strengths and weaknesses: Both Brython and Skulpt use hand-written Python parsers which are difficult to maintain. VistaPython uses a parser generator, Antlr , to automatically generate the JavaScript code for the parser. The parser can be updated to match the latest Python version by simply running a script. Also, both Brython and Skulpt generate JavaScript code which is then evaluated. In VistaPython, the compiler produces a \"code object\" which is then executed using the bytecode interpreter. The first approach will result in faster code whereas the second approach can be more flexible for code stepping, etc. PyScript is based on Pyodide which is a port of CPython to WebAssembly. PyScript can be upgraded the latest Python release by recompiling the latest CPython sources. Its main disadvantage is that it is very heavy to load and seems to run poorly on mobile devices. In VistaPython, the load profiles are: vm.js (Python virtual machine) 761kb Python parser 368 kb Mobile client GUI 2.4 Mb Desktop client GUI 2.9 Mb Compiled applications can be run using only the Python virtual machine (761kb). The design goal of VistaPython is to be able to load compiled applications from a database and run them quickly on any web device."},
{"Title": "A simple website scraper script", "Author": "u/SAV_NC", "Content": "Web Scraper Script What My Project Does This project scrapes websites to extract and display titles and links of articles. It processes multiple websites in parallel, fetching and parsing content to provide a consolidated list of articles with their full URLs. Target Audience Home users, researchers, and web enthusiasts who need to gather information from multiple websites quickly and efficiently. Features Parallel Processing : Uses ThreadPoolExecutor to fetch multiple websites concurrently, speeding up the scraping process. Error Handling and Logging : Provides detailed logging for debugging and retry mechanisms for robustness. Full URL Extraction : Ensures that all extracted links are complete URLs, enhancing usability. Customizable Headers : Allows customization of HTTP headers to mimic different browsers. Script Overview The script consists of several key components: Fetching URLs The script fetches content from the given URLs using the requests library. It includes retry logic with exponential backoff to handle transient errors. Parsing Content The script uses BeautifulSoup to parse the fetched HTML content and extract article titles and links. It ensures that the links are converted to full URLs using urljoin . Concurrent Execution The script employs ThreadPoolExecutor to fetch and parse content from multiple websites in parallel, improving efficiency. Access the Script You can access the script on GitHub here: Web Scraper Script on GitHub How to Use Install Dependencies : Ensure you have requests and beautifulsoup4 installed: pip install requests beautifulsoup4 Run the Script : Provide the URLs of the websites you want to scrape as arguments: python3 web-scraper.py https://yahoo.com https://sports.yahoo.com Conclusion This web scraper script is designed to be robust, efficient, and easy to use. It handles multiple websites in parallel, provides detailed logging, and ensures full URL extraction for all links. Ideal for users who need to quickly gather and consolidate information from various sources."},
{"Title": "Open source Python projects with good software design that is worth studying", "Author": "u/bolt_runner", "Content": "What are some software projects written in python that are well-structured and use good code design practices that are worth spending time to study?"},
{"Title": "Log Monitoring with Kafka ETL using Python via Docker and Pathway", "Author": "u/muditjps", "Content": "Hi r/Python , This project is for a Streaming ETL problem statement for Fraud-detection/Log Monitoring use-case. Here's a link to the blog explainer: https://pathway.com/developers/templates/kafka-etl GitHub Repo link: https://github.com/pathwaycom/pathway/tree/main/examples/projects/kafka-ETL What the Project Does Let's say we're monitoring logs from servers in New York and Paris. The logs have different time zones so you need to unify these different time zones into a single format to maintain data integrity. Now, Kafka is a popular ETL tool but it's usable only in Java/Scala. Target Audience This is mostly for Python developers/data scientists/ML engineers and people who work on Fraud Detection or ETL. Comparison This project leverages Pathway, a Python ETL framework powered by an underlying Rust engine that surpasses Flink/Kafka in benchmarks. With this Pythonic framework we: Extract data streams from Kafka using built-in Kafka input connectors. Convert times with varying time zones into unified timestamps the datetime module. Load the final data stream back into Kafka. The entire script is available as an app template on the repo, which can be run via Docker in minutes. Open to your feedback/questions!"},
{"Title": "localslackirc - bridge slack and IRC", "Author": "u/sonobanana33", "Content": "I made a minor bugfix release of localslackirc https://codeberg.org/ltworf/localslackirc It can be installed via apt or ran from sources. No pypi package, sorry. What My Project Does After configuring it with a token from slack, it creates a local IRC server that bridges with slack. It supports threads, sending files. It doesn't support reactions. It supports muting @here notifications from certain users or certain channels. It allows to silently leave a channel, but rejoins it if the user is personally mentioned there. Target Audience Mostly people who have to use slack for work and would prefer IRC. Comparison I am not aware of a project doing the same thing. I know weechat has a slack plugin, but that's slightly different. I don't use weechat and I wanted to keep using my IRC client. out of date link to avoid the post from being removed: https://github.com/ltworf/localslackirc"},
{"Title": "Python community in Amsterdam, The Netherlands", "Author": "u/FuturesBrightDavid", "Content": "Hi, I'm trying to find a Python community in Amsterdam in The Netherlands.  There used to be an active MeetUp group and Slack , but there has been little to no activity on either in a long, long time. Pythonistas in my city, what social / networking events or activities are there around here? Additionally, would anyone be interested in reviving the Python MeetUps in Amsterdam?"},
{"Title": "Eventum: Flexible event generator", "Author": "u/rnv812", "Content": "Hi, recently I created event generator in Python called Eventum . Here is a link to website: https://eventum-generatives.github.io/Website/ And the main repo: https://github.com/Eventum-Generatives/EventumCore What My Project Does It can be used in task like: Generation of datasets Simulation of processes in real time Filling different systems with demo data Testing on arbitrary data and stress testing Target Audience This generating tool is mostly for developers and people who work with data. It is also very near to ELK stack, OpenSearch and SIEM systems like Splunk . But you can use it as you want :) Comparison There is a project Eventgen developed by Splunk, but Eventum has next advantages over it: More rich events scheduling Extended functionality in event templates More parametrizable configurations Has content developing tools (UI for visualization time distributions and rendering templates)"},
{"Title": "Robogram - Minimal Wrapper for Telegram Bot API in Python", "Author": "u/RitvikTheGod", "Content": "Guys, I recently released my first (in a while) open-source project wrapper on Telegram Bot API . I call it robogram and when I was developing in Python, I had a use case to send notifications from Raspberry Pi to my iPhone via Telegram . After searching online, I found no minimalist wrapper in Python 3+ to send messages via Bot API. So, I decided to create one :-) What My Project Does Minimal Wrapper around the Telegram Bot API. It's only dependency is requests in Python which is ubiquitous. It allows to retrieve info on Bot, or to send messages to users via personal chat, channel, or group. Target Audience Toy project I just came up with, after realizing no solution out there was best fit for me. But I have deployed this on production for personal project, and it's for sure production-ready. Target audience here would be other developers who are on Telegram and looking to leverage Bot API to facilitate the sending of messages or notifications to an audience on Telegram. Comparison Some packages out there are only async support, or only work on Python 2 (actually I found one with some popularity that doesn't work in Python 3+ at all), or are dependency- or code- heavy and can introduce code bloat, especially to small, personal projects. As someone working on a personal project myself, I wanted a lightweight solution that only used minimal dependencies such as requests for making API requests. So, since I could not find one out there in wild, I decided to create my own! -- Interested to get your thoughts, if anyone likes it I will be glad to feedback. https://github.com/rnag/robogram"},
{"Title": "Introducing Lambda Forge: Simplifying AWS Lambda Deployment and Development!", "Author": "u/No_Coffee_9879", "Content": "Hey everyone, I just wanted to share a project I've been working on called Lambda Forge . It's a tool designed to simplify the deployment and management of AWS Lambda functions. If you're like me and spend a lot of time working with serverless architecture, you might find it pretty useful. What My Project Does Lambda Forge helps you deploy and manage AWS Lambda functions with ease. One of its standout features is the WebSocket connection for hot reloading of local code. It uses MQTT over Websockets to proxy requests to a local server, making development seamless. No more redeploying code just to see if your changes work! Target Audience This project is meant for developers who work with AWS Lambda in both production and development environments. Whether you're a seasoned backend engineer or just getting started with serverless, Lambda Forge can help streamline your workflow. Comparison Compared to other deployment tools, Lambda Forge focuses on enhancing the development experience with hot reloading capabilities. Many existing tools require a full redeployment for changes to take effect, which can be time-consuming. Lambda Forge's WebSocket integration saves time by allowing you to see changes in real-time without redeployment. If you're interested, you can check out the documentation here: Lambda Forge Docs And if you want to dive into the code or contribute, here's the GitHub repo: Lambda Forge on GitHub I‚Äôd love to hear your thoughts and feedback."},
{"Title": "Friday Daily Thread: r/Python Meta and Free-Talk Fridays", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "Mirascope-Python's Alternative To Langchain", "Author": "u/Active-Fuel-49", "Content": "Mirascope is a Python library that lets you access a range of Large Language Models, but in a more straightforward and Pythonic way. https://www.i-programmer.info/news/90-tools/17275-mirascope-pythons-alternative-to-langchain.html"},
{"Title": "Python on Cloud GPUs", "Author": "u/jrbourbeau", "Content": "Hi All, I wanted to try to speed up some Python code with a GPU recently and was pretty shocked at how difficult it is to properly set up and configure things. I have lots of experience in the PyData space, but am definitely not a cloud devops expert. So some colleagues and I wrote a decorator that automatically sets up a cloud VM, runs the decorated function, and returns the function‚Äôs result back locally to my laptop. Here‚Äôs an example that trains a PyTorch model on an NVIDIA A10 GPU on AWS. The Coiled Function API is nice because I didn‚Äôt have to build any Docker images, muck around in the AWS console, or do anything special to set up a cloud GPU. That said, there are definitely tradeoffs here. We optimized for privacy and no standing costs, so it takes ~1-2 minutes to fully spin up VMs (no warm pool of VMs waiting). We also only run on AWS/GCP/Azure so this doesn‚Äôt help with on-prem workloads. I‚Äôm definitely biased as I work at Coiled, but think this is a simple way to run Python on cloud hardware (especially for folks without a lot of cloud experience). I‚Äôm curious to hear from folks here. Do you have a favorite way to run Python code on the cloud? What do you like about your current setup? For example, ergonomics, performance, something else?"},
{"Title": "Web scraper for protein prices", "Author": "u/Knockoutpie1", "Content": "Hey everyone, looking for some input. For work I‚Äôve worked on web scraping for prices to see if my components are adequately priced on the internet compared to competitors. I can use this for protein prices as a personal project. I have experience now with Beautiful Soup, Selenium, and Excel Power BI. What route should I go? Should I only pull pricing from Amazon? Or should I do Amazon and the manufacturer site to see which is better pricing? Ideas would be great. Should be a fun project. If I go with beautiful soup, there‚Äôs no UI and I can print all to terminal If I use selenium, I can use UC to pass anti-bot measures and also print to terminal, but it will open a browser window for each price scrape. If I use excel power BI, I‚Äôll just load data to a worksheet and pricing will update at the price of a button."},
{"Title": "Textual Serve - Serve TUIs in the browser", "Author": "u/willm", "Content": "Textual Serve ( https://github.com/Textualize/textual-serve ) is a project which serves TUIs (built with Textual) in the browser. This is self-hosted, so you don't need to rely on any external service."},
{"Title": "Python on ARM laptops", "Author": "u/Fun-Asparagus-837", "Content": "Hi there ! I'm thinking about buying an ARM windows laptop with the new Qualcomm chips. They will replace the x86 so I was wondering : Will There be a massive risk of non-compatibility of Python packages ? I guess they are made for x86 but I don't know if it's possible to work with them with an ARM based CPU. Edit : Had a great deal on the ideapad pro 5 gen 9 so I went for it. Glad to have these incredible specs and decided to rely on x86 chip for the moment, because I wanted to avoid all the early-adoption problems"},
{"Title": "Python Project Management Primer", "Author": "u/Martynoas", "Content": "This article explores how to manage Python project environments and dependencies, as well as how to structure projects effectively."},
{"Title": "Video Quality Ranker", "Author": "u/SAV_NC", "Content": "What my project does Ranks videos based on overall quality. Takes into account multiple metrics to determine what quality is the best. Target audience Home users / Video enthusiasts Comparison This project uses the following metrics to rank videos: Resolution : Higher resolution videos are preferred. Frame Rate : Videos with higher frame rates are ranked higher. Bitrate : Higher bitrate often indicates better quality. Codec : Some codecs provide better quality than others at the same bitrate. The script extracts these metrics using ffprobe from the FFmpeg suite and sorts the videos accordingly. Here's how the metrics are used: Resolution : The script first compares the resolution (width x height) of the videos. Higher resolutions are ranked higher. Frame Rate : If two videos have the same resolution, the one with the higher frame rate is ranked higher. Bitrate : For videos with the same resolution and frame rate, the bitrate is used to determine the quality. Codec : In case of a tie in all other metrics, the codec is considered to break the tie. Access the Script You can access the script on GitHub here"},
{"Title": "A JIT compiler for CPython", "Author": "u/lutipri", "Content": "Brandt Bucher talks on JIT compiler for Python at CPython Core Developer Sprint. Brandt is  a member of the Faster CPython project , which is working on making the reference implementation of the language faster via a variety of techniques. https://www.youtube.com/watch?v=HxSHIpEQRjs"},
{"Title": "Conway's game of life. can you find an optimization?", "Author": "u/Significant_Water_28", "Content": "little challenge for you, how fast can this be pushed in python? This function takes a numpy.ndarray / 2d numpy array, and returns the updated array. iv updated this function several times, this i the fastiest so far. numba jit dosn't like the double roll, and its faster than for loops in jit. def conways_game_of_life(board:numpy.ndarray): n_neighbour = sum(numpy.roll(numpy.roll(board, i, 0), j, 1) for i in (-1, 0, 1) for j in (-1, 0, 1) if (i != 0 or j != 0)) board[(n_neighbour<2) | (n_neighbour>3)] = 0 board[(n_neighbour==3)] = 1 return board"},
{"Title": "json3pdf : Batch OCR for high quality document archiving.", "Author": "u/DrumcanSmith", "Content": "What my project does Performs OCR on scanned Books using Microsoft Azure Document Intelligence read Target audience People who are unsatisfied with traditional OCR People who want to add clear text to the original PDF and not just extract the text. People who want to archive documents at best quality. Comparasion In my use case traditional OCR was near to useless. Tesseract was meh, Google API didn't process large files. Document Intelligence takes up to 500MB (although in practice a little less), and is possible to OCR 400-600 pages over books in batch by dividing and merging the source and results locally by only a few chunks. It doesn't provide the text in PDF form so that was my reason to start this project. Still in alpha and in separate modules and a lot of rigid coding, but it is working fine for my original task so thought maybe I'd showcase it. https://github.com/DesertDoggy/json3pdf"},
{"Title": "Thursday Daily Thread: Python Careers, Courses, and Furthering Education!", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "Experimental Python Wheels for Windows on ARM64", "Author": "u/Balance-", "Content": "For anyone on a (new) Windows on Arm system, I found this great repo with Arm64 Windows wheels: https://github.com/cgohlke/win_arm64-wheels Highlights 256 packages for Python 3.12 Built with numpy 2 if possible Scipy stack: numpy with OpenBLAS, scipy, matplotlib, Pandas, scikit-learn, scikit-image, numba, etc. GIS stack: GDAL, netCDF4, pyproj, Shapely, rasterio, basemap, Fiona, etc. Image IO: Imagecodecs, Pillow, OpenImageIO, OpenEXR, pylibCZIrw, etc. Noteworthy: Pytorch, Kivy, opencv_python_headless, pymol-open-source, pywin32"},
{"Title": "Parsing Python ASTs 20x faster with Rust", "Author": "u/the1024", "Content": "https://www.gauge.sh/blog/parsing-python-asts-20x-faster-with-rust"},
{"Title": "Trying to find this package", "Author": "u/CompositePrime", "Content": "I should have saved the post but maybe 4-6 months ago I was reading a post (I am pretty sure it was in r/Python ) where someone created a package that creates a visual for data contained within a list. For example, let‚Äôs say I have a data frame where one of the columns is named ‚Äúcolors‚Äù and each record contains a list of colors. One record might be [black,blue,yellow] another record might have [blue,yellow,black]. The visual had two parts where the top was a column chart to show the frequency of the list combinations and below the column chart was more of a table that showed each ‚Äúcolor‚Äù as one column and then across the row for each color and under the columns from the chart above was an indicator of sorts that would be greyed out of the color for that row was not in the corresponding columns list and highlighted another color of it was. Anyways this is probably a long shot but either the package or the name of this visual would be super helpful. Thanks python community!"},
{"Title": "Wednesday Daily Thread: Beginner questions", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "I am Nominating Myself for PSF Board of Directors", "Author": "u/tavallaie", "Content": "I am nominating myself for the PSF Board of Directors! üåü Check out my latest blog post to learn more about my journey, my commitment to the Python community, and my application for an OFAC license to expand educational activities in restricted areas. Read more at my blog"},
{"Title": "Scrapegraph AI Tutorial; Scrape Websites Easily With LLaMA AI", "Author": "u/INSERT_KEYWORD", "Content": "I'm going to show you how to get Scrapegraph AI up and running, how to set up a language model, how to process JSON, scrape websites, use different AI models, and even turning your data into audio. Sounds like a lot, but it's easier than you think, and I'll walk you through it step by step. https://www.scrapingbee.com/blog/scrapegraph-ai-tutorial-scrape-websites-easily-with-llama-ai/"},
{"Title": "What are the hardware requirements in a laptop to run Python + Future AI based projects?", "Author": "u/Madlynik", "Content": "I will buy a laptop for coding purposes but just started learning and practising Python using Pyecharm. What are the software requirements that lead to hardware specs a general Python coder must look into? Please suggest the hardware setup within a pocket friendly budget."},
{"Title": "Looking for a good WYZIWIG/visual editor to go with with Jinja + Weasyprint", "Author": "u/Benoss", "Content": "End goal is to produce PDF using external data and a template. Needs to support Jinja tags, conditionals and loops. Using https://github.com/Kozea/WeasyPrint and https://github.com/pallets/jinja as base stack (Open to other suggestions) I was thinking of building some base HTML templates but would be awesome if I could find a visual HTML editor that could produce code 100% compatible with Weasyprint so that end users can build templates by themselves or modify existing ones. Could be Wysiwyg based using https://editorjs.io or https://github.com/slab/quill or more advanced web builders like https://github.com/GrapesJS/grapesjs Anybody built something similar?"},
{"Title": "NumPy 2.0.0 is the first major release since 2006.", "Author": "u/commandlineluser", "Content": "NumPy 2.0.0 is the first major release since 2006. https://github.com/numpy/numpy/releases/tag/v2.0.0 https://numpy.org/devdocs/release/2.0.0-notes.html https://numpy.org/devdocs/numpy_2_0_migration_guide.html"},
{"Title": "Load Tests Python Task Queues", "Author": "u/tuple32", "Content": "What My Project Does While looking for task queues, I found that there are many options available in the Python ecosystem, making it really hard to choose the right one. To get a sense of how each library performs and to help make an informed decision, I conducted a load test on some of the most popular ones: Python-RQ, ARQ, Celery, Huey, and Dramatiq. Target Audience I hope my findings can help those who are also looking for a task queue solution in Python. Comparison Most articles out there seem to focus on comparing the features of these libraries but rarely discuss performance. While there could be a lot of improvements on my tests, I think it still provide some different insights into how each library handles heavy loads and concurrency. Links: You can read  my findings on my blog Check out the source code: on Github Thanks"},
{"Title": "Aurora: An extensible Python static site generator", "Author": "u/zerojames_", "Content": "What My Project Does Aurora is a fast, extensible Python static site generator. With Aurora, I can generate my personal website (~1,700 files, with multiple layers of jinja2 templates for each page) in < 4 seconds. Aurora generated 292,884 pages from a Hacker News post dataset in 2m:20s. Aurora supports incremental static regeneration, where pages can be regenerated in under 400ms, with hot reloading. I documented how this works on my blog . Target Audience I'm building Aurora to help me run my website, but it is built to be general so you can use it for your own projects. I would love feedback! I want this to be a tool for running static sites in production, at scale. Comparison Aurora is inspired by the folder structure of Jekyll, but is written in Python. It has a hooks API that lets you define custom Python functions that manipulate the state of a page. This allows you to implement custom behaviours in isolation of the engine itself. I use this to open link previews from a cache that I plan to use on my website, among other things."},
{"Title": "Suggestion: make ray.io a part of Python's std lib", "Author": "u/jmakov", "Content": "Imagine having the option to write code once and run on multiple cores or on the cluster as part of the std lib. I know there's a company (currently) behind it - Anyscale, also not sure what the license is but other than that, what's holding the Py community back?"},
{"Title": "Advise on choosing UI technology with Python", "Author": "u/green9cactus", "Content": "I am new to python and currently working on simple 3 layer web application - frontend - ? backend API to fetch data from DB - python DB - cloud This application has main intention to fetch data from DB, display graphs , table format data etc.  also perform some combination analysis of data and show on UI. Which less complex and stable technology I should prefer for frontend ? python flask, Bulma, Mesop by google or any other ? Thank you."},
{"Title": "Tuesday Daily Thread: Advanced questions", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "Ruff: A Modern Python Linter for Error-Free and Maintainable Code", "Author": "u/ajpinedam", "Content": "Linting is essential to writing clean and readable code to share with others. A linter, like Ruff, is a tool that analyzes your code and looks for errors, stylistic issues, and suspicious constructs. Linting allows you to address issues and improve your code quality before you commit your code and share it with others. Ruff is a modern linter that‚Äôs extremely fast and has a simple interface, making it straightforward to use. It also aims to be a drop-in replacement for many other linting and formatting tools, such as Flake8, isort, and Black. It‚Äôs quickly becoming one of the most popular Python linters. Installing Ruff Now that you know why linting your code is important and how Ruff is a powerful tool for the job, it‚Äôs time to install it. Thankfully, Ruff works out of the box, so no complicated installation instructions or configurations are needed to start using it. Assuming your project is already set up with a virtual environment, you can install Ruff in the following ways: ```bash $ python -m pip install ruff ``` You can check that Ruff installed correctly by using the ruff version command: ```bash $ ruff version ruff 0.4.7 ``` Linting Your Python Code While linting helps keep your code consistent and error-free, it doesn‚Äôt guarantee that your code will be bug-free. Finding the bugs in your code is best handled with a debugger and adequate testing, which won‚Äôt be covered in this tutorial. Coming up in the next sections, you‚Äôll learn how to use Ruff to check for errors and speed up your workflow. Checking for Errors ```bash $ ruff check one_ring.py:1:8: F401 [*] `os` imported but unused one_ring.py:10:12: F821 Undefined name `name` Found 2 errors. [*] 1 fixable with the `--fix` option. ``` Success! Ruff found two errors. Not only does it show the file and line numbers of the errors, but it also gives you error codes and messages. In addition, it lets you know that one of the two errors is fixable. Great! You can tell Ruff to fix errors by applying the --fix flag. Here‚Äôs what happens when you follow its suggestion: ```bash $ ruff check --fix one_ring.py:9:12: F821 Undefined name `name` Found 2 errors (1 fixed, 1 remaining). ``` You can find the rest of this Free tutorial here"},
{"Title": "Advice for creating 3D modelling program", "Author": "u/Latter-History-8053", "Content": "I am creating a Python program which models 3D shapes so that they can be saved and or interacted with (i.e. rotated). The process currently takes a while to render shapes consisting of multiple materials. The libraries being implemented are currently matplotlib and numpy. What would you advise for improving the rendering process (library choice etc)?"},
{"Title": "pieshell: python for shell scripting and as an interactive shell", "Author": "u/Severe_Inflation5326", "Content": "Pieshell is a Python shell environment that combines the expressiveness of shell pipelines with the power of python iterators. It can be used in two major ways: As an interactive shell replacing e.g. bash As an ordinary python module replacing e.g. subprocess.Popen Obligatory example: 140:/home/oven/pieshell >>> for x in ls(-a) | tr(\"s\", \"S\"): ...   if x.endswith('.py'): ...      print x ... Setup.py Source code: https://github.com/redhog/pieshell What the project does It's a replacement for the subprocess module, and for bash as an interactive shell, and makes interacting with shell pipelines easier. Target Audience System administrators, system software developers, data scientists Comparison While os.system is very limited but easy to use, subprocess.Popen offers a lot of flexibility, but the interface is very low level. Any actual pipelining of multiple programs is pretty much required to be done by e.g. a bash process, constructing the pipeline as a shell script string. Further, interacting with standard in and standard out requires careful IO handling. Pieshell on the other hand lets you construct pipelines as python objects. Standard io from a pipeline can be handled using iterators or async iterators. Pieshell has full asyncio integration."},
{"Title": "How does Python earn money? What would have been their business model?", "Author": "u/Civil-Captain5676", "Content": "I was wondering recently about any startup and any coding language that how does they make money. So I was curious to know about Python which is widely used"},
{"Title": "I created a script to automatically patch revanced", "Author": "u/ltlbwu", "Content": "What My Project Does AutoReVanced is a Python script that automates downloading and patching APKs using ReVanced patches from ApkPure. It's perfect for anyone wanting to patch their revanced app. Target Audience Suitable for a fun side project or hobbyists, AutoReVanced is designed for anyone wanting to customize Android apps with ReVanced patches. Comparison Unlike alternatives, AutoReVanced is automatic. GitHub: autorevanced"},
{"Title": "Monday Daily Thread: Project ideas!", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "abstract-factories - a simple framework for content creation pipelines", "Author": "u/HistoricalCrow", "Content": "Hey all, my project abstract_factories is up to gauge interest and primarily feedback. The design goal is to make it easier to iterate on typical Content Creation pipeline tools (tool dev, rigging, validation, asset management etc) with a flexible framework to provide convenience, open and simple design and no dependencies (currently). It's an approach I've used a lot over the years and found it pretty versatile in production across numerous projects. Key features Auto-registration of matching items (types or instances) from any given path or python module. Simple or conditional item identifiers. Versioning. Recursive path searching (recursive module search in review). Dynamic resolving and importing modules in packaged (supports relative importing). Usage Examples There are a couple of simple examples given along with tests to cover all of the current features. What the project does It's a convenience package for creating scalable tools and frameworks using Abstract Factory design pattern. Target Audience Due to the solutions it's built for, it's aimed primarily at Technical Artists, Technical Animators, Pipeline and Tool Developers, but I'm interested in hearing about other possible applications. Comparison Compared to other Factory and Abstract Factory convenience packages, mine is based on the work from this GDC talk . The direct abstract-factories currently comes with a few more conveniences I've found useful during production. The idea stems from boiling down Pyblish to something that became a little more reusable when writing frameworks as opposed to being the framework. Suggestions, questions, comments etc welcome."},
{"Title": "Showcase: pdf-to-podcast.com -- Convert PDF's to podcast episodes. Free and open-source :)", "Author": "u/knowsuchagency", "Content": "What My Project Does Upload any PDF and have it converted into a podcast episode with two or more speakers discussing its contents. https://github.com/knowsuchagency/pdf-to-podcast Target Audience Anyone, but other developers in-particular. The code is open-source on GitHub and there's a link to the source on https://pdf-to-podcast.com . I want the project to serve as an illustrative example of how to build useful things on top of LLMs with relatively little code. Comparison I just made this for fun. It's possible there are other similar projects"},
{"Title": "Have anyone tried google/mesop", "Author": "u/codes_astro", "Content": "Google Open sourced Mesop. Mesop is a Python-based UI framework that allows you to rapidly build web apps. Used at Google for rapid internal app development similar to Streamlit. find more here"},
{"Title": "I created Yu-Gi-Oh! Power of Chaos save handler", "Author": "u/wildpantz", "Content": "Quick backstory: Upper floor of my house is sort of a man-cave until we decorate it, so during this time I have two PCs which I use to play games with a friend when we have extra time to waste. The other day I remembered the game mentioned in the title and we had lots of fun playing it (there's 3 different games in this series). I decided I'd transfer the save file to my main PC so I can play when he's not visiting and I quickly learned it's an extremely annoying process to transfer save files across different PCs. Long story short, you need to find a proper registry key (which isn't always located at same spot for some reason) and you need to locate a system.dat file also located in a folder that isn't always in the same place. This process gets tedious pretty quick, so I decided to use the power of Python to make my life easier. What the project does: It's essentially a CLI save handler for the game mentioned in the title. It has 5 slots where you can backup your current save or load the backup to the computer. It can also fix minor registry issues if needed. Target audience: Given that I'm about 20 years too late... I'd say mostly people with very slow PCs or people who like to inhale nostalgia. I learned a lot about using winreg and msvcrt and getch, so while I will likely get bored of the game in the coming weeks, I'm happy I learned something new in the meantime, plus maybe someone finds it useful! Source code: markomavrinac/yugioh_poc_save_handler: Yu-Gi-Oh! Power of Chaos save handler - A script to manage your save games across multiple computers (github.com)"},
{"Title": "Tutorial: A Timely Python Multi-page Streamlit Application on Olympic Medal Winning Countries", "Author": "u/jgloewen", "Content": "Streamlit is an open-source app framework that allows data scientists and analysts to create interactive web applications with ease. Using just a few lines of Python, you can turn data scripts into shareable web apps. And combined with a data visualization library like Plotly, you can create beautiful charts and maps with only a few lines of code. In this article, let me step you through how to use Streamlit to create a multi-page interactive application that visualizes Olympic medal data. The application will have three pages: an overview of medal counts, a country-specific analysis, and a choropleth map displaying global medal distributions. Let‚Äôs get to it! Link to free article HERE Github repo HERE"},
{"Title": "Learning Python coming from a JVM background", "Author": "u/Human_Dependent6814", "Content": "I have 4 years worth JVM languages (Java, Kotlin) and have a need to learn some Python.  What's a good resource to get up to speed quickly with idiomatic Python?"},
{"Title": "I made a cool calendar app with PyQt6", "Author": "u/Specialist-Arachnid6", "Content": "Tempus is a calendar with horoscopes, reminders, etc made with PyQt6 What my Project does? Tempus is a desktop-based calendar management application built with PyQt6, allowing users to manage their todos, reminders, and special dates efficiently. It offers features like adding, editing, and deleting tasks and reminders, as well as marking dates as special. Tempus ensures users stay organized and never miss important events. Plus, it shows you how many days are remaining until a special day in the dashboard. Target Audience Well, anyone who uses a desktop calendar app I guess? Comparison I did some research and couldn't find good calendar apps made with PyQt6.  If you guys knows any, please mention it below and I'm sorry in advance. GitHub https://github.com/rohankishore/Tempus"},
{"Title": "Better-OrderedMultiDict - a fast pure-pyton implementation of an ordered multi-valued dictionary.", "Author": "u/JoachimCoenen", "Content": "What my project does It provides a fast pure-python implementation of an ordered, multi-valued dictionary. Target audience Python developers that need this kind of specialized functionality. This can be used in production. It has no dependencies. The code is unit-tested (almost fully, I'm working on it) It requires Python 3.12+ Comparison Comparison to dict and OrderedDict dict and OederedDict are already ordered, but they only allow one value per key. You could use a defaultdict of lists, but then you have these disadvantages: you can end up with empty lists within the dict if you aren't careful you lose the order of individual items within the dict: items = [(1, '1'), (2, '2'), (2, '22'), (1, '11')] normal_dict = defaultdict(list) for key, value in items: normal_dict [key].append(value) om_dict = OrderedMultiDict(items) print(list(normal_dict .items)) # prints [(1, ['1', '11']), (2, ['2', '22'])] print(list(om\\_dict.items))     # prints [(1, '1'), (2, '2'), (2, '22'), (1, '11')] iterating over all key/value pairs can be cumbersome as you need nested loops Comparison to omdict . OederedDict provides a (in my opinion) nicer interface with less surprising behavior or pitfalls. My implementation is also faster. e.g iterating over all items is ~5x faster. More info This started as a toy project, that later became useful to me, so I decided to cleanup the code, add tests, and publish it. from better_orderedmultidict import OrderedMultiDict omd: OrderedMultiDict[int, int] = OrderedMultiDict([(1,1), (2,2), (1,11), (2,22)]) for key in reversed(omd.unique_keys()): print(f\"{key}: {omd.getall(key)}\") # prints: # 2: [2, 22] # 1: [1, 11] print(omd.popfirstitem())  # prints: (1, 1) print(omd.poplast(2))  # prints: 22 for key in reversed(omd.unique_keys()): print(f\"{key}: {omd.getall(key)}\") # prints: # 2: [2] # 1: [11] Installation You can install Better-OrderedMultiDict using pip: pip install better-orderedmultidict Contributing If you have any suggestions or improvements for Better-OrderedMultiDict, feel free to submit a pull request or open an issue on the GitHub repository . I appreciate any feedback or contributions! Links Here's the link to the GitHub repository: https://github.com/JoachimCoenen/Better-OrderedMultiDict Here's the link to PyPi: https://pypi.org/project/better-orderedmultidict"},
{"Title": "Cant decide between flask, django ninja or fastAPI for sideproject", "Author": "u/Eggesalt", "Content": "As the title says, I cant decide what to use for rest api for mye summer project. I am uni student, so this project will only be very small scale project. I have made simpel rest apis in sll of them, but still cant decide which one to actuslly use for my project. Do anyone have any tips for which might be right one? A thing to consider for me answel is how easy it is to host."},
{"Title": "Sunday Daily Thread: What's everyone working on this week?", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "Built a RAG ( Retrieval-Augmented Generation ) model using Gemini Api.", "Author": "u/inobody_somebody", "Content": "what my project does This project is built to solve the issue of LLM unable to produce relevant answers for information in a particular context. uses the information  to train the model and stored it in a database and uses  this database to get relevant answers from the Model. Target audiance This project is for people who want to train a LLM on a particular piece of information. comparison This model only gives answers for information regarding the data you provided in the file. It will not answer any other questions including formal greetings. GitHub link : https://github.com/dharmateja2810/RAG-Retrieval-Augmented-Generation-Model"},
{"Title": "Python automation ideas", "Author": "u/LeastPrice8673", "Content": "Hi I‚Äôm looking for inspiration for some stupid python automation projects. If you have done something funny or stupid using python automation I would love to hear it."},
{"Title": "Lua-style code blocks for Python", "Author": "u/guangrei", "Content": "Python is a great programming language, but sometimes the indentation can be terrible for some people (especially people with visual impairments). So i created Lython . What the project does: Lython replacing the Python indentation to lua-style code blocks. this is example lython code def test(num) for i in range(num) do if i == 0 then print(\"zero\") elif i % 2 == 1 then print(\"odd\") else print(\"even\") end # if else end # for end # def test(10) for more info, please visit lython repo. Target audience: Peoples with visual impairments (especially) and Programmers who want to write python code with new experience (generally) Repo & Source code: guangrei/lython"},
{"Title": "I made an MMORPG with Python & Telegram in 4 weeks", "Author": "u/LordOmbro", "Content": "well, kind of. I made Pilgram, an infinite idle RPG where your character goes on adventures and notifies you when stuff happens. What my project does The bot provides a text interface with wich you can \"play\" an MMO RPG, it's basically an online idle adventure game Target audience It's a toy project that i made out of boredom, also it sounded cool Comparison I never heard of anything like this except for some really old browser games. Maybe i'm just not informed. More info How is it infinite? The secret is AI . Every quest and event in the game is generated by AI depending on the demand of the players, so in theory you can go on an infinite amount of quests. Why did i call it an MMO? Because you can kind of play with your friends by creating & joining guilds and by sending gifts to eachother. There even is a guild leaderboard to see who gets the most points :) The interface is exclusively text based, but the command interpreter i wrote is pretty easy to integrate in other places, even in GUIs if anyone wants to try. I tried out a lot of new things for this project, like using ORMs, writing unit tests (don't look at those, i kinda got bored after a short while), using AI & writing generic enough code that it can be swapped with any other implementation. I think most of the code i wrote is pretty ok, but you can tell me what to change & what to improve if you want. Links here's the link to the code: https://github.com/SudoOmbro/pilgram if you wanna try out the version i'm running on my server start a conversation with pilgram_bot on Telegram, don't expect a balanced experience at first since that was kind of the last of my problems lol"},
{"Title": "Introducing Temporal Adjusters: Simplify Time Series Adjustments in Python!", "Author": "u/MDTv_Teka", "Content": "Hey guys! I'm excited to introduce Temporal Adjusters, a new Python package designed to make time series adjustments easier and more efficient. If you work with time series data, you'll find this tool incredibly useful for various temporal adjustments. What my project does Adjusters are a key tool for modifying temporal objects. They exist to externalize the process of adjustment, permitting different approaches, as per the strategy design pattern. Temporal Adjuster provides tools that help pinpoint very specific moments in time, without having to manually count days, weeks, or months. In essence, a Temporal Adjuster is a function that encapsulates a specific date/time manipulation rule. It operates on a temporal object (representing a date, time, or datetime) to produce a new temporal object adjusted according to the rule. Examples might be an adjuster that sets the date avoiding weekends, or one that sets the date to the last day of the month. Installation You can install Temporal Adjuster using pip: pip install temporal-adjuster Usage This package provides a set of predefined temporal adjusters that can be used to adjust a temporal object in various ways. For example: >>> from datetime import date, datetime >>> from temporal_adjuster import TemporalAdjuster >>> from temporal_adjuster.common.enums import Weekday >>> TemporalAdjuster.first_day_of_next_week(date(2021, 1, 1)) datetime.date(2021, 1, 4) >>> TemporalAdjuster.last_day_of_last_month(datetime(2021, 1, 1)) datetime.datetime(2020, 12, 31) >>> TemporalAdjuster.first_of_year(Weekday.SATURDAY, date(2021, 1, 1)) datetime.date(2021, 1, 2) >>> TemporalAdjuster.nth_of_month(Weekday.SUNDAY, datetime(2021, 5, 1), 2) datetime.datetime(2021, 5, 9) >>> TemporalAdjuster.next(Weekday.MONDAY, datetime(2021, 2, 11), 2) datetime.datetime(2021, 2, 15) Contributing If you have any suggestions or improvements for pynimbar, feel free to submit a pull request or open an issue on the GitHub repository as per the CONTRIBUTING document. We appreciate any feedback or contributions! Target audience This can be used in production. It has only one depedency, dateutils, which if you're manipulating temporal objects you probably already have. All the code is 100% unit-tested, as well as build tested for all supported Python versions. Comparison This is based on Java's native TemporalAdjuster interfaces, but I found no similar library/functionality for Python."},
{"Title": "Created an Api for APKpure", "Author": "u/ltlbwu", "Content": "Like the title said. I created an API fro apkpure.com . I was creating a script to automate YouTube Revanced, but i couldn't find anyway to download the apk. You can try out the app here: https://github.com/anishomsy/apkpure What My Project Does It allows you to download apk from apkpure . Users can easily fetch specific versions of Android apps programmatically. Target Audience it is a hobby project, anyone can use it Comparison I did not find any existing alternatives. So I created my own. The only other way was to download it manually which is very tedious. Please lmk how i can improve. Thank you"},
{"Title": "Saturday Daily Thread: Resource Request and Sharing! Daily Thread", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "My first Python package, D1py: A very simple library to interact with Cloudflare D1 Database API", "Author": "u/ogMasterPloKoon", "Content": "What My Project Does Cloudflare offers a free SQLite based database D1. I needed it for some personal project so I thought of creating a very simple wrapper for it. D1py let's you connect to D1 database in your cloudflare account and run SQL queries(CRUD operations). Target audience For those who need a simple wrapper for Cloudflare D1 API for their projects. Comparison Right now there are no Python wrappers or libraries for D1 yet.... that's why I thought of creating one. It's not perfect but it is my first attempt at writing a small library/package for doing a task. Source Repository: https://github.com/Suleman-Elahi/D1py Feel free to drop any suggestions. Thanks."},
{"Title": "Perpetual - a self-generalizing, hyperparameter-free gradient boosting machine", "Author": "u/mutlu_simsek", "Content": "https://github.com/perpetual-ml/perpetual What My Project Does PerpetualBooster is a gradient boosting machine (GBM) algorithm which doesn't have hyperparameters to be tuned so that you can use it without needing hyperparameter optimization packages unlike other GBM algorithms. Similar to AutoML libraries, it has a budget parameter which ranges between (0, 1) . Increasing the budget parameter increases predictive power of the algorithm and gives better results on unseen data. Start with a small budget and increase it once you are confident with your features. If you don't see any improvement with further increasing budget , it means that you are already extracting the most predictive power out of your data. Target Audience The project is meant for production. You can replace hyperparameter packages plus other gradient boosting algorithms with PerpetualBooster. Comparison Other gradient boosting algorithms (XGBoost, LightGBM, Catboost) and most of the machine learning algorithms need hyperparameter optimization for the best performance on unseen data. But PerpetualBooster doesn't have hyperparameters so it doesn't need hyperparameter tuning. It has a built-in generalization algorithm and provides the best performance. The following table summarizes the results for the California Housing dataset: Perpetual budget LightGBM n_estimators Perpetual mse LightGBM mse Perpetual cpu time LightGBM cpu time Speed-up 0.33 100 0.192 0.192 10.1 990 98x 0.35 200 0.190 0.191 11.0 2030 186x 0.45 300 0.187 0.188 18.7 3272 179x"},
{"Title": "Problem details for FastAPI applications (RFC9457)", "Author": "u/BluesFiend", "Content": "Just released v0.8.0 of fastapi_problem to provide problem details for FastAPI applications. Hoping it can provide value to some other peoples projects. Code: https://github.com/NRWLDev/fastapi-problem Docs: https://nrwldev.github.io/fastapi-problem/ Pypi: https://pypi.org/project/fastapi-problem/ What My Project Does Provides a simple exception handler and an underlying exception class heirarchy to remove the need to think about error management in your FastAPI project, just raise errors as appropriate and let the handler deal with responses. Target Audience Web developers Comparison There was a previous project that supported RFC7807 but that is no longer maintained, and is also made obsolete by RFC9457. RFC9457 For anyone who does not make use of FastAPI, the underlying exception library has also been released, and can be used to implement handlers for any web framework you might be into. https://github.com/NRWLDev/rfc9457 https://pypi.org/project/rfc9457/"},
{"Title": "I tried to explain python imports", "Author": "u/MaKaNuReddit", "Content": "When I was a beginner (or maybe still I am) I struggled a lot with pythons import function. Over the years I went over different approaches, how to handle imports and ended up using mostly exclusive poetry. I've met a lot of people struggling the same way, bit always could just explain very shortly my experience. I've now decided to write it down as a scenario, where I can show and explain my pitfalls: https://github.com/MaKaNu/pyimport-explained"},
{"Title": "a new version of ultimateultimateguitar", "Author": "u/sonobanana33", "Content": "What My Project Does It is a CLI to get songs from ultimateguitar. How it looks like: https://youtu.be/Spm1IIaYo8Q I've only tried it on linux. Available in debian and pypi. Target audience For musicians who also use the terminal and who don't especially like the ultimateguitar website. Comparison I'm not aware of other projects doing the same thing. Compared to the website, it can transpose and it is much faster. Source Project website: https://codeberg.org/ltworf/ultimateultimateguitar Out of date website (just here to avoid the post to be auto-removed): https://github.com/ltworf/ultimateultimateguitar"},
{"Title": "how about one-line try-except statement ?", "Author": "u/17thCurlyBrace", "Content": "is there a proposal for a shorter exception handling syntax for those very frequent cases where a library function doesn't return \"error value\" like str.index ? something like instead of : try: i = my_str.index(\"sub\", st, en) except ValueError: # if \"sub\" has not been found pass else: # do stuff with i (note that i usually want independent error handling here) something like this : i = my_str.index(\"sub\", st, en) except ValueError -1 # or maybe even return here if i == -1: # also can return right away if i want to avoid an indent next # do stuff with i ... i suspect there might be something \"un-pythonic\" here in what i am imagining , but please forgive me if that's the case . i am a fan of Python for many years , but haven't really invested any time in learning the philosophy so i am interested in what the community thinks about this , how ok would such syntax be from the point of the \"Python way\" , and if there is such a proposal i would like to know if i can consider maybe voting on it somehow"},
{"Title": "uv added experimental commands for `uv add/remove`", "Author": "u/BaggiPonte", "Content": "uv is the \"pip but blazingly fast‚Ñ¢Ô∏è because it's written in rust\" and is developed by the same folks that did ruff. In 0.2.11 they released an experimental/preview command of `uv add/remove` that adds a library to pyproject.toml. It's the first step to become a fully-fledged package manager! I noticed you can also manage python installations with uv using `uv toolchain` command (i.e. be like pyenv) and run tools (like a smaller version of pipx) with `uv run`. I'm genuinely excited about this, Python packaging is going to become such a smooth experience üòé Commands are in preview so expect missing stuff. (I bear no affiliation with astral) https://github.com/astral-sh/uv"},
{"Title": "Pathway - Build Mission Critical ETL and RAG in Python (used by NATO, F1)", "Author": "u/dxtros", "Content": "Hi Python data folks, I am excited to share Pathway, a Python data processing framework we built for ETL and RAG pipelines. https://github.com/pathwaycom/pathway What My Project Does We started Pathway to solve event processing for IoT and geospatial indexing. Think freight train operations in unmapped depots bringing key merchandise from China to Europe. This was not something we could use Flink or Elastic for. Then we added more connectors for streaming ETL (Kafka, Postgres CDC‚Ä¶), data indexing (yay vectors!), and LLM wrappers for RAG. Today Pathway provides a data indexing layer for live data updates, stateless and stateful data transformations over streams, and retrieval of structured and unstructured data. Pathway ships with a Python API and a Rust runtime based on Differential Dataflow to perform incremental computation. All the pipeline is kept in memory and can be easily deployed with Docker and Kubernetes (pipelines-as-code). We built Pathway to support enterprises like F1 teams and processors of highly sensitive information to build mission-critical data pipelines. We do this by putting security and performance first. For example, you can build and deploy self-hosted RAG pipelines with local LLM models and Pathway‚Äôs in-memory vector index, so no data ever leaves your infrastructure. Pathway connectors and transformations work with live data by default, so you can avoid expensive reprocessing and rely on fresh data. You can install Pathway with pip and Docker, and get started with templates and notebooks: https://pathway.com/developers/showcases We also host demo RAG pipelines implemented 100% in Pathway, feel free to interact with their API endpoints: https://pathway.com/solutions/rag-pipelines#try-it-out We'd love to hear what you think of Pathway!"},
{"Title": "Friday Daily Thread: r/Python Meta and Free-Talk Fridays", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "Polars 1.0 will be out in a few weeks, but you can already install the pre-release!", "Author": "u/marcogorelli", "Content": "In a few weeks, Polars 1.0 will be out. How exciting! You can already try out the pre-release by running: ``` pip install -U --pre polars ``` If you encounter any bugs, you can report them to https://github.com/pola-rs/polars/issues , so they can be fixed before 1.0 comes out. Release notes: https://github.com/pola-rs/polars/releases/tag/py-1.0.0-alpha.1"},
{"Title": "Try PyCharm (30% off!) and they donate 100% to the Django Software Foundation", "Author": "u/Affectionate_Sky9709", "Content": "There's a promotion right now to try PyCharm, get a 30% discount, and 100% of what you pay goes directly to the Django Software Foundation, which maintains Django and keeps it free for everyone. https://jb.gg/2atgzm I hope this kind of post is allowed."},
{"Title": "I ported Rust's Regex Library To Python, but the time taken by the compile parameter was high.", "Author": "u/RevolutionaryPen4661", "Content": "(.venv) PS D:\\flpc> python .\\seed\\test.py Operation  | flpc (ms)  | re (ms) ---------------------------------- Compile    | 1496.18077 | 0.00000 Search     | 19.67597   | 1721.07339 Find Match | 15.62524   | 16.72506 Full Match | 15.62500   | 0.00000 Split      | 0.00000    | 1722.88108 Find All   | 3.02815    | 1660.32910 Find Iter  | 5.96547    | 1672.50776 Sub        | 0.00000    | 1548.61116 Subn       | 6.70719    | 1676.84698 Escape     | 4.87757    | 0.00000 (.venv) PS D:\\flpc> flpc is the name of the library. I named it (spelt as flacpuc). The strange thing is that why the compile time is high of flpc (rust) than of re module (implemented in Pure-Python) (it does the same thing what re.compile does in Python). The benchmark is done on: PATTERN = r'(\\w+)\\s+(\\d+)' TEXT = ''.join(choices(ascii_letters + digits, k=1000)) # choices function from random module ITERATIONS = 100 The problem is that, the python should be slow in the parameter (Regex Compile). However, the rest of parameters looks great! VERY FAST!"},
{"Title": "Vedo or PyVista?", "Author": "u/AlexTheRandomizer", "Content": "Hi guys! What are your experiences with Vedo or PyVista? Which one do you prefer? Did you have any specific issues which either of these libraries? I'm mostly interested in meshes and point clouds rendering."},
{"Title": "Sold my Python open source project to a San Francisco AI company. Now I work for them. AMA.", "Author": "u/romerio86", "Content": "About a year ago, I posted on this sub. I was terrified. I was launching a new framework. Another framework? Yes, I was crazy enough to think we needed yet another framework. Thankfully, the response was great. Many were excited to try it. Others were understandably skeptical, and respectfully asking good questions. This time, I'm posting for completely different reasons. I want to share a story. A story of which this sub, and hundreds of you, are part. It all started 2 years ago, when I was laid off from my analytics consulting job. I had a well-paying, comfortable job in the UK. Then I moved from the UK to Poland, where I live now, and continued working remotely. I was living the dream; earning a London salary while living in a place with a lower cost of living. Until it ended with a layoff. I thought, this is it. My career is dead. I didn't speak Polish properly, limiting my options. And finding another fully remote job working for the UK sounded overly optimistic at the time. Being in my mid 30s and with a family to support, I didn't want to start over again. I knew Python and data analytics quite well, and also had frontend skills I had gained throughout the years. So I thought... I need to show what I can do. I didn't have a portfolio at all; my GitHub was empty. After trying Streamlit, I thought the concept was great, but the execution wasn't. So I wrote an article on Medium, discussing how a better, faster alternative was possible. I also created a POC and shared it on GitHub. Thankfully, due to contacts at my previous job, I was able to find another remote job, working for the UK w. With even better pay. So naturally, I forgot about my portfolio-building efforts. But after a few months, an investor (VC) from Germany reached out to me. He had seen the Medium article and asked me whether I'd like to do this full time. I hesitated, but eventually decided to explore this further. I didn't need any investment though; my idea was quite simple. And to be honest, not too different from other frameworks, just faster. I had to think bigger. One day, at London Stansted Airport, while waiting to board a plane home, I decided to go for it and came up with the idea of no-code in the front, Python in the back. In other words, building the frontend using a visual editor, while allowing for full freedom in the backend using Python, and abstracting all the connectivity between. The VC liked the idea, but wasn't fully convinced about my ability to execute. He decided not to invest. But since I liked the idea and thought it could go somewhere, I decided to try building it myself, at night, after work. For 9 months, that was my reality. Nights, weekends. If my baby son would wake up, early mornings too. In May 2023, I managed to get the framework to a state I was happy with, and launched it. The response was very good. I eventually got to 1000 stars on GitHub, a milestone for any open source project. To a great extent, thanks to the support of communities such as r/python and r/opensource . Also, thanks to sites like Medium and Product Hunt. A few months later, in November 2023, the CTO of a multibillion AI company reached out to me. They wanted to acquire my framework, hire me, and build a team for me to continue developing it. I was ecstatic. He told me he'd go on a Thanksgiving break for a few days and that he'd reach out to me after. He never got back to me. Accepting that this wasn't going to happen was tough. Two weeks later, the CTO of another AI company called me, together with the CEO. They also wanted to acquire me and make me a part of their team. A smaller company, much more interesting and already quite established, with clients such as Accenture and Salesforce. But with grit and determination to win in the space of enterprise generative AI. This time, it did work out and my framework was finally acquired. Now I work for them and I lead a team focused on maintaining this open source project. Happy to answer any questions. And THANK YOU for your support r/python !!! For those curious: https://github.com/writer/writer-framework"},
{"Title": "Building AI Text-to-Video Model From Scratch", "Author": "u/FareedKhan557", "Content": "What My Project Does This project aims to create a small-scale text-to-video model that can generate videos based on text prompts. Target audience This project is designed for individuals who want to learn how to create their own text-to-video model from scratch but don't know where to start. It will provide a basic guide from beginning to end, covering everything from generating the training data to training a model and using that trained model to generate AI videos. Comparison Currently available text-to-video models require high computational power, and their complex code makes it difficult for Rookie developers to understand the practical implementation, beyond just the theory. To address this, I have created a small-scale GAN architecture, similar to text-to-video models, which can be trained on a CPU or a single T4 GPU. GitHub Code, documentation, and example can all be found on GitHub: https://github.com/FareedKhan-dev/AI-text-to-video-model-from-scratch"},
{"Title": "Sunday Daily Thread: What's everyone working on this week?", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "Saturday Daily Thread: Resource Request and Sharing! Daily Thread", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "My library VidGear `v0.3.3` - brings libcamera API Support to python.", "Author": "u/abhi_uno", "Content": "Hello Python developers! I'm excited to announce the release of VidGear v0.3.3 , which brings official support for the libcamera backend in its PiGear API ! This update enhances the capabilities of Raspberry Pi Camera Modules and provides limited USB camera support. More about PiGear: PiGear is a specialized API optimized for Raspberry Pi üçá Boards, offering comprehensive support for camera modules (e.g., OmniVision OV5647 Camera Module, Sony IMX219 Camera Module) and limited compatibility for USB cameras. PiGear implements a seamless and robust wrapper around the Picamera2 Python library, simplifying integration with minimal code changes and ensuring a smooth transition for developers already familiar with the Picamera2 API. PiGear leverages the libcamera API under the hood with multi-threading, providing high-performance üî•, enhanced control, and functionality for Raspberry Pi camera modules. PiGear handles common configuration parameters and non-standard settings for various camera types, simplifying the integration process. PiGear currently supports PiCamera2 API parameters such as sensor, controls, transform, and format, with internal type and sanity checks for robust performance. While primarily focused on Raspberry Pi camera modules, PiGear also provides basic functionality for USB webcams (only with Picamera2 API), along with the ability to accurately differentiate between USB and Raspberry Pi cameras using metadata. PiGear seamlessly switches to the legacy picamera library if the Picamera2 library is unavailable, ensuring seamless backward compatibility. PiGear also provides a flexible multi-threaded framework around the complete picamera API, allowing developers to effortlessly exploit a wide range of parameters, such as brightness, saturation, sensor_mode, iso, exposure, and more. Furthermore, PiGear supports the use of multiple camera modules, including those found on Raspberry Pi Compute Module IO boards and USB cameras (only with Picamera2 API). We're eager to see the innovative projects you'll create with PiGear! For more details and to get started, check out our GitHub repository . Happy coding! Feel free to ask any questions or share your feedback below. Let's discuss and innovate together! üöÄ"},
{"Title": "discover-plugins - track which plugins are installed into your python environment", "Author": "u/fesch2", "Content": "What my project does discover-plugins is a simple CLI tool that lets you list and filter plugins entrypoints installed into a python environment. I recently had to track down a bug that I ultimately resulted from a plugin I had installed into my environment.  To my surprise, there was no easy way to list which kind of plugins were installed, so I decided to build my own tool. Target Audience discover-plugins is intended as a debugging tool for those times when you are not quite sure which plugins are currently part of your python environment. Installation pipx install discover-plugins Usage Find all installed plugins related to pytest (the relevant group name is pytest11 ): discover-plugins --group pytest11 The tool defaults to use the first python interpreter on your path, you can optionally specify which interpreter to use with the --interpreter flag. The output will list all entrypoints belonging to the pytest11 group. For example, if you had installed a single pytest plugin ( pytest-aws-apigateway ) the output would look like this: { \"pytest11\": [ { \"name\": \"pytest_httpx\", \"group\": \"pytest11\", \"value\": \"pytest_httpx\" }, { \"name\": \"anyio\", \"group\": \"pytest11\", \"value\": \"anyio.pytest_plugin\" }, { \"name\": \"pytest-aws-apigateway\", \"group\": \"pytest11\", \"value\": \"pytest_aws_apigateway.plugin\" } ] } Links Link to GitHub: https://github.com/felixscherz/discover-plugins PyPI: https://pypi.org/project/discover-plugins/ Let me know if the tool helped you out! Cheers!"},
{"Title": "Is anyone here looking for a developer to contribute to your personal projects?", "Author": "u/homelander_30", "Content": "I guess the title explains it all, I'm looking for some personal projects to work or contribute on and would be really helpful if anyone is looking for a dev. I did look upon some open-source projects but they were too advanced and out of scope for me so I just wanna start small and learn."},
{"Title": "cool tool made with python", "Author": "u/SuccessfulLiving757", "Content": "I made a cool tool with python named Cookie Monster (not the one from sesmene street). It fetches cookies from a website and it is kinda broken... you can install it from https://sojoyork.github.io ! And yes it is one of my best python projects! I hope you like it.! And the GitHub repository is https://github.com/sojoyork/sojoyork.github.io ! (also am new to reddit)"},
{"Title": "I made a little Python quiz for interns and new Python developers at my company", "Author": "u/Penny-loafers", "Content": "I put this quiz together to help create conversation for interns and new python developers at my company. Its based on the content from one of my favourite books ( Fluent Python ). I hope you enjoy it! Quiz"},
{"Title": "Running Python in Web Browsers", "Author": "u/pdfisk", "Content": "Python is one of the world's most popular programming languages and the web is the most ubiquitous application platform. There are several projects which aim to enable Python to run in web browsers. Brython is an implementation of Python 3 written in JavaScript. Skulpt is an implementation of Python 2/3 written in JavaScript. PyScript is an implementation of Python 3 written in WebAssembly. Transcrypt is a Python to JavaScript compiler - unfortunately, the project seems to have been abandoned. Batavia is a Python virtual machine written in JavaScript - unfortunately, the project seems to have been abandoned. Finally, I have created VistaPython which is also intended to run Python 3 in web browsers but by using a bytecode interpreter written in JavaScript. Each design has strengths and weaknesses: Both Brython and Skulpt use hand-written Python parsers which are difficult to maintain. VistaPython uses a parser generator, Antlr , to automatically generate the JavaScript code for the parser. The parser can be updated to match the latest Python version by simply running a script. Also, both Brython and Skulpt generate JavaScript code which is then evaluated. In VistaPython, the compiler produces a \"code object\" which is then executed using the bytecode interpreter. The first approach will result in faster code whereas the second approach can be more flexible for code stepping, etc. PyScript is based on Pyodide which is a port of CPython to WebAssembly. PyScript can be upgraded the latest Python release by recompiling the latest CPython sources. Its main disadvantage is that it is very heavy to load and seems to run poorly on mobile devices. In VistaPython, the load profiles are: vm.js (Python virtual machine) 761kb Python parser 368 kb Mobile client GUI 2.4 Mb Desktop client GUI 2.9 Mb Compiled applications can be run using only the Python virtual machine (761kb). The design goal of VistaPython is to be able to load compiled applications from a database and run them quickly on any web device."},
{"Title": "A simple website scraper script", "Author": "u/SAV_NC", "Content": "Web Scraper Script What My Project Does This project scrapes websites to extract and display titles and links of articles. It processes multiple websites in parallel, fetching and parsing content to provide a consolidated list of articles with their full URLs. Target Audience Home users, researchers, and web enthusiasts who need to gather information from multiple websites quickly and efficiently. Features Parallel Processing : Uses ThreadPoolExecutor to fetch multiple websites concurrently, speeding up the scraping process. Error Handling and Logging : Provides detailed logging for debugging and retry mechanisms for robustness. Full URL Extraction : Ensures that all extracted links are complete URLs, enhancing usability. Customizable Headers : Allows customization of HTTP headers to mimic different browsers. Script Overview The script consists of several key components: Fetching URLs The script fetches content from the given URLs using the requests library. It includes retry logic with exponential backoff to handle transient errors. Parsing Content The script uses BeautifulSoup to parse the fetched HTML content and extract article titles and links. It ensures that the links are converted to full URLs using urljoin . Concurrent Execution The script employs ThreadPoolExecutor to fetch and parse content from multiple websites in parallel, improving efficiency. Access the Script You can access the script on GitHub here: Web Scraper Script on GitHub How to Use Install Dependencies : Ensure you have requests and beautifulsoup4 installed: pip install requests beautifulsoup4 Run the Script : Provide the URLs of the websites you want to scrape as arguments: python3 web-scraper.py https://yahoo.com https://sports.yahoo.com Conclusion This web scraper script is designed to be robust, efficient, and easy to use. It handles multiple websites in parallel, provides detailed logging, and ensures full URL extraction for all links. Ideal for users who need to quickly gather and consolidate information from various sources."},
{"Title": "Open source Python projects with good software design that is worth studying", "Author": "u/bolt_runner", "Content": "What are some software projects written in python that are well-structured and use good code design practices that are worth spending time to study?"},
{"Title": "Log Monitoring with Kafka ETL using Python via Docker and Pathway", "Author": "u/muditjps", "Content": "Hi r/Python , This project is for a Streaming ETL problem statement for Fraud-detection/Log Monitoring use-case. Here's a link to the blog explainer: https://pathway.com/developers/templates/kafka-etl GitHub Repo link: https://github.com/pathwaycom/pathway/tree/main/examples/projects/kafka-ETL What the Project Does Let's say we're monitoring logs from servers in New York and Paris. The logs have different time zones so you need to unify these different time zones into a single format to maintain data integrity. Now, Kafka is a popular ETL tool but it's usable only in Java/Scala. Target Audience This is mostly for Python developers/data scientists/ML engineers and people who work on Fraud Detection or ETL. Comparison This project leverages Pathway, a Python ETL framework powered by an underlying Rust engine that surpasses Flink/Kafka in benchmarks. With this Pythonic framework we: Extract data streams from Kafka using built-in Kafka input connectors. Convert times with varying time zones into unified timestamps the datetime module. Load the final data stream back into Kafka. The entire script is available as an app template on the repo, which can be run via Docker in minutes. Open to your feedback/questions!"},
{"Title": "localslackirc - bridge slack and IRC", "Author": "u/sonobanana33", "Content": "I made a minor bugfix release of localslackirc https://codeberg.org/ltworf/localslackirc It can be installed via apt or ran from sources. No pypi package, sorry. What My Project Does After configuring it with a token from slack, it creates a local IRC server that bridges with slack. It supports threads, sending files. It doesn't support reactions. It supports muting @here notifications from certain users or certain channels. It allows to silently leave a channel, but rejoins it if the user is personally mentioned there. Target Audience Mostly people who have to use slack for work and would prefer IRC. Comparison I am not aware of a project doing the same thing. I know weechat has a slack plugin, but that's slightly different. I don't use weechat and I wanted to keep using my IRC client. out of date link to avoid the post from being removed: https://github.com/ltworf/localslackirc"},
{"Title": "Python community in Amsterdam, The Netherlands", "Author": "u/FuturesBrightDavid", "Content": "Hi, I'm trying to find a Python community in Amsterdam in The Netherlands.  There used to be an active MeetUp group and Slack , but there has been little to no activity on either in a long, long time. Pythonistas in my city, what social / networking events or activities are there around here? Additionally, would anyone be interested in reviving the Python MeetUps in Amsterdam?"},
{"Title": "Eventum: Flexible event generator", "Author": "u/rnv812", "Content": "Hi, recently I created event generator in Python called Eventum . Here is a link to website: https://eventum-generatives.github.io/Website/ And the main repo: https://github.com/Eventum-Generatives/EventumCore What My Project Does It can be used in task like: Generation of datasets Simulation of processes in real time Filling different systems with demo data Testing on arbitrary data and stress testing Target Audience This generating tool is mostly for developers and people who work with data. It is also very near to ELK stack, OpenSearch and SIEM systems like Splunk . But you can use it as you want :) Comparison There is a project Eventgen developed by Splunk, but Eventum has next advantages over it: More rich events scheduling Extended functionality in event templates More parametrizable configurations Has content developing tools (UI for visualization time distributions and rendering templates)"},
{"Title": "Robogram - Minimal Wrapper for Telegram Bot API in Python", "Author": "u/RitvikTheGod", "Content": "Guys, I recently released my first (in a while) open-source project wrapper on Telegram Bot API . I call it robogram and when I was developing in Python, I had a use case to send notifications from Raspberry Pi to my iPhone via Telegram . After searching online, I found no minimalist wrapper in Python 3+ to send messages via Bot API. So, I decided to create one :-) What My Project Does Minimal Wrapper around the Telegram Bot API. It's only dependency is requests in Python which is ubiquitous. It allows to retrieve info on Bot, or to send messages to users via personal chat, channel, or group. Target Audience Toy project I just came up with, after realizing no solution out there was best fit for me. But I have deployed this on production for personal project, and it's for sure production-ready. Target audience here would be other developers who are on Telegram and looking to leverage Bot API to facilitate the sending of messages or notifications to an audience on Telegram. Comparison Some packages out there are only async support, or only work on Python 2 (actually I found one with some popularity that doesn't work in Python 3+ at all), or are dependency- or code- heavy and can introduce code bloat, especially to small, personal projects. As someone working on a personal project myself, I wanted a lightweight solution that only used minimal dependencies such as requests for making API requests. So, since I could not find one out there in wild, I decided to create my own! -- Interested to get your thoughts, if anyone likes it I will be glad to feedback. https://github.com/rnag/robogram"},
{"Title": "Introducing Lambda Forge: Simplifying AWS Lambda Deployment and Development!", "Author": "u/No_Coffee_9879", "Content": "Hey everyone, I just wanted to share a project I've been working on called Lambda Forge . It's a tool designed to simplify the deployment and management of AWS Lambda functions. If you're like me and spend a lot of time working with serverless architecture, you might find it pretty useful. What My Project Does Lambda Forge helps you deploy and manage AWS Lambda functions with ease. One of its standout features is the WebSocket connection for hot reloading of local code. It uses MQTT over Websockets to proxy requests to a local server, making development seamless. No more redeploying code just to see if your changes work! Target Audience This project is meant for developers who work with AWS Lambda in both production and development environments. Whether you're a seasoned backend engineer or just getting started with serverless, Lambda Forge can help streamline your workflow. Comparison Compared to other deployment tools, Lambda Forge focuses on enhancing the development experience with hot reloading capabilities. Many existing tools require a full redeployment for changes to take effect, which can be time-consuming. Lambda Forge's WebSocket integration saves time by allowing you to see changes in real-time without redeployment. If you're interested, you can check out the documentation here: Lambda Forge Docs And if you want to dive into the code or contribute, here's the GitHub repo: Lambda Forge on GitHub I‚Äôd love to hear your thoughts and feedback."},
{"Title": "Friday Daily Thread: r/Python Meta and Free-Talk Fridays", "Author": "u/AutoModerator", "Content": "Daily Thread"},
{"Title": "Mirascope-Python's Alternative To Langchain", "Author": "u/Active-Fuel-49", "Content": "Mirascope is a Python library that lets you access a range of Large Language Models, but in a more straightforward and Pythonic way. https://www.i-programmer.info/news/90-tools/17275-mirascope-pythons-alternative-to-langchain.html"},
{"Title": "Python on Cloud GPUs", "Author": "u/jrbourbeau", "Content": "Hi All, I wanted to try to speed up some Python code with a GPU recently and was pretty shocked at how difficult it is to properly set up and configure things. I have lots of experience in the PyData space, but am definitely not a cloud devops expert. So some colleagues and I wrote a decorator that automatically sets up a cloud VM, runs the decorated function, and returns the function‚Äôs result back locally to my laptop. Here‚Äôs an example that trains a PyTorch model on an NVIDIA A10 GPU on AWS. The Coiled Function API is nice because I didn‚Äôt have to build any Docker images, muck around in the AWS console, or do anything special to set up a cloud GPU. That said, there are definitely tradeoffs here. We optimized for privacy and no standing costs, so it takes ~1-2 minutes to fully spin up VMs (no warm pool of VMs waiting). We also only run on AWS/GCP/Azure so this doesn‚Äôt help with on-prem workloads. I‚Äôm definitely biased as I work at Coiled, but think this is a simple way to run Python on cloud hardware (especially for folks without a lot of cloud experience). I‚Äôm curious to hear from folks here. Do you have a favorite way to run Python code on the cloud? What do you like about your current setup? For example, ergonomics, performance, something else?"},
{"Title": "Web scraper for protein prices", "Author": "u/Knockoutpie1", "Content": "Hey everyone, looking for some input. For work I‚Äôve worked on web scraping for prices to see if my components are adequately priced on the internet compared to competitors. I can use this for protein prices as a personal project. I have experience now with Beautiful Soup, Selenium, and Excel Power BI. What route should I go? Should I only pull pricing from Amazon? Or should I do Amazon and the manufacturer site to see which is better pricing? Ideas would be great. Should be a fun project. If I go with beautiful soup, there‚Äôs no UI and I can print all to terminal If I use selenium, I can use UC to pass anti-bot measures and also print to terminal, but it will open a browser window for each price scrape. If I use excel power BI, I‚Äôll just load data to a worksheet and pricing will update at the price of a button."}
]